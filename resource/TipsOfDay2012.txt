
本机ip 10.1.171.132

通过svn管理记录文件 eg google code  TortoiseSVN
搭建centos测试系统(vmware7) ssh连接
wiki scheng 
Linux Container - LXC	
openapi rds  (关系型数据库服务)
	ref: http://www.ibm.com/developerworks/linux/library/l-lxc-containers/
test
	https://my-javaweb-project-demo.googlecode.com/svn
google 检索 apache site:*.apache.org 高级搜索
* mina
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
	It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
* Confluence 2.9.
	- 企业级 wiki ，便于交流互动 ，文档修改并记录历史类似版本控制，可以回滚，很是方便

* bat 批处理 不继续执行  (搜素 bat 调用mvn - 对于bat执行好mvn后就不继续执行其他操作的问题解决搜索关键词)
	- mavn web project 自动部署启动容器脚本(bat脚本)
		-------
			rem Eclipse 开发 maven web project部署脚本，便于部署调试

			echo stop tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call shutdown.bat

			echo build...
			echo
			cd D:\workspace\SLB-API-v2
			call mvn clean package

			echo delpoy...
			echo
			cd target
			cp -r slb.war D:\apache-tomcat-6.0.35\webapps

			echo start tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call startup.bat

			:end
		-------
	-
		在于不熟悉bat。联想到shell脚本，shell脚本会继续执行
		-------
			bat中mvn命令执行完后不继续执行的解决方法
			2012-04-24 17:29codeif.com 比如有下面一段批处理程序
			mvn clean
			echo “hello world”

			输出如下
			…..
			[INFO] BUILD SUCCESSFUL
			[INFO] ————————————————————————
			[INFO] Total time: 25 seconds
			[INFO] Finished at: Tue Apr 24 17:21:55 CST 2012
			[INFO] Final Memory: 43M/123M
			[INFO] ————————————————————————
			D:\test>

			hello world并没有输出,没有达到我们的预期
			在mvn前加上call,改为如下后
			call mvn clean
			echo “hello world”

			hello word就会输出了

			cmd命令行中Call的使用如下:
			Call 从一个批处理程序调用另一个批处理程序，并且不终止父批处理程序。
		------

* rest
	rest方式的请求，根据uri定位资源 ，各种http方法发送的请求 可以用matrix url请求rest服务
* memcache 
	c / c++
	项目主页: http://code.google.com/p/memcached/wiki/Clients	
	说明：
		memcached is a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. 
	Danga Interactive developed memcached to enhance the speed of LiveJournal.com, a site which was already doing 20 million+ dynamic page views per day for 1 million users with a bunch of webservers and a bunch of database servers. memcached dropped the database load to almost nothing, yielding faster page load times for users, better resource utilization, and faster access to the databases on a memcache miss. 
	If you're a developer, or interested in helping us along, please help test the latest beta release on the download page. We work hard to ensure the beta releases are of high quality, but as with all beta software, be warned. 
	
	 开源的东西，潜力与生俱来
	
	启动：
		memcached -d -m 10 -u root -l 10.1.171.130192.168.232.162  -p 12000 -c 256 -P /tmp/memcached.pid

	安装：
		
		- 需要libevent库 需要制定prefix
			wget http://github.com/downloads/libevent/libevent/libevent-2.0.18-stable.tar.gz --no-check-certificate
			tar -zxvf libevent-2.0.18-stable.tar.gz
			./configure --prefix=/usr
			make
			make install
			再继续memcache安装
			例子：
					Linux下Memcache服务器端的安装
					服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
					下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
					另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
					官网：http://www.monkey.org/~provos/libevent/
					下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

					用wget指令直接下载这两个东西.下载回源文件后。
					1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
					2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
					这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

					    1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
					    # cd /tmp
					    # wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
					    # wget http://www.monkey.org/~provos/libevent-1.2.tar.gz

					    2.先安装libevent：
					    # tar zxvf libevent-1.2.tar.gz
					    # cd libevent-1.2
					    # ./configure –prefix=/usr
					    # make
					    # make install

					    3.测试libevent是否安装成功：
					    # ls -al /usr/lib | grep libevent
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
					    -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
					    -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
					    -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
					    还不错，都安装上了。

					    4.安装memcached，同时需要安装中指定libevent的安装位置：
					    # cd /tmp
					    # tar zxvf memcached-1.2.0.tar.gz
					    # cd memcached-1.2.0
					    # ./configure –with-libevent=/usr
					    # make
					    # make install
					    如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
					    安装完成后会把memcached放到 /usr/local/bin/memcached ，

					    5.测试是否成功安装memcached：
					    # ls -al /usr/local/bin/mem*
					    -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
					    -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug 

					安装Memcache的PHP扩展
					1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
					2.安装PHP的memcache扩展

					    tar vxzf memcache-2.2.1.tgz
					    cd memcache-2.2.1
					    /usr/local/php/bin/phpize
					    ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
					    make
					    make install

					3.上述安装完后会有类似这样的提示：

					    Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

					4.把php.ini中的extension_dir = “./”修改为

					    extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

					5.添加一行来载入memcache扩展：extension=memcache.so

					memcached的基本设置：
					1.启动Memcache的服务器端：
					# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

					    -d选项是启动一个守护进程，
					    -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
					    -u是运行Memcache的用户，我这里是root，
					    -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
					    -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
					    -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
					    -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

					2.如果要结束Memcache进程，执行：

					    # kill `cat /tmp/memcached.pid`

					也可以启动多个守护进程，不过端口不能重复。

					3.重启apache，service httpd restart

					Memcache环境测试：
					运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
					< ?php
					$mem = new Memcache;
					$mem->connect(”127.0.0.1″, 11211);
					$mem->set(’key’, ‘This is a test!’, 0, 60);
					$val = $mem->get(’key’);
					echo $val;
					?>
					来自：http://blog.csdn.net/21aspnet/article/details/6827316
					
				服务端启动ok
				设置client调用？
* mongodb

* Elastic IP 弹性IP
	Elastic IP Addresses – Elastic IP addresses are static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account not a 
	particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to 
	mask instance or Availability Zone failures by programmatically remapping your public IP addresses to any instance in your account. Rather than waiting on a data technician 
	to reconfigure or replace your host, or waiting for DNS to propagate to all of your customers, Amazon EC2 enables you to engineer around problems with your instance or
	software by quickly remapping your Elastic IP address to a replacement instance. In addition, you can optionally configure the reverse DNS record of any of your Elastic IP
	addresses by filling out this form.

* json
	- 测试 json转换为map对象
		String str3 = "{\"code\":200,\"msg\":\"successful\",\"data\":{ \"lb_id\":\"123\",\" eip\":\"10.250.6.36\"}}";
		Map map3 = (Map)JSONObject.toBean(JSONObject.fromObject(str3),HashMap.class);
		System.out.println(map3.get("msg"));//successful
* ibatis
	ibatis配置文件的 typeHandler 标签配置类型转换处理方式
		·实现 com.aliyun.slb.api.dao.support.TypeHandlerCallback 接口

* aqua 
	ctrl + d -- desc table
* 遍历 map.entrySet()
		Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		
		Assert.assertEquals(map.size(), 2);
		Set<Entry<String,IMetaData>> set = map.entrySet();
		for(Entry<String, IMetaData> data:set){
* mysql
	一些命令使用，可以参考gui工具执行命令的sql参考 比如：Aqua Data Studio ，在alter table 时可以查看preview sql
	insert into vip (host,port,gmt_create,gmt_modify)values('host3',80,'2012-12-12 00:00:00','2012-12-12 00:00:00'); //id为自增列
	 select last_insert_id() as id from vip limit 1 

Apply address:http://www.taobao.ali.com/chanpin/wb/Lists/List4/view.aspx
* php 从小例子入手
	- shell中执行php
		chengs@houyi-vm19.dev.sd.aliyun.com $ vi foo.php

		#!/usr/local/bin/php -q
		<?
			$var = 'foo';
			echo $var."\n";
		?>

		"foo.php" [New] 5L, 62C written                                                                                  
		chengs@houyi-vm19.dev.sd.aliyun.com $ php foo.php 
		foo
		chengs@houyi-vm19.dev.sd.aliyun.com $ 


* ide 
	- eclipse 文件夹上下关系 project property - build path -move
		source folder ，设置源码包 build path - change to source folder
		xml 标签自动提示，schema ，dtd定义正确即可
		类似aqua data studio 通过快捷键查看表结构；通过 CTRL+T 快捷键查看类型的结构(实现，继承等)
	- eclipse 快捷键 
		ctrl + t;
		ctrl + 1 quick fix ，如改包名等
* php 
	 Discuz
* 测试，测试框架，测试插件
	* jtester
		- 测试框架，提供了各种测试方式及支持，比如mock，通过反射测试私有类等的工具JTesterReflector ，完整的去用一个测试框架。阅读其说明文档
		- 提供集成测试支持(如数据库等)
		- jtester是结合其他框架基础上的，比如@Test 注解用的就是testing框架，此时eclipse插件就下载testing(TestNG )的插件，即可在ide执行测试。ide比如eclipse执行单元
		测试框架的测试用例是根据框架的注解来解析执行的，找到框架的ide插件即可。
		下载地址：http://testng.org/doc/index.html 从其jar里找到网站信息
			http://beust.com/eclipse-old/ 5.14.0.1 新版本有问题，用这个旧版本
		- TestNG is designed to cover all categories of tests:  unit, functional, end-to-end, integration, etc...
			TestNG is a testing framework inspired from JUnit and NUnit but introducing some new functionalities that make it more powerful and easier to use
		

* 简称
	 业务运营支撑系统(BOSS) 
	 弹性计算(Elastic Computing - EC) 
	 云引擎(Cloud Engine - CE) 
	 开放存储服务(Open Storage Service - OSS) 
	 云数据库服务(Cloud Database Service - CDS) 
	 阿里邮箱(Ali Mail - AM) 
	 开放表服务（Open Table Service - OTS）
* 精度转换
	Long.valueOf(String.valueOf(compensationFailureJobHour * HOUR_SEC))
* maven
	- maven可以通过参数执行特定的goal，或测试某个用例，不需要全部执行，灵活 (-Dxxx=)
		mvn test -Dtest=AppDaoImplTest
	- maven 打包后，将jar包install到本地库中
		mvn package install

	- maven web project ,maven通过选择不同的 Archetype 快速建立对应的项目目录骨架。 maven构建
	web项目(eg:webx3.0项目)
		- 比如 group id 为 org.apache.maven.archetypes 下有多种Archetype。如何自定义Archetype？
		- 还有pom文件中必须引入servlet，jsp的相关jar包，scope设置为provided，表示它们最终不会打包到war项目中
	- mvn -Dmaven.surefire.debug=true -Dtest=OpenApplicatonControllerTest test
	- maven test 
		test 时需要debug，可以利用测试插件提供的方法，结合ide(eclipse)进行debug
			比如： Surefire Plugin 测试环节的插件，支持test时，进行debug ，下面为maven的官网说明摘取：
				Forked Tests
					By default, Maven runs your tests in a separate ("forked") process. You can use the maven.surefire.debug property to debug your forked tests remotely, like this:
						mvn -Dmaven.surefire.debug test	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
				launch configuration via the menu command "Run" > "Open Debug Dialog..."
					If you need to configure a different port, you may pass a more detailed value. For example, the command below will use port 8000 instead of port 5005.
						mvn -Dmaven.surefire.debug="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000 -Xnoagent -Djava.compiler=NONE"  test
				Non-forked Tests
					You can force Maven not to fork tests by configuring the forkMode configuration parameter.
						mvn -DforkMode=never test
					Then all you need to do is debug Maven itself. Since Maven 2.0.8, Maven has shipped with a "mvnDebug" shell script that you can use to launch Maven with convenient debugging options:
					mvnDebug -DforkMode=never testThen you can attach Eclipse to Maven itself, which may be easier/more convenient than debugging the forked executable.
				上面这段：	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
					launch configuration via the menu command "Run" > "Open Debug Dialog..."
				说明如何通过eclipse来进行maven的debug调试。-tip-
				mvn -Dmaven.surefire.debug test  //maven debug
	- maven添加jar到本地库
		mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
		添加源码到本地库 添加source
		 mvn install:install-file -DgroupId=org.apache.velocity -DartifactId=velocity -Dversion=1.6.2 -Dpackaging=jar -Dfile=velocity-1.6.2-sources.jar -DgeneratePom=true -Dclassifier=sources 
	- maven jar包重复问题，可通过
		mvn dependency:tree 查看依赖关系。
		配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
		对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
		只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。
		上面如果没效果：
			通过定义 <dependencyManagement> 来自己管理依赖版本，然后再引用来解决 .work well.
	- maven source:jar 打源码包
	- maven test时一种错误
	需要强制转换。
	- maven构建时报内存溢出解决
		 Windows环境中 
			找到文件%M2_HOME%\bin\mvn.bat	
			set MAVEN_OPTS= -Xms128m -Xmx512m
			E:\test>mvn -version
			E:\test>set MAVEN_OPTS= -Xms128m -Xmx512m
		Linux环境中 
			也可以通过设置环境变量解决该问题， 如，编辑文件 /etc/profile 如下
			MAVEN_OPTS=-Xmx512m
			export JAVA_HOME MAVEN_HOME MAVEN_OPTS JAVA_BIN PATH CLASSPATH
	- maven web project debug ，maven debug tomcat
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS% 启动tomcat调试模式 ，通过socket方式
	- maven 编译错误 
		原因之一：ide的一些操作导致冲突，清楚ide的附加内容(配置，临时文件等等)，mvn clean下，再重新import到ide中即可。
		原因之二：命令行下mvn操作与ide的操作，在缓存文件上导致错误，命令行clean了，但ide上没刷新 。解决就是ide上 maven clean 然后 project clean ，
			命令行就不会报错了。
	- maven 注解不支持 annotations are not supported in  ，显式定义插件，配置参数，设置jdk版本
		Maven default is using JDK1.3 for the project compilation, building or packaging (mvn compile, install). Since JDK1.3 is not support annotation, if your project has annotation, you need to configure your Maven to use the latest JDK version. The solution is very simple, just include the Maven compiler plugin and specify the JDK version. For example,
		<project ....>
		 <build>
		  <plugins>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>2.3.2</version>
				<configuration>
					<source>1.6</source>
					<target>1.6</target>
				</configuration>
			</plugin>
		   </plugins>
		  </build>
		</project>
		Above declaration tell Maven to use JDK 1.6.
	- maven 编码相关 - maven命令行执行能看到采用的编码
		a. maven插件在处理任务时，如果没有定义编码会自动匹配编码，如果与需要的不符，则运行时报错。解决：定义各插件执行的编码格式，如下：
			<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-resources-plugin</artifactId>
					<configuration>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
				<plugin>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>2.3.2</version>
					<configuration>
						<source>1.6</source>
						<target>1.6</target>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>

* 工具类
	 apache commond 
		StringUtils 
		...
* 协作
	”系统间协作的部分，找到相关人员沟通效率就快了，都是人定义的，谁定义谁最清楚 “

* python
	Zope - opensource appserver written by python

* Google App Engine 
		虽然GAE有很多限制和缺陷，但是我对GAE还是喜爱有加的。GAE是免费的，任何人都可以很轻松的通过GAE实现自己的Web应用。比如，做一些实用的小工具，
	实现一个博客程序来练手。通过GAE，我们可以轻松的搭建属于自己的Blog(micolog)，搭建属于自己的Wiki系统(NancyWiki)。
	没有GAE，就不会有大家都懂的gappproxy，gtap，twiter-feed。是的，你懂的。	
	from: http://www.cnblogs.com/coderzh/archive/2010/11/30/goodby-google-app-engine.html
* powerdesigner  生成er图
	pd12 连接mysql，database菜单-configure data connection - 选择 connection profiles 设置即可

* shell
	- 根据参数执行任务shell
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac

* linux
	- ssh远程命令行 ，通过 rz ,sz 传递/接受文件
	-   $# 是传给脚本(或者函数)的参数个数, $0 是脚本本身的名字, $@ 是传给脚本(或者函数)的所有参数的列表. 举例:

                  QUOTE:
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; cat foo.sh
                  #!/bin/bash

                  echo "script name   : $0"
                  echo "# of arguments: $#"
                  echo "all arguments : $@"
                  echo "arguments in order:"
                  for sArg in "$@"; do
                      echo "  $sArg"
                  done
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa bb cc
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc
                  arguments in order:
                    aa
                    bb
                    cc
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa "bb cc" dd
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc dd
                  arguments in order:
                    aa
                    bb cc
                    dd
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; bye


                  付：
                    $0   这个程式的执行名字       
                    $n   这个程式的第n个参数值，n=1..9       
                    $*   这个程式的所有参数       
                    $#   这个程式的参数个数       
                    $$   这个程式的PID       
                    $!   执行上一个背景指令的PID       
                    $?   执行上一个指令的返回值
	- linux shell命令中Esac是什么意思？
		一些刚刚接触bash编程的人，总是很奇怪bash里的一些关键字，知道它的功能，但不知道为什么要这样写。比如：
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac
		fi是if语句的结束，esac是case语句的结束。Fi和esac这样的关键字是不是很怪异呢？呵，仔细想一想，一点也不怪，考虑一下{} [] 等等，{和}是垂直轴对称的，[和]是垂直轴对称的。现在来看， if和fi及case和esac不也是这样吗？它们刚好反过，分别表示开始和结束。


linux command eg 命令
字符转换 unix字符 window字符
unix2dos dos2unix

SERVER=/home/user - 定义=号两边不能有空格

将shell执行的pid保存到文件，读取文件中的pid关闭程序
#! /bin/sh
SERVER=/home/chengs
java test > $SERVER/server.log & echo $! > $SERVER/server.pid
kill `cat server.pid` -- 这里注意是波浪号 ，不是单引号
	--------
		############################################################################
		mount -l -t

		sh startup.sh

		############################################################################
		该如何才能知道系统都有什么硬件设备，有如下几种方式：
		方式一：
		使用lsdev命令，可以显示系统中的设备及其特征。
		例如：lsdev -C
		但是一般的系统上可能没有这个命令，比如我装的fedora上面就没有这个命令。
		方法二：
		显示/proc/dev文件，这个文件记录了系统的一些硬件信息，
		例如：cat /proc/dev
		方法三：
		如果要查找特定的usb设备，则可以使用lsusb命令，列出所有的usb设备。
		如果要查找特定的pcmcia设备，则可以使用lspcmcia命令，列出所有的pcmcia设备。
		如果要查找特定的pci设备，则可以使用lspci命令，列出所有的pcm设备。
		来自：达内BBS
		############################################################################

		有些在freebsd下也能用…
		# uname -a               # 查看内核/操作系统/CPU信息
		# head -n 1 /etc/issue   # 查看操作系统版本
		# cat /proc/cpuinfo      # 查看CPU信息
		# hostname               # 查看计算机名
		# lspci -tv              # 列出所有PCI设备
		# lsusb -tv              # 列出所有USB设备
		# lsmod                  # 列出加载的内核模块
		# env                    # 查看环境变量资源
		# free -m                # 查看内存使用量和交换区使用量
		# df -h                  # 查看各分区使用情况
		# du -sh         # 查看指定目录的大小
		# grep MemTotal /proc/meminfo   # 查看内存总量
		# grep MemFree /proc/meminfo    # 查看空闲内存量
		# uptime                 # 查看系统运行时间、用户数、负载
		# cat /proc/loadavg      # 查看系统负载磁盘和分区
		# mount | column -t      # 查看挂接的分区状态
		# fdisk -l               # 查看所有分区
		# swapon -s              # 查看所有交换分区
		# hdparm -i /dev/hda     # 查看磁盘参数(仅适用于IDE设备)
		# dmesg | grep IDE       # 查看启动时IDE设备检测状况网络
		# ifconfig               # 查看所有网络接口的属性
		# iptables -L            # 查看防火墙设置
		# route -n               # 查看路由表
		# netstat -lntp          # 查看所有监听端口
		# netstat -antp          # 查看所有已经建立的连接
		# netstat -s             # 查看网络统计信息进程
		# ps -ef                 # 查看所有进程
		# top                    # 实时显示进程状态用户
		# w                      # 查看活动用户
		# id             # 查看指定用户信息
		# last                   # 查看用户登录日志
		# cut -d: -f1 /etc/passwd   # 查看系统所有用户
		# cut -d: -f1 /etc/group    # 查看系统所有组
		# crontab -l             # 查看当前用户的计划任务服务
		# chkconfig –list       # 列出所有系统服务
		# chkconfig –list | grep on    # 列出所有启动的系统服务程序
		# rpm -qa                # 查看所有安装的软件包
		cat /proc/cpuinfo ：查看CPU相关参数
		cat /proc/partitions ：查看硬盘和分区
		cat /proc/meminfo ：查看内存信息
		cat /proc/version ：查看版本，类似uname -r
		cat /proc/ioports ：查看设备io端口
		cat /proc/interrupts ：查看中断
		cat /proc/pci ：查看pci设备的信息
		cat /proc/swaps ：查看所有swap分区的信息
		来自：达内BBS
		############################################################################
		linux目录架构
		/   根目录
		/bin    常用的命令 binary file 的目錄
		/boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内
		     /boot/grub/menu.lst   GRUB设置
		     /boot/vmlinuz   内核
		     /boot/initrd     核心解壓縮所需 RAM Disk
		/dev    系统周边设备     
		/etc    系统相关设定文件
		     /etc/DIR_COLORS   设定颜色
		     /etc/HOSTNAME   设定用户的节点名
		     /etc/NETWORKING   只有YES标明网络存在
		     /etc/host.conf 文件说明用户的系统如何查询节点名
		     /etc/hosts 设定用户自已的IP与名字的对应表
		     /etc/hosts.allow 设置允许使用inetd的机器使用 
		     /etc/hosts.deny 设置不允许使用inetd的机器使用
		     /etc/hosts.equiv 设置远端机不用密码
		     /etc/inetd.conf 设定系统网络守护进程inetd的配置
		     /etc/gateways 设定路由器
		     /etc/protocols 设定系统支持的协议
		     /etc/named.boot 设定本机为名字服务器的配置文件
		     /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP
		     /etc/resolv.conf    设置DNS  
		     /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這兩個 X Server 的設定檔
		     /etc/fstab    记录开机要mount的文件系统
		     /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel
		     /etc/issue 记录用户登录前显示的信息
		     /etc/group 设定用户的组名与相关信息
		     /etc/passwd 帐号信息
		     /etc/shadow 密码信息
		     /etc/sudoers 可以sudo命令的配置文件
		     /etc/securetty 设定哪些终端可以让root登录
		     /etc/login.defs 所有用户登录时的缺省配置
		     /etc/exports 设定NFS系统用的
		     /etc/init.d/   所有服務的預設啟動 script 都是放在這裡的，例如要啟動或者關閉
		     /etc/xinetd.d/  這就是所謂的 super daemon 管理的各項服務的設定檔目錄
		     /etc/modprobe.conf   内核模块额外参数设定
		     /etc/syslog.conf   日志设置文件
		/home   使用者家目录
		/lib    系统会使用到的函数库
		     /lib/modules   kernel 的相关模块
		     /var/lib/rpm   rpm套件安装处 
		/lost+found    系統不正常產生錯誤時，會將一些遺失的片段放置於此目錄下
		/mnt     外设的挂载点
		/media   与/mnt类似
		/opt     主机额外安装的软件
		/proc    虚拟目录，是内存的映射
		      /proc/version   内核版本
		       /proc/sys/kernel   系统内核功能
		/root    系统管理员的家目录
		/sbin    系统管理员才能执行的指令
		/srv     一些服務啟動之後，這些服務所需要取用的資料目錄
		/tmp     一般使用者或者是正在執行的程序暫時放置檔案的地方
		/usr     最大的目录，存许应用程序和文件
		    /usr/X11R6：   X-Window目录 
		    /usr/src：    Linux源代码
		    /usr/include：系统头文件
		    /usr/openwin 存放SUN的OpenWin 
		    /usr/man 在线使用手册
		    /usr/bin           使用者可執行的 binary file 的目錄
		    /usr/local/bin     使用者可執行的 binary file 的目錄
		    /usr/lib           系统会使用到的函数库
		    /usr/local/lib     系统会使用到的函数库
		    /usr/sbin          系统管理员才能执行的指令
		    /usr/local/sbin    系统管理员才能执行的指令
		/var   日志文件
		    /var/log/secure    記錄登入系統存取資料的檔案，例如 pop3, ssh, telnet, ftp 等都會記錄在此檔案中
		    /var/log/wtmp      記錄登入者的訊息資料, last
		    /var/log/messages  幾乎系統發生的錯誤訊息
		    /var/log/boot.log  記錄開機或者是一些服務啟動的時候，所顯示的啟動或關閉訊息
		    /var/log/maillog   紀錄郵件存取或往來( sendmail 與 pop3 )的使用者記錄
		    /var/log/cron      記錄 crontab 這個例行性服務的內容
		    /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log/procmail.log：
		    分別是幾個不同的網路服務的記錄檔
		 
		一些常用的基本命令:
		uname -a    查看内核版本       
		ls -al    显示所有文件的属性
			-R, --recursive            list subdirectories recursively
			ls -a -R 显示子目录文件
		pwd         显示当前路径        
		cd -    返回上一次目录     cd ~    返回主目录
		date s      设置时间、日期          
		cal      显示日历     cal 2006
		bc          计算器具               
		man  & info     帮助手册
		locale     显示当前字体     locale -a    所有可用字体     /etc/sysconfig/i18n设置文件
		LANG=en    使用英文字体            
		sync       将数据同步写入硬盘        
		shutdonw -h now & half & poweroff  关机
		reboot     重启                   
		startx  &  init 5   进入图形介面
		/work  & ?work    向上、下查找文档内容
		chgrp      改变档案群组  chgrp testing install.log    
		chown     改变所属人   chown root:root install.log
		chmod      改变属性     chmod 777 install.log     read=4  write=2  execute=1
		cp   复制   cp filename
		rm   删除文件  rm -rf filename   强制删除文件 
			rm -rf directory or file   -r或-R或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
		rmdir   删除文件夹
		mv  移动    mv 123.txt 222.txt  重命名
		mkdir     创建文件夹  
			mkdir -p /usr/dat.txt  # -p 参数表示如果上级目录不存在则创建
		touch     创建文件  更新当前时间
		cat       由第一行开始显示     cat |more  分页
		nl        在内容前加行号
		more  &  less   一面一面翻动
		head -n filename   显示第N行内容
		tail -n filename  显示后N行内容
		od        显示非纯文档
		df -h 显示分区空间
		du  显示目录或文件的大小
		fdisk   分区设置    fdisk -l /dev/hda  显示硬盘分区状态
		mkfs    建立各种文件系统  mkfs -t ext3  /dev/ram15   
		fsck    检查和修复LINUX档案
		ln      硬链接   ln -s  软件链接
		whereis   查找命令
		locate    查找
		find      查找   find / -name "***.***"
		which     查看工具
		whoami    显示当前用户
		gcc -v    查看GCC版本
		chattr +i filename  禁止删除   chattr -i filename  取消禁止
		lsattr    显示隐藏档属性
		updatedb  更新资料库
		mke2fs    格式化   mkfs -t ext3 
		dd if=/etc/passwd of=/tmp/passwd.bak    备份
		mount     列出系统所有的分区
		mount -t iso9660 /dev/cdrom /mnt/cdrom   挂载光盘
		mount -t vfat /dev/fd0 /mnt/floppy       挂载软盘
		mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
		mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
		Linux-NTFS Project: http://linux-ntfs.sourceforge.net/
		umount /mnt/hda3  缷载
		ifconfig   显示或设置网络设备
			设置ip: ifconfig eth0 192.168.232.162 netmask 255.255.255.0
		service network restart   重启网卡  
		ifdown eth0  关闭网卡
		ifup eth0    开启网卡
		clear    清屏
		history    历史记录       !55  执行第55个指令
		stty   设置终端    stty -a
		fdisk /mbr   删除GRUB
		at     僅進行一次的工作排程
		crontab   循環執行的例行性命令    [e]编辑,[l]显示,[r]删除任务
		&       后台运行程序    tar -zxvf 123.tar.gz & --------->后台运行
		jobs    观看后台暂停的程序   jobs -l
		fg      将后台程序调到前台   fg n ------>n是数字,可以指定进行那个程序
		bg      让工作在后台运行
		kill    结束进程    kill -9 PID     [9]强制结束,[15]正常结束,[l]列出可用的kill信号
		ps aux  查看后台程序   
		top     查看后台程序   top -d 2    每两秒更新一次        top -d 2 -p10604   观看某个PID
			top -b -n 2 > /tmp/top.txt ----->將 top 的資訊進行 2 次，然後將結果輸出到 /tmp/top.txt    
		pstree   以树状图显示程序    [A]以 ASCII 來連接, [u]列出PID, [p]列出帐号
		killall   要刪除某個服務    killall -9 httpd
		free      显示内存状态     free -m  -------->以M为单位显示
		uptime    显示目前系统开机时间
		netstat   显示网络状态    netstat -tulnp------>找出目前系統上已在監聽的網路連線及其 PID
		dmesg     显示开机信息    demsg | more
		nice      设置优先权      nice -n -5 vi & ----->用 root 給一個 nice 植為 -5 ，用於執行 vi 
		renice    调整已存在优先权
		runlevel  显示目前的runlevel
		depmod    分析可载入模块的相依性
		lsmod     显示已载入系统的模块
		modinfo   显示kernel模块的信息
		insmod    载入模块
		modprobe   自动处理可载入模块
		rmmod     删除模块
		chkconfig   检查，设置系统的各种服务     chkconfig --list ----->列出各项服务状态
		ntsysv     设置系统的各种服务
		cpio      备份文件
		 

		压缩命令：
		 *.Z      compress 程式壓縮的檔案； 
		 *.bz2    bzip2 程式壓縮的檔案； 
		 *.gz     gzip 程式壓縮的檔案； 
		 *.tar    tar 程式打包的資料，並沒有壓縮過； 
		 *.tar.gz tar 程式打包的檔案，其中並且經過 gzip 的壓縮
		compress filename  压缩文件  加[-d]解压  uncompress
		gzip filename   压缩  加[-d]解压  zcat 123.gz 查看压缩文件内容
		bzip2 -z filename  压缩  加[-d]解压   bzcat filename.bz2  查看压缩文件内容
		tar -cvf /home/123.tar /etc  打包，不压缩
		tar -xvf 123.tar   解开包
		tar -zxvf /home/123.tar.gz  以gzip解压
		tar -jxvf /home/123.tar.bz2  以bzip2解压
		tar -ztvf /tmp/etc.tar.gz   查看tar内容
		cpio -covB  > [file|device]   份份
		cpio -icduv < [file|device]   还原
		 zip -r xxx.zip ./*.txt - 打包当前目录下所有txt文件 -r 表示递归所有子目录
		vi一般用法
		一般模式              编辑模式                  指令模式
		h 左               a,i,r,o,A,I,R,O             :w 保存
		j 下                进入编辑模式                :w! 强制保存
		k 上                dd 删除光标当前行           :q! 不保存离开
		l 右                ndd 删除n行                 :wq! 保存后离开
		0 移动到行首        yy 复制当前行                :e! 还原原始档
		$ 移动到行尾        nyy 复制n行                  :w filename 另存为
		H 屏幕最上          p,P 粘贴                     :set nu 设置行号
		M 屏幕中央          u  撤消                      :set nonu 取消行号
		L 屏幕最下          [Ctrl]+r 重做上一个动作       ZZ 保存离开
		G 档案最后一行      [ctrl]+z 暂停退出            :set nohlsearch   永久地关闭高亮显示
		/work 向下搜索                                   :sp 同时打开两个文档 
		?work 向上搜索                                   [Ctrl]+w 两个文档设换
		gg 移动到档案第一行                              :nohlsearch    暂时关闭高亮显示
		 
		认识SHELL
		alias    显示当前所有的命令别名      alias lm="ls -al"   命令别名    unalias lm 取消命令别名
		type      类似which
		exprot    设置或显示环境变量
		exprot PATH="$PATH":/sbin  添加/sbin入PATH路径
		echo $PATH    显示PATH路径
		bash      进入子程序
		name=yang     设定变量
		unset name    取消变量
		echo $name    显示变量的内容
		myname="$name its me"   &   myname='$name its me'     单引号时$name失去变量内容
		ciw=/etc/sysconfig/network-scripts/     设置路径
		env      列出所有环境变量
		echo $RANDOM    显示随意产生的数
		set      设置SHELL
		PS1='[\u@\h \w \A #\#]\$ '     提示字元的設定
		   [root@linux ~]# read [-pt] variable     -----------读取键盘输入的变量
		   參數：
		   -p  ：後面可以接提示字元！
		   -t  ：後面可以接等待的『秒數！』
		declare    声明 shell 变量
		ulimit -a   显示所有限制资料
		 ls /tmp/yang && echo "exist" || echo "not exist"
		 意思是說，當 ls /tmp/yang 執行後，若正確，就執行echo "exist" ,若有問題，就執行echo "not exist" 
		 echo $PATH | cut -d ':' -f 5       以:为分隔符,读取第5段内容
		 export | cut -c 10-20      读取第10到20个字节的内容
		 last | grep 'root'    搜索有root的一行,加[-v]反向搜索
		 cat /etc/passwd | sort    排序显示
		 cat /etc/passwd | wc      显示『行、字数、字节数』
		正规表示法
		[root@test root]# grep [-acinv] '搜尋字串' filename
		       參數說明：
		       -a ：將 binary 檔案以 text 檔案的方式搜尋資料
		       -c ：計算找到 '搜尋字串' 的次數
		       -i ：忽略大小寫的不同，所以大小寫視為相同
		       -n ：順便輸出行號
		       -v ：反向選擇，亦即顯示出沒有 '搜尋字串' 內容的那一行！

		文件内容查找：

		 grep -n 'the' 123.txt     搜索the字符 -----------搜尋特定字串       
		 grep -n 't[ea]st' 123.txt    搜索test或taste两个字符---------利用 [] 來搜尋集合字元
		 grep -n '[^g]oo' 123.txt     搜索前面不为g的oo-----------向選擇 [^] 
		 grep -n '[0-9]' 123.txt  搜索有0-9的数字
		 grep -n '^the' 123.txt 搜索以the为行首-----------行首搜索^
		 grep -n '^[^a-zA-Z]' 123.txt  搜索不以英文字母开头
		 grep -n '[a-z]$' 123.txt    搜索以a-z结尾的行---------- 行尾搜索$
		 grep -n 'g..d' 123.txt     搜索开头g结尾d字符----------任意一個字元 . 
		 grep -n 'ooo*' 123.txt     搜索至少有两个oo的字符---------重複字元 *
		sed    文本流编辑器    利用脚本命令来处理文本文件
		awd    模式扫描和处理语言
		 nl 123.txt | sed '2,5d'   删除第二到第五行的内容
		diff     比较文件的差异
		cmp      比较两个文件是否有差异
		patch    修补文件
		pr       要打印的文件格式化
		 

		帐号管理
		/etc/passwd    系统帐号信息
		/etc/shadow    帐号密码信息    经MD5 32位加密
		     在密码栏前面加『 * 』『 ! 』禁止使用某帐号
		/etc/group     系统群组信息
		/etc/gshadow
		newgrp    改变登陆组
		useradd  &  adduser    建立新用户  ---------> useradd -m test  自动建立用户的登入目录
			  useradd -m -g pgroup test --------->指定所属级
		/etc/default/useradd   相关设定
		/etc/login.defs       UID/GID 有關的設定
		passwd    更改密码 -----------> passwd test
		usermod   修改用户帐号
		userdel   删除帐号 ----------->userdel -r test
		chsh      更换登陆系统时使用的SHELL   [-l]显示可用的SHELL;[-s]修改自己的SHELL
		chfn      改变finger指令显示的信息
		finger    查找并显示用户信息
		id        显示用户的ID ----------->  id test
		groupadd   添加组
		groupmod   与usermod类似
		groupdel   删除组
		su test    更改用户   su -    进入root,且使用root的环境变量
		sudo       以其他身份来执行指令
		visudo     编辑/etc/sudoers      加入一行『 test ALL=(ALL) ALL 』
			   %wheel ALL = (ALL) ALL               系统里所有wheel群组的用户都可用sudo
			   %wheel ALL = (ALL) NOPASSWD: ALL     wheel群组所有用户都不用密码NOPASSWD
		       User_Alias ADMPW = vbird, dmtsai, vbird1, vbird3         加入ADMPW组
		       ADMPW ALL = NOPASSWD: !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, \
		       !/usr/bin/passwd root      可以更改使用者密码,但不能更改root密码 (在指令前面加入 ! 代表不可)
		PAM (Pluggable Authentication Modules, 嵌入式模組)
		who & w     看谁在线                     
		last        最近登陆主机的信息
		lastlog     最近登入的時間    读取 /var/log/lastlog 
		talk        与其他用户交谈
		write       发送信息    write test   [ctrl]+d 发送
		mesg        设置终端机的写入权限    mesg n 禁止接收     mesg y 
		wall        向所有用户发送信息    wall this is q test
		mail        写mail   
		/etc/default/useradd    家目录默认设置
		quota      显示磁盘已使用的空间与限制     quota -guvs ----->秀出目前 root 自己的 quota 限制值
			   quota -vu   查询
		quotacheck   检查磁盘的使用空间与限制     quotacheck -avug  ----->將所有的在 /etc/mtab 內，含有 quota 支援的 partition 進行掃瞄
			     [-m] 强制扫描  
		     quota一定要是独立的分区,要有quota.user和quota.group两件文件,在/etc/fstab添加一句:
		     /dev/hda3 /home ext3 defaults,usrquota,grpquota 1 2
		     chmod 600 quota*         设置完成,重启生效
		edquota    编辑用户或群组的quota  [u]用户,[g]群组,[p]复制,[t]设置宽限期限 
			   edquota -a yang       edquota -p yang -u young ----->复制    
		quotaon    开启磁盘空间限制     quotaon -auvg -------->啟動所有的具有 quota 的 filesystem
		quotaoff   关闭磁盘空间限制     quotaoff -a  -------->關閉了 quota 的限制
		repquota -av     查閱系統內所有的具有 quota 的 filesystem 的限值狀態
		Quota 從開始準備 filesystem 的支援到整個設定結束的主要的步驟大概是：
		1、設定 partition 的 filesystem 支援 quota 參數：
		由於 quota 必須要讓 partition 上面的 filesystem 支援才行，一般來說， 支援度最好的是 ext2/ext3 ，
		其他的 filesystem 類型鳥哥我是沒有試過啦！ 啟動 filesystem 支援 quota 最簡單就是編輯 /etc/fstab ，
		使得準備要開放的 quota 磁碟可以支援 quota 囉；
		2、建立 quota 記錄檔：
		剛剛前面講過，整個 quota 進行磁碟限制值記錄的檔案是 aquota.user/aquota.group， 
		要建立這兩個檔案就必須要先利用 quotacheck 掃瞄才行喔！
		3、編輯 quota 限制值資料：
		再來就是使用 edquota 來編輯每個使用者或群組的可使用空間囉；
		4、重新掃瞄與啟動 quota ：
		設定好 quota 之後，建議可以再進行一次 quotacheck ，然後再以 quotaon 來啟動吧！

		开机流程简介
		1、載入 BIOS 的硬體資訊，並取得第一個開機裝置的代號； 
		2、讀取第一個開機裝置的 MBR 的 boot Loader (亦即是 lilo, grub, spfdisk 等等) 的開機資訊； 
		3、載入 Kernel 作業系統核心資訊， Kernel 開始解壓縮，並且嘗試驅動所有硬體裝置； 
		4、Kernel 執行 init 程式並取得 run-level 資訊； 
		5、init 執行 /etc/rc.d/rc.sysinit 檔案； 
		6、啟動核心的外掛模組 (/etc/modprobe.conf)； 
		7、init 執行 run-level 的各個批次檔( Scripts )； 
		8、init 執行 /etc/rc.d/rc.local 檔案； 
		9、執行 /bin/login 程式，並等待使用者登入； 
		10、登入之後開始以 Shell 控管主機。 
		在/etc/rc.d/rc3.d內,以S开头的为开机启动,以K开头的为关闭,接着的数字代表执行顺序
		GRUB vga设定
		彩度\解析度  640x480  800x600  1024x768  1280x1024   bit 
		    256        769      771      773       775      8 bit 
		   32768       784      787      790       793     15 bit 
		   65536       785      788      791       794     16 bit 
		   16.8M       786      789      792       795     32 bit 

		./configure    检查系统信息       ./configure --help | more  帮助信息
		make clean     清除之前留下的文件
		make           编译
		make install   安装
		rpm -q  ----->查询是否安装             rpm -ql ------>查询该套件所有的目录
		rpm -qi ----->查询套件的说明资料       rpm -qc[d] ----->设定档与说明档
		rpm -ivh  ---->安装                    rpm -V  -------->查看套件有否更动过
		rpm -e  ------>删除                    rpm -Uvh ------->升级安装  
		--nodeps ----->强行安装                --test ----->测试安装

		来自：http://blogold.chinaunix.net/u/30619/showart.php?id=249558

		1、alternatives --install /usr/bin/java java /usr/java/jdk1.6.0_24/bin/java 300
		这一句的意思是给java这个LINK多加一个Path。至于什么是Link，请man alternatives，看alternatives命令的帮助，就大概能明白了。
		2、alternatives --config java 会出现一下信息：
		----------------------------------------------------------------------
		*  1           /usr/lib/jvm/jre-1.4.2-gcj/bin/java
		+ 2           /usr/java/jdk1.6.0_24/bin/java
		按 Enter 来保存当前选择[+]，或键入选择号码：2

		shutdown -h now
		halt
	
		############################################################################

		linux下Java环境的配置
		linux下Java环境的配置
			　　现在用linux的朋友越来越多了，前几天就有两个朋友问我linux下怎么配置java环境，我想还有很多朋友想了解学习这方面的东西，就写一个完全一点的linux java环境配置吧，希望对大家有帮助。
		一. 下载jdk5.0 for linux
		　　到sun的主页 http://java.sun.com/j2se/1.5.0/download.jsp 下载jdk安装文件jdk-1_5_0_05-linux-i586.bin
		二. 解压安装jdk
		　　在shell终端下进入jdk-1_5_0_05-linux-i586.bin文件所在目录，执行命令./jdk-1_5_0_05-linux-i586.bin这时会出现一段协议，连继敲回车，当询问是否同意的时候，输入yes，回车。之后会在当前目录下生成一个jdk-1.5.0_05目录，你可以将它复制到任何一个目录下。
		三. 需要配置的环境变量
		　　1.PATH环境变量。作用是指定命令搜索路径，在shell下面执行命令时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。
		　　2.CLASSPATH环境变量。作用是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。
		　　3. JAVA_HOME环境变量。它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。
		四. 三种配置环境变量的方法
		　　1. 修改/etc/profile文件
		　　　　如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
		　　　　·用文本编辑器打开/etc/profile
		　　　　·在profile文件末尾加入：
		　　　　　　JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　PATH=$JAVA_HOME/binPATH
		　　　　　　CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		　　　　　　export JAVA_HOME
		　　　　　　export PATH
		　　　　　　export CLASSPATH
		　　　　·重新登录
		　　　　·注解
		　　　　　　a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
		　　　　　　b. linux下用冒号“:”来分隔路径
		　　　　　　c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值
		　　　　　　　 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种
		　　　　　　　 常见的错误。
		　　　　　　d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
		　　　　　　e. export是把这三个变量导出为全局变量。
		　　　　　　f. 大小写必须严格区分。
		　　2. 修改.bashrc文件
		　　　　
		　　　　这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
		　　　　·用文本编辑器打开用户目录下的.bashrc文件
		　　　　·在.bashrc文件末尾加入：
		　　　　　　
		　　　　　　set JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　export JAVA_HOME
		　　　　　　set PATH=$JAVA_HOME/binPATH
			    　　　export PATH
			    　　　set CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
			    　　　export CLASSPATH
		　　　　·重新登录
		　　3. 直接在shell下设置变量
		　　　　不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
		　　　　只需在shell终端执行下列命令：
		　　　　export JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　export PATH=$JAVA_HOME/binPATH
		　　　　export CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		五. 测试jdk
		　　1. 用文本编辑器新建一个Test.java文件，在其中输入以下代码并保存：
		　　　　public class test {
		　　　　　　public static void main(String args[]) {
		　　　　　　　　System.out.println("A new jdk test !");
		　　　　　　}
		　　　　}
		　　2. 编译：在shell终端执行命令 javac Test.java
		　　3. 运行：在shell终端执行命令 java Test
		　　　　当shell下出现“A new jdk test !”字样则jdk运行正常。
		六. 卸载jdk
		　　·找到jdk安装目录的_uninst子目录
		　　·在shell终端执行命令./uninstall.sh即可卸载jdk。 



		############################################################################


		vi 

		保存退出
		* shift + ： 进入命令行状态
		* 输入wq ，并回车，即保存退出

		:w   保存文件但不退出vi 
		:w file 将修改另外保存到file中，不退出vi 
		:w!  强制保存，不推出vi
		:wq  保存文件并退出vi 
		:wq! 强制保存文件，并退出vi
		q：不保存文件，退出vi
		:q!不保存文件，强制退出vi 
		:e! 放弃所有修改，从上次保存文件开始再编辑



		############################################################################


		命令 结果定向到文件 

		rpm -qa >> /home/show

		查找到安装软件包名 ： java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5

		rpm -ql  java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5 —— 查询该套件所有的目录
		
		查找是否已安装mysql，有则卸载掉
		# rpm -qa | grep -i  mysql
		...
		# rpm -e xxxx

		############################################################################

		安装 bin格式的jdk软件包 
		进到软件包的目录下 ，运行 ./jdk1.6***.bin 即可安装
	--------

* base64 编码
		Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。
	Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符
	（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为
	适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所
	直接看到。

*	vmware7安装centos5 - 自定义方式 -  OS Installlation步骤选择install later(否则后面可能直接进入live CD 模式，不是正常安装模式)
		确保ssh模块已安装 ，通过ssh客户端连接vmware中的centos

*	虚拟集群,及其相关应用测试【测试】

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day1 2012年3月14日

1. 环境
	..
	eclipse 
		常用插件
			svn 
			mavn 
			spring插件 - 主要编译配置文件定位到java文件,自动提示等便捷功能
			Eclipse Web Tools Platform
			python 插件 pydev http://pydev.org/updates
			uml
			er - http://www.eclipse.org/gef/updates/index.php
			...
		eclipse jre配置设置为jdk
		-vm
		D:\Java\jdk1.6.0_10\bin\javaw.exe —— 这里路径注意下 空格之类处理为 progra~1
		-vmargs
		-Dosgi.requiredJavaVersion=1.5
		-Xms128m
		-Xmx256m	

		ide eclipse 依赖 ，依赖从上到下配置，上面不对会导致下面的类编译报错。

2. svn 
	wiki http://wiki.houyi.alibaba-inc.com/dashboard.action
	申请权限
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/
	和
	http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine

	department
	阿里云-云计算业务发展-基础产品-平台技术

wiki：
	http://wiki.houyi.alibaba-inc.com/dashboard.action

bbs:
	http://bbs.aliyun.com/

feitian SLB ACE（JCE...） (ACE - Ali Cloud Engine云引擎) OSS(kv storage)
	
	ACE php container, nodejs container,jsp container

3. Cloud Engine - Cloud Engine是一个基于AEC的web应用托管运行环境，能够提供应用的自动伸缩以及多种核心服务。
	
	Google App Engine
	


4. linux about
	* gdb:
		What is GDB?

		GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another 
		program was doing at the moment it crashed.

		GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act:

		    Start your program, specifying anything that might affect its behavior.
		    Make your program stop on specified conditions.
		    Examine what has happened, when your program has stopped.
		    Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. 

		The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might 
		be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft 
		Windows variants.
		
		DBP实战：
			问题：

			ndb进程cpu达到99%，怀疑存在死循环，需要排查

			1.   ps -eLf | grep nbd-server

			找出那个nbd-server线程占用cpu最高，记住他的ppid（线程id）

			2.   gdb nbd-server <pid>

			启动gdb ， attach到运行的nbd-server进程

			3.  info thread

			查看所有线程

			4. thread 10

			切换到这个线程

			5. bt

			查看线程堆栈

			6. 分析代码

			from:wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=3932212

5. ssh client
	PuTTY
6. 路由  消息订阅

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day2 2012年3月15日

1. 后羿系统
	
	参考资料 Sina App Engine数据存储服务架构
	
2.  svn 账户授权 即 svn 注册用户 
	wb_shen.chengs + pwd

	url
		...houyi/cloudengine
		...houyi/console
			branches-api...-requirement 

3. houyi 异步通知
	
	异步通知是后羿系统提供的一套基于HTTP协议主动向客户系统发送VM操作结果状态的基础服务。其基本流程如下：
	 
	通知系统交互流程说明：
	1. 后羿向外部系统发出通知，即访问外部系统提供的通知接收URL。// 外部系统提供的通知接收URL
	2. 客户系统接到通知请求，根据签名信息验证通知真实性。
	3. 客户系统处理通知。
	摘自：houyi api 说明doc

4. 通过svn checkout 部分houyi项目 熟悉 【配置 svn】
	svn插件拉下项目代码 (svn 项目绑定到对应的svn库上，(对于eclipse，如果绑定错误，先删除原有svn库，从team里重新绑定即可))
	maven插件构建
		部分依赖找不到的情况：(把所在目录下已有的文件删除)通过到依赖库手动下载pom文件和相应jar.swf等文件，放到maven的.m2文件夹中解决。
		nexus http://10.250.6.11:8081/nexus/index.html#welcome 

	maven版本问题，比如编译，打包等用到plugin时，选择合适的版本，配置正确的repo，目前用maven2.2.1
		配置文件配置:
			   <!-- profile
			     | Specifies a set of introductions to the build process, to be activated using one or more of the
			     | mechanisms described above. For inheritance purposes, and to activate profiles via <activatedProfiles/>
			     | or the command line, profiles have to have an ID that is unique.
			     |
			     | An encouraged best practice for profile identification is to use a consistent naming convention
			     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.
			     | This will make it more intuitive to understand what the set of introduced profiles is attempting
			     | to accomplish, particularly when you only have a list of profile id's for debug.
			     |
			     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.
			    -->			
			 <profile>
			      <id>dev</id>

			      <repositories>
				
				<repository>
				  <id>ay32-releases</id>
				  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>

				<repository>
				  <id>nexus-releases</id>
				  <name>nexusre</name>
				  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>
			     
			 </repositories>
				  <pluginRepositories>
				<pluginRepository>
					  <id>ay32-releases</id>
					  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				<pluginRepository>
					  <id>nexus-releases</id>
					  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				  </pluginRepositories>
			    </profile>
	

	通过maven脚本构建测试部署 ？

	ide里编辑，构建工具统一编译测试部署。
	mvn clean install -rf :houyi-console-web-staff 
	参数参考：
		usage: mvn [options] [<goal(s)>] [<phase(s)>]

		Options:
		 -am,--also-make                        If project list is specified, al
							build projects required by the
							list
		 -amd,--also-make-dependents            If project list is specified, al
							build projects that depend on
							projects on the list
		 -B,--batch-mode                        Run in non-interactive (batch)
							mode
		 -C,--strict-checksums                  Fail the build if checksums don'
							match
		 -c,--lax-checksums                     Warn if checksums don't match
		 -cpu,--check-plugin-updates            Ineffective, only kept for
							backward compatibility
		 -D,--define <arg>                      Define a system property
		 -e,--errors                            Produce execution error messages
		 -emp,--encrypt-master-password <arg>   Encrypt master security password
		 -ep,--encrypt-password <arg>           Encrypt server password
		 -f,--file <arg>                        Force the use of an alternate PO
							file.
		 -fae,--fail-at-end                     Only fail the build afterwards;
							allow all non-impacted builds to
							continue
		 -ff,--fail-fast                        Stop at first failure in
							reactorized builds
		 -fn,--fail-never                       NEVER fail the build, regardless
							of project result
		 -gs,--global-settings <arg>            Alternate path for the global
							settings file
		 -h,--help                              Display help information
		 -l,--log-file <arg>                    Log file to where all build outp
							will go.
		 -N,--non-recursive                     Do not recurse into sub-projects
		 -npr,--no-plugin-registry              Ineffective, only kept for
							backward compatibility
		 -npu,--no-plugin-updates               Ineffective, only kept for
							backward compatibility
		 -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates
		 -o,--offline                           Work offline
		 -P,--activate-profiles <arg>           Comma-delimited list of profiles
							to activate
		 -pl,--projects <arg>                   Comma-delimited list of specifie
							reactor projects to build instea
							of all projects. A project can b
							specified by [groupId]:artifactI
							or by its relative path.
		 -q,--quiet                             Quiet output - only show errors
		 -rf,--resume-from <arg>                Resume reactor from specified
							project
		 -s,--settings <arg>                    Alternate path for the user
							settings file
		 -T,--threads <arg>                     Thread count, for instance 2.0C
							where C is core multiplied
		 -t,--toolchains <arg>                  Alternate path for the user
							toolchains file
		 -U,--update-snapshots                  Forces a check for updated
							releases and snapshots on remote
							repositories
		 -up,--update-plugins                   Ineffective, only kept for
							backward compatibility
		 -V,--show-version                      Display version information
							WITHOUT stopping build
		 -v,--version                           Display version information
		 -X,--debug                             Produce execution debug output

		tip:
			parent pom declare most properties ,plugins etc,models under parent,only needs to config special requiments ,if needs to make war package for example and it can references definetions
			from parent pom ,just lile inheritance(eg struts2's configuration file struts.xml).

		maven 插件 ，源码自动下载

5. 熟悉houyi代码，结构
	
	
	
6. xStream javabean 与 xml ，json映射工具
	参考：http://www.cnblogs.com/hoojo/archive/2011/04/22/2025197.html
	部分如下：
		xStream框架

			xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换；

			前面有介绍过json-lib这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/21/2023805.html

			以及Jackson这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/22/2024628.html

			它们都完美支持JSON，但是对xml的支持还不是很好。一定程度上限制了对Java对象的描述，不能让xml完全体现到对Java对象的描述。
			这里将会介绍xStream对JSON、XML的完美支持。xStream不仅对XML的转换非常友好，而且提供annotation注解，可以在JavaBean中完成
			对xml节点、属性的描述。以及对JSON也支持，只需要提供相关的JSONDriver就可以完成转换。 

7. Quartz 调度

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day3 2012年3月16日

1. 项目目录结构 maven
	
	

2. 结合 openapi 接口文档 ，熟悉代码，规范

	以hoyi-console-openapi  为例，熟悉大体框架，配置方式，处理流程
	
	根据应用上下文配置文件(web.xml)，熟悉请求处理流程 （web应用 ,java应用根据程序入口）

		* struts2 ,spring ,ibatis
			spring
				bean管理 - pojo,dao bean ,action
				事务管理
			struts2
				interceptor - default and user defined interceptors / pluggable
				objectfactory = spring
				action继承/接口关系(部分)
					public class RackQueryAction extends PagingInfovalidator implements ExecuteAction {
					-> public abstract class PagingInfovalidator extends AbstractExecuteAction implements ActionValidator{
					-> public abstract class AbstractExecuteAction implements ExecuteAction {

				部分struts源码截取：【struts】
					multi-thread safe
					--------
						package com.opensymphony.xwork2;
						...
						public class ActionContext implements Serializable {
						    static ThreadLocal actionContext = new ThreadLocal();
						...
						    Map<String, Object> context;

						    public ActionContext(Map<String, Object> context) {
							this.context = context;
						    }
						...
						    public static void setContext(ActionContext context) {
							actionContext.set(context);
						    }
						    public static ActionContext getContext() {
							return (ActionContext) actionContext.get();
					--------
					
					--------
					...
					package com.opensymphony.xwork2;
					public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable {
					...
					    public Locale getLocale() {
						ActionContext ctx = ActionContext.getContext();
						if (ctx != null) {
						    return ctx.getLocale();
						} else {
						    LOG.debug("Action context not initialized");
						    return null;
						}
					    }
					...
					--------
					Interface :
						Action - All actions may implement this interface, which exposes the execute() method. 
						Validateable - Provides an interface in which a call for a validation check can be done.
						ValidationAware - ValidationAware classes can accept Action (class level) or field level error messages. Action level messages are kept in a Collection. 
									Field level error messages are kept in a Map from String field name to a List of field error msgs.
						TextProvider - Provides access to ResourceBundles and their underlying text messages.
						LocalProvider - Indicates that the implementing class can provide its own Locale. 
					
					ActionInvocation
							An ActionInvocation represents the execution state of an Action. It holds the Interceptors and the Action instance. By repeated re-entrant execution 
						of the invoke() method, initially by the ActionProxy, then by the Interceptors, the Interceptors are all executed, and then the Action and the Result.
						代理类，维护interceptors集合并依次序传递和执行ActionInvocation的实现类。？




			ibatis openAPI通过spring提供ibatis的template进行dao操作
				部分代码，spring集成ibatis部分
					--------
					package org.springframework.orm.ibatis;
					...
					public class SqlMapClientTemplate extends JdbcAccessor implements SqlMapClientOperations {
						public Object queryForObject(final String statementName, final Object parameterObject)
								throws DataAccessException {

							return execute(new SqlMapClientCallback() {
								public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
									return executor.queryForObject(statementName, parameterObject);
								}
							});
						...
						public Object execute(SqlMapClientCallback action) throws DataAccessException {
							Assert.notNull(action, "Callback object must not be null");
							Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

							// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
							// Connection (potentially transactional) in. This shouldn't be necessary if
							// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
							// we still need it to make iBATIS batch execution work properly: If iBATIS
							// doesn't recognize an existing transaction, it automatically executes the
							// batch for every single statement...

							SqlMapSession session = this.sqlMapClient.openSession();
							if (logger.isDebugEnabled()) {
								logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
							}
							Connection ibatisCon = null;

							try {
								Connection springCon = null;
								DataSource dataSource = getDataSource();
								boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

								// Obtain JDBC Connection to operate on...
								try {
									ibatisCon = session.getCurrentConnection();
									if (ibatisCon == null) {
										springCon = (transactionAware ?
												dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
										session.setUserConnection(springCon);
										if (logger.isDebugEnabled()) {
											logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
										}
									}
									else {
										if (logger.isDebugEnabled()) {
											logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
										}
									}
								}
								catch (SQLException ex) {
									throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
								}

								// Execute given callback...
								try {
									return action.doInSqlMapClient(session);
								}
								catch (SQLException ex) {
									throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
								}
								finally {
									try {
										if (springCon != null) {
											if (transactionAware) {
												springCon.close();
											}
											else {
												DataSourceUtils.doReleaseConnection(springCon, dataSource);
											}
										}
									}
									catch (Throwable ex) {
										logger.debug("Could not close JDBC Connection", ex);
									}
								}

								// Processing finished - potentially session still to be closed.
							}
							finally {
								// Only close SqlMapSession if we know we've actually opened it
								// at the present level.
								if (ibatisCon == null) {
									session.close();
								}
							}
						}	}
					...
					--------
			dbcp - DB connection pool


		* 枚举 enum 
			定义常量(可扩展的)，优于普通常量定义
			 AgreementParameter
			 GlobalErrorMessage
			...
				eg:
				return CloudEngineEvent.NGINX.getEvent();

				public enum CloudEngineEvent {
					REGISTER(10001),
					NGINX(30001),
					FASTCGI(30002),
					SLB(30003),
					MEMCACHED(30004),
					RDS(30005),
					NODEJS(30006)
					;
					
					private CloudEngineEvent(Integer event) {
						this.event = event;
					}
					
					private Integer event;
					public Integer getEvent() {
						return event;
					}
				}

		* 

	openAPI mode 要引用到得其他各层分别在不同的model中: (openapi为houyi项目其中一个model)
		<modules>
		  <module>houyi.console.model</module> 域模型(历史原因有部分分散在其他model中)
		  <module>houyi.console.util</module> 工具
		  <module>houyi.console.acl</module> 访问控制
		  <module>houyi.console.dao</module> DAO
		  <module>houyi.console.clc</module> 对内master交互模块(操作vm等)
		  <module>houyi.console.service</module> 逻辑层
		  <module>houyi.console.message</module> 消息
		  <module>houyi.console.statistics</module>  
		  <module>houyi.console.web/houyi.console.web.support</module>  web这块原先以portal调
		  <module>houyi.console.web/houyi.console.web.staff</module>
		  <module>houyi.console.web/houyi.console.web.admin</module>
		  <module>houyi.console.web/houyi.console.web.isv</module>
		  <module>houyi.console.openapi</module> 对外openapi模块
		</modules>		
	
	openAPI 放开的请求action配置：- 统一出入口 ？
		<package name="instance" extends="houyi-open" namespace="/">
			<action name="services" class="openAPIProxyAction" method="proxy"><!-- action交给spring管理，此action为：open api 的访问代理 -->
			   <result type="userActionResult"></result> <!-- 自定义result -->
			</action>
		</package>
		代理action利用req请求消息，通过工厂方式(目标action都实现相同接口)调用对应的目标acton，目标action通过spring context获得：
			// Return the bean instances that match the given object type (including subclasses), judging from either bean definitions or the value of getObjectType in the case of FactoryBeans. 
			Map map = context.getBeansOfType(ExecuteAction.class);


3. xen 快照 了解  虚拟机快照 【快照】
	虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
	chain 模式 比如 struts的intercepter ，插拔式
	
	http://server.it168.com/a2009/0723/611/000000611079.shtml
4. StringEscapeUtils 
	Escapes and unescapes Strings for Java, Java Script, HTML, XML, and SQL
	commons-lang包

5. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day4 2012年3月19日

1. RESTful REST 请求

http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v2/master/src/main/java/com/aliyun/cloudengine/
JCE的master以REST架构，处理openAPI(为get/post请求规范)请求需要提供一个适配层(将REST请求转换为http方式的get/post请求) ？ - Java Cloud Engine

jce的rest实现基于

rest http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/
	介绍jdk1.6提供的rest接口，master的rest基于jdk的rest接口 javax.ws.rs

基于 REST 的 Web 服务遵循一些基本的设计原则：
    系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的 URI。
    以遵循 RFC-2616 所定义的协议的方式显式地使用 HTTP 方法，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与 HTTP 方法之间的一对一映射：
        若要在服务器上创建资源，应该使用 POST 方法；
        若要检索某个资源，应该使用 GET 方法；
        若要更改资源状态或对其进行更新，应该使用 PUT 方法；
        若要删除某个资源，应该使用 DELETE 方法。
    URI 所访问的每个资源都可以使用不同的形式加以表示（比如 XML 或者 JSON），具体的表现形式取决于访问资源的客户端，客户端与服务提供者使用一种内容协商的机制（请求头与 MIME 类型）来选择合适的数据格式，最小化彼此之间的数据耦合。

【Task】
	以 /houyi-cloudengine-master/src/main/java/com/aliyun/cloudengine/RestAdminApplication.java 为例，熟悉rest方式，并分析rest方式与openapi标准的get/post方式如何转换 ？
	houyi-cloudengine-master 提供几个rest接口供外界调用。
	由于rest方式的请求url不同于普通http请求的url，需要提供一个模块处理标准http请求的处理(接受请求-调用接口-返回结果)
		rest方式URI: persion/123		http方式: persion?id=123
	
	cloudengine 运行是基于xuanyuan的一个组件，xuanyuan负责请求分配。
	
	参考实现的文档，搭建测试环境测试，判断是否支持预想的解决方案。 - tip -

2.  test 测试
JTester
	   http://java-tester.googlecode.com/svn/maven2/

	   http://www.blogjava.net/kiral/archive/2011/02/04/344072.html usage
	

3. 搭建 restful 环境，测试
	jersey + tomcat 的restful测试环境搭建：
		wiki https://wikis.oracle.com/display/Jersey/Main
		参考 http://www.ibm.com/developerworks/cn/web/wa-aj-tomcat/

	@POST 
	@Path("/test")
	@Produces(MediaType.APPLICATION_JSON)
	public String showTime(@FormParam("username") String userName,@Context HttpServletRequest httpRequest) {
	:
	:
	:
	}
	// jersey - 通过context注解获得httprequest对象
	
	对于openAPI调用(待测试)：
		可以给定URI请求，匹配到一个service上，然后取得request对象，做后续处理。
		(要做的步骤：
			配置一个service匹配opanapi的所有请求

		)

Using Entity Providers toMapHTTP Response and
Request Entity Bodies
Entity providers supply mapping services between representations and their associated Java
types. There are two types of entity providers: MessageBodyReader and MessageBodyWriter.
For HTTP requests, the MessageBodyReader is used to map an HTTP request entity body to
method parameters. On the response side, a return value is mapped to an HTTP response entity
body using a MessageBodyWriter. If the application needs to supply additional metadata, such
Responding to HTTP Resources
Chapter 3 • Creating a RESTful Resource Class 19
as HTTP headers or a different status code, a method can return a Response that wraps the
entity, and which can be built using Response.ResponseBuilder.

——jersey文档

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day5 Tuesday, March 20, 2012

1. day4第3条 go on
	* 下载jersey包
	* 新建web项目，导入jersey必要包
	* 配置jersey的请求处理servlet，并正确配置package属性：com.sun.jersey.config.property.packages - 指向你的resource包
	* 部署到tomcat中
	* 测试

	部分代码：
	-----
		<servlet>
			<servlet-name>Jersey REST Service</servlet-name>
			<servlet-class>
			  com.sun.jersey.spi.container.servlet.ServletContainer
			</servlet-class>
			<init-param>
			  <param-name>com.sun.jersey.config.property.packages</param-name>
			  <param-value>test.jersey.service</param-value>
			</init-param>
			<load-on-startup>1</load-on-startup>
		</servlet>
		<servlet-mapping>
		  <servlet-name>Jersey REST Service</servlet-name>
		  <url-pattern>/rest/*</url-pattern>
		</servlet-mapping>

		package test.jersey.service;
		@Path("hello")
		public class HelloResponse {

			@GET
			@Produces(MediaType.TEXT_PLAIN)
			public String sayHello(){
				return "Hello jersey";
			}
	
		}
	------
	[ Test ]
		req: http://localhost:8080/jersey/rest/hello
		resp: Hello jersey

	[ Test ]
		@GET
		@Produces(MediaType.TEXT_PLAIN)
		public String sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
			return "id:"+id+" name:"+name;
		}	
		request: http://localhost:8080/jersey/rest/hello?id=1&name=jack   - 
		response: id:1 name:jack

	[ Test ]
		@Path("/hello")
		public class HelloResponse {

			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			public MyResponse sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
		//		return "NORMAL id:"+id+" name:"+name+"\n";
				return new MyResponse(id,name);
			}
			
			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			@Path("/sayhello/{id}/{name}")
			public Object sayHelloRest(@DefaultValue("1") @PathParam("id") String id,@DefaultValue("1NaN") @PathParam("name") String name){
				return new MyResponse("1","jack");
			}
		}
		web.xml: 
			<servlet-mapping>
				  <servlet-name>Jersey REST Service</servlet-name>
				  <url-pattern>/open/*</url-pattern>
			</servlet-mapping>
		request: http://localhost:8080/jersey/open/hello/sayhello/1/1
		response: 
				<data>
					<id>1</id><
					name>jack</name>
				</data>

	要返回json或xml，需要将返回的对象配置上对象到xml的映射注解，比如利用jaxb等 ，需要提供一个对象到json或者xml的映射机制，如果直接返回
	jdk的list对象会报错，无法转换：
		A message body writer for Java class java.util.ArrayList, and Java type interface java.util.List, and MIME media type application/xml was not found
		eg:http://blog.coderunnr.com/2011/02/clienthandlerexception-a-message-body-writer-for-java-type-class-and-mime-media-type-applicationoctet-stream-was-not-found/
	将返回的pojo通过注解映射到xml即可：
		@XmlRootElement(name="data")
		public class MyResponse {
			
			private String id;
			
			private String name;
			
			public MyResponse(){}
			
			public MyResponse(String id,String name){
				this.id = id;
				this.name = name;
			}
			
			@XmlElement(name="id")
			public String getId() {
				return id;
			}
			public void setId(String id) {
				this.id = id;
			}
			
			@XmlElement(name="name")
			public String getName() {
				return name;
			}
			public void setName(String name) {
				this.name = name;
			}
		}
		

		问题：
			// 这个标签标示注解的方法支持下面定义的 2 种返回数据格式，具体确定？
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			
			如上，可以返回多个MIME，如何选择，确定返回的类型？
				比如，需要返回xml，或者需要返回json 
				看openAPI是根据什么返回指定格式的数据的？
					openAPI通过请求参数 format 来判断client请求的数据格式，故这里需要用到 @queryparam 来取得 format ，从而返回对应的
				格式。
			jersey guide：
					If a resource class is capable of producing more that one MIME media type then the resource method chosen will correspond to the most acceptable media type 
				as declared by the client. More specifically the Accept header of the HTTP request declared what is most acceptable. For example if the Accept header is:
					Accept: text/plain
				then the doGetAsPlainText method will be invoked. Alternatively if the Accept header is:
					Accept: text/plain;q=0.9, text/html
				which declares that the client can accept media types of "text/plain" and "text/html" but prefers the latter, then the doGetAsHtml method will be invoked.
				More than one media type may be declared in the same @Produces declaration, for example:
			方案1：从jersey guide看，可以根据http请求头的 accept定义值返回相应格式。
				但openapi规范提供的是根据get方式的 format参数来确定返回格式的
			方案2:：根据 format 字段，找到rest框架提供的动态自定义返回格式的设置 ？ 在哪里设置？
				在response里设置header，rest框架根据header定义的格式渲染结果。
				通过response根据需要的返回状态(status)取得responsebuilder对象(处理返回内容)，取得请求参数，通过builder设置返回的Cotent-Type类型(MediaType定义的类型)
				builder的entry方法处理需要返回的对象，build()，返回即可。

			【tip】误区，试图设置request的accept值来影响response的返回数据格式，要返回什么样的数据及其格式都可以通过response来设置。
				拥有者或者自身或其相关工具一般会提供操作其自身的值的入口。

				

2. jax-rs 注解(from jax-rs api)
	Consumer - Defines the media types that the methods of a resource class or MessageBodyReader can accept 定义资源可以接受处理的请求类型
	Produces - Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce
	MediaType - An abstraction for a media type. Instances are immutable(不变的). 


3. 对于第1条的REST框架也支持非REST请求uri的转发，这其中，只是转发的作用，不带有业务逻辑，是否可以用nginx的rewrite来实现？
	后续SLB也需要对openapi提供处理层，其中含业务逻辑，选择REST方式。

4. nginx rewrite 重写
	目标：将openapi的标准请求重写为符合REST接口的rest请求。
	nginx的rewrite规则(rewrite模块)：
	http://xx.host/action?id=xx&name=xx rewrite为 http://xx.host/action/xx/xx

	
	URL rewriting is a key element to Search Engine Optimization (SEO). ——　摘自：Nginx HTTP Server p141

		参考 http://chenxiaoyu.org/2011/10/30/nginx-modules.html
	正则表达式 规则 regex
	regular expression(Perl Compatible Regular Expression (PCRE) library):
		Metacharacter
			Description
		^
		Beginning
			The entity after this character must be found at the beginning.
			Example pattern: ^h
			Matching strings: hello, h, hh
			Non-matching strings: character, ssh
		$
		End
			The entity before this character must be found at the end.
			Example pattern: e$
			Matching strings: sample, e, file
			Non-matching strings: extra, shell
		.
		Any
			Matches any character.
			Example pattern: hell.
			Matching strings: hello, hellx, hell5, hell!
			Non-matching strings: hell, helo
		[ ]
		Set
			Matches any character within the specified set.
			Syntax: [a-z] for a range, [abcd] for a set, and [a-z0-9] for
			two ranges
			Example pattern: hell[a-y123]
			Matching strings: hello, hell1, hell2, hell3
			Non-matching strings: hellz, hell4, heloo
		[^ ]
		Negate set
			Matches any character that is not within the specified set.
			Example pattern: hell[^a-np-z0-9]
			Matching strings: hello, hell;
			Non-matching strings: hella, hell5
		|
		Alternation
			Matches the entity placed either before or after the |.
			Example pattern: hello|welcome
			Matching strings: hello, welcome, helloes, awelcome
			Non-matching strings: hell, ellow, owelcom
		( )
		Grouping
			Groups a set of entities, often to be used in conjunction with |.
			Example pattern: ^(hello|hi) there$
			Matching strings: hello there, hi there.
			Non-matching strings: hey there, ahoy there
		\
		Escape
			Allows you to escape special characters.
			Example pattern: Hello\.
			Matching strings: Hello., Hello. How are you?, Hi! Hello...
			Non-matching strings: Hello, Hello, how are you?

		Quantifiers
		So far, you are able to express simple patterns with a limited number of characters. Quantifiers allow you to extend the amount of accepted entities:
		Quantifier
			Description
		*
		0 or more times
			The entity preceding * must be found 0 or more times.
			Example pattern: he*llo
			Matching strings: hllo, hello, heeeello
			Non-matching strings: hallo, ello
		+
		1 or more times
			The entity preceding + must be found 1 or more times.
			Example pattern: he+llo
			Matching strings: hello, heeeello
			Non-matching strings: hllo, helo
		?
		0 or 1 time
			The entity preceding ? must be found 0 or 1 time.
			Example pattern: he?llo
			Matching strings: hello, hllo
			Non-matching strings: heello, heeeello
		{x}
		x times
			The entity preceding {x} must be found x times.
			Example pattern: he{3}llo
			Matching strings: heeello, oh heeello there!
			Non-matching strings: hello, heello, heeeello
		{x,}
		At least x times
			The entity preceding {x,} must be found at least x times.
			Example pattern: he{3}llo
			Matching strings: heeello, heeeeeeello
			Non-matching strings: hllo, hello, heello
		{x,y}
		x to y times
			The entity preceding {x,y} must be found between x and y times.
			Example pattern: he{2,4}llo
			Matching strings: heello, heeello, heeeello
			Non-matching strings: hello, heeeeello
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day6 Wednesday, March 21, 2012

1. openapi 
	OpenAPI - 消息推送/订阅(Message push/subscrible)  -Master 
	
	根据登记在消息服务器上的订阅节点信息，进行push

2. python nodejs 
	python yaml模块 - YAML是一种直观的能够被电脑识别的的数据序列化格式，容易被人类阅读，并且容易和脚本语言交互。YAML类似于XML，但是语法比XML简单得多，对于转化成数组或可以hash的数据时是很简单有效的。

3.  wget 从vmware中的centso访问本机的rest服务
	取得返回内容，cat查看
	sshl连接到centos命令行操作。
	
	环境：
		apache ,
		tomcat,
		nginx,
		mysql,
		eclipse,
		python,(test)
		nodejs,(test)
		linux container(test)

4. CIDR Classless Inter-Domain Routing 了解
	无类别域间路由选择
	ref:
		CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给
	服务提供商（ISP），	再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，
	从而减轻Internet路由器的负担。		

5. ce里shell脚本熟悉
	"#!/bin/sh" - 对shell的声明，说明你所用的是那种类型的shell及其路径所在。
	自定义shell function封装常用功能，提高shell编写效率。
		eg: 


6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day7 Thursday, March 22, 2012

1. ace mast agent(python shell) 
	master 职责


2.  ace 计量单位讨论会议，
	字段需要取出推送到消息系统，供后续计量，计费
	主要关于 计量字段需求，及可行性确认
	详见记录
	tip: 由于涉及多个系统的交互，如何处理规则，处理变化的问题，如果适应变化减少依赖耦合。

3. cloudengine 熟悉
	master ,agent 部分
	master调用agent
	agent根据不同的应用类型(目前:php，nodejs，jsp)调用相应的build脚本(配置环境运行环境，部署应用，启动应用，启动agent)

	nodejs http://nodejs.org/
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day8 Friday, March 23, 2012

1. cloudengine 
	trunk
		agent - agent模块(python)
			fastcgi
			memcached
			monitor
			nginx
			nodejs
			test
			yaml
		carrier - Erlang (rebar ...)
		ftpserver - ftp服务(java)
		master - master(java)
		memcahched_pach - memchche部署
		nginx_pach - nginx部署
		nodejs -  nodejs部署(build_agent -> install_agent -> install_nodejs -> upgrade_nodejs)
		php - php部署

2. ACE计量 
	计量单位，字段说明
	oss接口
	ms接口

	目标：将ACE各计量单位取到并以ms要求的格式推送给ms(Metering Service)计量系统系统 ，有一个python的
	的实现可以参考:
		python 
			程序基本结构
			变量，运算 etc
			模块
				MySQLdb
					eg 通过此模块与mysql数据库交互：(下载这个库有linux和win版本)
						conn=MySQLdb.connect(host="localhost",user="root",passwd="sa",db="mytable")
	
			执行
			应用
	* 

	参考 houyi-console/static (java)实现，上述任务 【Task】
	= = URL请求的要求(格式，构造)等可以参考这个实现 = =
		定义数据格式
		定义任务
		spring配置调用执行

		步骤：(公用动作比如推送等已有实现，调用其逻辑处理即可) 细化
			>> 取
				* MS取SLB流量(appid对应的流量，appid指每个具体的应用)	单位 byte
					- 从ACE DB中取得appid对应的slb_id，及应用的id与SLB的id对应关系 1对1
						- 从DB得到app_id对应的slb_id(cloudengine库)

							-- 从DB得到app_id对应的slb_id
							select 
								app.id app_id,
								slb.id slb_id
							from app app,slb_alloc_record slb
							where app.id = slb.id
							
					- 请求Meteriing Service，根据slb_id取数据
						MS接口文档(比如如何查询SLB数据？)
						

					-  MS返回vip对应的流量数据的数据格式
						Flow_detail的格式如下：
						[tcp(VIP:80|2|3|)(VIP:8080|2|3|)][http(www.a.com:80|2|3|)(www.b.com:90|2|3|)]
					
					- 

				* MS取OSS
					- 从app表(cloudengine)取得kv_bucket
						select 
							id app_id,
							kv_bucket
						from app
					- URL格式
						columns: storage;
						where: openid=ace;pid=oss;bid=26842;inst_id=$bucketname;begin_time=13123121400;end_time =132123241500;inst_id,migrate-win2003-vifs
						http://10.1.157.163:8080/aliyun/QS/OSS/RAW
						bid - 用户ID，app所属的用户
						$bucketname对应kv_bucket
					- 
						
				* DB取cpu时间等
					‘cloudengine`.`fastcgi_app_running_info` cpu_acc_usage App的cpu持续使用时间，单位：秒

			>> 处理

			>> 推送 写往MS
				推送数据格式
					* 在 DataFormat里定义枚举 
					*  pojo (实现接口)
					* 请求
						http request header:
						PUT /aliyun.com/QS/SLB/RAW HTTP/1.1（待定，需姜一提供）
						HOST: ms.aliyun.com
						CONTENT‐LENGTH: 12345
						META: uid,string;inst_id,string; time, integer; usetime,integer; total_in,integer;total_out,integer;tcp_flow_in,integer;tcp_flow_out,integer;http_flow_in,integer;http_flow_out,integer;vip_type,string;rs,integer;flow_detail,string;region_id,string;end_time,integer;
						“META为用户发送的数据的格式信息，这部分必须添加在http的header部分，为计量服务(MS)特有字段”
						http://metering.aliyun-inc.com:8080/aliyun/QS/OSS/RAW  —— 线上系统的地址
						http://10.1.157.163:8080/aliyun/QS/SLB/RAW —— 测试时用测试系统地址
					* 整理推送的字段对照 doc ？
						Cpu(ms)、流量(byte)、存储空间(byte)、请求次数、memory-cache(byte)

						属性名			类型			单位			描述
						uid				string							包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务
						time				integer							开始时间(记录当前记录的时刻，为一点态时间，如果用户的计量数据采集并非实时，则time表示抽样开始时间即begin_time，采用可显示的unix时间表示法)
						end_time			integer							结束时间(表示抽样结束时间，同样采用可显示的unix时间表示法)
						inst_id			string							应用id即appid
						cpu				integer			ms				cpu使用时间
						flow				integer			byte				总流量(http流量)
						flow_in			integer			byte				流入流量
						flow_out			integer			byte				流出流量
						app_size			integer			byte				存储空间(oss)
						req_count			integer			个				请求次数(包括pv内的多个异步请求)
						version			integer							版本号，目前为1



						






		uid：包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day9 Monday, March 26, 2012

1. 计量的接口说明 最新的 ？
	

2. 把ace计量初步需求写入文档，
	类似于slb接口文档等
	
	目的：设计ace计量项，并取到后处理然后提交到ms系统
	计量项列表：
	实现：
		计量项获取：
		处理
		推送
	xuanyuan cloudengine数据库表间关系由程序控制，注释说明关系。

3. job的具体实现，失败补偿逻辑，参看console中的static模块
	？


4. 通过powerdesigner的reverse engine ，从database的sql文件将ddl转换为er图，了解db表关系

5. velocity 方便对象格式化到文件
	...
	velocityEngine.init();//spring配置好resourceLoaderPath
	template = velocityEngine.getTemplate(templateFile);
	VelocityContext context = new VelocityContext();
	context.put("datasMap", map);
	writer = new FileWriter(outfile);
	template.merge(context, writer);
	...
6. spring + quartz 执行定时任务
	<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
		<property name="targetObject" ref="task" />
		<property name="targetMethod" value="execute" />
		<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
	</bean>	
	<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
		<property name="jobDetail" ref="collectDataDetail" />
		<property name="cronExpression" value="0 0 */1 * * ?" />
	</bean>  
	<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="triggers">
			<list>
				<ref bean="collectDataTrigger" />
			</list>
		</property>
	</bean>
7. 操作记录及时保存为数据库的日志，后续补偿机制根据数据库补偿并更新 ？
	细节

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day10 Tuesday, March 27, 2012

1. 根据上面ace计量文档，编码
	对于时间如何处理，补偿机制

2. ACE计量先不提供需要访问MS的SLB和OSS数据，暂先考虑DB数据 【task】
	先实现ace监控数据的抽取推送。
		一些dao需要自己定义以取监控数据
		时间校准，以抽取逻辑定义的时间为准，根据定义的时间去取监控数据并汇总，处理，推送
	处理的整体流程：
		关键是发生错误的补偿处理逻辑：
		tasklog表记录task日志。		

3. 表说明
	region - 代表一个集群
测试环境 mysql
mysql -h10.249.153.1 -ucloudengine -pcloudengine2011 -Dcloudengine



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day11 Wednesday, March 28, 2012

1. 设计好补偿处理逻辑
	结合day10第二条的表记录job及其result实现补偿处理。

2. 任务处理已有设计，在已有的任务设计下实现功能
	* job代表每一次执行的任务
		job推送前都记录到数据库，job下的内容保存为临时文件。
	* spring+squza定时任务
	* 日期处理
		DateUtils.java —— 将date日期格式化为需要的格式；date到秒；string+patten到date  (SimpleDateFormat实现)
	* pojo
		TaskLog 任务日志pojo
			private Long id;
			private int status; // 1:success,0:failed
			private String filename;
			private Long taskTime;
			private int jobType; //[0:vm job,1:device job; default 0]
			private Date beginTime;
			private Date endTime;
			OR文件：/houyi-console-dao/src/main/resources/ibatis/TaskLog.xm
				houyi库 statistics_log
	* service
		JobService ：job相关操作
			public boolean addOrModify(TaskLog job);
			public boolean checkStatus(TaskLog job);
			public List<TaskLog> listFailedJobs(long startTime);
			public List<TaskLog> listJobs(long startTime,long endTime);
			public TaskLog getLastJob();
	* dao
		TaskLogDao ：任务日志DAO操作
			void insertTaskLog(TaskLog log) ;
			void updateTaskLog(TaskLog log) ;
			TaskLog getTaskLog(TaskLog log) ;
			TaskLog getLastTaskLog();
			List<TaskLog> getFailedTaskLogs(Long bTime);
			List<TaskLog> getTaskLogs(Long bTaskTime,Long eTaskTime);

	* task 由于时间等内容不好共用，可再设计一个task，并通过spring配置执行。
		或对task进行业务无关的再抽象，只留下共用的逻辑，其他都内聚到job自身中。-tip-

	处理流程：(包括 Task ，JobProducer，需要的service,dao,pojo) - 由程序入口分析
		--> task - execute()定时执行这个方法 - 调用dojob()  —— dojob是单线程的，如果job多或者某个前面的job占用时间长会影响后面的job的执行开始时间 ？ tip 如果是独立的task则不用考虑影响问题
			遍历执行注入的jobproducer实现 (获取方式：beans = (Map<String, JobProducer>) applicationContext.getBeansOfType(JobProducer.class))
		--> jobproducer(具体job逻辑在jobproducer的实现类里编写)\
		--> service
		--> dao
		逻辑就在task，jobproducer,abstract jobproducer中，定义自己的逻辑即可。
			原有任务以task作为主流程控制，jobproducer抽象类及其实现定义了所有逻辑。抽象类提供公用逻辑或抽象方法统一逻辑。-tip-
				取数据 - 存入数据库/文件(通过velocity映射对象集合(以appid为标识)存为文本) - push - 更新状态
3. 模拟实现
	根据原有static模块任务设计
		* 定义数据结构 pojo ,velocity模板(用于对象格式化持久化)
			是否需要将此pojo作为对象查询？即某个查询直接返回此pojo，需要ibatis映射配置，这样只要查询一次关联几张表得到数据；或者分别查询在程序中处理。
			暂定位分别查询。分别查询，减少关联
		* 实现一个job producer
		* 定时task类，可能需要再实现一个并在spring里配置(原task再抽象以下，可配置)，
		参考配置：
			<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
				<property name="targetObject" ref="task" />
				<property name="targetMethod" value="execute" />
				<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
			</bean>	
			<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
				<property name="jobDetail" ref="collectDataDetail" />
				<property name="cronExpression" value="0 0 */1 * * ?" />
			</bean>  
			<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
				<property name="triggers">
					<list> <!-- 此处配置定时要执行的task列表 -->
						<ref bean="collectDataTrigger" /> 
					</list>
				</property>
			</bean>
		* 判断tasklog是否已执行过，通过jobtype类型和jobtime-job开始时间，如果是依据查询的最新执行时间作为job开始时间
			if (jobService.checkStatus(job))
			{
				logger.info("exist job:" + jobTime);
				return true;
			}
		* abstract producer的一些公用成员变量是否可以提供get方法供子类调用，子类不用重复定义 ？
		* task的recoverJob逻辑处理丢失的任务（比如关机等造成的任务丢失），目前任务是能处理丢失10次的任务，是否可以根据做新一次的任务的开始时间
		结合当前时间计算共丢失多少次任务，然后执行所有丢失的任务？
			Task
			------
			...
				/** Get the last record of success in the log table **/
				TaskLog log = jobService.getLastJob();

				/** compensate for missing the task **/
				if (log != null)
				{
					int i = 1;
					while (log.getTaskTime() + i * HOUR_SEC < jobTime)
					{
						/** Compensate for 10 times **/
						if (i == 10)
						{
							break;
						}

						TaskLog job = new TaskLog();
						job.setBeginTime(new Date());
						job.setTaskTime(log.getTaskTime() + i * HOUR_SEC);
						job.setStatus(0);
						jobService.addOrModify(job);
						i++;
					}
				}
			...
			------
		* 一些任务参数是否可以配置到配置文件中，类似abstract job producer的parentpath路径配置 比如：采集间隔，一些补偿机制参数 ？
		* statistics_log表？
		* app的类别区分是哪个字段(php,nodejs,jsp) ?
			templetid?
		* 用到的一些接口需要修改 ，通过的方式过少，是否可修改，其他地方是否有调用？
			比如提供id数组查询。
		* 应用运行时状态表
			fastcgi_app_running_info
			nginx_app_running_info
			memcache_app_running_info
			nodejs_app_running_info
		* console与cloudengine不是同一项目，maven管理依赖，引入cloudengine的包？
			自己重新写maping文件pojo及dao接口和实现。不依赖不相关系统。
			在dao，model等模块加入对应代码。
		* ibatis查询，可以根据外键设置关联查询，减少查询次数
		* 由于是另外一个数据库，需要再配置数据源
		* 在houyi-console-dao里写dao层用到pojo是static中的，是否把pojo，dao，service都按照模块放置，负责dao就要依赖到static中的pojo ？
			static的model不直接提供dao，而是从其他数据组合而成。比如从appdao的查询记录里组合而成。
		* 统计一个时间段的缓存使用量，如何取？暂定为求和
		* 参考master的constant 包定义的常量，帮助了解一些业务知识
			AppType 定义了应用的类型。php.nodejs...
			app 的 language 属性定义apptype类型。
		* 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day12 Thursday, March 29, 2012

1. go on 
	新建maven project开发，独立功能
	参考console的static模块，做成一个任务模块(业务，逻辑分离，易配置)
	wiki地址：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8259199
	svn ：http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk
	web项目 or java进程(jar包main函数启动) or 作为一个组件部署（作为组件部署，有哪些要求，比如 cloudengine 在 xuanyuan 上运行）？
	
	* 导入需要的包
	* 拷贝公用代码 工具类 等
	* dao设计依据master，提供抽象dao实现namespace的spring配置
	* 参考master用jtester测试
		加入jtester依赖包 地址http://java-tester.googlecode.com
		jtester 配置文件中 unitils.modules=database,dbunit,dbfit,inject,spring,tracer ，这里列出了需要的模块
		编译测试，提示编译版本问题时，可以切换下jdk版本，并clean下project。
		测试用例数据，参考master的：eg
			@DbFit(when = {"AgentCheckResultDaoTest.testReadByAgentId.when.wiki"})
		集成spring测试时，可能由于spring配置等问题导致maven test失败；可通过基本的main函数先保证spring的注入式正确的 -tip-
		maven test + main method test
		maven clean + eclipse project clean solve cmplile problems 
	
		如何自动生成测试用例 ？ ，对每个方法都手工去编写基础测试代码过于繁琐
		
		wiki方式数据库测试时，jtester测试时可以根据wiki配置临时清除表数据，做测试，结束后回滚。

	*  wiki project描述

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day13 Friday, March 30, 2012

1. ameasure-data project
	job基础代码与业务代码分离，实现可配置。
	* 配置maven插件,jar (以及插件的参数配置，jar执行main函数配置 etc - 参考maven jar插件说明：http://maven.apache.org/shared/maven-archiver/index.html)
	* 测试报 Could not find Velocity resource: class path resource [VM_global_library.vm
	* 配置maven插件 maven-assembly-plugin ,packaged with-dependencies 打包并加上依赖 ,配置assembly参数，比如jar分别打包，
		打包时可能jar包文件重复，test目录下的测试文件也打包进来，配置一些参数即可，例如：
			-----
			...
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.Test</mainClass>
							</manifest>
						</archive>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				(2)
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<descriptors>
							<descriptor>src/main/assembly/src.xml</descriptor>
						</descriptors>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.StartTask</mainClass>
							</manifest>
						</archive>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0" 
				  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				  xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd">
				  <!-- TODO: a jarjar format would be better -->
				  <id>with-dependencies</id>
				  <formats>
				    <format>zip</format>
				  </formats>
				  <includeBaseDirectory>false</includeBaseDirectory>
				  
				  <dependencySets>
				    <dependencySet>
				      <outputDirectory>/</outputDirectory>
				      <useProjectArtifact>true</useProjectArtifact>
				      <unpack>false</unpack>
				      <scope>runtime</scope>
				    </dependencySet>
				  </dependencySets>
				</assembly>
			...
			-----
			打成上面这种jar包集合方式，在同一文件夹下运行即可，省去classpath配置的麻烦。

		maven clean after close resource opened -tip-
	* 加上shell执行脚本，调用此jar并执行
	* 原有推送逻辑，一次job比如推50条，一条失败就退出，暂处理为本次任务再尝试推送(设定尝试次数)
	*  ibatis 在命令行下运行找不到mapping文件，在eclipse下测试ok 原因？ 待  —— ibatis没问题，spring也ok，字体用的不好(大小写居然相似，
		最后还是仔细看了错误输出，错误点才发现大小写)大小写错误，配置文件配置和实际文件大小写不一致！！！-tip-
		如何避免：提示文件找不到，名称不匹配等等，首要看是否书写错误，能拷贝一定拷贝，不要手工输入，特变是在配置文件场合。 -tip-




2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day14 Saturday, March 31, 2012

1. measure-data
	* 逻辑细化 command
	* quartz ? cluster
		利用quartz实现调度执行，将操作记入日志，失败处理另外实现并
	* 任务测试
		测试表 tasklog `statistics_log`
			CREATE TABLE  `cloudengine`.`statistics_log` (
			  `id` int unsigned NOT NULL AUTO_INCREMENT  COMMENT '@desc 主键ID' ,
			  `status` tinyint NOT NULL COMMENT '@desc 1', 
			  `filename` varchar(128)  COMMENT '@desc filename',
			  `task_time` datetime NOT NULL  COMMENT '@desc tasktime',
			  `begin_time` datetime NOT NULL  COMMENT '@desc begin_time',
			  `end_time` datetime NOT NULL  COMMENT '@desc end_time',
			  `job_type` tinyint NOT NULL COMMENT '@desc 1', 
			  PRIMARY KEY (`id`)
			) ENGINE=InnoDB DEFAULT CHARSET=utf8;
			ALTER TABLE `statistics_log` MODIFY COLUMN `task_time` bigint(20) NOT NULL GO
			测试数据：
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(1,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',3);
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(2,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',1);
	* 提供开启程序，退出程序脚本 ，通过命令操作即可 。可参考tomcatd的脚本
		手工停止任务执行。（或强制停止并处理强制停止任务的恢复逻辑），假如某次job有200条记录在推送了150条时，程序关闭了
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day15 Thursday, April 05, 2012

1. 逻辑实现
计量会议
linux环境：
	10.250.8.214 chengs 123456
shell 下java程序控制：
	  -----
	  ...
		#! /bin/sh

		#启动方法
		start(){

			java -Xms128m -Xmx2048m -jar test1.jar 5 > log.log &
			java -Xms128m -Xmx2048m -jar test2.jar 5 > log.log &
			tail -f result.log
		}
		#停止方法
		stop(){
			ps -ef|grep test|awk '{print $2}'|while read pid
			do
			   kill -9 $pid
			done
		}

		case "$1" in
		start)
		  start
		  ;;
		stop)
		  stop
		  ;;
		restart)
		  stop
		  start
		  ;;
		*)
		  printf 'Usage: %s {start|stop|restart}\n' "$prog"
		  exit 1
		  ;;
		esac

		...
		CLASS_PATH=dayemail.jar
		CLASS_PATH=$CLASS_PATH:lib/activation.jar
		CLASS_PATH=$CLASS_PATH:lib/classes12.jar
		CLASS_PATH=$CLASS_PATH:lib/c3p0-0.9.1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/commons-email-1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/dom4j-1.6.jar
		CLASS_PATH=$CLASS_PATH:lib/jaxen-1.1.1.jar
		CLASS_PATH=$CLASS_PATH:lib/jxl.jar
		CLASS_PATH=$CLASS_PATH:lib/log4j-1.2.16.jar
		CLASS_PATH=$CLASS_PATH:lib/mail.jar

		SERVER=/qzpt/mydayemail
		cd $SERVER   
		  
		case "$1" in   
		  
		  start)   
		    nohup java -Dfile.encoding=UTF8 -Xms64M -Xmx256M -cp $CLASS_PATH com.trendsnet.myemail.EmailShell > $SERVER/server.log 2>&1 &   
		    echo $! > $SERVER/server.pid   
		    ;;   
		  
		  stop)   
		    kill `cat $SERVER/server.pid`   
		    rm -rf $SERVER/server.pid   
		    ;;   
		  
		  restart)   
		    $0 stop   
		    sleep 1   
		    $0 start   
		    ;;   
		  
		  *)   
		    echo "Usage: myshell.sh {start|stop|restart}"  
		    ;;   
		  
		esac   
		  
		exit 0  
	...
	-----
	来自：http://www.iteye.com/topic/1122093
	* 在程序中中增加一个hook,jvm退出时会执行hook中的代码 
	Runtime.getRuntime().addShutdownHook(Thread); 
	kill -15 （SIGTERM）能够执行hook中代码 
	kill -9   (SIGKILL) 不能够执行hook中代码 
	在程序关闭前做处理工作，然后关闭。
	* 启动的时候将shell脚本的PID记录到文件里面，然后关闭的时候就可以直接读文件获取PID，避免用ps查询了，有可能不准确的 
	echo $! > $SERVER/server.pid

2. mvn test package etc 配置好资源文件 如 -tip-
	<resource>
	<directory>src/main/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>

	<resource>
	<directory>src/test/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.wiki</include>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>
	上面，加载包括main和test下的所有配置文件(部分子目录下的文件)。
mvn test生成的报告会说明失败原因，依据错误解决问题。
maven test failure —— 错误报告会告知哪里导致错误，一步步检查 cause 即可。另，test等都是依据pom的配置执行的，pom的配置要细心。
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day16 Friday, April 06, 2012

1. test 抽象类(实现方法，测视类中静态内部类继承) ，私有方法（反射）

	

2. Cron expressions  ,quartz
	-----
	...
		Method method = aceCalcJob.getClass().getDeclaredMethod("buildAceCalcStruct", Date.class,Date.class);
			method.setAccessible(true);
			Object result = method.invoke(aceCalcJob,startDate,endDate );
			@SuppressWarnings("unchecked")
			Map<String,IMetaData> map = (Map<String,IMetaData>)result;
	...
	-----
3. acecalc
	* 任务第一次执行时，采集时间点的确定，根据app的创建日期为起点开始采集？
		自动查询数据库得出 or 配置文件配置初始抽取时间点 or 两者都支持
	* 

4. MS 改为 OMS 参看其文档
	开放计量服务(OMS)的数据模型包括以下几个概念:
		 Object
		 Domain
		 Accessid
		 Accesskey
	上面观念划分，体现了OMS的REST服务方式。
	
	推送数据格式：
		* Date 目前Date只支持GMT格式，具体的GMT格式可参考如下示例:
			Wed, 30 Aug 1991 09:13:05 GMT
			更多关于GMT时间格式的信息，请参考RFC|1123
		* 
		
5. 
cpu

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day17 Monday, April 09, 2012

1. 新OMS提交修改

2. 访问次数 pv 所在表
	nginx_app_abstract_running_info 
	nginx_app_running_info
3. 推送测试环境 ？ OMS测试环境提供推送测试
	测试推送逻辑
demo http://svn.simba.taobao.com/svn/Apsara/openapi/trunk/java/src/com/aliyun/openservices/oms/

	uri：http://10.230.201.85:8080/ACE_RAW
	accessid: rot1d0cc9bxp97vpcwjyo98o
	accesskey: 0GC/ahEtRiNReKA1NhuNimJ2b3A

	* 推送格式改为xml
	* 请求头变化
	
	加好各种header后，进行签名，带上content 发送请求。

	
	临时文件名，取名时需要考虑2个或2个以上操作发生在同一秒内的情况。

	403 签名错误 ，
	400 非法参数 InvalidParameterValue <Message>unsuported content-type</Message>
	* put内容的字段变化了 原来的uid，改为3个分开：
		eg:
			#foreach ($data.value in $datasMap.entrySet())
			   <Object><uid>default</uid><pid>ace</pid><bid>aliyun</bid><inst_id>$data.value.appId</inst_id><time>$data.value.startTime</time><cpu_acc_usage>$data.value.cpuAccUsage</cpu_acc_usage><memcache_size>$data.value.memcacheSize</memcache_size><req_count>$data.value.reqCount</req_count><lb_id>$!data.value.lbId</lb_id><version>$data.value.version</version><end_time>$data.value.endTime</end_time></Object>
			#end
	 * OMS client的get方法，查询测试用。
		查询OMS
	main test 输出：
		{response=<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authenticate user</Message>
		<RequestID>41e3d2b9-31d0-2c4f-493b-e4635bff819b</RequestID>
		</Error>
		, status=403}

4. mem_size 暂取为某个计量时间段内的平均值 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day18 Tuesday, April 10, 2012

1. 
	* oms get测试 - pass
	* 一次put多个object测试
	* 启动，关闭脚本修改 
	* 计量值多数据测试，统计的sql是否存在问题，大数据计算精度问题
	* 某些job中app并没有产生任何数据是否应该抛弃，不推送到OMS上，导致的问题是，在某个时间点或者区间查询时导致没有数据。？
	* quartz 挂起api ，正常停止任务，不建议job执行时强制关闭进程（程序逻辑需要处理这种例外）
	* 运行jar的配置文件独立到jar外面便于配置 
		通过spring配置加载外部配置文件。
			spring配置文件也配置在外部(不在classpath上)，spring提供了org.springframework.context.support.ClassPathXmlApplicationContext 以加载classpath之外的配置文件。外部配置文件 -tip-
		log4j提供的配置文件设置类 org.apache.log4j.xml.DOMConfigurator ，可以设置定时检查配置文件修改并重新加载配置。在main函数里初始化如下：
			String log4jfile = System.getProperty("user.dir") +File.separator +"config"+ File.separator +"log4j.xml";
			DOMConfigurator.configure(log4jfile);
		配置文件改为：
			spring和properties文件都移到jar外面，ibatis配置文件还是在jar包中。
			问题是，maven如何打包时，把config文件夹拷贝一份和包在同目录下？ assembly ？
			改为：
				配置文件只把关键的 log4j,job,jdbc 等放在jar外面加载，其他进jar包。
			shell 脚本需要在bin目录下运行，否则有配置文件找不到等错误 -tip- ，如何优化shell脚本
	* 拿到真实环境的相关数据库表机构，是否与本机一致？比如statistics_log表
	

2.  oms get测试

	已push成功的待查询测试数据：
		<?xml version="1.0" encoding="UTF-8"?>
		<Objects>   
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id></lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>
	get查询请求参数：
		"GET /ACE_RAW HTTP/1.1[\r][\n]"
		"Authorization: OMS rot1d0cc9bxp97vpcwjyo98o:yqb7kFIP3prg8z0x4gw5T4lnXEw=[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:30 GMT[\r][\n]"
		"x-oms-filter: time=1334019600[\r][\n]"
		"x-oms-select: uid;pid;bid;inst_id;time;cpu_acc_usage;memcache_size;req_count;lb_id;version;end_time[\r][\n]"
		"User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]"
		"Host: 10.230.201.85:8080[\r][\n]"
		"[\r][\n]"

	返回成功信息：
		"HTTP/1.1 200 OK[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:31 GMT[\r][\n]"
		"Server: Apache/2.2.17 (Unix)[\r][\n]"
		"Content-Length: 322[\r][\n]"
		"Content-Type: text/xml;charset=UTF-8[\r][\n]"
		"[\r][\n]"
		"<?xml version="1.0" encoding="UTF-8" ?>
		<Objects>
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id>0</lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>"

	注：上面put的数据与get返回的数据 lb_id由空变为了0，这是OMS对某些字段如果空会置默认值的逻辑。

	uid+time
	uid+pid+bid+inst_id+time
	目前就这两个你有权限查
	
	domain没有操作权限：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authorize user</Message>
		<RequestID>7a44a74b-211a-fda1-68b6-7f5907108b41</RequestID>
		</Error>	
	查询条件错误：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>InvalidQueryExpressison</Code>
		<Message>query condition not match any dimension</Message>
		<RequestID>66a00276-6ad9-d94f-1bf7-db7f0c4830ba</RequestID>
		</Error>	
3. 部署  程序运行目录定义说明（配置简单操作为好）
		bin - 放运行脚本
		build - 放编译脚本(svn下载，maven构建，部署到设定的目录(到bin,lib,config))
		config - 存放配置文件(log4j,job等的配置文件)
		lib - jar文件
		logs - 日志

		操作从调用build下的脚本开始执行。
		build下放置build好的文件，如何deploy脚本将build好的文件分别部署到相应的目录中去。
		bin下的启动脚本需要在bin当前目录下运行，否则报配置文件找不到？

4. sh -x xx.sh 查看
	脚本可能因为隐藏字符导致错误，执行时 -x 查看即可。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day19 Wednesday, April 11, 2012

1. 
	执行过程中断处理
	那些数据时不用推送的，比如某个时间段都没有产生数据（这压缩数据交给oms？）


2. shell 执行路径问题  shell 必须在当前路径执行，否则路径错误 ，解决？【 spring加载资源文件路径 ，类路径，外部路径 配置路径 路径设置 改变工作目录 当前路径】
	关键：cd 命令，设置当前路径 
	#!/root/bash
	echo `pwd`
	current_dir=$(cd "$(dirname "${0}")";pwd)
	echo $current_dir
	
	pwd会因为执行路径不同而变化，current_dir可以取到shell所在路径。 

	但对于没有动态调用 user.dir 找到classpath之外资源路径的情况，可以在非shell所在目录执行时，在shell里cd到所在base目录，这样
	后续java加载取值时，取得就是cd后的路径。-tip-

	shell执行时，指定java系统参数 user.dir 即可 ，即指定java执行时用户当前目录为程序所在主目录（base目录，其子目录有lib，bin等等）。-tip-
	通过java命令的 -D 参数指定 user.dir ,结合程序逻辑，指定资源文件等的路径path。
		String log4jFile = System.getProperty("user.dir") + File.separator + "config"+ File.separator +"log4j.xml";
		-----
		...
			#!/bin/bash
			BIN_DIR=$(cd "$(dirname "${0}")";pwd)
			BASE_DIR=`dirname $BIN_DIR`
			LIB_DIR=$BASE_DIR/lib
			LOG_DIR=$BASE_DIR/logs
			#set for java to load resource
			USER_DIR=$BASE_DIR
			JAR_NAME=houyi-measuredata-all-0.0.1.jar
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    start)
				cd $BASE_DIR # 转到程序需要的工作路径，比如需要此路径来加载资源文件，spring里从外部文件加载的资源文件相对此$BASE_DIR取路径即可。
				java -Xms64M -Xmx256M -Duser.dir=$USER_DIR -jar $LIB_DIR/$JAR_NAME > $BIN_DIR/server.log 2>&1 &
				echo $! > $BIN_DIR/server.pid
				;;
			    stop)
				kill `cat $BIN_DIR/server.pid`
				rm -rf $BIN_DIR/server.pid
				;;
			    *)
				echo  "invalid option ,usage: $0 [insert|remove]";
				;;
			esac

			exit 0
		...
		-----
		通过 -Duser.dir=xxx 设置user.dir参数好

		执行路径，相对路径 ，程序默认读当前路径，执行路径时，在shell可以 cd 到所需要的当前路径(工作路径)，再执行即可。
		
3. svn 提交 eclipse ，还是用svn客户端 
	eg: TortoiseSVN   
		check for modification - revert  
	可以用客户端管理版本，eclipse只负责项目开发。 不同svn客户端交叉用可能出错误。
	svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk 
	username
	password
4. 从svn下载到maven编译到部署运行 ，整个的脚本
	svn取到项目源码
	mvn 构建
		不同机子上构建时依赖可能出现的问题：
			Error transferring file: Connection refused
			Specified destination directory cannot be created: /usr/ali/maven/repository/org/slf4j/slf4j-api/1.5.6 - maven库没有添加jar权限，改为已有的版本绕过
				eg: ls /usr/ali/maven/repository/org/slf4j/slf4j-api


5. 部署说明文档 (测试，部署人员依据此文档操作)
	* 从10.250.8.214机子上拷贝目录measure(/home/admin/measure)到目标机/home/admin目录下，进入该目录 (编译机和运行机都采用上面的目录结构)
	* 执行bulid 目录中的build.sh构建
	* 然后执行build目录下的deploy.sh部署
	* 再执行bin目录下的execute.sh启动和关闭程序，用法如下：
		execute.sh start - 启动程序
		execute.sh stop - 关闭程序
	目录结构说明：
		measure
			- bin 包含执行程序的脚本 execute.sh ，shell执行日志文件server.log,程序的的pid备份server.pid
			- build 包含构建和部署脚本build.sh,deploy.sh
			- config 包含程序配置文件log4j，job，jdbc的属性配置
			- logs 程序执行日志
			- src 存放源码
				- target 打包后的文件(zip)

6. maven换其他环境编译时，依赖找不到解决，看错误日志找到依赖找不到的原因，一般即可解决

7.  shell 脚本  ,字符不认识问题 ，在windows下的文本，通过ssh工具拷贝到linux中后，不能正常执行命令。可能是字符编码或者异常特殊符号(;/r)等问题，可在linux下
新建shell解决，拷贝的一般都有问题。

或者，是因为使用的ssh客户端没设置好，传输时编码问题？从svn下载下来的shell(原在windows下创建)都不能正常执行。 -tip-

原因：unix，dos 字符间需要转换 
	xxx@xxx$ uni
		unicode_start  unicode_stop   uniq           unix2dos       unix_chkpwd
	dos2unix

8. 
unix2dos dos2unix

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
day20 Thursday, April 12, 2012

1.  
	sql独立，将各自的查询sql独立查询，程序里再组合，编写涉及到表的pojo和映射文件
	dao db wiki 测试
		'file://D:\workspace\measure/target/dbfit/com\aliyun\houyi\measuredata\dao\impl\MemacheAppRunningInfoDaoImplTest.testReadAceCalInfocByTimePeriod.when.html'

2. 
	ls -R 
	shell判断文件是否存在，再做后续操作
		if [ -f urfile ]  then
			./a.sh   
		fi

3. sql独立
	对于数据量可预知且不大的情况下，可以进行关联查询，减少访问数据库次数。对于数据量非常大的表最好单独查询，计量减少关联查询。 -tip-

4. 单元测试，补上db部分的测试，验证sql逻辑等 -tip-
	mvn test -Dtest=AppDaoImplTest 只测试某个用例
5. 
duplicate entry key 
	确认那些字段是唯一的，一条若有多个唯一的，保证都唯一，否则数据库报错可能误报，比如有key3和key8都是unique，此时即使key3是唯一的，但key8
	是重复的，执行后可能会误报key3重复，实际上是key8重复。-tip-

6. vip 表字段修改，测试时注意
	 alter table vip add lb_id varchar(20) default NULL;
	 alter table vip MODIFY COLUMN lb_id varchar(20) default NULL;

7. mysql ,ibatis
	mysql的各种数字统计函数对应的类型不同
		需要定义好。在sql语句里转换好类型。
8. maven test 时报错误，找不到某个类，是因为测试环境和开发环境冲突了，比如在开发环境用了测试的jar，会导致错误，部署时，除去测试的依赖。 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day21 Friday, April 13, 2012

1. 
	*  job 的丢失处理时间和临时文件保留时间改为配
	* ace计量中agent的角色
		计量数据由agent上报，同app同类型数据可能有多个agent上报，统计时，需要注意这点。比如求平均时需要先求时间段内每个agent各自
		数据的平均值，再对平均值求和。
	* JCE OpenAPI
		svn改了新分支，下载新的cloudengine分支
			http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v5/master

2. job 的丢失处理时间
	和临时文件保留时间改为配
	丢失文件查找费时间

3. jce openapi  
	目标：
		标准openapi请求转接到rest服务处理。
	具体：
		根据一个请求路径，比如 /open，将所有对openapi的请求转到openapi调用service来处理，在这个service里，得到openapi的请求参数
	，根据参数调用master提供的service进行处理并返回。其中对参数的验证等可参考rest路径请求进来的处理过程。
			
	RestOpenService.java  供 openapi 调用的service
	目前文档里稳定的接口是 3.1->3.9

4. sql ，app_id,agent_id 一个app_id对应每个agent_id平均值的和,一次分组求平均，一次分组求和，多次分组统计即可 -tip-
	-------
	...
		select
		    app_id,
		    sum(tempmem.memcache_size) as memcache_size
		from (
		    SELECT  
			memcache_agent_id,
			app_id,
			ifnull(avg(mem_bytes),0) as memcache_size 
		    FROM memcache_app_running_info
		    group by memcache_agent_id
		    ) tempmem
		group by tempmem.app_id
	...
	-------
	前提 memcache_agent_id 与 app_id 为一对一或多对一的关系。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day22 Monday, April 16, 2012

1. 
	* 根据mast提供的service和jce openapi ,设计一个供openapi调用，处理普通get,put方式的rest服务。
		目标：此服务通过master提供的接口，实现jce openapi提供的接口服务(比如创建app,删除app等等)
			请求的验证，master在提供的service调用里已有处理，故此服务只根据请求的action定位到service，传递参数。
		
	* wiki 添加ace计量sql语句供review
		- app_id查询时应该不带状态，如果只取已部署的app，可能导致部分app运行数据丢失
		- memcache 计算sql语句错误，app_id和memcache上报agentId是多对多关系。
			
	* ace的部署方式，加上先从svn下载默认目录结构(包含build部署，执行脚本)，然后执行build进行build,然后deploy，最后execute
		这样，部署ace计量程序步骤如下：
			a. 在有写权限的临时路径下执行
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/deploy-env			
			b. 进入上面checkout下来的目录(deploy-env)，找到measure目录，将其拷贝到/home/admin/measure目录下(若没有此目录则新建，若重名就另外取目录名亦可)
				cd deploy-env
				cp -r measure /home/admin/measure
			c. 进入 /home/admin/measure 目录
				cd /home/admin/measure
			d 执行构建脚本
				sh build/build.sh
			e 执行部署脚本
				sh build/deploy.sh
			f 执行启动服务脚本
				sh bin/execute.sh

2. master的rest对openapi，
提供一个rest service接受所有openapi请求，内部通过一个方法接受所有请求并解析后调用对应action，service处理。

jce的openapi调用文档 —— 据此文档解析请求，调用jce master提供的service


3. ots
	http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000

4.maven debug
	mvn -Dmaven.surefire.debug test
	在ide，比如eclipse上配置远程debug(remote java application)，通过socket来debug。
	通过所使用的maven测试插件自带说明来配置debug，文档最清楚 -tip-

	运行上面maven命令后，再到eclipse配置debug run 为remote java application等配置，执行debug即可进入远程debug模式。
5. jce openapi
	根据请求的action的不同，分发到各自的function去处理，如何去分发？
		通过反射？
			定义acton与方法的的对应关系,比如以属性文件方式配置
			根据action通过反射调用service的方法
		还是自定义注解解析请求uri的方式？
			参考Spring MVC ，提供了完全基于注解的配置
				参考：http://www.cnblogs.com/sunwei2012/archive/2010/05/11/1732518.htm
					http://www.infoq.com/cn/articles/cf-java-annotationl
	* jce日志接口调用
		query_app_log这个接口的type类型，应用的日志是在ols(open log service)服务 里获取的
		
6. 自定义 annotation 实现元数据配置 ，自定义注解
	* 定义action注解
		actionName - 请求的action名称
		parms - 对应action所需要的参数(这里每个action参数不一致，引出下面的问题)
			需要rest提供一种方式，可以取到比较原始的请求消息，可以进行自定义再处理，而不是在rest方法里定义好
		需要取那个参数。？
	* 通过注解，由于每个jec open api的请求参数不同，所有需要根据rest规范，得到请求的所有参数，
	参考了sum的RESTfulWeb Services Developer'sGuide(p26)，可以通过context注解来注入请求上下文内容，
	从而获得所有请求参数。再匹配到对应的action取到各自的参数，调用service执行逻辑。-tip-
		----
		...
			Form parameters (indicated by decorating the parameter with javax.ws.rs.FormParam)
			extract information from a request representation that is of the MIME media type
			application/x-www-form-urlencoded and conforms to the encoding specified by HTML
			forms, as described here. This parameter is very useful for extracting information that is
			POSTed by HTML forms. The following example extracts the form parameter named "name"
			from the POSTed form data.
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(@FormParam("name") String name) {
			// Store the message
			}
			If it is necessary to obtain a general map of parameter names to values, use code such as that
			shown in the following example , for query and path parameters.
			@GET
			public String get(@Context UriInfo ui) {
			MultivaluedMap<String, String> queryParams = ui.getQueryParameters();
			MultivaluedMap<String, String> pathParams = ui.getPathParameters();
			}
			Or code such as the following for header and cookie parameters:
			@GET
			public String get(@Context HttpHeaders hh) {
			MultivaluedMap<String, String> headerParams = hh.getRequestHeaders();
			Map<String, Cookie> pathParams = hh.getCookies();
			}
			In general @Context can be used to obtain contextual Java types related to the request or
			response.
			For form parameters it is possible to do the following:
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(MultivaluedMap<String, String> formParams) {
			// Store the message
			}
		...
		-----
		先看了注解源码说明，再依据文档。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day23 Tuesday, April 17, 2012

1. 
	* 通过 rest  的规范中的 @context 注解来取得请求参数，传递给其他函数处理
		action映射在启动时初始化好。
	* jce openapi
	接口文档里面提到的一些param 字符串需要你这边把输入参数转换为json。
		转换的内容在 com.aliyun.cloudengine.model.opeanapi 下，里面以Param结尾的类定义
		siteId是之前跟王永生约定好的，调用方的标识ID
	- com.aliyun.cloudengine.service.openapi.OpenApiFacadeService(定义在spring-base-service.xml中) 处理openapi请求
		需要将请求参数转换为json格式传递
	- 日志查询需要用到ols ？待
		集合jce openapi文档参考ols文档
		关于ACE OpenAPI的日志查询接口说明
			1、操作接口是query_app_log，日志类型是manipulateLog和appRunningLog 
			2、以上两种类型的日志需要通过OTS获取，其他类型的通过调用master接口获取
			3、测试环境调用地址：curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'
			4、具体的调用可参见《开放日志服务接口文档.docx》

2. maven添加jar到本地库
	mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
	from:http://blog.sina.com.cn/s/blog_4b81125f0100ifnm.html
3. maven jar包重复问题，可通过
	mvn dependency:tree 查看依赖关系。
	配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
	对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
	只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。

	若还是冲突，修改scope为provided，或者通过exclusions来处理。
4. 关于ace计量pv
	nginx_app_abstract_running_info 中的pv包含静态和动态之和； nginx_app_running_info 中的pv只为静态请求次数

5. http状态表示 ，状态常量定义 
	import org.apache.commons.httpclient.HttpStatus;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day24 Wednesday, April 18, 2012

1. 
	* jce open api
		- jce接口中的site_id就是jce请求的site_user_id ?site_id不是用户调用jce open apisite_user_id这个site_id表示阿里云，万网或是其他的id标识，可以
		   到app表取到(注意：目前取app表的user_id作为site_id,后续会废弃user_id改为app表的site_id的值)这个site_id在到openapi处理时已经附加在用户请求中了
		   参考 产品线接入Open API规范说明_v0.2
		- 由于线上cloudengine的库表结构和最新开发的库表结构可能不一致，从trunk上拿线上版本的表，再测试下 ？
			包括相关的mapping文件pojo等
		- ace计量bid定为26842，测试时用的aliyun
		- 测试oms时，可以到ace_calc_struct.xml把生成数据替换为测试数据测试
		- jce sevice接口调用参数改为传递对象方式，原为json
	* ace计量
		- 对于没有任何app的情况，跳过不处理。

2. firefox 能正确显示json格式，ie8却不能处理 ？
	即content-type = application/json时ie8不认识，不会处理。
	查看ie8支持的媒体类型：

3. 通过注解anotation配置映射信息 ,取代配置文件实现元数据配置。
	------
	...
		@Retention(RetentionPolicy.RUNTIME)
		@Target(ElementType.METHOD)
		public @interface OpenAction {
			
			String actinName();
			String[] paramNames();
			
		}	
	...
	------
4. mysql 
	不同版本统计函数返回的数据类型也是不一致的，

5. jce openapi 日志
	日志类型,manipulateLog、accessLog、jettyRunningLog、appRunningLog
		其中，manipulateLog和appRunningLog类型日志从OLS服务获取，accessLog、jettyRunningLog调用master接口获取。

	OLS测试地址：
		curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'	
		服务位置：http://ols.aliyun-inc.com
6. 测试时从类相同路径加载资源文件
	this.getClass().getResourceAsStream("JobServiceImplTest.testPushRequest.xml");
	加载资源的方法有多种，下面摘自网络小节：
			------
				Java中getResourceAsStream的用法
				首先，Java中的getResourceAsStream有以下几种： 
				1). Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从
				ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。 
				2). Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由
				ClassLoader获取资源。 
				3). ServletContext. getResourceAsStream(String path)：默认从WebAPP根目录下取资源，Tomcat下path是否以’/'开头无所谓，
				当然这和具体的容器实现有关。 
				4). Jsp下的application内置对象就是上面的ServletContext的一种实现。 
				其次，getResourceAsStream 用法大致有以下几种： 
				第一： 要加载的文件和.class文件在同一目录下，例如：com.x.y 下有类me.class ,同时有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("myfile.xml"); 
				第二：在me.class目录的子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.y.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("file/myfile.xml"); 
				第三：不在me.class目录下，也不在子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				总结一下，可能只是两种写法 
				第一：前面有 “   / ” 
				“ / ”代表了工程的根目录，例如工程名叫做myproject，“ / ”代表了myproject 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				第二：前面没有 “   / ” 
				代表当前类的目录 
				me.class.getResourceAsStream("myfile.xml"); 
				me.class.getResourceAsStream("file/myfile.xml"); 
			------

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day25 Thursday, April 19, 2012

1. 
	* jce open api
		- ols日志部分
			a. 根据jce openapi文档日志查询部分需求，设计接口及实现
			b. 使用master内处理http发送接收请求的代码与日志服务交互
				http交互公用代码
		其余action实现
2. 关于rest的response问题 -tip-
	* 在简单的测试项目中一个pojo service在暴露rest服务并做处理返回时，这个返回对象需要是rest规范定义的response的
	子类，这样rest框架处理时就能正确响应给请求者。
	* 还有一种方式，就是这个rest service继承某个类，或实现接口，其暴露的rest服务方法只返回pojo对象，处理响应交给依赖的
	类去处理
	fire: REST方法的返回对象必须是REST接口定义的Response类的子类。上面的说明还是和所使用的rest框架相关的，下面的 RESTEasy 框架
	rest服务返回的就是直接的pojo对象，框架自身回去处理把pojo构造为标准的http response返回。
3. RESTEasy  框架实现REST服务
	RESTEasy
		RESTEasy is a JBoss project that provides various frameworks to help you build RESTful Web Services and RESTful Java applications. 
	It is a fully certified and portable implementation of the JAX-RS specification. JAX-RS is a new JCP specification that provides a Java API for RESTful Web Services over the HTTP protocol.
		RESTEasy can run in any Servlet container, but tighter integration with the JBoss Application Server is also available to make the user experience nicer in that environment. 
	While JAX-RS is only a server-side specification, RESTEasy has innovated to bring JAX-RS to the client through the RESTEasy JAX-RS Client Framework. This client-side framework allows you to map outgoing HTTP requests to remote servers using JAX-RS annotations and interface proxies.

	from:http://www.jboss.org/resteasy/

	搭建 RESTEasy 测试project。
4. String.valueOf() 注意null值

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day26 Friday, April 20, 2012

1. 
	* 测试jce openapi
		- 由于运行环境不易构建，通过 mock 方式测试用例，mock出需要的条件。
			mock测试目的：测试目标类的功能时，模拟其依赖对象，关键在于测试目标类。
		- openapi把用户请求转发给jce open api前会去校验action是否存在
		- 停止APP的参数不统一？jce open api文档有的参数pojo中没有
	* 参照jce open api对比所有参数正确性 ？ 

2. jtester 可以利用其提供的反射工具类进行特殊方法(如私有方法)的测试
	JTesterReflector 通过反射执行调用测试
	提供集成测试支持(如数据库等)
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day27 Monday, April 23, 2012

1. 
	*jce openapi 
		- post请求 rest 取得post参数集合	
			结合openapi的post请求规范提供服务
		- 日志部分接口定义说明 ，返回码，格式
		- 功能增加，实现
			update OpenApiFacadeService ，svn diff with previous version ，得到新增接口方法，实现对应逻辑及单元测试。


2. rest post请求参数 , get post parameters restful -tip-
	jersey文档说明如下：
		In general @Context can be used to obtain contextual Java types related to the request or response. For form parameters it is possible to do the following:

		Example 2.19. Obtaining general map of form parameters

		@POST
		@Consumes("application/x-www-form-urlencoded")
		 public void post(MultivaluedMap<String, String> formParams) {
		     // Store the message
		 }
	参数集合，自动封装Injection 自动注入 。
		get请求通过uriinfo封装
		post请求直接通过MultivaluedMap封装

3.for test
#for test case 
slb.api.server=1
slb.api.serviceSecretKey=2
slb.api.session=3
slb.api.regionNo=4
ftp.url=1
ftp.address=2
ftp.port=3
dns.server=4

4.  调用过程
	请求处理
	资源分配
	rpc(mina)
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
		It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
	结果处理
5. quartz 属性配置文件配置跳过更新检查
	或者通过java命令的 -D参数设置
		-Dorg.terracotta.quartz.skipUpdateCheck=true
6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day28 Tuesday, April 24, 2012

1. 
	* jce openapi 内部联调
		- 测试环境openapi接入前准备
			mysql -utest -ptest
			openapi 
				配置接入参数到 服务表 和 action表
			测试地址：http://10.230.129.182:8088/open?
			jce 测试环境wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8651094
		- master的属性配置到 /src/main/conf/cemaster_env.properties 中，test下的属性只供测试调用
		- rest暴露的服务uri定位 /open 
		- wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=6094915
		- site_id master的接口实现已经做了参数验证，桥接层不需要处理，提供统一的异常提示。
			转接层不做业务相关的处理,让了解业务的逻辑去处理验证是否符合要求。模块责任清晰
			参考 struts2的自动参数注入逻辑，不匹配的置为null
	* 着手 SLB API V2 时间点 4.30
2. 测试环境 mysql
	10.250.8.214
	mysql -utest -ptest
	open api服务接入配置：
	use openapi
		service_provider
			insert into service_provider values(7,'ace','http://10.230.129.182:8088/open?','1.0','ace',now(),now());
		api
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('create_app',60,'create_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_name',60,'check_app_name',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_domain',60,'check_app_domain',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_web_container_quota',60,'set_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('reverse_proxy_quota',60,'reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_memcache_quota',60,'set_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_start_args',60,'set_app_start_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_stop_args',60,'set_app_stop_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('start_app',60,'start_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('stop_app',60,'stop_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('build_app',60,'build_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_build_job',60,'query_build_job',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app',60,'query_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_app',60,'delete_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app_topolgy',60,'query_app_topolgy',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_os_monitor',60,'query_os_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_reverse_proxy_quota',60,'query_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_web_container_quota',60,'query_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_quota',60,'query_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_info',60,'query_memcache_info',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_jvm_monitor',60,'query_jvm_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_reverse_proxy_configuration',60,'set_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('test_reverse_proxy_configuration',60,'test_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('get_reverse_proxy_configuration',60,'get_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_reverse_proxy_configuration',60,'delete_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_net_io',60,'query_net_io',1,1,7,now(),now());

3. 产品线接入openapi ，诸如验证，访问控制，负载，api是否开放等等由openapi负责 ，产品线关心业务。 -tip-

4. jce openapi 测试
	测试每一个action ，测试结果以与rest接口暴露的action的返回结果一致为准。
		create_app
			domain_name 格式要求 xxxxxx.aliapp.com ，xx位置格式要求为4-18个字符
		url=http://10.230.129.78:8088/open?oauth_nonce=28587223711112&start_args=test_start_args&oauth_version=1.0&oauth_consumer_key=TestVMFhd506uBsO&app_name=testAppName1088&site_user_id=1088&oauth_signature=sZUqPtyuaPXlsRx1NVnboV0tIaw%3D%0D%0A&oauth_signature_method=HMAC-SHA1&action=create_app&app_language=2&stop_args=test_stop_args&user_id=1&domain_name=ace2012.aliapp.com&git_url=test.git.url&oauth_timestamp=1335258526
		{"data":{"appId":3},"code":200,"msg":"success"}			
	* yaml 格式配置消息 -tip-
		准备此格式配置内容
	* 

5.  SLB API V2
	* 目标
		- 接收用户请求
		- 根据请求消息，构造请求体，调用后端slb，得到结果
			需要根据request信息，查询db得到调用slb后端接口的必要参数
				region_id所属的HOUYI region id
		- 将结果状态处理下 比如 -100 转换为-2100，返回给用户
		- 实现slb后端提供的接口调用(定义的action操作)
	* check out 代码
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 阅读相关文档
	* 查看源码
		框架构成：struts2 + spring + ibatis 
			- bean交给spring管理，struts配置文件引用其名称；action定义于spring配置中 ，通过ApplicationContext的getBeansOfType(Class type)获得所有action的名称实例map
			- 请求映射通过统一的proxyaction接受，并根据请求的action，通过反射执行对应action的接口方法，得到返回结果。
			   其中的action名到对应action实例的映射关系实现通过ExecuteActionFactory初始化，这里的设计，每个action名对应一个
			    action处理类，启动时以bean names as keys and the corresponding bean instances as values初始化到map中。
			- 需要用的参数，拦截器处理好放到threadlocal实现的RequestContextHolder对象中，提供了静态方法，供service调用slb后端
			   时调用

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day29 Wednesday, April 25, 2012

1. 
	* slb api v2
		- 根据上面分析，现在的任务是：
			a. 实现slb后端文档提供的操作Action类，并配置到spring配置中
			b. LoadBalancerService 加入新的功能定义，并实现
				
		- 涉及到vm的信息(比如向lb_id中加vm时) ，需要到后羿vm处去查询  ，数据库 houyi
			配置文件：slbapi.properties 
				ec.api.url=http://10.230.204.65/open/services?
		- 一些交互细节，demo等可参考v1版本的代码(houyi-console下)
			svn 地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/trunk
			如 /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/LBControlServiceImpl.java 参考其与slb后端交互逻辑。
		- slb后端的请求url从region表中获得。
		- post请求：
			注意请求内容以multipart的方式构造请求体，这样服务端接收时才能正确解析。
		- 返回码搞清楚
			对于slb后端返回的状态码，如果为负数则减去2000作为返回状态码
			如果slb api前端报错，则根据前端文档返回对应状态及msg

		- 任何异常(Exception)都指定到错误的result上去。
2. 
openapi接入的服务
mysql> select * from service_provider;
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
| sp_id | sp_name  | url                                 | version | description | gmt_create          | gmt_modify          |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
|     1 | ecs      | http://10.230.204.65/open/services? | 1.0     | ecs         | 2011-12-31 17:13:55 | 2011-12-31 17:13:55 |
|     2 | slb      | http://10.230.204.65/open/services? | 1.0     | slb         | 2012-01-10 10:21:07 | 2012-01-10 10:21:07 |
|     3 | ecs_test | http://127.0.0.1:8888/?             | 1.0     | ecs test    | 2012-01-18 17:31:33 | 2012-01-18 17:31:33 |
|     4 | boss     | http://10.230.128.5:8080/           | 1.0     | boss        | 2012-04-20 15:20:26 | 2012-04-20 15:20:26 |
|     5 | rds      | http://127.0.0.1:8888/?             | 1.0     | rds         | 2012-04-20 15:20:39 | 2012-04-20 15:20:39 |
|     6 | git      | http://ceqa-gitserver1:4567/api     | 1.0     | git         | 2012-04-23 16:42:49 | 2012-04-23 16:42:49 |
|     7 | ace      | http://10.230.129.182:8088/open?    | 1.0     | ace         | 2012-04-24 10:20:47 | 2012-04-24 10:20:47 |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
ecs - vm openapi

3. slb v2 
	测试url：http://localhost:8080/slb/api.do?action=create_loadbalancer
		 <?xml version="1.0" encoding="utf-8" ?> 
		 <rsp>
		  <code>-50</code> 
		  <msg>illegal user</msg> 
		  </rsp>


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day30 Thursday, April 26, 2012

1. 
	* slb api v2 
		* 走通一个action
			http://localhost:8080/slb/api?action=create_loadbalancer&user_id=1&session=xxx

2. maven web 项目debug ，maven tomcat debug
	修改tomcat启动脚本,远程调试：
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%  
3. 请求slb后端方式的修改
	slb后端服务是REST方式，在请求时需要满足其格式要求。
		比如除了get方式外，其他请求方式post，put，delete请求方式，都需要把请求体也放到URI中，目前采用的是 Matrix URIs  方式：
			Matrix URIs 
			Matrix spaces and Semicolons 
			It is maybe obvious to note that there are many, many hierarchical systems. An interesting analogy with a hierarchical power is, in a programming language, a sequence of parameters supplied to a command or a procedure. For example, in some languages a procedure may take positional parameters which may be optional so that any parameters from a certain point on may be omitted. This syntax can be compared with a hierarchical slash separated URL path. This is an interesting analogy because looking at the alternative representation for procedure parameters which consists of a list of procedure name and value pairs. This leads us naturally to a discussion of the use of the semi-colon in URLs and the matrix syntax. Just as the slash separated set of elements is useful for representing a tree, so a set of names and equally significant parameter can represent a space more like a (possible sparse) matrix. In this case navigation to "close" locations is done by varying one or more parameters which form the dimensions of the matrix. This is the purpose of the a=b; parts of URL syntax which was added later in the URL's history. The initial need was to put qualifiers onto URLs which were themselves hierarchical. 

			The analogy with procedure call holds still when looking at combined forms: The hierarchical part of the URL is paused first, and then the semi-colon separated qualifiers are paused as indicating positions in some matrix. As an example let's imagine the URL of an automatically generated map in which the parameters for latitude, longitude and scale are given separately. Each may be named, and each if omitted may take a default. So, for example,

				 //moremaps.com/map/color;lat=50;long=20;scale=32000

			might be the URL of an automatically generated map. 
			摘自：http://www.w3.org/DesignIssues/MatrixURIs.html
	根据上面：
			请求SLB后端时，get请求直接根据uri格式要求请求；对于有content内容(注意区别与普通post请求是放到请求体重)的请求，
		需要以Matrix URIs的方式，把请求内容放到uri中，再去请求。-tip-
	
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day31 Friday, April 27, 2012

1. 
	* SLB API v2
		- 根据slb对外api文档，将请求结果处理后依据slb后端调用文档调用，并返回结果
2. 测试
	* 创建LoadBalancer：		
		客户端请求：http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
		slb后端请求：http://10.230.130.129:8088/lbs/lbname1;lb_type=compact;region_id=region-test;eip_type=internet;user_id=1
			结果：{response={"data":{"lb_id":"25-region-test","eip":"42.120.64.227"},"code":200,"msg":"successful"}, status=200}
			struts的自定义result处理结果时报错。
				处理结果返回类型的 UserActionResult 在 response.getWriter().write(resultFormat.value(result)); 处转换对象为json或者xml时报错？
	* 查询LoadBalancer信息：
		http://10.230.130.129:8088/lbs/123/
		user_id如何传递？
	* 查询loadbalancer列表 http://10.230.130.129:8088/lbs;user_id=1
		结果：{"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","26-region-test","27-region-test","28-region-test","29-region-test","30-region-test","31-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test"]},"code":200,"msg":"successful"}



3. 
SLB API 错误码：
		2000 - 2100 -平台错误
		>2100 业务错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day32 Saturday, April 28, 2012

1. 
	* 根据slb后端文档，实现调用接口，对比前端用户api文档，修改接口实现中需要参数转换的逻辑。
	* 拿到rest服务的源码校对url请求 ？
		- 看rest服务代码，测试请求来的精确
			eg：查询lb:http://10.230.130.129:8088/lbs/43-region-test;user_id=1 这里需要将user_id传递过去，因为slb后端是根据lb_id和user_id都匹配来查询lb的
	* slb api v2 平台错误提示需要细化，比如：
		http://localhost:8080/slb/api?action=query_loadbalancer&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":-2003,"msg":"system exception"}
		http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":200,"data":{"lb_id":"43-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.215","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		第一个请求的错误，具体原因是action的名称不对，可以细化错误提示，便于调试和理解。

		错误，异常提醒细化 

2. 
	测试记录：
		创建LB: 
			compact http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"53-region-test","eip":"42.120.64.204"},"msg":"successful"}
			hybrid http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=hybrid&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"60-region-test","eip":"42.120.64.238"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname2&lb_type=hybrid&eip_type=internet&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","eip":"42.120.64.226"},"msg":"successful"}
		查询LB: http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.227","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		删除LB: http://localhost:8080/slb/api?action=delete_loadbalancer&region_no=region-test&lb_id=31-region-test&&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置LB: http://localhost:8080/slb/api?action=config_loadbalancer&region_no=region-test&lb_id=25-region-test&status=active&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询LB列表：http://localhost:8080/slb/api?action=list_loadbalancers&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test","40-region-test","41-region-test","42-region-test","43-region-test","44-region-test"]},"msg":"successful"}
		
		创建VIP: 
			compact: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A80%2C%22backend_port%22%3A82%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22persistence_timeout%22%3A1000%2C%22check%22%3A{%22type%22%3A%22vtcp%22}}}%2C{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A83%2C%22status%22%3A%22inactive%22%2C%22backend_port%22%3A81%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22forwardfor%22%3A%22on%22%2C%22keepalive%22%3A%22on%22}}]&lb_id=59-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}
			hy: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=62-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}		
				http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=23-region-test&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
		删除VIP: http://localhost:8080/slb/api?action=delete_vip&region_no=region-test&lb_id=25-region-test&frontend_port_list=[80,90]&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置VIP: http://localhost:8080/slb/api?action=config_vip&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询VIP: http://localhost:8080/slb/api?action=query_vip_info&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"protocol":"tcp","port":80,"status":"stopped","config":{"scheduler":"rr","check":{"type":"vtcp"},"persistence_timeout":1000}},"msg":"successful"}
		查询VIP的健康状态: http://localhost:8080/slb/api?action=query_vip_healthcheck&frontend_port=80&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"rs_list":[]},"msg":"successful"}

		添加VM: http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22vm1%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=22-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"22-region-test","vm_list":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		查询VM信息: http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"weight":100,"vm_name":"vm1"}]},"msg":"successful"}
			注：ip与vm名称是一对一，如果为一对多则会出错。依据业务为准
		删除VM: http://localhost:8080/slb/api?action=delete_vm&vm_list=[%22vm1%22]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		切换VM: http://localhost:8080/slb/api?action=switch_vm&old_vm=[%22vm1%22]&new_vm=[{%22vm_name%22:%22vm2%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
			注：与文档说明返回不一致？
		查询VM信息: http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"53-region-test","vm_list":[]},"msg":"successful"}
		
		// hybrid
		添加Rule: http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=59-region-test&session=accessid1&sign=xx
			{"code":-2402,"msg":"RuleNotSupport"} //compact lb 不能添加rule
			http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=60-region-test&session=accessid1&sign=xx
			hybrid:http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool2%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","rule_id":"1-region-test"},{"name":"rule2","rule_id":"2-region-test"}]},"msg":"successful"}
		配置Rule: http://localhost:8080/slb/api?action=config_rule&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}
		查询Rule: http://localhost:8080/slb/api?action=query_rule_info&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","domain":"www.xxx.com","rs_pool_name":"rspool2","rule_id":"1-region-test","scheduler":"wrr","private_header":{"key2":"value2","key1":"value1"}},{"name":"rule2","domain":"www.abc.com","rs_pool_name":"rspool2","rule_id":"2-region-test","scheduler":"wrr"}]},"msg":"successful"}
		删除Rule: http://localhost:8080/slb/api?action=delete_rule&rule_name_list=[%22rule1%22]&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}

		// compact
		添加rs pool: http://localhost:8080/slb/api?action=create_rs_pool&name=rspool1&protocol=http&port=80&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"name":"rspool1","protocol":"http","port":80},"msg":"successful"}
			http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool2&protocol=http&port=80&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"name":"rspool2","protocol":"http","port":80},"msg":"successful"}
		查询RS POOL列表: http://localhost:8080/slb/api?action=list_rs_pool&vm_name=vm2&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":-2502,"msg":"RealServerParseError"}
			http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=60-region-test&region_no=region-test&session=cao.yin&sign=xx
			{"code":-2502,"msg":"RealServerParseError"} //SLB 后端bug，待修改
		添加rs 到 rs pool: http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool1&rs_list=[{%22vm_name%22:%22vm2%22}]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool2&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		从rs pool 删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool1&rs_list=[%22vm-tes1%22,%22vm-test2%22]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
		删除rs pool:http://localhost:8080/slb/api?action=delete_rs_pool&rs_pool_name=rspool2&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":-2505,"msg":"RspoolRuleExist"} //前提 删除rs pool配置的rule
		删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool2&rs_list=[%22ceqa-ag-0419160429%22]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		切换rs: http://localhost:8080/slb/api?action=switch_rs&rs_pool_name=rspool2&old_rs=[%22ceqa-ag-0419160429%22]&new_rs=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day33 Wednesday, May 02, 2012

1. 
	* SLB API action测试
		- vm 与 ip的转换，slbapi库的rs表ip与vm是一对一还是一对多？ select * from rs; ，一对一
	* 


2.系统错误提醒设计细化
	错误码提示易定位，人性化
	从总体设计异常提示。

3. 懂业务测试效率更高，特别对于具有依赖关系逻辑的测试。
	slb api测试中，不少用例的测试都是具有依赖关系的，需要前提条件满足才能继续下一个用例的测试
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day34 Thursday, May 03, 2012

1. 
	* slb api需要和vm api交互的地方，参看 云服务器api说明4.0版本
		比如用户调用slb api传递的是vm的名称，slb api层需要将name转换为ip传给slb后端，slb后端返回的数据中将vm的ip消息转换为vm的名称。
			vm api的测试账户？key ，id
			vm_name = DotProject-4661  / ceqa-ag-0419160429
				cao.yin
				cao.yin
				ec.api.url=http://10.230.204.65/open/services?
	* 上面替换的需求，需要定义查找的key名称，可以统一到常量中，避免硬编码 ？
	* jce open api 修改action时也同时需要到open api表去修改action的名称，哪里会先处理action的正确性。
	* 在 add rs vm,delete rs vm,switch rs vm 时本地rs表的数据是否正确变化也需要测试通过？
	* 一些依赖导致的错误，比如add_rs时需要先add_vm这样在rs表里会有ip与name的对应数据，否则报错，此时应该细化这个错误提示，不都是 sysytemerror ，客户端或者
	开发者自己也不便于debug
	* rs ,vm 删除时都要去删除rs表的记录，也要查询是否有冲突？
2. slb api需要做vm ip和vm name转换的地方，对比slb后端api与slb api
	add_vm //done
	delete_vm //done
	switch_vm //done
	query_vm_info //done
	query_vip_healthcheck //done
	add_rs //done
	delete_rs //done
	switch_rs //done
	query_rs_pool_info  (list_rs_pool) //done
	delete_rs_pool //done

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day35 Friday, May 04, 2012

1. 
	* 配置slb api日志，调用日志，业务日志分开
		api调用日志记录调用前后时间，按照设计的日志格式输出。可以在拦截器中记录调用日志
	* 
2. 


