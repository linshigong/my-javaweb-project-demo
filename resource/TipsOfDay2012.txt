
本机ip 10.1.171.132

通过svn管理记录文件 eg google code  TortoiseSVN
搭建centos测试系统(vmware7) ssh连接
wiki scheng 
Linux Container - LXC	
openapi rds  (关系型数据库服务)
	ref: http://www.ibm.com/developerworks/linux/library/l-lxc-containers/
test
	https://my-javaweb-project-demo.googlecode.com/svn
google 检索 apache： site:*.apache.org 高级搜索
	site:cnblogs.com 工厂
* 性能调优
	log系统调优，如log4j
		log4j.appender.monitorAppender.BufferedIO=true
		log4j.appender.monitorAppender.BufferSize=8192
		这 个选项用于告诉log4j输出日志的时候采用缓冲的方式，而不是即时flush方式，并且设定了缓冲为8K，8K是默认值，可以根据日志输出的情况来修 改。
		这个选项很重要，在测试中发现，当并发访问很高，例如每一秒100个并发以上，使用缓存跟不使用缓冲差距很大。具体数字我这里就不列出来了。
		另外我想说的是，log4j输出缓冲日志是以8K为单位的，因为磁盘的一个block为8K，这样可以减少碎片，也就是说假设你设置缓存为18K，log4j在
		16K（8K*2)的时候就会输出），而不是18K。
		ref: http://www.blogjava.net/conans/articles/345083.html



* 学习的载体 -tip-
	如tomcat源码：NIO，Servlet3.0，comet,classloader，服务器编程，JMX and etc.
* 编码
	ref: http://baike.corp.taobao.com/index.php/编码规范最佳实践
		
* Comet技术
	适用场景：
		适合事件驱动的 Web 应用，以及对交互性和实时性要求很强的应用，如股票交易行情分析、聊天室和 Web 版在线游戏等。
	起源：
		AJAX应用中存在一个致命的缺陷无法满足传统桌面系统的需求。那就是“服务器发起的消息传递(Server-Initiated Message Delivery)”。
		B/S架构中由于HTTP的无状态，只能通过轮询(Polling)技术不断刷新页面来获得最新的数据(见图18-5)。这种方式不但浪费服务器的资源，最重要的是每次建立(或关闭)新的HTTP连接
		都有一定的延迟，这种延迟使得频繁信息传递的应用无法忍受。于是就产生了“服务器推送技术”。
	实现：
		下面将介绍两种 Comet 应用的实现模型。
		1）基于 AJAX 的长轮询（long-polling）方式	
		2）基于 Iframe 及 htmlfile 的流（streaming）方式

* 取模 模运算
	取模运算即模运算，模运算即求余运算。“模”是“Mod”的音译，模运算多应用于程序编写中。 Mod的含义为求余。模运算在数论和程序设计中
	都有着广泛的应用，从奇偶数的判别到素数的判别，
	ref: http://baike.baidu.com/view/4887065.htm
* 位运算 << 左移运算 >> 右移运算
	ref：http://www.cnblogs.com/highriver/archive/2011/08/15/2139600.html

	
* java hashcode equal方法
	java中hashcode方法的引入，是为了集合数据结构而出现，比如Map结构，用来计算哈希值并作为键以提高性能
	下面是JDK包中HashMap类的put方法部分：
	------

	------
	
* 发布
	在AG执行
* java 集合数据结构的适用场景
	----
		1) ArrayList

	　　基于数组方式实现，无容量的限制。

	　　在执行插入元素时可能要扩容，在删除元素时并不会减少数组的容量。

	　　如果希望相应的缩小数组容量，可以调用trimToSize()

	　　在查找元素时要遍历数组，对于非null的元素采取equals的方式寻找。

	　　非线程安全。

	　　2) LinkedList

	　　基于双向链表机制实现。

	　　元素的插入、移动较快。

	　　非线程安全。

	　　3) Vector

	　　基于Object数组的方式来实现的。

	　　基于synchronized实现的线程安全的ArrayList。

	　　在插入元素时容量扩充的机制和ArrayList稍有不同：

	　　如果capcacityIncrement > 0, 则Object数组的大小扩大为现有size加上capcacityIncrement；

	　　如果capcacityIncrement < 0, 则Object数组的大小扩大为现有size的两倍；

	　　4) Stack

	　　基于Vector实现，支持LIFO。

	　　5) HashSet

	　　基于HashMap实现，无容量限制。

	　　不允许元素重复。

	　　非线程安全。

	　　6) TreeSet

	　　基于TreeMap实现，支持排序。

	　　非线程安全。

	　　7) HashMap

	　　采用数组方式存储key、value构成的Entry对象，无容量限制。

	　　基于key hash寻找Entry对象存放到数组的位置，对于hash冲突采用链表的方式来解决。

	　　在插入元素时可能会扩大数组的容量，在扩大容量时会重新计算hash，并复制对象到新的数组中。

	　　非线程安全。

	　　8) TreeMap

	　　基于红黑树实现，无容量限制。

	　　非线程安全。

	　　-----------------------------------

	　　适用场景：

	　　对于查找和删除较为频繁，且元素数量较多的应用，Set或Map是更好的选择；

	　　ArrayList适用于通过为位置来读取元素的场景；

	　　LinkedList 适用于要头尾操作或插入指定位置的场景；

	　　Vector 适用于要线程安全的ArrayList的场景；

	　　Stack 适用于线程安全的LIFO场景；

	　　HashSet 适用于对排序没有要求的非重复元素的存放；

	　　TreeSet 适用于要排序的非重复元素的存放；

	　　HashMap 适用于大部分key-value的存取场景；

	　　TreeMap 适用于需排序存放的key-value场景。
	----
* 项目管理工具
	项目构建
		maven
		ant
	版本控制
		svn
	bugfree
		缺陷跟踪系统
	wiki系统
		mediawiki
		页面自身的连接地址修改在移动标签功能中。
		删除重定向页这个对象，即可删除重定向到的页面
	项目管理
		redmine
	
* nginx
		nginx不单可以作为强大的web服务器，也可以作为一个反向代理服务器，而且nginx还可以按照调度规则实现动态、静态页面的分离，可以按照轮询、ip哈希、
	URL哈希、权重等多种方式对后端服务器做负载均衡，同时还支持后端服务器的健康检查。

	如果只有一台服务器时,这个服务器挂了,那么对于网站来说是个灾难.因此，这时候的负载均衡就会大显身手了,它会自动剔除挂掉的服务器.

	下面简单的介绍下我使用Nginx做负载的体会

	下载---安装Nginx这些不介绍了,前篇有介绍.

	windows和Linux下配置Nginx负载的写法一样,故不分开介绍.

	Nginx负载均衡一些基础知识:

	nginx 的 upstream目前支持 4 种方式的分配 
	1)、轮询（默认） 
		每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 
	2)、weight 
		指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 
	2)、ip_hash 
		每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。  
	3)、fair（第三方） 
		按后端服务器的响应时间来分配请求，响应时间短的优先分配。  
	4)、url_hash（第三方）

	配置nginx实现负载均衡
	以下面nginx.conf为例
		--------
		Xml代码  
		#user  nobody;  
		worker_processes  1;  
		  
		error_log  logs/error.log;  
		  
		events {  
		    worker_connections  1024;  
		}  
		  
		  
		http {  
		    include       mime.types;  
		    default_type  application/octet-stream;  
		  
		    sendfile        on;  
		    keepalive_timeout  65;  
		  
		    #gzip  on;  
		    upstream  www.docyeah.com   {  
			      server   192.168.1.11:8080;  
			      server   192.168.1.101:8080;  
		    }  
		    server {  
			listen       80;  
			server_name  www.docyeah.com;  
			charset utf-8;  
			location / {  
			    root   html;  
			    index  index.html index.htm;  
			    proxy_pass        http://www.docyeah.com;  
			    proxy_set_header  X-Real-IP  $remote_addr;  
			    client_max_body_size  100m;  
			}  
		  
		  
			location ~ ^/(WEB-INF)/ {   
			deny all;   
			}   
		  
			error_page   500 502 503 504  /50x.html;  
			location = /50x.html {  
			    root   html;  
			}  
		  
		    }  
		}  
		--------

* RSS
		RSS是在互联网上被广泛采用的内容包装和投递协议。网络用户可以在客户端借助于支持RSS的新闻工具软件，在不打开网站内容页面的情况下，
	阅读支持RSS输出的网站内容。
	1) RSS文件结构
		示例：
	<?xml version="1.0" encoding="gb2312" ?> 
	<rss version="2.0">　
	<channel> 
	　　<title>我的Blog</title>                 //channel的标题
	　　<description>与我自己的技术Blog相关联</description>   //channel的介绍
	　　<link>http://counter.csdn.net/pv.aspx?id=72</link>     //channel的url
	　　<item> 
	　　<title><!-- 项标题 --></title>           //item的标题
	　　<link><!-- 项 URL --></link>           //item的url
	　　<description><!-- 简要描述 --></description>        //item的介绍
	　　<!-- 可选的/可扩展的元素 -->        //item的其他属性，比如更新时间
	　　</item> 
	　　<item>
	　　<!-- 可多个<item>项目-->           //一个channel有多个item
	　　</item>
	</channel>
	</rss>
		RSS是两级结构，第一级结构是channel，相当于blog系统中某人的blog，第二级结构是item，相当于blog中的文章。属性中最重要的是title、description和link，
	title是标题，description是介绍，link是与其相关的url。 

	2) RSS的使用
		有的网站提供了RSS自动发现机制，可以很方便地把RSS的URL添加到RSS阅读器中。如果没有自动发现，那么可以手动把RSS链接的URL添加到RSS阅读器中，
	这样就加入了一个用户订阅的频道。在RSS阅读器中可以更新频道列表或点击一个item链接打开该item的页面。 

	3) RSS的工作机制
			内容提供者在其网站上添加RSS的链接，以提供RSS订阅功能，当打开这个链接时，传送过去了一些频道信息，比如：blog的作者名。
			一种做法是，RSS链接URL指向的是一个空内容的页面，该页面后台程序通过传过来的频道信息访问数据库，获取频道列表，用Response.Write向该空页面
		写出XML格式的文件。
			另一种做法是，RSS链接URL指向的是一个xml文件，该文件由服务器的程序事先生成好的，放在服务器上，访问时静态获取，服务器在作者每添加一个频道列表
		时自动更新该xml文件。
			第一种做法的优点是管理方便，因为不需要为每个频道生成xml文件，所有的RSS请求都由一个后台页面处理，接口统一，但每次访问RSS链接时，都要动态地
		写出RSS频道列表，访问效率相对较低，第二种做法的优点是访问时，只是返回一个静态的xml文件，不需要访问数据库来临时生成，所以访问效率相对较高，但
		每更新一次频道列表中的项时，就要自动地重新生成xml文件以保证RSS文件的最新，这样就降低了更新的效率。本系统中采用的是第一种方法。 

	4) RSS的实现
	RSS有两大部件：RSS链接和RSS阅读器

* google reader
	rss订阅
		将outlook的rss源或google reader中的rss源导出为OPML文件，这样其他rss工具就可直接导入
* 泛型
	泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类。可以把类型参数看作是使用
	参数化类型时指定的类型的一个占位符，就像方法的形式参数是运行时传递的值的占位符一样。

	可以在集合框架（Collection framework）中看到泛型的动机。例如，Map 类允许您向一个 Map 添加任意类的对象，即使最常见的情况是在给定映射
	（map）中保存某个特定类型（比如 String）的对象。

	因为 Map.get() 被定义为返回 Object，所以一般必须将 Map.get() 的结果强制类型转换为期望的类型，如下面的代码所示：

	Map m = new HashMap();
	m.put("key", "blarg");
	String s = (String) m.get("key");

	要让程序通过编译，必须将 get() 的结果强制类型转换为 String，并且希望结果真的是一个 String。但是有可能某人已经在该映射中保存了不是 String 的东西，
	这样的话，上面的代码将会抛出 ClassCastException。

	理想情况下，您可能会得出这样一个观点，即 m 是一个 Map，它将 String 键映射到 String 值。这可以让您消除代码中的强制类型转换，同时获得一个附加的
	类型检查层，该检查层可以防止有人将错误类型的键或值保存在集合中。这就是泛型所做的工作。
	from: http://www.cnblogs.com/panjun-Donet/archive/2008/09/27/1300609.html

* ICMP协议
	简介
		ICMP是（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。
	控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递
	起着重要的作用。
		ICMP协议是一种面向连接的协议，用于传输出错报告控制信息。它是一个非常重要的协议，它对于网络安全具有极其重要的意义。
		它是TCP/IP协议族的一个子协议,属于网络层协议,主要用于在主机与路由器之间传递控制信息,包括报告错误、交换受限控制和状态信息等。当
	遇到IP数据无法访问目标、IP路由器无法按当前的传输速率转发数据包等情况时，会自动发送ICMP消息。

	ICMP原理
		ICMP提供一致易懂的出错报告信息。发送的出错报文返回到发送原数据的设备，因为只有发送设备才是出错报文的逻辑接受者。发送设备随后
	可根据ICMP报文确定发生错误的类型，并确定如何才能更好地重发失败的数据包。但是ICMP唯一的功能是报告问题而不是纠正错误，纠正错误的任务由发送
	方完成。
		我们在网络中经常会使用到ICMP协议，比如我们经常使用的用于检查网络通不通的Ping命令（Linux和Windows中均有），这个“Ping”的过程实际上就是
	ICMP协议工作的过程。还有其他的网络命令如跟踪路由的Tracert命令也是基于ICMP协议的。
	from: http://baike.baidu.com/view/30564.htm
	
	死亡之Ping
		在IP协议规范中规定了一个IP包的最大尺寸，而大多数的包处理程序又假设包的长度超过这个最大尺寸这种情况是不会出现的。因此，包的重组代码
	所分配的内存区域也最大不超过这个最大尺寸。这样，超大的包一旦出现，包当中的额外数据就会被写入其他正常区域。这很容易导致系统进入非稳定状态，
	是一种典型的缓存溢出（Buffer Overflow）攻击。在防火墙一级对这种攻击进行检测是相当难的，因为每个分片包看起来都很正常。
		由于使用ping工具很容易完成这种攻击，以至于它也成了这种攻击的首选武器，这也是这种攻击名字的由来。当然，还有很多程序都可以做到这一点，
	因此仅仅阻塞ping的使用并不能完全解决这个漏洞。预防死亡之ping的最好方法是对操作系统打补丁，使内核将不再对超过规定长度的包进行重组。
* ARP
	- 在之前的一篇文章，TCP/IP链路层协议中说到，在以太网链路传输中，必需是以48比特位的网络接口硬件地址建立连接的，而我们应用程序之间的通信
	是以32比特位的IP地址建立连接的，这就需要我们把32比特的IP地址映射到48比特的硬件地址（MAC地址）。ARP（address resolution protocol）,RARP(
	reverse address resolution protocol),就是针对这一功能定义的协议规范。

	以太网目的地址和以太网源地址分别是指6字节，48bit的硬件地址。当「以太网目的地址」为：FF：FF：FF：FF：FF：FF，即全部为1时，则表示这是个
	广播地址，所有的以太网接口都要接收这个帧数据。当发送ARP请求数据帧时，因为是要请求查找指定的IP地址所映射的硬件地址，所以会广播所有的
	网络上的主机，则此时的目的以太网地址就是：FF：FF：FF：FF：FF：FF
* 环回接口 
	 环回接口（Loopback Interface）
	 大家都熟知「127.0.10.1」或者「localhost」，也知道它们主要是同一台主机上两个应用进行TCP/IP通信的IP地址或主机名。这就是「环回接口」的相关概念。
	NOTE：
	1) 一个传给环回接口的IP数据报不能出现在任何网络上
	2) 传给广播地址或多播地址的数据报复制一分给环回接口，然后才送到以太网上。这是因为广播和多播传送本身就包括主机本身
	3) 任何传给该主机IP地址的数据均送到环回接口
	from:		http://www.cnblogs.com/jcli/archive/2013/01/27/2874091.html

* new 
	http://www.aliway.com/read.php?fid=73&tid=188016
	做一个名医的病人，相关的事可以咨询

* IP IP转换 IP地址 IP段 IP Segment
	- IP概述 http://www.cnblogs.com/jcli/archive/2013/02/03/2880671.html
	- 所谓IP地址就是给每个连接在Internet上的主机分配的一个32bit地址。按照TCP/IP协议规定，IP地址用二进制来表示，每个IP地址长32bit，比特换算成字节，
	就是4个字节。例如一个采用二进制形式的IP地址是“00001010000000000000000000000001”，这么长的地址，人们处理起来也太费劲了。为了方便人们的使用，
	IP地址经常被写成十进制的形式，中间使用符号“.”分开不同的字节。于是，上面的IP地址可以表示为“10.0.0.1”。IP地址的这种表示法叫做“点分十进制表示法”，
	这显然比1和0容易记忆得
	from: http://zhidao.baidu.com/question/282553232.html
	PS: 也可转换为16进制、长整型等

	C0-A8-0A-11  是IPArr转换为string类型时的输出结果，也是192 168 10 17 的16进制285911232 是IPArr转换为整数的结果,C0是最低位，也就是说该整数是由 
	11-0A-A8-C0转换成10进制的来的
	
	- IP转换为long的例子：
		------
		IPV4 {
					public Long ip2Long(String strIP) {
						long[] ip = new long[4];
						int position1 = strIP.indexOf(".");
						int position2 = strIP.indexOf(".", position1 + 1);
						int position3 = strIP.indexOf(".", position2 + 1);
						ip[0] = Long.parseLong(strIP.substring(0, position1));
						ip[1] = Long.parseLong(strIP
								.substring(position1 + 1, position2));
						ip[2] = Long.parseLong(strIP
								.substring(position2 + 1, position3));
						ip[3] = Long.parseLong(strIP.substring(position3 + 1));
						Long ip2Long = (ip[0] << 24) + (ip[1] << 16) + (ip[2] << 8)
								+ ip[3];
						return ip2Long;
					}
		------
		每个IP用二进制表示，长度为32bit，

* virtual host
	- 介绍
		The term Virtual Host refers to the practice of running more than one web site (such as company1.example.com and company2.example.com) on a single machine. 
		Virtual hosts can be "IP-based", meaning that you have a different IP address for every web site, or "name-based", meaning that you have multiple names running on each IP address. 
		The fact that they are running on the same physical server is not apparent to the end user.
	- apache支持virtual host：
		Apache was one of the first servers to support IP-based virtual hosts right out of the box. Versions 1.1 and later of Apache support both IP-based and name-based virtual 
		hosts (vhosts). The latter variant of virtual hosts is sometimes also called host-based or non-IP virtual hosts.
		
* rewrite技术 伪静态技术	URL rewrite技术	 URL重写
	- URL rewrite
		URL 重写是截取传入 Web 请求并自动将请求重定向到其他 URL 的过程 
			将http://www.new.com/work/index.php?action=list&para1=test&para2=test2
			转换为：
			http://work.new.com/list/para1/test/para2/test2
	参考：http://www.itlearner.com/code/apache2.2/rewrite/rewrite_guide.html  初级URL重写指南
		http://www.baidu.com/link?url=jCVVGJqjJ4zBBpC8yDF8xDhgsCi-AJZjCGkIr62EKcS52ktxVCl-tMokRHKqpDjN4om
	静态技术，便于搜索引擎收录页面。
	。。。
	
* apache apache2
	- virtual host配置
		httpd.conf
		--------
			Listen 80

			<VirtualHost *:80> 
			#   General setup for the virtual host
			DefaultType text/xml

			DocumentRoot "/home/admin/houyi_directory_backup/houyi/service/"

			ErrorLog /home/admin/houyi_directory_backup/houyi/service/logs/openapi/error_log

			<Directory />
			    Options FollowSymLinks
			#    Options None
			    AllowOverride None
			    Order allow,deny
			    Allow from all
			</Directory>

			<Directory "/home/admin/houyi_directory_backup/houyi/service/">
			    Options FollowSymLinks
			#    Options None
			    AllowOverride None
			    Order allow,deny
			    Allow from all
			</Directory>

			<FilesMatch "^\.ht">
			    Order allow,deny
			    Deny from all
			</FilesMatch>
			AccessFileName .htaccess
			</VirtualHost>
		--------
		建议单独配置virtual host到httpd-vhost.conf中。

	- apache作为反向代理后端为jetty配置
		参考：http://blog.csdn.net/zhuying_linux/article/details/6600071   Apache +Jetty的负载均衡与集群配置（上）

		例子：
		原来apache与jboss通过ajp协议，现在nginx与jetty通过http or what others?	   在httpd.conf中配置 apache+jetty 负载均衡			
			1) 暂且直接配置为http方式通讯：
				<IfModule proxy_module>
					ProxyPass /open http://127.0.0.1:8080/open #静态文件的请求不需要转发，由apache直接返回，需要配置DocumentRoot 为程序目录(为防止冲突，建议配虚拟机)
				</IfModule> 
			2) 若需要，也可以配置为ajp方式通讯，主要配置如下：
				加载需要的模块：
					LoadModule proxy_module modules/mod_proxy.so
					LoadModule proxy_ajp_module modules/mod_proxy_ajp.so
					LoadModule proxy_balancer_module modules/mod_proxy_balancer.so
				配置httpd.conf：
					<IfModule proxy_ajp_module>
						ProxyPass open ajp://127.0.0.1:8190/open
						#ProxyPassReverse /open ajp://127.0.0.1:8080/open/api #rewrite if need
					</IfModule>
				确保backend的ajp端口与上面配置的一致（8190）。
	- proxy_ajp_module 模块
		apache的httpd.conf文件配置module信息，proxy_ajp_module模块用于ajp协议的通讯，需要mod_proxy模块，即proxy_ajp_module模块是一个
		AJP support module for mod_proxy。
		摘自官网的usage：
		-------
			Usage

			This module is used to reverse proxy to a backend application server (e.g. Apache Tomcat) using the AJP13 protocol. The usage is similar to an HTTP reverse proxy, 
			but uses the ajp:// prefix:

			#Simple Reverse Proxy
			ProxyPass /app ajp://backend.example.com:8009/app		 //简单配置
			Balancers may also be used:

			#Balancer Reverse Proxy
			<Proxy balancer://cluster>								      //根据权重负载均衡，可用性考虑？	    mok_jk?
				BalancerMember ajp://app1.example.com:8009 loadfactor=1
				BalancerMember ajp://app2.example.com:8009 loadfactor=2
				ProxySet lbmethod=bytraffic
			</Proxy>
			ProxyPass /app balancer://cluster/app

			Note that usually no ProxyPassReverse directive is necessary. The AJP request includes the original host header given to the proxy, and the application server can be 
			expected to generate self-referential headers relative to this host, so no rewriting is necessary.	  //ProxyPassReverse配置说明，只有当proxy接收的url与后端的不一致时才需要配置此项，否则不建议

			The main exception is when the URL path on the proxy differs from that on the backend. In this case, a redirect header can be rewritten relative to the original host URL (
			not the backend ajp:// URL), for example:

			Rewriting Proxied Path

			ProxyPass /apps/foo ajp://backend.example.com:8009/foo
			ProxyPassReverse /apps/foo http://www.example.com/foo
			However, it is usually better to deploy the application on the backend server at the same path as the proxy rather than to take this approach.
		-------
		详见官网的module说明：http://httpd.apache.org/docs/2.2/mod/mod_proxy_ajp.html

	
* InfoQ ArchSummit全球架构师峰会 腾讯大讲堂 PPT 
	
* 数据仓库 data warehouse
	数据分析
	数据统计 数据统计方案 数据汇总分析 数据汇总分析方案
	数据挖掘
	BI 商业智能
 
* 统计需求 月统计 天统计
	通过提前归并的方式，避免即时扫描，对于大量数据的情况尤其需要考虑
	如果是关系型数据库，大量表扫描也耗性能，需要归并，分布式RDS即DRDS？
	如果是nosql数据量大的统计也代价高，需要归并，支持水平扩展
* google code svn
	google code 提供svn服务，但页面上不便于svn操作，比如添加分支，添加目录等，可通过svn工具来操作，如 TortoiseSVN，来建立新目录等等。

* 代码合并    svn merger merger代码 * svn
	- branch上的多次修改要合并到新拉的branch上
		直接merger branch方便，用patch后续有冲突，merger时使用场景为：
			对一个branch有多个版本的修改，现在需要对这多个版本的修改合并到其他branch上
	- 基于trunk拉分支并提交修改到分支后，若中间没有并行项目，分支合并到主干时，可拉最新的trunk，将分支修改合并进来，再提交即可
	- 基于trunk拉分支并提交修改到分支后，若中间有其他项目发布且已合并到trunk，可在每次trunk修改后，将trunk修改合并到分支上，避免后面合并多个
	项目的多处修改冲突的风险。
		此方法不能避免并行项目做了大量修改导致其他分支合并到trunk时出现大量冲突的问题。需要在项目启动时考虑到这些问题。尽量避开交叉修改的项目并行
		进行。

* RX TX TX RX
	TX: transmit 传送
	RX: receive 接收 

	tx是发送（transport），rx是接收(receive)。以ros为中心。   比如你的外网网卡，wan,rx是wan接受ISP的
	传输数据， 即下载速度。wan的tx,是工作站经ros wan网卡向isp上传的速度，既上传速度。
	内网网卡lan的rx，应该是ros接受来之内网工作站的上传，既是上传速度。tx是lan网卡传给工作站的速
	度，即工作站经内网网卡下载的速度 （以ros为中心）。
	有没有分啊
	tx rx 每个版本都不一样的啊
	而且相对于外网和内网的解释又是相反的
	你就记住一般RX外网指的是下载，TX指的是上传
	而内网相反就行了
	from: http://www.ubooo.com/rou/2009/0324/111.html

* http chunk http chunked	 * chunked
	- httpclient读取chunked输出时，根据/r/n来判断chunk结束，根据读取开始位置到读到/r/n所读的长度作为chunked的长度。将协议中chunkSize作为了chunk内容的
	一部分。
	验证上面的分析：
		

	- 例子：
		https://github.com/netty/netty/tree/3.5/src/main/java/org/jboss/netty/example/http/snoop
		
		git clone https://github.com/mar200851/netty.git sign in first

	- 测试chunked输出
		通过线程的睡眠模拟大量数据按块发送和处理的过程。例子如下：
			------
			/* 1) Write by byte */
			//size of first chunk
			out.write(Integer.toHexString(trunk1.length()*2).getBytes());
			out.write(CRLF);
			//send first chunk
			out.write(trunk1.getBytes());
			out.write(trunk1.getBytes());
			out.write(CRLF);
			out.flush();
			sleep();
			//size of second chunk
			out.write(Integer.toHexString(trunk2.length()).getBytes());
			out.write(CRLF);
			//send second chunk
			out.write(trunk2.getBytes());
			out.write(CRLF);
			out.flush();
			sleep();
			//send chunked data end flag
	//		out.write(ZERO);
			out.write(ZERO);
			out.write(CRLF);
			//send CRLF
			out.write(CRLF);
			out.flush();
			------
			注意，每发送一个chunked结束去手动flush下输出流，否则可能导致等待缓存满了才输出。
	- servlet返回chunked响应例子
		------
		@Override
			protected void doGet(HttpServletRequest req, HttpServletResponse resp)
					throws ServletException, IOException {
				resp.setHeader("Pragma", "No-cache");
				resp.setHeader("Cache-Control", "no-cache");
				resp.setDateHeader("Expires", 0);
				
				resp.setHeader("Transfer-Encoding", "chunked");
				
				OutputStream out = resp.getOutputStream();//与使用write的区别，少了流转换的开销？
				String trunk1 = "chunk1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
				String trunk2 = "chunk2";
				//size of first chunk
				out.write(Integer.toHexString(trunk1.length()*2).getBytes());
				out.write(CRLF);
				//send first chunk
				out.write(trunk1.getBytes());
				out.write(trunk1.getBytes());
				out.write(CRLF);
				//size of second chunk
				out.write(Integer.toHexString(trunk2.length()).getBytes());
				out.write(CRLF);
				//send second chunk
				out.write(trunk2.getBytes());
				out.write(CRLF);
				//send chunked data end flag
				out.write(ZERO);
				out.write(CRLF);
				//send CRLF
				out.write(CRLF);
			}
		------
	- 优势
		能一边接受数据一边处理已接收的数据，如果只是一次性取到所有的再去处理，则体现不出chunked的优势

	- 对于返回内容不能立即取到大小，返回是一个过程时，每次只返回可用数据的一块（完整可解析的一个块）。
	参考：http://www.cnblogs.com/jcli/archive/2012/10/19/2730440.html

		一般http通信时会使用content_length头信息来表示服务器发送的文档内容长度，该头信息定义域http1.0协议RFC 1945 10.4章节中，浏览器接收到此头信息后
	接受完content_length中定义的产度字节后开始解析页面，但是如果服务器端有部分数据延迟发送则会出现浏览器白屏，用户体验差。
		解决方案是在http1.1协议中EFC 2616中14.41章节中定义的Transfer_encoding：chunked的头信息。chunked编码定义在3.6.1中，所有HTTP1.1都应该支持使用
	chunked编码动态的提供body内容的长度的方式。进行chunked编码传输的http数据要在消息头部设置transfer_encoding：chunked表示content body将用chunked编码
	传输内容。根据定义，浏览器不需要等到内容字节全部下载完成，只要接收到一个chunked块就可以解析页面，并可以下载html中定义的页面内容，包括js，
	css，image等
		
		采用chunked编码有两种选择一种是设定server的IO buffer长度让server自动flush buffer中的内容另一种是手动调用IO中的flush函数，不同的语言IO中都有flush功能：
		
		php：ob_flush();flush()
		perl:STDOUT->autoflush(1);
		java:out.flush()
		python:sys.stout.flush()
		ruby:stdout.flush
		
		采用http1.1的transfer_encoding：chunked并且把IO的buffer flush下来，一遍浏览器更早的下载页面配套资源，不可能在头中包含content_length域来指明报文体长度，
	此时就需要通过transfer_encoding域来确定报文体长度
	from: http://blog.csdn.net/ruby1098/article/details/6730424

	- http1.1支持
	----------
		Chunked Transfer Coding

		The chunked encoding modifies the body of a message in order to transfer it as a series of chunks, each with its own size indicator, followed by an OPTIONAL trailer 
		containing entity-header fields. This allows dynamically produced content to be transferred along with the information necessary for the recipient to verify that it has 
		received the full message.

		       Chunked-Body   = *chunk
					last-chunk
					trailer
					CRLF
		       chunk          = chunk-size [ chunk-extension ] CRLF
					chunk-data CRLF
		       chunk-size     = 1*HEX
		       last-chunk     = 1*("0") [ chunk-extension ] CRLF
		       chunk-extension= *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
		       chunk-ext-name = token
		       chunk-ext-val  = token | quoted-string
		       chunk-data     = chunk-size(OCTET)
		       trailer        = *(entity-header CRLF)
		The chunk-size field is a string of hex digits indicating the size of the chunk. The chunked encoding is ended by any chunk whose size is zero, followed by the trailer, which is terminated 
		by an empty line.

		The trailer allows the sender to include additional HTTP header fields at the end of the message. The Trailer header field can be used to indicate which header fields are included 
		in a trailer (see section 14.40).

		A server using chunked transfer-coding in a response MUST NOT use the trailer for any header fields unless at least one of the following is true:

		a)the request included a TE header field that indicates "trailers" is acceptable in the transfer-coding of the response, as described in section 14.39; or,

		b)the server is the origin server for the response, the trailer fields consist entirely of optional metadata, and the recipient could use the message (in a manner acceptable to the origin server) 
		without receiving this metadata. In other words, the origin server is willing to accept the possibility that the trailer fields might be silently discarded along the path to the client.

		This requirement prevents an interoperability failure when the message is being received by an HTTP/1.1 (or later) proxy and forwarded to an HTTP/1.0 recipient. It avoids a situation 
		where compliance with the protocol would have necessitated a possibly infinite buffer on the proxy.

		An example process for decoding a Chunked-Body is presented in appendix 19.4.6.

		All HTTP/1.1 applications MUST be able to receive and decode the "chunked" transfer-coding, and MUST ignore chunk-extension extensions they do not understand.
	----------

	下面为对chunked编码的decode方式说明：
	----------
		19.4.6 Introduction of Transfer-Encoding

		HTTP/1.1 introduces the Transfer-Encoding header field (section 14.41). Proxies/gateways MUST remove any transfer-coding prior to forwarding a message via a MIME-compliant protocol.

		A process for decoding the "chunked" transfer-coding (section 3.6) can be represented in pseudo-code as:

		       length := 0
		       read chunk-size, chunk-extension (if any) and CRLF
		       while (chunk-size > 0) {
			  read chunk-data and CRLF
			  append chunk-data to entity-body
			  length := length + chunk-size
			  read chunk-size and CRLF
		       }
		       read entity-header
		       while (entity-header not empty) {
			  append entity-header to existing header fields
			  read entity-header
		       }
		       Content-Length := length
		       Remove "chunked" from Transfer-Encoding
	----------

	from: http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html rfc2616 Hypertext Transfer Protocol -- HTTP/1.1

* IOPS (Input/Output Operations Per Second)
	即每秒进行读写（I/O）操作的次数，多用于数据库等场合，衡量随机访问的性能。存储端的IOPS性能和主机端的IO是不同的，
	IOPS是指存储每秒可接受多少次主机发出的访问，主机的一次IO需要多次访问存储才可以完成。例如，主机写入一个最小的数据块，
	也要经过“发送写入请求、写入数据、收到写入确认”等三个步骤，也就是3个存储端访问。
	from: http://baike.baidu.com/view/2302083.htm
* bps
	byte per second
* linux kernel
	http://www.makelinux.net/kernel_map/
* 服务总线 消息总线 ESB EMB
* 化整为零 -tip-
	太多太杂，晕头转向？试试化整为零
* 文档
	http://www.ishare.sina.com.cn
	http://www.slideshare.net/
* 红黑树 Red-Black tree
	TreeMap基于红黑树实现 jdk1.6
	
	A red–black tree is a type of self-balancing binary search tree, a data structure used in computer science, typically used to implement associative arrays.
	from: http://en.wikipedia.org/wiki/Red%E2%80%93black_tree	 

	相关点：
	Binary tree 二叉树
			In computer science, a binary tree is a tree data structure in which each node has at most two child nodes, usually distinguished as "left" and "right". Nodes with children are parent nodes, and child nodes may contain references to their parents. Outside the tree, there is often a reference to the "root" node (the ancestor of all nodes), if it exists. Any node in the data structure can be reached by starting at root node and repeatedly following references to either the left or right child. A tree which does not have any node other than root node is called a null tree. In a binary tree a degree of every node is maximum two. A tree with n nodes has exactly n−1 branches or degree.
		Binary trees are used to implement binary search trees and binary heaps.
		from: http://en.wikipedia.org/wiki/Binary_tree

* tair
	-
	Tair是什么
　　	Tair是一个分布式的key/value系统。

　　Tair有四种引擎：
		mdb, rdb, kdb和ldb。分别基于四种开源的key/value数据库：memcached, Redis, Kyoto Cabinet和leveldb。Tair可以让你更方便地使用这些KV数据库。比如Redis没有提供sharding操作，
		如果有多个Redis Server，你需要自己写代码实现sharding，Tair帮你封装了这些。

　　Tair有以下优点：
　　1) 统一的API。无论底层使用何种引擎，上层的API是一样的。
　　2) Tair将集群操作封装起来，解放了开发者。淘宝内部在使用Tair时，一般都是双机房双集群容错，利用invalid server保证两个集群间的一致性，这些对于开发者都是透明的。

	Tair使用场景
	1.) 非持久化(mdb,rdb)
		数据可以以key/value的形式存储
		数据可以接受丢失
		访问速度要求很高
		单个数据大小不是很大，一般在KB级别
		数据量很大，并且有较大的增长可能性
		数据更新不频繁
	2) 持久化(kdb,ldb)
		数据可以以key/value的形式存储
		数据需要持久化
		单个数据大小不是很大，一般在KB级别
		数据量很大，并且有较大的增长可能性
		数据的读写比例较高
	
	Tair的架构
	　　Tair是Master/Slave结构。Config Server管理Data Server节点、维护Data Server的状态信息；Data Server负责数据存储，按照Config Server的指示完成数据复制和迁移工作，
		并定时给Config Server发送心跳信息。Config Server是单点，采用一主一备的方式保证可靠性

	Tair的功能
	1) 动态增加或减少data server
	　　Config Server使用Hash算法将数据桶均匀分布到不同的Data Server。当某个Data Server发生故障时，Config Server会察觉这一情况，重新计算一张数据桶的分布表，并将到故障Data Server的访问转到别的DataServer上。这个过程中，有可能因为负载平衡出现数据迁移。Config Server会检查Data Server的负载，将数据迁移到负载较小的节点上。迁移过程中，Config Server会保证路由表的正确性，使得客户端能够得到数据。
	　　客户端连接Config Server时，会下载最新的路由表。如果连接某个Data Server不成功（可能宕机了），客户端会重新连接Config Server以获得最新的路由表。
	2) 数据桶分布策略
	　　数据桶的分布策略有两种：负载平衡优先和位置安全优先。负载平衡不用说。安全位置优先是指同一个桶的两个duplication要分布在不同的机房。
	3)客户端
	　　Tair Server使用C++编写，利用socket通信。原则上只要支持socket的语言都可以连接，目前只提供Java和C++客户端。
* java GC
	 Java GC 算法

	当一个对象不再被引用的时候，内存回收它占领的空间，以便空间被后来的新对象使用。除了释放没用的对象，垃圾收集也可以清除内存记录碎片。

	1、 引用计数法(Reference Counting Collector)

	    引用计数法是唯一没有使用根集的垃圾回收的法，该算法使用引用计数器来区分存活对象和不再使用的对象。一般来说，堆中的每个对象对应一个引用计数器。当每一次创建一个对象并赋给一个变量时，引用计数器置为1。当对象被赋给任意变量时，引用计数器每次加1当对象出了作用域后(该对象丢弃不再使用)，引用计数器减1，一旦引用计数器为0，对象就满足了垃圾收集的条件。
	    基于引用计数器的垃圾收集器运行较快，不会长时间中断程序执行，适宜地必须 实时运行的程序。但引用计数器增加了程序执行的开销，因为每次对象赋给新的变量，计数器加1，而每次现有对象出了作用域生，计数器减1。
	　　
	ps：用根集的方法（既有向图的方法）进行内存对象管理，可以消除循环引用的问题．就是说如果有三个对象相互引用，只要他们和根集是不可达的，gc也是可以回收他们．根集的方法精度很高，但是效率低．计数器法精度低（无法处理循环引用），但是执行效率高．

	2、tracing算法(Tracing Collector)

	    tracing算法是为了解决引用计数法的问题而提出，它使用了根集的概念。基于tracing算法的垃圾收集器从根集开始扫描，识别出哪些对象可达，哪些对象不可达，并用某种方式标记可达对象，例如对每个可达对象设置一个或多个位。在扫描识别过程中，基于tracing算法的垃圾收集也称为标记和清除 (mark-and-sweep)垃圾收集器。

	3、compacting算法(Compacting Collector)

	    为了解决堆碎片问题，基于tracing的垃圾回收吸收了Compacting算法的思想，在清除的过程中，算法将所有的对象移到堆的一端，堆的另一端就变成了一个相邻的空闲内存区，收集器会对它移动的所有对象的所有引用进行更新，使得这些引用在新的位置能识别原来 的对象。在基于Compacting 算法的收集器的实现中，一般增加句柄和句柄表。

	4、copying算法(Coping Collector)

	    该算法的提出是为了克服句柄的开销和解决堆碎片的垃圾回收。
	    将内存分为两个区域(from space和to space)。所有的对象分配内存都分配到from space。在清理非活动对象阶段，把所有标志为活动的对象，copy到to space，之后清楚from space空间。然后互换from sapce和to space的身份。既原先的from space变成to sapce，原先的to space变成from space。每次清理，重复上述过程。
	    优点：copy算法不理会非活动对象，copy数量仅仅取决为活动对象的数量。并且在copy的同时，整理了heap空间，即，to space的空间使用始终是连续的，内存使用效率得到提高。
	    缺点：划分from space和to space，内存的使用率是1／2。收集器必须复制所有的活动对象，这增加了程序等待时间。

	5、generation算法(Generational Collector)

	    来自IBM的一组统计数据：98％的java对象，在创建之后不久就变成了非活动对象；只有2％的对象，会在长时间一直处于活动状态。

	     (1)young generation

	    年轻代分三个区。一个Eden区，两个Survivor区。大部分对象在 Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor区也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制到 tenured generation。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来对象，和从前一个 Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。
	    young generation的gc称为minor gc。经过数次minor gc，依旧存活的对象，将被移出young generation，移到tenured generation

	    (2)tenured generation

	    生命周期较长的对象，归入到tenured generation。一般是经过多次minor gc，还 依旧存活的对象，将移入到tenured generation。（当然，在minor gc中如果存活的对象的超过survivor的容量，放不下的对象会直接移入到tenured generation）
	tenured generation的gc称为major gc，就是通常说的full gc。
	    采用compaction算法。由于tenured generaion区域比较大，而且通常对象生命周期都比较长，compaction需要一定时间。所以这部分的gc时间比较长。
	    minor gc可能引发full gc。当eden＋from space的空间大于tenured generation区的剩余空间时，会引发full gc。这是悲观算法，要确保eden＋from space的对象如果都存活，必须有足够的tenured generation空间存放这些对象。

	    (3)permanent generation

	    该区域比较稳定，主要用于存放classloader信息，比如类信息和method信息。
	对于spring hibernate这些需要动态类型支持的框架，这个区域需要足够的空间。(这部分空间应该存在于方法区而不是heap中)。

	6、adaptive算法(Adaptive Collector)

	    在特定的情况下，一些垃圾收集算法会优于其它算法。基于Adaptive算法的垃圾收集器就是监控当前堆的使用情况，并将选择适当算法的垃圾收集器。
	from: http://blog.csdn.net/salahg/article/details/5912101Molator's Downloads


* OS
	MLXOS
		Multitask Layered eXecution Operating System
	What is MLXOS ?
		MLXOS is a microkernel operating system, including μ-kernel, user space drivers and utilities.
	from: http://www.mlxos.org/mlxos.html

* HBase * nosql
	
* Amazon Virtual Private Cloud (Amazon VPC) 自定义网络
	允许您在 Amazon Web Services (AWS) 云中预配置一个专用、隔离的部分，让您能够在定义的虚拟网络中启动 AWS 资源。借助 Amazon VPC，
您可以定义与自己的数据中心运行的传统网络非常相似的虚拟网络拓扑。您可以完全掌控您的虚拟联网环境，包括选择自有的 IP 地址范围、创建子网，以及配置路由表和网关。
您可以轻松自定义 Amazon VPC 的网络配置。例如，您可以为可访问 Internet 的 Web 服务器创建公有子网，而将数据库或应用程序服务器等后端系统放在不能访问 Internet 的私有子网中。
您可以利用安全组和网络访问控制列表等多种安全层，帮助对各个子网中 Amazon EC2 实例的访问进行控制。
此外，您也可以在公司数据中心和 VPC 之间创建硬件虚拟专用网络 (VPN) 连接，将 AWS 云用作公司数据中心的扩展。



* linux core文件 gdb调试
	当一个程序崩溃时，在进程当前工作目录的core文件中复制了该进程的存储图像。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。
	ref: http://blog.csdn.net/fengxinze/article/details/6800175

	ulimet -a 查看系统配置

* 
* 远程调试 jar 远程调试 jar调试
	远程调试 Java 应用程序
	如果您还没安装该程序，请下载 Eclipse V3.4（Ganymede）。在 Ganymede 中，套接字（socket）监听连接器被添加到 Remote Java Application 启动配置类型。Eclipse 最新的套接字监听连接器允许您打开 Java 调试器，它能够监听特定套接字上的连接。可以从命令行选项打开被调试的程序，并将其连接到调试器。在 Ganymede 发布之前，仅有一个连接套接字的连接器，被调试的程序所在的机器必须是一个与调试器相连的调试主机。由于受到内存和 CPU 不足的限制，要想让移动设备充当主机是不现实的。
	为了进行远程调试，必须使用 Java Virtual Machine (JVM) V5.0 或更新版本，比如 IBM® J9 或 Sun Microsystem 的 Java SE Development Kit（JDK）。

	JPDA 简介
	Sun Microsystem 的 Java Platform Debugger Architecture (JPDA) 技术是一个多层架构，使您能够在各种环境中轻松调试 Java 应用程序。JPDA 由两个接口（分别是 JVM Tool Interface 和 JDI）、
	一个协议（Java Debug Wire Protocol）和两个用于合并它们的软件组件（后端和前端）组成。它的设计目的是让调试人员在任何环境中都可以进行调试。JPDA 不仅能够用于桌面系统，
	而且能够在嵌入式系统上很好地工作。
	JVM Tool Interface (JVMTI) 规定必须为调试提供 VM（编辑注：从 Java V5 开始，将用 JVMTI 代替 Java V1.4 中的 JVMDI）。Java Debug Wire Protocol (JDWP) 描述调试信息的格式，
	以及在被调试的进程和调试器前端之间传输的请求，调试器前端实现 JDI，比如 Eclipse、Borland JBuilder 等。根据 Sun 的 JPDA 规范，被调试的程序常常称为 debuggee。JDI 是一个高级的接口，
	它定义用于远程调试的信息和请求。下面给出了调试器的架构。

	常用缩写词
	JDI — Java 调试接口（Java Debug Interface）
	JDT — Java 开发工具（Java Development Tools）
	JDWP — Java 调试网络协议（Java Debug Wire Protocol）
	JPDA — Java 平台调试器架构（Java Platform Debugger Architecture）
	JVM — Java 虚拟机（Java Virtual Machine）
	JVMDI — JVM 调试接口（JVM Debug Interface）
	JVMTI — JVM 工具接口（JVM Tool Interface）
	VM — 虚拟机（Virtual Machine）

	JDWP 包含许多参数，用于为远程 Java 应用程序调用所需的程序。以下是本文用到的一些参数。
	-Xdebug
		启用调试特性。
	-Xrunjdwp:<sub-options>
		在目标 VM 中加载 JDWP 实现。它通过传输和 JDWP 协议与独立的调试器应用程序通信。下面介绍一些特定的子选项。
		从 Java V5 开始，您可以使用 -agentlib:jdwp 选项，而不是 -Xdebug 和 -Xrunjdwp。但如果连接到 V5 以前的 VM，只能选择 -Xdebug 和 -Xrunjdwp。下面简单描述 -Xrunjdwp 子选项。
	transport
		这里通常使用套接字传输。但是在 Windows 平台上也可以使用共享内存传输。
	server
		如果值为 y，目标应用程序监听将要连接的调试器应用程序。否则，它将连接到特定地址上的调试器应用程序。
	address
		这是连接的传输地址。如果服务器为 n，将尝试连接到该地址上的调试器应用程序。否则，将在这个端口监听连接。
	suspend
	如果值为 y，目标 VM 将暂停，直到调试器应用程序进行连接。
	要获得每个调试设置的详细解释，请参考 JPDA 文档（参见 参考资料）。
	清单 2 是一个示例，显示如何在调试模式下启动 VM 并监听端口 8765 的套接字连接。

	清单 2. 作为调试服务器的目标 VM
					
		-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8765

	清单 3 显示如何使用位于 8000 端口的主机 127.0.0.1 上的套接字连接运行中的调试器应用程序。

	清单 3. 作为调试客户机的目标 VM
					
		-Xdebug -Xrunjdwp:transport=dt_socket,address=127.0.0.1:8000

	from: http://www.ibm.com/developerworks/cn/opensource/os-eclipse-javadebug/
* 
	http://www.yake.org
	http://slashdot.org/story/06/04/21/213221/simple-open-source-3d-game-engines
	Vega Strike
		开源中国搜索
		http://zh.wikipedia.org/wiki/Vega_Strike
			相关链接
	http://dev.ryzom.com/projects/ryzom/wiki good have 
		http://www.cnblogs.com/xiaop/

		* ryzom
			模块化，组件化的设计。核心框架和业务无关，各自发展
			http://blog.sina.com.cn/s/articlelist_1850874464_0_4.html
		* doom3 engine开源

* java dns 缓存
	%JAVA_HOME/jre/lib/security/java.security
	dns默认缓存30s，负值表示永久缓存，修改此值可能导致下面攻击：
		DNS spoofing attack/Cache poisoning attacks DNS欺骗攻击
		from: http://en.wikipedia.org/wiki/DNS_cache_poisoning
			
* 前端
	js测试工具：testacular	https://github.com/vojtajina/testacular/wiki
* 服务器端的无阻塞编程
	找到阻塞的点
	实现
	AIO ,EPOLL,TCP

	实现复杂性与性能的兼顾考虑

* SSL
	- SSL协议详解 http://kb.cnblogs.com/page/162080/
	- SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。
		TLS与SSL在传输层对网络连接进行加密。
	
* 格式化输出
	java提供工具类方便格式化输出

* 数据结构
	时间复杂度	
		　算法复杂度分为时间复杂度和空间复杂度。其作用： 时间复杂度是度量算法执行的时间长短；而空间复杂度是度量算法所需存储空间的大小
	随机存取（相对于顺序存取）
		是随机存储结构，意思就是你想找第几个数可以用下标直接找到
		而链式存储就不行，你想找第几个数必须一个一个地数过去，所以不是随机存储
	硬盘连续读写与随机读写
		

* 网络攻击
	- DDOS

	- SYN攻击
		
* 事务 数据库事务 
	- 事务并发问题：
		1) 脏读：包含未提交数据的读取。例如，事务1 更改了某行。事务2 在事务1 提交更改之前读取已更改的行。
			如果事务1 回滚更改，则事务2 便读取了逻辑上从未存在过的行。
		2) 不可重复读取：当某个事务不止一次读取同一行，并且一个单独的事务在两次（或多次）读取之间修改该行时，
			因为在同一个事务内的多次读取之间修改了该行，所以每次读取都生成不同值，从而引发不一致问题。
		3) 幻象：通过一个任务，在以前由另一个尚未提交其事务的任务读取的行的范围中插入新行或删除现有行。
			带有未提交事务的任务由于该范围中行数的更改而无法重复其原始读取。 
	- 根据隔离级别的不同，DBMS为并行访问提供不同的互斥保证。在SQL Server数据库中，提供四种隔离级别：
	未提交读、提交读、可重复读、可串行读。这四种隔离级别可以不同程度地保证并发的数据完整性：
		隔离级别	脏 读	不可重复读取	幻 像
		未提交读	是		是				是
		提交读		否		是				是
		可重复读	否		否				是
		可串行读	否		否				否
	
	解决办法：
		原则，能不用数据库锁就不用
		1) 若只是简单的更新，可直接在update语句中完成，而不是读出来修改后再写进去(如：update test set sum=sum+1)
		2) 若更新操作简单，在关键的更新处做是否成功判断来解决并发问题，如：
			问题：要抽出20个奖，可是最后并发多抽出了30个
			if (有未中奖的名额)  {
			    update(奖品状态为中奖);
			    insert(写入中奖列表);
			    echo(你中奖了！);
			} 
			
			修改为：
			if (有未中奖的名额)  {
			    if (update(奖品状态为中奖)) {
				insert(写入中奖列表);
				echo(你中奖了！);
			    }
			}
		3) 数据库锁


* windows下命令格式
	- netstat -an 1 |grep 220.181.111.148
	- 

11.18.2012 
* jvm dump堆栈
	- java命令行中配置jvm参数
		* set JVM parameters for head dump when OOM happens
		 * -XX:+HeapDumpOnOutOfMemoryError
		 * -XX:HeapDumpPath=d:\\tmp
		 * 
		 * set at run configure(+ is add,- is remove ,be care)
		 * 
		 * eg output:
		 * 
		 * java.lang.OutOfMemoryError: Java heap space
			Dumping heap to d:\\tmp\java_pid4608.hprof ...
			Heap dump file created [68393251 bytes in 0.462 secs]
			Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
				at java.util.HashMap.<init>(HashMap.java:187)
				at java.util.HashMap.<init>(HashMap.java:199)
				at test.OOM.testOOM.main(testOOM.java:28)
	- 主动获取堆栈
		 jstack dump堆栈信息 （以时间段dump多份便于对比）
			jstack 1345 > dump1

		windows系统
			tasklist
			jstack -l $PID
* IPMI
	- 智慧平台管理接口（Intelligent Platform Management Interface）原本是一种Intel架构的企业系统的周边设备所采用的一种工业标准。IPMI亦是一个开放的免费标准，使用者无需支付额外的费用即可使用此标准。
	IPMI 能够横跨不同的操作系统、固件和硬件平台，可以智慧型的监视、控制和自动回报大量服务器的运作状况，以降低服务器系统成本。
	from: http://zh.wikipedia.org/wiki/IPMI

	使用 ipmi 的先决条件——想要实现对服务器的 ipmi 管理，必须在硬件、OS、管理工具等几个方面都满足：
	from: http://www.chinahost.org/page-3490-1-1.html?fw=bipmi IPMI操作指南

	华为IMana管理程序对许多IPMI的传统功能支持更不在话下，如系统引导、控制台重定向、虚拟介质、传感器监控、电源控制、系统日志等等(eg: Tecal RH2285)

* select for update
	注意锁的级别，尽量减小锁的范围
	需要在事务中进行

* 缓存 缓存系统 cache 分布式缓存 缓存方案
	Cacheonix :
		Cacheonix is an open source clustered cache and distributed data management framework for Java that allows its users to scale Java applications 
		in a cluster while preserving the simplicity of design and coding in a single Java VM.
		主要特点：
			可靠的分布式 Java 缓存
			通过复制实现高可用性
			支持泛型的缓存 API
			可与 ORM 框架集成
			使用数据分区实现负载均衡
			支持非多播网络
			高性能计算
			快速的本地 Java 缓存
			分布式锁机制
		from: http://www.cacheonix.com/
* 产品
	产品的管理
	产品升级（迭代发布OR其他）
	运维管理
		产品的发布
			分级别发布（降低风险）
	
* 分布式事务 * distribute transaction
	例子
	JTA(java transaction api)
	JTOM：
		JOTM is an open source Transaction Manager implemented in java. It supports several transaction models and specifications providing transaction support for clients 
		using a wide range of middleware platforms (J2EE, CORBA, Web Services, OSGi).
		http://jotm.ow2.org/xwiki/bin/view/Main/

	
* http trunk

* jmonkeyengine

* apache common包
	老版本源码下载，有老版本区：
		http://archive.apache.org/dist/commons/dbcp/

* jetty
	- 架构
		connector,handler,threadpool
	- 起多个jetty实例用于web服务，设置不同端口
		
	- 配置远程调试时，应用启动错误
		JAVA_OPTIONS="$JAVA_OPTIONS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=y"	
		suspend=y 表示启动时进入调试

	- jetty支持ajp协议，加载jetty-ajp.xml配置即可，实现jetty外面一层反向代理层。如apache+jetty
		or haproxy+jetty ,nginx+jetty
	- jetty web结构及部署实践
		jetty-maven-plugin
		1）下载jetty7或更高版本
		2）解压
		3）mv到安装目录，并用ln -s命令起个连接
		jetty安装完毕
		通过bin下的脚本来执行启动关闭等操作

		下载api的jetty运行目录，里面配置了基本信息，通过此目录来起停api
			etc目录自己管理，start.ini配置启动项


	- jetty介绍
		Jetty provides an HTTP server, HTTP client, and javax.servlet container. These components are open source and available for commercial use and distribution.
		Jetty is used in a wide variety of projects and products. Jetty can be embedded in devices, tools, frameworks, application servers, and clusters. See the Jetty Powered page 
	for more uses of Jetty.
		The core Jetty project is hosted by the Eclipse Foundation. The codehaus provides Jetty accessories , integrations, and extensions, as well as hosting older versions of Jetty. 
	See the About page for information about the project structure.
	from: http://jetty.codehaus.org/jetty/


* Jetty7 Continuation
	- API注释中对continuation的说明：
		Continuation. A continuation is a mechanism by which a HTTP Request can be suspended and restarted after a timeout or an asynchronous event has occurred. 
	- 异步HTTP

自行车 钢货架
* code source code
	http://www.codeproject.com/
* jprofiler ,MAT, 内存分析工具，性能分析工具，检测工具
	- Memory Analyzer (MAT)
		The Eclipse Memory Analyzer is a fast and feature-rich Java heap analyzer that helps you find memory leaks and reduce memory consumption.
			Use the Memory Analyzer to analyze productive heap dumps with hundreds of millions of objects, quickly calculate the retained sizes of objects, 
		see who is preventing the Garbage Collector from collecting objects, run a report to automatically extract leak suspects.
		http://www.eclipse.org/mat/
* excel单元格换行（手动）
	ALT + Enter
* ESB enterprise service bus
	企业级服务总线
	SOA

* ethtool
	
	tso、gso
	------
		Large segment offload
		From Wikipedia, the free encyclopedia


		Dialogue box showing offload TCP segmentation settings for an Intel Pro 1000 NIC
		In computer networking, large segment offload (LSO) is a technique for increasing outbound throughput of high-bandwidth network connections by reducing CPU overhead. It works by queuing up large buffers and letting the network interface card (NIC) split them into separate packets. The technique is also called TCP segmentation offload (TSO) when applied to TCP, or generic segmentation offload (GSO).
		The inbound counterpart of large segment offload is large receive offload (LRO).
		[edit]Operation

		When large chunks of data are to be sent over a computer network, they need to be first broken down to smaller segments that can pass through all the network elements like routers and switches between the source and destination computers. This process is referred to as segmentation. Segmentation is often done by the TCP protocol in the host computer. Offloading this work to the NIC is called TCP segmentation offload (TSO).
		For example, a unit of 64KB (65,536 bytes) of data is usually segmented to 46 segments of 1448 bytes each before it is sent over the network through the NIC. With some intelligence in the NIC, the host CPU can hand over the 64 KB of data to the NIC in a single transmit request, the NIC can break that data down into smaller segments of 1448 bytes, add the TCP, IP, and data link layer protocol headers -- according to a template provided by the host's TCP/IP stack -- to each segment, and send the resulting frames over the network. This significantly reduces the work done by the CPU. Many new NICs on the market today support TSO.
		Some network cards implement TSO generically enough that it can be used for offloading fragmentation of other transport layer protocols, or by doing IP fragmentation for protocols that don't support fragmentation by themselves, such as UDP.
	------
	
	ref: http://en.wikipedia.org/wiki/Large_segment_offload

* 灰度发布 灰度发布引擎 , 不同版本兼容问题设计
		灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部用户继续用A，一部分用户开始用B，
	如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、
	调整问题，以保证其影响度。
	from：http://baike.baidu.com/view/2563299.htm

* keluda * 组件化 组件化系统设计，架构设计
	当前只使用缺陷管理模块，取代原来的bugfree（不便于统计和bug全局管理）

	
* JVM配置，jvm优化
	------
		Java HotSpot VM Options

		XML 
		This document provides information on typical command-line options and environment variables that can affect the performance characteristics of the Java HotSpot Virtual Machine. 
		Unless otherwise noted, all information in this document pertains to both the Java HotSpot Client VM and the Java HotSpot Server VM.

		Categories of Java HotSpot VM Options
		  
		Standard options recognized by the Java HotSpot VM are described on the Java Application Launcher reference pages for Windows, Solaris and Linux. This document deals exclusively 
		with non-standard options recognized by the Java HotSpot VM:

		Options that begin with -X are non-standard (not guaranteed to be supported on all VM implementations), and are subject to change without notice in subsequent releases of the JDK.
		Options that are specified with -XX are not stable and are subject to change without notice.
		Users of JDKs older than 1.3.0 who wish to port to a Java HotSpot VM, should see Java HotSpot Equivalents of Exact VM flags.

		Some Useful -XX Options
		  
		Default values are listed for Java SE 6 for Solaris Sparc with -server. Some options may vary per architecture/OS/JVM version. Platforms with a differing default value are listed in the description.

		Boolean options are turned on with -XX:+<option> and turned off with -XX:-<option>.
		Numeric options are set with -XX:<option>=<number>. Numbers can include 'm' or 'M' for megabytes, 'k' or 'K' for kilobytes, and 'g' or 'G' for gigabytes (for example, 32k is the same as 32768).
		String options are set with -XX:<option>=<string>, are usually used to specify a file, a path, or a list of commands
		Flags marked as manageable are dynamically writeable through the JDK management interface (com.sun.management.HotSpotDiagnosticMXBean API) and also through JConsole. In Monitoring and Managing Java SE 6 Platform Applications, Figure 3 shows an example. The manageable flags can also be set through jinfo -flag. 

		The options below are loosely grouped into categories.

		Behavioral options change the basic behavior of the VM.
		Garbage First (G1) Garbage Collection Options
		Performance tuning options are knobs which can be used to tune VM performance.
		Debugging options generally enable tracing, printing, or output of VM information.
		  
		Behavioral Options

		Option and Default Value	Description
		-XX:-AllowUserSignalHandlers	Do not complain if the application installs signal handlers. (Relevant to Solaris and Linux only.)
		-XX:AltStackSize=16384	Alternate signal stack size (in Kbytes). (Relevant to Solaris only, removed from 5.0.)
		-XX:-DisableExplicitGC	Disable calls to System.gc(), JVM still performs garbage collection when necessary.
		-XX:+FailOverToOldVerifier	Fail over to old verifier when the new type checker fails. (Introduced in 6.)
		-XX:+HandlePromotionFailure	The youngest generation collection does not require a guarantee of full promotion of all live objects. (Introduced in 1.4.2 update 11) [5.0 and earlier: false.]
		-XX:+MaxFDLimit	Bump the number of file descriptors to max. (Relevant  to Solaris only.)
		-XX:PreBlockSpin=10	Spin count variable for use with -XX:+UseSpinning. Controls the maximum spin iterations allowed before entering operating system thread synchronization code. (Introduced in 1.4.2.)
		-XX:-RelaxAccessControlCheck	Relax the access control checks in the verifier. (Introduced in 6.)
		-XX:+ScavengeBeforeFullGC	Do young generation GC prior to a full GC. (Introduced in 1.4.1.)
		-XX:+UseAltSigs	Use alternate signals instead of SIGUSR1 and SIGUSR2 for VM internal signals. (Introduced in 1.3.1 update 9, 1.4.1. Relevant to Solaris only.)
		-XX:+UseBoundThreads	Bind user level threads to kernel threads. (Relevant to Solaris only.)
		-XX:-UseConcMarkSweepGC	Use concurrent mark-sweep collection for the old generation. (Introduced in 1.4.1)
		-XX:+UseGCOverheadLimit	Use a policy that limits the proportion of the VM's time that is spent in GC before an OutOfMemory error is thrown. (Introduced in 6.)
		-XX:+UseLWPSynchronization	Use LWP-based instead of thread based synchronization. (Introduced in 1.4.0. Relevant to Solaris only.)
		-XX:-UseParallelGC	Use parallel garbage collection for scavenges. (Introduced in 1.4.1)
		-XX:-UseParallelOldGC	Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC. (Introduced in 5.0 update 6.)
		-XX:-UseSerialGC	Use serial garbage collection. (Introduced in 5.0.)
		-XX:-UseSpinning	Enable naive spinning on Java monitor before entering operating system thread synchronizaton code. (Relevant to 1.4.2 and 5.0 only.) [1.4.2, multi-processor Windows platforms: true]
		-XX:+UseTLAB	Use thread-local object allocation (Introduced in 1.4.0, known as UseTLE prior to that.) [1.4.2 and earlier, x86 or with -client: false]
		-XX:+UseSplitVerifier	Use the new type checker with StackMapTable attributes. (Introduced in 5.0.)[5.0: false]
		-XX:+UseThreadPriorities	Use native thread priorities.
		-XX:+UseVMInterruptibleIO	Thread interrupt before or with EINTR for I/O operations results in OS_INTRPT. (Introduced in 6. Relevant to Solaris only.)

		Back to Options 
		  
		Garbage First (G1) Garbage Collection Options

		Option and Default Value	Description
		-XX:+UseG1GC	Use the Garbage First (G1) Collector
		-XX:MaxGCPauseMillis=n	Sets a target for the maximum GC pause time. This is a soft goal, and the JVM will make its best effort to achieve it.
		-XX:InitiatingHeapOccupancyPercent=n	Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes 'do constant GC cycles'. The default value is 45.
		-XX:NewRatio=n	Ratio of new/old generation sizes. The default value is 2.
		-XX:SurvivorRatio=n	Ratio of eden/survivor space size. The default value is 8.
		-XX:MaxTenuringThreshold=n	Maximum value for tenuring threshold. The default value is 15.
		-XX:ParallelGCThreads=n	Sets the number of threads used during parallel phases of the garbage collectors. The default value varies with the platform on which the JVM is running.
		-XX:ConcGCThreads=n	Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running.
		-XX:G1ReservePercent=n	Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10.
		-XX:G1HeapRegionSize=n	With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb.

		Back to Options 
		 
		Performance Options

		Option and Default Value	Description
		-XX:+AggressiveOpts	Turn on point performance compiler optimizations that are expected to be default in upcoming releases. (Introduced in 5.0 update 6.)
		-XX:CompileThreshold=10000	Number of method invocations/branches before compiling [-client: 1,500]
		-XX:LargePageSizeInBytes=4m	Sets the large page size used for the Java heap. (Introduced in 1.4.0 update 1.) [amd64: 2m.]
		-XX:MaxHeapFreeRatio=70	Maximum percentage of heap free after GC to avoid shrinking.
		-XX:MaxNewSize=size	Maximum size of new generation (in bytes). Since 1.4, MaxNewSize is computed as a function of NewRatio. [1.3.1 Sparc: 32m; 1.3.1 x86: 2.5m.]
		-XX:MaxPermSize=64m	Size of the Permanent Generation.  [5.0 and newer: 64 bit VMs are scaled 30% larger; 1.4 amd64: 96m; 1.3.1 -client: 32m.]
		-XX:MinHeapFreeRatio=40	Minimum percentage of heap free after GC to avoid expansion.
		-XX:NewRatio=2	Ratio of new/old generation sizes. [Sparc -client: 8; x86 -server: 8; x86 -client: 12.]-client: 4 (1.3) 8 (1.3.1+), x86: 12]
		-XX:NewSize=2m	Default size of new generation (in bytes) [5.0 and newer: 64 bit VMs are scaled 30% larger; x86: 1m; x86, 5.0 and older: 640k]
		-XX:ReservedCodeCacheSize=32m	Reserved code cache size (in bytes) - maximum code cache size. [Solaris 64-bit, amd64, and -server x86: 48m; in 1.5.0_06 and earlier, Solaris 64-bit and amd64: 1024m.]
		-XX:SurvivorRatio=8	Ratio of eden/survivor space size [Solaris amd64: 6; Sparc in 1.3.1: 25; other Solaris platforms in 5.0 and earlier: 32]
		-XX:TargetSurvivorRatio=50	Desired percentage of survivor space used after scavenge.
		-XX:ThreadStackSize=512	Thread Stack Size (in Kbytes). (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]
		-XX:+UseBiasedLocking	Enable biased locking. For more details, see this tuning example. (Introduced in 5.0 update 6.) [5.0: false]
		-XX:+UseFastAccessorMethods	Use optimized versions of Get<Primitive>Field.
		-XX:-UseISM	Use Intimate Shared Memory. [Not accepted for non-Solaris platforms.] For details, see Intimate Shared Memory.
		-XX:+UseLargePages	Use large page memory. (Introduced in 5.0 update 5.) For details, see Java Support for Large Memory Pages.
		-XX:+UseMPSS	Use Multiple Page Size Support w/4mb pages for the heap. Do not use with ISM as this replaces the need for ISM. (Introduced in 1.4.0 update 1, Relevant to Solaris 9 and newer.) [1.4.1 and earlier: false]
		-XX:+UseStringCache	Enables caching of commonly allocated strings.
		 
		-XX:AllocatePrefetchLines=1	Number of cache lines to load after the last object allocation using prefetch instructions generated in JIT compiled code. Default values are 1 if the last allocated object was an instance and 3 if it was an array. 
		 
		-XX:AllocatePrefetchStyle=1	Generated code style for prefetch instructions.
		0 - no prefetch instructions are generate*d*,
		1 - execute prefetch instructions after each allocation,
		2 - use TLAB allocation watermark pointer to gate when prefetch instructions are executed.
		 
		-XX:+UseCompressedStrings	Use a byte[] for Strings which can be represented as pure ASCII. (Introduced in Java 6 Update 21 Performance Release) 
		 
		-XX:+OptimizeStringConcat	Optimize String concatenation operations where possible. (Introduced in Java 6 Update 20) 
		 

		Back to Options 
		  
		Debugging Options

		Option and Default Value	Description
		-XX:-CITime	Prints time spent in JIT Compiler. (Introduced in 1.4.0.)
		-XX:ErrorFile=./hs_err_pid<pid>.log	If an error occurs, save the error data to this file. (Introduced in 6.)
		-XX:-ExtendedDTraceProbes	Enable performance-impacting dtrace probes. (Introduced in 6. Relevant to Solaris only.)
		-XX:HeapDumpPath=./java_pid<pid>.hprof	Path to directory or filename for heap dump. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)
		-XX:-HeapDumpOnOutOfMemoryError	Dump heap to file when java.lang.OutOfMemoryError is thrown. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)
		-XX:OnError="<cmd args>;<cmd args>"	Run user-defined commands on fatal error. (Introduced in 1.4.2 update 9.)
		-XX:OnOutOfMemoryError="<cmd args>; 
		<cmd args>"	Run user-defined commands when an OutOfMemoryError is first thrown. (Introduced in 1.4.2 update 12, 6)
		-XX:-PrintClassHistogram	Print a histogram of class instances on Ctrl-Break. Manageable. (Introduced in 1.4.2.) The jmap -histo command provides equivalent functionality.
		-XX:-PrintConcurrentLocks	Print java.util.concurrent locks in Ctrl-Break thread dump. Manageable. (Introduced in 6.) The jstack -l command provides equivalent functionality.
		-XX:-PrintCommandLineFlags	Print flags that appeared on the command line. (Introduced in 5.0.)
		-XX:-PrintCompilation	Print message when a method is compiled.
		-XX:-PrintGC	Print messages at garbage collection. Manageable.
		-XX:-PrintGCDetails	Print more details at garbage collection. Manageable. (Introduced in 1.4.0.)
		-XX:-PrintGCTimeStamps	Print timestamps at garbage collection. Manageable (Introduced in 1.4.0.)
		-XX:-PrintTenuringDistribution	Print tenuring age information.
		-XX:-TraceClassLoading	Trace loading of classes.
		-XX:-TraceClassLoadingPreorder	Trace all classes loaded in order referenced (not loaded). (Introduced in 1.4.2.)
		-XX:-TraceClassResolution	Trace constant pool resolutions. (Introduced in 1.4.2.)
		-XX:-TraceClassUnloading	Trace unloading of classes.
		-XX:-TraceLoaderConstraints	Trace recording of loader constraints. (Introduced in 6.)
		-XX:+PerfSaveDataToFile	Saves jvmstat binary data on exit.
		-XX:ParallelGCThreads=n	Sets the number of garbage collection threads in the young and old parallel garbage collectors. The default value varies with the platform on which the JVM is running.
		-XX:+UseCompressedOops	Enables the use of compressed pointers (object references represented as 32 bit offsets instead of 64-bit pointers) for optimized 64-bit performance with Java heap sizes less than 32gb.
		-XX:+AlwaysPreTouch	Pre-touch the Java heap during JVM initialization. Every page of the heap is thus demand-zeroed during initialization rather than incrementally during application execution.
		-XX:AllocatePrefetchDistance=n	Sets the prefetch distance for object allocation. Memory about to be written with the value of new objects is prefetched into cache at this distance (in bytes) beyond the address of the last allocated object. Each Java thread has its own allocation point. The default value varies with the platform on which the JVM is running.
		-XX:InlineSmallCode=n	Inline a previously compiled method only if its generated native code size is less than this. The default value varies with the platform on which the JVM is running.
		-XX:MaxInlineSize=35	Maximum bytecode size of a method to be inlined.
		-XX:FreqInlineSize=n	Maximum bytecode size of a frequently executed method to be inlined. The default value varies with the platform on which the JVM is running.
		-XX:LoopUnrollLimit=n	Unroll loop bodies with server compiler intermediate representation node count less than this value. The limit used by the server compiler is a function of this value, not the actual value. The default value varies with the platform on which the JVM is running.
		-XX:InitialTenuringThreshold=7	Sets the initial tenuring threshold for use in adaptive GC sizing in the parallel young collector. The tenuring threshold is the number of times an object survives a young collection before being promoted to the old, or tenured, generation.
		-XX:MaxTenuringThreshold=n	Sets the maximum tenuring threshold for use in adaptive GC sizing. The current largest value is 15. The default value is 15 for the parallel collector and is 4 for CMS.
		-Xloggc:<filename>	Log GC verbose output to specified file. The verbose output is controlled by the normal verbose GC flags.
		-XX:-UseGCLogRotation	Enabled GC log rotation, requires -Xloggc.
		-XX:NumberOfGClogFiles=1	Set the number of files to use when rotating logs, must be >= 1. The rotated log files will use the following naming scheme, <filename>.0, <filename>.1, ..., <filename>.n-1.
		-XX:GCLogFileSize=8K	The size of the log file at which point the log will be rotated, must be >= 8K.
	------
	from: http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html

* 代码review辅助工具 * review board
	- Code Review Tool
		Install Code Review Tool (only once):
		Open ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/ .
		Register to create your account.
		Use svn up to sync the latest code. The should be a bin directory under the repository root containing post-review and review.tmpl.
		Use cp review.tmpl review to create your version of review script. Modify review file by finding --username=your-name and replacing your-name with your account name registered in step 1. NOTE: Don't delete the space right after your name, otherwise you will encounter problem when you run review script with parameters.
		Modify your ~/.bashrc and add these lines:
			#export LANG=en_US.UTF-8
			#export LANGUAGE=en_US.UTF-8
			#export LC_ALL=en_US.UTF-8
			export PATH=$PATH:/<your repository path>/bin
		Open a new console to start using reviewboard.
		Use su to change to root account
		rpm -ivh ​http://yum.ops.aliyun-inc.com/application/5Server/x86_64/apsara/python-simplejson-2.0.3-3.el5.x86_64.rpm
		Use exit back to your account
		Review steps:
		Modify code.
		If there is new file created, type svn add <file-name>. Otherwise, the content will not be covered in the laterly generated diff file.
		Run review to submit a review item to Review Board.
		Use browser to login Review Board and find your review item draft.
		Add summary, reviewers, description for your item and publish.
		Waiting for review result and check in after approval.
		Apply diff to your local source tree:
		Start with a clean source tree. If you are editing some files in the current tree, use "svn co" to create another tree for code review.
		Click "Download Diff" in the Review Board UI. Save the diff file to your local disk.
		In the project root directory, use "patch -i diff_file -p2" to apply diff.
		(Notes: "-p2" will strip 2 leading slashes from each file name found in the diff_file. For example, supposing the file name in the diff_file was "/trunk/include/apsara/common/safeguard.h", setting -p2 gives "include/apsara/common/safeguard.h", -p0 gives the entire file name unmodified.)
		(Tips: su and apt-get install patch and exit if get 'patch: command not found' prompt)
		(Tips: please ensure the diff is created under the root directory of Apsara source code)
		(Tisp: -pNum means skip Num Slashes when do the patch, please refer to "man patch")
		Now your local source tree is modified according to the diff.
		When finished, use "svn revert . -R" (Do not doubt there is a flaw on your screen between "revert" and "-R". That is exact a dot indicating where the project root is) to revert changes.
		NOTE: This removes all your local changes on this patched copy of the project except for those newly created file by patch. So be sure not to do revert on your own working copy !
		NOTE:
		When you modified code according to a review comment, please use "add comment" to mark it as "done". If you made a different change or think the comment is wrong, also use "add comment" to take note, e.g. "done using a different implementation: ..." or "this is not a bug, because ...".
		When you finished modifying code, please update the review request with new code. Please don't create a new review request. Run 'review -r reviewNum' to update the previous request.
		3. Remember to close review requests (mark as 'submitted') when the code has been checked in.

		Manual steps if you don't use above script
		cd to your apsara root folder. e.g /home/<alias>/apsara
		CMD svn diff > mychange.diff
		login ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/
		click "New Review Request"
		in Base Diff path, input "trunk"
		in diff, browse and select diff file you just created.
		click "Create Review Request"
		in next page, input title for your review request, usually we use [Project]-[component name] as prefix, e.g: AOS-Fuxi ir AUC-XXXX.
		select people you want to send review to. then publish your review request.
		How to enable syntax highlighting for your code review
		Login your review board site.
		Navigate into my account page by the url ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/account/preferences/ .
		Choose the checkbox "Enable syntax highlighting in the diff viewer" and save it. The default status is unchecked.
		NOTE: If enabled, syntax highlighting will be used in the Diff Viewer. This offers improved readability of diffs, but takes longer time to render.	
		from: http://wiki.aliyun-inc.com/projects/apsara/wiki/ApsaraDevEnv#no1
	- 
		reviewboard.
			Take the pain out of code review
			http://www.reviewboard.org/docs/manual/1.0/
		python实现：
		项目主页：
			http://code.google.com/p/reviewboard/
		
		使用方法：
			1)   在飞天reviewboard上注册账号<http://reviewboard.dev.sd.aliyun.com/>
			2)   通过网页提交review requests或者使用post-review命令行提交(网页有坑，反正我是提交失败了)

			Post-review依赖于python2.7，需要设置下环境变量
			[root@AT-HOUYIDEV-AG]$ unalias  post-review    
			[root@AT-HOUYIDEV-AG]$ export PATH=/home/tops/bin:/usr/local/bin:$PATH
			[root@AT-HOUYIDEV-AG]$ cd /apsarapangu/disk4/apsara-0.8.6/ec_flow_billing
			[root@AT-HOUYIDEV-AG]$ post-review  --server=http://reviewboard.dev.sd.aliyun.com/ReviewBoard --summary='xxxx'  --username=xxx --revision-range=R1:R2
			会生产一个request链接，贴到浏览器里头，修改review request的相关描述并publish。

		通过review board页面提交或者通过post-review命令工具实现
			post-review命令参数说明，查看其.py源码，找到帮助，sudo post-review --help
	
* htttpd
	apache服务器，指定httpd.cof文件启动，在执行命令的目录下的confi文件夹中的，tpd.conf文件中配置~~。。。
* 设计模式
	- 工厂模式是创建型模式中最典型的模式，主要是用来创建对象，减少我们在使用某个对象时的new() 操作，我相信大家都有这样的困惑，
	目前我所在的项目都在程序开发的过程中，还是有很多的new()操作出现在表现层中，并没有通过工厂来创建对象，一方面可能是因为我们自身比较懒，
	不规范项目的编码形式，另外一方面也是由于项目的进度比较紧，没有那么多的时间去
	完成工厂的统一创建，当然对于这样的动态创建对象的工厂，推荐的做法还是我们后面会讲到的创建型模式--《抽象工厂模式》来解决吧。
	from: http://www.cnblogs.com/hegezhou_hot/archive/2010/11/30/1892227.html
* Megastore:
	Providing Scalable, Highly Available
Storage for Interactive Services
* jmx 监控 java监控 性能监控 性能
	java，javaee程序监控插件：http://code.google.com/p/javamelody/

* tomcat6			 tomcat源码分析
	- Comet support tomcat6
		Comet support allows a servlet to process IO asynchronously, receiving events when data is available for reading on the connection (rather than always 
		using a blocking read), and writing data back on connections asynchronously (most likely responding to some event raised from some other source).
		ref: http://localhost:8080/docs/aio.html
	- tomcat架构，组件层次
		最外层是Server，内部有多个Service，每个Service内部有多个Connector和多个Engine，每个Engine中可以有多个Host和，每个Host中可以有多个Context即webapp

		这个层次结构从tomcat的server.xml文件的层次中能看出，在其自带的文档关于架构部分也有说明。


		Apache Tomcat Architecture　ref: http://localhost:8080/docs/architecture/index.html 自带Doc中有关于架构的说明
			Overview - An overview of the Tomcat server architecture with key terms and concepts.
			Server Startup - A detailed description, with sequence diagrams, of how the Tomcat server starts up.
			Request Process Flow - A detailed description of how Tomcat handles a request.

	- tomcat6类加载器层次
		Bootstrap->System->Common-->Webapp1
								|->Webapp2
		说明：					
			Bootstrap — This class loader contains the basic runtime classes provided by the Java Virtual Machine, plus any classes from JAR files present in the System Extensions 
						directory ($JAVA_HOME/jre/lib/ext). Note: some JVMs may implement this as more than one class loader, or it may not be visible (as a class loader) at all.
			System — This class loader is normally initialized from the contents of the CLASSPATH environment variable. All such classes are visible to both Tomcat internal classes, 
						and to web applications. However, the standard Tomcat startup scripts ($CATALINA_HOME/bin/catalina.sh or %CATALINA_HOME%\bin\catalina.bat) totally ignore 
						the contents of the CLASSPATH environment variable itself, and instead build the System class loader from the following repositories:
				- $CATALINA_HOME/bin/bootstrap.jar — Contains the main() method that is used to initialize the Tomcat server, and the class loader implementation classes it depends on.
				- $CATALINA_BASE/bin/tomcat-juli.jar and $CATALINA_HOME/bin/tomcat-juli.jar — Logging implementation classes. These include enhancement classes to java.util.logging API, 
				known as Tomcat JULI, and a package-renamed copy of Apache Commons Logging library used internally by Tomcat. See logging documentation for more details.
				- $CATALINA_HOME/bin/commons-daemon.jar — The classes from Apache Commons Daemon project.

				The tomcat-juli.jar and commons-daemon.jar JARs in $CATALINA_HOME/bin are not present in the CLASSPATH built by catalina.bat|.sh scripts, but are referenced from 
				the manifest file of bootstrap.jar.

				If $CATALINA_BASE and $CATALINA_HOME do differ and $CATALINA_BASE/bin/tomcat-juli.jar does exist, the startup scripts will add it to CLASSPATH before bootstrap.jar, 
				so that Java will look into $CATALINA_BASE/bin/tomcat-juli.jar for classes before it will look into $CATALINA_HOME/bin/tomcat-juli.jar referenced by bootstrap.jar. It should work 
				in most cases but, if you are using such configuration, it might be recommended to remove tomcat-juli.jar from $CATALINA_HOME/bin so that only one copy of the file is present on the 
				classpath. The next version of Tomcat, Tomcat 7, takes different approach here.
			Common — This class loader contains additional classes that are made visible to both Tomcat internal classes and to all web applications.
				Normally, application classes should NOT be placed here. The locations searched by this class loader are defined by the common.loader property in 
				$CATALINA_BASE/conf/catalina.properties. The default setting will search the following locations in the order they are listed:
					- unpacked classes and resources in $CATALINA_BASE/lib
					- JAR files in $CATALINA_BASE/lib
					- unpacked classes and resources in $CATALINA_HOME/lib
					- JAR files in $CATALINA_HOME/lib
			WebappX — A class loader is created for each web application that is deployed in a single Tomcat instance. All unpacked classes and resources in the /WEB-INF/classes 
				directory of your web application, plus classes and resources in JAR files under the /WEB-INF/lib directory of your web application, are made visible to this web application, 
				but not to other ones.

		ref: http://localhost:8080/docs/class-loader-howto.html
	- 结合tomcat使用NIO来理解
		---------
			在web服务器上阻塞IO(BIO)与NIO一个比较重要的不同是，我们使用BIO的时候往往会为每一个web请求引入多线程，每个web请求一个单独的线程，
			所以并发量一旦上去了，线程数就上去了，CPU就忙着线程切换，所以BIO不合适高吞吐量、高可伸缩的web服务器；而NIO则是使用单线程(单个CPU)或者
			只使用少量的多线程(多CPU)来接受Socket，而由线程池来处理堵塞在pipe或者队列里的请求.这样的话，只要OS可以接受TCP的连接，web服务器就可以处理该请求。
			大大提高了web服务器的可伸缩性。

			从Tomcat6.0以后, Java开发者很容易就可以是用NIO的技术来提升tomcat的并发处理能力。

			<Connector port="8080" protocol="HTTP/1.1"
			connectionTimeout="20000"
			redirectPort="8443" />
			修改成：

			<Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol"
			connectionTimeout="20000"
			redirectPort="8443" />
			然后启动服务器，你会看到org.apache.coyote.http11.Http11NioProtocol start的信息，表示NIO已经启动
		---------
		ref: http://www.cnblogs.com/killbug/archive/2012/11/25/2787717.html

	- bootstrap
		org.apache.catalina.startup.Bootstrap
		main方法的：daemon.load(args); daemon.start(); 为主要启动过程，前面是初始化等工作
		
	-
	feature：NIO,MBEAN etc
	svn: http://svn.apache.org/repos/asf/tomcat/tc6.0.x/trunk/

	- tomcat源码分析
		--------
			Tomcat的体系结构或者源码，
			将Tomcat的源码导入到ide中，编写实例进行代码跟踪（debug）。

			准备：
			1.Tomcat源码下载

			这个里下载tomcat-6.0.33源码。
			2.ant安装，用于编译tomcat的源码。
			ant下载解压后将其bin添加到系统环境path中。
			3.IDE——选用Eclipse3.7。
			 
			=================================
			第一步：
			解压Tomcat源码，例如解压到D:\tomcat\apache-tomcat-6.0.33-src。
			第二步：
			2.1）使用ant编译tomcat源码，在编译之前需要下载相关的依赖项目。我们并不知道编译需要哪些依赖项目，怎么办？
			让ant来帮忙吧！我们只需要准备一个存放这些依赖项目的地方，例如d:\tomcat\basepath。
			2.2）要让ant工作起来，我们还要将apache-tomcat-6.0.33-src文件夹中的build.properties.default重命名为build.properties，
			并且打开它，修改base.path=d:\tomcat\basepath。
			2.3）下载依赖项目，进入命令控制台，进入目录D:\tomcat\apache-tomcat-6.0.33-src，执行命令：ant download。
			2.4）等依赖项目下载好后，就可以编译tomcat了。执行命令：ant。当编译完成后，我们可以查看目录D:\tomcat\apache-tomcat-6.0.33-src，
			可以发现里面多了一个文件夹：output。
			output文件夹的结构如下：

			我们会发现这个结构和从安装包里解压出来的tomcat结构一致。
			进入bin，启动tomcat成功，就说明——ant编译tomcat成功了！
			 
			=====================================
			将tomcat源码导入eclipse。
			第一步：
			在eclipse里新建一个java项目，例如：tomcat6。
			第二步：
			import->file system
			在From directory选择tomcat源码，选择java和test（如果你需要测试的话选择test），如下图：

			在into folder中选择我们刚新建的tomcat6，finish。
			note：将java、test设置成source folder，java build path ->Source->Add folder...->选择java和test。
			现在项目结构如下图所示：

			第三部：导入jar包。
			上面那些不爽的红叉是因为缺少jar的原因，我们现在需要那些jar包呢？
			test需要junit.jar，这个直接用eclipse里面的即可。
			java中需要：
			ant.jar
			jaxrpc.jar
			org.eclipse.jdt.core_3.3.1.v_780_R33x.jar
			wsdl4j-1.5.1.jar
			导入后就清爽了！

			第四步：
			在eclipse中启动tomcat。
			找到类：org.apache.catalina.startup包中的Bootstrap类。
			run as：在Arguments的VM arguments中设置
			-Dcatalina.home="d:\output\build"
			然后就可以启动了！
			 
			==========================================
			问题：
			为什么要设置-Dcatalina.home="d:\output\build"？
			首先说明output是什么——它就是ant编译出来的output文件夹，大家可以试试删除里面的东西看还是否可以成功启动。
			如果不配置这个参数又会发生什么情况呢？删除-Dcatalina.home="d:\output\build"，报错：
			2011-10-20 14:49:35 org.apache.catalina.startup.ClassLoaderFactory validateFile
			警告: Problem with directory [D:\myWorkSpace\tomcat6\lib], exists: [false], isDirectory: [false], canRead: [false]
			2011-10-20 14:49:35 org.apache.catalina.startup.ClassLoaderFactory validateFile
			警告: Problem with directory [D:\myWorkSpace\tomcat6\lib], exists: [false], isDirectory: [false], canRead: [false]
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina load
			警告: Can't load server.xml from D:\myWorkSpace\tomcat6\conf\server.xml
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina load
			警告: Can't load server.xml from D:\myWorkSpace\tomcat6\conf\server.xml
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina start
			严重: Cannot start server. Server instance is not configured.
			从中可以看出在项目的根目录下没有lib文件夹，没有conf文件夹，conf中没有server.xml，从而不能实例化server。
			那么按照他的提示做，在启动就ok了！
		--------
		from: http://www.cnblogs.com/huangfox/archive/2011/10/20/2218970.html

		从bootstrap处debug分析，debugtomcat的启动过程以及处理请求流程等。


* 旋风网页版
	离线download
* ant
	- build.xml
		<target>标签定义了ant的操作 ，如 #ant download ,#ant compile ,#ant clean
	- ivy ant的子项目，管理依赖
		从maven库下载依赖jar
	- 
		一个ant项目拿到，如何确认其使用的ant版本？
		已有编译的jar中查找(eg:MANIFEST.MF)

	- eclipse导入ant工程
		----------
		不同于maven可以直接对IDE的支持(mvn eclipse:eclipse -DdownloadSources=true -DdownloadJavaDocs=true),ant并不具有这样的命令.这样如果eclipse需要import ant工程需要加入两个.classPath .project文件。如下: 
		.project 
		<?xml version="1.0" encoding="UTF-8"?> 
		<projectDescription> 
		<name>your_project-name</name> 
		<comment></comment> 
		<projects> 
		</projects> 
		<buildSpec> 
		  <buildCommand> 
		   <name>org.eclipse.jdt.core.javabuilder</name> 
		   <arguments> 
		   </arguments> 
		  </buildCommand> 
		</buildSpec> 
		<natures> 
		  <nature>org.eclipse.jdt.core.javanature</nature> 
		</natures> 
		</projectDescription> 


		.classpath 
		<?xml version="1.0" encoding="UTF-8"?> 
		<classpath> 
		    <classpathentry kind="src" path="src"/> 
		    <classpathentry kind="src" path="othersrc"/> 
		       <classpathentry kind="con" 
		path="org.eclipse.jdt.launching.JRE_CONTAINER"/> 
		    <!--<classpathentry kind="lib" path="lib/dom4j.jar"/>--> 
		    <classpathentry kind="output" path="classes"/> 
		</classpath> 

		方法2:可以导入为 
		导入的时候选new project-->Java Project From Existing Ant Buildfile 
		最后在你的workspace下面只有一个build.xml被导过去 
		前提是你的build.xml要正确包含需要的全部东西，比如你要用到的资源文件,类等等
		----------
		from: http://blog.csdn.net/screensky/article/details/7840893
* google应用
	https://drive.google.com/?authuser=0#my-drive		  google云端硬盘
		生态系统
			浏览器
			OS
			搜索
			社交 google+
			。。。

* md5 * 完整性验证
	md5码验证，或其他方式验证文件完整性(integrity of the files)。
	Verify the integrity of the files
	It is essential that you verify the integrity of the downloaded files using the PGP or MD5 signatures. Please read Verifying Apache Software Foundation Releases 
	for more information on why you should verify our releases.
	The PGP signatures can be verified using PGP or GPG. First download the KEYS as well as the asc signature file for the relevant distribution. 
	Make sure you get these files from the main distribution site, rather than from a mirror. Then verify the signatures using
	% pgpk -a KEYS
	% pgpv downloaded_file.asc
	or
	% pgp -ka KEYS
	% pgp downloaded_file.asc
	or
	% gpg --import KEYS
	% gpg --verify downloaded_file.asc
	Alternatively, you can verify the MD5 signature on the files. A unix program called md5 or md5sum is included in many unix distributions. It is also available as part of GNU Textutils. 
	Windows users can get binary md5 programs from here , here , or here.

* lua
	http://sourceforge.net/projects/luabinaries/files/5.2.1/Executables/

* 网卡绑定 网卡HA bond * linux双网卡绑定 网卡bond
	什么的linux系统？
	sles：
	# vi /etc/sysconfig/network/ifcfg-bond0 插入如下内容

	BOOTPROTO='static'
	IPADDR='10.34.81.21'
	NETMASK='255.255.255.0'
	STARTMODE='onboot'
	BONDING_MASTER='yes'
	BONDING_MODULE_OPTS='mode=1 miimon=200 use_carrier=1'
	BONDING_SLAVE0='eth1'
	BONDING_SLAVE1='eth2'

	检查# /etc/sysconfig/network/ 下有没有eth1、eth2的MAC地址配置，若有，则删除
	启动双网卡绑定# rcnetwork restart

	其中：BONDING_MODULE_OPTS='mode=1 为主备 0为负荷分担 

	redhat：

	创建一个ifcfg-bond0
	# vi /etc/sysconfig/network-scripts/ifcfg-bond0
	DEVICE=bond0
	BONDING_OPTS="mode=1 miimon=500"
	BOOTPROTO=none
	ONBOOT=yes
	BROADCAST=192.168.0.255
	IPADDR=192.168.0.180
	NETMASK=255.255.255.0
	NETWORK=192.168.0.0
	USERCTL=no
	其中：BONDING_OPTS="mode=1 为主备 0为负荷分担 

	修改/etc/sysconfig/ifcfg-ethX
	这里说的ethX指要加入绑定网卡的名称，本例中是eth0、eth1。
	# vi  /etc/sysconfig/ifcfg-eth0
	DEVICE=eth0 BOOTPROTO=none ONBOOT=yes MASTER=bond0 SLAVE=yes USERCTL=no
	# vi  /etc/sysconfig/ifcfg-eth1
	DEVICE=eth1BOOTPROTO=none ONBOOT=yes MASTER=bond0 SLAVE=yes USERCTL=no

	配置/etc/modprobe.conf，添加alias bond0 bonding
	# vi /etc/modprobe.conf
	alias eth0 pcnet32
	alias eth1 pcnet32
	alias scsi_hostadapter mptbase
	alias scsi_hostadapter1 mptspi
	alias bond0 bonding

	重启网络服务
	#service network restart

	from: http://zhidao.baidu.com/question/314912483.html&__bd_tkn__=74b942223728982e1751a83eb7fc2bbc951c80f48078338d51fed8133ea5c69d362ad36bb4bcda3b39bb3949f6bbe47087ac3af56e60b1f4e7eb60157b5df93b9c65adf05d0f03de0125277edc31b8084973e9027e22be84a139470b052c3b2abf6378313fb7d9deef0efaaccbdc8d03c93d24f146ac

* git，open source
	从git上，google code上也能看到开源项目
	facebook:
		https://github.com/facebook
	
*avahi
	/var/log/messages
		avahi-daemon[3329]: Host name conflict, retrying with <localhost-99>

	Avahi 是 zeroconf 协议的实现。它可以在没有 DNS 服务的局域网里发现基于 zeroconf 协议的设备和服务。它跟 mDNS 一样。除非你有兼容的设备或使用 zeroconf 协议的服务，
	否则应该关闭它

	Avahi
	Avahi 是Zeroconf规范的开源实现，常见使用在Linux上。包含了一整套多播DNS(multicastDNS)/DNS-SD网络服务的实现。它使用 的发布授权是LGPL。
	Zeroconf规范的另一个实现是Apple公司的Bonjour程式。Avahi和Bonjour相互兼容(废话，都走同一个 规范标准嘛，就象IE，Firefox，chrome都能跑HTTP1.1一样)。

	Avahi允许程序在不需要进行手动网络配置的情况 下，在一个本地网络中发布和获知各种服务和主机。例如，当某用户把他的计算机接入到某个局域网时，如果他的机器运行有Avahi服务
	，则Avahi程式自 动广播，从而发现网络中可用的打印机、共享文件和可相互聊天的其他用户。这有点象他正在接收局域网中的各种网络广告一样。

	Linux下系统实际启动的进程名，是avahi-daemon

	除非你有兼容的设备或使用 zeroconf 协议的服务，否则应该关闭它。  
	如果你用不到 把该服务直接关闭    
	/etc/init.d/avahi-daemon stop or service avahi-daemon  stop

* vpn,proxy ,brea k
	https://trial5.securetrial.net/home

	web page proxy to access www

	http://www.gamesites200.com/wowprivate/
		set it up by yourself
* facebook
	http://www.facebook.com/note.php?note_id=76191543919&ref=mf
	开源项目在git：
		https://github.com/facebook

* 服务器端技术
	搭设服务器都需要的技术，架构，安全，维护，扩展

* 公开课
	http://open.163.com/
* kernel
	build kernel with lvs support: 
	1) Obtain and Unpack Kernel
	It is always easiest to start with a fresh kernel. You can obtain this from www.kernel.org.
	This example will use the 2.4.20 kernel. It can be unpacked using the following command
	which should unpack the kernel into the linux-2.4.20 directory.
	tar -jxvf linux-2.4.20.tar.bz2
	2) Obtain and Unpack LVS
	LVS can be obtained from www.linuxvirtualserver.org. This example will use 1.0.9. It
	can be unpacked using the following command which should pack the kernel into the
	ipvs-1.0.9 directory.
	tar -zxvf ipvs-1.0.9.tar.gz
	3) Apply LVS Patches to Kernel
	Two minor kernel patches are required in order for the LVS modules to compile. To
	apply these patches use the following:
	cd linux-2.4.20/
	patch -pq < ../ipvs-1.0.9/linuxkernel_ksyms_c.diff
	patch -pq < ../ipvs-1.0.9/linuxnet_netsyms_c.diff
	A third patch is applied to allow interfaces to be hidden. Hidden interfaces do not
	respond to ARP requests and are used on real servers with LVS direct routing.
	patch -pq < ../ipvs-1.0.9/contrib/patches/hidden-2.4.20pre10-1.diff
	4) Congure the kernel
	First ensure that the tree is clean:
	make mrproper
	Now congure the kernel. There are a variety of ways of doing this including make menuconfig,
	make xconfig and make config. Regardless of the method that you use, be sure to
	compile in netlter support, with at least the following options. It is suggested that
	where possible these options are built as modules.
	Networking options --->
	Network packet filtering (replaces ipchains)
	<m> IP: tunnelling
	IP: Netfilter Configuration --->
	<m> Connection tracking (required for masq/NAT)
	<m> FTP protocol support
	<m> IP tables support (required for filtering/masq/NAT)
	<m> Packet filtering
	<m> REJECT target support
	<m> Full NAT
	5
	<m> MASQUERADE target support
	<m> REDIRECT target support
	<m> NAT of local connections (READ HELP) (NEW)
	<m> Packet mangling
	<m> MARK target support
	<m> LOG target support
	5) Build and Install the Kernel
	As the kernel has been recongured the build dependencies need to be reconstructed.
	make dep
	The kernel and modules may now be build using:
	make bzImage modules
	To install the newly built modules and kernel run the following command. This should install
	the modules under /lib/modules/2.4.20/and the kernel in /boot/vmlinuz-2.4.20
	make install modules_install
	6) Update boot loader
	In the case of grub is used as the boot loader then a new entry should be added
	to /etc/grub.conf. This example assumes that the /boot partition is /dev/hda3.
	Existing entries in /etc/grub.conf should be used as a guide.
	title 2.4.20 LVS
	root (hd0,0)
	kernel /vmlinuz-2.4.20 ro root=/dev/hda3
	If the boot loader is lilo then a new entry should be added to /etc/lilo.conf. This
	example assumes that the / partition is /dev/hda2. Existing entries in /etc/lilo.conf
	should be used as a guide.
	image=/boot/vmlinuz-2.4.20
	label=2.4.20-lvs
	read-only
	root=/dev/hda2
	Once /etc/lilo.conf has been updated run lilo.
	lilo
	Added Linux-LVS *
	Added Linux
	Added LinuxOLD
	7) Reboot the system.
	At your boot loader's prompt be sure to boot the newly created kernel.	
* xStream框架
	xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换； 
	pojo转xml

* wsdl
	REST service wsdl

	WSDL的作用  
		原理：从XML-RPC和SOAP的使用我们可以看到， 请求消息都是根据服务提供方的服务接口来生成一个HTTP请求，在请求当中封装所要调用的方法，以及方法调用时的参数。
	　　客户端服务调用代码要完成的任务，也就是使用实现所提供的接口，来声明调用方所需要的方法名及参数，然后由实现根据用户的输入来组合HTTP请求。　　
	　 　这个过程可以这样来描述，首先获取用户输入，然后把输入变成实现所要求的存储格式，然后再把该格式变成HTTP请求。一般情况下，我们需要手工完成到第 二步，但是，
	这个过程显然是可以把他自动化的，自动化的效果就是用户不再需要书写这部分的代码，减少工作量和降低出错几率。　　
	　　自动化的过程就需要WSDL的参与，他提供了服务方服务的描述，调用方根据这个描述，就可以知道服务所需要的参数个数，然后向用户索取。得到输入以后，
	实现可以根据WSDL的要求来把输入转换成特定的存储格式，或者直接生成最后的HTTP请求。　　
	　 　对于每个服务，WSDL需要描述两部分的内容，一是接口，二是实现。接口描述了服务的格式，例如服务名，服务参数，服务结果。服务实现则描述了，
	用户所 对应提供的输入如何转换成符合某一实现协议的形式，一般情况下，我们使用SOAP作为实现协议，那么客户端在分析了WSDL文件以后，将会把用户的输入转 换成
	我们已经看到过的SOAP请求，之后的过程就与之前的完全一样。
	
	Describe REST Web services with WSDL 2.0 
		http://www.ibm.com/developerworks/webservices/library/ws-restwsdl/

* zookeeper
	 - 实例
		ref: http://www.cnblogs.com/zhangzhang/archive/2013/01/16/2863339.html
	\- 解决hadoop的单点故障(single point of failure of Name Node)，ZooKeeper能够用来leader选举,配置信息维护等。在一个分布式的环境中，
		我们需要一个Master实例或存储一些配置信息，确保文件写入的一致性等。目前ZooKeeper解决Hadoop的单点故障实现的是主备机方式。

		leader-follower模式

		Master选举
			-动态
			主备切换，一旦某个机器A挂了，马上能够通知到slave，然后slave能够在ZK挃定节点上获取master最后的运行状态，然后就可以把自己标识为master了。

		ZooKeeper是Hadoop的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、命名服务、分布式同步、组服务等。
		ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

	- ZooKeeper 典型的应用场景
			Zookeeper 从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，
		一旦这些数据的状态发生 变化，
			Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式，关于 Zookeeper 的详细架构等
		内部细节可以阅读 Zookeeper的源码

		下面详细介绍这些典型的应用场景，也就是 Zookeeper 到底能帮我们解决那些问题？下面将给出答案。

		1) 统一命名服务（Name Service）

		分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住，通常情况下用树形的名称结构是一个理想的选择，树形 的名称结构是一个有层次的目录结构，
		既对人友好又不会重复。说到这里你可能想到了 JNDI，没错 Zookeeper 的 Name Service 与 JNDI 能够完成的功能是差不多的，它们都是将有层次的目录结构关联到一定资源上，但是 Zookeeper 
		的 Name Service 更加是广泛意义上的关联，也许你并不需要将名称关联到特定资源上，你可能只需要一个不会重复名称，就像数据库中产生一个唯一的数字主键一样。

		Name Service 已经是 Zookeeper 内置的功能，你只要调用 Zookeeper 的 API 就能实现。如调用 create 接口就可以很容易创建一个目录节点。

		2) 配置管理（Configuration Management） 发布&订阅服务

		配置的管理在分布式应用环境中很常见，例如同一个应用系统需要多台 PC Server 运行，但是它们运行的应用系统的某些配置项是相同的，如果要修改这些相同的配置项，
		那么就必须同时修改每台运行这个应用系统的 PC Server，这样非常麻烦而且容易出错。

		像这样的配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，
		每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中。

		3) 集群管理（Group Membership）

		Zookeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，
		集群中其它集群必须知道，从而做出调整重新分配服 务策略。同样当增加集群的服务能力时，就会增加一台或多台 Server，同样也必须让“总管”知道。

		Zookeeper 不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election。

		它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用 getChildren (String  path, boolean watch) 方法并
		设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时getChildren 上的 Watch 将会被调用，所以
		其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。

		Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以
		它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，
		假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。
		这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题。

		4) 共享锁（Locks）

		共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，实现方式也是需要获得锁的 Server 创建一个 
		EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren 方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，如果正是自己创建的，
		那么它就获得了这个锁，如果不是那么它就调用 exists (String  path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，一直到自己创建的节点是列表中最小编号的目录节点，
		从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了。

		5) 队列管理

		Zookeeper 可以处理两种类型的队列：

		当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。
		队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。
		同步队列用 Zookeeper 实现的实现思路如下：

		创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是
		创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 / synchronizing 目录的所有目录节点，也就是 member_i。判断 i 的值是否已经是成员的个数，
		如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。

		用下面的流程图更容易理解：

		FIFO 队列用 Zookeeper 实现思路如下：

		实现的思路也非常简单，就是在特定的目录下创建 SEQUENTIAL 类型的子目录 /queue_i，这样就能保证所有成员加入队列时都是有编号的，出队列时通过 getChildren( ) 方法
		可以返回当前所有的队列中的元素，然后消费其中最小的一个，这样就能保证 FIFO。

		下面是生产者和消费者这种队列形式的示例代码，完整的代码请看附件：		
	
* ssh
	- key登陆,公钥认证登陆
		SSH设置
		在Hadoop启动以后，Namenode是通过SSH（Secure Shell）来启动和停止各个节点上的各种守护进程的，这就需要在节点之间执行指令的时候是不需要输入密码的方式，故我们需要配置SSH使用无密码公钥认证的方式。
		首先要保证每台机器上都装了SSH服务器，且都正常启动。实际中我们用的都是OpenSSH，这是SSH协议的一个免费开源实现。FC5中默认安装的OpenSSH版本是OpenSSH4.3P2。
		以本文中的三台机器为例，现在dbrg-1是主节点，它需要主动发起SSH连接到dbrg-2和dbrg-3，对于SSH服务来说，dbrg-1就是SSH客户端，而dbrg-2、dbrg-3则是SSH服务端，因此在dbrg-2，dbrg-3上需要确定sshd服务已经启动。简单的说，在dbrg-1上需要生成一个密钥对，即一个私钥，一个公钥。将公钥拷贝到dbrg-2，dbrg-3上，这样，比如当dbrg-1向dbrg-2发起ssh连接的时候，dbrg-2上就会生成一个随机数并用dbrg-1的公钥对这个随机数进行加密，并发送给dbrg-1；dbrg-1收到这个加密的数以后用私钥进行解密，并将解密后的数发送回dbrg-2，dbrg-2确认解密的数无误后就允许dbrg-1进行连接了。这就完成了一次公钥认证过程。

		对于本文中的三台机器，首先在dbrg-1上生成密钥对：
		[dbrg@dbrg-1:~]$ssh-keygen  -t  rsa
		这个命令将为dbrg-1上的用户dbrg生成其密钥对，询问其保存路径时直接回车采用默认路径，当提示要为生成的密钥输入passphrase的时候，直接回车，也就是将其设定为空密码。生成的密钥对id_rsa，id_rsa.pub，默认存储在/home/dbrg/.ssh目录下。然后将id_rsa.pub的内容复制到每个机器(也包括本机)的/home/dbrg/.ssh/authorized_keys文件中，如果机器上已经有authorized_keys这个文件了，就在文件末尾加上id_rsa.pub中的内容，如果没有authorized_keys这个文件，直接cp或者scp就好了，下面的操作假设各个机器上都没有authorized_keys文件。

		对于dbrg-1
		[dbrg@dbrg-1:.ssh]$cp id_rsa.pub authorized_keys

		对于dbrg-2（dbrg-3同dbrg-2的方法）
		[dbrg@dbrg-2:~]$mkdir .ssh
		[dbrg@dbrg-1:.ssh]$scp authorized_keys dbrg-2:/home/dbrg/.ssh/
		此处的scp就是通过ssh进行远程copy，此处需要输入远程主机的密码，即dbrg-2机器上dbrg帐户的密码，当然，你也可以用其他方法将authorized_keys文件拷贝到其他机器上

		[dbrg@dbrg-2:.ssh]$chmod 644 authorized_keys
		这一步非常关键，必须保证authorized_keys只对其所有者有读写权限，其他人不允许有写的权限，否则SSH是不会工作的。我就曾经在配置SSH的时候郁闷了好久。

		[dbrg@dbrg-2:.ssh]ls -la
		drwx------ 2 dbrg dbrg .
		drwx------ 3 dbrg dbrg ..
		 -rw-r--r-- 1 dbrg dbrg authorized_keys
		注意每个机器上的.ssh目录的ls -la都应该和上面是一样的

		接着，在三台机器上都需要对sshd服务进行配置(其实是可以不用配置的，完成了上面的那些操作了以后SSH就已经可以工作了)，在三台机器上修改文件/etc/ssh/sshd_config
		#去除密码认证
		PasswordAuthentication  no
		AuthorizedKeyFile   .ssh/authorized_keys

		至此各个机器上的SSH配置已经完成，可以测试一下了，比如dbrg-1向dbrg-2发起ssh连接
		[dbrg@dbrg-1:~]$ssh  dbrg-2
		如果ssh配置好了，就会出现以下提示信息
		The authenticity of host [dbrg-2] can't be established.
		Key fingerprint is 1024 5f:a0:0b:65:d3:82:df:ab:44:62:6d:98:9c:fe:e9:52.
		Are you sure you want to continue connecting (yes/no)?
		OpenSSH告诉你它不知道这台主机，但是你不用担心这个问题，因为你是第一次登录这台主机。键入“yes”。这将把这台主机的“识别标记”加到“~/.ssh/know_hosts”文件中。第二次访问这台主机的时候就不会再显示这条提示信息了。
		然后你会发现不需要输入密码就可以建立ssh连接了，恭喜你，配置成功了
		不过，别忘了测试本机ssh  dbrg-1
* pssh
	pssh  is  a program for executing ssh in parallel on a number of hosts.  It provides features such as sending input to all of the pro-
	cesses, passing a password to ssh, saving output to files, and timing out.

	PSSH provides parallel versions of OpenSSH and related tools. Included are pssh, pscp, prsync, pnuke, and pslurp. The project includes psshlib which can be used within custom applications. 
	The source code is written in Python and can be cloned from:
	git clone http://code.google.com/p/parallel-ssh/ 

	eg:
		pssh -i -h /tmp/nc.list 'sudo python /tmp/virt_ops_release_20120829/virt_ops.py -m ruleset -f config_env -c /tmp/virt_ops_release_20120829/modules/ruleset_ops/config/ruleset_config_env.json'

	  ------
		pssh HOWTO

		Table of Contents
		1. Installation and Setup
		2. Preliminaries
		3. Examples
		3.1. pssh
		3.2. pscp
		3.3. pnuke
		4. Environment Variables
		5. Feedback
		1. Installation and Setup
		To install the software, become root on your machine and do the following (on RedHat systems): 

		   # rpm -ivh pssh-0.2.3-1.i386.rpm
		   Preparing...                ########################################### [100%]
		      1:pssh                   ########################################### [100%]
		 

		By default, the software installs itself in /usr/localbin and /usr/local/lib. Thus, you'll next want to modify your PATH if needed: 

		# export PATH=$PATH:/usr/local/bin

		--------------------------------------------------------------------------------

		2. Preliminaries
		All four programs will print their usage and give an example if no arguments are given. For example, with pssh: 

		   # pssh
		   Usage: pssh [OPTIONS] -h hosts.txt prog [arg0] ..
		   
		     -h --hosts   hosts file (each line "host[:port] [user]")
		     -l --user    username (OPTIONAL)
		     -p --par     max number of parallel threads (OPTIONAL)
		     -o --outdir  output directory for stdout files (OPTIONAL)
		     -t --timeout timeout in seconds to do ssh to a host (OPTIONAL)
		     -v --verbose turn on warning and diagnostic messages (OPTIONAL)
		     -O --options SSH options (OPTIONAL)
		   
		   Example: pssh -h ips.txt -l irb2 -o /tmp/foo uptime
		 
		And for pscp:

		   # pscp
		   Usage: pscp [OPTIONS] -h hosts.txt local remote
		   
		     -h --hosts     hosts file (each line "host[:port] [login]")
		     -r --recursive recusively copy directories (OPTIONAL)
		     -l --user      username (OPTIONAL)
		     -p --par       max number of parallel threads (OPTIONAL)
		     -t --timeout   timeout in seconds to do scp to a host (OPTIONAL)
		     -O --options   SSH options (OPTIONAL)
		   
		   Example: pscp -h hosts.txt -l irb2 foo.txt /home/irb2/foo.txt
		 
		Note that before using any of these tools, you will need to start ssh-agent! This can be done as follows (substitute zsh with your particular shell).

		   # ssh-agent zsh
		   # ssh-add
		   Enter passphrase for /x/bnc/.ssh/identity: 

		--------------------------------------------------------------------------------

		3. Examples
		3.1. pssh
		The following example runs hostname on three machines (IPs or hostnames) specified in the file ips.txt using login irb2 and saves the output in /tmp/foo. 

		   # cat ips.txt
		   128.112.152.122
		   18.31.0.190
		   128.232.103.201
		   
		   # pssh -h ips.txt -l irb2 -o /tmp/foo hostname
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # ls /tmp/foo
		   128.112.152.122  128.232.103.201  18.31.0.190
		   
		   # cat /tmp/foo/*
		   planetlab-1.cs.princeton.edu
		   planetlab1.xeno.cl.cam.ac.uk
		   planetlab1.lcs.mit.edu

		By default, pssh uses at most 32 ssh processes in parallel to ssh to the various nodes. (This is somewhat important if you're controlling hundreds or thousands of machines.) By default, it also uses a timeout of one minute to ssh to a node and obtain a result. For ssh commands that take longer than this (e.g., sleep 61), the -t option can be used. Note that pssh and pnuke have a default timeout of one minute. pscp and prsync have no default timeout, but one can be specified using the -t option.

		--------------------------------------------------------------------------------

		3.2. pscp
		Here's an example of using pscp to copy files in parallel to a set of machines.

		   # pscp -h ips.txt -l irb2 /etc/hosts /tmp/hosts
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22

		Using the -r option will perform a recursive copy for copying entire directories.
  
		--------------------------------------------------------------------------------

		3.3. pnuke
		The pnuke command is useful when you want to kill a bunch of processes on a set of machines. For example, suppose you've got a bunch of java processes running on three nodes that you'd like to nuke (let's use the three machines from the pssh example). Here you would do the following:

		   # pnuke -h ips.txt -l irb2 java
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22

		The result of the above is to send kill -9 to all processes owned by irb2 with the string java in their name (as reported by ps -ef).

		--------------------------------------------------------------------------------

		4. Environment Variables
		All four programs take similar sets of options. All of these options can be set using the following environment variables:

		   PSSH_HOSTS
		   PSSH_USER
		   PSSH_PAR
		   PSSH_OUTDIR
		   PSSH_VERBOSE
		   PSSH_OPTIONS

		Here are some example settings:

		   # export PSSH_HOSTS="/x/bnc/ips.txt"
		   # export PSSH_USER="irb2"
		   # export PSSH_PAR="32"
		   # export PSSH_OUTDIR="/tmp/bar"
		   # export PSSH_VERBOSE="0"
		   # export PSSH_OPTIONS="UserKnownHostsFile /tmp/known_hosts"

		Using the above settings, the examples can be executed succinctly as:

		   # pssh hostname
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # ls /tmp/bar
		   128.112.152.122  128.232.103.201  18.31.0.190
		   
		   # cat /tmp/bar/*
		   planetlab-1.cs.princeton.edu
		   planetlab1.xeno.cl.cam.ac.uk
		   planetlab1.lcs.mit.edu
		   
		   # pscp /etc/hosts /tmp/hosts
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # pnuke java  
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
	
		--------------------------------------------------------------------------------
	  ------

	参考：http://code.google.com/p/parallel-ssh

* Naming Service * 命名服务 * jndi
	命名服务(Naming Service)提供了一种为对象命名的机制，可以定位任何通过网络可以访问的机器上的对象，使得用户可以在无需知道对象位置的情况下获取和使用对象。 
	使用命名服务，首先要将对象在命名服务器上注册，然后用户就可以通过命名服务器的地址和该对象在命名服务器上注册的JNDI名找到该对象，获得其引用了。
	
	nuwa

	架构上，总线架构，各种服务通过总线相互通信，消息总线

* 数据库优化，索引 * 数据库相关 
	- 资源
		http://www.dbanotes.net
	 - SQL Server 索引
		 -------
			  SQL Server索引进阶第十五篇：索引的最佳实践

			    索引设计是数据库设计中比较重要的一个环节，对数据库的性能其中至关重要的作用，但是索引的设计却又不是那么容易的事情，性能也不是那么轻易就获取到的，很多的技术人员因为不恰当
			    的创建索引，最后使得其效果适得其反，可以说“成也索引，败也索引”


			    在本篇文章中，我们在学习了之前的知识之后，推荐14条指导方针。这14条指导方针可以帮助你更好的为数据库构建索引。

			    本篇文章的格式使用了由Addison Wesley出版社出版的<Framework Design Guidelines>中使用的格式。每一个最佳实践之前都使用了如下4个动词：要，考虑，避免、不要，分别代表如下意思:

			    要(Do):这个原则要坚决遵守

			    考虑(Consider):通常情况下都要遵循这个原则，但如果你对原则背后的原理有了深入了理解，可以根据实际情况不采用这个原则

			    避免(Avoid):考虑的反义词,意味着避免做某这类事，但同样，如果你了解了背后的原理，则可以根据实际情况做这类事。

			    不要(Do Not)：避免的增强版,意思是无论什么时候都不要做这类事。

			 
			指导方针

			要了解跑在数据库上的应用程序/用户

			    使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。

			    当然，如果你全程参与了程序的设计和开发，那再好不过。但这种情况少之又少，大多数情况都是你直接接手数据库和应用程序，这时你就需要两步走的了解你所接手的东西-通过外部和内部。

			    外部方法包括从用户那里了解程序相关的信息，观察他们使用程序的过程，阅读用户文档和交接文档。

			    内部方法是去看程序本身对数据库产生的操作。比如说Activity Monitor, Profiler等工具，也可以使用sys.dm_db_index usage_stats和sys.dm_db_missing_index_XXX系列DMV中找到所需信息，这些信息包
			    括用的最多的查询，用的最多的索引，用的少的索引以及本应建却没有建的索引。

			    通过找到拖累系统性能的查询，比如报表服务中用到的语句，agent中执行的T-SQL，SSIS中执行的T-SQL以及存储过程。找到这类信息就可以知道优化该从何处下手。

			    得到上面的信息后，就可以知道哪些索引应当存在，哪些索引应该删除。

			不要过度创建索引

			    过多的索引和太少的索引都不是好事。表中该有多少索引可不是一个固定的数字。当你为主键，候选键和外键建立了索引之后，剩下的索引该怎么建就需要谨慎分析后再做定夺了。

			要明白这点:同样的数据库在不同的环境下要有不同的索引

			    在忙时或是闲时；在OLTP环境或是OLAP环境下，所需要的索引是不同的。

			    比如每天晚上一次性大量更新数据的报表数据库在这时只需要少量索引，而在日间忙时则需要大量索引。数据库上跑少量查询要比数据库跑大量查询需要更少的索引。

			要给每个表设置主键

			    虽然SQL Server并不强制要求设置主键。但一个没有主键的表无论在OLTP还是OLAP环境下都是一件危险的事，因为没有主键就不能保证每行是唯一的。这时你就无法知道同一行数据是否在表
			    中存在两条，尤其是在你还没有足够的信息去分析这点时。

			    尽管SQL Server不强制要求设置主键，但主键是关系数据库的一个关键理论。如果没有主键约束，那么与之关联的唯一索引或是连接操作就有可能产生意料之外的性能问题。

			    除此之外，很多第三方开发工具或插件也要求表有主键，比如说吧，ADO.Net的SqlCommandBuilder和Entity Data Modeler都依赖表中存在主键约束。另外，主键约束会创建一个同名的唯一索引来保
			    证主键的唯一性。

			考虑给每个表设置聚集索引

			    本系列第三篇关于聚集索引的文章阐述了聚集索引带来的好处。使用聚集索引表中的数据就是按聚集索引键的顺序存在而不再以堆存放。使用聚集索引的好处是使得数据按照聚集索引键的顺序
			    存放，并使得后插入的元素依然保持这个顺序。

			    如果你遵循了上一个建议，那么每个表都应该有主键，因此，每一个表都应该有一个或多个索引，让其中的一个索引成为聚集索引。聚集索引本身并不会使得表上多了一个索引，而是让表的结
			    构更好的组织。

			    选择聚集索引键时，要记住第六篇文章中所说的，聚集索引键应该唯一，短和尽量不需要改动。

			考虑使用外键作为聚集索引键的最左列

			    将外键设置为聚集索引的最左列就是将表中的数据按照这列的值进行汇总和组织，这也是查询所需。比如说你用信用卡消费这个行为是和卡关联最强的的，而不是和你刷卡的商场以及处理这笔
			    消费的银行。则将信用卡号作为消费记录表中聚集索引的最左列，使得所有同一张卡的消费信息就会存在连续的页中。

			    当然了，你还需要另外一个很少变动的列和这个信用卡号列组合起来保证聚集索引键的唯一性。

			考虑为索引添加包含列

			    （译者注：这里作者文章有BUG，这段和上段一样，我就大胆的写一下原因吧。）为索引添加包含列的原因是减少对索引所在表的书签查找。因为包含列不会占用索引的非叶子节点空间，所以
			    不会影响B树的高度，通过在叶子节点附加上一些列，使得索引更容易的“覆盖”所请求的查询，从而减少了书签查找，降低了查询成本。

			    但同样，使用包含列使得非聚集索引占用的空间增加了，所以使用包含列时要综合考虑。

			避免为重复值很多的未过滤列创建非聚集索引

			    更早之前的一条建议“永远不要索引性别列”，是由于这列只会存在男性和女性两个值。当遇到WHERE Gender=的语句时使用表扫描要远远好于书签查找，查询优化器无法从这个索引中获益。

			考虑为列中重复值最多的值创建过滤索引

			    如果某列大量的行中都存在相同的值，这个值可以是NULL，那么使用过滤索引将这个值过滤掉，剩下的值所生成的索引就会更小，小索引使得查询优化器选择书签查找而不是表扫描，SQL 
			    Server也就更容易使用索引。

			考虑使用填充因子来面对未来的数据增长

			    假如一个表中只有几个月的数据，但这个表年底的数据已经可以估算出来时，重建索引的过程中将填充因子设置为7或8，这将使索引占用的页和年底占用的页大致相同，这可以更早的暴漏性能
			    问题，比如说表扫描时IO的占用。

			考虑使用填充因子来减少页分裂

			    加入表中的数据已经达到了页所能容纳的最大值。那么再插入数据就会导致页分裂了。因此重建索引时可以使用填充因子，如果数据库写大于读的话，设置填充因子为75，如果读写大致相等的
			    话，设置填充因子为90到95.

			要在创建非聚集索引之前，先创建聚集索引

			    与之对应的指导方针是：在删除聚集索引之前，先删除非聚集索引。如果你不按照这条方针做，则会导致无意义的重建非聚集索引。将表由聚集索引变为堆会使得表上的
			    非聚集索引重建，因为非聚集索引的书签由聚集索引键变为RID。

			要根据索引的使用频率定期整理索引碎片或是重建索引

		    如果一个索引经常用于扫描，正如我们在第11篇文章中所说，那么外部碎片对于性能的影响就变得非常大。这时你就需要考虑在外部碎片到达10%的时候整理索引了。
		    当外部碎片达到30%时就需要重建索引。对于OLTP环境来说，上面的值是一个分界点，这个点就是整理或重建索引的代价小于其带来的性能提升。
		 -------
	
* NFS services
	The Network File System (NFS) was developed to allow machines to mount a disk partition on a remote machine as if it were a local disk. It allows for fast, seamless sharing of files across a network. 
	
* 机器学习
	
* NAT
	网络地址转换（NAT）简介
	NAT概述
	　　NAT（Network Address Translation，网络地址转换）是将IP 数据包头中的IP 地址转换为另一个IP 地址的过程。在实际应用中，
	NAT 主要用于实现私有网络访问公共网络的功能。这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用IP 地址空间的枯竭。
	　　说明：
	　　私有 IP 地址是指内部网络或主机的IP 地址，公有IP 地址是指在因特网上全球唯一的IP 地址。
	　　RFC 1918 为私有网络预留出了三个IP 地址块，如下：
	　　A 类：10.0.0.0～10.255.255.255
	　　B 类：172.16.0.0～172.31.255.255
	　　C 类：192.168.0.0～192.168.255.255
	　　上述三个范围内的地址不会在因特网上被分配，因此可以不必向ISP 或注册中心申请而在公司或企业内部自由使用。
	NAT工作流程
	　　①如右图这个 client 的 gateway 设定为 NAT 主机，所以当要连上 Internet 的时候，该封包就会被送到 NAT 主机，这个时候的封包 Header 之 source IP 为 192.168.1.100 ；
	　　②而透过这个 NAT 主机，它会将 client 的对外联机封包的 source IP ( 192.168.1.100 ) 伪装成 ppp0 ( 假设为拨接情况 )这个接口所具有的公共 IP ，因为是公共 IP 了，
	所以这个封包就可以连上 Internet 了！同时 NAT 主机并且会记忆这个联机的封包是由哪一个 ( 192.168.1.100 ) client 端传送来的；
		注：这里NAT主机会记忆信息以区分不同client的包
	　　③由 Internet 传送回来的封包，当然由 NAT 主机来接收了，这个时候， NAT 主机会去查询原本记录的路由信息，并将目标 IP 由 ppp0 上面的公共 IP 改回原来的 192.168.1.100 ；
	　　④最后则由 NAT 主机将该封包传送给原先发送封包的 Client 。

	from: http://baike.baidu.com/view/16102.htm
* lvs DR			slb
	测试版本
		centos5 32 
			2.6.18-194.el5
		keepalived Keepalived v1.1.20
		ipvsadm v1.24

	- 检测vip漂移，failover
		ICMP包局域网内的其他主机也能收到
		lvs的主/备机通过发送arp包，来取得vip的所有权，要验证vip漂移正确，可通过在vip本机上ping vip，抓tcp的 ICMP 包来确定vip是否切换到对应的机子上。
		a. ping vip eg: ping 192.168.0.199
		b. 在2台lvs机上执行:
			#tcpdump | grep ICMP
		c. 根据lvs机的应答确定vip的位置
			如果vip在A机子上，则在A机上ping vip是不会有tcpdump的  ICMP包(ping本地地址不会广播ICMP包)

		 lvs主备切换 ，vip漂移问题，切换问题
			/etc/init.d/iptables stop

			lvs主备切换如果工作不正常，确认是不是防火墙的原因（防火墙阻止了keepalived的功能），下面是查找主备不切换，每个lvs启动后都是master状态：
			------
				Hi,

				I found that it is always best if possible to turn off the firewall and see if it works,
				then turn on the firewall.

				On 05/24/2012 08:16 AM, lakshmi priya wrote: 
			------
			from : http://comments.gmane.org/gmane.linux.keepalived.devel/3864

			根据上面的提示，测试成功，确实是linux防火墙导致keepalived的主备切换功能失效，具体应该是vrrp协议的交互受阻，下面是测试成功的log：
				Sep 20 02:46:39 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 added
				Sep 20 02:46:40 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 added
				Sep 20 02:46:45 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Received higher prio advert
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering BACKUP STATE
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) removing protocol VIPs.
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 removed
				Sep 20 02:49:26 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 removed
			
			ps：
				iptalbles全部关闭不建议，可以查看keepalived的端口占用说明，开发其需要的端口即可。

	- realserver
		---------
			在两台Web Server上执行realserver.sh脚本，为lo:0绑定VIP地址10.0.0.148、抑制ARP广播。

			[root@web1 ~]# cat realserver.sh
			复制代码

			#!/bin/bash
			#description: Config realserver

			VIP=10.0.0.148
			 
			/etc/rc.d/init.d/functions
			 
			case "$1" in
			start)
			       /sbin/ifconfig lo:0 $VIP netmask 255.255.255.255 broadcast $VIP
			       /sbin/route add -host $VIP dev lo:0
			       echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
			       echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
			       echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
			       echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
			       sysctl -p >/dev/null 2>&1
			       echo "RealServer Start OK"
			       ;;
			stop)
			       /sbin/ifconfig lo:0 down
			       /sbin/route del $VIP >/dev/null 2>&1
			       echo "0" >/proc/sys/net/ipv4/conf/lo/arp_ignore
			       echo "0" >/proc/sys/net/ipv4/conf/lo/arp_announce
			       echo "0" >/proc/sys/net/ipv4/conf/all/arp_ignore
			       echo "0" >/proc/sys/net/ipv4/conf/all/arp_announce
			       echo "RealServer Stoped"
			       ;;
			*)
			       echo "Usage: $0 {start|stop}"
			       exit 1
			esac
			 
			exit 0
		---------
		此脚本在realserver上执行。

		注意，VIP是独立的，如果想将lvs服务与realserver放在同一台机子上测试的话，要保证vip是独立的（非lvs机的ip，也非rs机的ip）
		上面这个脚本设置VIP查找的，如果错用了lvs或rs自身的ip，则出服务异常。

		下面为一个测试例子：
			VIP=10.1.171.253
			2台VM，既充当LVS机，也充当RS机
				vm1:
					ip=10.1.171.140
				vm2:
					ip=10.1.171.148
			起keepalived：
				service keepalived start
			
			执行上面的shell脚本，绑定VIP的访问

			查看LVS，vip下rs状态列表
				[root@mydev2 home]# ipvsadm -L
				IP Virtual Server version 1.2.1 (size=4096)
				Prot LocalAddress:Port Scheduler Flags
				  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
				TCP  10.1.171.253:webcache rr persistent 50
				  -> mydev2.test.com.cn:http      Local   1      0          0         
				  -> mydev.test.com.cn:http       Masq    1      0          0      
				  
				  可以看到2个rs都正常服务了。

			测试场景：
				1）keepalived检查rs的健康情况，对于down掉的rs，从rs列表中去除(ipvsadm -L验证是否去除)
					关闭某台rs的http服务
				2）lvs vip漂移验证（也即LoadBalance主机和BackUP主机之间failover的实现）
					关闭某台lvs机的lvs服务，即关闭keepalived
					验证VIP转移到另一台lvs机上，访问正常。

			问题：上面的shell脚本，当rs正常访问后，ip add命令的结果中vip在eth0的信息中，即使删除lo:0也没用？	 若rs没启动成功此命令中eth0中不会有vip的信息
				#ip add
				1: lo: <LOOPBACK,UP,LOWER_UP> mtu 16436 qdisc noqueue 
				    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
				    inet 127.0.0.1/8 scope host lo
				    inet6 ::1/128 scope host 
				       valid_lft forever preferred_lft forever
				2: peth0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast qlen 1000
				    link/ether fe:ff:ff:ff:ff:ff brd ff:ff:ff:ff:ff:ff
				    inet6 fe80::fcff:ffff:feff:ffff/64 scope link 
				       valid_lft forever preferred_lft forever
				3: sit0: <NOARP> mtu 1480 qdisc noop 
				    link/sit 0.0.0.0 brd 0.0.0.0
				4: virbr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
				    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
				5: vif0.0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether fe:ff:ff:ff:ff:ff brd ff:ff:ff:ff:ff:ff
				    inet6 fe80::fcff:ffff:feff:ffff/64 scope link 
				       valid_lft forever preferred_lft forever
				6: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether 00:0c:29:93:bd:30 brd ff:ff:ff:ff:ff:ff
				    inet 10.1.171.140/25 brd 10.1.171.255 scope global eth0
				    inet 10.1.171.253/32 scope global eth0
				    inet6 fe80::20c:29ff:fe93:bd30/64 scope link 
				
				avahi-daemon服务影响lvs的vip漂移，待确定？
					lvs机切换master/backup时，vip不能正常漂移(从 /var/log/messages日志查看中分析出)
					关闭这个服务lvs主备正常切换。
			
	- lvs安装
		系统编译进内核方式，或者从源码编译安装
		源码安装好后，要修改系统加载（grub，lilo）配置，内核指向打了lvs的patch编译出的内核，启动时选择此内核。

		查看：ls /lib/modules/xxx

	- lvs实现的负载均衡方式
		1) DR 
			Direct Routing: Packets from end users are forwarded directly to the real server. The IP
			packet is not modified, so the real servers must be configured to accept traffic for the
			virtual server's IP address. This can be done using a dummy interface or packet filtering
			to redirect traffic addressed to the virtual server's IP address to a local port. The real
			server may send replies directly back to the end user. Thus, the linux director does not
			need to be in the return path.
				第一次需要修改，后续可以直接enduser和realservr通信
		2) NAT
			
		3) Tunnel
			类似DR，但realserver可以和LD不在同一网络。
	- lvs+keepalived
		http://www.cnblogs.com/mchina/archive/2012/08/27/2644391.html

* linux 系统信息 查看
	linux如何查看系统信息
	一：cpu
	   [root@srv /]# more /proc/cpuinfo | grep "model name"
	 model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	  model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo | cut -f2 -d:
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	二：内存
	[root@srv /]# grep MemTotal /proc/meminfo
	MemTotal:        614400 kB
	[root@srv /]# free -m
			   total        used        free    shared     buffers    cached
	Mem:          600       23       576           0           0           0
	-/+ buffers/cache:       23       576
	Swap:          0           0           0
	[root@srv /]# free -m |grep "Mem" | awk '{print $2}'
	600

	三：查看CPU位数(32 or 64)
	[root@srv /]# getconf LONG_BIT
	32

	四：查看linux版本
	[root@srv /]# more /etc/redhat-release
	CentOS release 5 (Final)
	[root@srv /]# more /etc/issue
	CentOS release 5 (Final)
	Kernel \r on an \m
	[root@srv /]# more /proc/version
	Linux version 2.6.18-92.1.18.el5.028stab060.2PAE ([email=root@rhel5-32-build-xemul]root@rhel5-32-build-xemul[/email]) (gc
	c version 4.1.2 20071124 (Red Hat 4.1.2-42)) #1 SMP Tue Jan 13 12:31:30 MSK 2009

	五：查看内核版本
	[root@srv /]# uname -r
	2.6.18-92.1.18.el5.028stab060.2PAE
	[root@srv /]# uname -a
	Linux srv.eddiechen.cn 2.6.18-92.1.18.el5.028stab060.2PAE #1 SMP Tue Jan 13 12:31:30 MSK 2009 i686 i686 i386 GNU/Linux

	六：查看时区
	[root@srv /]# date -R
	Wed, 25 Feb 2009 02:20:50 +0000
	[root@srv /]# mv /etc/localtime /etc/localtime.save
	[root@srv /]# cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
	[root@srv /]# date -R
	Wed, 25 Feb 2009 10:24:26 +0800

	七：主机名
	查看主机名
	[root@srv /]# hostname
	www.ifuoo.com
	修改主机名
	[root@srv /]# cat /etc/sysconfig/network
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	八：查看selinux情况
	[root@srv /]# sestatus
	SELinux status:                disabled

	九：网络
	IP
	[root@srv /]# ifconfig | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'
	207.154.202.216
	网关
	[root@srv /]# cat /etc/sysconfig/network
	NETWORKING="yes"
	GATEWAY="192.0.2.1"
	HOSTNAME="srv.eddiechen.cn"
	dns
	[root@srv /]# cat /etc/resolv.conf
	nameserver 208.74.168.131
	nameserver 208.74.168.132
	nameserver 4.2.2.1
	修改Host文件
	[root@srv /]# cat /etc/hosts
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	十：已经安装的软件包
	[root@srv /]# rpm -qa | wc -l
	197
	[root@srv /]# yum list installed | wc -l
	198

	十一：磁盘和分区
	[root@srv /]# df -h
	Filesystem          Size    Used          Avail Use    %    Mounted on

	/dev/simfs              10G     353M              9.7G       4%    /

	[root@srv /]# du -sh

	353M

	[root@srv /]# du /etc -sh

	4.6M     /etc

	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	九：查看键盘布局

	cat /etc/sysconfig/keyboard

	cat /etc/sysconfig/keyboard | grep KEYTABLE | cut -f2 -d=

	十二：查看默认语言

	echo $LANG $LANGUAGE

	cat /etc/sysconfig/i18n

	==================================

	http://hi.baidu.com/mypc007

	通过以下命令，可以查看RS/6000系统配备的物理内存的大小。

	　　lsdev -Cc memory

	　　查看RS/6000配置的物理内存设备，下面为其输出示例：

	　　mem0 Available 00-00 Memory

	　　L2cache0 Available 00-00 L2 Cache

	　　再使用命令

	　　lsattr -El mem0

	　　输出如下

	　　size 512 Total amount of physical memory in Mbytes False

	　　goodsize 512 Amount of usable physical memory in Mbytes False

	　　此例说明机器的物理内存为512MB。如果前面lsdev的输出中有设备名 mem1，则使用同样的命令查看其对应的大小并依此类推。L2cache0 为系统二级缓存(Level 2 Cache)的设备名。同样，使用命令：

	　　lsattr -El L2cache0

	　　可以查看其大小。

	查看LINUX系统位数

	1.编程实现：

	在程序中返回sizeof(int)的值，返回的结果是操作系统的字节数。若返回4则是32位操作系统，返回8即是64位。

	2.getconf命令：

	getconf命令可以获取系统的基本配置信息，比如操作系统位数，内存大小，磁盘大小等。

	例如：

	确定磁盘 hdisk0 大小，若是 root 用户，则输入：

	getconf DISK_SIZE /dev/hdisk0

	确定实际内存大小：getconf REAL_MEMORY

	确定是否机器硬件是 32 位或 64 位：getconf HARDWARE_BITMODE

	确定是否内核是 32 位或 64 位： getconf KERNEL_BITMODE

	若以上的getconf KERNEL_BITMODE方法不成功(在我的机器上就不成功)，可能是因为版本不一致，可以再尝试用：getconf WORD_BIT，这个命令返回int类型的长度，与sizeof(int)一致。
* diff和patch使用指南
　　diff和patch是一对工具，在数学上来说，diff是对两个集合的差运算，patch是对两个集合的和运算。
　　diff比较两个文件或文件集合的差异，并记录下来，生成一个diff文件，这也是我们常说的patch文件，即补丁文件。
　　patch能将diff文件运用于 原来的两个集合之一，从而得到另一个集合。举个例子来说文件A和文件B,经过diff之后生成了补丁文件C,那么着个过程相当于 A -B = C ,
	那么patch的过程就是B+C = A 或A-C =B。	
	
　　	因此我们只要能得到A, B, C三个文件中的任何两个，就能用diff和patch这对工具生成另外一个文件。
　　这就是diff和patch的妙处。下面分别介绍一下两个工具的用法:
　　1). diff的用法
　　diff后面可以接两个文件名或两个目录名。 如果是一个目录名加一个文件名，那么只作用在那么个目录下的同名文件。
　　如果是两个目录的话，作用于该目录下的所有文件，不递归。如果我们希望递归执行，需要使用-r参数。
　　命令diff A B >C ,一般A是原始文件，B是修改后的文件，C称为A的补丁文件。

　　	不加任何参数生成的diff文件格式是一种简单的格式，这种格式只标出了不一样的行数和内容。我们需要一种更详细的格式，可以标识出不同之处的上下文环境，
	这样更有利于提高patch命令的识别能力。这个时候可以用-c开关。	
　　2). patch的用法
　　patch用于根据原文件和补丁文件生成目标文件。还是拿上个例子来说
　　patch A C 就能得到B, 这一步叫做对A打上了B的名字为C的补丁。
　　之一步之后，你的文件A就变成了文件B。如果你打完补丁之后想恢复到A怎么办呢？
　　patch -R B C 就可以重新还原到A了。
　　所以不用担心会失去A的问题。
　　其实patch在具体使用的时候是不用指定原文件的，因为补丁文件中都已经记载了原文件的路径和名称。patch足够聪明可以认出来。但是有时候会有点小问题。比如一般对两个目录diff的时候可能已经包含了原目录的名字，但是我们打补丁的时候会进入到目录中再使用patch,着个时候就需要你告诉 patch命令怎么处理补丁文件中的路径。可以利用-pn开关，告诉patch命令忽略的路径分隔符的个数。举例如下：
　　A文件在 DIR_A下，修改后的B文件在DIR_B下，一般DIR_A和DIR_B在同一级目录。我们为了对整个目录下的所有文件一次性diff,我们一般会到DIR_A和DIR_B的父目录下执行以下命令
　　diff -rc DIR_A DIR_B >C
　　这个时候补丁文件C中会记录了原始文件的路径为 DIR_A/A
　　现在另一个用户得到了A文件和C文件，其中A文件所在的目录也是DIR_A。 一般，他会比较喜欢在DIR_A目录下面进行patch操作，它会执行	   
　　
	patch
　　但是这个时候patch分析C文件中的记录，认为原始文件是./DIR_A/A，但实际上是./A，此时patch会找不到原始文件。为了避免这种情况我们可以使用-p1参数如下
　　patch -p1	     
　　此时，patch会忽略掉第1个”/”之前的内容，认为原始文件是 ./A，这样就正确了。
　　最后有以下几点注意：
　　1). 一次打多个patch的话，一般这些patch有先后顺序，得按次序打才行。
　　2). 在patch之前不要对原文件进行任何修改
　　3). 如果patch中记录的原始文件和你得到的原始文件版本不匹配(很容易出现)，那么你可以尝试使用patch, 如果幸运的话，可以成功。大部分情况下，会有不匹配的情况，此时patch会生成rej文件，记录失败的地方，你可以手工修改。

	from: http://www.linuxsky.org/doc/admin/200712/213.html

* libvirt libvirt库 虚拟化库
	- 统一抽象虚拟化操作接口，避免不同hypervistor的学习成本
		比如，封装了xen API，这样通过统一的libvirt API即可管理xen hypervistor
	- 简介
		The virtualization API

		libvirt is:
		- A toolkit to interact with the virtualization capabilities of recent versions of Linux (and other OSes), see our project goals for details.
		- Free software available under the GNU Lesser General Public License.
		- A long term stable C API
		- A set of bindings for common languages
		- A CIM provider for the DMTF virtualization schema
		- A QMF agent for the AMQP/QPid messaging system
		
		libvirt supports:
		- The KVM/QEMU Linux hypervisor
		- The Xen hypervisor on Linux and Solaris hosts.
		- The LXC Linux container system
		- The OpenVZ Linux container system
		- The User Mode Linux paravirtualized kernel
		- The VirtualBox hypervisor
		- The VMware ESX and GSX hypervisors
		- The VMware Workstation and Player hypervisors
		- The Microsoft Hyper-V hypervisor
		- Virtual networks using bridging, NAT, VEPA and VN-LINK.
		- Storage on IDE/SCSI/USB disks, FibreChannel, LVM, iSCSI, NFS and filesystems
		
		libvirt provides:
		- Remote management using TLS encryption and x509 certificates
		- Remote management authenticating with Kerberos and SASL
		- Local access control using PolicyKit
		- Zero-conf discovery using Avahi multicast-DNS
		- Management of virtual machines, virtual networks and storage
		- Portable client API for Linux, Solaris and Windows

* xen 
	- vhd (virtual hard disk)
		Blktap2：Xen 4.0中所采用新的虚拟硬盘(VHD)提供了高性能虚拟机快照和克隆功能，此外还可以在不停止虚拟机处理的情况下做实时虚拟磁盘快照
	- 选择一种开源实现，以此为基础，利用其API或修改源码实现业务需求；需要对开源产品本身的深入研究，然后在此基础上开发相应工具，于自身业务系统对接，实现产品（包扩相关的方方面面的再封装和管理）。
	- tapdisk2
		tap_disk 结构抽象了 tapdisk2 所有支持的 disk 类型，如 vhd, qcow, img 等等

		ref: http://blog.csdn.net/majieyue
	- xen api
		通过xen开发的API，管理xen
		OR 通过修改源码，实现特殊业务
	- xen device 快照管理			    tapdisk2
		http://blog.csdn.net/majieyue/article/category/846491
	-  xen 快照 了解  虚拟机快照 【快照】
		虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
	由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
		chain 模式 比如 struts的intercepter ，插拔式
		
		http://server.it168.com/a2009/0723/611/000000611079.shtml
	- nc通过libvirt采集所属vm性能数据
	- 内存管理
		xm info 查看总内存和可使用的内存

		xm list
		也看查看dom0的内存数
			xm list -l 116
			查看domain的详细信息

		free -m 查看dom0的内存使用情况

		如果dom0占用过多内存，可以通过
		xm mem-set 0 xxx设置dom0的内存

		centos5 xen3
		创建domu时，报内存问题：

			网上搜索确定为xen的一个bug，可通过打patch解决。

	想到centos5上安装xen4，但Redhat 和Cent OS系统现在集成的是Xen3.x的版本，如果你不愿意折腾自行编译安装Xen4,下面教你用第三方Yum源快速安装xen4：
		$ cd /etc/yum.repos.d
		$ sudo wget http://www.gitco.de/repo/GITCO-XEN4.0.0_testing_x86_64.repo
		$ sudo yum update
		Dependencies Resolved
		==========================================================================================
		Package Arch Version Repository Size
		==========================================================================================
		Updating:
		xen x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 12 M
		xen-devel x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 408 k
		xen-libs x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 366 k
		Transaction Summary
		==========================================================================================
		Install 0 Package(s)
		Update 3 Package(s)
		Remove 0 Package(s)
		Total download size: 13 M
		Is this ok [y/N]: y
		grub.conf添加记录
		title CentOS (2.6.18-164.15.1.el5xen)
		root (hd0,0)
		kernel /xen.gz-4.0.0
		module /vmlinuz-2.6.18-164.15.1.el5xen ro root=/dev/VolGroup00/LogVol00 rhgb quiet
		module /initrd-2.6.18-164.15.1.el5xen.img
		重启即可
		$ sudo reboot
		from: http://bbs.linuxtone.org/thread-7259-1-1.html

		xen第三方源：http://www.gitco.de/repo/

* linux 安装方式
	系统集成了的软件安装
	源码编译安装
		如果需要打patch，则打好相应的patch后再编译安装
	第三方源安装
* linux c 开发			linux c/c++ c++ cpp
	- eclipse集成cpp开发环境，下载CDT版本的eclipse，或者安装CDT插件
		CDT插件：http://download.eclipse.org/tools/cdt/releases/helios
		eclipse for javaee版本，安装插件，再安装minGW

	- 以简单的c/c++例子学习
		http://www.oschina.net/code/list/2/cpp?show=month
		源码中国等技术网站，有用户上传的各类源码程序，是一个好的学习资源

	eg：keepalived目录结构
		bin		- 制作好的rpm包
		patch	- svn更新patch
		source	- 源码包
		spec - 用于制作rpm包
	* cpp
		 - 查看头文件的定义方法的具体实现时，可以从其new出来的实现类中查看对应方法的实现逻辑
		 - 内存分配方式
			内存的三种分配方式：
			1) 从静态存储区分配：此时的内存在程序编译的时候已经分配好，并且在程序的整个运行期间都存在。全局变量，static变量等在此存储。
			2) 在栈区分配：相关代码执行时创建，执行结束时被自动释放。局部变量在此存储。栈内存分配运算内置于处理器的指令集中，效率高，但容量有限。
			3) 在堆区分配：动态分配内存。用new/malloc时开辟，delete/free时释放。生存期由用户指定，灵活。但有内存泄露等问题。

			struts中属性的初始化，将引用的地址赋给结构体的成员

		 - vector
			vector容器类型
			vector容器是一个模板类，可以存放任何类型的对象（但必须是同一类对象）。vector对象可以在运行时高效地添加元素，并且vector中元素是连续存储的。
			vector的构造

			函数原型：
			template<typename T>
			explicit vector();                                 // 默认构造函数，vector对象为空
			explicit vector(size_type n, const T& v = T());    // 创建有n个元素的vector对象
			vector(const vector& x);
			vector(const_iterator first, const_iterator last);

			注：vector容器内存放的所有对象都是经过初始化的。如果没有指定存储对象的初始值，那么对于内置类型将用0初始化，对于类类型将调用其默认构造函数进行初始化
			（如果有其它构造函数而没有默认构造函数，那么此时必须提供元素初始值才能放入容器中）。

			举例：
			vector<string> v1;         // 创建空容器，其对象类型为string类
			vector<string> v2(10);     // 创建有10个具有初始值（即空串）的string类对象的容器
			vector<string> v3(5, "hello"); // 创建有5个值为“hello”的string类对象的容器
			vector<string> v4(v3.begin(), v3.end());  // v4是与v3相同的容器（完全复制）

			vector的操作（下面的函数都是成员函数）

			bool empty() const;                    // 如果为容器为空，返回true；否则返回false
			size_type max_size() const;            // 返回容器能容纳的最大元素个数
			size_type size() const;                // 返回容器中元素个数  
			size_type capacity() const;            // 容器能够存储的元素个数，有：capacity() >= size()  
			void reserve(size_type n);             // 确保capacity() >= n
			void resize(size_type n, T x = T());   // 确保返回后，有：size() == n；如果之前size()<n，那么用元素x的值补全。

			reference front();                     // 返回容器中第一个元素的引用（容器必须非空）
			const_reference front() const;                   
			reference back();                      // 返回容器中最后一个元素的引用（容器必须非空）
			const_reference back() const;

			reference operator[](size_type pos);   // 返回下标为pos的元素的引用（下标从0开始；如果下标不正确，则属于未定义行为。
			const_reference operator[](size_type pos) const; 
			reference at(size_type pos);           // 返回下标为pos的元素的引用；如果下标不正确，则抛出异常out_of_range
			const_reference at(size_type pos) const;
			    
			void push_back(const T& x);            // 向容器末尾添加一个元素          
			void pop_back();                       // 弹出容器中最后一个元素（容器必须非空）

			// 注：下面的插入和删除操作将发生元素的移动（为了保持连续存储的性质），所以之前的迭代器可能失效
			iterator insert(iterator it, const T& x = T());        // 在插入点元素之前插入元素（或者说在插入点插入元素）
			void insert(iterator it, size_type n, const T& x);     // 注意迭代器可能不再有效（可能重新分配空间）
			void insert(iterator it, const_iterator first, const_iterator last);

			iterator erase(iterator it);           // 删除指定元素，并返回删除元素后一个元素的位置（如果无元素，返回end()）
			iterator erase(iterator first, iterator last); // 注意：删除元素后，删除点之后的元素对应的迭代器不再有效。

			void clear() const;                    // 清空容器，相当于调用erase( begin(), end())

			void assign(size_type n, const T& x = T());   // 赋值，用指定元素序列替换容器内所有元素
			void assign(const_iterator first, const_iterator last);

			const_iterator begin() const;          // 迭代序列
			iterator begin();
			const_iterator end() const;
			iterator end();

			const_reverse_iterator rbegin() const;
			reverse_iterator rbegin();
			const_reverse_iterator rend() const; 
			reverse_iterator rend();

			vector对象的比较（非成员函数）

			针对vector对象的比较有六个比较运算符：operator==、operator!=、operator<、operator<=、operator>、operator>=。

			其中，对于operator==和operator!=，如果vector对象拥有相同的元素个数，并且对应位置的元素全部相等，则两个vector对象相等；否则不等。
			对于operator<、operator<=、operator>、operator>=，采用字典排序策略比较。

			注：其实只需要实现operator==和operator!=就可以了，其它可以根据这两个实现。因为，operator!= (lhs, rhs) 就是 !(lhs == rhs)，operator<=(lhs, rhs) 就是 !(rhs < lhs)，operator>(lhs, rhs) 
			就是 (rhs < lhs)，operator>=（lhs, rhs) 就是 !(lhs, rhs)。

			vector类的迭代器

			vector类的迭代器除了支持通用的前缀自增运算符外，还支持算术运算：it + n、it - n、it2 - it1。注意it2 - it1返回值为difference_type（signed类型）。

			注意，任何改变容器大小的操作都可能造成以前的迭代器失效。
		 - header file 头文件
				在C语言家族程序中，头文件被大量使用。一般而言，每个C++/C程序通常由头文件(header files)和定义文件(definition files)组成。头文件作为一种包含功能函数、
			数据接口声明的载体文件，用于保存程序的声明(declaration)，而定义文件用于保存程序的实现 (implementation)。而且 .c就是你写的程序文件。
				一般在一个应用开发体系中，功能的真正逻辑实现是以硬件层为基础，在驱动程序、功能层程序以及用户的应用程序中完成的。头文件的主要作用在于调用库功能，
			对各个被调用函数给出一个描述，其本身不包含程序的逻辑实现代码，它只起描述性作用，告诉应用程序通过相应途径寻找相应功能函数的真正逻辑实现代码。用户程序
			只需要按照头文件中的接口声明来调用库功能，编译器会从库中提取相应的代码。
				从以上结构图来看，头文件是用户应用程序和函数库之间的桥梁和纽带。在整个软件中，头文件不是最重要的部分，但它是C语言家族中不可缺少的组成部分。
			做一个不算很恰当的比喻，头文件就像是一本书中的目录，读者(用户程序)通过目录，可以很方便就查阅其需要的内容(函数库)。在一本书中，目录固然重要，但绝对
			不是一本书的核心的、最重要的部分。

		 - destructor 与构造器对应，用于过期时清理对应构造器未释放的对象
				When you use a constructor to create an object, the program undertakes the responsibility of
			tracking that object until it expires. At that time, the program automatically calls a special
			member function bearing the formidable title destructor. The destructor should clean up any
			debris, so it actually serves a useful purpose. For example, if your constructor uses new to allocate
			memory, the destructor should use delete to free that memory. The Stock constructor
			doesn’t do anything fancy like using new, so the Stock class destructor doesn’t really have any
			tasks to perform. In such a case, you can simply let the compiler generate an implicit, donothing
			destructor, which is exactly what the first version of the Stock class does.

			Unlike a constructor,
			a destructor must have no arguments. Thus, the prototype for a Stock destructor must be this:
			~Stock();
			Because a Stock destructor has no vital duties, you can code it as a do-nothing function:
			Stock::~Stock()
			{
			}
			However, just so that you can see when the destructor is called, you can code it this way:
			Stock::~Stock() // class destructor
			{
			cout << “Bye, “ << company << “!\n”;
			}

		 - 源码结合教程，快速看懂逻辑
			ClassName::~DestructorMethodName(){
			}
		 - 引用 参数值传递与址传递
			概念：
			引用引入了对象的一个同义词。定义引用的表示方法与定义指针相似，只是用&代替了*。引用（reference）是c++对c语言的重要扩充。
			引用就是某一变量（目标）的一个别名，对引用的操作与对变量直接操作完全一样。引用的声明方法：类型标识符 &引用名=目标变量名；　
			说明：
			（1）&在此不是求地址运算，而是起标识作用。
		　　（2）类型标识符是指目标变量的类型。
		　　（3）声明引用时，必须同时对其进行初始化。
		　　（4）引用声明完毕后，相当于目标变量名有两个名称，即该目标原名称和引用名，且不能再把该引用名作为其他变量名的别名。
			　　int a,&ra=a;
			　　a为目标原名称，ra为目标引用名。给ra赋值：ra=1; 等价于 a=1;
		　　（5）声明一个引用，不是新定义了一个变量，它只表示该引用名是目标变量名的一个别名，它本身不是一种数据类型，因此引用本身不占存储单元，系统也不给引用分配存储单元。故：对引用求地址，就是对目标变量求地址。&ra与&a相等。
		　　（6）不能建立数组的引用。因为数组是一个由若干个元素所组成的集合，所以无法建立一个数组的别名。
			
			引用参数：
				1) 传递可变参数
			　　传统的c中，函数在调用时参数是通过值来传递的，这就是说函数的参数不具备返回值的能力。
			　　所以在传统的c中，如果需要函数的参数具有返回值的能力，往往是通过指针来实现的
				2) 给函数传递大型对象
			　　当大型对象被传递给函数时，使用引用参数可使参数传递效率得到提高，因为引用并不产生对象的
			　　副本，也就是参数传递时，对象无须复制。

			引用返回值：只有类里面的方法可以返回引用，并且引用对象为类成员变量；对于一般的函数调用,返回引用将导致编译出错

			常引用：常引用声明方式：const 类型标识符&引用名=目标变量名；用这种方式声明的引用，不能通过引用对目标变量的值进行修改,从而使引用的目标成为const，
				达到了引用的安全性。

			引用和多态：引用是除指针外另一个可以产生多态效果的手段。这意味着，一个基类的引用可以指向它的派生类实例

		- 继承
			一个派生类可以从一个基类派生，也可以从多个基类派生。从一个基类派生的继承称为单继承；从多个基类派生的继承称为多继承。
			　　派生类的定义格式
			　　单继承的定义格式如下：
			　　class <派生类名>:<继承方式><基类名>
			　　{
			　　<派生类新定义成员>
			　　};
			　　其中，<派生类名>是新定义的一个类的名字，它是从<基类名>中派生的，并且按指定的<继承方式>派生的。<继承方式>常使用如下三种关键字给予表示：
			　　public 表示公有基类；
			　　private 表示私有基类；
			　　protected 表示保护基类；
			　　多继承的定义格式如下：
			　　class <派生类名>:<继承方式1><基类名1>,<继承方式2><基类名2>,…
			　　{
			　　<派生类新定义成员>
			　　};
			　　可见，多继承与单继承的区别从定义格式上看，主要是多继承的基类多于一个。
			　　如果省略继承方式，对'class'将采用私有继承，对'struct'将采用公有继承。

				from: http://baike.baidu.com/view/2129194.htm
		- 虚函数 virtual
			定义：在某基类中声明为 virtual 并在一个或多个派生类中被重新定 义的成员函数[1]
			语法：virtual 函数返回类型 函数名（参数表） { 函数体 }
			用途：实现多态性，通过指向派生类的基类指针，访问派生类中同名覆盖成员函数
			虚函数必须是基类的非静态成员函数，其访问权限可以是protected或public，在基类的类定义中定义虚函数的一般形式：
			　　class 基类名{
			　　.......
			　　virtual 返回值类型 将要在派生类中重载的函数名（参数列表）；
			　　}；
		
			动态联编规定，只能通过指向基类的指针或基类对象的引用来调用虚函数，其格式：
		　　1) 指向基类的指针变量名->虚函数名（实参表）
		　　2) 基类对象的引用名. 虚函数名（实参表）

		　　使用虚函数，我们可以灵活的进行动态绑定，当然是以一定的开销为代价。如果父类的函数（方法）根本没有必要或者无法实现，完全要依赖子类去实现的话，可以把此函数（方法）设为virtual 函数名=0 我们把这样的函数（方法）称为纯虚函数。
		　　如果一个类包含了纯虚函数，称此类为抽象类。
		- 简介
			美国AT&T贝尔实验室的本贾尼·斯特劳斯特卢普（Bjarne Stroustrup）博士在20世纪80年代初期发明并实现了C++（最初这种语言被称作“C with Classes”）。 
			一开始C++是作为C语言的增强版出现的，从给C语言增加类开始，不断的增加新特性。虚函数（virtual function）、运算符重载（operator overloading）、
			多重继承（multiple inheritance）、模板（template）、异常（exception）、RTTI、命名空间（name space）逐渐被加入标准。 
			
			1998年国际标准组织（ISO）颁布了C++程序设计语言的国际标准ISO/IEC 1988-1998。C++是具有国际标准的编程语言，通常称作ANSI/ISOC++
		- prototype define /function define /call function
		- 
			access names in a given namespace. The simplest way is to use
			::, the scope-resolution operator, to qualify a name with its namespace:
			Jack::pail = 12.34; // use a variable
			Jill::Hill mole; // create a type Hill structure
			Jack::fetch(); // use a function
		- prototype一般定义在头文件中，在cpp文件中具体实现；命名空间及其下面的类名字空间；
		- ->与::
			首先介绍一下C语言中的结构。对于一个结构来说， 
			struct MyStruct { 
			int member_a; 
			}; 
			如果有个变量MyStruct s，那么使用其中的成员元素时可以用 
			s.member_a = 1； 
			如果采用指针方法访问，比如MyStruct * ps，那么同样的访问必须用箭头号： 
			ps->member_a = 1; 

			::只用在类成员函数和类成员变量中。比如，声明一个类： 
			class CA { 
			public: 
			int ca_var; 
			int add(int a, int b); 
			int add(int a); 
			}; 
			那么在实现这个函数时，必须这样书写： 
			int CA::add(int a, int b) 
			{ 
			return a + b; 
			} 
			另外，双冒号也常常用于在类变量内部作为当前类实例的元素进行表示，比如: 
			int CA::add(int a) 
			{ 
			return a + ::ca_var; 
			} 
			表示当前类实例中的变量ca_var。

	* CEGUI

* 打开outlook的时候，错误提示“无法启动Microsoft Office Outlook。无法打开Outlook窗口”	* 修复 *系统修复　* 自修复
	    重启机器仍无法解决问题。
	    解决办法：
	    Win7：开始> 搜索程序和文件夹里》输入“Outlook.exe /resetnavpane”回车
	    WinXP：开始>执行>输入“Outlook.exe /resetnavpane”回车
	    然后正常启动就可以了。
	怕你输错，直接把我引号里的复制过去。

	ps：
		这个自修复功能还是蛮不错的

* IP转发 * ip forward ,在Linux中使能IP转发
	
	应用：iptables中配置ip转发规则，需要开启ip转发功能。

	Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统，使用下面命令：
	cat /proc/sys/net/ipv4/ip_forward
 	如果上述文件中的值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。
	要想打开IP转发功能，可以直接修改上述文件：
	echo 1 > /proc/sys/net/ipv4/ip_forward
	把文件的内容由0修改为1。禁用IP转发则把1改为0。
	上面的命令并没有保存对IP转发配置的更改，下次系统启动时仍会使用原来的值，要想永久修改IP转发，需要修改/etc/sysctl.conf文件，修改下面一行的值：
	net.ipv4.ip_forward = 1
	修改后可以重启系统来使修改生效，也可以执行下面的命令来使修改生效：
	sysctl -p /etc/sysctl.conf
	进行了上面的配置后，IP转发功能就永久使能了
	from: http://easwy.com/blog/archives/enable-ip-forward-on-linux/

	How to enable IP Forwarding in Linux
		By default any modern Linux distributions will have IP Forwarding disabled. This is normally a good idea, as most peoples will not need IP Forwarding, but if we are setting up a Linux router/gateway or maybe a VPN server (pptp or ipsec) or just a plain dial-in server then we will need to enable forwarding. This can be done in several ways that I will present bellow.
		Check if IP Forwarding is enabled
		We have to query the sysctl kernel value net.ipv4.ip_forward to see if forwarding is enabled or not:
		Using sysctl:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 0
		or just checking out the value in the /proc system:
		cat /proc/sys/net/ipv4/ip_forward
		0
		As we can see in both the above examples this was disabled (as show by the value 0).
		Enable IP Forwarding on the fly
		As with any sysctl kernel parameters we can change the value of net.ipv4.ip_forward on the fly (without rebooting the system):
		sysctl -w net.ipv4.ip_forward=1
		or
		echo 1 > /proc/sys/net/ipv4/ip_forward
		the setting is changed instantly; the result will not be preserved after rebooting the system.
		Permanent setting using /etc/sysctl.conf
		If we want to make this configuration permanent the best way to do it is using the file /etc/sysctl.conf where we can add a line containing net.ipv4.ip_forward = 1
		/etc/sysctl.conf:
		net.ipv4.ip_forward = 1
		if you already have an entry net.ipv4.ip_forward with the value 0 you can change that 1.
		To enable the changes made in sysctl.conf you will need to run the command:
		sysctl -p /etc/sysctl.conf
		On RedHat based systems this is also enabled when restarting the network service:
		service network restart
		and on Debian/Ubuntu systems this can be also done restarting the procps service:
		/etc/init.d/procps.sh restart
		Using distribution specific init scripts
		Although the methods presented above should work just fine and you would not need any other method of doing this, I just wanted to note that there are also other methods to enable IP Forwarding specific to some Linux distributions.
		For example Debian based distributions might use the setting:
		/etc/network/options:
		ip_forward=no
		set it to yes and restart the network service.
		Also RedHat distributions might set this using:
		/etc/sysconfig/network:
		FORWARD_IPV4=true
		and again restart the network service.
		Regardless the method you have used once you have completed this you can check it out using the same method shown above:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 1
		cat /proc/sys/net/ipv4/ip_forward
		1
		If the result is 1 then the Linux system will start forwarding IP packets even if they are not destined to any of its own network interfaces.
		ps. I was setting up a VPN dial-in server when I wrote this post 

* keepalived是VRRP的完美实现，因此在介绍keepalived之前，先介绍一下VRRP的原理。
	VRRP协议简介
	在现实的网络环境中，两台需要通信的主机大多数情况下并没有直接的物理连接。对于这样的情况，它们之间路由怎样选择？主机如何选定到达目的主机的下一跳路由，
	这个问题通常的解决方法有二种：
	·        在主机上使用动态路由协议(RIP、OSPF等)
	·        在主机上配置静态路由
	很明显，在主机上配置路态路由是非常不切实际的，因为管理、维护成本以及是否支持等诸多问题。配置静态路由就变得十分流行，但路由器(或者说默认网关default gateway)却经常
	成为单点。
	VRRP的目的就是为了解决静态路由单点故障问题。

	VRRP通过一竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。

	工作机制

	在一个VRRP虚拟路由器中，有多台物理的VRRP路由器，但是这多台的物理的机器并不能同时工作，而是由一台称为MASTER的负责路由工作，其它的都是BACKUP，MASTER并非一成不变，VRRP让每个VRRP路由器参与竞选，最终获胜的就是MASTER。MASTER拥有一些特权，比如 拥有虚拟路由器的IP地址，我们的主机就是用这个IP地址作为静态路由的。拥有特权的MASTER要负责转发发送给网关地址的包和响应ARP请求。

	VRRP通过竞选协议来实现虚拟路由器的功能，所有的协议报文都是通过IP多播(multicast)包(多播地址 224.0.0.18)形式发送的。虚拟路由器由VRID(范围0-255)和一组IP地址组成，对外表现为一个周知的MAC地址。所以，在一个虚拟路由 器中，不管谁是MASTER，对外都是相同的MAC和IP(称之为VIP)。客户端主机并不需要因为MASTER的改变而修改自己的路由配置，对他们来 说，这种主从的切换是透明的。

	在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP广告包(VRRPAdvertisement message)，BACKUP不会抢占MASTER，除非它的优先级(priority)更高。当MASTER不可用时(BACKUP收不到广告包)， 多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性。

	由于安全性考虑，VRRP包使用了加密协议进行加密。

	==========================================

	vrrp简介
	随着Internet的迅猛发展，基于网络的应用逐渐增多。这就对网络的可靠性提出了越来越高的要求。斥资对所有网络设备进行更新当然是一种很好的可靠性解决方案；
	但本着保护现有投资的角度考虑，可以采用廉价冗余的思路，在可靠性和经济性方面找到平衡点。

	  虚拟路由冗余协议就是一种很好的解决方案。在该协议中，对共享多存取访问介质（如以太网）上终端IP设备的默认网关(Default Gateway)进行冗余备份，
	  从而在其中一台路由设备宕机时，备份路由设备及时接管转发工作，向用户提供透明的切换，提高了网络服务质量。 

	一、协议概述

	  在基于TCP/IP协议的网络中，为了保证不直接物理连接的设备之间的通信，必须指定路由。目前常用的指定路由的方法有两种：一种是通过路由协议（比如：内部路由协议RIP和OSPF）
	  动态学习；另一种是静态配置。在每一个终端都运行动态路由协议是不现实的，大多客户端操作系统平台都不支持动态路由协议，
	  即使支持也受到管理开销、收敛度、安全性等许多问题的限制。因此普遍采用对终端IP设备静态路由配置，一般是给终端设备指定一个或者多个默认网关(Default Gateway)。
	  静态路由的方法简化了网络管理的复杂度和减轻了终端设备的通信开销，但是它仍然有一个缺点：如果作为默认网关的路由器损坏，所有使用该网关为下一跳主机的通信必然要中断。
	  即便配置了多个默认网关，如不重新启动终端设备，也不能切换到新的网关。采用虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)可以很好的避免静态指定网关的缺陷。

	  在VRRP协议中，有两组重要的概念：VRRP路由器和虚拟路由器，主控路由器和备份路由器。VRRP路由器是指运行VRRP的路由器，是物理实体，虚拟路由器是指VRRP协议创建的，
	  是逻辑概念。一组VRRP路由器协同工作，共同构成一台虚拟路由器。该虚拟路由器对外表现为一个具有唯一固定IP地址和MAC地址的逻辑路由器。处于同一个VRRP组中的路由器
	  具有两种互斥的角色：主控路由器和备份路由器，一个VRRP组中有且只有一台处于主控角色的路由器，可以有一个或者多个处于备份角色的路由器。VRRP协议使用选择策略
	  从路由器组中选出一台作为主控，负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。当由于某种原因主控路由器发生故障时，
	  备份路由器能在几秒钟的时延后升级为主路由器。由于此切换非常迅速而且不用改变IP地址和MAC地址，故对终端使用者系统是透明的。 

	二、工作原理

	  一个VRRP路由器有唯一的标识：VRID，范围为0—255。该路由器对外表现为唯一的虚拟MAC地址，地址的格式为00-00-5E-00-01-[VRID]。主控路由器负责对ARP请求用该MAC地址做应答。这样，无论如何切换，保证给终端设备的是唯一一致的IP和MAC地址，减少了切换对终端设备的影响。

	  VRRP控制报文只有一种：VRRP通告(advertisement)。它使用IP多播数据包进行封装，组地址为224.0.0.18，发布范围只限于同一局域网内。这保证了VRID在不同网络中可以重复使用。为了减少网络带宽消耗只有主控路由器才可以周期性的发送VRRP通告报文。备份路由器在连续三个通告间隔内收不到VRRP或收到优先级为0的通告后启动新的一轮VRRP选举。

	  在VRRP路由器组中，按优先级选举主控路由器，VRRP协议中优先级范围是0—255。若VRRP路由器的IP地址和虚拟路由器的接口IP地址相同，则称该虚拟路由器作VRRP组中的IP地址所有者；IP地址所有者自动具有最高优先级：255。优先级0一般用在IP地址所有者主动放弃主控者角色时使用。可配置的优先级范围为1—254。优先级的配置原则可以依据链路的速度和成本、路由器性能和可靠性以及其它管理策略设定。主控路由器的选举中，高优先级的虚拟路由器获胜，因此，如果在VRRP组中有IP地址所有者，则它总是作为主控路由的角色出现。对于相同优先级的候选路由器，按照IP地址大小顺序选举。VRRP还提供了优先级抢占策略，如果配置了该策略，高优先级的备份路由器便会剥夺当前低优先级的主控路由器而成为新的主控路由器。

	  为了保证VRRP协议的安全性，提供了两种安全认证措施：明文认证和IP头认证。明文认证方式要求：在加入一个VRRP路由器组时，必须同时提供相同的VRID和明文密码。适合于避免在局域网内的配置错误，但不能防止通过网络监听方式获得密码。IP头认证的方式提供了更高的安全性，能够防止报文重放和修改等攻击。

	三、 应用实例

	  最典型的VRRP应用：RTA、RTB组成一个VRRP路由器组，假设RTB的处理能力高于RTA，则将RTB配置成IP地址所有者，H1、H2、H3的默认网关设定为RTB。则RTB成为主控路由器，负责ICMP重定向、ARP应答和IP报文的转发；一旦RTB失败，RTA立即启动切换，成为主控，从而保证了对客户透明的安全切换。

	  在VRRP应用中，RTA在线时RTB只是作为后备，不参与转发工作，闲置了路由器RTA和链路L1。通过合理的网络设计，可以到达备份和负载分担双重效果。让RTA、RTB同时属于互为备份的两个VRRP组：在组1中RTA为IP地址所有者；组2中RTB为IP地址所有者。将H1的默认网关设定为RTA；H2、H3的默认网关设定为RTB。这样，既分担了设备负载和网络流量，又提高了网络可靠性。

	  VRRP协议的工作机理与CISCO公司的HSRP（Hot Standby Routing Protocol）有许多相似之处。但二者主要的区别是在CISCO的HSRP中，需要单独配置一个IP地址作为虚拟路由器对外体现的地址，这个地址不能是组中任何一个成员的接口地址。

	  使用VRRP协议，不用改造目前的网络结构，最大限度保护了当前投资，只需最少的管理费用，却大大提升了网络性能，具有重大的应用价值。

* linux
	- Linux调试工具strace和gdb常用命令小结
		---------
				strace（用来跟踪任何程序的系统调用）和 GDB 调试工具（用来在受控的环境中运行程序的功能齐全的调试工具）
				strace 专注于监控一个程序系统调用和它接受到的所有信号（与Unix系统上的truss是一样的），使用的是内核系统调用ptrace。另外，还有类似的ltrace（同样是
			基于ptrace的），它功能是能够跟踪进程的库函数调用。
				gdb比starce能做的事情更多，比如gdb可以获得堆栈跟踪信息，堆栈跟踪不仅会告诉你程序当前正在做什么，有底层的信息（如等待网络套接字），也有较高
			级别的信息（如正在执行什么类型的网络操作）。
			下面是使用过程中一些命令小结:
			
			strace调试工具
				strace工具用于跟踪进程执行时的系统调用和所接收的信号，包括参数、返回值、执行时间。在Linux中，用户程序要访问系统设备，必须由用户态切换到
			内核态，这是通过系统调用发起并完成的。
			strace常用参数：
			-c　　统计每种系统调用执行的时间、调用次数、出错次数，程序退出时给出报告
			-p pid　　跟踪指定的进程，可以使用多个-p同时跟踪多个进程
			-o filename　　strace默认输出到stdout，-o可以将输出写入到指定的文件
			-f　　跟踪由fork产生的子进程的系统调用
			-ff　　常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到各个filename.pid文件中
			-F　　尝试跟踪vfork子进程系统调用，注意：与-f同时使用时, vfork不被跟踪
			-e expr　　输出过滤表达式，可以过滤掉不想输出的strace结果
			-e trace=set　　指定跟踪set中的系统调用
			-e trace=network　　跟踪与网络有关的所有系统调用
			-e strace=signal　　跟踪所有与系统信号有关的系统调用
			-e trace=ipc　　跟踪所有与进程通讯有关的系统调用
			-e signal=set　　指定跟踪set中的信号
			-e read=set　　输出从指定文件中读出的数据，例如-e read=3,5
			-e write=set　　输出写入到指定文件中的数据，例如-e write=1
			-r　　打印每一个系统调用的相对时间
			-t　　在输出中的每一行前加上时间信息
			-tt　　在输出中的每一行前加上时间信息，时间精确到微秒级
			-ttt　　在输出中的每一行前加上时间信息，输出为相对时间
			-s　　指定每一行输出字符串的长度（默认为32）
			strace使用举例：
			strace -t whoami  #跟踪whoami可执行程序，每行输出结果前打印执行的时间
			strace -p 17151 -p 17152 -p 17153  #同时跟踪进程17151、17152、17153
			strace -f -e trace=read,write -p 17151 -o log  #跟踪进程17151及子进程中read和write系统调用，输出到log文件
			gdb调试工具
			GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具。gcc编译时加上-g参数，可以使可执行程序加上gdb调试信息。
			（1）info
			简写：i，列出gdb子命令的信息，如info break，info variables，info stack等。
			（2）list [file:]function
			简写：l，查看当前行的上下文，默认为10行，也可以设置在某个函数处列出源码。
			（3）edit [file:]function
			简写：e，编辑当前所在的行，也可以编辑某个函数的源码。
			（4）break [file:]function
			简写：b，设置断点，可以设置在某行或某个函数处。
			（5）run [arglist]
			简写：r，运行程序至断点处停住，run命令之后可以加上调试程序需要的参数。
			（6）next
			简写：n，单条语句执行。
			（7）continue
			简写：c，继续运行程序至下一个断点。
			（8）print
			简写：p，打印变量的值。
			（9）bt
			查看函数堆栈信息。
			（10）enter
			回车键，重复上一次调试命令。
			（11）help [name]
			显示指定的gdb命令的帮助信息。
			（12）quit
			简写：q，退出gdb。
			from: http://www.cnblogs.com/zhangzhang/archive/2013/01/07/2850355.html
		---------
	- strace命令
		---------
				strace 是一个非常简单的工具，用来跟踪可执行程序的系统调用(system call)。最简单的使用是，它追踪可行程序运行时的整个生命周期，输出每一个系统调用的名字，参数和返回值。 
			但是它还可以做更多的事情：
			 
			它可以基于系统调用或者系统调用组来过滤
			它可以通过计算制定系统调用的次数，花费的时间以及成功和失败的次数来描述系统调用的使用
			它可以追踪发送给进程的信号(signal)
			它可以通过进程id(pid)号加入到任意正在运行的进程上
			 
			如何使用
			 
			找出一个程序启动时读取了哪个配置文件
			 
			有的时候，你发发现，无论你如何修改配置文件，应用程序并没有按照你的思路去运行，这是什么原因？一个浅显但容易忽视的考虑是，应用程序启动时读取了你认为要读取的配置文件了吗？看下面的例子：
			 
			 $ strace php 2>&1 | grep php.ini          open("/usr/local/bin/php.ini", O_RDONLY) = -1 ENOENT (No such file or directory)          open("/usr/local/lib/php.ini", O_RDONLY) = 4          lstat64("/usr/local/lib/php.ini", {st_mode=S_IFLNK|0777, st_size=27,        ...}) = 0          readlink("/usr/local/lib/php.ini", "/usr/local/Zend/etc/php.ini",        4096) = 27          lstat64("/usr/local/Zend/etc/php.ini", {st_mode=S_IFREG|0664,st_size=40971, ...}) = 0    
			上述php程序程序会首先从/usr/local/bin/下读取php.ini文件，也许不是你想的首先从/usr/local/lib/下读取。
			上述的输出会很多，我们甚至可以通过参数来指定只追踪我们关心的系统调用，类似如下：
			 
			  $ strace -e open php 2>&1 | grep php.ini           open("/usr/local/bin/php.ini", O_RDONLY) = -1 ENOENT (No such file or         directory)           open("/usr/local/lib/php.ini", O_RDONLY) = 4  
			为什么程序没有打开我的文件？
			 
			每一个可执行程序读取文件时，如果权限不够，则会遭拒绝。而如果文件找不到，也并不会报错，除非你在程序里设置了错误处理，So，如果程序没有读取我的文件，我该如何跟踪呢？
			 
			 $ strace -e open,access 2>&1 |grep your-filename
			检查open()和access()系统调用的输出结果，看看是什么原因
			 
			进程此刻正在做什么？
			 
			你的程序突然消耗了大量的CPU，或者程序似乎被挂起了，那么我们通过进程的pid号看看此刻它正在做什么
			 
			 root@dev:~# strace -p 15427           Process 15427 attached - interrupt to quit           futex(0x402f4900, FUTEX_WAIT, 2, NULL           Process 15427 detached  
			通过跟踪，你知道程序挂起的原因是正在调用futex()。
			 
			程序的时间花在什么地方
			 
			你总是希望程序能够按照你的意愿去工作，也希望它能在正确的时间做正确的事情，甚至希望它是最优的，尽可能在程序运行的周期内，消耗的90%以上的资源都是在做需要做的事情，而不是简单的等待。也许，下面的这个指令可以帮上你的忙:
			 
			 root@dev:~# strace -c -p 11084
			 Process 11084 attached - interrupt to quit
			 Process 11084 detached
			 % time     seconds  usecs/call     calls    errors syscall
			 ------ ----------- ----------- --------- --------- ----------------
			  94.59    0.001014          48        21           select
			   2.89    0.000031           1        21           getppid
			   2.52    0.000027           1        21           time
			 ------ ----------- ----------- --------- --------- ----------------
			 100.00    0.001072                    63           total
			 root@dev:~# 
			如果你是跟踪的后台守护进程，可以通过上面的指令跟踪一段时间，然后按ctrl+c退出，strace会根据获得信息描述出上面的结果。
			上述的例子说明当前进程(postmaster)最要的时间花在等待select()函数上，在每调用一次select函数后，它分别调用getpid函数和time函数. 如果是非后台守护进程，那strace可以跟踪进程的开始至结束，类似下面这样：
			 
			 root@dev:~# strace -c >/dev/null ls
			 % time     seconds  usecs/call     calls    errors syscall
			 ------ ----------- ----------- --------- --------- ----------------
			  23.62    0.000205         103         2           getdents64
			  18.78    0.000163          15        11         1 open
			  15.09    0.000131          19         7           read
			  12.79    0.000111           7        16           old_mmap
			   7.03    0.000061           6        11           close
			   4.84    0.000042          11         4           munmap
			   4.84    0.000042          11         4           mmap2
			   4.03    0.000035           6         6         6 access
			   3.80    0.000033           3        11           fstat64
			   1.38    0.000012           3         4           brk
			   0.92    0.000008           3         3         3 ioctl
			   0.69    0.000006           6         1           uname
			   0.58    0.000005           5         1           set_thread_area
			   0.35    0.000003           3         1           write
			   0.35    0.000003           3         1           rt_sigaction
			   0.35    0.000003           3         1           fcntl64
			   0.23    0.000002           2         1           getrlimit
			   0.23    0.000002           2         1           set_tid_address
			   0.12    0.000001           1         1           rt_sigprocmask
			 ------ ----------- ----------- --------- --------- ----------------
			 100.00    0.000868                    87        10 total
			ls程序大部分时间花在读取目录条目上面。
			 
			为什么我不能连接到服务器？
			 
			调试进程不能连接到服务器是一个痛苦的事情，因为原因很多，比如DNS失效啦，连接被挂起啦，服务器返回异常数据啦，服务器本身异常啦，等等。一般网络调试方面，很多人会想到另外一个非常不错的工具-tcpdump。但它的参数太多了，而且你要从上百个连接进程中找出其中一个进程为什么不能连接恐怕是一件非常费力的工作。strace 其实也能在这种情景下帮上你的忙，它仅仅输出与系统调用相关的数据，从而可以让我们的注意力更集中。类似下面这样：
			 
			 $ strace -e poll,select,connect,recvfrom,sendto nc www.news.com 80
			 sendto(3, "\24\0\0\0\26\0\1\3\255\373NH\0\0\0\0\0\0\0\0", 20, 0, {sa_family=AF_NETLINK, pid=0, groups=00000000}, 12) = 20
			 connect(3, {sa_family=AF_FILE, path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
			 connect(3, {sa_family=AF_FILE, path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "\213\321\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\34\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "\213\321\201\200\0\1\0\1\0\1\0\0\3www\4news\3com\0\0\34\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 153
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "k\374\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\1\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "k\374\201\200\0\1\0\2\0\0\0\0\3www\4news\3com\0\0\1\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 106
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "\\\2\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\1\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "\\\2\201\200\0\1\0\2\0\0\0\0\3www\4news\3com\0\0\1\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 106
			 connect(3, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("216.239.122.102")}, 16) = -1 EINPROGRESS (Operation now in progress)
			 select(4, NULL, [3], NULL, NULL)        = 1 (out [3])
			那么，上述的输出，说明进程发生了什么呢？
			注意到这个进程尝试连接/var/run/nscd/socket连接了吗？这意味着nc程序首先会去连接NSCD- Name Service Cache Daemon - 它通常用于设置和NIS，YP，LDAP或者类似目录协议相关的域名查询配置上。在上述例子中，连接失败了。
			 
			接下来进程开始连接到DNS，这点可以从sin_port=htons(53)输出可以看出。你可以看到，它接着做了一个sendto()的调用，发出了一个包含www.news.com信息的DNS包。然后读取返回的包数据，不知什么原因，它做了三次这样的尝试。一个可能的原因是www.news.com是一条CNAME记录。多次请求可能是nc程序处理的一种方式。
			 
			最后，它总算是发起了connect()操作，注意这个操作的返回结果是EINPROGRESS，这意味着这个连接是非阻塞式的，nc希望继续，于是它调用了select()。
			 
			增加read,write调用到strace跟踪的系统调用列表里，可以让我们看到下面的一些结果：
			 
			 read(0, "test\n", 1024)                 = 5
			 write(3, "test\n", 5)                   = 5
			 poll([{fd=3, events=POLLIN, revents=POLLIN}, {fd=0, events=POLLIN}], 2, -1) = 1
			 read(3, "
			上述表示它从读取”test” + 标准输入的一行信息，然后写入网络连接，接着调用poll来等待回应，然后读取网络反馈的信息并写到标准输出。
			from: http://5iwww.blog.51cto.com/856039/771031
		---------
	- linux挂载硬盘	    * linux挂载硬盘
		添加磁盘
		找到磁盘
			fdisk -l
		分区
			fidsk /dev/xxx
			n
			w
			...
		格式化
			mkfs -t ext3 /dev/xxx
		创建目录，并挂载上面的分区
			mkdir /disk
			mount /dev/xxx /disk
		验证挂载情况
			df -k
		设置开机自动挂载
			vi /etc/fstab
			/dev/xxx               /disk                 ext3    defaults        0 0
		from: http://blog.csdn.net/tianlesoftware/article/details/5642883

	- nslookup
		DNS信息
		Nslookup is a program to query Internet domain name servers.  Nslookup has two modes: interactive and non-interactive. Interactive
		       mode allows the user to query name servers for information about various hosts and domains or to print a list of hosts in a domain.
		       Non-interactive mode is used to print just the name and requested information for a host or domain
	- lsof
		查看进程打开文件数
	- chown -hR admin /home/admin/
		修改文件/文件夹所属
		chown root /u        Change the owner of /u to "root".
		 chown root:staff /u  Likewise, but also change its group to "staff".
		 chown -hR root /u    Change the owner of /u and subfiles to "root".

	- 账户管理 用户管理
		centos用户&组权限&添加删除用户问题详解

		1) Linux操作系统是多用户多任务操作系统，包括用户账户和组账户两种
		细分用户账户（普通用户账户，超级用户账户）除了用户账户以为还有组账户所谓组账户就是用户账户的集合，centos组中有两种类型，私有组和标准组，当创建一个新用户时，若没有指定他所属的组，centos就建立以个和该用户相同的私有组，此私有组中只包括用户自己。标准组可以容纳多个用户，如果要使用标准组，那创建一个新的用户时就应该指定他所属于的组，从另外一方面讲，同一个用户可以属于多个组，例如某个单位的领导组和技术组，lik是该单位的技术主管，所以他就是属于领导组和技术组。当一个用户属于多个组时，其登录后所属的组是主组，其它组为附加组。

		 

		2) Linux环境下的账户系统文件主要在/etc/passwd, /etc/shadow,/etc/group,和/etc/gshadow四个文件。基本含义就不多说了重点说一下，root的uid是0，从1-499是系统的标准账户，普通用户从uid 500开始。

		 

		3) 使用命令管理账户
		useradd 选项  用户名//添加新用户

		usermod 选项  用户名//修改已经存在的用户

		userdel -r    用户名//删除用户表示自家目录一起删除。

		groupadd 选项  组名// 添加新组

		groupmod 选项  组名//修改已经存在的组

		groupdel 组名  //删除已经存在的特定组。

		 

		例子
		useradd zhh888 //添加一个用户zh888

		groupadd blog  //新建一个blog组

		useradd -G blog zh //表示创建一个新用户zh，同时加入blog附加组中。

		useradd -d /var/ftp/pub -M ftpadmin //创建一个新用户ftpadmin,指定目录是/var/ftp/pub,不创建自家目录（-M)

		usermod -G blog zh888 //表示将zh888添加到附加组blog中去。

		userdel ftpadmin //表示删除ftpadmin用户

		userdel -r zhh888 //表示删除zh888和/home中的目录一起删除。

		groupdel blog //表示删除blog组。

		 

		4) 口令管理及时效
		创建用户之后就要给用户添加密码，设置的口令的命令式passwd
		passwd 选项  用户名

		passwd -l 用户名账号名//禁止用户账户口令

		passwd -S 用户名//表示查看用户账户口令状态

		passwd -u 用户名//表示恢复用户账号

		passwd -d 用户名//表示删除用户账户口令

		 

		5) chage 命令是保护密码的时效这样可以防止其他人猜测密码的时间。

		chage 选项 用户名

		参数有 -m days, -M days ,-d days, -I days ,-E date, -W days,-l
		例子：#chage -m 2 -M 30 -W zhh//表示的意思是要求用户zhh两天内不能更改密码，并且口令最长存活期是30天，并且口令过期5天通知zhh

		 

		6) 用户和组的状态查询命令

		whoami //用于显示当前的用户名称。

		groups 用户名//表示显示指定的用户所属的组，如果没指定用户则是当前用户所属的组。

		id //表示显示当前用户的uid gid和用户所属的组列表。

		su - 用户//表示转换到其他用户，如果su表示切换到自己的当前用户。

		newgrp 组名//表示转换用户的当前组到指定的附加组，用户必须属于该组才能进行。

		 

		7) 更改属主和同组人

		有时候还需要更改文件的属主和所属的组。只有文件的属主有权更改其他属主和所属的组，用户可以把属于自己的文件转让给大家。改变文件属主用chown命令

		chown [-R] <用户名或组><文件或目录>

		chown zh888 files//把文件files属主改成zh888用户。

		chown zh888.zh888 files//将文件files的属主和组都改成zh888。

		chown -R zh888.zh888 files//将files所有目录和子目录下的所有文件或目录的主和组都改成zh888.


		8) 设置文件的目录和目录生成掩码

		用户可以使用umask命令设置文件默认的生成掩码。默认的生成掩码告诉系统创建一个文件或目录不应该赋予哪些权限。如果用户将umask命令放在环境文件.bash_profile中，就可以控制所有新建的文件和目录的访问权限。

		umask [a1a2a3]
		a1表示的是不允许属主的权限，a2表示的是不允许同组人的权限，a3代表不允许其他人的权限。

		umask 022//表示设置不允许同组用户和其他用户有写的权限。

		umask //显示当前的默认生成掩码。

		 

		9) 特殊权限的设置

		SUID SGID 和sticky-bit

		除了一般权限还有特殊的权限存在，一些特殊权限存在特殊的权限，如果用户不需要特殊权限一般不要打开特殊权限，避免安全方面的问题。具体的用法可以百度和google一下。

		希望自己整理出来的知识能帮助网友更好的理解centos用户&组权限&添加删除用户等问题。

		from: http://hi.baidu.com/phpmsn/item/9dc1831e40124d6c3f87ce08

	- ln创建软连接，即win系统的快捷方式，省去输入全路径去执行脚本的问题		  -tip-
		如对于/etc/init.d/httpd 这个脚本，可以创建ln到工作目录下，便于执行
		ln -s /etc/init.d/httpd ~/httpd

	- run level 运行级别
		 Linux下有7个运行级别：

		0 系统停机模式，系统默认运行级别不能设置为0，否则不能正常启动，机器关闭。
		1) 单用户模式，root权限，用于系统维护，禁止远程登陆，就像Windows下的安全模式登录。
		2) 多用户模式，没有NFS网络支持。
		3) 完整的多用户文本模式，有NFS，登陆后进入控制台命令行模式。
		4) 系统未使用，保留一般不用，在一些特殊情况下可以用它来做一些事情。例如在笔记本电脑的电池用尽时，可以切换到这个模式来做一些设置。
		5) 图形化模式，登陆后进入图形GUI模式，X Window系统。
		6) 重启模式，默认运行级别不能设为6，否则不能正常启动。运行init 6机器就会重启。

		运行级别原理：

		1).在目录/etc/rc.d/init.d下有许多服务器脚本程序，一般称为服务(service)
		2).在/etc/rc.d下有7个名为rcN.d的目录，对应系统的7个运行级别
		3).rcN.d目录下都是一些符号链接（即软链接）文件，这些链接文件都指向/etc/rc.d/init.d目录下的service脚本文件，命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位阿拉伯数字。
		4).系统启动时，会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件：对于以K开头的文件，系统将终止对应的服； 对于以S开头的文件，系统将启动对应的服务
		5).查看运行级别用：runlevel
		#表示当前系统运行在level 3模式下
		6).进入其它运行级别用：init N，如果init 3则进入终端模式，init 5则登录图形GUI模式
		#表示运行级别由3进入到5
		#再次输入init 3，则运行级别由5回到3
		7).另外init0为关机，init 6为重启系统
		 注意：输入init 0，系统会关机；输入init 6，系统会自动重启。这两个命令要非常小心！

		标准的Linux运行级别为3或5，如果是3的话，系统就在多用户状态；如果是5的话，则是运行着X Window系统。
		不同的运行级别有不同的用处，也应该根据自己的不同情形来设置。
		例如，如果丢失了root口令，那么可以让机器启动进入单用户状态来设置。
		1). 在启动后的GRUB界面输入e；
		2).光标选择kernel那一行，再次输入e；
		3).在最后添加“空格single”，回车；
		4).按b键进入单用户模式；
		5).通过passwd root命令，修改root的密码；
		6).重启系统。
	- 

* 分布式存储 * 云存储
	http://www.cnblogs.com/jason-one/archive/2008/12/17/1356461.html

* 单点问题，单点故障
	- 单点session问题，采用分布式session实现无单点故障的分布式session服务
		·memcache + 
* iptables * 防火墙 * linux防火墙设置
	--------
		 linux防火墙基础和管理设置iptables规则

		 一、linux防火墙基础
		防火墙分为硬件防火墙和软件防火墙。
		1.概述
		linux 防火墙体系主要工作在网络层，针对TCP/IP数据包实施过滤和限制，属于典型的包过滤防火墙。
		包过滤机制：netfilter
		管理防火墙规则命令工具：iptables
		netfilter 指linux内核中实现包过滤防火墙的内部结构，不依程序或文件的形式存在，属于“内核态”的防火墙功能体系
		iptables 指管理linux防火墙的命令工具，属于“用户态”的防火墙管理体系
		2.iptables的规则表、链结构
		iptables的作用在于为包过滤机制的实现提供规则，通过不同的规则作出不同的反应.
		iptables管理4个表、以及他们的规则链
		   filter,用于路由网络数据包。
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包从服务器流出
		FORWARD 网络数据包经服务器路由
		   nat,用于NAT表.NAT(Net Address Translation )是一种IP地址转换方法。
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		OUTPUT 网络数据包流出服务器
		   mangle,用于修改网络数据包的表，如TOS(Type Of Service),TTL(Time To Live),等
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包流出服务器
		FORWARD 网络数据包经由服务器转发
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		   raw, 用于决定数据包是否被跟踪机制处理
		OUTPUT 网络数据包流出服务器
		PREROUTING 网络数据包到达服务器时可以被修改
		3.数据包过滤匹配流程
		1>.规则表之间的优先顺序
		依次应用：raw、mangle、nat、filter表
		2>.规则链之间的优先顺序
		入站数据流向
		转发数据流向
		出站数据流向
		3>.规则链内部各条防火墙规则之间的优先顺序
		 
		二、管理和配置Iptables规则
		1.iptables的基本语法格式
		iptables [-t 表名] 命令选项 [链名] [条件匹配] [-] 目标动作或跳转
		表名链名用于指定iptables命令所做对象，未指定默认filter表，命令选项指于管理iptables规则的方式（插入、删除··）；条件匹配指定对条件的符合而处理；目标动作或跳转指定数据包的处理方式。
		2.管理iptables规则
		控制选项
		 -A 在链尾添加一条规则
		　-D 从链中删除一条规则
		 -I 在链中插入一条规则
		 -R 修改、替换某链的某规则
		 -L 列出某个链上的规则
		 -F 清空链，删除链上的所有规则
		 -N 创建一个新链
		 -X 删除某个规则链
		 -P 定义某个链的默认策略
		     -n 数字形式显示结果
		 -v 查看规则列表详细信息
		 -V 查看iptables命令工具版本
		 -h 查看命令帮助信息
		 -line-numbers 查看规则列表，显示顺序号
		增加、插入、删除和替换规则
		相关规则定义的格式为：
		iptables  [-t表名]  <-A | I | D | R> 链名 [规则编号] [-i | o 网卡名称] [-p 协议类型] [-s 源IP地址 | 源子网] [--sport 源端口号] [-d目标IP地址 | 目标子网] [--dport目标端口号] <-j动作>
		参数说明如下。
		[-t表名]：定义默认策略将应用于哪个表，可以使用filter、nat和mangle，如果没有指定使用哪个表，iptables就默认使用filter表。
		-A：新增加一条规则，该规则将会增加到规则列表的最后一行，该参数不能使用规则编号。
		-I：插入一条规则，原本该位置上的规则将会往后顺序移动，如果没有指定规则编号，则在第一条规则前插入。
		-D：从规则列表中删除一条规则，可以输入完整规则，或直接指定规则编号加以删除。
		-R：替换某条规则，规则被替换并不会改变顺序，必须要指定替换的规则编号。
		<链名>：指定查看指定表中哪个链的规则列表，可以使用INPUT、OUTPUT、FORWARD、PREROUTING、OUTPUT和POSTROUTING。
		[规则编号]：规则编号用于插入、删除和替换规则时用，编号是按照规则列表的顺序排列，规则列表中第一条规则的编号为1。
		[-i | o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出。网卡名称可以使用ppp0、eth0和eth1等。
		[-p 协议类型]：可以指定规则应用的协议，包含TCP、UDP和ICMP等。
		[-s 源IP地址 | 源子网]：源主机的IP地址或子网地址。
		[--sport 源端口号]：数据包的IP的源端口号。
		[-d目标IP地址 | 目标子网]：目标主机的IP地址或子网地址。
		[--dport目标端口号]：数据包的IP的目标端口号。 
		<-j动作>：处理数据包的动作，各个动作的详细说明可以参考表10-3。 
		1>.添加及插入规则
		   在Filter表的INPUT链的末尾添加一条防护墙规则
		[root@s2 ~]# iptables -t filter -A INPUT -p tcp -j ACCEPT
		   在Filter表的INPUT链中插入一条防护墙规则
		[root@s2 ~]# iptables -I INPUT -p udp -j ACCEPT
		   在在Filter表的INPUT链中插入一条防护墙规则（为链中第二条规则）
		[root@s2 ~]# iptables -I INPUT 2 -p icmp -j ACCEPT
		2>.查看规则表
		   查看Filter表的INPUT链中的所有规则，同时显示顺序号
		[root@s2 ~]# iptables -L INPUT --line-numbers
		Chain INPUT (policy ACCEPT)
		num  target     prot opt source               destination         
		1    ACCEPT     udp  --  anywhere             anywhere            
		2    ACCEPT     icmp --  anywhere             anywhere            
		3    REJECT     icmp --  anywhere             anywhere  
		   查看filter表各链中所有规则的详细信息，以数字形式显示地址和端口信息
		[root@s2 ~]# iptables -vnL
		Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
		pkts bytes target     prot opt in     out     source               destination         
		1189  154K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 ACCEPT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 REJECT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           reject-with icmp-port-unreachable 
		2449  221K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		3>.删除、清空规则
		   删除Filter表的INPUT链中的第2条规则
		[root@s2 ~]# iptables -D INPUT 2
		   清空filter表、nat表、mangle表各链中的所有规则	
		[root@s2 ~]# iptables -F
		[root@s2 ~]# iptables -t nat -F
		[root@s2 ~]# iptables -t mangle -F
		4>.设置规则链的默认策略
		最基本的两种策略为ACCEPT（允许）、DROP（丢弃）
		   将filter表中的FORWARD规则链的默认策略设为 DROP
		[root@s2 ~]# iptables -t filter -P FORWARD DROP
		   将filter表中的 OUTPUT规则链的默认策略设为 ACCEPT
		[root@s2 ~]# iptables -P OUTPUT ACCEPT
		5>.获得iptables相关选项用法的帮助信息
		   查看iptables命令中关于icmp协议的信息
		[root@s2 ~]# iptables -p icmp -h
		6>.新增、删除自定义规则链
		   清空raw表中自定义的所有规则链
		[root@s2 ~]# iptables -t raw -X
		3.条件匹配
		1>.通用条件匹配
		一般直接使用，而不依赖于其他的条件匹配及其扩展。常见匹配方式如下：
		协议匹配：用于检查数据包的网络协议
		拒绝进入防火墙的所有icmp协议数据包
		[root@s2 ~]# iptables -I INPUT -p icmp -j REJECT
		允许防火墙转发除icmp协议以外的所有数据包（“！”反取）	
		[root@s2 ~]# iptables -A FORWARD -p ! icmp -j ACCEPT
		[root@s2 ~]# iptables -L FORWARD
		Chain FORWARD (policy DROP)
		target     prot opt source               destination         
		ACCEPT    !icmp --  anywhere             anywhere    
		地址匹配：用于检查数据包的IP地址、网络地址。
		拒绝转发来自192.168.1.11主机的数据，允许来自192.168.0.0/24网段数据
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.11 -j REJECT
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT
		网络接口匹配：用于检查数据包从防火墙的哪个接口进入或离开
		丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP
		封堵IP地址段！并2小时后解锁
		[root@s2 ~]# iptables -I INPUT -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# iptables -I FORWARD -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# at now +2 hours
		at> iptables -D INPUT 1
		at> iptables -D FORWARD 1
		at> <EOT>
		job 1 at 2010-04-25 17:43
		2>.隐含条件匹配
		通常需要以指定的协议匹配为前提，对应功能由iptables自动装载内核。常见的隐含匹配方式如下：
		端口匹配：用于检查数据包的TCP或UDP端口号
		仅允许系统管理员从202.13.0.0/16网段使用SSH方式远程登录防火墙主机
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -j DROP
		允许本机开放TCP端口的 20 ~ 1024 提供的应用服务
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT
		[root@s2 ~]# iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT
		允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT
		[root@s2 ~]# iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT
		TCP标记匹配：用于检查数据包的TCP标记位
		拒绝从外网接口（eth1）直接访问防火墙本机的数据包，但允许响应防火墙TCP请求的数据包进入
		[root@s2 ~]# iptables -P INPUT DROP
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags SYN, RST, ACK SYN -j REJECT
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags ! --syn -j ACCEPT
		ICMP类型匹配：用于检查ICMP数据包
		禁止其他主机ping防火墙主机，但是允许防火墙能ping其他主机
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Request -j DROP
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Reply -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT
		显示条件匹配：需要额外的内核模块提供，因此需要手工指定匹配方式
		MAC地址匹配：主要检查数据包的源MAC地址
		[root@s2 ~]# iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP
		多端口匹配：检查数据包的源端口、目标端口时，用于匹配多个不连续的端口号。
		[root@s2 ~]# iptables -A INPUT -p tcp -m multiport --dport 20.21.24.11.1250:1280 -j ACCEPT
		多IP地址匹配：检查数据包的源地址、目标地址时，用于匹配一段范围内的IP地址
		[root@s2 ~]# iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP
		状态匹配：基于iptables的状态跟踪机制，检查数据包的连接状态
		禁止转发与正常TCP连接无关的非--syn请求数据包
		[root@s2 ~]# iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP
		4.数据包控制
		最常见处理方式;
		ACCEPT:允许数据包通过
		DROP：直接丢弃数据包，不给任何回应信息
		REJECT：拒绝数据包通过，必要时发个响应信息
		LOG: 记录日志信息，将数据包递给下一条规则
		对于尝试通过SSH方式登录防火墙主机的访问数据，记录日志信息并禁止访问
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j DROP
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j LOG
		用户自定义链：将数据传给用户自定义的链进行处理
		自定义一个链MYLAN 转发至192.168.1.0/24 网段数据包交给该链中的规则处理。
		[root@s2 ~]# iptables -t filter -N MYLAN
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A FORWARD -d 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A MYLAN -p icmp -j DROP
		SNAT:（源地址转换）修改数据包的源IP地址
		DNAT:（目标地址转换）修改数据包的目标IP地址
		 

		from: http://xiaozhuang.blog.51cto.com/4396589/874244

	--------
* redis
		redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。

* jboss
	- jboss启动失败一例
		jboss一个jmx相关的mbean注册时，由于identity不能识别，导致启动失败，需要本地回环(127.0.0.1)在/etc/hosts
		文件中有hostname执行本地回环的定义。
		如：
			127.0.0.1 identify-host-name
	- jboss简介
		1. Jboss Server 目录结构

		bin　　　　　　　　Start up scripts and start up configuration files available for Unix and Windows environments  
		bundles　　　　　　Location of OSGi bundles  
		docs/schema　　　　XML schema definition files  
		domain　　　　　　Configuration files, deployment content, and writable areas used by the domain mode processes run from this installation.  
		modules　　　　　　AS 7 is based on a modular classloading architecture. The various modules used in the server are stored here.  
		standalone　　　　Configuration files, deployment content, and writable areas used by the single standalone server run from this installation.  
		welcome-content　　Default Welcome Page content
		2. Standalone 目录结构

		1）configuration   
		　　Configuration files for the standalone server that runs off of this installation. All configuration information for the running server is located here and is the single place for configuration modifications for the standalone server.  
		2）data   
		　　Persistent information written by the server to survive a restart of the server  
		3）deployments   
		　　End user deployment content can be placed in this directory for automatic detection and deployment of that content into the server's runtime.   NOTE: The server's management API is recommended for installing deployment content. File system based deployment scanning capabilities remain for developer convenience.  
		4）lib/ext   
		　　Location for installed library jars referenced by applications using the Extension-List mechanism  
		5）log   
		　　standalone server log files  
		6）tmp   
		　　location for temporary files written by the server

		3. Jboss Rule

		JBoss Rules 的前身是Codehaus的一个开源项目叫Drools。最近被纳入JBoss门下，更名为JBoss Rules，成为了JBoss应用服务器的规则引擎。

		参考文档：
		https://docs.jboss.org/author/display/AS7/Getting+Started+Guide#GettingStartedGuide-GettingStartedwithJBossApplicationServer7
	- jboss 优化，服务器优化，系统优化

		   JBOSS访问缓慢，查看jboss的并发请求数及其TCP连接状态：
		netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
		LAST_ACK 5
		SYN_RECV 263
		CLOSE_WAIT 30
		ESTABLISHED 308
		FIN_WAIT1 499
		FIN_WAIT2 71
		CLOSING 20
		TIME_WAIT 19070
		检查发现TIME_WAIT 状态链接很高, 这样就需要对内核做些优化，
		Vi /etc/sysctl.conf
		net.ipv4.tcp_fin_timeout = 30
		net.ipv4.tcp_keepalive_time = 300
		net.ipv4.tcp_syncookies = 1
		net.ipv4.tcp_tw_reuse = 1
		net.ipv4.tcp_tw_recycle = 1
		net.core.netdev_max_backlog =8096
		net.ipv4.ip_local_port_range = 1024    65000
		net.ipv4.tcp_max_tw_buckets = 5000
		 
		修改完记的使用sysctl -p 让它生效

		以上参数的注解
		/proc/sys/net/ipv4/tcp_tw_reuse
		该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接。

		/proc/sys/net/ipv4/tcp_tw_recycle
		recyse是加速TIME-WAIT sockets回收

		对tcp_tw_reuse和tcp_tw_recycle的修改，可能会出现.warning, got duplicate tcp line warning, got BOGUS tcp line.上面这二个参数指的是存在这两个完全一样的TCP连接，这会发生在一个连接被迅速的断开并且重新连接的情况，而且使用的端口和地址相同。但基本上这样的事情不会发生，无论如何，使能上述设置会增加重现机会。这个提示不会有人和危害，而且也不会降低系统性能，目前正在进行工作

		/proc/sys/net/ipv4/tcp_keepalive_time
		表示当keepalive起用的时候,TCP发送keepalive消息的频度。缺省是2小时

		/proc/sys/net/ipv4/tcp_fin_timeout    最佳值和BSD一样为30
		fin_wait1状态是在发起端主动要求关闭tcp连接，并且主动发送fin以后，等待接收端回复ack时候的状态。对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。

		/proc/sys/net/core/netdev_max_backlog
		该文件指定了，在接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
		net.ipv4.ip_local_port_range = 1024    65000
		表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
		 
		net.ipv4.tcp_max_tw_buckets = 5000
		表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。
		 
		 
		其它查看连接数据命令：
		1)统计80端口连接数
		netstat -nat|grep -i "80"|wc -l
		1
		2）统计httpd协议连接数
		ps -ef|grep httpd|wc -l
		1
		3）、统计已连接上的，状态为“established'
		netstat -na|grep ESTABLISHED|wc -l
		2
		4)、查出哪个IP地址连接最多,将其封了.
		netstat -na|grep ESTABLISHED|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
		 
		netstat -na|grep SYN|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
		iptables的设置:
		 
		防止同步包洪水（Sync Flood）
		# iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT
		也有人写作
		#iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT
		--limit 1/s 限制syn并发数每秒1次，可以根据自己的需要修改
		防止各种端口扫描
		# iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j
		ACCEPT
		Ping洪水攻击（Ping of Death）
		# iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT
		 
		 
		修改JBOSS连接池：
		Vi /usr/local/jboss/server/default/deploy/jbossweb-tomcat55.sar/server.xml
		<Connector port="80" address="${jboss.bind.address}"
			 maxThreads="500" strategy="ms" maxHttpHeaderSize="8192"
			 emptySessionPath="true" maxKeepAliveRequests="1"
			 enableLookups="false" redirectPort="8443" acceptCount="100"
			 connectionTimeout="10000" disableUploadTimeout="true"/>
		 
		 
		修改JBOSS内存：
		Vi /usr/local/jboss/bin/run.conf
		if [ "x$JAVA_OPTS" = "x" ]; then
		   JAVA_OPTS="-Xms1024m -Xmx2048m -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.rmi.dgc.server.gcInterval=3600000"
		fi
		 

		from:http://kerry.blog.51cto.com/172631/161179

* What Is a Socket	  * socket socket http socket与http
		A socket is one end-point of a two-way communication link between two programs running on the network. 
	Socket classes are used to represent the connection between a client program and a server program. The java.net package provides 
	two classes--Socket and ServerSocket--that implement the client side of the connection and the server side of the connection, respectively. 

	socket与http关系
		http基于socket
			socket是点对点通讯的基础，一个抽象接口层；http是在socket层上面在封装，根据http协议定义的编码要求来收发；即也可自行根据socket实现自定义的通讯协议
			比如定义 nuwa://xxx协议，迅雷的thunder://，电驴ed2k://|file|
			·例子：http://www.cnblogs.com/sunwei2012/archive/2010/04/06/1705634.html 自定义应用层通信协议
				通信协议精确地定义了双方通信控制信息和解释信息：发送方能将特定信息（文本、图片、音频、视频）按协议封装成指定格式的数据包，最终以串行化比特流在网络上传输；接收方接收到数据包后，根据协议将比特流解析为本地化数据，从而获取对方发送过来的原始信息。
				通信协议包括三个要素：
				（1）语法：规定了信息的结构和格式；
				（2）语义：表明信息要表达的内容；
				（3）同步：规则涉及双方的交互关系和事件顺序。
				整个计算机网络的实现体现为协议的实现，TCP/IP协议是Internet互联网的核心协议。

* log * log4j
	- log4j调优
		log4j输出log到文件时，使用缓冲输出
			log4j.appender.monitorAppender.BufferedIO=true
			log4j.appender.monitorAppender.BufferSize=8192
		组装输出内容之前可对logger的输出级别先进行判断而不要完全依赖log4j控制，因为组装输出日志内容也是要损耗效率的。
			//若log4j并未开启info级日志记录，直接返回
			if(!monitorLogger.isInfoEnabled()){
				return;
			}
			StringBuilder log = new StringBuilder();
			logSql.append(logPk+" ");
		ref: http://www.blogjava.net/conans/articles/345083.html


	- isDebugEnabled()的判断什么时候需要？
		if (replace && log.isDebugEnabled())
			log.debug("Expanded " + before + " to " + repository);
		这个时候，需要判断isDebugEnabled()，可以减少字符串拼接的操作；

		log.debug("Failed to operate")
		此时不需要，debug()方法中已判断了日志级别，不过还是会进入debug()方法处理一下再出来，若性能要求高，还是和上面一样，判断isDebugEnabled()再输出log。

	- log4j配置时
		定义appender，定义logger
		自定义的appender注意类全路径不要搞错（服务器启动时console会报提示）
		对于一些未定义的日志可统一在log4j.xml的root标签中记录，去掉报找不到appender的warn
		sql的日志，需要定义logger指向到java.sql
	- logger.error(e) vs logger.error("xxx",e)
	看log4j的error方法说明，直接传对象接收的是message消息对象，如何给的是非message对象，可能没有重写tostring方法，输出的日志内容为对象而不是异常的内容。

* nginx
	  ---------
	  ...
		   server {
			listen       80;
			server_name  openapi.aliyun.com;

			charset UTF-8;

			proxy_connect_timeout 600;
			proxy_read_timeout 600;
			proxy_send_timeout 600;

			#access_log  logs/host.access.log  main;

			if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
			{ 
			  set $domain $1; 
			  set $new_uri /openapi/$domain$request_uri;
			} 

			location /{
			    proxy_set_header        X-Real-IP $remote_addr;
			    proxy_set_header        Host $host;
			    proxy_pass http://127.0.0.1:8080$new_uri;
			
			}

		       location /slb/api{
				   proxy_set_header        X-Real-IP $remote_addr;
				   proxy_set_header        Host $host;
	...
	---------
	部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
			
	小结：
			当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
		启动失败了，即服务器是起来了，但应用却没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
		ok的情况下极可能就是应用启动失败）。
			这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。

* concurrent包 ，java concurrent	       * 并发 * 同步 * java并发/同步
	- 锁
		synchronized方法（锁定方法所在的实例化对象，若实例化对象不为同一个，则不能同步）
		synchronized块（以声明的锁对象进行锁定，若锁的实例不同则不能同步）

	- java concurrent 探秘
			我们都知道，在JDK1.5之前，Java中要进行业务并发时，通常需要有程序员独立完成代码实现，当然也有一些开源的框架提供了这些功能，
		但是这些依然没有JDK自带的功能使用起来方便。而当针对高质量Java多线程并发程序设计时,为防止死蹦等现象的出现，比如使用java之前的wait()、notify()和synchronized等，
		每每需要考虑性能、死锁、公平性、资源管理以及如何避免线程安全性方面带来的危害等诸多因素，往往会采用一些较为复杂的安全策略，加重了程序员的开发负担.万幸的是，
		在JDK1.5出现之后，Sun大神（Doug Lea）终于为我们这些可怜的小程序员推出了java.util.concurrent工具包以简化并发完成。开发者们借助于此，将有效的减少竞争条件（race conditions）
		和死锁线程。concurrent包很好的解决了这些问题，为我们提供了更实用的并发程序模型。

		Executor                  ：具体Runnable任务的执行者。
		ExecutorService           ：一个线程池管理者，其实现类有多种，我会介绍一部分。我们能把Runnable,Callable提交到池中让其调度。
		Semaphore                 ：一个计数信号量
		ReentrantLock             ：一个可重入的互斥锁定 Lock，功能类似synchronized，但要强大的多。
		Future                    ：是与Runnable,Callable进行交互的接口，比如一个线程执行结束后取返回的结果等等，还提供了cancel终止线程。
		BlockingQueue             ：阻塞队列。
		CompletionService         : ExecutorService的扩展，可以获得线程执行结果的
		CountDownLatch            ：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。
		CyclicBarrier             ：一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点
		Future                    ：Future 表示异步计算的结果。
		ScheduledExecutorService ：一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。

		接下来逐一介绍
		from：http://www.cnblogs.com/aurawing/articles/1887056.html
* volatile / Java中的volatile关键字	 
	关于volatile
		我们知道，在Java中设置变量值的操作，除了long和double类型的变量外都是原子操作，也就是说，对于变量值的简单读写操作没有必要进行同步。这在JVM 1.2之前，Java的内存模型实现
	总是从主存读取变量，是不需要进行特别的注意的。而随着JVM的成熟和优化，现在在多线程环境下volatile关键字的使用变得非常重要。在当前的Java内存模型下，线程可以把变量保存在
	本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，
	造成数据的不一致。要解决这个问题，只需要像在本程序中的这样，把该变量声明为volatile（不稳定的）即可，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。
	一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。
	
	Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 
	Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才与共享成员变量的原始值对比。 
	这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。 
	而volatile关键字就是提示VM：对于这个成员变量不能保存它的私有拷贝，而应直接与共享成员变量交互。 
	使用建议：在两个或者更多的线程访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，不必使用。 
	由于使用volatile屏蔽掉了VM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。
	from: http://www.cnblogs.com/xwdreamer/archive/2012/05/13/2498615.html
* svn 代码
	版本控制，代码管理，使用
	整个SVN代码管理可以看做一棵倒置的树

		1、Branches做为分支，它就像树枝，最终还是合并到主干，用来控制新需求、需求变更、BUG修改等，每个分支都有一个专用的目的，分支编号将跟特定目标关系与需求管理文档内容关联。
		2、Tags做为里程碑，它就像树根，每一次Tag的生成都要根深蒂固，才能站稳，用来控制分支测试版本和生产正式版本，标志着一个时期。
		3、Trunk做为主干，它就是雄壮的树干，由它来生出树枝，扎下树根，他的作用是保存着最稳定，功能最全面的程序代码，用来管理整个项目。
	- svn 命令
		svn log -r486678 查看某个reversion log

* tddl	  取模，拆分，定位
	参考: http://rdc.taobao.com/team/jm/archives/1645

search in index find pdf 
* 平台，产品线，生态
	一个好的平台，衍生出多种产品线，构建良好的生态
* OSGi * osgi
	- bundle之间接口调用前，需要在MANIFEST.MF中导入要使用的bundle（根据发布bundle的MANIFEST.MF文件描述来确定）。
		Bundle-SymbolicName: example
		Export-Package: example.service

		Require-Bundle: example
	- OSGI练习
		通过eclipse的plug-in项目，实现采用Equinox来实验
		一个OSGI框架+N个bundle

		参考：
			http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-osgi/index.html		基于 OSGi 的面向服务的组件编程
			http://www.ibm.com/developerworks/cn/opensource/os-ecl-osgibdev/			利用 Eclipse 开发基于 OSGi 的 Bundle 应用
				bundle间的引用关系，需要在manifest,mf文件中定义
				将bundle打成jar包，便于osgi框架安装：osgi>install file:///c:\osgi\exampleclient.jar
				此例子中，client启动后需要接受console的输入，故不要自动启动，否则可能使用不了console；可以先启动example的nameservice服务后，再手动启动client，此时
				console即可接收输入。
								       
	- 	（OOSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。
	OSGi Alliance是一个由Sun Microsystems、IBM、爱立信等于1999年3月成立的开放的标准化组织，最初名为Connected Alliance。该组织及其标准原本主要目的在于使服务提供商通过住宅网关，
	为各种家庭智能设备提供各种服务。目前该平台逐渐成为一个为室内、交通工具、移动电话和其他环境下的所有类型的网络设备的应用程序和服务进行传递和远程管理的开放式服务平台。
	该规范和核心部分是一个框架 ，其中定义了应用程序的生命周期模式和服务注册。基于这个框架定义了大量的OSGi服务： 日志、配置管理、偏好，HTTP（运行servlet）、XML分析、
	设备访问、软件包管理、许可管理、星级、用户管理、IO连接、连线管理、Jini和 UPnP。
	这个框架实现了一个优雅、完整和动态的组件模型。应用程序（称为bundle）无需重新引导可以被远程安装、启动、升级和卸载（其中Java包／类的管理被详细定义）。
	API中还定义了运行远程下载管理政策的生命周期管理。服务注册允许bundles去检测新服务和取消的服务，然后相应配合。
	OSGi原先关注于服务网关，其实可用于多个方面。现在OSGi规范已经用于从移动电话到开源的Eclipse（其中包括了与IBM的OSGi框架SMF兼容的开源版本）。
	OSGi服务平台的应用包括：服务网关、 汽车、移动电话、 工业自动化、建筑物自动化、 PDA 网格计算、娱乐（如iPronto）、和 IDE。
	OSGi规范是由成员通过公开的程序开发，对公众免费而且没有许可证限制。但是OSGi Alliance的兼容性程序只对成员开放，目前有12个兼容的实现。
	2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。ProSyst是面向OSGi开发者的Eclipse插件。
	2003年10月， 诺基亚、摩托罗拉，ProSyst 和其他OSGi成员组建了Mobile Expert Group (MEG)为下一代智能手机规范业务平台，做为对 MIDP 和CDC的补充。
	
	eclipse 3.7.2提供了OSGI控制台
	- osgi初探 例子
		http://www.cnblogs.com/bjzhanghao/archive/2007/11/21/967320.html 利用OSGi DS实现可配置Web应用程序初探
* IaaS（Infrastructure as a Service），即基础设施即服务

* BVT (Build Verification Test)
	　　BVT是在所有开发工程师都已经检入自己的代码，项目组编译生成当天的版本之后进行，主要目的是验证最新生成的软件版本在功能上是否完整，主要的软件特性是否正确。
	如无大的问题，就可以进行相应的功能测试。BVT优点是时间短，验证了软件的基本功能。缺点是该种测试的覆盖率很低。因为运行时间短，不可能把所有的情况都测试到。

	自动化测试：通过脚本语言，比如python（丰富的库），建立各个测试用例，配置测试数据，编写测试逻辑，自动化测试，并输出结果。

* cgroups
	What are CGroups?
		You might be wondering at this point what CGroups actually are ? At a high level, it is a generic mechanism the kernel provides for grouping of processes and applying controls to those groups. 
	The grouping is done via a virtual filesystem called “cgroup”. Within this filesytem, each directory defines a new group. Thus groups can be arranged to form an arbitrarily nested hierarchy simply 
	by creating new sub-directories.

		Tunables within a cgroup are provided by what the kernel calls ‘controllers’, with each controller able to expose one or more tunable or control. When mounting the cgroups filesystem it is possible to
	indicate what controllers are to be activated. This makes it possible to mount the filesystem several times, with each mount point having a different set of (non-overlapping) controllers. Why might separate 
	mount points be useful ? The key idea is that this allows the administrator to construct differing group hierarchies for different sets of controllers/tunables.

	memory: Memory controller
	    Allows for setting limits on RAM and swap usage and querying cumulative usage of all processes in the group
	cpuset: CPU set controller
	    Binding of processes within a group to a set of CPUs and controlling migration between CPus
	cpuacct: CPU accounting controller
	    Information about CPU usage for a group of processes
	cpu: CPU schedular controller
	    Controlling the priorization of processes in the group. Think of it as a more advanced nice level
	devices: Devices controller
	    Access control lists on character and block devices
	freezer: Freezer controller
	    Pause and resume execution of processes in the group. Think of it as SIGSTOP for the whole group
	net_cls: Network class controller
	    Control network utilization by associating processes with a ‘tc’ network class

		This isn’t the blog post to go into fine details about each of these controllers & their capabilities, the high level overview will do. Suffice to say that at this time, the libvirt LXC driver (container based virtualization) 
	will use all of these controllers except for net_cls and cpuset, while the libvirt QEMU driver will only use the cpu and devices controllers. 

* SQL分页语句 分页
	- mysql通过limit语句实现分页；
				  
	- sql server分页
		摘自网络
		---------
			有关分页 SQL 的资料很多，有的使用存储过程，有的使用游标。本人不喜欢使用游标，我觉得它耗资、效率低；使用存储过程是个不错的选择，
			因为存储过程是经过预编译的，执行效率高，也更灵活。先看看单条 SQL 语句的分页 SQL 吧。

			方法1：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id NOT IN
				  (
				  SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
				  )
			ORDER BY id

			方法2：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id >
				  (
				  SELECT ISNULL(MAX(id),0) 
				  FROM 
					(
					SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
					) A
				  )
			ORDER BY id

			方法3：
			适用于 SQL Server 2005
			SELECT TOP 页大小 * 
			FROM 
				(
				SELECT ROW_NUMBER() OVER (ORDER BY id) AS RowNumber,* FROM table1
				) A
			WHERE RowNumber > 页大小*(页数-1)

			说明，页大小：每页的行数；页数：第几页。使用时，请把“页大小”和“页大小*(页数-1)”替换成数字。

			其它的方案：如果没有主键，可以用临时表，也可以用方案三做，但是效率会低。
			建议优化的时候，加上主键和索引，查询效率会提高。

			通过SQL 查询分析器，显示比较：我的结论是:
			分页方案二：(利用ID大于多少和SELECT TOP分页）效率最高，需要拼接SQL语句
			分页方案一：(利用Not In和SELECT TOP分页)   效率次之，需要拼接SQL语句
			分页方案三：(利用SQL的游标存储过程分页)    效率最差，但是最为通用
		    ---------

* LVM
		LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分
	区管理的灵活性。前面谈到，LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。
	物理卷（physical volume）物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备（如RAID），是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，
	却包含有与LVM相关的管理参数。
	　　Linux用户安装Linux操作系统时遇到的一个最常见的难以决定的问题就是如何正确地给评估各分区大小，以分配合适的硬盘空间。而遇到出现 某个分区空间耗尽时，
	解决的方法通常是使用符号链接，或者使用调整分区大小的工具（比如PatitionMagic等），但这都只是暂时解决办法，没有根本解决问题。随着Linux的逻辑盘卷管理功能的出现，
	这些问题都迎刃而解，用户在无需停机的情况下方便地调整各个分区大小。	

	lvm howto：http://blog.haohtml.com/archives/10298

* VNC
	
	- VNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC是一款优秀的远程控制工具软件，由著名的AT&T的欧洲研究实验室开发的。
	VNC是在基于UNIX和Linux操作系统的免费的开放源码软件，远程控制能力强大，高效实用，其性能可以和Windows和MAC中的任何远程控制软件媲美。 
	在Linux中，VNC包括以下四各命令：vncserver，vncviewer，vncpasswd，和vncconnect。大多数情况下我只需要其中的两个命令：vncserver和vncviewer。
	
	TightVNC
	　　应用平台： Win9x/NT/2000/XP/2003 Linux/unix
	　　自由软件，遵循GPL条款，源代码开源，个人、企业使用均无任何限制。
		vnc的加强，短小精悍，功能强大。
	- 配置vnc访问xen的vm
		有时需要通过主机hvc0登录到虚拟机中，有时需要借助vnc登录虚拟机进行管理，这样就需要有相应的配置保证两者都能正常输出。具体的配置如下文。
		
		hvc是Xen虚拟化技术引入的对虚拟机进行控制的虚拟console，在虚拟机的配置中自动完成；VNC显示VGA硬件输出，可以完成对虚拟机的管理。
		在Xen虚拟化技术中hvc则是自带的，而VNC的输出需要借助qemu-dm来模拟VGA硬件。		
		
		hvc0的输出不需要调整，只需要在虚拟机中配置串口输出，就能够使得hvc0在串口输出；而tty1通过VGA输出，用VNC显示。具体配置如下，

		在虚拟机中完成：

		#vi  /boot/grub/menu.lst    视虚拟机的启动文件而变动

		serial --unit=0 --speed=38400 --word=8 --parity=no --stop=1

		在内核行添加如下的参数

		console=ttyS0,38400n8

		在/etc/securetty 中保证有ttyS0

		#echo ‘ttyS0’ >> /etc/securetty

		修改/etc/inittab保证有以下的内容

		#vi /etc/inittab

		1:2345:respawn:/sbin/getty 38400 hvc0

		2:2345:respawn:/sbin/getty 38400 tty1

		然后将虚拟机重启，就可以同时在VNC和host主机中访问虚拟机了。

* RPC
	 - 通过socket进行RPC调用
		 --------
		 ...
			OutputStream localOutputStream = paramSocket.getOutputStream();

			BufferedWriter localBufferedWriter = new BufferedWriter(new OutputStreamWriter(localOutputStream));
			localBufferedWriter.write("GET /?address=");
			localBufferedWriter.write(this.mRemoteAddress);
			localBufferedWriter.write("&method=");
			localBufferedWriter.write(MethodName);
			localBufferedWriter.write("&timeout=");
			localBufferedWriter.write(Integer.toString(this.mRpcTimeout));
			localBufferedWriter.write("&client=");
			localBufferedWriter.write(this.mRpcClientName);
			localBufferedWriter.write("&token=");
			localBufferedWriter.write(this.mRpcToken);
			localBufferedWriter.write(" HTTP/1.1\r\n");
			localBufferedWriter.write("HOST: *\r\n");
			localBufferedWriter.write("Content-Length: ");
			localBufferedWriter.write(Integer.toString(this.mRpcParameter.length));
			localBufferedWriter.write("\r\nConnection: Keep-Alive\r\n");
			localBufferedWriter.write("\r\n");
			localBufferedWriter.flush();

			localOutputStream.write(this.mRpcParameter);
			localOutputStream.flush();

			InputStream localInputStream = paramSocket.getInputStream();
			paramSocket.setSoTimeout(this.mRpcTimeout);
		...
		--------

	 - 介绍：
			RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，
		 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。
		 在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易
			RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程
		发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息的到达为止。
		当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程
		接收答复信息，获得进程结果，然后调用执行继续进行。
	　　	目前，有多种 RPC 模式和执行。最初由 Sun 公司提出。IETF ONC 宪章重新修订了 Sun 版本，使得 ONC RPC 协议成为
		IETF 标准协议。现在使用最普遍的模式和执行是开放式软件基础的分布式计算环境（DCE）。

* xml
	- <![CDATA[]]>

* 测试  Cucumber			 性能测试
	- tengine+tair性能测试
		
		ref: http://baike.corp.taobao.com/index.php/Cache_compare#.E6.80.A7.E8.83.BD.E6.AF.94.E8.BE.83	统一Web接入之静态化cache方案对比
	- 自动化测试
		Cucumber的目录结构和执行过程

	- 性能测试工具 ab	   (ApacheBench)  
		-----------
		简介
		ab的全称是ApacheBench，是 Apache 附带的一个小工具，专门用于 HTTP Server 的benchmark testing，可以同时模拟多个并发请求。前段时间看到公司的开发人员也在用它作一些测试，看起来也不错
		，很简单，也很容易使用，所以今天花一点时间看了一下。
		通过下面的一个简单的例子和注释，相信大家可以更容易理解这个工具的使用。
		一个简单的例子
		/*在这个例子的一开始，我执行了这样一个命令 ab -n 10 -c 10 http://www.google.com/。这个命令的意思是启动 ab ，向 www.google.com 发送10个请求(-n 10) ，并每次发送10个请求(-c 10)——也就是说
		一次都发过去了。跟着下面的是 ab 输出的测试报告，红色部分是我添加的注释。*/

		C:\Program Files\Apache Software Foundation\Apache2.2\bin>ab -n 10 -c 10 http://www.google.com/
		This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0
		Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
		Copyright 1997-2005 The Apache Software Foundation, http://www.apache.org/
		Benchmarking www.google.com (be patient).....done    
		Server Software:        GWS/2.1
		Server Hostname:        www.google.com
		Server Port:            80
		Document Path:          /
		Document Length:        230 bytes
		Concurrency Level:      10

		/*整个测试持续的时间*/

		Time taken for tests:   3.234651 seconds

		/*完成的请求数量*/

		Complete requests:      10

		/*失败的请求数量*/

		Failed requests:        0

		Write errors:           0

		Non-2xx responses:      10

		Keep-Alive requests:    10

		/*整个场景中的网络传输量*/

		Total transferred:      6020 bytes

		/*整个场景中的HTML内容传输量*/

		HTML transferred:       2300 bytes

		/*大家最关心的指标之一，相当于 LR 中的 每秒事务数 ，后面括号中的 mean 表示这是一个平均值*/

		Requests per second:    3.09 [#/sec] (mean)

		/*大家最关心的指标之二，相当于 LR 中的 平均事务响应时间 ，后面括号中的 mean 表示这是一个平均值*/

		Time per request:       3234.651 [ms] (mean)

		/*这个还不知道是什么意思，有知道的朋友请留言，谢谢 ^_^ */

		Time per request:       323.465 [ms] (mean, across all concurrent requests)

		/*平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题*/

		Transfer rate:          1.55 [Kbytes/sec] received

		/*网络上消耗的时间的分解，各项数据的具体算法还不是很清楚*/

		Connection Times (ms)

			      min  mean[+/-sd] median   max

		Connect:       20  318 926.1     30    2954

		Processing:    40 2160 1462.0   3034    3154

		Waiting:       40 2160 1462.0   3034    3154

		Total:         60 2479 1276.4   3064    3184

		/*下面的内容为整个场景中所有请求的响应情况。在场景中每个请求都有一个响应时间，其中 50％ 的用户响应时间小于 3064 毫秒，60 ％ 的用户响应时间小于 3094 毫秒，最大的响应时间小于 
		3184 毫秒*/

		Percentage of the requests served within a certain time (ms)

		  50%   3064

		  66%   3094

		  75%   3124

		  80%   3154

		  90%   3184

		  95%   3184

		  98%   3184

		  99%   3184

		 100%   3184 (longest request)

		更多信息

		ab 不像 LR 那么强大，但是它足够轻便，如果只是在开发过程中想检查一下某个模块的响应情况，或者做一些场景比较简单的测试，ab 还是一个不错的选择——至少不用花费很多时间去学习 LR 
		那些复杂的功能，就更别说那 License 的价格了。

		下面是 ab 的详细参数解释，大家有兴趣的可以研究一下，最近没有足够多的时间研究，如果哪位朋友有兴趣希望可以帮忙翻译一下每个参数的含义，有问题讨论也欢迎在这里回帖 ^_^

		ab [ -A auth-username:password ] [ -c concurrency ] [ -C cookie-name=value ] [ -d ] [ -e csv-file ] [ -g gnuplot-file ] [ -h ] [ -H custom-header ] [ -i ] [ -k ] [ -n requests ] [ -p POST-file ] [ -P proxy-auth-username:password ]
		[ -q ] [ -s ] [ -S ] [ -t timelimit ] [ -T content-type ] [ -v verbosity] [ -V ] [ -w ] [ -x <table>-attributes ] [ -X proxy[:port] ] [ -y <tr>-attributes ] [ -z <td>-attributes ] [http://]hostname[:port]/path

		-A auth-username:password

		Supply BASIC Authentication credentials to the server. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the server needs it (i.e., has sent an
		401 authentication needed).

		-c concurrency

		Number of multiple requests to perform at a time. Default is one request at a time.

		-C cookie-name=value

		Add a Cookie: line to the request. The argument is typically in the form of a name=value pair. This field is repeatable.

		-d

		Do not display the "percentage served within XX [ms] table". (legacy support).

		-e csv-file

		Write a Comma separated value (CSV) file which contains for each percentage (from 1% to 100%) the time (in milliseconds) it took to serve that percentage of the requests. This is usually more useful than the 'gnuplot' file; as the
		results are already 'binned'.

		-g gnuplot-file

		Write all measured values out as a 'gnuplot' or TSV (Tab separate values) file. This file can easily be imported into packages like Gnuplot, IDL, Mathematica, Igor or even Excel. The labels are on the first line of the file.

		-h

		Display usage information.

		-H custom-header

		Append extra headers to the request. The argument is typically in the form of a valid header line, containing a colon-separated field-value pair (i.e., "Accept-Encoding: zip/zop;8bit").

		-i

		Do HEAD requests instead of GET.

		-k

		Enable the HTTP KeepAlive feature, i.e., perform multiple requests within one HTTP session. Default is no KeepAlive.

		-n requests

		Number of requests to perform for the benchmarking session. The default is to just perform a single request which usually leads to non-representative benchmarking results.

		-p POST-file

		File containing data to POST.

		-P proxy-auth-username:password

		Supply BASIC Authentication credentials to a proxy en-route. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the proxy needs it (i.e., has
		sent an 407 proxy authentication needed).

		-q

		When processing more than 150 requests, ab outputs a progress count on stderr every 10% or 100 requests or so. The -q flag will suppress these messages.

		-s

		When compiled in (ab -h will show you) use the SSL protected https rather than the http protocol. This feature is experimental and very rudimentary. You probably do not want to use it.

		-S

		Do not display the median and standard deviation values, nor display the warning/error messages when the average and median are more than one or two times the standard deviation apart. And default to the min/avg/max values.
		(legacy support).

		-t timelimit

		Maximum number of seconds to spend for benchmarking. This implies a -n 50000 internally. Use this to benchmark the server within a fixed total amount of time. Per default there is no timelimit.

		-T content-type

		Content-type header to use for POST data.

		-v verbosity

		Set verbosity level - 4 and above prints information on headers, 3 and above prints response codes (404, 200, etc.), 2 and above prints warnings and info.

		-V

		Display version number and exit.

		-w

		Print out results in HTML tables. Default table is two columns wide, with a white background.

		-x <table>-attributes

		String to use as attributes for <table>. Attributes are inserted <table here >.

		-X proxy[:port]

		Use a proxy server for the requests.

		-y <tr>-attributes

		String to use as attributes for <tr>.

		-z <td>-attributes

		String to use as attributes for <td>.

		相关链接

		ab 是 Apache 的一个安装组件，所以需要下载 Apache 安装后才能使用，可以访问 Apache 的项目主页来下载 http://httpd.apache.org/download.cgi

		ab 的更多信息可以参加 Apache 主页上的描述

		http://httpd.apache.org/docs/2.0/programs/ab.html

		from: http://www.cnblogs.com/jackei/archive/2006/07/18/454144.html
		-----------
	- 部署打开debug
		远程shell(调用python封装好的各个接口调用，执行命令，传入参数即可)执行请求，ide debug处理过程
* yum 
	- yum 安装指定目录，指定安装目录
		--installroot=[path]  set install root
	- yum源设置
		比如使用163镜像站，可以参考其提供的使用帮助,下面为摘取部分：
			CentOS镜像使用帮助
			使用说明
				首先备份/etc/yum.repos.d/CentOS-Base.repo
				    mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
			下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份)
				•CentOS5
				•CentOS6
			运行yum makecache生成缓存
			from: http://mirrors.163.com/.help/centos.html
						
	- yum的使用:  
	    1)包的更新  
	    1.1)检查可更新包: yum check-update  
	    1.2)更新所有包: yum update  
	    1.3)更新指定包: yum update package_name  
	    1.4)版本升级: yum upgrade  
	    2)包安装与删除  
	    2.1)yum install package_name  
	    2.2)yum remove package_name  
	    3)包搜索  
	    3.1)搜索特定包: yum search package_name  
	    3.2)搜索包含特定文件名的包:yum provides name  
	    4)包列表  
	    4.1)列出所有安装或更新的包: yum list  
	    4.2)列出指定包:yum list name  
	    4.3)列出可更新包:yum list updates  
	    4.4)列出已安装包:yum list installed  
	    4.5)列出已安装但不包含在资源库中的包:yum list extras  

	CentOS yum源设定
	    2.1)加快yum下载速度: yum -y install yum-fastestmirror,在CentOs 4上名字叫做yum-plugin-fastestmirror  
	    2.2)yum源文件:/etc/yum.repos.d/CentOS-Base.repo  
	    2.3)CentOS 5的yum源设为上海交通大学网站 

* vim
	-自动缩进
		在文件末尾添加一行，输入  set autoindent
		在添加一行，输入         set cindent
		其中 autoindent 是自动缩进； cindent是特别针对 C语言语法自动缩进
	- 可以为操作的一行添加下划线
		set cursorline
   	- vimdiff
		vimdiff 命令比较文本，比较文件，文件比较 对比工具
	- 替换
		vi/vim 中可以使用 :s 命令来替换字符串
		:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
		:s/vivian/sky/g 替换当前行所有 vivian 为 sky
		:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
		:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
		n 为数字，若 n 为 .，表示从当前行开始到最后一行
		:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
		:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
		可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
		:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	
	- set paste 保持黏贴格式
	- 
		~/.vimrc - vim对当前用户的配置文件
		~/.vim/colors 目录下放自己的颜色方案文件  ，用户自己的设置

		颜色方案下载地址：http://www.vim.org/scripts/script.php?script_id=1651

	- 可以设置编辑的颜色方案
		通常, 如果工作在终端模式下, 你只有一个黑色的背景和白色的前景色. 这种配色太单调了, 看起也太暗淡了. 其实颜色方案是可以设计的.
		默认的, 你在终端下打开Vim时的的颜色和你打开的终端的颜色是一样的. 不过Vim给了用户一个权力来改变颜色的. 最常使用的就是配色方案文件. 这些文件通常放在Vim安装目录下的colors目录下.
		你可以简单地通过下面的命令在己安装的本色方案中切换
			:colorscheme mycolors
		mycolors要换成安装的配色方案的名称. 如可你不知道安装了哪些配色方案, 可以在写下下面的命令后:
			:colorscheme
		通过按tab键来在安装的配色方案的名字间切换. 当发现了想要的配色方案后 就可以按回车键来应用它.
		配色方案不仅只是应用在前景色和背景色, 也可以设置代码的高亮显示, 错误如何标识, 和其他的一些文本的可视化标识. 
		
		安装配色方案：
			root@ag # rpm -qa | grep -i vim	      - 找到vim的安装包
			vim-common-7.0.109-6.el5
			vim-enhanced-7.0.109-6.el5
			vim-minimal-7.0.109-6.el5
			root@ag # rpm -ql vim-common-7.0.109-6.el5 | grep colors		- 找到colors目录位置      - 
			/usr/share/vim/vim70/colors
			/usr/share/vim/vim70/colors/README.txt
			/usr/share/vim/vim70/colors/blue.vim
			/usr/share/vim/vim70/colors/darkblue.vim
			/usr/share/vim/vim70/colors/default.vim
			/usr/share/vim/vim70/colors/delek.vim
			/usr/share/vim/vim70/colors/desert.vim
			/usr/share/vim/vim70/colors/elflord.vim
			/usr/share/vim/vim70/colors/evening.vim
			/usr/share/vim/vim70/colors/koehler.vim
			/usr/share/vim/vim70/colors/morning.vim
			/usr/share/vim/vim70/colors/murphy.vim
			...

			将配色方案文件 *.vim，拷贝到colors目录下，
			切换颜色方案：
			:colorscheme SchemeFileName 
		
	-
		:reg 查看剪贴板内容
	- search
		type '/' > type words > key 'n' for next match
	- 在整个文件里面有效移动光标
		VIM 有很多命令，可以用来到达文件里面你想到达的地方。下面是一些在文件里面移动的命令：
	　　<C-F>：向下移动一屏。
	　　<C-D>：向下移动半屏。
	　　<C-B>：向上移动一屏。
	　　<C-U>：向上移动半屏。
	　　G：到文件尾
	　　numG：移动光标到指定的行（num）。（比如 10G 就是到第 10 行）
	　　gg：到文件首
	　　H：移动光标到屏幕上面
	　　M：移动光标到屏幕中间
	　　L：移动光标到屏幕下面
	　　*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。
	　　/text：从当前光标处开始搜索字符串 text，并且到达 text 出现的地方。必须使用回车来开始这个搜索命令。如果想重复上次的搜索的话，按 n移动到下个 text 处，N 移动到上一个 text 处 。
	　　？text：和上面类似，但是是反方向。
	　　m{a-z}：在当前光标的位置标记一个书签，名字为 a-z 的单个字母。书签名只能是小写字母。你看不见书签的存在，但它确实已经在那里了。
	　　`a：到书签 a 处。注意这个不是单引号，它一般位于大部分键盘的 1 的左边。
	　　`.：到你上次编辑文件的地方。这个命令很有用，而且你不用自己去标记它。
	　　%：在成对的括号等符号间移动，比如成对的 [ ] ， { }， ( ) 之间。将光标放到任意符号上，然后通过 % 来移动到和这个符号匹配的符号上，% 还可以正确的识别括号的嵌套层数，总是移动到真正匹配的位置上。因此这个命令在编辑程序代码的时候非常有用，可以让你方便的在一段代码的头尾间移动。
	　　6、它主要应用在--Linux系统
	- VIM 复制黏贴
		内容：
		用vim 这么久 了，始终也不知道怎么在vim 中使用系统粘贴板，通常要在网上复制 一段代码都是先gedit打开文件，中键粘贴后关闭，然后再用vim 打开编辑，真的不 爽；上次论坛上有人问到了怎么在vim 中使用系统粘贴板，印象里回复很多，有好几页的回复却没有解决问题，今天实在受不了了又在网上找办法，竟意外地找到 了，贴出来分享一下。

		如果只是想使用系统粘贴板的话直接在输入模式按Shift+Inset（粘贴）就可以了，下面讲一下vim 的粘贴板的基础知识，有兴趣的可以看看，应该会有所收获的。
		vim 帮助文档里与粘贴板有关的内容如下：

		    vim 有12个粘贴板，分别是0、1、2、...、9、a、“、＋；用:reg命令可以查看各个粘贴板里的内容。在vim 中简单用y只是复制 到“（双引号)粘贴板里，同样用p粘贴的也是这个粘贴板里的内容；

		    要将vim 的内容复制 到某个粘贴板，需要退出编辑模式，进入正常模式后，选择要复制 的内容，然后按"Ny（注意带引号）完成复制 ，其中N为粘贴板号(注意是按一下双引号然后按粘贴板号最后按y)，例如要把内容复制 到粘贴板a，选中内容后按"ay就可以了，有两点需要说明一下：
			“号粘贴板（临时粘贴板）比较特殊，直接按y就复制 到这个粘贴板中了，直接按p就粘贴这个粘贴板中的内容；
			+号粘贴板是系统粘贴板，用"+y将内容复制 到该粘贴板后可以使用Ctrl＋V将其粘贴到其他文档（如firefox、gedit）中，同理，要把在其他地方用Ctrl＋C或右键复制 的内容复制 到vim 中，需要在正常模式下按"+p；

		    要将vim 某个粘贴板里的内容粘贴进来，需要退出编辑模式，在正常模式按"Np，其中N为粘贴板号，如上所述，可以按"5p将5号粘贴板里的内容粘贴进来，也可以按"+p将系统全局粘贴板里的内容粘贴进来。

		注意：在我这里，只有vim.gtk或vim.gnome才能使用系统全局粘贴板，默认的vim.basic看不到+号寄存器。安装vim.gnome使用apt-get install vim-gnome，然后vim自动会链接到vim.gnome。
		（二）
		yy  複製游標所在行整行。或大寫一個 Y。
		2yy 或 y2y  複製兩行。ㄟ，請舉一反三好不好！:-)
		y^  複製至行首，或 y0。不含游標所在處字元。
		y$  複製至行尾。含游標所在處字元。
		yw  複製一個 word。
		y2w 複製兩個字。
		yG  複製至檔尾。
		y1G 複製至檔首。
		p   小寫 p 代表貼至游標後（下）。
		P   大寫 P 代表貼至游標前（上）。
		    整行的複製，按 p 或 P 時是插入式的貼在下（上）一行。非整行的複製則是貼在游標所在處之後（前）。
		"ayy  將本行文字複製到 a 緩衝區
		    a 可為 26 個英文字母中的一個，如果是小寫的話，原先的內容會被清掉，如果是大寫的話是 append 的作用，會把內容附加到原先內容之後。
		    " 是 Enter 鍵隔壁的那一個同上符號（ditto marks）。
		"ap  將 a 緩衝區的內容貼上。
		    緩衝區的術語在 vim 稱為 registers，vim 擴充了相當多的功能，有興趣深入的朋友請 :h registers。您用 d、c、s、x、y 等指令改變或刪除的內容都是放在 registers 中的。例如：您用 dd 刪除的一行，也是可以使用 p 來貼上的。只要是在緩衝區的內容都可以使用 p 來貼上，不是一定要 y 起來的內容才能用 p。因此您認為 p 是 paste 也可以，認為是 put 可能較正確。
		5"ayy  複製五行內容至 a 緩衝區。
		5"Ayy  再複製五行附在 a 內容之後，現在 a 中有十行內容了！
		    ㄟ！不要我一直用 a 您就認為只有 a 可以用喔。26 個英文字母都可以的，交叉運用下，您會發覺 vi(m) 肚量不小。
		    問題來了！忘記誰是誰的時候怎麼辦？ :reg（冒號命令）就會列出所有 registers 的代號及內容。您現在就試著按看看。咦！怎麼還有數目字、特殊符號的緩衝區，原來您剛剛刪除（複製）的內容就預設放在 " 這個緩衝區，然後依序是 0,1,2,...9。也就是說您按 p 不加什麼的話，是取出 " 緩衝區的內容的。% 指的是目前編輯的檔案，# 指的是前一次編輯的檔案。還有其它的呀！因為沒什麼重要，就請 :h registers 吧！registers 有個 "s" 結尾，不要搞錯了，而且 Tab 的補全鍵 vim 也支援的，也就是說您鍵入 :h regi 再按 Tab 鍵，vim 就會幫您補全，按了 Tab 後發現不是您要的，那就繼續按，總會出現您要的。:-)
		    Tab 補全的功能，elvis 也有，但叫出 registers 列表的命令則沒有，您得自行記憶在您的腦袋瓜子裡。而且 elvis 的補全能力並沒 vim 強。

		另外,按下v键,可以进入可视模式,这个时候可以更自由更灵活的选取要复制的段落,区块了.

* 一致性hash算法（consistent hashing） hash圆环 ，环形hash robin环 Round Robin round-robin    一致性哈希	 （这里以memcached客户端的应用为例子说明）
	- 与加入/移除结点时缓存重新发布的关系
	- 一致性哈希算法最大程度的避免了key在服务节点列表上的重新分布，其他附带的改进就是有的一致性哈希算法还增加了虚拟服务节点的方法，也就是一个服务节点在环上有多个映射点，
	这样就能抑制分布不均匀，最大限度地减小服务节点增减时的缓存重新分布。
	- memcached客户端

	- http://www.cnblogs.com/liyulong1982/articles/2497731.html
	- 哈希分布与一致性哈希简介  		
			在我们的日常web应用开发当中memcached可以算作是当今的标准开发配置了。相信memcache的基本原理大家也都了解过了，memcache虽然是分布式的应用服务，
		但分布的原则是由client端的api来决定的，api根据存储用的key以及已知的服务器列表，根据key的hash计算将指定的key存储到对应的服务器列表上。
		基本的原理以及分布
			在这里我们通常使用的方法是根据 key的hash值%服务器数取余数 的方法来决定当前这个key的内容发往哪一个服务器的。这里会涉及到一个hash算法的分布问题，
		哈希的原理用一句话解释就是两个集合间的映射关系函数，在我们通常的应用中基本上可以理解为 在集合A（任意字母数字等组合，此处为存储用的key）里的一条记录
		去查找集合B（如0-2^32）中的对应记录。（题外话：md5的碰撞或者说冲突其实就是发生在这里，也就是说多个A的记录映射到了同一个B的记录）

		- 实际应用-
		显然在我们的应用中集合A的记录应该更均匀的分布在集合B的各个位置，这样才能尽量避免我们的数据被分布发送到单一的服务器上，
		在danga的memcached的原始版本（perl）中使用的是crc32的算法用java的实现写出来：
		    private static int origCompatHashingAlg( String key ) {
			int hash    = 0;
			char[] cArr = key.toCharArray();

			for ( int i = 0; i < cArr.length; ++i ) {
			    hash = (hash * 33) + cArr[i];
			}

			return hash;
		    }
		这里还有另一个改进版本的算法：
		    private static int newCompatHashingAlg( String key ) {
			CRC32 checksum = new CRC32();
			checksum.update( key.getBytes() );
			int crc = (int) checksum.getValue();

			return (crc >> 16) & 0x7fff;
		    }
		- 分布率测试 -
			有人做过测试，随机选择的key在服务器数量为5的时候所有key在服务器群组上的分布概率是：
			
			显然使用旧的crc32算法会导致第三个memcached服务的负载更高，但使用新算法会让服务之间的负载更加均衡。
			其他常用的hash算法还有FNV-1a Hash,RS Hash,JS Hash,PJW Hash,ELF Hash,AP Hash等等。有兴趣的童鞋可以查看这里：
				http://www.partow.net/programming/hashfunctions/
				http://hi.baidu.com/algorithms/blog/item/79caabee879ece2a2cf53440.html
		- 小结 -
			至此我们了解到了在我们的应用当中要做到尽量让我们的映射更加均匀分布，可以使服务的负载更加合理均衡。
		- 新问题 -
			但到目前为止我们依然面对了这样一个问题：就是服务实例本身发生变动的时候，导致服务列表变动从而会照成大量的cache数据请求会miss，
			几乎大部分数据会需要迁移到另外的服务实例上。这样在大型服务在线时，瞬时对后端数据库/硬盘照成的压力很可能导致整个服务的crash。
		- 一致性哈希（Consistent Hashing） -
			在此我们采用了一种新的方式来解决问题，处理服务器的选择不再仅仅依赖key的hash本身而是将服务实例（节点）的配置也进行hash运算。
				1) 首先求出每个服务节点的hash，并将其配置到一个0~2^32的圆环（continuum）区间上。
				2) 其次使用同样的方法求出你所需要存储的key的hash，也将其配置到这个圆环（continuum）上。
				3) 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务节点上。如果超过2^32仍然找不到服务节点，就会保存到第一个memcached服务节点上。

	from: http://www.cnblogs.com/liunx/archive/2010/03/24/1693925.html

* API 用户体验
	开发的api遵循一定的规范：（整齐划一，看着清爽）
		接口命名
		返回码规划（分段）
		错误提示格式 比如驼峰式书写
		语义描述统一
* error
	cannot find symbol —— maven test项目时报此错误，可能和eclipse编译的冲突，先清除eclipse的编译文件，再执行mvn test

* debug
	* 提奥斯
	从日志看，应用或者服务器日志；
	错误可能被应用屏蔽，没有输出，此时只能看应用的日志。

* virtual networking 虚拟网络
	
* 业务熟悉 熟悉业务
	文档
	从数据库表理解
	代码

* NIO 非阻塞操作/ 阻塞操作 消息驱动
	- 输入和输出都经过Buffer层，数据以块的方式处理（区别老IO以字节流的方式处理）

	-
	上图就是这个项目的总体结构图，从图中可以看出该程序分为这几大块：连接侦听线程、连接对象队列、发送线程池、接收线程池、分发线程、
	事件处理对象、监控处理对象。下面我将描述下整个连接处理过程：
	1、 连接侦听线程循环接收一个连接请求，如果有连接请求过来，则返回一个连接Socket对象，否则该线程就阻塞等待，直到有一个连接请求过来。
	2、 封装该返回的Socket对象（主要是封装获取完整包数据，发送方法，关闭方法等）成Connection对象，并把封装好的Connection对象放入连接对象队列。
	3、 分发线程不停的轮询连接对象队列，如果发现有可接收数据的连接对象，则扔给接收线程池去处理；如果发现有可发送数据的连接对象，则扔给发送线程池
	去处理。如果轮询一圈发现既没有可发送数据的连接对象也没有可接收数据的连接对象，则该线程会休眠一段时间，休眠过后又接着循环。
	4、 发送线程池内有一个连接对象队列，从队列中取出一个连接对象并发送数据，且记录连接状态信息。
	5、 接收线程池内也有一个连接对象队列，从队列中取出一个连接对象并接收一个数据包，且记录连接状态信息。如果接收的数据包是心跳检测包则更新连接状态，
	如果是数据包则通过事件处理对象发送给probe系统。
	    从上面的过程来看，我们可能看不出设计上面的漏洞，但有几个地方确实非常影响效率，在这里我想先提出来：
	1、 连接侦听线程一直在侦听，有连接请求过来则会返回，没有则会阻塞；这样这个线程就会一直挂着；如果时时刻刻都有很多的连接过来，这个线程还会充分发挥
	它的作用，但其实大部分时候，连接请求并没有这么频繁，所以这个线程大部分时间是阻塞的；这样为了这样一个功能单独利用一个线程就有点浪费了。
	2、 分发线程不停的轮询过程是导致整个系统效率低下最严重的一块，分发线程不停的轮询连接对象队列，其实分发线程并不知道哪个线程需要发送数据，哪些线程
	需要接收数据，而他只是盲目地从队列的头遍历到队列的尾部，如果发现没有可操作的连接对象则休眠一段时间；其实在大部分情况下，连接对象并不是时时刻刻
	都有数据发送和接收，所以这个分发线程大部分时间空循环，白忙了；并且这个休眠时间也不好控制，如果时间长了，则程序的即时性不够，如果太短了，程序似乎
	就是在空跑了。
	3、 在连接对象上发送和接收数据包的时候，这些方法都是阻塞操作的；所以当有大量的数据可接收和发送的时候，这种阻塞的操作时非常浪费资源的。
	    以上所提出的问题，如果是在并发规模比较小的情况下，是没有什么问题；但确实有很大的改进空间。上面的问题归结起来主要是两个：
	1、 当有连接请求过来或者有Socket连接有数据可读可写的时候，我们不会立即知道，我们必须要一个一个的轮询，我们能否有一种机制，即是，当有连接请求过来或者
	连接有数据可读或者可写的时候，直接通知我们来处理，而不需要我们主动轮询。
	2、 当读数据或者写数据的时候，所有的方法都阻塞了，能不能有一种办法当我们写数据或者接收数据的时候不用阻塞，而是直接返回，这样就明显提高了线程的使用率了。
	    值得我们庆幸的是，在Java的JDK1.4之后的版本，提供了NIO包，这里提出了事件驱动的I/O编程模式和非阻塞信道的概念，NIO里面的Selector对象解决了上面提出分发
	    和轮询的问题，Channel接口解决了阻塞读写的问题。我相信这些组件能够帮我们解决上面所提出的所有问题。所以下面有很大一部分篇幅来介绍NIO的使用和一些底层的机制。
	from: http://www.cnblogs.com/cpcpc/archive/2011/09/05/2167931.html

* visio
	- 输出图片格式
		
	- 提供多种图的绘制支持，比如uml，需要安装模板。
	- 序列图，可以用横版画图；宽度还不够的话，可以将名称换行(选中文本工具，即可编辑一些形状的名称)
	- 有些地方不可编辑，可能是保护原因，在形状上右键格式的保护力设置
	- 取消保护后，可以根据文本是文本或者文本块（选中某中文本按钮移上去后会以图表方式提示鼠标位置是文本还是文本块），
	  选中相应按钮，来调整形状的文字说明
	- 修改图层次序，在形状上右键的格式中设置
	- 对于名称，不能直接用文本按钮来设置，还是需要在名称属性里填上值，然后通过文本工具来设置文本格式，否则可能名称为空。
* redmine * 项目管理系统
	- redmine
		Redmine是用Ruby开发的基于web的项目管理软件，是用ROR框架开发的一套跨平台项目管理系统，据说是源于Basecamp的ror版而来，
		支持多种数据库，有不少自己独特的功能，例如提供wiki、新闻台等，还可以集成其他版本管理系统和BUG跟踪系统，例如SVN、CVS、TD等等。
		这种 Web 形式的项目管理系统通过“项目（Project）”的形式把成员、任务（问题）、文档、讨论以及各种形式的资源组织在一起，大家参与更新任务、
		文档等内容来推动项目的进度，同时系统利用时间线索和各种动态的报表形式来自动给成员汇报项目进度。

* 测试环境
	单台linux物理机 > xen虚拟多个vm (vm的lxc下多个app,eg:jetty)> 疏通vm网络 > 在vm上部署haproxy+keepalived以及web应用实现软负载均衡 > ...
	/etc/sysconfig/network-scripts/ifcfg-eth0
	/etc/sysconfig/network
	/etc/hosts
	域名服务器配置文件：/etc/resolv.conf
	
	 -------------------------
	 slbapi测试环境：
		mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
		http://10.230.204.24/slb/api?
 * spring
	- Log4jConfigListener 
		log4j配置动态加载，Spring默认刷新Log4j配置文件的间隔,单位为millisecond
	- spring抽象类注入，spring接口注入有区别
		抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	- spring通过aop拦截器，拦截自定义注解所注解的方法 参考day52
		参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/
	- ioc时注意，有些ioc是直接通过注解注入的，故在配置文件中找不到，这个细节要注意
		作用：1）管理对象关系，避免了直接new实现，更符合接口编程 2）对象生命周期管理

		@Autowired(required = true)
		public void setXX(@Qualifier("xx") xx xx) {
			//
		}
	- 编程式事务一例：
		spring 编程式事务管理
		1）bean配置
		<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
		   <property name="dataSource" ref="dataSource" />
		</bean>

		<bean id="transactionTemplate" class="org.springframework.transaction.support.TransactionTemplate" >
		   <property name="transactionManager" ref="transactionManager"/>
		</bean>

		<bean id="servie" class="SimpleService">
		  <property name="transactionTemplate" ref="transactionTemplate"/>
		</bean>

		TransactionTemplate是线程安全的，不同的service可以共用一个bean实例，其配置状态也是一致的。
		如果要用到不同的配置状态，则需要配置不同的TransactionTemplate Bean

		2）在Service中，定义TransactionTemplate全局变量

		public class SimpleService implements Service {
		  
		  private final TransactionTemplate transactionTemplate;

		  public void setTransactionTemplate(TransactionTemplate transactionTemplate) {
		    this.transactionTemplate = transactionTemplate;
		  }

		  public Object someServiceMethod() {
		    return transactionTemplate.execute(new TransactionCallback() {

		      // the code in this method executes in a transactional context
		      public Object doInTransaction(TransactionStatus status) {
			updateOperation1();
			return resultOfUpdateOperation2();
		      }
		    });
		  }
		}

		3）使用status.setRollbackOnly()方法回滚事务

		transactionTemplate.execute(new TransactionCallbackWithoutResult() {

		  protected void doInTransactionWithoutResult(TransactionStatus status) {
		    try {
		      updateOperation1();
		      updateOperation2();
		    } catch (SomeBusinessExeption ex) {
		      status.setRollbackOnly();
		    }
		  }
		});

		doInTransaction方法一旦执行完毕，事务自动提交；如果在catch块中设置了回滚setRollbackOnly，方法执行完毕将“提交”回滚。

		4、有返回值，使用TransactionCallback；如果没有返回值，使用TransactionCallbackWithoutResult
 * word * office word
	- word的列表问题，多级列表调整缩进样式，选中列表项，右键选“调整列表缩进”，具体看哪个对话框。

* 消息系统 消息中间件 MQ
	- AMQP协议
		rabbitMQ基于此协议实现
			tutorial：http://www.rabbitmq.com/tutorials/tutorial-one-python.html

	- 消息队列 消息队列框架 message queue ，MQ
	发布/订阅
	MQ的特点：
			MQ的消费-生产者模型的一个典型的代表，一端往消息队列中不断的写入消息，而另一端则可以读取或者订阅队列中的消息。MQ和JMS类似，
		但不同的是JMS是SUN JAVA消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品。
	使用场景(异步处理需求):
		　　最近在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从
		而提高了系统的吞吐量。

	- Jafka - 一个高性能的消息系统 : http://www.blogjava.net/xylz/archive/2012/05/10/377759.html
		淘宝内部使用的Kafka克隆版metaq,内部做了大量的改进和附加组件。如果你需要一个全功能的“复杂”系统，可以试试metaq: 
			https://github.com/killme2008/Metamorphosis
	
	- Rabbitmq erlang实现的消息中间件
		http://www.rabbitmq.com/
		根据tutorial说明，provider或者consumer都可以建立queue

	- JMS		       * JMS
		JMS是一种与厂商无关的 API，用来访问消息收发系统。它类似于 JDBC(Java Database Connectivity)：这里，JDBC 是可以用来访问许多不同关系数据库的 API，
	而 JMS 则提供同样与厂商无关的访问方法，以访问消息收发服务。许多厂商目前都支持 JMS，包括 IBM 的 MQSeries、BEA的 Weblogic JMS service和 Progress 的 
	SonicMQ，这只是几个例子。 JMS 使您能够通过消息收发服务（有时称为消息中介程序或路由器）从一个 JMS 客户机向另一个 JMS客户机发送消息。消息是 JMS 
	中的一种类型对象，由两部分组成：报头和消息主体。报头由路由信息以及有关该消息的元数据组成。消息主体则携带着应用程序的数据或有效负载。根据有效
	负载的类型来划分，可以将消息分为几种类型，它们分别携带：简单文本 (TextMessage)、可序列化的对象 (ObjectMessage)、属性集合 (MapMessage)、字节流
	(BytesMessage)、原始值流 (StreamMessage)，还有无有效负载的消息 (Message)。
	
	消息通信是软件组件或应用程序用来通信的一种方法。JMS就是一种允许应用程序创建、发送、接收、和读取消息的JAVA技术。				

	JMS提供者实现
	　　要使用Java消息服务，你必须要有一个JMS提供者，管理会话和队列。现在既有开源的提供者也有专有的提供者。 　　
		开源的提供者包括： 　　
			Apache ActiveMQ —— is the most popular and powerful open source messaging and Integration Patterns server
			http://activemq.apache.org/
* haproxy
		HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代 理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。
	HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。
	并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。
		HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，
	很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，
	这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。

	haproxy与lvs的关系：
		软件负载均衡一般通过两种方式来实现：基于操作系统的软负载实现和基于第三方应用的软负载实现。LVS就是基于Linux操作系统实现的一种软负载，
		HAProxy就是开源的并且基于第三应用实现的软负载。
	
	HAProxy相比LVS的使用要简单很多，功能方面也很丰富。当 前，HAProxy支持两种主要的代理模式:"tcp"也即4层（大多用于邮件服务器、内部协议通信服务器等），
	和7层（HTTP）。在4层模式 下，HAProxy仅在客户端和服务器之间转发双向流量。7层模式下，HAProxy会分析协议，并且能通过允许、拒绝、交换、增加、修改
	或者删除请求 (request)或者回应(response)里指定内容来控制协议，这种操作要基于特定规则。
	
	---------
	我现在用HAProxy主要在于它有以下优点，这里我总结下：
		一、免费开源，稳定性也是非常好，这个可通过我做的一些小项目可以看出来，单Haproxy也跑得不错，稳定性可以与LVS相媲美；
		二、根据官方文档，HAProxy可以跑满10Gbps-New benchmark of HAProxy at 10 Gbps using Myricom's 10GbE NICs (Myri-10G PCI-Express)，这个作为软件级负载均衡，
		也是比较惊人的；
		三、HAProxy可以作为MySQL、邮件或其它的非web的负载均衡，我们常用于它作为MySQL(读)负载均衡；
		四、自带强大的监控服务器状态的页面，实际环境中我们结合Nagios进行邮件或短信报警，这个也是我非常喜欢它的原因之一；
		五、HAProxy支持虚拟主机。
	---------
	from: http://www.cnblogs.com/dkblog/archive/2011/07/06/2098949.html

	数据库(读)负载均衡：
		应用维持一个数据库连接池的情况
* 系统部署架构
	请求 > web负载均衡 > squid web cache > web server > squid db cache > 数据库负载均衡> db

* loadbalance 负载均衡	      * slb software load balance * lb 
	haproxy + keepalived 方式实现软负载均衡
		http://www.cnblogs.com/dkblog/archive/2011/07/06/2098949.html

	slb的优点（相对于dns实现的lb）：
	SLB has several benefits, which is why it is such a highly successful and widely
	employed technology. Three main benefits directly address the concerns and
	needs of highly trafficked, mission-critical web sites:
	Flexibility
		SLB allows the addition and removal of servers to a site at any time, and the
		effect is immediate. Among other advantages, this allows for the maintenance
		of any machine, even during peak hours with little or no impact to the site. A
		load balancer can also intelligently direct traffic using cookies, URL parsing,
		static and dynamic algorithms, and much more.
	High availability
		SLB can check the status of the available servers, take any nonresponding
		servers out of the rotation, and put them in rotation when they are functioning
		again. This is automatic, requiring no intervention by an administrator.
		Also, the load balancers themselves usually come in a redundant configuration,
		employing more than one unit in case any one unit fails.
	Scalability
		Since SLB distributes load among many servers, all that is needed to increase
		the serving power of a site is to add more servers. This can be very economical,
		since many small- to medium-sized servers can be much less expensive
		than a few high-end servers. Also, when site load increases, servers can be
		brought up immediately to handle the increase in traffic.
	
* html/css模板 ，有此类网站搜集页面模板
	http://www.html-themes.com/free/
				
* 正则表达式 例子
	通过一些小正则工具来验证表达式
	
	整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
	只能输入数字："^[0-9]*$"。 
	只能输入n位的数字："^\d{n}$"。 
	只能输入至少n位的数字："^\d{n,}$"。 
	只能输入m~n位的数字：。"^\d{m,n}$" 
	只能输入零和非零开头的数字："^(0|[1-9][0-9]*)$"。 
	只能输入有两位小数的正实数："^[0-9]+(.[0-9]{2})?$"。 
	只能输入有1~3位小数的正实数："^[0-9]+(.[0-9]{1,3})?$"。 
	只能输入非零的正整数："^\+?[1-9][0-9]*$"。 
	只能输入非零的负整数："^\-[1-9][]0-9"*$。 
	只能输入长度为3的字符："^.{3}$"。 
	只能输入由26个英文字母组成的字符串："^[A-Za-z]+$"。 
	只能输入由26个大写英文字母组成的字符串："^[A-Z]+$"。 
	只能输入由26个小写英文字母组成的字符串："^[a-z]+$"。 
	只能输入由数字和26个英文字母组成的字符串："^[A-Za-z0-9]+$"。 
	只能输入由数字、26个英文字母或者下划线组成的字符串："^\w+$"。 
	验证用户密码："^[a-zA-Z]\w{5,17}$"正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。 
	验证是否含有^%&',;=?$\"等字符："[^%&',;=?$\x22]+"。 
	只能输入汉字："^[\u4e00-\u9fa5]{0,}$" 
	验证Email地址："^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$"。 
	验证InternetURL："^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$"。 
	验证电话号码："^(\(\d{3,4}-)|\d{3.4}-)?\d{7,8}$"正确格式为："XXX-XXXXXXX"、"XXXX-XXXXXXXX"、"XXX-XXXXXXX"、"XXX-XXXXXXXX"、"XXXXXXX"和"XXXXXXXX"。 
	验证身份证号（15位或18位数字）："^\d{15}|\d{18}$"。 
	验证一年的12个月："^(0?[1-9]|1[0-2])$"正确格式为："01"～"09"和"1"～"12"。 
	验证一个月的31天："^((0?[1-9])|((1|2)[0-9])|30|31)$"正确格式为；"01"～"09"和"1"～"31"。 
	匹配中文字符的正则表达式： [\u4e00-\u9fa5] 

	匹配双字节字符(包括汉字在内)：[^\x00-\xff] 
	-  more -
			正则表达式语法 
		在典型的搜索和替换操作中，必须提供要查找的确切文字。这种技术对于静态文本中的简单搜索和替换任务可能足够了，但是由于它缺乏灵活性，因此在搜索动态文本时就有困难了，甚至是不可能的。 

		使用正则表达式，就可以： 

		•测试字符串的某个模式。例如，可以对一个输入字符串进行测试，看在该字符串是否存在一个电话号码模式或一个信用卡号码模式。这称为数据有效性验证。
		•替换文本。可以在文档中使用一个正则表达式来标识特定文字，然后可以全部将其删除，或者替换为别的文字。
		•根据模式匹配从字符串中提取一个子字符串。可以用来在文本或输入字段中查找特定文字。 
		例如，如果需要搜索整个 web 站点来删除某些过时的材料并替换某些HTML 格式化标记，则可以使用正则表达式对每个文件进行测试，看在该文件中是否存在所要查找的材料或 HTML 格式化标记。用这个方法，就可以将受影响的文件范围缩小到包含要删除或更改的材料的那些文件。然后可以使用正则表达式来删除过时的材料，最后，可以再次使用正则表达式来查找并替换那些需要替换的标记。

		另一个说明正则表达式非常有用的示例是一种其字符串处理能力还不为人所知的语言。VBScript 是 Visual Basic 的一个子集，具有丰富的字符串处理功能。与 C 类似的 Jscript 则没有这一能力。正则表达式给 JScript 的字符串处理能力带来了明显改善。不过，可能还是在 VBScript 中使用正则表达式的效率更高，它允许在单个表达式中执行多个字符串操作。

		一个正则表达式就是由普通字符（例如字符 a 到 z）以及特殊字符（称为元字符）组成的文字模式。该模式描述在查找文字主体时待匹配的一个或多个字符串。正则表达式作为一个模板，将某个字符模式与所搜索的字符串进行匹配。

		这里有一些可能会遇到的正则表达式示例：


		JScript VBScript 匹配 
		/^\[ \t]*$/ "^\[ \t]*$" 匹配一个空白行。 
		/\d{2}-\d{5}/ "\d{2}-\d{5}" 验证一个ID 号码是否由一个2位数字，一个连字符以及一个5位数字组成。 
		/<(.*)>.*<\/\1>/ "<(.*)>.*<\/\1>" 匹配一个 HTML 标记。 



		下表是元字符及其在正则表达式上下文中的行为的一个完整列表：


		字符 描述 
		\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 后向引用、或一个八进制转义符。例如，'n' 匹配字符 "n"。'\n' 匹配一个换行符。序列 '\\' 匹配 "\" 而 "\(" 则匹配 "("。 
		^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 '\n' 或 '\r' 之后的位置。 
		$ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 '\n' 或 '\r' 之前的位置。 
		* 匹配前面的子表达式零次或多次。例如，zo* 能匹配 "z" 以及 "zoo"。 * 等价于{0,}。 
		+ 匹配前面的子表达式一次或多次。例如，'zo+' 能匹配 "zo" 以及 "zoo"，但不能匹配 "z"。+ 等价于 {1,}。 
		? 匹配前面的子表达式零次或一次。例如，"do(es)?" 可以匹配 "do" 或 "does" 中的"do" 。? 等价于 {0,1}。 
		{n} n 是一个非负整数。匹配确定的 n 次。例如，'o{2}' 不能匹配 "Bob" 中的 'o'，但是能匹配 "food" 中的两个 o。 
		{n,} n 是一个非负整数。至少匹配n 次。例如，'o{2,}' 不能匹配 "Bob" 中的 'o'，但能匹配 "foooood" 中的所有 o。'o{1,}' 等价于 'o+'。'o{0,}' 则等价于 'o*'。 
		{n,m} m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。刘， "o{1,3}" 将匹配 "fooooood" 中的前三个 o。'o{0,1}' 等价于 'o?'。请注意在逗号和两个数之间不能有空格。 
		? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 "oooo"，'o+?' 将匹配单个 "o"，而 'o+' 将匹配所有 'o'。 
		. 匹配除 "\n" 之外的任何单个字符。要匹配包括 '\n' 在内的任何字符，请使用象 '[.\n]' 的模式。 
		(pattern) 匹配pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 '\(' 或 '\)'。 
		(?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 "或" 字符 (|) 来组合一个模式的各个部分是很有用。例如， 'industr(?:y|ies) 就是一个比 'industry|industries' 更简略的表达式。 
		(?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如， 'Windows (?=95|98|NT|2000)' 能匹配 "Windows 2000" 中的 "Windows" ，但不能匹配 "Windows 3.1" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 
		(?!pattern) 负向预查，在任何不匹配Negative lookahead matches the search string at any point where a string not matching pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如'Windows (?!95|98|NT|2000)' 能匹配 "Windows 3.1" 中的 "Windows"，但不能匹配 "Windows 2000" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始  
		x|y 匹配 x 或 y。例如，'z|food' 能匹配 "z" 或 "food"。'(z|f)ood' 则匹配 "zood" 或 "food"。  
		[xyz] 字符集合。匹配所包含的任意一个字符。例如， '[abc]' 可以匹配 "plain" 中的 'a'。  
		[^xyz] 负值字符集合。匹配未包含的任意字符。例如， '[^abc]' 可以匹配 "plain" 中的'p'。  
		[a-z] 字符范围。匹配指定范围内的任意字符。例如，'[a-z]' 可以匹配 'a' 到 'z' 范围内的任意小写字母字符。  
		[^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，'[^a-z]' 可以匹配任何不在 'a' 到 'z' 范围内的任意字符。  
		\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\b' 可以匹配"never" 中的 'er'，但不能匹配 "verb" 中的 'er'。  
		\B 匹配非单词边界。'er\B' 能匹配 "verb" 中的 'er'，但不能匹配 "never" 中的 'er'。 
		\cx 匹配由x指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。 x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 'c' 字符。  
		\d 匹配一个数字字符。等价于 [0-9]。  
		\D 匹配一个非数字字符。等价于 [^0-9]。  
		\f 匹配一个换页符。等价于 \x0c 和 \cL。 
		\n 匹配一个换行符。等价于 \x0a 和 \cJ。 
		\r 匹配一个回车符。等价于 \x0d 和 \cM。 
		\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 
		\S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 
		\t 匹配一个制表符。等价于 \x09 和 \cI。 
		\v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 
		\w 匹配包括下划线的任何单词字符。等价于'[A-Za-z0-9_]'。  
		\W 匹配任何非单词字符。等价于 '[^A-Za-z0-9_]'。  
		\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如， '\x41' 匹配 "A"。'\x041' 则等价于 '\x04' & "1"。正则表达式中可以使用 ASCII 编码。. 
		\num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，'(.)\1' 匹配两个连续的相同字符。  
		\n 标识一个八进制转义值或一个后向引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为后向引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 
		\nm 标识一个八进制转义值或一个后向引用。如果 \nm 之前至少有is preceded by at least nm 个获取得子表达式，则 nm 为后向引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的后向引用。如果前面的条件都不满足，若  n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。 
		\nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 
		\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。 

		常用正则：
		1.验证用户名和密码：（ "^[a-zA-Z]\w{5,15}$ "）正确格式： "[A-Z][a-z]_[0-9] "组成,并且第一个字必须为字母6~16位； 
		2.验证电话号码：（ "^(\d{3.4}-)\d{7,8}$ "）正确格式：xxx/xxxx-xxxxxxx/xxxxxxxx； 
		3.验证身份证号（15位或18位数字）：（ "^\d{15} ¦\d{18}$ "）； 
		4.验证Email地址：( "^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ ")； 
		5.只能输入由数字和26个英文字母组成的字符串：( "^[A-Za-z0-9]+$ ") ; 
		6.整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
		7.只能输入数字： "^[0-9]*$ "。 
		8.只能输入n位的数字： "^\d{n}$ "。 
		9.只能输入至少n位的数字： "^\d{n,}$ "。 
		10.只能输入m~n位的数字：。 "^\d{m,n}$ " 
		11.只能输入零和非零开头的数字： "^(0 ¦[1-9][0-9]*)$ "。 
		12.只能输入有两位小数的正实数： "^[0-9]+(.[0-9]{2})?$ "。 
		13.只能输入有1~3位小数的正实数： "^[0-9]+(.[0-9]{1,3})?$ "。 
		14.只能输入非零的正整数： "^\+?[1-9][0-9]*$ "。 
		15.只能输入非零的负整数： "^\-[1-9][]0-9 "*$。 
		16.只能输入长度为3的字符： "^.{3}$ "。 
		17.只能输入由26个英文字母组成的字符串： "^[A-Za-z]+$ "。 
		18.只能输入由26个大写英文字母组成的字符串： "^[A-Z]+$ "。 
		19.只能输入由26个小写英文字母组成的字符串： "^[a-z]+$ "。 
		20.验证是否含有^%& &apos;,;=?$\ "等字符： "[^%& &apos;,;=?$\x22]+ "。 
		21.只能输入汉字： "^[\u4e00-\u9fa5]{0,}$ " 
		22.验证URL： "^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$ "。 
		23.验证一年的12个月： "^(0?[1-9] ¦1[0-2])$ "正确格式为： "01 "～ "09 "和 "1 "～ "12 "。 
		24.验证一个月的31天： "^((0?[1-9]) ¦((1 ¦2)[0-9]) ¦30 ¦31)$ "正确格式为； "01 "～ "09 "和 "1 "～ "31 "。
		25."^\d+$ "　　//非负整数（正整数 + 0） 
		26."^[0-9]*[1-9][0-9]*$ "　　//正整数 
		27."^((-\d+) ¦(0+))$ "　　//非正整数（负整数 + 0） 
		28."^-[0-9]*[1-9][0-9]*$ "　　//负整数 
		29."^-?\d+$ "　　　　//整数 
		30."^\d+(\.\d+)?$ "　　//非负浮点数（正浮点数 + 0）
		31."^(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*))$ "　　//正浮点数 
		32."^((-\d+(\.\d+)?) ¦(0+(\.0+)?))$ "　　//非正浮点数（负浮点数 + 0） 
		33."^(-(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*)))$ "　　//负浮点数
		34."^(-?\d+)(\.\d+)?$ "　　//浮点数 
		35."^[A-Za-z]+$ "　　//由26个英文字母组成的字符串
		36."^[A-Z]+$ "　　//由26个英文字母的大写组成的字符串 
		37."^[a-z]+$ "　　//由26个英文字母的小写组成的字符串 
		38."^[A-Za-z0-9]+$ "　　//由数字和26个英文字母组成的字符串 
		39."^\w+$ "　　//由数字、26个英文字母或者下划线组成的字符串
		40."^[\w-]+(\.[\w-]+)*@[\w-]+(\.[\w-]+)+$ "　　　　//email地址
		41."^[a-zA-z]+://(\w+(-\w+)*)(\.(\w+(-\w+)*))*(\?\S*)?$ "　　//url 
		42.提取信息中的网络链接: (h ¦H)(r ¦R)(e ¦E)(f ¦F) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		43.提取信息中的邮件地址: \w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)* 
		44.提取信息中的图片链接: (s ¦S)(r ¦R)(c ¦C) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		45.提取信息中的ip地址: (\d+)\.(\d+)\.(\d+)\.(\d+) 
		46.提取信息中的中国手机号码: (86)*0*13\d{9} 
		47.提取信息中的中国固定电话号码: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{8} 
		48.提取信息中的中国电话号码（包括移动和固定电话）: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{7,14} 
		49.提取信息中的中国邮政编码: [1-9]{1}(\d+){5} 
		50.提取信息中的中国身份证号码: \d{18} ¦\d{15} 
		51.提取信息中的整数： \d+ 
		52.提取信息中的浮点数（即小数）：(-?\d*)\.?\d+ 
		53.提取信息中的任何数字 ： (-?\d*)(\.\d+)? 
		54.提取信息中的中文字符串： [\u4e00-\u9fa5]* 
		55.提取信息中的双字节字符串 (汉字)：[^\x00-\xff]* 
		56.提取信息中的英文字符串：\w*
		57.提取任意HTML标记之间的内容：<script[\s\S]+</script *>
		58.高强度日期验证
		     ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-))$

		59.高强度日期+时间验证
		    ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-)) (20|21|22|23|[0-1]?\d):[0-5]?\d:[0-5]?\d$

		从上面我们可以看到: "^ "表示后面紧跟着的字符为开头;与之相对应的式 "$ "以紧跟前面的字符为结尾.但是要注意的式当 "^ "位于 "[] "里时,表示 "非 "的意思,例如:[^AZ]表示不能为 "AZ "中的任一个字符. "[] "表示当中的一个字符. "{} "可以取得一个范围,例如 "{9} "表示9个,而 "{1,9} "表示1到9个字符. 

		正则调试工具：
		/Files/yasin/RegexTester.zip 
		来自：http://www.cnblogs.com/yasin/archive/2009/07/20/1527013.html

* Squid cache 
	- Why should I deploy Squid?
		(Or.. "Why should I bother with web caching? Can't I just buy more bandwidth?")
		The developers of the HTTP protocol identified early on that there was going to be exponential growth in content and, concerned with distribution mechanisms, added powerful caching primitives.
		These primitives allow content developers and distributors to hint to servers and end-user applications how content should be validated, revalidated and cached. This had the effect of dramatically reducing the amount of bandwidth required to serve content and improved user response times.
		Squid is one of the projects which grew out of the initial content distribution and caching work in the mid-90s. It has grown to include extra features such as powerful access control, authorization, logging, content distribution/replication, traffic management and shaping and more. It has many, many work-arounds, new and old, to deal with incomplete and incorrect HTTP implementations.
		
		For ISPs: Save on bandwidth, improve user experience
		Squid allows Internet Providers to save on their bandwidth through content caching. Cached content means data is served locally and users will see this through faster download speeds with frequently-used content.
		A well-tuned proxy server (even without caching!) can improve user speeds purely by optimising TCP flows. Its easy to tune servers to deal with the wide variety of latencies found on the internet - something that desktop environments just aren't tuned for.
		Squid allows ISPs to avoid needing to spend large amounts of money on upgrading core equipment and transit links to cope with ever-demanding content growth. It also allows ISPs to prioritise and control certain web content types where dictacted by technical or economic reasons.
		
		For Websites: Scale your application without massive investment in hardware and development time
		Squid is one of the oldest content accelerators, used by thousands of websites around the world to ease the load on their servers. Frequently-seen content is cached by Squid and served to the end-client with only a fraction of the application server load needed normally. Setting up an accelerator in front of an existing website is almost always a quick and simple task with immediate benefits.
		
		For Content Delivery Providers: distribute your content worldwide
		Squid makes it easy for content distributors and streaming media developers to distribute content worldwide. CDN providers can buy cheap PC hardware running Squid and deploy in strategic locations around the internet to serve enormous amounts of data cheaply and efficiently.
		A large number of companies have deployed servers running Squid in the past in exactly this manner.

	- Squid cache（简称为Squid）是一个流行的自由软件（GNU通用公共许可证）的代理服务器和Web缓存服务器。
		Squid有广泛的用途，从作为网页服务器的前置cache服务器缓存相关请求来提高Web服务器的速度，到为一组人共享网络资源而缓存万维网，域名系统和其他网络搜索，
		到通过过滤流量帮助网络安全，到局域网通过代理上网。Squid主要设计用于在Unix一类系统运行。
	- 代理服务器和Web缓存服务器
	- Lighttpd->Squid->Apache :架构：
			上述处理链，Lighttpd在最前面，专门处理静态内容的请求，把动态内容请求通过 Proxy模块转发给Squid，如果Squid中有该请求的内容且没有过期，
		则直接返回给Lighttpd。新请求或者过期的页面请求交由Apache 中的脚本程序来处理。经过Lighttpd和Squid的两级过滤，Apache需要处理的请求大大减少，
		减少了Web应用程序的压力。同时这样的构架，便于把不同的处理分散到多台计算机上进行，由Lighttpd在前面统一分发。 
			在这种架构下，每一级都是可以进行单独优化的，比如Lighttpd可以采用异步IO方式，Squid可以启用内存来缓存，Apache可以启用 MPM（Multi -Processing Modules，
		多道处理模块）等，并且每一级都可以使用多台机器来均衡负载，伸缩性好。
	- summary
			Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. 
		Squid has extensive access controls and makes a great server accelerator. It runs on most available operating systems, including Windows and is licensed under the GNU GPL.
			Making the most of your Internet Connection
			Squid is used by hundreds of Internet Providers world-wide to provide their users with the best possible web access. Squid optimises the data flow between client and server to improve 
		performance and caches frequently-used content to save bandwidth. Squid can also route content requests to servers in a wide variety of ways to build cache server hierarchies which 
		optimise network throughput.
			Website Content Acceleration and Distribution
			Thousands of web-sites around the Internet use Squid to drastically increase their content delivery. Squid can reduce your server load and improve delivery speeds to clients. Squid can also be used 
		to deliver content from around the world - copying only the content being used, rather than inefficiently copying everything. Finally, Squid's advanced content routing configuration allows you to build 
		content clusters to route and load balance requests via a variety of web servers.
		
		[The Squid systems] are currently running at a hit-rate of approximately 75%, effectively quadrupling the capacity of the Apache servers behind them. This is particularly noticeable when a large surge 
		of traffic arrives directed to a particular page via a web link from another site, as the caching efficiency for that page will be nearly 100%. " - Wikimedia Deployment Information. 
	ref: http://www.squid-cache.org/Intro/
* hadoop
	- 提供暴露rest方式的service
		rest实现应该用了jersey(jersey jar)
	- sbin/hadoop-setup-hdfs.sh
		用户问题
		Optional parameters:
		     --format                                                        Force namenode format
		     --group=hadoop                                                  Set Hadoop group
		     -h                                                              Display this message
		     --hdfs-user=hdfs                                                Set HDFS user
		     --kerberos-realm=KERBEROS.EXAMPLE.COM                           Set Kerberos realm
		     --hdfs-user-keytab=/home/hdfs/hdfs.keytab                       Set HDFS user key tab
		     --mapreduce-user=mr                                             Set mapreduce user			
	- install		     参考：http://blog.csdn.net/starxu85/article/details/2120412
		svn: https://svn.apache.org/repos/asf/hadoop/common/tags/release-1.0.3/
			编译安装，要考虑jdk版本，ant版本，hadoop版本
		
		或者直接下rpm包安装，目录prefix不支持不推荐

		下载tar包，解压即可: 
			http://mirror.bjtu.edu.cn/apache/hadoop/common/stable/hadoop-1.0.3.tar.gz
			tar -xvf  hadoop-1.0.3.tar.gz	     （避免rpm包安装，文件散落在各个目录中）
			设置hadoop-env.sh配置java环境

		user
			groupadd hadoop
			useradd -d /hadoop/home -g hadoop hadoop
			chown -R hadoop:hadoop /hadoop 修改目录所有者
			passwd hadoop hadooppassword
		
		ssh无密码登陆（user hadoop）
		
		rpm安装，不指定prefix，默认安装
			/etc/hadoop/hadoop-env.sh
				设置环境参数，java配置等等
			hadoop-site.xml
				配置
		/etc/init.d/hadoop/hadoop-namenode statt
		tail -f /var/log/hadoop/xxx.log

		hadoop账户启动服务，执行目录，日志目录，通过chown让hadoop具有权限。

	-  这里先大致介绍一下Hadoop.
			本文大部分内容都是从官网Hadoop上来的。其中有一篇介绍HDFS的pdf文档，里面对Hadoop介绍的比较全面了。我的这一个系列的Hadoop学习笔记
		    也是从这里一步一步进行下来的，同时又参考了网上的很多文章，对学习Hadoop中遇到的问题进行了归纳总结。
			言归正传，先说一下Hadoop的来龙去脉。谈到Hadoop就不得不提到Lucene和Nutch。首先，Lucene并不是一个应用程序，而是提供了一个纯Java的高性能
		全文索引引擎工具包，它可以方便的嵌入到各种实际应用中实现全文搜索/索引功能。Nutch是一个应用程序，是一个以Lucene为基础实现的搜索引擎应用，
		Lucene为Nutch提供了文本搜索和索引的API，Nutch不光有搜索的功能，还有数据抓取的功能。在nutch0.8.0版本之前，Hadoop还属于Nutch的一部分，而从nutch0.8.0开始，
		将其中实现的NDFS和MapReduce剥离出来成立一个新的开源项目，这就是Hadoop，而nutch0.8.0版本较之以前的Nutch在架构上有了根本性的变化，那就是完全构建在
		Hadoop的基础之上了。在Hadoop中实现了Google的GFS和MapReduce算法，使Hadoop成为了一个分布式的计算平台。
		   其实，Hadoop并不仅仅是一个用于存储的分布式文件系统，而是设计用来在由通用计算设备组成的大型集群上执行分布式应用的框架。
		   Hadoop包含两个部分：

		   1)HDFS

		      即Hadoop Distributed File System (Hadoop分布式文件系统)
				HDFS具有高容错性，并且可以被部署在低价的硬件设备之上。HDFS很适合那些有大数据集的应用，并且提供了对数据读写的高吞吐率。HDFS是一个master/slave的结构，
		      就通常的部署来说，在master上只运行一个Namenode，而在每一个slave上运行一个Datanode。
		      HDFS支持传统的层次文件组织结构，同现有的一些文件系统在操作上很类似，比如你可以创建和删除一个文件，把一个文件从一个目录移到另一个目录，
		      重命名等等操作。Namenode管理着整个分布式文件系统，对文件系统的操作（如建立、删除文件和文件夹）都是通过Namenode来控制。 
		     下面是HDFS的结构：

				从上面的图中可以看出，Namenode，Datanode，Client之间的通信都是建立在TCP/IP的基础之上的。当Client要执行一个写入的操作的时候，命令不是马上就发送
		      到Namenode，Client首先在本机上临时文件夹中缓存这些数据，当临时文件夹中的数据块达到了设定的Block的值（默认是64M）时，Client便会通知Namenode，
		      Namenode便响应Client的RPC请求，将文件名插入文件系统层次中并且在Datanode中找到一块存放该数据的block，同时将该Datanode及对应的数据块信息告诉Client，
		      Client便这些本地临时文件夹中的数据块写入指定的数据节点。
				HDFS采取了副本策略，其目的是为了提高系统的可靠性，可用性。HDFS的副本放置策略是三个副本，一个放在本节点上，一个放在同一机架中的另一个节点上，
		      还有一个副本放在另一个不同的机架中的一个节点上。当前版本的hadoop0.12.0中还没有实现，但是正在进行中，相信不久就可以出来了。

		   2) MapReduce的实现

			      MapReduce是Google 的一项重要技术，它是一个编程模型，用以进行大数据量的计算。对于大数据量的计算，通常采用的处理手法就是并行计算。至少现阶段而言，
		      对许多开发人员来说，并行计算还是一个比较遥远的东西。MapReduce就是一种简化并行计算的编程模型，它让那些没有多少并行计算经验的开发人员也可以开发并行应用。
				MapReduce的名字源于这个模型中的两项核心操作：Map和 Reduce。也许熟悉Functional Programming（函数式编程）的人见到这两个词会倍感亲切。简单的说来，
		      Map是把一组数据一对一的映射为另外的一组数据，其映射的规则由一个函数来指定，比如对[1, 2, 3, 4]进行乘2的映射就变成了[2, 4, 6, 8]。Reduce是对一组数据进行归约，
		      这个归约的规则由一个函数指定，比如对[1, 2, 3, 4]进行求和的归约得到结果是10，而对它进行求积的归约结果是24。
		      关于MapReduce的内容，建议看看孟岩的这篇MapReduce:The Free Lunch Is Not Over!

		   好了，作为这个系列的第一篇就写这么多了，我也是刚开始接触Hadoop，下一篇就是讲Hadoop的部署，谈谈我在部署Hadoop时遇到的问题，也给大家一个参考，少走点弯路。

		- 公钥认证过程 数字签名 非对称加密
			简单的说，在dbrg-1上需要生成一个密钥对，即一个私钥，一个公钥。将公钥拷贝到dbrg-2，dbrg-3上，这样，比如当dbrg-1向dbrg-2发起ssh连接的时候，
		dbrg-2上就会生成一个随机数并用dbrg-1的公钥对这个随机数进行加密，并发送给dbrg-1；dbrg-1收到这个加密的数以后用私钥进行解密，并将解密后的数发送回dbrg-2，
		dbrg-2确认解密的数无误后就允许dbrg-1进行连接了。这就完成了一次公钥认证过程。
* gfs
	一曰google file system	   (google)
	一曰global file system  (redhat)

* mina 以及基于mina的应用，如apache的纯java ftp server
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
	It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.

	 Apache FtpServer
		The Apache FtpServer is a 100% pure Java FTP server. It's designed to be a complete and portable FTP server engine solution based on currently available open protocols. 
		FtpServer can be run standalone as a Windows service or Unix/Linux daemon, or embedded into a Java application. We also provide support for integration within Spring 
		applications and provide our releases as OSGi bundles.
		from：http://mina.apache.org/ftpserver/index.html
	mina：http://mina.apache.org/downloads.html

The default network support is based on Apache MINA, a high performance asynchronous IO library. Using MINA, FtpServer can scale to a large number of concurrent users.

It is also an FTP application platform. We have developed a Java API to let you write Java code to process FTP event notifications that we call the Ftplet API. Apache FtpServer provides an implementation of an FTP server to support this API.

* Confluence 2.9.
	- 企业级 wiki ，便于交流互动 ，文档修改并记录历史类似版本控制，可以回滚，很是方便
* junit
	- 参考开源框架使用junit的方式 eg: metaq
	- junit fixture工作
		方法执行前准备工作，可以通过注解来配置，比如 @Before表示在每个用例执行前都行执行这个before注解的方法。

	-	请牢记！请牢记这一条 JUnit 最佳实践：测试任何可能的错误。单元测试不是用来证明您是对的，而是为了证明您没有错。
		JUnit 深入
		当然，JUnit 提供的功能决不仅仅如此简单，在接下来的内容中，我们会看到 JUnit 中很多有用的特性，掌握它们对您灵活的编写单元测试代码非常有帮助。
		Fixture
			何谓 Fixture ？它是指在执行一个或者多个测试方法时需要的一系列公共资源或者数据，例如测试环境，测试数据等等。在编写单元测试的过程中，
		您会发现在大部分的测试方法 在进行真正的测试之前都需要做大量的铺垫——为设计准备 Fixture 而忙碌。这些铺垫过程占据的代码往往比真正测试的代码多得多，
		而且这个比率随着测试的复杂程度的增加而递增。当多个测试方法都需要做同样的铺垫时，重复代 码的“坏味道”便在测试代码中弥漫开来。这股“坏味道”会弄脏您的代码，
		还会因为疏忽造成错误，应该使用一些手段来根除它。
			JUnit 专门提供了设置公共 Fixture 的方法，同一测试类中的所有测试方法都可以共用它来初始化 Fixture 和注销 Fixture。和编写 JUnit 测试方法一样，
		公共 Fixture 的设置也很简单，您只需要：
		1).使用注解 org,junit.Before 修饰用于初始化 Fixture 的方法。
		2).使用注解 org.junit.After 修饰用于注销 Fixture 的方法。
		3).保证这两种方法都使用 public void 修饰，而且不能带有任何参数。

* test * mock  * jmock		       * 单元测试 * 集成测试		 * jtester
	- jtest用unitils的@SpringBeanByName注解时注意，注解的属性可以不在spring里配置，需要通过其他类注入了此属性来测试
	- 定义期望执行expectation时，如果步骤多，不易于定位那里不对			  -tip-
		可以通过化整为零方式，去掉所有的期望，从第一个执行开始，结合debug逐步补充上执行过程中需要的expectation。
		需要什么就mock或expect什么
				
	- jtester mock 自身方法，私有方法等
		------
			new MockUp<AbstractExecuteAction>() {
						@SuppressWarnings("unused")
						@Mock
						public ResultDomain getResourceOwner(){
							ResultDomain result = ResultDomainVisitor.createSuccessResult();
							Map<String,Object> map = new HashMap<String, Object>();
							map.put(GroupParameter.RESOURCE_OWNER.getName(), "1");
							result.setData(map);
							return result;
						}
					};
		------

		私有方法，可在mock块中声明为public类型，例如：
		----
		...
			new MockUp<xxxServiceImpl>(){
				@SuppressWarnings("unused")
				@Mock
				public void removeXXX(List<xxx> xxx) {//原方法为private，此处定义为public以免执行时报无access权限
					//do nothing
				}
			};
		...
		----
	- jtester
		mock时，可通过比较未mock对象和mocked对象的运行状态值（cglib or jdk proxy）来判断是否正确mock了。
	- 单元测试ok后，可以进行集成测试，以测试集成逻辑调用是否ok，比如各个环节的集成调用。
		
	- 查找框架已提供的mock类
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。
	- jtester ,用jmock框架
		写期望 Expectations 时，要注意按照调用次序写 -tip-
				a. 
					when(resourceQueryFacade.query(Instance.class, (String[])any)).thenReturn(new Instance[]{new Instance(),new Instance()}); //java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Lcom.aliyun.houyi.entity.Instance;
				b. 
					//resourceQueryFacade.query(Instance.class, (String[])any);
					//returnValue(new Instance[]{new Instance(),new Instance()});
				上面2中写法结果不一样。
		报 unexpected invocation 错误时，一般为expectation顺序不对，或者个数不对，比如某个方法有2个拦截器判断，就需要写2个expectation
			可以通过一步步 debug 找到那里写的不对（笨了点，但实用，终极解决 ~~）
				主要是通过反射执行代码，debug时要注意。debug也帮助理解mock测试的过程。比如：方法执行前会先执行方法拦截器。 -tip-
				“ ----------- 一步步的debug，验证执行逻辑是否符合预期，也能知道是什么原因导致用例执行失败。----------"
					是expectation顺序不对，还是数目不对或是其他，都可找到。
		如果一个对象被mock了，那么每次调用的expectation需要编写，否则返回null（在一些场合就会报错）
	- void mock 无返回值方法mock mock void
		直接mock那个对象或相应的方法，不做处理即可。
	- new Expectations(){
		理解Expectations的含义：
			Expectations即期望，录制期望发生的动作（设置期望返回值），执行时，按照期望的顺序执行（如不是期望定义的顺序会报错）。
		期望Expectations与mock的关系？
			expectations里 要按照执行顺序写期望逻辑。
				否则报调用错误 unexpected invocation xxx
		参考下面jmock的说明：
			JMockit Expectations

			TheJMockit Expectationsmocking API provides arecord-replaymodel for writingbehavior-basedtests. In this model, a test
			begins by setting one or moreexpectationson the invocations made from code under test to its collaborators (dependencies). 
				The classes and instances for such dependencies are established through the declaration of one or
			moremocked typesinside the test class/method. Such mocked types can be declared through instance fields of the test
			class or of an Expectations anonymous subclass inside a test method, and also through parameters of test methods
			(even though JUnit and TestNG don't allow regular test methods to have parameters). After expectations are defined in
			thisrecording phase, the test transitions to thereplay phase, when the code under test is exercised. The invocations that
			actually occur on the mocked collaborators are handled according to the mocked type declarations and the corresponding
			expectations recorded on them (if any). At the end of the replay phase, those expectations for which one or more
			invocations were expected are automatically verified so that missing invocations can be detected.
	- mock私有方法时，参数的设置方式如下，否则报类似错误：Invalid null value passed as argument 0 (instead of null, provide the Class object for the parameter type)
		
	- 单元测试
		做的好处多，特别对于合作开发，对可变情况的检测，功能完整性，逻辑错误等等。
	- junit mock
		执行顺序
			是否可以手动顺序调用用例？
		数据库测试支持 ，类似jtester?
	- easymock与junit结合 
		EasyMock:
			http://www.easymock.org/
			EasyMock provides Mock Objects for interfaces (and objects through the class extension) by generating them on the fly using Java's proxy mechanism. Due to EasyMock's unique style of recording expectations, most refactorings will not affect the Mock Objects. So EasyMock is a perfect fit for Test-Driven Development.
		例子：
			-----
			...
				public void testRegisterUser() {   
					User user = new User();   
					user.type = "vip";   
					userDao = createMock(UserDao.class);   
					expect(userDao.insertUser(user)).andReturn(true);   
					replay(userDao);   
					userService.setUserDao(userDao);   
					assertEquals(true, userService.registerUser(user));   
					verify(userDao);  
				} 
			...
			-----
* struts
	- struts2的返回
		根据action的result的配置，定义返回值，可自定义一个result继承框架的result接口接口，在返回给client前进行特殊处理。

	- ValueStack valueStack = con.getValueStack();
			ResultDomain result = (ResultDomain)valueStack.findValue(ResultDomainVisitor.RESULT_KEY, ResultDomain.class);
	- ActionContext
		内部实现为 ThreadLocal
	- struts拦截器测试 ，interceptor 测试
		struts2框架提供了相应的mock类，便于测试 ，比如：
			com.opensymphony.xwork2.mock.MockActionInvocation
		spring框架页提供了struts框架等框架类的mock实现，方便测试 比如：org.springframework.mock.web.MockHttpServletRequest
		
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。

* bat 批处理 不继续执行  (搜素 bat 调用mvn - 对于bat执行好mvn后就不继续执行其他操作的问题解决搜索关键词)
	- start命令
		下面是一个小脚本，批量启动开机后需要打开的程序。
		pre.bat
		-----
		...
			echo day pre...
			echo chrome
			start C:\Users\wb_shen.chengs\AppData\Local\Google\Chrome\Application\chrome.exe
			echo eclipse
			start D:\eclipse\eclipse.exe
			echo outlook
			start outlook.exe /resetnavpane
			echo wangwang
			call "D:\PROGRA~1\AliWangWang\AliIM.exe" /run:desktop
		...
		------
	- mavn web project 自动部署启动容器脚本(bat脚本)
		-------
			rem Eclipse 开发 maven web project部署脚本，便于部署调试

			echo stop tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call shutdown.bat

			echo build...
			echo
			cd D:\workspace\SLB-API-v2
			call mvn clean package

			echo delpoy...
			echo
			cd target
			cp -r slb.war D:\apache-tomcat-6.0.35\webapps

			echo start tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call startup.bat

			:end
		-------
	-
		在于不熟悉bat。联想到shell脚本，shell脚本会继续执行
		-------
			bat中mvn命令执行完后不继续执行的解决方法
			2012-04-24 17:29codeif.com 比如有下面一段批处理程序
			mvn clean
			echo “hello world”

			输出如下
			…..
			[INFO] BUILD SUCCESSFUL
			[INFO] ————————————————————————
			[INFO] Total time: 25 seconds
			[INFO] Finished at: Tue Apr 24 17:21:55 CST 2012
			[INFO] Final Memory: 43M/123M
			[INFO] ————————————————————————
			D:\test>

			hello world并没有输出,没有达到我们的预期
			在mvn前加上call,改为如下后
			call mvn clean
			echo “hello world”

			hello word就会输出了

			cmd命令行中Call的使用如下:
			Call 从一个批处理程序调用另一个批处理程序，并且不终止父批处理程序。
		------

* rest
	rest方式的请求，根据uri定位资源 ，各种http方法发送的请求 可以用matrix url请求rest服务

* Redis
	　　redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。
	http://redis.io/

* Memcached  
	- 缓存系统MemCached的Java客户端优化历程 http://www.infoq.com/cn/articles/memcached-java
		参考
			用concurrent包替换原先synchronize关键字
			

	- HA的实现
		Memcached 是什么？
			Memcached是一种集中式Cache，支持分布式横向扩展。这里需要解释说明一下，很多开发者觉得Memcached是一种分布式缓存系统，
			但是其实Memcached服务端本身是单实例的，只是在客户端实现过程中可以根据存储的主键做分区存储，而这个区就是Memcached服务端的一个或者多个实例，
			如果将客户端也囊括到Memcached中，那么可以部分概念上说是集中式的。其实回顾一下集中式的构架，无非两种情况：一是节点均衡的网状（JBoss Tree Cache），
			利用JGroup的多播通信机制来同步数据；二是Master-Slaves模式（分布式文件系统），由Master来管理Slave，比如如何选择Slave，如何迁移数据等都是由Master来完成，
			但是Master本身也存在单点问题。下面再总结几个它的特点来理解一下其优点和限制。
		内存存储：
			不言而喻，速度快，但对于内存的要求高。这种情况对CPU要求很低，所以常常采用将Memcached服务端和一些CPU高消耗、内存低消耗应用部署在一起。
			（我们的某个产品正好有这样的环境，我们的接口服务器有多台，它们对CPU要求很高——原因在于WS-Security的使用，但是对于内存要求很低，因此可以
			用作Memcached的服务端部署机器）。
		集中式缓存（Cache）：
			避开了分布式缓存的传播问题，但是需要非单点来保证其可靠性，这个就是后面集成中所作的集群（Cluster）工作，可以将多个Memcached作为一个虚拟的集群，
			同时对于集群的读写和普通的Memcached的读写性能没有差别。
		分布式扩展：
			Memcached很突出的一个优点就是采用了可分布式扩展的模式。可以将部署在一台机器上的多个Memcached服务端或者部署在多个机器上的Memcached服务端组成
			一个虚拟的服务端，对于调用者来说则是完全屏蔽和透明的。这样做既提高了单机的内存利用率，也提供了向上扩容（Scale Out）的方式。
		Socket通信：
			这儿需要注意传输内容的大小和序列化的问题，虽然Memcached通常会被放置到内网作为缓存，Socket传输速率应该比较高（当前支持TCP和UDP两种模式，同时
			根据客户端的不同可以选择使用NIO的同步或者异步调用方式），但是序列化成本和带宽成本还是需要注意。这里也提一下序列化，对于对象序列化的性能往往
			让大家头痛，但是如果对于同一类的Class对象序列化传输，第一次序列化时间比较长，后续就会优化，也就是说序列化最大的消耗不是对象序列化，而是类的序列化。
			如果穿过去的只是字符串，这种情况是最理想的，省去了序列化的操作，因此在Memcached中保存的往往是较小的内容。
		特殊的内存分配机制：
			首先要说明的是Memcached支持最大的存储对象为1M。它的内存分配比较特殊，但是这样的分配方式其实也是基于性能考虑的，简单的分配机制可以更容易回收再分配，
			节省对CPU的使用。这里用一个酒窖做比来说明这种内存分配机制，首先在Memcached启动的时候可以通过参数来设置使用的所有内存——酒窖，然后在有酒进入的时候，
			首先申请（通常是1M）的空间，用来建酒架，而酒架根据这个酒瓶的大小将自己分割为多个小格子来安放酒瓶，并将同样大小范围内的酒瓶都放置在一类酒架上面。
			例如20厘米半径的酒瓶放置在可以容纳20-25厘米的酒架A上，30厘米半径的酒瓶就放置在容纳25-30厘米的酒架B上。回收机制也很简单，首先新酒入库，看看酒架是否有
			可以回收的地方，如果有就直接使用，如果没有则申请新的地方，如果申请不到，就采用配置的过期策略。从这个特点来看，如果要放的内容大小十分离散，同时大小比例
			相差梯度很明显的话，那么可能对于空间使用来说效果不好，因为很可能在酒架A上就放了一瓶酒，但却占用掉了一个酒架的位置。
		缓存机制简单：
			有时候很多开源项目做的面面俱到，但到最后因为过于注重一些非必要的功能而拖累了性能，这里提到的就是Memcached的简单性。首先它没有什么同步，消息分发，
			两阶段提交等等，它就是一个很简单的缓存，把东西放进去，然后可以取出来，如果发现所提供的Key没有命中，那么就很直白地告诉你，你这个Key没有任何对应的
			东西在缓存里，去数据库或者其他地方取；当你在外部数据源取到的时候，可以直接将内容置入到缓存中，这样下次就可以命中了。这里介绍一下同步这些数据的两种方式：
			一种是在你修改了以后立刻更新缓存内容，这样就会即时生效；另一种是说容许有失效时间，到了失效时间，自然就会将内容删除，此时再去取的时候就不会命中，然后
			再次将内容置入缓存，用来更新内容。后者用在一些实时性要求不高，写入不频繁的情况。
		客户端的重要性：
			Memcached是用C写的一个服务端，客户端没有规定，反正是Socket传输，只要语言支持Socket通信，通过Command的简单协议就可以通信。但是客户端设计的合理十分重要，
			同时也给使用者提供了很大的空间去扩展和设计客户端来满足各种场景的需要，包括容错、权重、效率、特殊的功能性需求和嵌入框架等等。
		几个应用点：
			小对象的缓存（用户的Token、权限信息、资源信息）；小的静态资源缓存；SQL结果的缓存（这部分如果用的好，性能提高会相当大，同时由于Memcached自身提供向上扩容，
			那么对于数据库向上扩容的老大难问题无疑是一剂好药）；ESB消息缓存。
		from: http://www.cnblogs.com/chenying99/archive/2012/06/29/2568958.html

	- 使用外部缓存框架，对应程序，通过统一接口调用，
	- memcached的交互接口
			    memcached的客户端通过TCP连接与服务器通信（UDP协议的接口也可以使用，详细说明请参考”UDP 协议”部分）。一个给定的运行中的memcached服务器在某个（可配置的）端口上监听连接；客户端连接该端口，发送命令给服务器，读取反馈，最后关闭连接。
	       没有必要发送一个专门的命令去结束会话。客户端可以在不需要该连接的时候就关闭它。注意：我们鼓励客户端缓存它们与服务器的连接，而不是每次要存储或读取数据的时候再次重新建立与服务器的连接。memcache同时打开很多连接不会对性能造成到大的影响，这是因为memcache在设计之处，就被设计成即使打开了很多连接（数百或者需要时上千个连接）也可以高效的运行。缓存连接可以节省与服务器建立TCP连接的时间开销（于此相比，在服务器段为建立一个新的连接所做准备的开销可以忽略不计）。
	       memcache通信协议有两种类型的数据：文本行和非结构化数据。文本行用来发送从客户端到服务器的命令以及从服务器回送的反馈信息。非结构化的数据用在客户端希望存储或者读取数据时。服务器会以字符流的形式严格准确的返回相应数据在存储时存储的数据。服务器不关注字节序，它也不知道字节序的存在。memcahce对非结构化数据中的字符没有任何限制，可以是任意的字符，读取数据时，客户端可以在前次返回的文本行中确切的知道接下来的数据块的长度。
	       文本行通常以“"r"n”结束。非结构化数据通常也是以“"r"n”结束，尽管"r、"n或者其他任何8位字符可以出现在数据块中。所以当客户端从服务器读取数据时，必须使用前面提供的数据块的长度，来确定数据流的结束，二不是依据跟随在字符流尾部的“"r"n”来确定数据流的结束，尽管实际上数据流格式如此。

	c 实现
	项目主页: http://code.google.com/p/memcached/wiki/Clients	
	说明：
		memcached is a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. 
	Danga Interactive developed memcached to enhance the speed of LiveJournal.com, a site which was already doing 20 million+ dynamic page views per day for 1 million users with a bunch of webservers and a bunch of database servers. memcached dropped the database load to almost nothing, yielding faster page load times for users, better resource utilization, and faster access to the databases on a memcache miss. 
	If you're a developer, or interested in helping us along, please help test the latest beta release on the download page. We work hard to ensure the beta releases are of high quality, but as with all beta software, be warned. 
	
	 开源的东西，潜力与生俱来
	
	启动：
		memcached -d -m 10 -u root -l 192.168.232.162  -p 12000 -c 256 -P /tmp/memcached.pid
		
		client: 官网说明：
			http://code.google.com/p/memcached/wiki/Clients
	安装：
		
		- 需要libevent库 需要制定prefix
			wget http://github.com/downloads/libevent/libevent/libevent-2.0.18-stable.tar.gz --no-check-certificate
			tar -zxvf libevent-2.0.18-stable.tar.gz
			./configure --prefix=/usr
			make
			make install
			再继续memcache安装
			例子：
					Linux下Memcache服务器端的安装
					服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
					下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
					另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
					官网：http://www.monkey.org/~provos/libevent/
					下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

					用wget指令直接下载这两个东西.下载回源文件后。
					1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
					2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
					这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

					    1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
					    # cd /tmp
					    # wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
					    # wget http://www.monkey.org/~provos/libevent-1.2.tar.gz

					    2.先安装libevent：
					    # tar zxvf libevent-1.2.tar.gz
					    # cd libevent-1.2
					    # ./configure –prefix=/usr
					    # make
					    # make install

					    3.测试libevent是否安装成功：
					    # ls -al /usr/lib | grep libevent
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
					    -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
					    -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
					    -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
					    还不错，都安装上了。

					    4.安装memcached，同时需要安装中指定libevent的安装位置：
					    # cd /tmp
					    # tar zxvf memcached-1.2.0.tar.gz
					    # cd memcached-1.2.0
					    # ./configure –with-libevent=/usr
					    # make
					    # make install
					    如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
					    安装完成后会把memcached放到 /usr/local/bin/memcached ，

					    5.测试是否成功安装memcached：
					    # ls -al /usr/local/bin/mem*
					    -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
					    -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug 

					安装Memcache的PHP扩展
					1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
					2.安装PHP的memcache扩展

					    tar vxzf memcache-2.2.1.tgz
					    cd memcache-2.2.1
					    /usr/local/php/bin/phpize
					    ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
					    make
					    make install

					3.上述安装完后会有类似这样的提示：

					    Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

					4.把php.ini中的extension_dir = “./”修改为

					    extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

					5.添加一行来载入memcache扩展：extension=memcache.so

					memcached的基本设置：
					1.启动Memcache的服务器端：
					# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

					    -d选项是启动一个守护进程，
					    -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
					    -u是运行Memcache的用户，我这里是root，
					    -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
					    -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
					    -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
					    -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

					2.如果要结束Memcache进程，执行：

					    # kill `cat /tmp/memcached.pid`

					也可以启动多个守护进程，不过端口不能重复。

					3.重启apache，service httpd restart

					Memcache环境测试：
					运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
					< ?php
					$mem = new Memcache;
					$mem->connect(”127.0.0.1″, 11211);
					$mem->set(’key’, ‘This is a test!’, 0, 60);
					$val = $mem->get(’key’);
					echo $val;
					?>
					来自：http://blog.csdn.net/21aspnet/article/details/6827316
					
				服务端启动ok
				设置client调用？

	- 访问linux虚拟机中的memcache,需要设置linux防火墙规则，否则不能访问服务 key=centos memcache 访问
		-------
			在虚拟机里安装了centos，在centos里安装memcached服务器,可是在本机里使用memcached的php扩展来访问虚拟机里centos的memcached服务时，没有响应，发现PHP的日志里有以下信息：
			[html] view plaincopyprint?
			01.[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。  
			[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。


			后来在网上找了一些资料，才找到解决办法。即是在centos的iptable增加两条规则，让用户可以访问虚拟机的memcached的服务。
			命令如下：
			#/sbin/iptables -I INPUT -p tcp --dport 11211 -j ACCEPT
			#/sbin/iptables -I INPUT -p udp --dport 11211 -j ACCEPT
			/etc/ini.d/iptabls save/status
			如果启动memcached服务时用了其他端口，在将你的端口号代替11211. 
		-------
	- 用了gwhalin 的Memcached-Java-Client  api，基本操作ok

	这个java版本的memcached客户端，实现了多memcached集群实例的存取支持(需要避免热点cache)。
		参看：SockIOPool类
			提供3种hash方式，不同的方法对缓存分布是否均匀有影响以及是否支持多client。说明如下：
				- SockIOPool.NATIVE_HASH (0)     - native String.hashCode() - fast (cached) but not compatible with other clients
				- SockIOPool.OLD_COMPAT_HASH (1)	- original compatibility hashing alg (works with other clients)
				- SockIOPool.NEW_COMPAT_HASH (2)	- new CRC32 based compatibility hashing algorithm (fast and works with other clients)
				- SockIOPool.CONSISTENT_HASH(3)	- MD5 Based -- Stops thrashing when a server added or removed
				以及consistent hash的实现，避免了key在服务节点列表上的重新分布，有的还实现了虚拟节点让缓存发布更加均匀。

	------
		public class test {

			public static void main(String[] args) {
				
				MemcachedClient mc = new MemcachedClient();
				
				mc.add("a", 1);
				
				System.out.println(mc.get("a"));
				
			}
			
			
			//inital iopool
			static {
				String[] serverlist = { "192.168.232.162:12000" };

				SockIOPool pool = SockIOPool.getInstance();
				pool.setServers(serverlist);
				pool.initialize();	
			}

			
		}
	------
* mongodb

* Elastic IP 弹性IP
	Elastic IP Addresses – Elastic IP addresses are static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account not a 
	particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to 
	mask instance or Availability Zone failures by programmatically remapping your public IP addresses to any instance in your account. Rather than waiting on a data technician 
	to reconfigure or replace your host, or waiting for DNS to propagate to all of your customers, Amazon EC2 enables you to engineer around problems with your instance or
	software by quickly remapping your Elastic IP address to a replacement instance. In addition, you can optionally configure the reverse DNS record of any of your Elastic IP
	addresses by filling out this form.

* json
	- 测试 json转换为map对象
		String str3 = "{\"code\":200,\"msg\":\"successful\",\"data\":{ \"lb_id\":\"123\",\" eip\":\"10.250.6.36\"}}";
		Map map3 = (Map)JSONObject.toBean(JSONObject.fromObject(str3),HashMap.class);
		System.out.println(map3.get("msg"));//successful
* ibatis
	- 缓存及其扩展
		比如结合memcached使用(oscache为默认配置)
		iBatis提供CacheController接口，用于实现第三方缓存架构的扩展
		http://blog.csdn.net/ecsoftcn/article/details/1777904
		
		memcached整合ibatis
		ibatis自带的本地缓存有FIFO，LRU等，对于分布式缓存也有osCache支持，而最常用的memcached也可以整合到ibatis里滴，这样通过map关系配置，就省了很多硬编码。
		http://www.cnblogs.com/langke93/archive/2011/03/30/2217387.html

		iBatis整理——EhCache支持扩展
		http://snowolf.iteye.com/blog/1481969

		目的：
			ibatis结合memcached实现分布式缓存(比如查询缓存)

		基于上面小节下，ibatis默认没有内置memcached的缓存支持，但是设计上已考虑到缓存实现的不同，提供了CacheController接口用于自定义缓存实现，基于这个接口ibatis内置实现了
		FIFO,LRU,OSCACHE,MEMERY，现在可以自己实现用于memcached的CacheController实现，再进行相应的配置即可。这里可以学习下ibatis的接口设计，易于扩展，也体现了对于涉及具体
		实现的地方需要考虑是否需要扩展，从而设计为接口。-tip- * 架构 * 设计 * 扩展
	- ibatis也支持简单的内置对象返回
		比如用queryList方法返回resultClass="hashmap"的List<Map>数据结构
	- mapping文件语句定义
		插入数据时，返回其主键（自定义查询的主键）
		<insert id="insertImage" parameterMap="imageParameter">
		insert into xxx(id,new_id,name)
		values(?,?,?)
		<selectKey resultClass="long" keyProperty="newId">
			select last_insert_id() as new_id from xxx limit 1
		</selectKey>
		</insert>

	- mapping文件，标签属性的意义整理：     there is a trick if u ignore this^^ 
		比如<select></select>标签中：
			resultMap	  自定义返回结果bean的map映射定义，通过map定义将结果集映射为bean	 ,将查询结果集映射到不同的对象
				返回对象为自定义的class
			resultClass 基本类
				返回对象为标准class
			parameterMap 自定义参数bean到参数map的映射，可以定义参数对象的属性如何映射到SQL查询语句的动态参数上
			paremeterClass 基本参数类


	- ibatis属性转换，自定义转换 TypeHandlerCallback
		通过在mapping文件中直接定义或者统一定义
		（1）各自的mapping文件中	（sqlMap）
			<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
			<typeAlias alias="snapshotStorageTypeHandler" type="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>	
			<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER" typeHandler="snapshotStorageTypeHandler"/>
		（2）在config文件中统一配置（sqlMapConfig）
			<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
			<typeHandler javaType="snapshotStorageType" callback="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>

			<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER"/>
	- where calse的共用需要设计好，否则反而增加维护
		<isNotEqual>语句需要注意，类似if..else，可能会意外带入条件，最好还是用匹配上的条件去判断<isNotEmpty>,<isEqual>
	- in查询，条件sql
		select 
			xx
		 from xx
		 where  
		 <iterate property="userIds" prepend=" xx " open="(" close=")" conjunction=",">
			#ids[]#
		 </iterate> 
	- ibatis mapping文件检查       ，ibatis启动
		会验证每个语句的传入参数/对象是否和定义的名称一致，不一致报出来相应的语句错误。	单元测试加载ibatis框架以验证mapping文件格式正确。
	- * SQL预编译
		下面我们就来详细看一下有关预编译的一些知识。
		   1、什么是预编译语句
		   预编译语句PreparedStatement 是java.sql中的一个接口，它是Statement的子接口。通过Statement对象执行SQL语句时，需要将SQL语句发送给DBMS，由DBMS首先进行编译后再执行。预编译语句和Statement不同，在创建PreparedStatement 对象时就指定了SQL语句，该语句立即发送给DBMS进行编译。当该编译语句被执行时，DBMS直接运行编译后的SQL语句，而不需要像其他SQL语句那样首先将其编译。
		   2、什么时候使用预编译语句
		   一般是在需要反复使用一个SQL语句时才使用预编译语句，预编译语句常常放在一个fo r或者while循环里面使用，通过反复设置参数从而多次使用该SQL语句。为了防止SQL注入漏洞，在某些数据操作中也使用预编译语句。
		   3、为什么使用预编译语句
		   预编译机制除了在开篇提到的可以防止SQL注入外，还有一下两方面的优点：
		   (1)提高效率
		   数据库处理一个SQL语句，需要完成解析SQL语句、检查语法和语义以及生成代码，一般说来，处理时间要比执行语句所需要的时间长。预编译语句在创建的时候已经是将指定的SQL语句发送给了DBMS，完成了解析、检查、编译等工作。因此，当一个SQL语句需要执行多次时，使用预编译语句可以减少处理时间，提高执行效率。
		   (3)提高代码的可读性和可维护性
		   将参数与SQL语句分离出来，这样就可以方便对程序的更改和扩展，同样，也可以减少不必要的错误。
		   4、预编译语句的使用
		   代码段二中创建了包含带两个 IN 参数占位符的 PreparedStatement 对象，在执行之前，必须设置每个 ? 参数的值。这可通过调用 setXXX 方法来完成，该方法的第一个参数是要设置的参数的序数位置，第二个参数是设置给该参数的值，其中 XXX 是与该参数相应的类型。例如，以下代码将第一个参数设为 “tom”，第二个参数设为 “123456a”：
		   pstmt.setString(1, “tom”);
		   pstmt.setString(2, “123456a”);
		   一旦设置了给定语句的参数值，其值将一直保留，直到被设置为新值或者调用clearParameters()方法清除它为止。
		   问题延伸：请大家看一下以下的代码：
		    String sqlSt = “sel ect* from table1 where name=”+tb_name+” and passwo rd=”+tb_pwo rd;
		   PrepareStatement pst = con.createPreparementStatement();
		   ResultSet rsPst = pst.exe cuteQuery(sqlSt);
		 
		    那么在安全性和执行效率方面会不会有问题呢？请感兴趣的同事可以自己尝试一下吧。
		    from：http://www.52testing.com/showart.asp?id=67

	- ibatis 与sql注入
		假设用户执行
		    select * from product where id = 5 
		    这条语句。其中5是有用户输入的。
		    SQL注入的含义就是，一些捣蛋用户输入的不是5，而是
		    5;  delete  from  orders
		    那么原来的SQL语句将会变为，
		    select * from product where id=5;  delete  from  orders 
		    在执行完select后，还将删除orders表里的所有记录。（如果他只删了这些记录，已经谢天谢地了，他可能会做更可怕地事情）。
		    不过庆幸的是，Ibatis使用的是预编译语句（PreparedStatement
		    s ）。

		    上述语句会被编译为，
		    select * from product where id=? 
		    从而有效防止SQL注入。
		    不过当你使用$占位符时就要注意了。
		     
		    例如：动态的选择列和表
		    SELECT * FROM $TABLE_NAME$ WHERE $COLUMN_NAME$ = #value# 
		     
		    这时你一定要仔细过滤那些值以避免SQL注入。当然这种情况不只存在Ibatis中。		
			参考资料：
			【iBATIS in Action】3.5.2 SQL injection 
		    from: http://www.2cto.com/Article/201203/124648.html
		
		总结：
			正如上文所说，动态选择列或表或构造排序等操作时，需要手工过滤那些值以避免sql注入。
			当需要编程来避免sql注入时，可以通过工具类处理错位参数的字符，转义特殊字符。

	- ibatis配置文件的 typeHandler 标签配置类型转换处理方式
		·实现 com.aliyun.slb.api.dao.support.TypeHandlerCallback 接口
	- 动态where条件
		<dynamic prepend="WHERE">
			<isNotEmpty property="ip">
				ip=#ip#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="lbId">
				lb_id=#lbId#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="rsPoolName">
				rs_pool_name=#rsPoolName#
			</isNotEmpty>
		</dynamic>	
	- ibatis debug sql 执行语句位置
		com.ibatis.sqlmap.engine.execution.SqlExecutor
			public void executeQuery(StatementScope statementScope, Connection conn, String sql, Object[] parameters, int skipResults, int maxResults, RowHandlerCallback callback) throws SQLException {
* aqua 
	ctrl + d -- desc table
* 遍历 map.entrySet()
		Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		
		Assert.assertEquals(map.size(), 2);
		Set<Entry<String,IMetaData>> set = map.entrySet();
		for(Entry<String, IMetaData> data:set){
 * Amoeba
		Amoeba for MySQL致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的时候充当query 路由功能，
	专注 分布式数据库 proxy 开发。座落与Client、DB Server(s)之间。对客户端透明。具有负载均衡、高可用性、Query过滤、读写分离、
	可路由相关的query到目标数据库、可并发请求多台数据库合并结果。 在Amoeba上面你能够完成多数据源的高可用、负载均衡、数据切片的功能。
		目前在很多企业的生产线上面使用。
	from: http://xfshean.blog.163.com/blog/static/60206566201272224458578/
* mysql
	- 导数据
		select into from	 (mysql不支持)
		insert into from
			eg:
				insert into Table1(field1,field2) select field1,1 from Table2;
		------
			如何在mysql从多个表中组合字段然后插入到一个新表中，通过一条sql语句实现。具体情形是：有三张表a、b、c，现在需要从表b和表c中
			分别查几个字段的值插入到表a中对应的字段。对于这种情况，我们可以使用如下的语句来实现：

			1) INSERT INTO db1_name(field1,field2) SELECT field1,field2 FROM db2_name
			      当然，上面的语句比较适合两个表的数据互插，如果多个表就不适应了。对于多个表，我们可以先将需要查询的字段join起来，然后组成一个视图后再select from就可以了：

			2) INSERT INTO a(field1,field2) SELECT * FROM(SELECT f1,f2 FROM b JOIN c) AS tb
			      其中f1是表b的字段，f2是表c的字段，通过join查询就将分别来自表b和表c的字段进行了组合，然后再通过select嵌套查询插入到表a中，这样就满足了我们这个场景了，如果需要不止2个表，那么可以多个join的形式来组合字段。需要注意的是嵌套查询部分最后一定要有设置表别名，如下：

			3) SELECT * FROM(SELECT f1,f2 FROM b JOIN c) AS tb
			      即最后的as tb是必须的（当然tb这个名称可以随意取），即指定一个别名，否则在mysql中会报如下错误：

			ERROR 1248 (42000): Every derived TABLE must have its own alias
			      即每个派生出来的新表都必须指定别名才可以的。
		------
		注：不同数据库支持的语法不同，可参考对应的使用说明

	- 主备切换 自动切换
		通过VIP（需要主备库IP在同一网段）
		通过DNS
		其他
	- master HA
		通过ZK竞选master
		MHA
			A primary objective of MHA is automating master failover and slave promotion within short (usually 10-30 seconds) downtime, without suffering from replication consistency problems, 
			without spending money for lots of new servers, without performance penalty, without complexity (easy-to-install), and without changing existing deployments.
			
			ref: http://code.google.com/p/mysql-master-ha

	- 用户被拒绝
		Access denied for user 'test'@'10.1.171.195'
		注意此处，'test'@'10.1.171.195整个对mysql来说是一个用户标识，不要纠结那个IP而误认为mysql连接到错误的IP上去了(配置都是对的啊???!!!)'
	- mysql注释
		create table xxx (
			xxx varchar(32) NOT NULL COMMENT '@desc xxx',
			xxx tinyint(1) unsigned DEFAULT '1' NOT NULL COMMENT '@descxxx',
			PRIMARY KEY(xxx,xxx)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='xxx';
		字段注释
		表注释

	- 事务隔离级别
		mysql默认事务隔离级别：
			mysql>help ISOLATION
			Query global and session transaction isolation levels:
				mysql>SELECT @@GLOBAL.tx_isolation, @@tx_isolation
					REPEATABLE-READ

		mysql 事务级别说明：
		--------
			The following list describes how MySQL supports the different
			transaction levels:

			o READ UNCOMMITTED

			  SELECT statements are performed in a nonlocking fashion, but a
			  possible earlier version of a row might be used. Thus, using this
			  isolation level, such reads are not consistent. This is also called a
			  "dirty read." Otherwise, this isolation level works like READ
			  COMMITTED.

			o READ COMMITTED

			  A somewhat Oracle-like isolation level with respect to consistent
			  (nonlocking) reads: Each consistent read, even within the same
			  transaction, sets and reads its own fresh snapshot. See
			  http://dev.mysql.com/doc/refman/5.1/en/innodb-consistent-read.html.

			  For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE),
			  InnoDB locks only index records, not the gaps before them, and thus
			  allows the free insertion of new records next to locked records. For
			  UPDATE and DELETE statements, locking depends on whether the
			  statement uses a unique index with a unique search condition (such as
			  WHERE id = 100), or a range-type search condition (such as WHERE id >
			  100). For a unique index with a unique search condition, InnoDB locks
			  only the index record found, not the gap before it. For range-type
			  searches, InnoDB locks the index range scanned, using gap locks or
			  next-key (gap plus index-record) locks to block insertions by other
			  sessions into the gaps covered by the range. This is necessary
			  because "phantom rows" must be blocked for MySQL replication and
			  recovery to work.

			  *Note*: In MySQL 5.1, if the READ COMMITTED isolation level is used
			  or the innodb_locks_unsafe_for_binlog system variable is enabled,
			  there is no InnoDB gap locking except for foreign-key constraint
			  checking and duplicate-key checking. Also, record locks for
			  nonmatching rows are released after MySQL has evaluated the WHERE
			  condition. As of MySQL 5.1, if you use READ COMMITTED or enable
			  innodb_locks_unsafe_for_binlog, you must use row-based binary
			  logging.

			o REPEATABLE READ

			  This is the default isolation level for InnoDB. For consistent reads,
			  there is an important difference from the READ COMMITTED isolation
			  level: All consistent reads within the same transaction read the
			  snapshot established by the first read. This convention means that if
			  you issue several plain (nonlocking) SELECT statements within the
			  same transaction, these SELECT statements are consistent also with
			  respect to each other. See
			  http://dev.mysql.com/doc/refman/5.1/en/innodb-consistent-read.html.

			  For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE),
			  UPDATE, and DELETE statements, locking depends on whether the
			  statement uses a unique index with a unique search condition, or a
			  range-type search condition. For a unique index with a unique search
			  condition, InnoDB locks only the index record found, not the gap
			  before it. For other search conditions, InnoDB locks the index range
			  scanned, using gap locks or next-key (gap plus index-record) locks to
			  block insertions by other sessions into the gaps covered by the
			  range.

			o SERIALIZABLE

			  This level is like REPEATABLE READ, but InnoDB implicitly converts
			  all plain SELECT statements to SELECT ... LOCK IN SHARE MODE if
			  autocommit is disabled. If autocommit is enabled, the SELECT is its
			  own transaction. It therefore is known to be read only and can be
			  serialized if performed as a consistent (nonlocking) read and need
			  not block for other transactions. (This means that to force a plain
			  SELECT to block if other transactions have modified the selected
			  rows, you should disable autocommit.)
		  --------
	- MySQL查询结果导出到文件
		选择某些行作为需要的数据
			SELECT id,dbname FROM `index` into outfile "d://aaa.txt";
		一般大家都会用 “SELECT INTO OUTFIL”将查询结果导出到文件，但是这种方法不能覆盖或者添加到已经创建的文件，下文为您介绍的这种方法则很好地解决了此问题。
		一般大家都会用 “SELECT INTO OUTFIL”将查询结果导出到文件，但是这种MySQL查询结果导出到文件方法不能覆盖或者添加到已经创建的文件。例如：
		mysql> select 1 into outfile '/tmp/t1.txt';  
			需要有写文件的权限
			chmod a+rw $DIR_NAME
			drwxrwxrwx
			owner group everyone

			Unix permissions concern who can read a file or directory, write to it, and execute it. Permissions are granted or withheld with a magic 3-digit number. 
			The three digits correspond to the owner (you); the group (?); and the world (everyone else).
			
	- 读写分离
		实现方式有2种：
			1）对应用透明，通过proxy方式（如mysql proxy等代理工具实现）
				    mysql proxy
					get mysql-proxy: http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.3-linux-rhel5-x86-64bit.tar.gz
					lua/lua-devel
					mysql-devel
					glib2-devel.x86_64
					libevent

					make
					make install

					/usr/local/bin/mysql-proxy 

					lua脚本

				    amoeba
					座落与Client、DB Server(s)之间。对客户端透明。具有负载均衡、高可用性、Query过滤、读写分离、可路由相关的query到目标数据库、可并发请求多台数据库合并结果
			2）在应用层实现读写分离（如可以配置多个数据源，按需要注入对应的数据源）
	- mysqlbinlog
		二进制日志
			主从复制，数据恢复。。。通过mysql的binlog
	- mysql主从复制 mysql用户管理

		环境：linux 2.6.32-220.el6.x86_64
			mysql  Ver 14.14 Distrib 5.1.61, for redhat-linux-gnu (x86_64) using readline 5.1

		下面以InnoDB引擎为例，说明配置主从复制的方法。
		 
		1) 配置/etc/my.cnf
			修改主服务器my.cnf，在[mysqld]中增加如下内容：
			##打开binlog
			log-bin=mysql-bin
			##服务器ID。服务器之间不能有重复ID，一般主是1
			server-id=1

			修改从服务器my.cnf，设置server-id=2。
			另外，主从服务器的ip和端口信息配置不在my.cnf里配置，整合到后面的change master命令里。
			修改了my.cnf，重启主从服务器：
			mysqladmin -uroot shutdown


		2) 主服务器上添加数据库复制用户
			在主服务器上，必须为从服务器创建主从复制的用户，并设置replication slave权限。所用具体命令如下：
			create user rep;
			grant replication slave on *.* to rep@'10.250.8.33' identified by '';
			flush privileges;
			10.250.8.33是从服务器，就通过rep用户密码为空来同步复制。通过查询user表查看Repl_slave_priv的值为Y：
			select * from mysql.user where user='rep'\G;

		3) 获取主服务器的快照：
			show master status\G;
				+------------------+----------+--------------+------------------+
				| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |
				+------------------+----------+--------------+------------------+
				| mysql-bin.000003 |      106 |              |                  |
				+------------------+----------+--------------+------------------+
			记录File 及Position 项的值，以便之后对从服务器进行配置。File是当前处理的binlog，
			Position是处理的binlog位置，这是从服务器的同步起点。

		4) 在从服务器上操作，连接主服务器开始同步数据：
			Change master to
			Master_host = '10.250.8.11',
			Master_port = 3306,
			Master_user = 'rep',
			Master_password = '',
			Master_log_file = 'mysql-bin.000003',
			Master_log_pos = 106;
			这里包含的信息有主机的地址和端口、主机提供的复制帐号、主机的binlog位置信息。Master_log_file和Master_log_pos是主服务器的快照信息，从服务器从该binlog的相应位置开始从主服务器同步数据。
			启动从服务器线程就可以开始同步了：
			start slave;
			一旦从服务器开始同步了，就能在数据文件目录下找到2个文件master.info和relay-log.info。从服务器利用这2个文件来跟踪处理了多少master的binlog。
			分别在主从服务器show processlist查看连接，就可以看到rep用户的连接，可证明复制已经生效。

		初步验证：
			
			a. 分别在主从服务器show processlist查看连接，就可以看到rep用户的连接，可证明复制已经生效。
				mysql> show processlist;
				+----+------+-------------------------+------+-------------+------+----------------------------------------------------------------+------------------+
				| Id | User | Host                    | db   | Command     | Time | State                                                          | Info             |
				+----+------+-------------------------+------+-------------+------+----------------------------------------------------------------+------------------+
				|  3 | rep  | vm3.mytest.com.cn:39581 | NULL | Binlog Dump |  920 | Has sent all binlog to slave; waiting for binlog to be updated | NULL            
			b. 或者查看mysql的日志，查看复制情况
				tail -f -n100 /var/log/mysqld.log

				从mysql的log：
					120917 14:45:36 [ERROR] Slave I/O: error reconnecting to master 'rep@10.250.8.11:3306' - retry-time: 60  retries: 86400, Error_code: 2013
					120917 14:46:36 [Note] Slave: connected to master 'rep@10.250.8.11:3306',replication resumed in log 'mysql-bin.000002' at position 432
			

		参考：http://www.cnblogs.com/luoine/archive/2011/05/25/2056493.html

	- mysql执行计划，sql执行计划
		mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

		mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		更多见mysql计划ppt说明

	- mysql数据dump
		mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
		source /home/xx.sql
	- 从文件导大量数据到数据库时，可以用
		source path/file eg: source d:\xx.sql
		如果拷贝出来去执行速度很慢。
		linux下：
			mysql -uxx -pxx -Ddbname < xx.sql
		需要相应权限
	-  mysql账户管理，账户授权
		GRANT ALL PRIVILEGES ON *.* TO 'monty'@'localhost' IDENTIFIED BY 'some_pass' WITH GRANT OPTION;
	- 一些命令使用，可以参考gui工具执行命令的sql参考 比如：Aqua Data Studio ，在alter table 时可以查看preview sql
	insert into vip (host,port,gmt_create,gmt_modify)values('host3',80,'2012-12-12 00:00:00','2012-12-12 00:00:00'); //id为自增列
	 select last_insert_id() as id from vip limit 1 
	 - select * from `group`
		group是mysql的关键词，需要引起来查询
		（mysql  Ver 14.14 Distrib 5.1.40, for unknown-linux-gnu (x86_64) using readline 5.1）
	- mysql>system ls
		mysql下执行shell，命令行命令方式
	- mysql where条件字符串不区分大小写
		？是否哪里可以设置要区分大小写
	- mysql 区分大小写
		参考day66
	- mysql用户管理
		create user houyi@10.250.8.214;
		set password for houyi = password('houyi');
		GRANT ALL PRIVILEGES ON *.* TO 'houyi'@'10.250.8.214' IDENTIFIED BY 'houyi' WITH GRANT OPTION;
		
Apply address:http://www.taobao.ali.com/chanpin/wb/Lists/List4/view.aspx
* php 从小例子入手
	- shell中执行php
		chengs@houyi-vm19.dev.sd.aliyun.com $ vi foo.php

		#!/usr/local/bin/php -q
		<?
			$var = 'foo';
			echo $var."\n";
		?>

		"foo.php" [New] 5L, 62C written                                                                                  
		chengs@houyi-vm19.dev.sd.aliyun.com $ php foo.php 
		foo
		chengs@houyi-vm19.dev.sd.aliyun.com $ 

* eclipse 插件开发 eclipse plugin
	http://code.google.com/p/eclipse-fonts/ 这是简单设置编辑器字体大小的插件，可以学习eclipse的plugin编程 ?
	
* ide * eclipse
	- quick fix	       ctrl+1
		修改属性名，类名等，需要IDE自动修改依赖的地方，可通过此功能去做，无需各处都手动修改		
	- eclipse设置文件默认编辑器时，在edit配置中，比如wiki类型，可以新建类型，设置编辑器时，需要设置默认编辑器（有default按钮），否则ide可能出错，导致设置失败。
	- debug时，保证被debug的程序和当前源码一致，否则可能debug异常（比如debug不进来）
	- eclipse debug时，可以激活 break points窗口中的skip all break points按钮，这样会跳过所有debug点。
		debug点图标上会多个右斜线
	- 设置文件默认打开编辑器：general - appearance - editors - file associations 比如设置文本方式打开xml文件
	- 对于同时要打开重名项目的需求，可以通过放到不同的workspace中，单独打开操作，避开重名冲突。
	- 字体大小
		当设置字体的按钮不能用时，我就碰到了点的没反应，我们可以下载eclipse设置字体相关的插件，
		通过插件间接设置我们想要的字体，大小等。（官方文档都是基于IDE的设置窗口，但按钮是失效的，也是是bug）
		http://code.google.com/p/eclipse-fonts/ 这是其中一个插件
			
	- Eclipse取消Show in Breadcrumb
		随手右键启用这个功能，半天么找到如何取消，囧。。。
		百度了下，方且搞定，位置在：
			window > customize perspective > tool bar visibility > editor presentation > toggle greadcrumb
		工具栏上有个按钮，也可直接取消选中。
		后记：不过，对eclipse的使用及设置又学了一招。
	ctrl + shift + L 列出所有快捷键列表
	- 字母大小写
		ctrl + shift + x (大写)/ ctrl + shift + y (小写)
	- eclipse 文件夹上下关系 project property - build path -move
		source folder ，设置源码包 build path - change to source folder
		xml 标签自动提示，schema ，dtd定义正确即可
		类似aqua data studio 通过快捷键查看表结构；通过 CTRL+T 快捷键查看类型的结构(实现，继承等)
	- eclipse 快捷键 
		ctrl + t;
		ctrl + 1 quick fix ，如改包名等
		ctrl + shift + r 查找资源类
			在open按钮处选择打开方式，后面会以此方式为默认
		ctrl + shift + t 查找类型(比如某个jar包中的某个类)
	- debug插件，远程debug时，有时报错，
		一般是已打开了其debug模式，可以关闭debug（有多个debug在进行时，需要在debug面板选择需要操作的debug实例），重新打开remote debug，
		再不行，可以尝试重启eclipse再debug
	- eclipse 的 type hierarchy 面板应用
		在测试时，比如jtester测试，如果只想执行某一个方法的测试，可以在这个视图的方法上右击执行（通过反射执行，不用执行每个用例）

* Source Insight
	- 
		Source Insight是一个面向项目开发的程序编辑器和代码浏览器，它拥有内置的对C/C++, C#和Java等程序的分析。Source Insight能分析你的源代码并在你工作的同时动态维护
	它自己的符号数据库，并自动为你显示有用的上下文信息。 Source Insight不仅仅是一个强大的程序编辑器，它还能显示reference trees，class inheritance diagrams和call trees。
	Source Insight提供了最快速的对源代码的导航和任何程序编辑器的源信  息。 Source Insight提供了快速和革新的访问源代码和源信息的能力。与众多其它编辑器产品不同，
	Source Insight能在你编辑的同时分析你的源代码，为你提供实用的信息并立即进行分析。
	- 快捷键
		alt+,/. 回退/前进
		ctrl+= 进入方法定义
		shift+F8 高亮显示选中内容
	- 导入工程方法
		project->new project>选泽源码所在目录>...


* php 
	 Discuz
	 开源bug管理系统bugfree：
		 http://www.bugfree.org.cn/blog/?page_id=9
* 测试，测试框架，测试插件
	* jtester
		- 不便于全局mock，需要细粒度到方法mock时，注意被mock属性的定义，需要定义到实现类，而不能是接口类型（否则不会被mock），正确例子如下：
			new Expectations(){
				@Mocked(methods={"selectXXX"})
				ImageDaoImpl imageDao; //这里声明的是实现类
				{
					when(imageDao.selectXXX(anyLong, (Image)any, anyInt, -1)).thenReturn(expectImageList);
				}
				@Mocked(methods={"detailXXX"})
				SnapshotServiceImpl snapshotService;    
				{
					when(snapshotService.detaildetailXXX("testSnapshotId", "testRegionNO")).thenReturn(expectResult);
				}
			};
		- jtester顺序执行，按次序执行，类似集成测试的方式
			观察jtester执行用例的方式，是以方法名排序的，通过加入字符人工干预其排序达到顺序执行用例，解决依赖测试问题（比如要先创建LB，才能查询LB,删除LB等等）。
		- jtest 事务回滚测试，事务测试，unitils测试事务
			@Transactional(TransactionMode.DISABLED)
				测试事务时，需要关闭测试框架的事务，否则会出现在测试框架开启的事务中，又开启新的事务，导致交叉，不能准确的测试事务一致性。
		- 
			jtester框架测试，用dbfit测试数据库，默认以jtester.properties的数据库操作，若要动态跨数据库操作可以在wiki文件里配置，格式如下：

			指定需要连接的库
				|connect|jdbc:mysql://10.10.10.10/databaseName?useUnicode=true&amp;characterEncoding=utf-8|userName|password|com.mysql.jdbc.Driver|
				|clean table|`tableName`|
				|insert|`table|`tableName`|`|
				|id|name|
				|1|jack|
				|2|tom|
			采用默认库
				|connect|
				|clean table|`tableName`|
		- 测试异常抛出
			-----
			...
				new Expectations(){
					{	when(xx).thenReturn(xx);
						throwException(new RuntimeException(xxx));
					}
				};
				try{
					xxx.execute();
				}catch (Exception e) {
					Assert.assertEquals(e.getClass(), RuntimeException.class);
					Assert.assertEquals(e.getMessage(), xxx);
				}
			...
			-----
		- 一个测试方法，含多个测试点的时候
			可以按照顺序依次测试（在同一个方法中），不过expectation需要新建（从之前的拷贝过来即可），改动点需要设置的地方，再assert即可。
		- 测试框架，提供了各种测试方式及支持，比如mock，通过反射测试私有类等的工具JTesterReflector ，完整的去用一个测试框架。阅读其说明文档
		- 提供集成测试支持(如数据库等)
		- jtester是结合其他框架基础上的，比如@Test 注解用的就是testing框架，此时eclipse插件就下载testing(TestNG )的插件，即可在ide执行测试。ide比如eclipse执行单元
		测试框架的测试用例是根据框架的注解来解析执行的，找到框架的ide插件即可。
		下载地址：http://testng.org/doc/index.html 从其jar里找到网站信息
			http://beust.com/eclipse-old/eclipse-5.14.0.1 新版本有问题，用这个旧版本
		- TestNG is designed to cover all categories of tests:  unit, functional, end-to-end, integration, etc...
			TestNG is a testing framework inspired from JUnit and NUnit but introducing some new functionalities that make it more powerful and easier to use
		- 新项目加入jtester步骤：
			1）加入依赖
				<repositories>
					<repository>
					<id>jtester-maven</id>
					<name>JTester</name>
					<url>http://java-tester.googlecode.com/svn/maven2/</url>
					</repository>
				</repositories>		
				<dependencies>
					<dependency>
					<groupId>org.jtester</groupId>
					<artifactId>jtester</artifactId>
					<version>1.0.1</version>
					<scope>test</scope>
				</dependency>				
			2）添加jtester.properties配置文件到classpath
				
			3）创建抽象父类，进行测试前的资源初始化操作
				@SpringApplicationContext({
					"classpath:houyi-spring-test.xml",
					"classpath:houyi-spring-dao.xml",
				    "classpath:houyi-spring-db.xml",
				    "classpath:houyi-openapi.xml",
					})
				@AutoBeanInject(maps = { @BeanMap(intf = "**.*", impl = "**.impl.*Impl") })
				public abstract class BaseJtester extends JTester {
				}
				这里 classpath:houyi-spring-test.xml 是配置了jdbc等配置文件信息的参数信息，要配置正确
			4）测试类继承上面的抽象类（db，mock，etc）
				public class ZoneDaoImplTest extends BaseJtester {
					
					@SpringBeanByName
					ZoneDao zoneDao;
					
					@DbFit(when={"ZoneDaoImplTest.testQueryClusterIdByZoneId.when.wiki"})
					@Test
					public void testQueryClusterIdByZoneId(){
						String clusterId = zoneDao.queryClusterIdByZoneId("testZoneId");
						Assert.assertEquals("testClusterId", clusterId);
					}
		- 配置jtester时，报属性文件找不到
			Caused by: java.io.FileNotFoundException: C:\Users\wb_shen.chengs\.houyi\jdbc.properties (系统找不到指定的路径。)
				查找jtester抽象父类，导入的配置文件中，是否那个配置文件引用了错误的路径；如果原配置文件不能动，可以再test包下的resource中对其
			做个拷贝，修改相应值，替代原配置文件导入。

* 简称
	 业务运营支撑系统(BOSS) 
	 弹性计算(Elastic Computing - EC) 
	 云引擎(Cloud Engine - CE) 
	 开放存储服务(Open Storage Service - OSS) 
	 云数据库服务(Cloud Database Service - CDS) 
	 阿里邮箱(Ali Mail - AM) 
	 开放表服务（Open Table Service - OTS）
* 精度转换
	Long.valueOf(String.valueOf(compensationFailureJobHour * HOUR_SEC))
* maven
	- maven web项目 maven项目 部署 测试 ，可通过bat或shell的方式来自动化编译打包部署，方便web项目的调试
		搜索本文件内容：mavn web project 自动部署启动容器脚本(bat脚本)
	- maven jvm参数配置 配置jvm    maven运行参数配置
		maven默认的jvm配置，比如内存不能满足需要，可能导致错误，如：java.lang.OutOfMemoryError: PermGen space问题
		下面摘自网络，可参考：
		-------
		　有时候我们需要设定maven环境下的JVM参数，以便通过maven执行的命令或启动的系统能得到它们需要的参数设定。比如：当我们使用jetty:run启动jetty服务器时，在进行热部署时会经常发生:java.lang.OutOfMemoryError: PermGen space问题,这时我们需要增大JVM参数MaxPermSize的值。再者，当我们需要进行远程调试时，也需要设置监听端口。maven配置jvm参数的地方是%M2_HOME%/bin/mvn.bat文件，这是启动Maven的脚本文件，在该文件中你能看到有一行注释为：@REM set MAVEN_OPTS=-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000．通过添加set MAVEN_OPTS可以为maven设定jvm参数了。比如：
		　　1.建立远程调试，端口为:4000的设定为：
		　　set MAVEN_OPTS=-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=4000
		注意：suspend最好设定为n.设定上述参数后，在eclipse中新建远程调试，设置端口为4000，这样通过jetty:run启动系统时就可以进行远程调试了。
		　　2.解决自动热部署时java.lang.OutOfMemoryError: PermGen space问题解决这一问题只需要增大PermGen区，默认为 64m，设置方法为：
		　　set MAVEN_OPTS=-XX:MaxPermSize=128M
		-------
		from：http://blog.csdn.net/bluishglc/article/details/6310071

	- maven clean时，linux中若文件被ln连接引用，需要删除引用（如target中的war包被引用）
		可重新svn co
	- 发布jar到nexus
		发布到中央库需要具有一定权限
			mvn deploy:deploy-file -DgroupId=com.google.inject.extensions -DartifactId=guice-servlet -Dversion=3.0 -Dpackaging=jar -Dfile=guice-servlet-3.0.jar -Durl=http://www.some-domain.com/some-path -DrepositoryId=nexus
	- maven依赖jar的下载问题
		maven下载pom中定义的jar依次从本项目的pom中配置的repository.url>指向的地址下载，若没有则去本地maven的repository列表逐个去下载。
		由于子pom中没有定义jar的本地repository地址，本地maven配置也没有其地址，从而报jar找不到。

		项目pom中的repository配置方式例子(若项目中没有配置，则本地maven库需要配置)：
			<repositories>
				<repository>
				<id>jtester-maven</id>
				<name>JTester</name>
				<url>http://java-tester.googlecode.com/svn/maven2/</url>
				</repository>
			</repositories>

	- nexus
		maven本地库搭建
		http://blog.csdn.net/westkingwy/article/details/7671371
			nexus-webapp-1.4.1/conf/plexus.properties 此属性文件配置nexus信息

	- mvn clean package -Dmaven.test.skip=true -Dconfig.file=/home/admin/houyi-ace4j/service/config/auto-config.properties
	- maven 循环依赖问题，依赖交叉
		可通过将接口抽取到一个模块中，被其他实现模块引用；接口模块自身不依赖或只依赖类似model的中立模块

	- 忽略测试失败
		mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	- 测试覆盖率插件 surefire-report
		mvn surefire-report:report-only
	- maven项目分为多个子项目debug时，如果debug到的类不在当前子项目中，会找不到源码，可把关联的子项目源码包位置指定给ide，指定class的目录，比如com.xxx.xx
	- mavne 插件使用说明，查阅其官方说明：
		eclipse插件：maven-eclipse-plugin http://maven.apache.org/plugins/maven-eclipse-plugin/
		mvn某些goal执行错误时，可以尝试eclipse中clean项目再执行。
			如果eclipse使用的jdk和maven使用的jdk不是同一个的话，会报编译错误；保证2者使用同一个jdk。

	- maven可以通过参数执行特定的goal，或测试某个用例，不需要全部执行，灵活 (-Dxxx=)
		mvn test -Dtest=AppDaoImplTest
	- maven 打包后，将jar包install到本地库中
		mvn package install

	- maven版本编译问题，若maven版本低，默认会采用jdk1.3编译，需要在pom中指定java版本：
			-------
			<plugin>
			    <groupId>org.apache.maven.plugins</groupId>
			    <artifactId>maven-compiler-plugin</artifactId>
			    <configuration>
			      <source>1.6</source>
			      <target>1.6</target>
			    </configuration>
			 </plugin>
			-------
		版本不对报：annotations are not supported in -source 1.3


	- maven web project ,maven通过选择不同的 Archetype 快速建立对应的项目目录骨架。 maven构建
	web项目(eg:webx3.0项目)
		- 比如 group id 为 org.apache.maven.archetypes 下有多种Archetype。如何自定义Archetype？
		- 还有pom文件中必须引入servlet，jsp的相关jar包，scope设置为provided，表示它们最终不会打包到war项目中
	- mvn执行测试时进行debug
		mvn -Dmaven.surefire.debug=true -Dtest=OpenApplicatonControllerTest test
	- maven test 
		test 时需要debug，可以利用测试插件提供的方法，结合ide(eclipse)进行debug
			比如： Surefire Plugin 测试环节的插件，支持test时，进行debug ，下面为maven的官网说明摘取：
				Forked Tests
					By default, Maven runs your tests in a separate ("forked") process. You can use the maven.surefire.debug property to debug your forked tests remotely, like this:
						mvn -Dmaven.surefire.debug test	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
				launch configuration via the menu command "Run" > "Open Debug Dialog..."
					If you need to configure a different port, you may pass a more detailed value. For example, the command below will use port 8000 instead of port 5005.
						mvn -Dmaven.surefire.debug="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000 -Xnoagent -Djava.compiler=NONE"  test
				Non-forked Tests
					You can force Maven not to fork tests by configuring the forkMode configuration parameter.
						mvn -DforkMode=never test
					Then all you need to do is debug Maven itself. Since Maven 2.0.8, Maven has shipped with a "mvnDebug" shell script that you can use to launch Maven with convenient debugging options:
					mvnDebug -DforkMode=never testThen you can attach Eclipse to Maven itself, which may be easier/more convenient than debugging the forked executable.
				上面这段：	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
					launch configuration via the menu command "Run" > "Open Debug Dialog..."
				说明如何通过eclipse来进行maven的debug调试。-tip-
				mvn -Dmaven.surefire.debug test  //maven debug
	- maven添加jar到本地库
		mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
		添加源码到本地库 添加source
		 mvn install:install-file -DgroupId=org.apache.velocity -DartifactId=velocity -Dversion=1.6.2 -Dpackaging=jar -Dfile=velocity-1.6.2-sources.jar -DgeneratePom=true -Dclassifier=sources 

		从jar导入到maven库与从maven项目源码编译导入到库的区别：若从源码编译导入则jar自身依赖的jar会自动下载（依赖jar的pom文件已定义其自身的依赖）。		


	- maven jar包重复问题，可通过
		mvn dependency:tree 查看依赖关系。
		配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
		对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
		只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。
		上面如果没效果：
			通过定义 <dependencyManagement> 来自己管理依赖版本，然后再引用来解决 .work well.
	- maven source:jar 打源码包
	- maven test时一种错误
	需要强制转换。
	- maven构建时报内存溢出解决
		 Windows环境中 
			找到文件%M2_HOME%\bin\mvn.bat	
			set MAVEN_OPTS= -Xms128m -Xmx512m
			E:\test>mvn -version
			E:\test>set MAVEN_OPTS= -Xms128m -Xmx512m
		Linux环境中 
			也可以通过设置环境变量解决该问题， 如，编辑文件 /etc/profile 如下
			MAVEN_OPTS=-Xmx512m
			export JAVA_HOME MAVEN_HOME MAVEN_OPTS JAVA_BIN PATH CLASSPATH
	- maven web project debug ，maven debug tomcat
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS% 启动tomcat调试模式 ，通过socket方式
	- maven 编译错误 
		原因之一：ide的一些操作导致冲突，清楚ide的附加内容(配置，临时文件等等)，mvn clean下，再重新import到ide中即可。
		原因之二：命令行下mvn操作与ide的操作，在缓存文件上导致错误，命令行clean了，但ide上没刷新 。解决就是ide上 maven clean 然后 project clean ，
			命令行就不会报错了。
	- maven 注解不支持 annotations are not supported in  ，显式定义插件，配置参数，设置jdk版本
		Maven default is using JDK1.3 for the project compilation, building or packaging (mvn compile, install). Since JDK1.3 is not support annotation, if your project has annotation, you need to configure your Maven to use the latest JDK version. The solution is very simple, just include the Maven compiler plugin and specify the JDK version. For example,
		<project ....>
		 <build>
		  <plugins>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>2.3.2</version>
				<configuration>
					<source>1.6</source>
					<target>1.6</target>
				</configuration>
			</plugin>
		   </plugins>
		  </build>
		</project>
		Above declaration tell Maven to use JDK 1.6.
	- maven 编码相关 - maven命令行执行能看到采用的编码
		a. maven插件在处理任务时，如果没有定义编码会自动匹配编码，如果与需要的不符，则运行时报错。解决：定义各插件执行的编码格式，如下：
			可以通过 mvn -version 查看maven默认采用的编码是什么？
			<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-resources-plugin</artifactId>
					<configuration>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
				<plugin>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>2.3.2</version>
					<configuration>
						<source>1.6</source>
						<target>1.6</target>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
	- 执行时，设置maven参数
			mvn -Dmaven.test.skip=false test 不跳过测试的test操作
	- No goals needed for project - skipping 跳过测试问题
		大项目下有多个子项目，某些子项目mvn test 不执行里面的test，报：No goals needed for project - skipping
		内部程序配置冲突是原因之一
* 工具类
	 apache commond 
		StringUtils 
		...
* 协作
	”系统间协作的部分，找到相关人员沟通效率就快了，都是人定义的，谁定义谁最清楚 “

* python
	- 终端输入，命令行输入，用户输入 用raw_input([prompt])
		var = raw_input("Enter something: ")
		print "you entered ", var
	- pythobn脚本
		使用库时，尽量使用内置的库，避免依赖问题，比如:
			from _pyio import open
			直接使用内置的:open即可
		
	- 异常捕获
		抛出异常：
			raise errorclass, errorvalue

		捕获异常
		try:
			xxx
		except xxxException:
			xxx

	-----
		Python的异常处理能力是很强大的，可向用户准确反馈出错信息。在Python中，异常也是对象，可对它进行操作。所有异常都是基类Exception的成员。所有异常都从基类Exception继承，而且都在exceptions模块中定义。Python自动将所有异常名称放在内建命名空间中，所以程序不必导入exceptions模块即可使用异常。一旦引发而且没有捕捉SystemExit异常，程序执行就会终止。如果交互式会话遇到一个未被捕捉的SystemExit异常，会话就会终止。

		方式一:try语句:

		1使用try和except语句来捕获异常

		try:
		   block
		except [exception,[data…]]:
		   block

		try:
		block
		except [exception,[data...]]:
		   block
		else:
		   block

		该种异常处理语法的规则是：

		·   执行try下的语句，如果引发异常，则执行过程会跳到第一个except语句。

		·   如果第一个except中定义的异常与引发的异常匹配，则执行该except中的语句。

		·   如果引发的异常不匹配第一个except，则会搜索第二个except，允许编写的except数量没有限制。

		·   如果所有的except都不匹配，则异常会传递到下一个调用本代码的最高层try代码中。

		·   如果没有发生异常，则执行else块代码。

		例:

		try:

		   f = open(“file.txt”,”r”)
		except IOError, e:
		   print e

		捕获到的IOError错误的详细原因会被放置在对象e中,然后运行该异常的except代码块

		捕获所有的异常

		try:
		   a=b
		   b=c
		except Exception,ex:
		   print Exception,":",ex

		使用except子句需要注意的事情，就是多个except子句截获异常时，如果各个异常类之间具有继承关系，则子类应该写在前面，否则父类将会直接截获子类异常。放在后面的子类异常也就不会执行到了。

		2 使用try跟finally:

		语法如下:

		try:
		   block
		finally:
		   block

		该语句的执行规则是：

		·   执行try下的代码。

		·   如果发生异常，在该异常传递到下一级try时，执行finally中的代码。

		·   如果没有发生异常，则执行finally中的代码。

		第二种try语法在无论有没有发生异常都要执行代码的情况下是很有用的。例如我们在python中打开一个文件进行读写操作，我在操作过程中不管是否出现异常，最终都是要把该文件关闭的。

		这两种形式相互冲突，使用了一种就不允许使用另一种，而功能又各异

		2. 用raise语句手工引发一个异常:

		raise [exception[,data]]

		在Python中，要想引发异常，最简单的形式就是输入关键字raise，后跟要引发的异常的名称。异常名称标识出具体的类：Python异常是那些类的对象。执行raise语句时，Python会创建指定的异常类的一个对象。raise语句还可指定对异常对象进行初始化的参数。为此，请在异常类的名称后添加一个逗号以及指定的参数（或者由参数构成的一个元组）。

		例:

		try:
		    raise MyError #自己抛出一个异常
		except MyError:
		    print 'a error'

		raise ValueError,’invalid argument’
		捕捉到的内容为:

		type = VauleError
		message = invalid argument
	-----
	from: http://blog.csdn.net/JINXINXIN_BEAR_OS/archive/2011/02/23/6202784.aspx

	- 定义编码格式 Defining Python Source Code Encodings
		支持中文，需要在源文件中定义字符编码格式，比如：
			#coding=utf-8
		ref: http://www.python.org/dev/peps/pep-0263/


	- pytest
		python测试工具
		scales from simple unit to complex functional testing
	- edit plue开发python
		
		运行python文件，需要参数时，可以配置对应tool的argument选项，如：配置为 $(FileName) $(Prompt) ，这样在运行时允许指定参数

		语法高亮，换行等
		运行python
		-----
			EditPlus开发python 编辑器环境的配置

			Python也可以使用编辑器进行开发。例如，文本编辑软件EditPlus也能成为Python的编辑、执行环境，甚至可以用于调试程序。EditPlus具备语法加亮、
			代码自动缩进等功能。本节介绍一下如何配置EditPlus编辑器的开发环境。

			1)添加Python群组

			首先启动EditPlus，然后单击【工具】|【配置用户工具】命令，打开【参数】对话框。在【参数】对话框中单击【添加工具】按钮，在弹出的菜单中选择【程序】命令。
			新建的群组名称命名为“Python”，分别在【菜单文本】文本框中输入“python”，在【命令】文本框中输入Python的安装路径，在【参数】文本框中输入“$(FileName)”，
			在【起始目录】文本框中输入“$(FileDir) ”。勾选【捕获输出】选项，Python程序运行后的输出结果将显示在Edit Plus的输出栏中，否则，运行Python程序后将弹出命令行窗口，
			并把结果输出到命令行中。

			设置完成后的对话框如图1-10所示。单击【确定】按钮，新建一个Python文件，【工具】菜单下将会出现【python】选项。单击【python】选项或按快捷键Ctrl＋1，
			就可以运行Python程序。

			2)设置Python高亮和自动完成

			EditPlus不仅可以作为Python的开发环境，还支持Java、C#、PHP、HTML等其他类型的语言。不同语言的语法高亮显示和自动完成的特征各不相同。为了实现语法加亮
			和自动完成功能，需要下载python.acp和python.stx这两个特征文件。下载地址为http://www.editplus.com/files/pythonfiles.zip。下载后把文件python.acp和python.stx解压到EditPlus
			的安装目录下。acp后缀的文件表示自动完成的特征文件，stx后缀的文件表示语法加亮的特征文件。在编写Python代码之前，需要先在EditPlus中设置这些特征文件。

			（1）选择【文件】|【设置与语法】选项，在【文件类型】列表中选择【python】选项，【描述】文本框中输入“python”，【扩展名】文本框中输入“py”，如图1-11所示。

			图1-10  在EditPlus中添加对Python的支持图1-11  设置Python的特征文件

			（2）在【设置与语法】选项卡中，在【语法文件】文本框中输入python.stx的路径，在【自动完成】文本框中输入python.acp的路径。

			 

			（3）Python的语法中没有使用begin、end或{}区分代码块，而是使用冒号和代码缩进的方式区分代码之间的层次关系。单击【制表符/缩进】按钮，打开【制表符与缩进】
			对话框。设置Python代码的缩进方式，如图1-12所示。在使用IDE工具时，输入冒号代码会自动缩进，EditPlus也可以设置该功能。在【制表符】和【缩进】文本框中分别
			输入空格的个数，一般设置为“4”。把【启用自动缩进】选项选中，在【自动缩进开始】文本框中输入“:”。单击【确定】按钮保存设置。

			（4）单击【函数模型】按钮，打开【函数模型】对话框，如图1-13所示。在【函数模型正则表达式】文本框中输入“/[ //t/]*def/[ //t/].+:”。单击【确定】按钮保存设置。

			图1-12  Python代码的缩进方式

			图1-13  设置函数模型

			至此，EditPlus的Python开发环境就设置完成了。EditPlus还可以建立Python文件的模板，以后每次新建Python文件都可以在模板的基础上编写代码。编写Python代码经常要
			使用中文，同时也要考虑跨平台的功能，因此可以建立名为“template.py”的模板文件。template.py的内容如下所示。

			 

			#!/usr/bin/python

			# -*- coding: UTF-8 -*-

			  第1行代码使Python程序可以在UNIX平台上运行。

			  第2行代码设置编码集为UTF-8，使Python代码可以支持中文。

			注意在EditPlus中通过快捷键Ctrl＋F11可以查看当前python文件中的函数列表。

			 

			    运行Python程序前，需要先保存Python程序。下面使用EditPlus编写一段Python程序并输出结果，如图1-14所示。
		-----
		参考：http://blog.csdn.net/hendyyou/article/details/4694973

	- python命令行参数处理
		测试命令行参数问题时，可通过run as命令来配置运行参数，从而测试参数

	- python异常分析，异常日志由上到下，为异常的入口点，直到报错的地方；java是由下而上，日志前面是具体出错的地方
		------
			[root@AT-HOUYIDEV_AG]$ python houyiapi_bigregion2new_update_regionstatus.py 
			Before update houyi.region_status, houyi.region_status has 0 records
			Traceback (most recent call last):
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 46, in <module>
			    main()
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 42, in main
			    import_region_status_into_houyi()
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 31, in import_region_status_into_houyi
			    houyidb.execute(sql)
			  File "/usr/local/lib/python2.5/site-packages/pypet/common/database.py", line 103, in execute
			    return self.cursor.execute(_format(sql), args)
			  File "build/bdist.linux-x86_64/egg/MySQLdb/cursors.py", line 174, in execute
			  File "build/bdist.linux-x86_64/egg/MySQLdb/connections.py", line 36, in defaulterrorhandler
			_mysql_exceptions.OperationalError: (1054, "Unknown column 'AT' in 'field list'")
		------
	- eclipse开发python
		在pyconsole中导入module时，需要设置项目的pydev-PYTHONPATH（设置PATH）

	- 文件头部的预处理语句说明
		#!/usr/bin/python是告诉操作系统执行这个脚本的时候，调用/usr/bin下的python解释器；
		#!/usr/bin/env python这种用法是为了防止操作系统用户没有将python装在默认的/usr/bin路径里。当系统看到这一行的时候，首先会到env设置里查找python的安装路径，再调用对应路径下的解释器程序完成操作。
		#!/usr/bin/python相当于写死了python路径;
		#!/usr/bin/env python会去环境设置寻找python目录,推荐这种写法
	- GC
		mark-and-sweep
			The mark-and-sweep algorithm is called a tracing garbage collector because is traces out the entire collection of objects that are directly or indirectly accessible by the program.  The objects 
		that a program can access directly are those objects which are referenced by local variables on the processor stack as well as by any global variables that refer to objects. In the context of garbage 
		collection, these variables are called the roots .

			The mark-and-sweep algorithm consists of two phases: 
			1) In the first phase, it finds and marks all accessible objects. The first phase is called the mark phase. 
			2) In the second phase, the garbage collection algorithm scans through the heap and reclaims all the unmarked objects. The second phase is called the sweep phase.	At the same time, 
			the marked field on every live object is set back to False in preparation for the next invocation of the mark-and-sweep garbage collection algorithm

			In order to distinguish the live objects from garbage, we record the state of an object in each object. That is, we add a special bool field to each object called, say, marked. By default, 
		all objects are unmarked when they are created. Thus, the marked field is initially False.
			The main disadvantage of the mark-and-sweep approach is the fact that that normal program execution is suspended while the garbage collection algorithm runs. In particular, this can be 
		a problem in a program that interacts with a human user or that must satisfy real-time execution constraints. For example, an interactive application that uses mark-and-sweep garbage collection 
		becomes unresponsive periodically.

		see for detail: http://www.brpreiss.com/books/opus7/html/page425.html#figgarbage5
			新建的object状态为默认的false即不会被本次回收 ；从根处开始查找引用树；
			The Fragmentation Problem 内存碎片问题


	- List comprehension
		python最强大的的特性之一
			A list comprehension is a syntactic construct available in some programming languages for creating a list based on existing lists. It follows the form of the mathematical 
		set-builder notation (set comprehension) as distinct from the use of map and filter functions.
		eg of list comprehension:
			["%s=%s" % (k, v) for k, v in params.items()]

			>>> li = [1, 9, 8, 4]
			>>> [elem*2 for elem in li]
			[2, 18, 16, 8]

	- python类型转换、数值操作
		类型转换
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		函数                      描述
		 int(x [,base ])         将x转换为一个整数
		 long(x [,base ])        将x转换为一个长整数
		 float(x )               将x转换到一个浮点数
		 complex(real [,imag ])  创建一个复数
		 str(x )                 将对象 x 转换为字符串
		 repr(x )                将对象 x 转换为表达式字符串
		 eval(str )              用来计算在字符串中的有效Python表达式,并返回一个对象
		 tuple(s )               将序列 s 转换为一个元组
		 list(s )                将序列 s 转换为一个列表
		 chr(x )                 将一个整数转换为一个字符
		 unichr(x )              将一个整数转换为Unicode字符
		 ord(x )                 将一个字符转换为它的整数值
		 hex(x )                 将一个整数转换为一个十六进制字符串
		 oct(x )                 将一个整数转换为一个八进制字符串

		序列操作
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		操作                      描述
		 s + r                   序列连接
		 s * n , n * s           s的 n 次拷贝,n为整数
		 s % d                   字符串格式化(仅字符串)
		 s[i]                    索引
		 s[i :j ]                切片
		 x in s , x not in s     从属关系
		 for x in s :            迭代
		 len(s)                  长度
		 min(s)                  最小元素
		 max(s)                  最大元素
		 s[i ] = x               为s[i]重新赋值
		 s[i :j ] = r            将列表片段重新赋值
		 del s[i ]               删除列表中一个元素
		 del s[i :j ]            删除列表中一个片段

		数值操作
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		x << y                  左移
		 x >> y                  右移
		 x & y                   按位与
		 x | y                   按位或
		 x ^ y                   按位异或 (exclusive or)
		 ~x                      按位翻转
		 x + y                   加
		 x - y                   减
		 x * y                   乘
		 x / y                   常规除
		 x // y                  地板除
		 x ** y                  乘方 (xy )
		 x % y                   取模 (x mod y )
		 -x                      改变操作数的符号位
		 +x                      什么也不做
		 ~x                      ~x=-(x+1)
		 abs(x )                 绝对值
		 divmod(x ,y )           返回 (int(x / y ), x % y )
		 pow(x ,y [,modulo ])    返回 (x ** y ) x % modulo
		 round(x ,[n])           四舍五入，n为小数点位数
		 x < y                   小于
		 x > y                   大于
		 x == y                  等于
		 x != y                  不等于(与<>相同)
		 x >= y                  大于等于
		 x <= y                  小于等于

	- 教程 快速入门 
		http://www.diveintopython.net/	Dive Into Python

		深入的话，看python源码剖析（C实现的动态语言）

		这里有不少书籍，比较详细：
		http://www.brpreiss.com/

	- 
		Zope - opensource appserver written by python
		PyDev eclipse python插件 http://www.fabioz.com/pydev/updates
		PyDev for Eclipse 简介 http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-pydev/index.html
	- python小工具（根据配置文件订正对应的表）
		数据库操作
		文件操作
		读取执行参数
	- 命令行执行py文件
		配置python命令到环境变量中
		cmd or shell中执行：python xxx.py即可；参数传递 --key=xxx,--name=xxx
	
	- __init__.py在目录下，代表module包；一般为空，也可初始化值

* Google App Engine 
		虽然GAE有很多限制和缺陷，但是我对GAE还是喜爱有加的。GAE是免费的，任何人都可以很轻松的通过GAE实现自己的Web应用。比如，做一些实用的小工具，
	实现一个博客程序来练手。通过GAE，我们可以轻松的搭建属于自己的Blog(micolog)，搭建属于自己的Wiki系统(NancyWiki)。
	没有GAE，就不会有大家都懂的gappproxy，gtap，twiter-feed。是的，你懂的。	
	from: http://www.cnblogs.com/coderzh/archive/2010/11/30/goodby-google-app-engine.html
* powerdesigner  生成er图
	pd12 连接mysql，database菜单-configure data connection - 选择 connection profiles 设置即可

* shell
	- 遍历指定目录下所有文件
		for i in $(find .)
		do
		    echo $i
		done
	- 根据shell命令行参数执行对应的方法
		
	- 判断当前执行shell的用户	用户判断
		if [ $USER != "admin" ]		      或者  $(whoami) != "admin" Or `whoami` != "admin"
		then
			echo "****** ERROR: only user admin can execute this script!"
			exit 2
		fi		
	-  字符串分组
		cat tempoutfile20121119.txt | grep "cn-hangzhou-dg-a01" |awk -F"|" '{print $3}' >temmmp3
	- 
		#!/bin/bash
		str=$1
		echo $str
		service keepalived $str
	- if [ $# -lt 2 ]; then 命令行参数个数小于2判断
		if [ $# -eq 3 ]; then 参数个数等于3
		shell运算符：
			
	- 判断输入参数个数
		#!/bin/sh
		num=$#
		echo $num
		
	- shell执行时，确保有执行权限
	- shell中调用其他shell ,用点运算符或source命令
		./shell.sh stop
	- 根据参数执行任务shell
		-----
			#!/bin/bash
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    insert) echo "device inserted.";;
			    remove) echo "device removed.";;
			    *) echo "invalid option.";;
			esac
		-----
	- 常用shell ，执行sh后，用tail显示执行log
		-----
			#!/bin/bash

			if [ $# -lt 2 ];
			then
				echo "USAGE: $0 -f server.properties"
				exit 1
			fi
			LOGFILE=$(dirname $0)/../logs/metaServer.log

			nohup sh $(dirname $0)/meta-run-class.sh com.taobao.metamorphosis.server.MetamorphosisStartup $@ 2>&1 >>$LOGFILE &
			tail $LOGFILE -f
		-----
* linux
	- 命令行下html浏览工具
		htmlview

	- sysctl命令 * 内核配置 * kernel配置 * kernel设置
		vi /etc/sysctl.conf
		sysctl -p 使内核配置生效
		sysctl - configure kernel parameters at runtime

	- 目录树显示，树状目录显示
		tree /home/admin/ -L 2 
	-  linux在关机或重启时自动执行某个任务
	　　先写一个脚本放在/etc/rc.d/init.d下，chmod -f 777 ， 再ln -s 到 /etc/rc.d/rc0.d/K01脚本名 与 /etc/rc.d/rc6.d/K01脚本名,同时也要 ln -s 到 /etc/rc.d/rc3.d/S99脚本名 与/etc/rc.d/rc5.d/S99脚本名。
	　　K开头的代表系统关闭的时候执行，S开头的代表开机的时候执行。注意服务器脚本编写的规范，因为有K开通的软链接并不一定会在关机的时候自动去执行，这是为什么呢？
	刚开始一直没搞明白，后来从网上看到，执行K脚本的时候会查询/var/lock/subsys/下是否有与K开头脚本同名的空文件名，如果没有就不去执行，所以要按照服务器脚本编写的规范，
	启动的时候要在/var/lock/subsys/先touch一个与K01后面同名的空文件.同时也要调用/etc/rc.d/init.d/functions能够接受star与stop命令信号，具体可以参考/etc/rc.d/rc文件，
	本人是在/etc/rc.d/rc0.d/K01yum基础上改写实现的。

	补充：
	--------
		linux /etc/rc.d/目录的详解
		分类： Linux 2008-04-09 16:16 1516人阅读 评论(0) 收藏 举报

		rc.d的内容如下：
		init.d/ :各种服务器和程序的二进制文件存放目录。
		rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
		还有三个脚本:rc.sysinit, rc, rc.local

		redhat的启动方式和执行次序是：
		加载内核
		执行init程序
		/etc/rc.d/rc.sysinit # 由init执行的第一个脚本
		/etc/rc.d/rc $RUNLEVEL # $RUNLEVEL为缺省的运行模式
		/etc/rc.d/rc.local
		/sbin/mingetty # 等待用户登录

		在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
		调入keymap以及系统字体
		启动swapping
		设置主机名
		设置NIS域名
		检查（fsck）并mount文件系统
		打开quota
		装载声卡模块
		设置系统时钟
		等等。


		/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
		，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
		从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
		/etc/rc.d/rc3.d/下的脚本。
		值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
		的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

		init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
		action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
		至此，LINUX的启动结束。 

		 

		最后自己补充一些:

		1. 许多网络服务都由超级服务/etc/rc.d/init.d/xinetd启动,这些服务的配置文件在/etc/xinetd.d/目录下,

		如telnet就是由xinetd启动的,其配置文件如下(fc7)

		  1 # default: on
		  2 # description: The telnet server serves telnet sessions; it uses /
		  3 #   unencrypted username/password pairs for authentication.
		  4 service telnet
		  5 {
		  6     flags       = REUSE
		  7     socket_type = stream
		  8     wait        = no
		  9     user        = root
		 10     server      = /usr/sbin/in.telnetd
		 11     log_on_failure  += USERID
		 12     disable     = no
		 13 }
		修改配置文件以后,重启xinetd服务即可.
	from: http://blog.csdn.net/cradmin/article/details/2270497
	--------
		2. 除了直接调用脚本外(如/etc/rc.d/init.d/xinetd),还可以用service命令来控制init.d目录下的服务,

		     如 service xinetd restart,


	ps：上面摘自网络，个人总结：
		要在linux开关机时执行自定义任务，可在 /etc/rc.d/init.d 目录下放脚本；ln到/etc/rc.d/目录下对应启动级别目录下；然后在/var/lock/subsys/目录下建同名文件。
	 
	- text 分辨率修改
		vim /boot/grub/menu.lst 
		kernel行末尾加上 vga=791
	- curl 
		测

	- beep关闭
		1）编辑 /etc/inputrc，找到
		＃set bell style none
		这一行，去掉前面的注释符号。
		2）或者编辑 /etc/profile，添加这一句，	setterm -blength 0即可。
	- md5sum
		计算md5值，验证文件完整性。
	- 设置开机启动
		在 /etc/rc.d/rc.local 	    目录：
			/etc/rc.d目录详解：
			--------
				rc.d的内容如下：
				init.d/ :各种服务器和程序的二进制文件存放目录。
				rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
				还有三个脚本:rc.sysinit, rc,  rc.local

				redhat的启动方式和执行次序是：
				加载内核
				执行init程序
				/etc/rc.d/rc.sysinit            # 由init执行的第一个脚本
				/etc/rc.d/rc $RUNLEVEL          # $RUNLEVEL为缺省的运行模式
				/etc/rc.d/rc.local
				/sbin/mingetty                  # 等待用户登录

				在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
				  调入keymap以及系统字体
				  启动swapping
				  设置主机名
				  设置NIS域名
				  检查（fsck）并mount文件系统
				  打开quota
				  装载声卡模块
				  设置系统时钟
				等等。


				/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
				，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
				从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
				/etc/rc.d/rc3.d/下的脚本。
				值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
				的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

				init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
				action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
				至此，LINUX的启动结束。
				from: http://zhidao.baidu.com/question/10963481.html
			--------
	- /etc/init.d/ 目录，存放程序的启动文件，比如mysql，httpd，iptables等等，这里都是程序安装好后，统一把控制脚本放到这里
	- 看程序启动参数
		ps 命令看程序启动命令
	- 系统配置，语言，网络等等
		/etc/sysconfig 目录下
	- 字符编码，语言设置，编码设置	      
		vim的i进入insert模式错误：
		/etc/sysconfig/i18n
		内容修改为：
			LANG="en_US.UTF-8"
			SYSFONT="latarcyrheb-sun16"
		重新加载下：
			source /etc/sysconfig/i18n
		vim按i键，正常进入insert模式

		支持中文 ，解决中文乱码

	- 修改所有者，修改拥有者
		例：要将当前目录下名 title 的文件夹及其子文件的所有者改为geust组的su用户，方法如下：
		#chown -R su.geust title
		-R 递归式地改变指定目录及其下的所有子目录和文件的拥有者。

		chown -R admin src ——修改当前目录中的src目录及其所有内容的所有者为admin

	- 端口占用查询 ，端口查询 linux端口查询
		查询端口被谁占用（linux命令）
		分类： linux 资料或经验 2012-03-26 16:59 118人阅读 评论(0) 收藏 举报
		lsof -i:3306
		查看3306端口被谁占用
		lsof简介
		lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (tcp) 和用户数据报协议 (udp) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。
		lsof使用
		lsof输出信息含义
		在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。
		from: http://blog.csdn.net/shuhuai007/article/details/7395690
	- ls --color=never 或 --color=aways
		命令行 ，终端 ，颜色
	- ssh远程命令行 ，通过 rz ,sz 传递/接受文件
		远程拷贝目录结构：
			scp -r $LIB_DIR/* admin@$1:$LIB_DIR/   #这里需要ssh可以自动登入，比如通过公钥认证
				scp -r xx.zip admin@xx.xx.xx.xx:/home/youDir
			------
				Linux下rz/sz安装及使用方法
				-
				-
				1)    工具说明
				在SecureCRT这样的ssh登录软件里, 通过在Linux界面里输入rz/sz命令来上传/下载文件. 对于RHEL5, rz/sz默认没有安装所以需要手工安装.
				sz: 将选定的文件发送(send)到本地机器;
				rz：运行该命令会弹出一个文件选择窗口, 从本地选择文件上传到服务器(receive).
				下载安装包lrzsz-0.12.20.tar.gz: http://www.ohse.de/uwe/software/lrzsz.html

				2)    软件安装
				首先通过sftp工具把安装文件上传到/tmp目录下.

				# cd /tmp
				# tar zxvf lrzsz-0.12.20.tar.gz && cd lrzsz-0.12.20
				# ./configure && make && make install
				 

				上面安装过程默认把lsz和lrz安装到了/usr/local/bin/目录下, 下面创建软链接, 并命名为rz/sz:

				# cd /usr/bin
				# ln -s /usr/local/bin/lrz rz
				# ln -s /usr/local/bin/lsz sz
				 

				3)    使用说明
				打开SecureCRT软件 -> Options -> session options -> X/Y/Zmodem 下可以设置上传和下载的目录; 然后在用SecureCRT登陆linux终端的时候:
				# sz filename (发送文件到客户端,zmodem接收可以自行启动)
				# rz (从客户端上传文件到linux服务端)

				:)

				来自：http://www.ej38.com/showinfo/linux-183843.htm
			------
	
		* SecureCRT
			- 快捷键 alt + 1,2,3....切换子标签窗口

	-   $# 是传给脚本(或者函数)的参数个数, $0 是脚本本身的名字, $@ 是传给脚本(或者函数)的所有参数的列表. 举例:

                  QUOTE:
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; cat foo.sh
                  #!/bin/bash

                  echo "script name   : $0"
                  echo "# of arguments: $#"
                  echo "all arguments : $@"
                  echo "arguments in order:"
                  for sArg in "$@"; do
                      echo "  $sArg"
                  done
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa bb cc
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc
                  arguments in order:
                    aa
                    bb
                    cc
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa "bb cc" dd
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc dd
                  arguments in order:
                    aa
                    bb cc
                    dd
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; bye


                  付：
                    $0   这个程式的执行名字       
                    $n   这个程式的第n个参数值，n=1..9       
                    $*   这个程式的所有参数       
                    $#   这个程式的参数个数       
                    $$   这个程式的PID       
                    $!   执行上一个背景指令的PID       
                    $?   执行上一个指令的返回值
	- linux shell命令中Esac是什么意思？
		一些刚刚接触bash编程的人，总是很奇怪bash里的一些关键字，知道它的功能，但不知道为什么要这样写。比如：
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac
		fi是if语句的结束，esac是case语句的结束。Fi和esac这样的关键字是不是很怪异呢？呵，仔细想一想，一点也不怪，考虑一下{} [] 等等，{和}是垂直轴对称的，[和]是垂直轴对称的。现在来看， if和fi及case和esac不也是这样吗？它们刚好反过，分别表示开始和结束。
	- 内核升级 linux 内核 升级 
		下面是centos例子：
			----
				具体的过程如下:
				[root@localhost ~]# uname -r
				2.6.18-194.el5
				1.下载linux-2.6.30内核包到/usr/src目录
				cd /usr/src
				wget ftp://ftp.kernel.org/pub/linux/kernel/v2.6/linux-2.6.30.tar.gz
				tar -xzvf linux-2.6.30.tar.bz2 -C /usr/src
				cd linux-2.6.30
				make mrproper  清除环境变量，即清除配置文件
				make menuconfig 在菜单模式下选择需要编译的内核模块:
				networking support—>networking options—>network packet filtering framework(netfilter)
				(1).core netfilter configuration
				A 勾中”Netfilter connection tracking support”  -m state相关模块是依赖它的，不选则没有。
				B 将netbios name service protocal support(new)   编译成模块,不然后面升级iptables后启动时会出错
				C 勾中“Netfilter Xtables support (required for ip_tables)”
				(2).IP: Netfilter Configuration
				A 将 “IPv4 connection tracking support (require for NAT)” 编译成模块。
				B 勾中IP tables support (required for filtering/masq/NAT) 。
				C 将 “Full NAT” 下的 “MASQUERADE target support” 和 “REDIRECT target support” 编译成模块
				(3).其它模块可以根据自己的需要进行选择,若不懂可以参考内核配置手册.
				make clean  确保所有东西均保持最新状态.
				make bzImage  生成内核文件
				make modules 编译模块
				make modules_install 安装模块
				make install  安装
				mkinitrd  /boot/initrd_2.6.30.img  2.6.30  根据内核版本和指定参数生成映像文件
				cp arch/x86/boot/bzImage /boot/vmlinuz-2.6.30
				cp /usr/src/linux-2.6.30/System.map /boot/System.map-2.6.30
				2.在/etc/grub.conf添加如下2.6.30的信息,并把default=1改为default=0
				[root@localhost ~]# cat /etc/grub.conf
				# grub.conf generated by anaconda
				#
				# Note that you do not have to rerun grub after making changes to this file
				# NOTICE:  You have a /boot partition.  This means that
				#          all kernel and initrd paths are relative to /boot/, eg.
				#          root (hd0,0)
				#          kernel /vmlinuz-version ro root=/dev/VolGroup00/LogVol00
				#          initrd /initrd-version.img
				#boot=/dev/sda
				default=0
				timeout=5
				splashimage=(hd0,0)/grub/splash.xpm.gz
				hiddenmenu
				title CentOS (2.6.18-194.el5)
					root (hd0,0)
					kernel /vmlinuz-2.6.18-194.el5 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.18-194.el5.img
				title CentOS (2.6.30)
					root (hd0,0)
					kernel /vmlinuz-2.6.30 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.30.img
				3.此步若没有操作,重启会报错”insmod: error inserting ‘/lib/dm-region-hash.ko’: –1 File exits”,原因是重复了，根据网上查到的资料，2.6.x自编译内核会有这个小bug,我测试过不修改直接重启，虽然有报错，但仍然可以进入系统的.

				[root@localhost]cp /boot/initrd-2.6.30.img /tmp
				[root@localhost]cd /tmp/
				[root@localhost tmp]mkdir newinitrd
				[root@localhost tmp]cd newinitrd/
				[root@localhost newinitrd]zcat ../initrd-2.6.30.img |cpio -i
				[root@localhost newinitrd]vi init             删掉重复的如下两行:
				echo “Loading dm-region-hash.ko module”
				insmod /lib/dm-region-hash.ko
				[root@localhost newinitrd]# find .|cpio -c -o > ../initrd
				14765 blocks
				[root@localhost newinitrd]# cd ..
				[root@localhost tmp]# gzip -9 < initrd > initrd-2.6.30.img
				[root@localhost tmp]# ls
				gconfd-root  initrd  initrd-2.6.30.img  mapping-root  newinitrd  scim-panel-socket:0-root
				[root@localhost tmp]# mv /boot/initrd-2.6.30.img /home/
				[root@localhost tmp]# cp initrd-2.6.30.img /boot/
				[root@localhost tmp]#reboot
				4.重启成功后,再看看内核，是2.6.30，ok了。
				[root@localhost ~]# uname -r
				2.6.30 
			----
			from: http://bbs.51cto.com/thread-788212-1.html
		实际：
			make menuconfig 报需要ncurses包(及其devel包)
				yum install ncurses-devel //通过yum安装


	linux command eg 命令
	字符转换 unix字符 window字符
	unix2dos dos2unix

	SERVER=/home/user - 定义=号两边不能有空格

	将shell执行的pid保存到文件，读取文件中的pid关闭程序
	#! /bin/sh
	SERVER=/home/chengs
	java test > $SERVER/server.log & echo $! > $SERVER/server.pid
	
	- 关于Linux网络配置
		一：什么是网络接口卡以及如何查看网络接口的网络信息：
		 在Linux系统中，主机的网络接口卡通常称为“网络接口”，我们可以使用ifconfig命令来查看网络
		 
		接口的信息（普通用户使用/sbin/ifconfig）:
		 [root@lht ~]# ifconfig
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:6712 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1219 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:590780 (576.9 KiB)  TX bytes:156407 (152.7 KiB)
			   Interrupt:177 Base address:0x1080
		 
		lo        Link encap:Local Loopback
			   inet addr:127.0.0.1  Mask:255.0.0.0
			   inet6 addr: ::1/128 Scope:Host
			   UP LOOPBACK RUNNING  MTU:16436  Metric:1
			   RX packets:1654 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1654 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:0
			   RX bytes:3893045 (3.7 MiB)  TX bytes:3893045 (3.7 MiB)
		 “eth0”是Linux系统中第一块以太网卡的名称，在大多数主机中只有一块物理网卡，因此“eth0”
		 
		代表系统中唯一的网络接口。
		 “lo”是Linux系统中的“环回”网络接口，“lo”并不代表真正的网络接口，而是一个虚拟的网络
		 
		接口，其IP地址永远是“127.0.0.1”；“lo”网络接口通常用于对本机的网络测试，这样在主机没
		 
		有物理网络接口或物理网络接口没有激活时Linux系统仍然可以完成网络相关的操作；
		 查看指定接口网络信息：ifconfig 网络接口名称：
		 [root@lht ~]# ifconfig eth0
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:832 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:139 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:73325 (71.6 KiB)  TX bytes:22844 (22.3 KiB)
			   Interrupt:177 Base address:0x1080
		 
		[root@lht ~]#
		 其中“HWaddr”表示网络接口物理地址（MAC地址），“inet addr”表示网络接口IP地址，“Bcast
		 
		”表示网各接口所在网络的广播地址，“Mask”表示网络接口的子网掩码；另外我们还可以用
		 
		ifconfig -a查看所有网络接口的网络信息。
		 二：查看网关地址和路由信息：
		 1：route:route命令不使用任何命令选项和参数时可以显示当前Linux主机中的路由表信息：
		 [root@lht ~]# route
		 Kernel IP routing table
		 Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
		 192.168.5.0     *               255.255.255.0   U     0      0        0 eth0
		 169.254.0.0     *               255.255.0.0     U     0      0        0 eth0
		 default         192.168.5.1     0.0.0.0         UG    0      0        0 eth0
		 2：使用ping命令测试与其他主机的网络连接：
		 ping 目标主机地址
		 [root@lht ~]# ping 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.123 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.176 ms
		 64 bytes from 192.168.5.104: icmp_seq=3 ttl=64 time=0.163 ms
		 64 bytes from 192.168.5.104: icmp_seq=4 ttl=64 time=0.818 ms
		 
		--- 192.168.5.104 ping statistics ---
		 4 packets transmitted, 4 received, 0% packet loss, time 3004ms
		 rtt min/avg/max/mdev = 0.123/0.320/0.818/0.288 ms
		 注意：ping命令会持续发送测试包，因此会一直在屏幕上显示每个包的测试结果，使用Ctrl+C组合键
		 
		将结束ping命令发送测试数据包；
		 使用ping命令发送指定数量的数据包进行网络测试连接：
		 ping -c 测试数据包的数量 目标的主机地址：
		 [root@lht ~]# ping -c 2 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.146 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.170 ms
		 
		--- 192.168.5.104 ping statistics ---
		 2 packets transmitted, 2 received, 0% packet loss, time 1002ms
		 rtt min/avg/max/mdev = 0.146/0.158/0.170/0.012 ms
		 3:使用traceroute命令测试当前主机到目的主机之间经过了哪些网络节点：
		 traceroute 目的主机地址
		 [root@lht ~]# traceroute 192.168.5.104
		 traceroute to 192.168.5.104 (192.168.5.104), 30 hops max, 40 byte packets
		  1   (192.168.5.104)  0.859 ms  0.255 ms  0.625 ms
		 三：查看主机名称信息：
		 1：使用hostname命令查看当前主机名称：
		 [root@lht ~]# hostname
		 lht
		 2：更改主机名称：
		 [root@lht ~]# hostname lihantuan
		 [root@lht ~]# hostname
		 lihantuan
		 3：使用nslookup查询liuux主机中的域名：
		 nslookup->输入需要查询的域名->回车
		 nslookup 待解析的域名
		 四：网络设置方法：
		 1：DHCP网络配置：
		 使用dhclient命令可以从DHCP服务器中申请新的网络配置应用于当前的Linux主机；
		 2：手工网络配置：
		 ip地址配置命令：
		 ifconfig eth0 ip地址 netmask 子网掩码
		 [root@lht ~]# ifconfig eth0 192.168.5.247 netmask 255.255.255.0
		 [root@lht ~]#
		 注意ifconfig命令设置的网络接口属性只在当前系统运行时起效，重启后将按照网络接口配置文件
		 
		ifcfg-xxx重新设置网络接口属性；
		 3：路由配置命令：
		 添加默认网关路由：
		 route add default gw 网关地址
		 [root@lht ~]# route add default gw 192.168.5.104
		 [root@lht ~]#
		 删除默认网关：
		 route del default gw 网关地址：
		 [root@lht ~]# route del default gw 192.168.5.104
		 [root@lht ~]#
		 4：通过修改配置文件进行网络设置：
		 修改网络接口配置文件ifcfg-xxx,其中\"xxx\"是网络接口名称：
		 vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 [root@lht ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 # Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]
		 DEVICE=eth0//用于设置网络接口的名称
		 BOOTPROTO=static//用于设置网络接口是配置为静态地址（static）还是配置为dhcp；
		 BROADCAST=192.168.5.255
		 HWADDR=00:0C:29:D1:42:3F
		 IPADDR=192.168.5.247 //设置网络接口地址
		 GATEWAY=192.168.5.1 //设置网络接口的默网关
		 IPV6ADDR=
		 IPV6PREFIX=
		 NETMASK=255.255.255.0 //设置网络接口的子网掩码
		 NETWORK=192.168.5.0
		 ONBOOT=yes
		 保存好配置文件后还得重启网络服务：
		 [root@lht ~]# /etc/init.d/network restart
		 Shutting down interface eth0:                              [  OK  ]
		 Shutting down loopback interface:                          [  OK  ]
		 Bringing up loopback interface:                            [  OK  ]
		 Bringing up interface eth0:                                [  OK  ]
		 5：修改主机配置文件：
		 /etc/sysconfig/network
		 [root@lht ~]# cat /etc/sysconfig/network
		 NETWORKING=yes
		 NETWORKING_IPV6=yes
		 HOSTNAME=lht
		 GATEWAY=192.168.5.1
		 如果改了/etc/sysconfig/network里的主机名，则还需更改/etc/hosts里的主机名
		 [root@lht ~]# cat /etc/host
		 cat: /etc/host: No such file or directory
		 [root@lht ~]# cat /etc/hosts
		 # Do not remove the following line, or various programs
		 # that require network functionality will fail.
		 127.0.0.1               lht localhost.localdomain localhost
		 ::1             localhost6.localdomain6 localhost6
		 再重启系统就生效；
		 系统管理员还可以通过修改hosts文件添加更多的IP地址与主机的对应记录，hosts文件保存后就会立
		刻生效。
		 6：域名服务器配置文件：/etc/resolv.conf
		 [root@lihantuan ~]# cat /etc/resolv.conf
		 nameserver 192.168.6.100
		 nameserver 192.168.6.90
		 nameserver配置选项设置DNS服务器的IP地址，文件中最多可以有3个nameserver记录，linux系统会
		 
		优先使用文件最上面的nameserver记录，当前面的DNS服务器无效时系统会自动使用后面的DNS服务器
		 进行域名解析。

		来自：http://my.oschina.net/adamboy/blog/35109

	kill `cat server.pid` -- 这里注意是波浪号 ，不是单引号
	--------
		############################################################################
		mount -l -t

		sh startup.sh

		############################################################################
		该如何才能知道系统都有什么硬件设备，有如下几种方式：
		方式一：
		使用lsdev命令，可以显示系统中的设备及其特征。
		例如：lsdev -C
		但是一般的系统上可能没有这个命令，比如我装的fedora上面就没有这个命令。
		方法二：
		显示/proc/dev文件，这个文件记录了系统的一些硬件信息，
		例如：cat /proc/dev
		方法三：
		如果要查找特定的usb设备，则可以使用lsusb命令，列出所有的usb设备。
		如果要查找特定的pcmcia设备，则可以使用lspcmcia命令，列出所有的pcmcia设备。
		如果要查找特定的pci设备，则可以使用lspci命令，列出所有的pcm设备。
		来自：达内BBS
		############################################################################

		有些在freebsd下也能用…
		# uname -a               # 查看内核/操作系统/CPU信息
		# head -n 1 /etc/issue   # 查看操作系统版本
		# cat /proc/cpuinfo      # 查看CPU信息
		# hostname               # 查看计算机名
		# lspci -tv              # 列出所有PCI设备
		# lsusb -tv              # 列出所有USB设备
		# lsmod                  # 列出加载的内核模块
		# env                    # 查看环境变量资源
		# free -m                # 查看内存使用量和交换区使用量
		# df -h                  # 查看各分区使用情况
			-h human can read
		# du -sh         # 查看指定目录的大小
		# grep MemTotal /proc/meminfo   # 查看内存总量
		# grep MemFree /proc/meminfo    # 查看空闲内存量
		# uptime                 # 查看系统运行时间、用户数、负载
		# cat /proc/loadavg      # 查看系统负载磁盘和分区
		# mount | column -t      # 查看挂接的分区状态
		# fdisk -l               # 查看所有分区
			/dev/hda4            2946        3916     7799557+   5  Extended
				未分配的空间
				fdisk /dev/hda
				m查看帮助
				n为新建分区
				输入起始和结束cylinders ，可以通过fdisk -l 查看可分配空间，工具也会提示可分配空间

		# swapon -s              # 查看所有交换分区
		# hdparm -i /dev/hda     # 查看磁盘参数(仅适用于IDE设备)
		# dmesg | grep IDE       # 查看启动时IDE设备检测状况网络
		# ifconfig               # 查看所有网络接口的属性
		# iptables -L            # 查看防火墙设置
		# route -n               # 查看路由表
		# netstat -lntp          # 查看所有监听端口
		# netstat -antp          # 查看所有已经建立的连接
		# netstat -s             # 查看网络统计信息进程
		# ps -ef                 # 查看所有进程
		# top                    # 实时显示进程状态用户
		# w                      # 查看活动用户
		# id             # 查看指定用户信息
		# last                   # 查看用户登录日志
		# cut -d: -f1 /etc/passwd   # 查看系统所有用户
		# cut -d: -f1 /etc/group    # 查看系统所有组
		# crontab -l             # 查看当前用户的计划任务服务
		# chkconfig –list       # 列出所有系统服务
			chkconfig  provides  a  simple  command-line  tool  for  maintaining the /etc/rc[0-6].d directory hierarchy by relieving system administrators of 
			the task of directly manipulating the  numerous  symbolic  links  in  those directories.
		# chkconfig –list | grep on    # 列出所有启动的系统服务程序
		# rpm -qa                # 查看所有安装的软件包
		cat /proc/cpuinfo ：查看CPU相关参数
		cat /proc/partitions ：查看硬盘和分区
		cat /proc/meminfo ：查看内存信息
		cat /proc/version ：查看版本，类似uname -r
		cat /proc/ioports ：查看设备io端口
		cat /proc/interrupts ：查看中断
		cat /proc/pci ：查看pci设备的信息
		cat /proc/swaps ：查看所有swap分区的信息
		来自：达内BBS
		############################################################################
		linux目录架构
		/   根目录
		/bin    常用的命令 binary file 的目錄
		/boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内
		     /boot/grub/menu.lst   GRUB设置
		     /boot/vmlinuz   内核
		     /boot/initrd     核心解壓縮所需 RAM Disk
		/dev    系统周边设备     
		/etc    系统相关设定文件
		     /etc/DIR_COLORS   设定颜色
		     /etc/HOSTNAME   设定用户的节点名
		     /etc/NETWORKING   只有YES标明网络存在
		     /etc/host.conf 文件说明用户的系统如何查询节点名
		     /etc/hosts 设定用户自已的IP与名字的对应表
		     /etc/hosts.allow 设置允许使用inetd的机器使用 
		     /etc/hosts.deny 设置不允许使用inetd的机器使用
		     /etc/hosts.equiv 设置远端机不用密码
		     /etc/inetd.conf 设定系统网络守护进程inetd的配置
		     /etc/gateways 设定路由器
		     /etc/protocols 设定系统支持的协议
		     /etc/named.boot 设定本机为名字服务器的配置文件
		     /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP
		     /etc/resolv.conf    设置DNS  
		     /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這兩個 X Server 的設定檔
		     /etc/fstab    记录开机要mount的文件系统
		     /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel
		     /etc/issue 记录用户登录前显示的信息
		     /etc/group 设定用户的组名与相关信息
		     /etc/passwd 帐号信息
		     /etc/shadow 密码信息
		     /etc/sudoers 可以sudo命令的配置文件
		     /etc/securetty 设定哪些终端可以让root登录
		     /etc/login.defs 所有用户登录时的缺省配置
		     /etc/exports 设定NFS系统用的
		     /etc/init.d/   所有服務的預設啟動 script 都是放在這裡的，例如要啟動或者關閉
		     /etc/xinetd.d/  這就是所謂的 super daemon 管理的各項服務的設定檔目錄
		     /etc/modprobe.conf   内核模块额外参数设定
		     /etc/syslog.conf   日志设置文件
		/home   使用者家目录
		/lib    系统会使用到的函数库
		     /lib/modules   kernel 的相关模块
		     /var/lib/rpm   rpm套件安装处 
		/lost+found    系統不正常產生錯誤時，會將一些遺失的片段放置於此目錄下
		/mnt     外设的挂载点
		/media   与/mnt类似
		/opt     主机额外安装的软件
		/proc    虚拟目录，是内存的映射
		      /proc/version   内核版本
		       /proc/sys/kernel   系统内核功能
		/root    系统管理员的家目录
		/sbin    系统管理员才能执行的指令
		/srv     一些服務啟動之後，這些服務所需要取用的資料目錄
		/tmp     一般使用者或者是正在執行的程序暫時放置檔案的地方
		/usr     最大的目录，存许应用程序和文件
		    /usr/X11R6：   X-Window目录 
		    /usr/src：    Linux源代码
		    /usr/include：系统头文件
		    /usr/openwin 存放SUN的OpenWin 
		    /usr/man 在线使用手册
		    /usr/bin           使用者可執行的 binary file 的目錄
		    /usr/local/bin     使用者可執行的 binary file 的目錄
		    /usr/lib           系统会使用到的函数库
		    /usr/local/lib     系统会使用到的函数库
		    /usr/sbin          系统管理员才能执行的指令
		    /usr/local/sbin    系统管理员才能执行的指令
		/var   日志文件
		    /var/log/secure    記錄登入系統存取資料的檔案，例如 pop3, ssh, telnet, ftp 等都會記錄在此檔案中
		    /var/log/wtmp      記錄登入者的訊息資料, last
		    /var/log/messages  幾乎系統發生的錯誤訊息
		    /var/log/boot.log  記錄開機或者是一些服務啟動的時候，所顯示的啟動或關閉訊息
		    /var/log/maillog   紀錄郵件存取或往來( sendmail 與 pop3 )的使用者記錄
		    /var/log/cron      記錄 crontab 這個例行性服務的內容
		    /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log/procmail.log：
		    分別是幾個不同的網路服務的記錄檔
		 
		一些常用的基本命令:
		uname -a    查看内核版本       
		ls -al    显示所有文件的属性
			-R, --recursive            list subdirectories recursively
			ls -a -R 显示子目录文件
			ls -h 显示文件大写，以可读方式显示结果
			-c 根据创建时间排序
		pwd         显示当前路径        
		cd -    返回上一次目录     cd ~    返回主目录
		date s      设置时间、日期          
		cal      显示日历     cal 2006
		bc          计算器具               
		man  & info     帮助手册
		locale     显示当前字体     locale -a    所有可用字体     /etc/sysconfig/i18n设置文件
		LANG=en    使用英文字体            
		sync       将数据同步写入硬盘        
		shutdonw -h now & half & poweroff  关机
		reboot     重启                   
		startx  &  init 5   进入图形介面
		/work  & ?work    向上、下查找文档内容
		chgrp      改变档案群组  chgrp testing install.log    
		chown     改变所属人   chown root:root install.log
		chmod      改变属性     chmod 777 install.log     read=4  write=2  execute=1
		cp   复制   cp filename
		rm   删除文件  rm -rf filename   强制删除文件 
			rm -rf directory or file   -r或-R或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
		rmdir   删除文件夹
		mv  移动    mv 123.txt 222.txt  重命名
		mkdir     创建文件夹  
			mkdir -p /usr/dat.txt  # -p 参数表示如果上级目录不存在则创建
		touch     创建文件  更新当前时间
		cat       由第一行开始显示     cat |more  分页
		nl        在内容前加行号
		more  &  less   一面一面翻动
		head -n filename   显示第N行内容
		tail -n filename  显示后N行内容
			tail -f  显示追加内容
			-f
			 如果输入文件是常规文件或如果 File 参数指定 FIFO（先进先出），那么 tail 命令不会在复制了输入文件的最后的指定单元后终止，而是继续从输入文件读取和复制额外的单元（当这些单元可用时）。如果没有指定 File 参数，并且标准输入是管道，则会忽略 -f 标志。tail -f 命令可用于监视另一个进程正在写入的文件的增长。

			 同时显示多个文件追加的内容，比如用于同时查看多个日志文件场景
			 tail -f -n20 logs/info.log logs/error.log
			
			显示文件前几行内容：
				 If the first character of N (the number of bytes or lines) is a `+',	       print beginning with the Nth item from the start of each file, otherwise,print the last N items in the file.
				 tail -f -n+10

		od        显示非纯文档
		df -h 显示分区空间      (磁盘)
		du  显示目录或文件的大小
		fdisk   分区设置    fdisk -l /dev/hda  显示硬盘分区状态
		mkfs    建立各种文件系统  mkfs -t ext3  /dev/ram15   
		fsck    检查和修复LINUX档案
		ln      硬链接   ln -s  软件链接
			rm -rf open.war
			ln -s /home/admin/houyi/service/src/houyi.console.openapi/target/open.war
		whereis   查找命令
		locate    查找
		find      查找   find / -name "***.***"
			在当前目录下查找包含 hello 字符串的 后缀名为 .c 的文件:
				find . -name "*.c" | xargs grep -H "hello"
		which     查看工具
		whoami    显示当前用户
		gcc -v    查看GCC版本
		chattr +i filename  禁止删除   chattr -i filename  取消禁止
		lsattr    显示隐藏档属性
		updatedb  更新资料库
		mke2fs    格式化   mkfs -t ext3 
		dd if=/etc/passwd of=/tmp/passwd.bak    备份
			用法：dd [操作符]...
			  或：dd 选项
			Copy a file, converting and formatting according to the operands.

			  bs=BYTES        force ibs=BYTES and obs=BYTES
			  cbs=BYTES       convert BYTES bytes at a time
			  conv=CONVS      convert the file as per the comma separated symbol list
			  count=BLOCKS    copy only BLOCKS input blocks
			  ibs=BYTES       read BYTES bytes at a time
			  if=FILE         read from FILE instead of stdin
			  iflag=FLAGS     read as per the comma separated symbol list
			  obs=BYTES       write BYTES bytes at a time
			  of=FILE         write to FILE instead of stdout
			  oflag=FLAGS     write as per the comma separated symbol list
			  seek=BLOCKS     skip BLOCKS obs-sized blocks at start of output
			  skip=BLOCKS     skip BLOCKS ibs-sized blocks at start of input
			  status=noxfer   suppress transfer statistics			

			从dvd制作iso文件：
			  dd if=/dev/cdrom of=/var/lib/libvirt/images/CentOS-6.2-x86_64-bin-DVD1.iso 
		mount     列出系统所有的分区
		mount -t iso9660 /dev/cdrom /mnt/cdrom   挂载光盘
		mount -t vfat /dev/fd0 /mnt/floppy       挂载软盘
		mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
		mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
		Linux-NTFS Project: http://linux-ntfs.sourceforge.net/
		umount /mnt/hda3  缷载
		ifconfig   显示或设置网络设备
			设置ip: ifconfig eth0 192.168.232.162 netmask 255.255.255.0
			ifconfig eth0 hw ether 00:11:33:44:55:66 - set mac
		service network restart   重启网卡  
		ifdown eth0  关闭网卡
		ifup eth0    开启网卡
		clear    清屏
		history    历史记录       !55  执行第55个指令
		stty   设置终端    stty -a
		fdisk /mbr   删除GRUB
		at     僅進行一次的工作排程
		crontab   循環執行的例行性命令    [e]编辑,[l]显示,[r]删除任务
			Crontab  is  the  program  used  to  install,  deinstall  or list the tables used to drive the cron(8) daemon in ISC Cron
		&       后台运行程序    tar -zxvf 123.tar.gz & --------->后台运行
		jobs    观看后台暂停的程序   jobs -l
		fg      将后台程序调到前台   fg n ------>n是数字,可以指定进行那个程序
		bg      让工作在后台运行
		kill    结束进程    kill -9 PID     [9]强制结束,[15]正常结束,[l]列出可用的kill信号
			kill -9 强制停止进程，kill不了
			kill -3 PID
				sudo kill -3 PID获取thread dump log
		ps aux  查看后台程序   
		top     查看后台程序   top -d 2    每两秒更新一次        top -d 2 -p10604   观看某个PID
			top -b -n 2 > /tmp/top.txt ----->將 top 的資訊進行 2 次，然後將結果輸出到 /tmp/top.txt    
		pstree   以树状图显示程序    [A]以 ASCII 來連接, [u]列出PID, [p]列出帐号
		killall   要刪除某個服務    killall -9 httpd
		free      显示内存状态     free -m  -------->以M为单位显示
		uptime    显示目前系统开机时间
		netstat   显示网络状态    netstat -tulnp------>找出目前系統上已在監聽的網路連線及其 PID
		dmesg     显示开机信息    demsg | more
		nice      设置优先权      nice -n -5 vi & ----->用 root 給一個 nice 植為 -5 ，用於執行 vi 
		renice    调整已存在优先权
		runlevel  显示目前的runlevel

		depmod    分析可载入模块的相依性
		lsmod     显示已载入系统的模块
		modinfo   显示kernel模块的信息
		insmod    载入模块
		modprobe   自动处理可载入模块
		rmmod     删除模块
		chkconfig   检查，设置系统的各种服务     chkconfig --list ----->列出各项服务状态
		ntsysv     设置系统的各种服务
		cpio      备份文件
		 

		压缩命令：
		 *.Z      compress 程式壓縮的檔案； 
		 *.bz2    bzip2 程式壓縮的檔案； 
		 *.gz     gzip 程式壓縮的檔案； 
		 *.tar    tar 程式打包的資料，並沒有壓縮過； 
		 *.tar.gz tar 程式打包的檔案，其中並且經過 gzip 的壓縮
		compress filename  压缩文件  加[-d]解压  uncompress
		gzip filename   压缩  加[-d]解压  zcat 123.gz 查看压缩文件内容
		bzip2 -z filename  压缩  加[-d]解压   bzcat filename.bz2  查看压缩文件内容
		tar -cvf /home/123.tar /etc  打包，不压缩
		tar -xvf 123.tar   解开包
		tar -zxvf /home/123.tar.gz  以gzip解压
		tar -jxvf /home/123.tar.bz2  以bzip2解压
		tar -ztvf /tmp/etc.tar.gz   查看tar内容
		cpio -covB  > [file|device]   份份
		cpio -icduv < [file|device]   还原
		 zip -r fileName ./*.txt - 打包当前目录下所有txt文件 -r 表示递归所有子目录
			zip -r foo . -i *.sql 打包当前目录下匹配文件名的文件到foo
		vi一般用法
		一般模式              编辑模式                  指令模式
		h 左               a,i,r,o,A,I,R,O             :w 保存
		j 下                进入编辑模式                :w! 强制保存
		k 上                dd 删除光标当前行           :q! 不保存离开
		l 右                ndd 删除n行                 :wq! 保存后离开
		0 移动到行首        yy 复制当前行                :e! 还原原始档
		$ 移动到行尾        nyy 复制n行                  :w filename 另存为
		H 屏幕最上          p,P 粘贴                     :set nu 设置行号
		M 屏幕中央          u  撤消                      :set nonu 取消行号
		L 屏幕最下          [Ctrl]+r 重做上一个动作       ZZ 保存离开
		G 档案最后一行      [ctrl]+z 暂停退出            :set nohlsearch   永久地关闭高亮显示
		/work 向下搜索                                   :sp 同时打开两个文档 
		?work 向上搜索                                   [Ctrl]+w 两个文档设换
		gg 移动到档案第一行                              :nohlsearch    暂时关闭高亮显示
		 
		认识SHELL
		alias    显示当前所有的命令别名      alias lm="ls -al"   命令别名    unalias lm 取消命令别名
		type      类似which
		exprot    设置或显示环境变量
		exprot PATH="$PATH":/sbin  添加/sbin入PATH路径
		echo $PATH    显示PATH路径
		bash      进入子程序
		name=yang     设定变量
		unset name    取消变量
		echo $name    显示变量的内容
		myname="$name its me"   &   myname='$name its me'     单引号时$name失去变量内容
		ciw=/etc/sysconfig/network-scripts/     设置路径
		env      列出所有环境变量
		echo $RANDOM    显示随意产生的数
		set      设置SHELL
		PS1='[\u@\h \w \A #\#]\$ '     提示字元的設定
		   [root@linux ~]# read [-pt] variable     -----------读取键盘输入的变量
		   參數：
		   -p  ：後面可以接提示字元！
		   -t  ：後面可以接等待的『秒數！』
		declare    声明 shell 变量
		ulimit -a   显示所有限制资料
		 ls /tmp/yang && echo "exist" || echo "not exist"
		 意思是說，當 ls /tmp/yang 執行後，若正確，就執行echo "exist" ,若有問題，就執行echo "not exist" 
		 echo $PATH | cut -d ':' -f 5       以:为分隔符,读取第5段内容
		 export | cut -c 10-20      读取第10到20个字节的内容
		 last | grep 'root'    搜索有root的一行,加[-v]反向搜索
		 cat /etc/passwd | sort    排序显示
		 cat /etc/passwd | wc      显示『行、字数、字节数』
		正规表示法
		[root@test root]# grep [-acinv] '搜尋字串' filename
		       參數說明：
		       -a ：將 binary 檔案以 text 檔案的方式搜尋資料
		       -c ：計算找到 '搜尋字串' 的次數
		       -i ：忽略大小寫的不同，所以大小寫視為相同
		       -n ：順便輸出行號
		       -v ：反向選擇，亦即顯示出沒有 '搜尋字串' 內容的那一行！

		文件内容查找：

		 grep -n 'the' 123.txt     搜索the字符 -----------搜尋特定字串       
		 grep -n 't[ea]st' 123.txt    搜索test或taste两个字符---------利用 [] 來搜尋集合字元
		 grep -n '[^g]oo' 123.txt     搜索前面不为g的oo-----------向選擇 [^] 
		 grep -n '[0-9]' 123.txt  搜索有0-9的数字
		 grep -n '^the' 123.txt 搜索以the为行首-----------行首搜索^
		 grep -n '^[^a-zA-Z]' 123.txt  搜索不以英文字母开头
		 grep -n '[a-z]$' 123.txt    搜索以a-z结尾的行---------- 行尾搜索$
		 grep -n 'g..d' 123.txt     搜索开头g结尾d字符----------任意一個字元 . 
		 grep -n 'ooo*' 123.txt     搜索至少有两个oo的字符---------重複字元 *
			tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'
				grep -v 查看不匹配的行（select non-matching lines）
					如果有多个字符串匹配，先去掉匹配率高的，否则可能导致响应慢
				grep -i 去区分大小写


		sed    文本流编辑器    利用脚本命令来处理文本文件
		awd    模式扫描和处理语言
		 nl 123.txt | sed '2,5d'   删除第二到第五行的内容
		diff     比较文件的差异
		cmp      比较两个文件是否有差异
		patch    修补文件
		pr       要打印的文件格式化
		 

		帐号管理
		/etc/passwd    系统帐号信息
		/etc/shadow    帐号密码信息    经MD5 32位加密
		     在密码栏前面加『 * 』『 ! 』禁止使用某帐号
		/etc/group     系统群组信息
		/etc/gshadow
		newgrp    改变登陆组
		useradd  &  adduser    建立新用户  ---------> useradd -m test  自动建立用户的登入目录
			  useradd -m -g pgroup test --------->指定所属级
		/etc/default/useradd   相关设定
		/etc/login.defs       UID/GID 有關的設定
		passwd    更改密码 -----------> passwd test
		usermod   修改用户帐号
		userdel   删除帐号 ----------->userdel -r test
		chsh      更换登陆系统时使用的SHELL   [-l]显示可用的SHELL;[-s]修改自己的SHELL
		chfn      改变finger指令显示的信息
		finger    查找并显示用户信息
		id        显示用户的ID ----------->  id test
		groupadd   添加组
		groupmod   与usermod类似
		groupdel   删除组
		su test    更改用户   su -    进入root,且使用root的环境变量
		sudo       以其他身份来执行指令
		visudo     编辑/etc/sudoers      加入一行『 test ALL=(ALL) ALL 』
			   %wheel ALL = (ALL) ALL               系统里所有wheel群组的用户都可用sudo
			   %wheel ALL = (ALL) NOPASSWD: ALL     wheel群组所有用户都不用密码NOPASSWD
		       User_Alias ADMPW = vbird, dmtsai, vbird1, vbird3         加入ADMPW组
		       ADMPW ALL = NOPASSWD: !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, \
		       !/usr/bin/passwd root      可以更改使用者密码,但不能更改root密码 (在指令前面加入 ! 代表不可)
		PAM (Pluggable Authentication Modules, 嵌入式模組)
		who & w     看谁在线                     
		last        最近登陆主机的信息
		lastlog     最近登入的時間    读取 /var/log/lastlog 
		talk        与其他用户交谈
		write       发送信息    write test   [ctrl]+d 发送
		mesg        设置终端机的写入权限    mesg n 禁止接收     mesg y 
		wall        向所有用户发送信息    wall this is q test
		mail        写mail   
		/etc/default/useradd    家目录默认设置
		quota      显示磁盘已使用的空间与限制     quota -guvs ----->秀出目前 root 自己的 quota 限制值
			   quota -vu   查询
		quotacheck   检查磁盘的使用空间与限制     quotacheck -avug  ----->將所有的在 /etc/mtab 內，含有 quota 支援的 partition 進行掃瞄
			     [-m] 强制扫描  
		     quota一定要是独立的分区,要有quota.user和quota.group两件文件,在/etc/fstab添加一句:
		     /dev/hda3 /home ext3 defaults,usrquota,grpquota 1 2
		     chmod 600 quota*         设置完成,重启生效
		edquota    编辑用户或群组的quota  [u]用户,[g]群组,[p]复制,[t]设置宽限期限 
			   edquota -a yang       edquota -p yang -u young ----->复制    
		quotaon    开启磁盘空间限制     quotaon -auvg -------->啟動所有的具有 quota 的 filesystem
		quotaoff   关闭磁盘空间限制     quotaoff -a  -------->關閉了 quota 的限制
		repquota -av     查閱系統內所有的具有 quota 的 filesystem 的限值狀態
		Quota 從開始準備 filesystem 的支援到整個設定結束的主要的步驟大概是：
		1、設定 partition 的 filesystem 支援 quota 參數：
		由於 quota 必須要讓 partition 上面的 filesystem 支援才行，一般來說， 支援度最好的是 ext2/ext3 ，
		其他的 filesystem 類型鳥哥我是沒有試過啦！ 啟動 filesystem 支援 quota 最簡單就是編輯 /etc/fstab ，
		使得準備要開放的 quota 磁碟可以支援 quota 囉；
		2、建立 quota 記錄檔：
		剛剛前面講過，整個 quota 進行磁碟限制值記錄的檔案是 aquota.user/aquota.group， 
		要建立這兩個檔案就必須要先利用 quotacheck 掃瞄才行喔！
		3、編輯 quota 限制值資料：
		再來就是使用 edquota 來編輯每個使用者或群組的可使用空間囉；
		4、重新掃瞄與啟動 quota ：
		設定好 quota 之後，建議可以再進行一次 quotacheck ，然後再以 quotaon 來啟動吧！

		开机流程简介
		1、載入 BIOS 的硬體資訊，並取得第一個開機裝置的代號； 
		2、讀取第一個開機裝置的 MBR 的 boot Loader (亦即是 lilo, grub, spfdisk 等等) 的開機資訊； 
		3、載入 Kernel 作業系統核心資訊， Kernel 開始解壓縮，並且嘗試驅動所有硬體裝置； 
		4、Kernel 執行 init 程式並取得 run-level 資訊； 
		5、init 執行 /etc/rc.d/rc.sysinit 檔案； 
		6、啟動核心的外掛模組 (/etc/modprobe.conf)； 
		7、init 執行 run-level 的各個批次檔( Scripts )； 
		8、init 執行 /etc/rc.d/rc.local 檔案； 
		9、執行 /bin/login 程式，並等待使用者登入； 
		10、登入之後開始以 Shell 控管主機。 
		在/etc/rc.d/rc3.d內,以S开头的为开机启动,以K开头的为关闭,接着的数字代表执行顺序
		GRUB vga设定
		彩度\解析度  640x480  800x600  1024x768  1280x1024   bit 
		    256        769      771      773       775      8 bit 
		   32768       784      787      790       793     15 bit 
		   65536       785      788      791       794     16 bit 
		   16.8M       786      789      792       795     32 bit 

		./configure    检查系统信息       ./configure --help | more  帮助信息
		make clean     清除之前留下的文件
		make           编译
		make install   安装
		rpm -q  ----->查询是否安装             rpm -ql ------>查询该套件所有的目录
		rpm -qi ----->查询套件的说明资料       rpm -qc[d] ----->设定档与说明档
		rpm -ivh  ---->安装                    rpm -V  -------->查看套件有否更动过
		rpm -e  ------>删除                    rpm -Uvh ------->升级安装  
			rpm -e --nodeps python-2.3.4-14.7.el4 卸载安装包，检查依赖包
		--nodeps ----->强行安装                --test ----->测试安装

		来自：http://blogold.chinaunix.net/u/30619/showart.php?id=249558

		1、alternatives --install /usr/bin/java java /usr/java/jdk1.6.0_24/bin/java 300
		这一句的意思是给java这个LINK多加一个Path。至于什么是Link，请man alternatives，看alternatives命令的帮助，就大概能明白了。
		2、alternatives --config java 会出现一下信息：
		----------------------------------------------------------------------
		*  1           /usr/lib/jvm/jre-1.4.2-gcj/bin/java
		+ 2           /usr/java/jdk1.6.0_24/bin/java
		按 Enter 来保存当前选择[+]，或键入选择号码：2

		shutdown -h now
		halt
	
	############################################################################

		linux下Java环境的配置
		linux下Java环境的配置
			　　现在用linux的朋友越来越多了，前几天就有两个朋友问我linux下怎么配置java环境，我想还有很多朋友想了解学习这方面的东西，就写一个完全一点的linux java环境配置吧，希望对大家有帮助。
		一. 下载jdk5.0 for linux
		　　到sun的主页 http://java.sun.com/j2se/1.5.0/download.jsp 下载jdk安装文件jdk-1_5_0_05-linux-i586.bin
		二. 解压安装jdk
		　　在shell终端下进入jdk-1_5_0_05-linux-i586.bin文件所在目录，执行命令./jdk-1_5_0_05-linux-i586.bin这时会出现一段协议，连继敲回车，当询问是否同意的时候，输入yes，回车。之后会在当前目录下生成一个jdk-1.5.0_05目录，你可以将它复制到任何一个目录下。
		三. 需要配置的环境变量
		　　1.PATH环境变量。作用是指定命令搜索路径，在shell下面执行命令时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。
		　　2.CLASSPATH环境变量。作用是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。
		　　3. JAVA_HOME环境变量。它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。
		四. 三种配置环境变量的方法
		　　1. 修改/etc/profile文件
		　　　　如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
		　　　　·用文本编辑器打开/etc/profile
		　　　　·在profile文件末尾加入：
		　　　　　　JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　PATH=$JAVA_HOME/binPATH
		　　　　　　CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		　　　　　　export JAVA_HOME
		　　　　　　export PATH
		　　　　　　export CLASSPATH
		　　　　·重新登录
		　　　　·注解
		　　　　　　a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
		　　　　　　b. linux下用冒号“:”来分隔路径
		　　　　　　c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值
		　　　　　　　 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种
		　　　　　　　 常见的错误。
		　　　　　　d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
		　　　　　　e. export是把这三个变量导出为全局变量。
		　　　　　　f. 大小写必须严格区分。
		　　2. 修改.bashrc文件
		　　　　
		　　　　这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
		　　　　·用文本编辑器打开用户目录下的.bashrc文件
		　　　　·在.bashrc文件末尾加入：
		　　　　　　
		　　　　　　set JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　export JAVA_HOME
		　　　　　　set PATH=$JAVA_HOME/binPATH
			    　　　export PATH
			    　　　set CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
			    　　　export CLASSPATH
		　　　　·重新登录
		　　3. 直接在shell下设置变量
		　　　　不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
		　　　　只需在shell终端执行下列命令：
		　　　　export JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　export PATH=$JAVA_HOME/binPATH
		　　　　export CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		五. 测试jdk
		　　1. 用文本编辑器新建一个Test.java文件，在其中输入以下代码并保存：
		　　　　public class test {
		　　　　　　public static void main(String args[]) {
		　　　　　　　　System.out.println("A new jdk test !");
		　　　　　　}
		　　　　}
		　　2. 编译：在shell终端执行命令 javac Test.java
		　　3. 运行：在shell终端执行命令 java Test
		　　　　当shell下出现“A new jdk test !”字样则jdk运行正常。
		六. 卸载jdk
		　　·找到jdk安装目录的_uninst子目录
		　　·在shell终端执行命令./uninstall.sh即可卸载jdk。 



		############################################################################


		vi 

		保存退出
		* shift + ： 进入命令行状态
		* 输入wq ，并回车，即保存退出

		:w   保存文件但不退出vi 
		:w file 将修改另外保存到file中，不退出vi 
		:w!  强制保存，不推出vi
		:wq  保存文件并退出vi 
		:wq! 强制保存文件，并退出vi
		q：不保存文件，退出vi
		:q!不保存文件，强制退出vi 
		:e! 放弃所有修改，从上次保存文件开始再编辑



		############################################################################


		命令 结果定向到文件 

		rpm -qa >> /home/show

		查找到安装软件包名 ： java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5

		rpm -ql  java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5 —— 查询该套件所有的目录
		
		查找是否已安装mysql，有则卸载掉
		# rpm -qa | grep -i  mysql			   -i : ignore case
		...
		# rpm -e xxxx

		############################################################################

		安装 bin格式的jdk软件包 
		进到软件包的目录下 ，运行 ./jdk1.6***.bin 即可安装
	--------

* base64 编码
		Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。
	Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符
	（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为
	适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所
	直接看到。

*	vmware7安装centos5 - 自定义方式 -  OS Installlation步骤选择install later(否则后面可能直接进入live CD 模式，不是正常安装模式)	      ，
	新建好VM后，再设置CD/DVD的地方指向ISO镜像，启动后，即可正常选择安装模式，进行安装
		确保ssh模块已安装 ，通过ssh客户端连接vmware中的centos
		vmware 修改磁盘容量 ，分区工具，重新分区
		http://www.cnblogs.com/ZhengGuoQing/archive/2008/04/03/1135803.html

*	虚拟集群,及其相关应用测试【测试】

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day1 2012年3月14日

1. 环境
	..
	eclipse 
		常用插件
			svn 
			mavn 
			spring插件 - 主要编译配置文件定位到java文件,自动提示等便捷功能
			Eclipse Web Tools Platform
			python 插件 pydev http://pydev.org/updates
			uml
			er - http://www.eclipse.org/gef/updates/index.php
			...
		eclipse jre配置设置为jdk
		-vm
		D:\Java\jdk1.6.0_10\bin\javaw.exe —— 这里路径注意下 空格之类处理为 progra~1
		-vmargs
		-Dosgi.requiredJavaVersion=1.5
		-Xms128m
		-Xmx256m	

		ide eclipse 依赖 ，依赖从上到下配置，上面不对会导致下面的类编译报错。

2. svn 
	wiki http://wiki.houyi.alibaba-inc.com/dashboard.action
	申请权限
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/
	和
	http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine

	department
	阿里云-云计算业务发展-基础产品-平台技术

wiki：
	http://wiki.houyi.alibaba-inc.com/dashboard.action

bbs:
	http://bbs.aliyun.com/

feitian SLB ACE（JCE...） (ACE - Ali Cloud Engine云引擎) OSS(kv storage)
	
	ACE php container, nodejs container,jsp container

test evn:
	Latest SLB Build: http://10.1.152.71/release/houyi/slb/trunk/2.0.476963.0/
	Latest Keepalived Build: http://10.1.152.71/release/houyi/slb/system/keepalived/1.1.20-476658.0/
	Latest HAProxy Build: http://10.1.152.71/release/houyi/slb/system/haproxy/1.4.15.1-476658.0/

	Bugfree: http://bugfree.aliyun-inc.com/index.php/bug/list/2

3. Cloud Engine - Cloud Engine是一个基于ACE的web应用托管运行环境，能够提供应用的自动伸缩以及多种核心服务。
	
	Google App Engine
	


4. linux about
	* gdb:
		What is GDB?

		GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another 
		program was doing at the moment it crashed.

		GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act:

		    Start your program, specifying anything that might affect its behavior.
		    Make your program stop on specified conditions.
		    Examine what has happened, when your program has stopped.
		    Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. 

		The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might 
		be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft 
		Windows variants.
		
		DBP实战：
			问题：

			ndb进程cpu达到99%，怀疑存在死循环，需要排查

			1.   ps -eLf | grep nbd-server

			找出那个nbd-server线程占用cpu最高，记住他的ppid（线程id）

			2.   gdb nbd-server <pid>

			启动gdb ， attach到运行的nbd-server进程

			3.  info thread

			查看所有线程

			4. thread 10

			切换到这个线程

			5. bt

			查看线程堆栈

			6. 分析代码

			from:wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=3932212

5. ssh client
	PuTTY
6. 路由  消息订阅

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day2 2012年3月15日

1. 后羿系统
	
	参考资料 Sina App Engine数据存储服务架构
	
2.  svn 账户授权 即 svn 注册用户 
	wb_shen.chengs + pwd

	url
		...houyi/cloudengine
		...houyi/console
			branches-api...-requirement 

3. houyi 异步通知
	
	异步通知是后羿系统提供的一套基于HTTP协议主动向客户系统发送VM操作结果状态的基础服务。其基本流程如下：
	 
	通知系统交互流程说明：
	1. 后羿向外部系统发出通知，即访问外部系统提供的通知接收URL。// 外部系统提供的通知接收URL
	2. 客户系统接到通知请求，根据签名信息验证通知真实性。
	3. 客户系统处理通知。
	摘自：houyi api 说明doc

4. 通过svn checkout 部分houyi项目 熟悉 【配置 svn】
	svn插件拉下项目代码 (svn 项目绑定到对应的svn库上，(对于eclipse，如果绑定错误，先删除原有svn库，从team里重新绑定即可))
	maven插件构建
		部分依赖找不到的情况：(把所在目录下已有的文件删除)通过到依赖库手动下载pom文件和相应jar.swf等文件，放到maven的.m2文件夹中解决。
		nexus http://10.250.6.11:8081/nexus/index.html#welcome 

	maven版本问题，比如编译，打包等用到plugin时，选择合适的版本，配置正确的repo，目前用maven2.2.1
		配置文件配置:
			   <!-- profile
			     | Specifies a set of introductions to the build process, to be activated using one or more of the
			     | mechanisms described above. For inheritance purposes, and to activate profiles via <activatedProfiles/>
			     | or the command line, profiles have to have an ID that is unique.
			     |
			     | An encouraged best practice for profile identification is to use a consistent naming convention
			     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.
			     | This will make it more intuitive to understand what the set of introduced profiles is attempting
			     | to accomplish, particularly when you only have a list of profile id's for debug.
			     |
			     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.
			    -->			
			 <profile>
			      <id>dev</id>

			      <repositories>
				
				<repository>
				  <id>ay32-releases</id>
				  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>

				<repository>
				  <id>nexus-releases</id>
				  <name>nexusre</name>
				  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>
			     
			 </repositories>
				  <pluginRepositories>
				<pluginRepository>
					  <id>ay32-releases</id>
					  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				<pluginRepository>
					  <id>nexus-releases</id>
					  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				  </pluginRepositories>
			    </profile>
	

	通过maven脚本构建测试部署 ？

	ide里编辑，构建工具统一编译测试部署。
	mvn clean install -rf :houyi-console-web-staff 
	参数参考：
		usage: mvn [options] [<goal(s)>] [<phase(s)>]

		Options:
		 -am,--also-make                        If project list is specified, al
							build projects required by the
							list
		 -amd,--also-make-dependents            If project list is specified, al
							build projects that depend on
							projects on the list
		 -B,--batch-mode                        Run in non-interactive (batch)
							mode
		 -C,--strict-checksums                  Fail the build if checksums don'
							match
		 -c,--lax-checksums                     Warn if checksums don't match
		 -cpu,--check-plugin-updates            Ineffective, only kept for
							backward compatibility
		 -D,--define <arg>                      Define a system property
		 -e,--errors                            Produce execution error messages
		 -emp,--encrypt-master-password <arg>   Encrypt master security password
		 -ep,--encrypt-password <arg>           Encrypt server password
		 -f,--file <arg>                        Force the use of an alternate PO
							file.
		 -fae,--fail-at-end                     Only fail the build afterwards;
							allow all non-impacted builds to
							continue
		 -ff,--fail-fast                        Stop at first failure in
							reactorized builds
		 -fn,--fail-never                       NEVER fail the build, regardless
							of project result
		 -gs,--global-settings <arg>            Alternate path for the global
							settings file
		 -h,--help                              Display help information
		 -l,--log-file <arg>                    Log file to where all build outp
							will go.
		 -N,--non-recursive                     Do not recurse into sub-projects
		 -npr,--no-plugin-registry              Ineffective, only kept for
							backward compatibility
		 -npu,--no-plugin-updates               Ineffective, only kept for
							backward compatibility
		 -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates
		 -o,--offline                           Work offline
		 -P,--activate-profiles <arg>           Comma-delimited list of profiles
							to activate
		 -pl,--projects <arg>                   Comma-delimited list of specifie
							reactor projects to build instea
							of all projects. A project can b
							specified by [groupId]:artifactI
							or by its relative path.
		 -q,--quiet                             Quiet output - only show errors
		 -rf,--resume-from <arg>                Resume reactor from specified
							project
		 -s,--settings <arg>                    Alternate path for the user
							settings file
		 -T,--threads <arg>                     Thread count, for instance 2.0C
							where C is core multiplied
		 -t,--toolchains <arg>                  Alternate path for the user
							toolchains file
		 -U,--update-snapshots                  Forces a check for updated
							releases and snapshots on remote
							repositories
		 -up,--update-plugins                   Ineffective, only kept for
							backward compatibility
		 -V,--show-version                      Display version information
							WITHOUT stopping build
		 -v,--version                           Display version information
		 -X,--debug                             Produce execution debug output

		tip:
			parent pom declare most properties ,plugins etc,models under parent,only needs to config special requiments ,if needs to make war package for example and it can references definetions
			from parent pom ,just lile inheritance(eg struts2's configuration file struts.xml).

		maven 插件 ，源码自动下载

5. 熟悉houyi代码，结构
	
	
	
6. xStream javabean 与 xml ，json映射工具
	参考：http://www.cnblogs.com/hoojo/archive/2011/04/22/2025197.html
	部分如下：
		xStream框架

			xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换；

			前面有介绍过json-lib这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/21/2023805.html

			以及Jackson这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/22/2024628.html

			它们都完美支持JSON，但是对xml的支持还不是很好。一定程度上限制了对Java对象的描述，不能让xml完全体现到对Java对象的描述。
			这里将会介绍xStream对JSON、XML的完美支持。xStream不仅对XML的转换非常友好，而且提供annotation注解，可以在JavaBean中完成
			对xml节点、属性的描述。以及对JSON也支持，只需要提供相关的JSONDriver就可以完成转换。 

7. Quartz 调度

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day3 2012年3月16日

1. 项目目录结构 maven
	
	

2. 结合 openapi 接口文档 ，熟悉代码，规范

	以hoyi-console-openapi  为例，熟悉大体框架，配置方式，处理流程
	
	根据应用上下文配置文件(web.xml)，熟悉请求处理流程 （web应用 ,java应用根据程序入口）

		* struts2 ,spring ,ibatis
			spring
				bean管理 - pojo,dao bean ,action
				事务管理
			struts2
				interceptor - default and user defined interceptors / pluggable
				objectfactory = spring
				action继承/接口关系(部分)
					public class RackQueryAction extends PagingInfovalidator implements ExecuteAction {
					-> public abstract class PagingInfovalidator extends AbstractExecuteAction implements ActionValidator{
					-> public abstract class AbstractExecuteAction implements ExecuteAction {

				部分struts源码截取：【struts】
					multi-thread safe
					--------
						package com.opensymphony.xwork2;
						...
						public class ActionContext implements Serializable {
						    static ThreadLocal actionContext = new ThreadLocal();
						...
						    Map<String, Object> context;

						    public ActionContext(Map<String, Object> context) {
							this.context = context;
						    }
						...
						    public static void setContext(ActionContext context) {
							actionContext.set(context);
						    }
						    public static ActionContext getContext() {
							return (ActionContext) actionContext.get();
					--------
					
					--------
					...
					package com.opensymphony.xwork2;
					public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable {
					...
					    public Locale getLocale() {
						ActionContext ctx = ActionContext.getContext();
						if (ctx != null) {
						    return ctx.getLocale();
						} else {
						    LOG.debug("Action context not initialized");
						    return null;
						}
					    }
					...
					--------
					Interface :
						Action - All actions may implement this interface, which exposes the execute() method. 
						Validateable - Provides an interface in which a call for a validation check can be done.
						ValidationAware - ValidationAware classes can accept Action (class level) or field level error messages. Action level messages are kept in a Collection. 
									Field level error messages are kept in a Map from String field name to a List of field error msgs.
						TextProvider - Provides access to ResourceBundles and their underlying text messages.
						LocalProvider - Indicates that the implementing class can provide its own Locale. 
					
					ActionInvocation
							An ActionInvocation represents the execution state of an Action. It holds the Interceptors and the Action instance. By repeated re-entrant execution 
						of the invoke() method, initially by the ActionProxy, then by the Interceptors, the Interceptors are all executed, and then the Action and the Result.
						代理类，维护interceptors集合并依次序传递和执行ActionInvocation的实现类。？




			ibatis openAPI通过spring提供ibatis的template进行dao操作
				部分代码，spring集成ibatis部分
					--------
					package org.springframework.orm.ibatis;
					...
					public class SqlMapClientTemplate extends JdbcAccessor implements SqlMapClientOperations {
						public Object queryForObject(final String statementName, final Object parameterObject)
								throws DataAccessException {

							return execute(new SqlMapClientCallback() {
								public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
									return executor.queryForObject(statementName, parameterObject);
								}
							});
						...
						public Object execute(SqlMapClientCallback action) throws DataAccessException {
							Assert.notNull(action, "Callback object must not be null");
							Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

							// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
							// Connection (potentially transactional) in. This shouldn't be necessary if
							// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
							// we still need it to make iBATIS batch execution work properly: If iBATIS
							// doesn't recognize an existing transaction, it automatically executes the
							// batch for every single statement...

							SqlMapSession session = this.sqlMapClient.openSession();
							if (logger.isDebugEnabled()) {
								logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
							}
							Connection ibatisCon = null;

							try {
								Connection springCon = null;
								DataSource dataSource = getDataSource();
								boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

								// Obtain JDBC Connection to operate on...
								try {
									ibatisCon = session.getCurrentConnection();
									if (ibatisCon == null) {
										springCon = (transactionAware ?
												dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
										session.setUserConnection(springCon);
										if (logger.isDebugEnabled()) {
											logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
										}
									}
									else {
										if (logger.isDebugEnabled()) {
											logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
										}
									}
								}
								catch (SQLException ex) {
									throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
								}

								// Execute given callback...
								try {
									return action.doInSqlMapClient(session);
								}
								catch (SQLException ex) {
									throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
								}
								finally {
									try {
										if (springCon != null) {
											if (transactionAware) {
												springCon.close();
											}
											else {
												DataSourceUtils.doReleaseConnection(springCon, dataSource);
											}
										}
									}
									catch (Throwable ex) {
										logger.debug("Could not close JDBC Connection", ex);
									}
								}

								// Processing finished - potentially session still to be closed.
							}
							finally {
								// Only close SqlMapSession if we know we've actually opened it
								// at the present level.
								if (ibatisCon == null) {
									session.close();
								}
							}
						}	}
					...
					--------
			dbcp - DB connection pool


		* 枚举 enum 
			定义常量(可扩展的)，优于普通常量定义
			 AgreementParameter
			 GlobalErrorMessage
			...
				eg:
				return CloudEngineEvent.NGINX.getEvent();

				public enum CloudEngineEvent {
					REGISTER(10001),
					NGINX(30001),
					FASTCGI(30002),
					SLB(30003),
					MEMCACHED(30004),
					RDS(30005),
					NODEJS(30006)
					;
					
					private CloudEngineEvent(Integer event) {
						this.event = event;
					}
					
					private Integer event;
					public Integer getEvent() {
						return event;
					}
				}

		* 

	openAPI mode 要引用到得其他各层分别在不同的model中: (openapi为houyi项目其中一个model)
		<modules>
		  <module>houyi.console.model</module> 域模型(历史原因有部分分散在其他model中)
		  <module>houyi.console.util</module> 工具
		  <module>houyi.console.acl</module> 访问控制
		  <module>houyi.console.dao</module> DAO
		  <module>houyi.console.clc</module> 对内master交互模块(操作vm等)
		  <module>houyi.console.service</module> 逻辑层
		  <module>houyi.console.message</module> 消息
		  <module>houyi.console.statistics</module>  
		  <module>houyi.console.web/houyi.console.web.support</module>  web这块原先以portal调
		  <module>houyi.console.web/houyi.console.web.staff</module>
		  <module>houyi.console.web/houyi.console.web.admin</module>
		  <module>houyi.console.web/houyi.console.web.isv</module>
		  <module>houyi.console.openapi</module> 对外openapi模块
		</modules>		
	
	openAPI 放开的请求action配置：- 统一出入口 ？
		<package name="instance" extends="houyi-open" namespace="/">
			<action name="services" class="openAPIProxyAction" method="proxy"><!-- action交给spring管理，此action为：open api 的访问代理 -->
			   <result type="userActionResult"></result> <!-- 自定义result -->
			</action>
		</package>
		代理action利用req请求消息，通过工厂方式(目标action都实现相同接口)调用对应的目标acton，目标action通过spring context获得：
			// Return the bean instances that match the given object type (including subclasses), judging from either bean definitions or the value of getObjectType in the case of FactoryBeans. 
			Map map = context.getBeansOfType(ExecuteAction.class);


3. xen 快照 了解  虚拟机快照 【快照】
	虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
	chain 模式 比如 struts的intercepter ，插拔式
	
	http://server.it168.com/a2009/0723/611/000000611079.shtml
4. StringEscapeUtils 
	Escapes and unescapes Strings for Java, Java Script, HTML, XML, and SQL
	commons-lang包

5. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day4 2012年3月19日

1. RESTful REST 请求

http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v2/master/src/main/java/com/aliyun/cloudengine/
JCE的master以REST架构，处理openAPI(为get/post请求规范)请求需要提供一个适配层(将REST请求转换为http方式的get/post请求) ？ - Java Cloud Engine

jce的rest实现基于

rest http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/
	介绍jdk1.6提供的rest接口，master的rest基于jdk的rest接口 javax.ws.rs

基于 REST 的 Web 服务遵循一些基本的设计原则：
    系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的 URI。
    以遵循 RFC-2616 所定义的协议的方式显式地使用 HTTP 方法，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与 HTTP 方法之间的一对一映射：
        若要在服务器上创建资源，应该使用 POST 方法；
        若要检索某个资源，应该使用 GET 方法；
        若要更改资源状态或对其进行更新，应该使用 PUT 方法；
        若要删除某个资源，应该使用 DELETE 方法。
    URI 所访问的每个资源都可以使用不同的形式加以表示（比如 XML 或者 JSON），具体的表现形式取决于访问资源的客户端，客户端与服务提供者使用一种内容协商的机制（请求头与 MIME 类型）来选择合适的数据格式，最小化彼此之间的数据耦合。

【Task】
	以 /houyi-cloudengine-master/src/main/java/com/aliyun/cloudengine/RestAdminApplication.java 为例，熟悉rest方式，并分析rest方式与openapi标准的get/post方式如何转换 ？
	houyi-cloudengine-master 提供几个rest接口供外界调用。
	由于rest方式的请求url不同于普通http请求的url，需要提供一个模块处理标准http请求的处理(接受请求-调用接口-返回结果)
		rest方式URI: persion/123		http方式: persion?id=123
	
	cloudengine 运行是基于xuanyuan的一个组件，xuanyuan负责请求分配。
	
	参考实现的文档，搭建测试环境测试，判断是否支持预想的解决方案。 - tip -

2.  test 测试
JTester
	   http://java-tester.googlecode.com/svn/maven2/

	   http://www.blogjava.net/kiral/archive/2011/02/04/344072.html usage
	

3. 搭建 restful 环境，测试
	jersey + tomcat 的restful测试环境搭建：
		wiki https://wikis.oracle.com/display/Jersey/Main
		参考 http://www.ibm.com/developerworks/cn/web/wa-aj-tomcat/

	@POST 
	@Path("/test")
	@Produces(MediaType.APPLICATION_JSON)
	public String showTime(@FormParam("username") String userName,@Context HttpServletRequest httpRequest) {
	:
	:
	:
	}
	// jersey - 通过context注解获得httprequest对象
	
	对于openAPI调用(待测试)：
		可以给定URI请求，匹配到一个service上，然后取得request对象，做后续处理。
		(要做的步骤：
			配置一个service匹配opanapi的所有请求

		)

Using Entity Providers toMapHTTP Response and
Request Entity Bodies
Entity providers supply mapping services between representations and their associated Java
types. There are two types of entity providers: MessageBodyReader and MessageBodyWriter.
For HTTP requests, the MessageBodyReader is used to map an HTTP request entity body to
method parameters. On the response side, a return value is mapped to an HTTP response entity
body using a MessageBodyWriter. If the application needs to supply additional metadata, such
Responding to HTTP Resources
Chapter 3 • Creating a RESTful Resource Class 19
as HTTP headers or a different status code, a method can return a Response that wraps the
entity, and which can be built using Response.ResponseBuilder.

——jersey文档

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day5 Tuesday, March 20, 2012

1. day4第3条 go on
	* 下载jersey包
	* 新建web项目，导入jersey必要包
	* 配置jersey的请求处理servlet，并正确配置package属性：com.sun.jersey.config.property.packages - 指向你的resource包
	* 部署到tomcat中
	* 测试

	部分代码：
	-----
		<servlet>
			<servlet-name>Jersey REST Service</servlet-name>
			<servlet-class>
			  com.sun.jersey.spi.container.servlet.ServletContainer
			</servlet-class>
			<init-param>
			  <param-name>com.sun.jersey.config.property.packages</param-name>
			  <param-value>test.jersey.service</param-value>
			</init-param>
			<load-on-startup>1</load-on-startup>
		</servlet>
		<servlet-mapping>
		  <servlet-name>Jersey REST Service</servlet-name>
		  <url-pattern>/rest/*</url-pattern>
		</servlet-mapping>

		package test.jersey.service;
		@Path("hello")
		public class HelloResponse {

			@GET
			@Produces(MediaType.TEXT_PLAIN)
			public String sayHello(){
				return "Hello jersey";
			}
	
		}
	------
	[ Test ]
		req: http://localhost:8080/jersey/rest/hello
		resp: Hello jersey

	[ Test ]
		@GET
		@Produces(MediaType.TEXT_PLAIN)
		public String sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
			return "id:"+id+" name:"+name;
		}	
		request: http://localhost:8080/jersey/rest/hello?id=1&name=jack   - 
		response: id:1 name:jack

	[ Test ]
		@Path("/hello")
		public class HelloResponse {

			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			public MyResponse sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
		//		return "NORMAL id:"+id+" name:"+name+"\n";
				return new MyResponse(id,name);
			}
			
			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			@Path("/sayhello/{id}/{name}")
			public Object sayHelloRest(@DefaultValue("1") @PathParam("id") String id,@DefaultValue("1NaN") @PathParam("name") String name){
				return new MyResponse("1","jack");
			}
		}
		web.xml: 
			<servlet-mapping>
				  <servlet-name>Jersey REST Service</servlet-name>
				  <url-pattern>/open/*</url-pattern>
			</servlet-mapping>
		request: http://localhost:8080/jersey/open/hello/sayhello/1/1
		response: 
				<data>
					<id>1</id><
					name>jack</name>
				</data>

	要返回json或xml，需要将返回的对象配置上对象到xml的映射注解，比如利用jaxb等 ，需要提供一个对象到json或者xml的映射机制，如果直接返回
	jdk的list对象会报错，无法转换：
		A message body writer for Java class java.util.ArrayList, and Java type interface java.util.List, and MIME media type application/xml was not found
		eg:http://blog.coderunnr.com/2011/02/clienthandlerexception-a-message-body-writer-for-java-type-class-and-mime-media-type-applicationoctet-stream-was-not-found/
	将返回的pojo通过注解映射到xml即可：
		@XmlRootElement(name="data")
		public class MyResponse {
			
			private String id;
			
			private String name;
			
			public MyResponse(){}
			
			public MyResponse(String id,String name){
				this.id = id;
				this.name = name;
			}
			
			@XmlElement(name="id")
			public String getId() {
				return id;
			}
			public void setId(String id) {
				this.id = id;
			}
			
			@XmlElement(name="name")
			public String getName() {
				return name;
			}
			public void setName(String name) {
				this.name = name;
			}
		}
		

		问题：
			// 这个标签标示注解的方法支持下面定义的 2 种返回数据格式，具体确定？
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			
			如上，可以返回多个MIME，如何选择，确定返回的类型？
				比如，需要返回xml，或者需要返回json 
				看openAPI是根据什么返回指定格式的数据的？
					openAPI通过请求参数 format 来判断client请求的数据格式，故这里需要用到 @queryparam 来取得 format ，从而返回对应的
				格式。
			jersey guide：
					If a resource class is capable of producing more that one MIME media type then the resource method chosen will correspond to the most acceptable media type 
				as declared by the client. More specifically the Accept header of the HTTP request declared what is most acceptable. For example if the Accept header is:
					Accept: text/plain
				then the doGetAsPlainText method will be invoked. Alternatively if the Accept header is:
					Accept: text/plain;q=0.9, text/html
				which declares that the client can accept media types of "text/plain" and "text/html" but prefers the latter, then the doGetAsHtml method will be invoked.
				More than one media type may be declared in the same @Produces declaration, for example:
			方案1：从jersey guide看，可以根据http请求头的 accept定义值返回相应格式。
				但openapi规范提供的是根据get方式的 format参数来确定返回格式的
			方案2:：根据 format 字段，找到rest框架提供的动态自定义返回格式的设置 ？ 在哪里设置？
				在response里设置header，rest框架根据header定义的格式渲染结果。
				通过response根据需要的返回状态(status)取得responsebuilder对象(处理返回内容)，取得请求参数，通过builder设置返回的Cotent-Type类型(MediaType定义的类型)
				builder的entry方法处理需要返回的对象，build()，返回即可。

			【tip】误区，试图设置request的accept值来影响response的返回数据格式，要返回什么样的数据及其格式都可以通过response来设置。
				拥有者或者自身或其相关工具一般会提供操作其自身的值的入口。

				

2. jax-rs 注解(from jax-rs api)
	Consumer - Defines the media types that the methods of a resource class or MessageBodyReader can accept 定义资源可以接受处理的请求类型
	Produces - Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce
	MediaType - An abstraction for a media type. Instances are immutable(不变的). 


3. 对于第1条的REST框架也支持非REST请求uri的转发，这其中，只是转发的作用，不带有业务逻辑，是否可以用nginx的rewrite来实现？
	后续SLB也需要对openapi提供处理层，其中含业务逻辑，选择REST方式。

4. nginx rewrite 重写
	目标：将openapi的标准请求重写为符合REST接口的rest请求。
	nginx的rewrite规则(rewrite模块)：
	http://xx.host/action?id=xx&name=xx rewrite为 http://xx.host/action/xx/xx

	
	URL rewriting is a key element to Search Engine Optimization (SEO). ——　摘自：Nginx HTTP Server p141

		参考 http://chenxiaoyu.org/2011/10/30/nginx-modules.html
	正则表达式 规则 regex
	regular expression(Perl Compatible Regular Expression (PCRE) library):
		Metacharacter
			Description
		^
		Beginning
			The entity after this character must be found at the beginning.
			Example pattern: ^h
			Matching strings: hello, h, hh
			Non-matching strings: character, ssh
		$
		End
			The entity before this character must be found at the end.
			Example pattern: e$
			Matching strings: sample, e, file
			Non-matching strings: extra, shell
		.
		Any
			Matches any character.
			Example pattern: hell.
			Matching strings: hello, hellx, hell5, hell!
			Non-matching strings: hell, helo
		[ ]
		Set
			Matches any character within the specified set.
			Syntax: [a-z] for a range, [abcd] for a set, and [a-z0-9] for
			two ranges
			Example pattern: hell[a-y123]
			Matching strings: hello, hell1, hell2, hell3
			Non-matching strings: hellz, hell4, heloo
		[^ ]
		Negate set
			Matches any character that is not within the specified set.
			Example pattern: hell[^a-np-z0-9]
			Matching strings: hello, hell;
			Non-matching strings: hella, hell5
		|
		Alternation
			Matches the entity placed either before or after the |.
			Example pattern: hello|welcome
			Matching strings: hello, welcome, helloes, awelcome
			Non-matching strings: hell, ellow, owelcom
		( )
		Grouping
			Groups a set of entities, often to be used in conjunction with |.
			Example pattern: ^(hello|hi) there$
			Matching strings: hello there, hi there.
			Non-matching strings: hey there, ahoy there
		\
		Escape
			Allows you to escape special characters.
			Example pattern: Hello\.
			Matching strings: Hello., Hello. How are you?, Hi! Hello...
			Non-matching strings: Hello, Hello, how are you?

		Quantifiers
		So far, you are able to express simple patterns with a limited number of characters. Quantifiers allow you to extend the amount of accepted entities:
		Quantifier
			Description
		*
		0 or more times
			The entity preceding * must be found 0 or more times.
			Example pattern: he*llo
			Matching strings: hllo, hello, heeeello
			Non-matching strings: hallo, ello
		+
		1 or more times
			The entity preceding + must be found 1 or more times.
			Example pattern: he+llo
			Matching strings: hello, heeeello
			Non-matching strings: hllo, helo
		?
		0 or 1 time
			The entity preceding ? must be found 0 or 1 time.
			Example pattern: he?llo
			Matching strings: hello, hllo
			Non-matching strings: heello, heeeello
		{x}
		x times
			The entity preceding {x} must be found x times.
			Example pattern: he{3}llo
			Matching strings: heeello, oh heeello there!
			Non-matching strings: hello, heello, heeeello
		{x,}
		At least x times
			The entity preceding {x,} must be found at least x times.
			Example pattern: he{3}llo
			Matching strings: heeello, heeeeeeello
			Non-matching strings: hllo, hello, heello
		{x,y}
		x to y times
			The entity preceding {x,y} must be found between x and y times.
			Example pattern: he{2,4}llo
			Matching strings: heello, heeello, heeeello
			Non-matching strings: hello, heeeeello
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day6 Wednesday, March 21, 2012

1. openapi 
	OpenAPI - 消息推送/订阅(Message push/subscrible)  -Master 
	
	根据登记在消息服务器上的订阅节点信息，进行push

2. python nodejs 
	python yaml模块 - YAML是一种直观的能够被电脑识别的的数据序列化格式，容易被人类阅读，并且容易和脚本语言交互。YAML类似于XML，但是语法比XML简单得多，
	对于转化成数组或可以hash的数据时是很简单有效的。

3.  wget 从vmware中的centso访问本机的rest服务
	取得返回内容，cat查看
	sshl连接到centos命令行操作。
	
	环境：
		apache ,
		tomcat,
		nginx,
		mysql,
		eclipse,
		python,(test)
		nodejs,(test)
		linux container(test)

4. CIDR Classless Inter-Domain Routing 了解
	无类别域间路由选择
	ref:
		CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给
	服务提供商（ISP），	再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，
	从而减轻Internet路由器的负担。		

	CIDR	Classless Inter-Domain Routing	无类别域间路由选择	是互联网中一种新的址方式，与传统的 A 类、B 类和 C 类寻址模式相比，CIDR 在 IP 地址分配方面更为高效。
	IP号段是125.203.96.0 - 125.203.127.255， 怎样转换成CIDR格式呢？化cidr格式其实就是找相同:
	125.203.0110 0000.0000 0000
	125.203.0111 1111.1111 1111
	前十九位相同,所以可以写成125.203.96.0/19

5. ce里shell脚本熟悉
	"#!/bin/sh" - 对shell的声明，说明你所用的是那种类型的shell及其路径所在。
	自定义shell function封装常用功能，提高shell编写效率。
		eg: 


6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day7 Thursday, March 22, 2012

1. ace mast agent(python shell) 
	master 职责


2.  ace 计量单位讨论会议，
	字段需要取出推送到消息系统，供后续计量，计费
	主要关于 计量字段需求，及可行性确认
	详见记录
	tip: 由于涉及多个系统的交互，如何处理规则，处理变化的问题，如果适应变化减少依赖耦合。

3. cloudengine 熟悉
	master ,agent 部分
	master调用agent
	agent根据不同的应用类型(目前:php，nodejs，jsp)调用相应的build脚本(配置环境运行环境，部署应用，启动应用，启动agent)

	nodejs http://nodejs.org/
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day8 Friday, March 23, 2012

1. cloudengine 
	trunk
		agent - agent模块(python)
			fastcgi
			memcached
			monitor
			nginx
			nodejs
			test
			yaml
		carrier - Erlang (rebar ...)
		ftpserver - ftp服务(java)
		master - master(java)
		memcahched_pach - memchche部署
		nginx_pach - nginx部署
		nodejs -  nodejs部署(build_agent -> install_agent -> install_nodejs -> upgrade_nodejs)
		php - php部署

2. ACE计量 
	计量单位，字段说明
	oss接口
	ms接口

	目标：将ACE各计量单位取到并以ms要求的格式推送给ms(Metering Service)计量系统系统 ，有一个python的
	的实现可以参考:
		python 
			程序基本结构
			变量，运算 etc
			模块
				MySQLdb
					eg 通过此模块与mysql数据库交互：(下载这个库有linux和win版本)
						conn=MySQLdb.connect(host="localhost",user="root",passwd="sa",db="mytable")
	
			执行
			应用
	* 

	参考 houyi-console/static (java)实现，上述任务 【Task】
	= = URL请求的要求(格式，构造)等可以参考这个实现 = =
		定义数据格式
		定义任务
		spring配置调用执行

		步骤：(公用动作比如推送等已有实现，调用其逻辑处理即可) 细化
			>> 取
				* MS取SLB流量(appid对应的流量，appid指每个具体的应用)	单位 byte
					- 从ACE DB中取得appid对应的slb_id，及应用的id与SLB的id对应关系 1对1
						- 从DB得到app_id对应的slb_id(cloudengine库)

							-- 从DB得到app_id对应的slb_id
							select 
								app.id app_id,
								slb.id slb_id
							from app app,slb_alloc_record slb
							where app.id = slb.id
							
					- 请求Meteriing Service，根据slb_id取数据
						MS接口文档(比如如何查询SLB数据？)
						

					-  MS返回vip对应的流量数据的数据格式
						Flow_detail的格式如下：
						[tcp(VIP:80|2|3|)(VIP:8080|2|3|)][http(www.a.com:80|2|3|)(www.b.com:90|2|3|)]
					
					- 

				* MS取OSS
					- 从app表(cloudengine)取得kv_bucket
						select 
							id app_id,
							kv_bucket
						from app
					- URL格式
						columns: storage;
						where: openid=ace;pid=oss;bid=26842;inst_id=$bucketname;begin_time=13123121400;end_time =132123241500;inst_id,migrate-win2003-vifs
						http://10.1.157.163:8080/aliyun/QS/OSS/RAW
						bid - 用户ID，app所属的用户
						$bucketname对应kv_bucket
					- 
						
				* DB取cpu时间等
					‘cloudengine`.`fastcgi_app_running_info` cpu_acc_usage App的cpu持续使用时间，单位：秒

			>> 处理

			>> 推送 写往MS
				推送数据格式
					* 在 DataFormat里定义枚举 
					*  pojo (实现接口)
					* 请求
						http request header:
						PUT /aliyun.com/QS/SLB/RAW HTTP/1.1（待定，需姜一提供）
						HOST: ms.aliyun.com
						CONTENT‐LENGTH: 12345
						META: uid,string;inst_id,string; time, integer; usetime,integer; total_in,integer;total_out,integer;tcp_flow_in,integer;tcp_flow_out,integer;http_flow_in,integer;http_flow_out,integer;vip_type,string;rs,integer;flow_detail,string;region_id,string;end_time,integer;
						“META为用户发送的数据的格式信息，这部分必须添加在http的header部分，为计量服务(MS)特有字段”
						http://metering.aliyun-inc.com:8080/aliyun/QS/OSS/RAW  —— 线上系统的地址
						http://10.1.157.163:8080/aliyun/QS/SLB/RAW —— 测试时用测试系统地址
					* 整理推送的字段对照 doc ？
						Cpu(ms)、流量(byte)、存储空间(byte)、请求次数、memory-cache(byte)

						属性名			类型			单位			描述
						uid				string							包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务
						time				integer							开始时间(记录当前记录的时刻，为一点态时间，如果用户的计量数据采集并非实时，则time表示抽样开始时间即begin_time，采用可显示的unix时间表示法)
						end_time			integer							结束时间(表示抽样结束时间，同样采用可显示的unix时间表示法)
						inst_id			string							应用id即appid
						cpu				integer			ms				cpu使用时间
						flow				integer			byte				总流量(http流量)
						flow_in			integer			byte				流入流量
						flow_out			integer			byte				流出流量
						app_size			integer			byte				存储空间(oss)
						req_count			integer			个				请求次数(包括pv内的多个异步请求)
						version			integer							版本号，目前为1



						






		uid：包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day9 Monday, March 26, 2012

1. 计量的接口说明 最新的 ？
	

2. 把ace计量初步需求写入文档，
	类似于slb接口文档等
	
	目的：设计ace计量项，并取到后处理然后提交到ms系统
	计量项列表：
	实现：
		计量项获取：
		处理
		推送
	xuanyuan cloudengine数据库表间关系由程序控制，注释说明关系。

3. job的具体实现，失败补偿逻辑，参看console中的static模块
	？


4. 通过powerdesigner的reverse engine ，从database的sql文件将ddl转换为er图，了解db表关系

5. velocity 方便对象格式化到文件
	...
	velocityEngine.init();//spring配置好resourceLoaderPath
	template = velocityEngine.getTemplate(templateFile);
	VelocityContext context = new VelocityContext();
	context.put("datasMap", map);
	writer = new FileWriter(outfile);
	template.merge(context, writer);
	...
6. spring + quartz 执行定时任务
	<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
		<property name="targetObject" ref="task" />
		<property name="targetMethod" value="execute" />
		<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
	</bean>	
	<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
		<property name="jobDetail" ref="collectDataDetail" />
		<property name="cronExpression" value="0 0 */1 * * ?" />
	</bean>  
	<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="triggers">
			<list>
				<ref bean="collectDataTrigger" />
			</list>
		</property>
	</bean>
7. 操作记录及时保存为数据库的日志，后续补偿机制根据数据库补偿并更新 ？
	细节

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day10 Tuesday, March 27, 2012

1. 根据上面ace计量文档，编码
	对于时间如何处理，补偿机制

2. ACE计量先不提供需要访问MS的SLB和OSS数据，暂先考虑DB数据 【task】
	先实现ace监控数据的抽取推送。
		一些dao需要自己定义以取监控数据
		时间校准，以抽取逻辑定义的时间为准，根据定义的时间去取监控数据并汇总，处理，推送
	处理的整体流程：
		关键是发生错误的补偿处理逻辑：
		tasklog表记录task日志。		

3. 表说明
	region - 代表一个集群
测试环境 mysql
mysql -h10.249.153.1 -ucloudengine -pcloudengine2011 -Dcloudengine



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day11 Wednesday, March 28, 2012

1. 设计好补偿处理逻辑
	结合day10第二条的表记录job及其result实现补偿处理。

2. 任务处理已有设计，在已有的任务设计下实现功能
	* job代表每一次执行的任务
		job推送前都记录到数据库，job下的内容保存为临时文件。
	* spring+squza定时任务
	* 日期处理
		DateUtils.java —— 将date日期格式化为需要的格式；date到秒；string+patten到date  (SimpleDateFormat实现)
	* pojo
		TaskLog 任务日志pojo
			private Long id;
			private int status; // 1:success,0:failed
			private String filename;
			private Long taskTime;
			private int jobType; //[0:vm job,1:device job; default 0]
			private Date beginTime;
			private Date endTime;
			OR文件：/houyi-console-dao/src/main/resources/ibatis/TaskLog.xm
				houyi库 statistics_log
	* service
		JobService ：job相关操作
			public boolean addOrModify(TaskLog job);
			public boolean checkStatus(TaskLog job);
			public List<TaskLog> listFailedJobs(long startTime);
			public List<TaskLog> listJobs(long startTime,long endTime);
			public TaskLog getLastJob();
	* dao
		TaskLogDao ：任务日志DAO操作
			void insertTaskLog(TaskLog log) ;
			void updateTaskLog(TaskLog log) ;
			TaskLog getTaskLog(TaskLog log) ;
			TaskLog getLastTaskLog();
			List<TaskLog> getFailedTaskLogs(Long bTime);
			List<TaskLog> getTaskLogs(Long bTaskTime,Long eTaskTime);

	* task 由于时间等内容不好共用，可再设计一个task，并通过spring配置执行。
		或对task进行业务无关的再抽象，只留下共用的逻辑，其他都内聚到job自身中。-tip-

	处理流程：(包括 Task ，JobProducer，需要的service,dao,pojo) - 由程序入口分析
		--> task - execute()定时执行这个方法 - 调用dojob()  —— dojob是单线程的，如果job多或者某个前面的job占用时间长会影响后面的job的执行开始时间 ？ tip 如果是独立的task则不用考虑影响问题
			遍历执行注入的jobproducer实现 (获取方式：beans = (Map<String, JobProducer>) applicationContext.getBeansOfType(JobProducer.class))
		--> jobproducer(具体job逻辑在jobproducer的实现类里编写)\
		--> service
		--> dao
		逻辑就在task，jobproducer,abstract jobproducer中，定义自己的逻辑即可。
			原有任务以task作为主流程控制，jobproducer抽象类及其实现定义了所有逻辑。抽象类提供公用逻辑或抽象方法统一逻辑。-tip-
				取数据 - 存入数据库/文件(通过velocity映射对象集合(以appid为标识)存为文本) - push - 更新状态
3. 模拟实现
	根据原有static模块任务设计
		* 定义数据结构 pojo ,velocity模板(用于对象格式化持久化)
			是否需要将此pojo作为对象查询？即某个查询直接返回此pojo，需要ibatis映射配置，这样只要查询一次关联几张表得到数据；或者分别查询在程序中处理。
			暂定位分别查询。分别查询，减少关联
		* 实现一个job producer
		* 定时task类，可能需要再实现一个并在spring里配置(原task再抽象以下，可配置)，
		参考配置：
			<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
				<property name="targetObject" ref="task" />
				<property name="targetMethod" value="execute" />
				<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
			</bean>	
			<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
				<property name="jobDetail" ref="collectDataDetail" />
				<property name="cronExpression" value="0 0 */1 * * ?" />
			</bean>  
			<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
				<property name="triggers">
					<list> <!-- 此处配置定时要执行的task列表 -->
						<ref bean="collectDataTrigger" /> 
					</list>
				</property>
			</bean>
		* 判断tasklog是否已执行过，通过jobtype类型和jobtime-job开始时间，如果是依据查询的最新执行时间作为job开始时间
			if (jobService.checkStatus(job))
			{
				logger.info("exist job:" + jobTime);
				return true;
			}
		* abstract producer的一些公用成员变量是否可以提供get方法供子类调用，子类不用重复定义 ？
		* task的recoverJob逻辑处理丢失的任务（比如关机等造成的任务丢失），目前任务是能处理丢失10次的任务，是否可以根据做新一次的任务的开始时间
		结合当前时间计算共丢失多少次任务，然后执行所有丢失的任务？
			Task
			------
			...
				/** Get the last record of success in the log table **/
				TaskLog log = jobService.getLastJob();

				/** compensate for missing the task **/
				if (log != null)
				{
					int i = 1;
					while (log.getTaskTime() + i * HOUR_SEC < jobTime)
					{
						/** Compensate for 10 times **/
						if (i == 10)
						{
							break;
						}

						TaskLog job = new TaskLog();
						job.setBeginTime(new Date());
						job.setTaskTime(log.getTaskTime() + i * HOUR_SEC);
						job.setStatus(0);
						jobService.addOrModify(job);
						i++;
					}
				}
			...
			------
		* 一些任务参数是否可以配置到配置文件中，类似abstract job producer的parentpath路径配置 比如：采集间隔，一些补偿机制参数 ？
		* statistics_log表？
		* app的类别区分是哪个字段(php,nodejs,jsp) ?
			templetid?
		* 用到的一些接口需要修改 ，通过的方式过少，是否可修改，其他地方是否有调用？
			比如提供id数组查询。
		* 应用运行时状态表
			fastcgi_app_running_info
			nginx_app_running_info
			memcache_app_running_info
			nodejs_app_running_info
		* console与cloudengine不是同一项目，maven管理依赖，引入cloudengine的包？
			自己重新写maping文件pojo及dao接口和实现。不依赖不相关系统。
			在dao，model等模块加入对应代码。
		* ibatis查询，可以根据外键设置关联查询，减少查询次数
		* 由于是另外一个数据库，需要再配置数据源
		* 在houyi-console-dao里写dao层用到pojo是static中的，是否把pojo，dao，service都按照模块放置，负责dao就要依赖到static中的pojo ？
			static的model不直接提供dao，而是从其他数据组合而成。比如从appdao的查询记录里组合而成。
		* 统计一个时间段的缓存使用量，如何取？暂定为求和
		* 参考master的constant 包定义的常量，帮助了解一些业务知识
			AppType 定义了应用的类型。php.nodejs...
			app 的 language 属性定义apptype类型。
		* 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day12 Thursday, March 29, 2012

1. go on 
	新建maven project开发，独立功能
	参考console的static模块，做成一个任务模块(业务，逻辑分离，易配置)
	wiki地址：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8259199
	svn ：http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk
	web项目 or java进程(jar包main函数启动) or 作为一个组件部署（作为组件部署，有哪些要求，比如 cloudengine 在 xuanyuan 上运行）？
	
	* 导入需要的包
	* 拷贝公用代码 工具类 等
	* dao设计依据master，提供抽象dao实现namespace的spring配置
	* 参考master用jtester测试
		加入jtester依赖包 地址http://java-tester.googlecode.com
		jtester 配置文件中 unitils.modules=database,dbunit,dbfit,inject,spring,tracer ，这里列出了需要的模块
		编译测试，提示编译版本问题时，可以切换下jdk版本，并clean下project。
		测试用例数据，参考master的：eg
			@DbFit(when = {"AgentCheckResultDaoTest.testReadByAgentId.when.wiki"})
		集成spring测试时，可能由于spring配置等问题导致maven test失败；可通过基本的main函数先保证spring的注入式正确的 -tip-
		maven test + main method test
		maven clean + eclipse project clean solve cmplile problems 
	
		如何自动生成测试用例 ？ ，对每个方法都手工去编写基础测试代码过于繁琐
		
		wiki方式数据库测试时，jtester测试时可以根据wiki配置临时清除表数据，做测试，结束后回滚。

	*  wiki project描述

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day13 Friday, March 30, 2012

1. ameasure-data project
	job基础代码与业务代码分离，实现可配置。
	* 配置maven插件,jar (以及插件的参数配置，jar执行main函数配置 etc - 参考maven jar插件说明：http://maven.apache.org/shared/maven-archiver/index.html)
	* 测试报 Could not find Velocity resource: class path resource [VM_global_library.vm
	* 配置maven插件 maven-assembly-plugin ,packaged with-dependencies 打包并加上依赖 ,配置assembly参数，比如jar分别打包，
		打包时可能jar包文件重复，test目录下的测试文件也打包进来，配置一些参数即可，例如：
			-----
			...
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.Test</mainClass>
							</manifest>
						</archive>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				(2)
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<descriptors>
							<descriptor>src/main/assembly/src.xml</descriptor>
						</descriptors>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.StartTask</mainClass>
							</manifest>
						</archive>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0" 
				  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				  xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd">
				  <!-- TODO: a jarjar format would be better -->
				  <id>with-dependencies</id>
				  <formats>
				    <format>zip</format>
				  </formats>
				  <includeBaseDirectory>false</includeBaseDirectory>
				  
				  <dependencySets>
				    <dependencySet>
				      <outputDirectory>/</outputDirectory>
				      <useProjectArtifact>true</useProjectArtifact>
				      <unpack>false</unpack>
				      <scope>runtime</scope>
				    </dependencySet>
				  </dependencySets>
				</assembly>
			...
			-----
			打成上面这种jar包集合方式，在同一文件夹下运行即可，省去classpath配置的麻烦。

		maven clean after close resource opened -tip-
	* 加上shell执行脚本，调用此jar并执行
	* 原有推送逻辑，一次job比如推50条，一条失败就退出，暂处理为本次任务再尝试推送(设定尝试次数)
	*  ibatis 在命令行下运行找不到mapping文件，在eclipse下测试ok 原因？ 待  —— ibatis没问题，spring也ok，字体用的不好(大小写居然相似，
		最后还是仔细看了错误输出，错误点才发现大小写)大小写错误，配置文件配置和实际文件大小写不一致！！！-tip-
		如何避免：提示文件找不到，名称不匹配等等，首要看是否书写错误，能拷贝一定拷贝，不要手工输入，特变是在配置文件场合。 -tip-




2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day14 Saturday, March 31, 2012

1. measure-data
	* 逻辑细化 command
	* quartz ? cluster
		利用quartz实现调度执行，将操作记入日志，失败处理另外实现并
	* 任务测试
		测试表 tasklog `statistics_log`
			CREATE TABLE  `cloudengine`.`statistics_log` (
			  `id` int unsigned NOT NULL AUTO_INCREMENT  COMMENT '@desc 主键ID' ,
			  `status` tinyint NOT NULL COMMENT '@desc 1', 
			  `filename` varchar(128)  COMMENT '@desc filename',
			  `task_time` datetime NOT NULL  COMMENT '@desc tasktime',
			  `begin_time` datetime NOT NULL  COMMENT '@desc begin_time',
			  `end_time` datetime NOT NULL  COMMENT '@desc end_time',
			  `job_type` tinyint NOT NULL COMMENT '@desc 1', 
			  PRIMARY KEY (`id`)
			) ENGINE=InnoDB DEFAULT CHARSET=utf8;
			ALTER TABLE `statistics_log` MODIFY COLUMN `task_time` bigint(20) NOT NULL GO
			测试数据：
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(1,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',3);
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(2,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',1);
	* 提供开启程序，退出程序脚本 ，通过命令操作即可 。可参考tomcatd的脚本
		手工停止任务执行。（或强制停止并处理强制停止任务的恢复逻辑），假如某次job有200条记录在推送了150条时，程序关闭了
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day15 Thursday, April 05, 2012

1. 逻辑实现
计量会议
linux环境：
	10.250.8.214 chengs 123456
shell 下java程序控制：
	  -----
	  ...
		#! /bin/sh

		#启动方法
		start(){

			java -Xms128m -Xmx2048m -jar test1.jar 5 > log.log &
			java -Xms128m -Xmx2048m -jar test2.jar 5 > log.log &
			tail -f result.log
		}
		#停止方法
		stop(){
			ps -ef|grep test|awk '{print $2}'|while read pid
			do
			   kill -9 $pid
			done
		}

		case "$1" in
		start)
		  start
		  ;;
		stop)
		  stop
		  ;;
		restart)
		  stop
		  start
		  ;;
		*)
		  printf 'Usage: %s {start|stop|restart}\n' "$prog"
		  exit 1
		  ;;
		esac

		...
		CLASS_PATH=dayemail.jar
		CLASS_PATH=$CLASS_PATH:lib/activation.jar
		CLASS_PATH=$CLASS_PATH:lib/classes12.jar
		CLASS_PATH=$CLASS_PATH:lib/c3p0-0.9.1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/commons-email-1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/dom4j-1.6.jar
		CLASS_PATH=$CLASS_PATH:lib/jaxen-1.1.1.jar
		CLASS_PATH=$CLASS_PATH:lib/jxl.jar
		CLASS_PATH=$CLASS_PATH:lib/log4j-1.2.16.jar
		CLASS_PATH=$CLASS_PATH:lib/mail.jar

		SERVER=/qzpt/mydayemail
		cd $SERVER   
		  
		case "$1" in   
		  
		  start)   
		    nohup java -Dfile.encoding=UTF8 -Xms64M -Xmx256M -cp $CLASS_PATH com.trendsnet.myemail.EmailShell > $SERVER/server.log 2>&1 &   
		    echo $! > $SERVER/server.pid   
		    ;;   
		  
		  stop)   
		    kill `cat $SERVER/server.pid`   
		    rm -rf $SERVER/server.pid   
		    ;;   
		  
		  restart)   
		    $0 stop   
		    sleep 1   
		    $0 start   
		    ;;   
		  
		  *)   
		    echo "Usage: myshell.sh {start|stop|restart}"  
		    ;;   
		  
		esac   
		  
		exit 0  
	...
	-----
	来自：http://www.iteye.com/topic/1122093
	* 在程序中中增加一个hook,jvm退出时会执行hook中的代码 
	Runtime.getRuntime().addShutdownHook(Thread); 
	kill -15 （SIGTERM）能够执行hook中代码 
	kill -9   (SIGKILL) 不能够执行hook中代码 
	在程序关闭前做处理工作，然后关闭。
	* 启动的时候将shell脚本的PID记录到文件里面，然后关闭的时候就可以直接读文件获取PID，避免用ps查询了，有可能不准确的 
	echo $! > $SERVER/server.pid

2. mvn test package etc 配置好资源文件 如 -tip-
	<resource>
	<directory>src/main/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>

	<resource>
	<directory>src/test/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.wiki</include>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>
	上面，加载包括main和test下的所有配置文件(部分子目录下的文件)。
mvn test生成的报告会说明失败原因，依据错误解决问题。
maven test failure —— 错误报告会告知哪里导致错误，一步步检查 cause 即可。另，test等都是依据pom的配置执行的，pom的配置要细心。
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day16 Friday, April 06, 2012

1. test 抽象类(实现方法，测视类中静态内部类继承) ，私有方法（反射）
	通过反射测试
	

2. Cron expressions  ,quartz		 cron表达式
	- expressions format
		Format
		A cron expression is a string comprised of 6 or 7 fields separated by white space. Fields can contain any of 
		the allowed values, along with various combinations of the allowed special characters for that 
		field. The fields are as follows:

		Field Name	Mandatory	Allowed Values	Allowed Special Characters 
		Seconds		YES			0-59				, - * / 
		Minutes		YES			0-59				, - * / 
		Hours		YES			0-23				, - * / 
		Day of month	YES			1-31				, - * ? / L W
		Month		YES			1-12 or JAN-DEC	, - * / 
		Day of week	YES			1-7 or SUN-SAT	, - * ? / L # 
		Year			NO			empty, 1970-2099	, - * / 
	- 
		-----
		...
			Method method = aceCalcJob.getClass().getDeclaredMethod("buildAceCalcStruct", Date.class,Date.class);
				method.setAccessible(true);
				Object result = method.invoke(aceCalcJob,startDate,endDate );
				@SuppressWarnings("unchecked")
				Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		...
		-----
3. acecalc
	* 任务第一次执行时，采集时间点的确定，根据app的创建日期为起点开始采集？
		自动查询数据库得出 or 配置文件配置初始抽取时间点 or 两者都支持
	* 

4. MS 改为 OMS 参看其文档 * OMS open metering service
	 OMS简介
		阿里云 计量 服务（ Open Metering Service ，简称 OMS），是阿里云对外提供 ），是阿里云对外提供 用户在阿里云平台上使各个服务（如 用户在阿里云平台上
		使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个
		服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 OSS OSS，OTS ，ODPS ，RDS ，VM ，ACE ）产生 的计量数据存储和查询
		服务。用户可以通过简单的 REST 接口 ，获取格式化的 ，获取格式化的 自 己
	
	开放计量服务(OMS)的数据模型包括以下几个概念:
		 Object
		 Domain
		 Accessid
		 Accesskey
	上面观念划分，体现了OMS的REST服务方式。
	
	推送数据格式：
		* Date 目前Date只支持GMT格式，具体的GMT格式可参考如下示例:
			Wed, 30 Aug 1991 09:13:05 GMT
			更多关于GMT时间格式的信息，请参考RFC|1123
		* 
		
5. 
cpu

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day17 Monday, April 09, 2012

1. 新OMS提交修改

2. 访问次数 pv 所在表
	nginx_app_abstract_running_info 
	nginx_app_running_info
3. 推送测试环境 ？ OMS测试环境提供推送测试
	测试推送逻辑
demo http://svn.simba.taobao.com/svn/Apsara/openapi/trunk/java/src/com/aliyun/openservices/oms/

	uri：http://10.230.201.85:8080/ACE_RAW
	accessid: rot1d0cc9bxp97vpcwjyo98o
	accesskey: 0GC/ahEtRiNReKA1NhuNimJ2b3A

	* 推送格式改为xml
	* 请求头变化
	
	加好各种header后，进行签名，带上content 发送请求。

	
	临时文件名，取名时需要考虑2个或2个以上操作发生在同一秒内的情况。

	403 签名错误 ，
	400 非法参数 InvalidParameterValue <Message>unsuported content-type</Message>
	* put内容的字段变化了 原来的uid，改为3个分开：
		eg:
			#foreach ($data.value in $datasMap.entrySet())
			   <Object><uid>default</uid><pid>ace</pid><bid>aliyun</bid><inst_id>$data.value.appId</inst_id><time>$data.value.startTime</time><cpu_acc_usage>$data.value.cpuAccUsage</cpu_acc_usage><memcache_size>$data.value.memcacheSize</memcache_size><req_count>$data.value.reqCount</req_count><lb_id>$!data.value.lbId</lb_id><version>$data.value.version</version><end_time>$data.value.endTime</end_time></Object>
			#end
	 * OMS client的get方法，查询测试用。
		查询OMS
	main test 输出：
		{response=<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authenticate user</Message>
		<RequestID>41e3d2b9-31d0-2c4f-493b-e4635bff819b</RequestID>
		</Error>
		, status=403}

4. mem_size 暂取为某个计量时间段内的平均值 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day18 Tuesday, April 10, 2012

1. 
	* oms get测试 - pass
	* 一次put多个object测试
	* 启动，关闭脚本修改 
	* 计量值多数据测试，统计的sql是否存在问题，大数据计算精度问题
	* 某些job中app并没有产生任何数据是否应该抛弃，不推送到OMS上，导致的问题是，在某个时间点或者区间查询时导致没有数据。？
	* quartz 挂起api ，正常停止任务，不建议job执行时强制关闭进程（程序逻辑需要处理这种例外）
	* 运行jar的配置文件独立到jar外面便于配置 
		通过spring配置加载外部配置文件。
			spring配置文件也配置在外部(不在classpath上)，spring提供了org.springframework.context.support.ClassPathXmlApplicationContext 以加载classpath之外的配置文件。外部配置文件 -tip-
		log4j提供的配置文件设置类 org.apache.log4j.xml.DOMConfigurator ，可以设置定时检查配置文件修改并重新加载配置。在main函数里初始化如下：
			String log4jfile = System.getProperty("user.dir") +File.separator +"config"+ File.separator +"log4j.xml";
			DOMConfigurator.configure(log4jfile);
		配置文件改为：
			spring和properties文件都移到jar外面，ibatis配置文件还是在jar包中。
			问题是，maven如何打包时，把config文件夹拷贝一份和包在同目录下？ assembly ？
			改为：
				配置文件只把关键的 log4j,job,jdbc 等放在jar外面加载，其他进jar包。
			shell 脚本需要在bin目录下运行，否则有配置文件找不到等错误 -tip- ，如何优化shell脚本
	* 拿到真实环境的相关数据库表机构，是否与本机一致？比如statistics_log表
	

2.  oms get测试

	已push成功的待查询测试数据：
		<?xml version="1.0" encoding="UTF-8"?>
		<Objects>   
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id></lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>
	get查询请求参数：
		"GET /ACE_RAW HTTP/1.1[\r][\n]"
		"Authorization: OMS rot1d0cc9bxp97vpcwjyo98o:yqb7kFIP3prg8z0x4gw5T4lnXEw=[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:30 GMT[\r][\n]"
		"x-oms-filter: time=1334019600[\r][\n]"
		"x-oms-select: uid;pid;bid;inst_id;time;cpu_acc_usage;memcache_size;req_count;lb_id;version;end_time[\r][\n]"
		"User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]"
		"Host: 10.230.201.85:8080[\r][\n]"
		"[\r][\n]"

	返回成功信息：
		"HTTP/1.1 200 OK[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:31 GMT[\r][\n]"
		"Server: Apache/2.2.17 (Unix)[\r][\n]"
		"Content-Length: 322[\r][\n]"
		"Content-Type: text/xml;charset=UTF-8[\r][\n]"
		"[\r][\n]"
		"<?xml version="1.0" encoding="UTF-8" ?>
		<Objects>
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id>0</lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>"

	注：上面put的数据与get返回的数据 lb_id由空变为了0，这是OMS对某些字段如果空会置默认值的逻辑。

	uid+time
	uid+pid+bid+inst_id+time
	目前就这两个你有权限查
	
	domain没有操作权限：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authorize user</Message>
		<RequestID>7a44a74b-211a-fda1-68b6-7f5907108b41</RequestID>
		</Error>	
	查询条件错误：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>InvalidQueryExpressison</Code>
		<Message>query condition not match any dimension</Message>
		<RequestID>66a00276-6ad9-d94f-1bf7-db7f0c4830ba</RequestID>
		</Error>	
3. 部署  程序运行目录定义说明（配置简单操作为好）
		bin - 放运行脚本
		build - 放编译脚本(svn下载，maven构建，部署到设定的目录(到bin,lib,config))
		config - 存放配置文件(log4j,job等的配置文件)
		lib - jar文件
		logs - 日志

		操作从调用build下的脚本开始执行。
		build下放置build好的文件，如何deploy脚本将build好的文件分别部署到相应的目录中去。
		bin下的启动脚本需要在bin当前目录下运行，否则报配置文件找不到？

4. sh -x xx.sh 查看
	脚本可能因为隐藏字符导致错误，执行时 -x 查看即可。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day19 Wednesday, April 11, 2012

1. 
	执行过程中断处理
	那些数据时不用推送的，比如某个时间段都没有产生数据（这压缩数据交给oms？）


2. shell 执行路径问题  shell 必须在当前路径执行，否则路径错误 ，解决？【 spring加载资源文件路径 ，类路径，外部路径 配置路径 路径设置 改变工作目录 当前路径】
	关键：cd 命令，设置当前路径 
	#!/root/bash
	echo `pwd`
	current_dir=$(cd "$(dirname "${0}")";pwd)
	echo $current_dir
	
	pwd会因为执行路径不同而变化，current_dir可以取到shell所在路径。 

	但对于没有动态调用 user.dir 找到classpath之外资源路径的情况，可以在非shell所在目录执行时，在shell里cd到所在base目录，这样
	后续java加载取值时，取得就是cd后的路径。-tip-

	shell执行时，指定java系统参数 user.dir 即可 ，即指定java执行时用户当前目录为程序所在主目录（base目录，其子目录有lib，bin等等）。-tip-
	通过java命令的 -D 参数指定 user.dir ,结合程序逻辑，指定资源文件等的路径path。
		String log4jFile = System.getProperty("user.dir") + File.separator + "config"+ File.separator +"log4j.xml";
		-----
		...
			#!/bin/bash
			BIN_DIR=$(cd "$(dirname "${0}")";pwd)
			BASE_DIR=`dirname $BIN_DIR`
			LIB_DIR=$BASE_DIR/lib
			LOG_DIR=$BASE_DIR/logs
			#set for java to load resource
			USER_DIR=$BASE_DIR
			JAR_NAME=houyi-measuredata-all-0.0.1.jar
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    start)
				cd $BASE_DIR # 转到程序需要的工作路径，比如需要此路径来加载资源文件，spring里从外部文件加载的资源文件相对此$BASE_DIR取路径即可。
				java -Xms64M -Xmx256M -Duser.dir=$USER_DIR -jar $LIB_DIR/$JAR_NAME > $BIN_DIR/server.log 2>&1 &
				echo $! > $BIN_DIR/server.pid
				;;
			    stop)
				kill `cat $BIN_DIR/server.pid`
				rm -rf $BIN_DIR/server.pid
				;;
			    *)
				echo  "invalid option ,usage: $0 [insert|remove]";
				;;
			esac

			exit 0
		...
		-----
		通过 -Duser.dir=xxx 设置user.dir参数好

		执行路径，相对路径 ，程序默认读当前路径，执行路径时，在shell可以 cd 到所需要的当前路径(工作路径)，再执行即可。
		
3. svn 提交 eclipse ，还是用svn客户端 
		eg: TortoiseSVN   
			check for modification - revert  
		可以用客户端管理版本，eclipse只负责项目开发。 不同svn客户端交叉用可能出错误。
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk 
		username
		password
	* svn
		- install (its package named subversion ,not svn)
			yum install subversion
		- 各种svn工具操作命令不相同，但svn基本功能都是提供的，只是不熟悉的话要去找找
			比如：TortoiseSVN 查看某个文件的提交记录 ，是调用 show log 菜单 ；eclipse的svn插件用的可能就是 xx history ；熟练度的关系

4. 从svn下载到maven编译到部署运行 ，整个的脚本
	svn取到项目源码
	mvn 构建
		不同机子上构建时依赖可能出现的问题：
			Error transferring file: Connection refused
			Specified destination directory cannot be created: /usr/ali/maven/repository/org/slf4j/slf4j-api/1.5.6 - maven库没有添加jar权限，改为已有的版本绕过
				eg: ls /usr/ali/maven/repository/org/slf4j/slf4j-api


5. 部署说明文档 (测试，部署人员依据此文档操作)
	* 从10.250.8.214机子上拷贝目录measure(/home/admin/measure)到目标机/home/admin目录下，进入该目录 (编译机和运行机都采用上面的目录结构)
	* 执行bulid 目录中的build.sh构建
	* 然后执行build目录下的deploy.sh部署
	* 再执行bin目录下的execute.sh启动和关闭程序，用法如下：
		execute.sh start - 启动程序
		execute.sh stop - 关闭程序
	目录结构说明：
		measure
			- bin 包含执行程序的脚本 execute.sh ，shell执行日志文件server.log,程序的的pid备份server.pid
			- build 包含构建和部署脚本build.sh,deploy.sh
			- config 包含程序配置文件log4j，job，jdbc的属性配置
			- logs 程序执行日志
			- src 存放源码
				- target 打包后的文件(zip)

6. maven换其他环境编译时，依赖找不到解决，看错误日志找到依赖找不到的原因，一般即可解决

7.  shell 脚本  ,字符不认识问题 ，在windows下的文本，通过ssh工具拷贝到linux中后，不能正常执行命令。可能是字符编码或者异常特殊符号(;/r)等问题，可在linux下
新建shell解决，拷贝的一般都有问题。

或者，是因为使用的ssh客户端没设置好，传输时编码问题？从svn下载下来的shell(原在windows下创建)都不能正常执行。 -tip-

原因：unix，dos 字符间需要转换 
	xxx@xxx$ uni
		unicode_start  unicode_stop   uniq           unix2dos       unix_chkpwd
	dos2unix

8. 
unix2dos dos2unix

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
day20 Thursday, April 12, 2012

1.  
	sql独立，将各自的查询sql独立查询，程序里再组合，编写涉及到表的pojo和映射文件
	dao db wiki 测试
		'file://D:\workspace\measure/target/dbfit/com\aliyun\houyi\measuredata\dao\impl\MemacheAppRunningInfoDaoImplTest.testReadAceCalInfocByTimePeriod.when.html'

2. 
	ls -R 
	shell判断文件是否存在，再做后续操作
		if [ -f urfile ]  then
			./a.sh   
		fi

3. sql独立
	对于数据量可预知且不大的情况下，可以进行关联查询，减少访问数据库次数。对于数据量非常大的表最好单独查询，计量减少关联查询。 -tip-

4. 单元测试，补上db部分的测试，验证sql逻辑等 -tip-
	mvn test -Dtest=AppDaoImplTest 只测试某个用例
5. 
duplicate entry key 
	确认那些字段是唯一的，一条若有多个唯一的，保证都唯一，否则数据库报错可能误报，比如有key3和key8都是unique，此时即使key3是唯一的，但key8
	是重复的，执行后可能会误报key3重复，实际上是key8重复。-tip-

6. vip 表字段修改，测试时注意
	 alter table vip add lb_id varchar(20) default NULL;
	 alter table vip MODIFY COLUMN lb_id varchar(20) default NULL;

7. mysql ,ibatis
	mysql的各种数字统计函数对应的类型不同
		需要定义好。在sql语句里转换好类型。
8. maven test 时报错误，找不到某个类，是因为测试环境和开发环境冲突了，比如在开发环境用了测试的jar，会导致错误，部署时，除去测试的依赖。 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day21 Friday, April 13, 2012

1. 
	*  job 的丢失处理时间和临时文件保留时间改为配
	* ace计量中agent的角色
		计量数据由agent上报，同app同类型数据可能有多个agent上报，统计时，需要注意这点。比如求平均时需要先求时间段内每个agent各自
		数据的平均值，再对平均值求和。
	* JCE OpenAPI
		svn改了新分支，下载新的cloudengine分支
			http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v5/master

2. job 的丢失处理时间
	和临时文件保留时间改为配
	丢失文件查找费时间

3. jce openapi  
	目标：
		标准openapi请求转接到rest服务处理。
	具体：
		根据一个请求路径，比如 /open，将所有对openapi的请求转到openapi调用service来处理，在这个service里，得到openapi的请求参数
	，根据参数调用master提供的service进行处理并返回。其中对参数的验证等可参考rest路径请求进来的处理过程。
			
	RestOpenService.java  供 openapi 调用的service
	目前文档里稳定的接口是 3.1->3.9

4. sql ，app_id,agent_id 一个app_id对应每个agent_id平均值的和,一次分组求平均，一次分组求和，多次分组统计即可 -tip-
	-------
	...
		select
		    app_id,
		    sum(tempmem.memcache_size) as memcache_size
		from (
		    SELECT  
			memcache_agent_id,
			app_id,
			ifnull(avg(mem_bytes),0) as memcache_size 
		    FROM memcache_app_running_info
		    group by memcache_agent_id
		    ) tempmem
		group by tempmem.app_id
	...
	-------
	前提 memcache_agent_id 与 app_id 为一对一或多对一的关系。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day22 Monday, April 16, 2012

1. 
	* 根据mast提供的service和jce openapi ,设计一个供openapi调用，处理普通get,put方式的rest服务。
		目标：此服务通过master提供的接口，实现jce openapi提供的接口服务(比如创建app,删除app等等)
			请求的验证，master在提供的service调用里已有处理，故此服务只根据请求的action定位到service，传递参数。
		
	* wiki 添加ace计量sql语句供review
		- app_id查询时应该不带状态，如果只取已部署的app，可能导致部分app运行数据丢失
		- memcache 计算sql语句错误，app_id和memcache上报agentId是多对多关系。
			
	* ace的部署方式，加上先从svn下载默认目录结构(包含build部署，执行脚本)，然后执行build进行build,然后deploy，最后execute
		这样，部署ace计量程序步骤如下：
			a. 在有写权限的临时路径下执行
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/deploy-env			
			b. 进入上面checkout下来的目录(deploy-env)，找到measure目录，将其拷贝到/home/admin/measure目录下(若没有此目录则新建，若重名就另外取目录名亦可)
				cd deploy-env
				cp -r measure /home/admin/measure
			c. 进入 /home/admin/measure 目录
				cd /home/admin/measure
			d 执行构建脚本
				sh build/build.sh
			e 执行部署脚本
				sh build/deploy.sh
			f 执行启动服务脚本
				sh bin/execute.sh

2. master的rest对openapi，
提供一个rest service接受所有openapi请求，内部通过一个方法接受所有请求并解析后调用对应action，service处理。

jce的openapi调用文档 —— 据此文档解析请求，调用jce master提供的service


3. ots
	http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000

4.maven debug
	mvn -Dmaven.surefire.debug test
	在ide，比如eclipse上配置远程debug(remote java application)，通过socket来debug。
	通过所使用的maven测试插件自带说明来配置debug，文档最清楚 -tip-

	运行上面maven命令后，再到eclipse配置debug run 为remote java application等配置，执行debug即可进入远程debug模式。
5. jce openapi
	根据请求的action的不同，分发到各自的function去处理，如何去分发？
		通过反射？
			定义acton与方法的的对应关系,比如以属性文件方式配置
			根据action通过反射调用service的方法
		还是自定义注解解析请求uri的方式？
			参考Spring MVC ，提供了完全基于注解的配置
				参考：http://www.cnblogs.com/sunwei2012/archive/2010/05/11/1732518.htm
					http://www.infoq.com/cn/articles/cf-java-annotationl
	* jce日志接口调用
		query_app_log这个接口的type类型，应用的日志是在ols(open log service)服务 里获取的
		
6. 自定义 annotation 实现元数据配置 ，自定义注解
	* 定义action注解
		actionName - 请求的action名称
		parms - 对应action所需要的参数(这里每个action参数不一致，引出下面的问题)
			需要rest提供一种方式，可以取到比较原始的请求消息，可以进行自定义再处理，而不是在rest方法里定义好
		需要取那个参数。？
	* 通过注解，由于每个jec open api的请求参数不同，所有需要根据rest规范，得到请求的所有参数，
	参考了sum的RESTfulWeb Services Developer'sGuide(p26)，可以通过context注解来注入请求上下文内容，
	从而获得所有请求参数。再匹配到对应的action取到各自的参数，调用service执行逻辑。-tip-
		----
		...
			Form parameters (indicated by decorating the parameter with javax.ws.rs.FormParam)
			extract information from a request representation that is of the MIME media type
			application/x-www-form-urlencoded and conforms to the encoding specified by HTML
			forms, as described here. This parameter is very useful for extracting information that is
			POSTed by HTML forms. The following example extracts the form parameter named "name"
			from the POSTed form data.
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(@FormParam("name") String name) {
			// Store the message
			}
			If it is necessary to obtain a general map of parameter names to values, use code such as that
			shown in the following example , for query and path parameters.
			@GET
			public String get(@Context UriInfo ui) {
			MultivaluedMap<String, String> queryParams = ui.getQueryParameters();
			MultivaluedMap<String, String> pathParams = ui.getPathParameters();
			}
			Or code such as the following for header and cookie parameters:
			@GET
			public String get(@Context HttpHeaders hh) {
			MultivaluedMap<String, String> headerParams = hh.getRequestHeaders();
			Map<String, Cookie> pathParams = hh.getCookies();
			}
			In general @Context can be used to obtain contextual Java types related to the request or
			response.
			For form parameters it is possible to do the following:
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(MultivaluedMap<String, String> formParams) {
			// Store the message
			}
		...
		-----
		先看了注解源码说明，再依据文档。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day23 Tuesday, April 17, 2012

1. 
	* 通过 rest  的规范中的 @context 注解来取得请求参数，传递给其他函数处理
		action映射在启动时初始化好。
	* jce openapi
	接口文档里面提到的一些param 字符串需要你这边把输入参数转换为json。
		转换的内容在 com.aliyun.cloudengine.model.opeanapi 下，里面以Param结尾的类定义
		siteId是之前跟王永生约定好的，调用方的标识ID
	- com.aliyun.cloudengine.service.openapi.OpenApiFacadeService(定义在spring-base-service.xml中) 处理openapi请求
		需要将请求参数转换为json格式传递
	- 日志查询需要用到ols ？待
		集合jce openapi文档参考ols文档
		关于ACE OpenAPI的日志查询接口说明
			1、操作接口是query_app_log，日志类型是manipulateLog和appRunningLog 
			2、以上两种类型的日志需要通过OTS获取，其他类型的通过调用master接口获取
			3、测试环境调用地址：curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'
			4、具体的调用可参见《开放日志服务接口文档.docx》

2. maven添加jar到本地库
	mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
	from:http://blog.sina.com.cn/s/blog_4b81125f0100ifnm.html
3. maven jar包重复问题，可通过
	mvn dependency:tree 查看依赖关系。
	配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
	对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
	只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。

	若还是冲突，修改scope为provided，或者通过exclusions来处理。
4. 关于ace计量pv
	nginx_app_abstract_running_info 中的pv包含静态和动态之和； nginx_app_running_info 中的pv只为静态请求次数

5. http状态表示 ，状态常量定义 
	import org.apache.commons.httpclient.HttpStatus;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day24 Wednesday, April 18, 2012

1. 
	* jce open api
		- jce接口中的site_id就是jce请求的site_user_id ?site_id不是用户调用jce open apisite_user_id这个site_id表示阿里云，万网或是其他的id标识，可以
		   到app表取到(注意：目前取app表的user_id作为site_id,后续会废弃user_id改为app表的site_id的值)这个site_id在到openapi处理时已经附加在用户请求中了
		   参考 产品线接入Open API规范说明_v0.2
		- 由于线上cloudengine的库表结构和最新开发的库表结构可能不一致，从trunk上拿线上版本的表，再测试下 ？
			包括相关的mapping文件pojo等
		- ace计量bid定为26842，测试时用的aliyun
		- 测试oms时，可以到ace_calc_struct.xml把生成数据替换为测试数据测试
		- jce sevice接口调用参数改为传递对象方式，原为json
	* ace计量
		- 对于没有任何app的情况，跳过不处理。

2. firefox 能正确显示json格式，ie8却不能处理 ？
	即content-type = application/json时ie8不认识，不会处理。
	查看ie8支持的媒体类型：

3. 通过注解anotation配置映射信息 ,取代配置文件实现元数据配置。
	------
	...
		@Retention(RetentionPolicy.RUNTIME)
		@Target(ElementType.METHOD)
		public @interface OpenAction {
			
			String actinName();
			String[] paramNames();
			
		}	
	...
	------
4. mysql 
	不同版本统计函数返回的数据类型也是不一致的，

5. jce openapi 日志
	日志类型,manipulateLog、accessLog、jettyRunningLog、appRunningLog
		其中，manipulateLog和appRunningLog类型日志从OLS服务获取，accessLog、jettyRunningLog调用master接口获取。

	OLS测试地址：
		curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'	
		服务位置：http://ols.aliyun-inc.com
6. 测试时从类相同路径加载资源文件
	this.getClass().getResourceAsStream("JobServiceImplTest.testPushRequest.xml");
	加载资源的方法有多种，下面摘自网络小节：
			------
				Java中getResourceAsStream的用法
				首先，Java中的getResourceAsStream有以下几种： 
				1). Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从
				ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。 
				2). Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由
				ClassLoader获取资源。 
				3). ServletContext. getResourceAsStream(String path)：默认从WebAPP根目录下取资源，Tomcat下path是否以’/'开头无所谓，
				当然这和具体的容器实现有关。 
				4). Jsp下的application内置对象就是上面的ServletContext的一种实现。 
				其次，getResourceAsStream 用法大致有以下几种： 
				第一： 要加载的文件和.class文件在同一目录下，例如：com.x.y 下有类me.class ,同时有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("myfile.xml"); 
				第二：在me.class目录的子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.y.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("file/myfile.xml"); 
				第三：不在me.class目录下，也不在子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				总结一下，可能只是两种写法 
				第一：前面有 “   / ” 
				“ / ”代表了工程的根目录，例如工程名叫做myproject，“ / ”代表了myproject 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				第二：前面没有 “   / ” 
				代表当前类的目录 
				me.class.getResourceAsStream("myfile.xml"); 
				me.class.getResourceAsStream("file/myfile.xml"); 
			------

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day25 Thursday, April 19, 2012

1. 
	* jce open api
		- ols日志部分
			a. 根据jce openapi文档日志查询部分需求，设计接口及实现
			b. 使用master内处理http发送接收请求的代码与日志服务交互
				http交互公用代码
		其余action实现
2. 关于rest的response问题 -tip-
	* 在简单的测试项目中一个pojo service在暴露rest服务并做处理返回时，这个返回对象需要是rest规范定义的response的
	子类，这样rest框架处理时就能正确响应给请求者。
	* 还有一种方式，就是这个rest service继承某个类，或实现接口，其暴露的rest服务方法只返回pojo对象，处理响应交给依赖的
	类去处理
	fire: REST方法的返回对象必须是REST接口定义的Response类的子类。上面的说明还是和所使用的rest框架相关的，下面的 RESTEasy 框架
	rest服务返回的就是直接的pojo对象，框架自身回去处理把pojo构造为标准的http response返回。
3. RESTEasy  框架实现REST服务
	RESTEasy
		RESTEasy is a JBoss project that provides various frameworks to help you build RESTful Web Services and RESTful Java applications. 
	It is a fully certified and portable implementation of the JAX-RS specification. JAX-RS is a new JCP specification that provides a Java API for RESTful Web Services over the HTTP protocol.
		RESTEasy can run in any Servlet container, but tighter integration with the JBoss Application Server is also available to make the user experience nicer in that environment. 
	While JAX-RS is only a server-side specification, RESTEasy has innovated to bring JAX-RS to the client through the RESTEasy JAX-RS Client Framework. This client-side framework allows you to map outgoing HTTP requests to remote servers using JAX-RS annotations and interface proxies.

	from:http://www.jboss.org/resteasy/

	搭建 RESTEasy 测试project。
4. String.valueOf() 注意null值

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day26 Friday, April 20, 2012

1. 
	* 测试jce openapi
		- 由于运行环境不易构建，通过 mock 方式测试用例，mock出需要的条件。
			mock测试目的：测试目标类的功能时，模拟其依赖对象，关键在于测试目标类。
		- openapi把用户请求转发给jce open api前会去校验action是否存在
		- 停止APP的参数不统一？jce open api文档有的参数pojo中没有
	* 参照jce open api对比所有参数正确性 ？ 

2. jtester 可以利用其提供的反射工具类进行特殊方法(如私有方法)的测试
	JTesterReflector 通过反射执行调用测试
	提供集成测试支持(如数据库等)
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day27 Monday, April 23, 2012

1. 
	*jce openapi 
		- post请求 rest 取得post参数集合	
			结合openapi的post请求规范提供服务
		- 日志部分接口定义说明 ，返回码，格式
		- 功能增加，实现
			update OpenApiFacadeService ，svn diff with previous version ，得到新增接口方法，实现对应逻辑及单元测试。


2. rest post请求参数 , get post parameters restful -tip-
	jersey文档说明如下：
		In general @Context can be used to obtain contextual Java types related to the request or response. For form parameters it is possible to do the following:

		Example 2.19. Obtaining general map of form parameters

		@POST
		@Consumes("application/x-www-form-urlencoded")
		 public void post(MultivaluedMap<String, String> formParams) {
		     // Store the message
		 }
	参数集合，自动封装Injection 自动注入 。
		get请求通过uriinfo封装
		post请求直接通过MultivaluedMap封装

3.for test
#for test case 
slb.api.server=1
slb.api.serviceSecretKey=2
slb.api.session=3
slb.api.regionNo=4
ftp.url=1
ftp.address=2
ftp.port=3
dns.server=4

4.  调用过程
	请求处理
	资源分配
	rpc(mina)
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
		It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
	结果处理
5. quartz 属性配置文件配置跳过更新检查
	或者通过java命令的 -D参数设置
		-Dorg.terracotta.quartz.skipUpdateCheck=true
6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day28 Tuesday, April 24, 2012

1. 
	* jce openapi 内部联调
		- 测试环境openapi接入前准备
			mysql -utest -ptest
			openapi 
				配置接入参数到 服务表 和 action表
			测试地址：http://10.230.129.182:8088/open?
			jce 测试环境wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8651094
		- master的属性配置到 /src/main/conf/cemaster_env.properties 中，test下的属性只供测试调用
		- rest暴露的服务uri定位 /open 
		- wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=6094915
		- site_id master的接口实现已经做了参数验证，桥接层不需要处理，提供统一的异常提示。
			转接层不做业务相关的处理,让了解业务的逻辑去处理验证是否符合要求。模块责任清晰
			参考 struts2的自动参数注入逻辑，不匹配的置为null
	* 着手 SLB API V2 时间点 4.30
2. 测试环境 mysql
	10.250.8.214
	mysql -utest -ptest
	open api服务接入配置：
	use openapi
		service_provider
			insert into service_provider values(7,'ace','http://10.230.129.182:8088/open?','1.0','ace',now(),now());
		api
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('create_app',60,'create_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_name',60,'check_app_name',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_domain',60,'check_app_domain',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_web_container_quota',60,'set_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values(set_reverse_proxy_quota',60,'set_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_memcache_quota',60,'set_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_start_args',60,'set_app_start_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_stop_args',60,'set_app_stop_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('start_app',60,'start_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('stop_app',60,'stop_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('build_app',60,'build_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_build_job',60,'query_build_job',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app',60,'query_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_app',60,'delete_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app_topolgy',60,'query_app_topolgy',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_os_monitor',60,'query_os_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_reverse_proxy_quota',60,'query_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_web_container_quota',60,'query_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_quota',60,'query_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_info',60,'query_memcache_info',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_jvm_monitor',60,'query_jvm_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_reverse_proxy_configuration',60,'set_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('test_reverse_proxy_configuration',60,'test_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('get_reverse_proxy_configuration',60,'get_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_reverse_proxy_configuration',60,'delete_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_net_io',60,'query_net_io',1,1,7,now(),now());

			| api_id | api_name                           | timeout | description                        | status | level_id | sp_id | gmt_create          | gmt_modify          |
			+--------+------------------------------------+---------+------------------------------------+--------+----------+-------+---------------------+---------------------+
			|    289 | create_app                         |      60 | create_app                         |      1 |        1 |     7 | 2012-04-24 10:30:45 | 2012-04-24 10:30:45 |
			|    291 | check_app_name                     |      60 | check_app_name                     |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    292 | check_app_domain                   |      60 | check_app_domain                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    293 | set_web_container_quota            |      60 | set_web_container_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    294 | set_reverse_proxy_quota            |      60 | set_reverse_proxy_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    295 | set_memcache_quota                 |      60 | set_memcache_quota                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    296 | set_app_start_args                 |      60 | set_app_start_args                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    297 | set_app_stop_args                  |      60 | set_app_stop_args                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    298 | start_app                          |     600 | start_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    299 | stop_app                           |      60 | stop_app                           |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    300 | build_app                          |      60 | build_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    301 | query_build_job                    |      60 | query_build_job                    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    302 | query_app                          |      60 | query_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    303 | delete_app                         |      60 | delete_app                         |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    304 | query_app_topology                 |      60 | query_app_topolgy                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    305 | query_os_monitor                   |      60 | query_os_monitor                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    306 | query_reverse_proxy_quota          |      60 | query_reverse_proxy_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    307 | query_web_container_quota          |      60 | query_web_container_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    308 | query_memcache_quota               |      60 | query_memcache_quota               |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    309 | query_memcache_info                |      60 | query_memcache_info                |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    310 | query_jvm_monitor                  |      60 | query_jvm_monitor                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    311 | set_reverse_proxy_configuration    |      60 | set_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    312 | test_reverse_proxy_configuration   |      60 | test_reverse_proxy_configuration   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    313 | get_reverse_proxy_configuration    |      60 | get_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    314 | delete_reverse_proxy_configuration |      60 | delete_reverse_proxy_configuration |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    315 | query_net_io                       |      60 | query_net_io                       |      1 |        1 |     7 | 2012-04-24 10:31:46 | 2012-04-24 10:31:46 |
	
	文档action名称定义：
		create_app
		check_app_name
		check_app_domain
		set_web_container_quota
		set_reverse_proxy_quota
		set_memcache_quota
		set_app_start_args
		set_app_stop_args
		start_app
		stop_app
		build_app
		query_build_job
		query_app
		delete_app
		query_app_topology
		query_os_monitor
		query_reverse_proxy_quota
		query_web_container_quota
		query_memcache_quota
		query_memcache_info
		query_jvm_monitor
		set_reverse_proxy_configuration
		test_reverse_proxy_configuration
		get_reverse_proxy_configuration
		delete_reverse_proxy_configuration
		query_net_io


3. 产品线接入openapi ，诸如验证，访问控制，负载，api是否开放等等由openapi负责 ，产品线关心业务。 -tip-

4. jce openapi 测试
	测试每一个action ，测试结果以与rest接口暴露的action的返回结果一致为准。
		create_app
			domain_name 格式要求 xxxxxx.aliapp.com ，xx位置格式要求为4-18个字符
		url=http://10.230.129.78:8088/open?oauth_nonce=28587223711112&start_args=test_start_args&oauth_version=1.0&oauth_consumer_key=TestVMFhd506uBsO&app_name=testAppName1088&site_user_id=1088&oauth_signature=sZUqPtyuaPXlsRx1NVnboV0tIaw%3D%0D%0A&oauth_signature_method=HMAC-SHA1&action=create_app&app_language=2&stop_args=test_stop_args&user_id=1&domain_name=ace2012.aliapp.com&git_url=test.git.url&oauth_timestamp=1335258526
		{"data":{"appId":3},"code":200,"msg":"success"}			
	* yaml 格式配置消息 -tip-
		准备此格式配置内容
	* 

5.  SLB API V2
	* 目标
		- 接收用户请求
		- 根据请求消息，构造请求体，调用后端slb，得到结果
			需要根据request信息，查询db得到调用slb后端接口的必要参数
				region_id所属的HOUYI region id
		- 将结果状态处理下 比如 -100 转换为-2100，返回给用户
		- 实现slb后端提供的接口调用(定义的action操作)
	* check out 代码
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 阅读相关文档
	* 查看源码
		框架构成：struts2 + spring + ibatis 
			- bean交给spring管理，struts配置文件引用其名称；action定义于spring配置中 ，通过ApplicationContext的getBeansOfType(Class type)获得所有action的名称实例map
			- 请求映射通过统一的proxyaction接受，并根据请求的action，通过反射执行对应action的接口方法，得到返回结果。
			   其中的action名到对应action实例的映射关系实现通过ExecuteActionFactory初始化，这里的设计，每个action名对应一个
			    action处理类，启动时以bean names as keys and the corresponding bean instances as values初始化到map中。
			- 需要用的参数，拦截器处理好放到threadlocal实现的RequestContextHolder对象中，提供了静态方法，供service调用slb后端
			   时调用

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day29 Wednesday, April 25, 2012

1. 
	* slb api v2
		- 根据上面分析，现在的任务是：
			a. 实现slb后端文档提供的操作Action类，并配置到spring配置中
			b. LoadBalancerService 加入新的功能定义，并实现
				
		- 涉及到vm的信息(比如向lb_id中加vm时) ，需要到后羿vm处去查询  ，数据库 houyi
			配置文件：slbapi.properties 
				ec.api.url=http://10.230.204.65/open/services?
		- 一些交互细节，demo等可参考v1版本的代码(houyi-console下)
			svn 地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/trunk
			如 /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/LBControlServiceImpl.java 参考其与slb后端交互逻辑。
		- slb后端的请求url从region表中获得。
		- post请求：
			注意请求内容以multipart的方式构造请求体，这样服务端接收时才能正确解析。
		- 返回码搞清楚
			对于slb后端返回的状态码，如果为负数则减去2000作为返回状态码
			如果slb api前端报错，则根据前端文档返回对应状态及msg

		- 任何异常(Exception)都指定到错误的result上去。
	* slb 测试
		测试地址：10.150.8.214
		部署
			部署结构：nginx+tomcat
			启动tomcat 
				/home/admin/slbapi/bin/tomcatctl start
			启动nginx（/home/admin/openapi/bin/nginxctl start）——若已启动，则不需要操作，只需启动tomcat即可
			
			http://10.250.8.214/slb/api?action=list_rs_pool&timestamp=2012-05-31+19%3A45%3A37&region_no=AT03-HOUYI1&session=lei.chang%40alibaba-inc.com&sign=kmEdDhkMXlIqGXxpsfwG3A%3D%3D

			查看tomcat日志，在..slbapi/.default/...tomcat-localhost-6.1xx.log
				
2. 
openapi接入的服务
mysql> select * from service_provider;
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
| sp_id | sp_name  | url                                 | version | description | gmt_create          | gmt_modify          |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
|     1 | ecs      | http://10.230.204.65/open/services? | 1.0     | ecs         | 2011-12-31 17:13:55 | 2011-12-31 17:13:55 |
|     2 | slb      | http://10.230.204.65/open/services? | 1.0     | slb         | 2012-01-10 10:21:07 | 2012-01-10 10:21:07 |
|     3 | ecs_test | http://127.0.0.1:8888/?             | 1.0     | ecs test    | 2012-01-18 17:31:33 | 2012-01-18 17:31:33 |
|     4 | boss     | http://10.230.128.5:8080/           | 1.0     | boss        | 2012-04-20 15:20:26 | 2012-04-20 15:20:26 |
|     5 | rds      | http://127.0.0.1:8888/?             | 1.0     | rds         | 2012-04-20 15:20:39 | 2012-04-20 15:20:39 |
|     6 | git      | http://ceqa-gitserver1:4567/api     | 1.0     | git         | 2012-04-23 16:42:49 | 2012-04-23 16:42:49 |
|     7 | ace      | http://10.230.129.182:8088/open?    | 1.0     | ace         | 2012-04-24 10:20:47 | 2012-04-24 10:20:47 |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
ecs - vm openapi

3. slb v2 
	测试url：http://localhost:8080/slb/api.do?action=create_loadbalancer
		 <?xml version="1.0" encoding="utf-8" ?> 
		 <rsp>
		  <code>-50</code> 
		  <msg>illegal user</msg> 
		  </rsp>


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day30 Thursday, April 26, 2012

1. 
	* slb api v2 
		* 走通一个action
			http://localhost:8080/slb/api?action=create_loadbalancer&user_id=1&session=xxx

2. maven web 项目debug ，maven tomcat debug
	修改tomcat启动脚本,远程调试：
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%  
3. 请求slb后端方式的修改
	slb后端服务是REST方式，在请求时需要满足其格式要求。
		比如除了get方式外，其他请求方式post，put，delete请求方式，都需要把请求体也放到URI中，目前采用的是 Matrix URIs  方式：
			Matrix URIs 
			Matrix spaces and Semicolons 
			It is maybe obvious to note that there are many, many hierarchical systems. An interesting analogy with a hierarchical power is, in a programming language, a sequence of parameters supplied to a command or a procedure. For example, in some languages a procedure may take positional parameters which may be optional so that any parameters from a certain point on may be omitted. This syntax can be compared with a hierarchical slash separated URL path. This is an interesting analogy because looking at the alternative representation for procedure parameters which consists of a list of procedure name and value pairs. This leads us naturally to a discussion of the use of the semi-colon in URLs and the matrix syntax. Just as the slash separated set of elements is useful for representing a tree, so a set of names and equally significant parameter can represent a space more like a (possible sparse) matrix. In this case navigation to "close" locations is done by varying one or more parameters which form the dimensions of the matrix. This is the purpose of the a=b; parts of URL syntax which was added later in the URL's history. The initial need was to put qualifiers onto URLs which were themselves hierarchical. 

			The analogy with procedure call holds still when looking at combined forms: The hierarchical part of the URL is paused first, and then the semi-colon separated qualifiers are paused as indicating positions in some matrix. As an example let's imagine the URL of an automatically generated map in which the parameters for latitude, longitude and scale are given separately. Each may be named, and each if omitted may take a default. So, for example,

				 //moremaps.com/map/color;lat=50;long=20;scale=32000

			might be the URL of an automatically generated map. 
			摘自：http://www.w3.org/DesignIssues/MatrixURIs.html
	根据上面：
			请求SLB后端时，get请求直接根据uri格式要求请求；对于有content内容(注意区别与普通post请求是放到请求体重)的请求，
		需要以Matrix URIs的方式，把请求内容放到uri中，再去请求。-tip-
	
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day31 Friday, April 27, 2012

1. 
	* SLB API v2
		- 根据slb对外api文档，将请求结果处理后依据slb后端调用文档调用，并返回结果
2. 测试
	* 创建LoadBalancer：		
		客户端请求：http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
		slb后端请求：http://10.230.130.129:8088/lbs/lbname1;lb_type=compact;region_id=region-test;eip_type=internet;user_id=1
			结果：{response={"data":{"lb_id":"25-region-test","eip":"42.120.64.227"},"code":200,"msg":"successful"}, status=200}
			struts的自定义result处理结果时报错。
				处理结果返回类型的 UserActionResult 在 response.getWriter().write(resultFormat.value(result)); 处转换对象为json或者xml时报错？
	* 查询LoadBalancer信息：
		http://10.230.130.129:8088/lbs/123/
		user_id如何传递？
	* 查询loadbalancer列表 http://10.230.130.129:8088/lbs;user_id=1
		结果：{"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","26-region-test","27-region-test","28-region-test","29-region-test","30-region-test","31-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test"]},"code":200,"msg":"successful"}



3. 
SLB API 错误码：
		2000 - 2100 -平台错误
		>2100 业务错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day32 Saturday, April 28, 2012

1. 
	* 根据slb后端文档，实现调用接口，对比前端用户api文档，修改接口实现中需要参数转换的逻辑。
	* 拿到rest服务的源码校对url请求 ？
		- 看rest服务代码，测试请求来的精确
			eg：查询lb:http://10.230.130.129:8088/lbs/43-region-test;user_id=1 这里需要将user_id传递过去，因为slb后端是根据lb_id和user_id都匹配来查询lb的
	* slb api v2 平台错误提示需要细化，比如：
		http://localhost:8080/slb/api?action=query_loadbalancer&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":-2003,"msg":"system exception"}
		http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":200,"data":{"lb_id":"43-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.215","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		第一个请求的错误，具体原因是action的名称不对，可以细化错误提示，便于调试和理解。

		错误，异常提醒细化 

2. 
	测试记录：
		创建LB: 
			compact http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"53-region-test","eip":"42.120.64.204"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
				{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
			hybrid http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=hybrid&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"60-region-test","eip":"42.120.64.238"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname2&lb_type=hybrid&eip_type=internet&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","eip":"42.120.64.226"},"msg":"successful"}
		查询LB: http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.227","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		删除LB: http://localhost:8080/slb/api?action=delete_loadbalancer&region_no=region-test&lb_id=31-region-test&&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置LB: http://localhost:8080/slb/api?action=config_loadbalancer&region_no=region-test&lb_id=25-region-test&status=active&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询LB列表：http://localhost:8080/slb/api?action=list_loadbalancers&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test","40-region-test","41-region-test","42-region-test","43-region-test","44-region-test"]},"msg":"successful"}
		
		创建VIP: 
			compact: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A80%2C%22backend_port%22%3A82%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22persistence_timeout%22%3A1000%2C%22check%22%3A{%22type%22%3A%22vtcp%22}}}%2C{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A83%2C%22status%22%3A%22inactive%22%2C%22backend_port%22%3A81%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22forwardfor%22%3A%22on%22%2C%22keepalive%22%3A%22on%22}}]&lb_id=59-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}
			http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=401-AT03-HOUYI1&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
			hy: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=62-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}		
				http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=23-region-test&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
		删除VIP: http://localhost:8080/slb/api?action=delete_vip&region_no=region-test&lb_id=25-region-test&frontend_port_list=[80,90]&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置VIP: http://localhost:8080/slb/api?action=config_vip&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询VIP: http://localhost:8080/slb/api?action=query_vip_info&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"protocol":"tcp","port":80,"status":"stopped","config":{"scheduler":"rr","check":{"type":"vtcp"},"persistence_timeout":1000}},"msg":"successful"}
		查询VIP的健康状态: http://localhost:8080/slb/api?action=query_vip_healthcheck&frontend_port=80&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"rs_list":[]},"msg":"successful"}

		添加VM: http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22vm1%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=22-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"22-region-test","vm_list":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		查询VM信息: http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"weight":100,"vm_name":"vm1"}]},"msg":"successful"}
			注：ip与vm名称是一对一，如果为一对多则会出错。依据业务为准
			http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"53-region-test","vm_list":[]},"msg":"successful"}
		删除VM: http://localhost:8080/slb/api?action=delete_vm&vm_list=[%22vm1%22]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		切换VM: http://localhost:8080/slb/api?action=switch_vm&old_vm=[%22vm1%22]&new_vm=[{%22vm_name%22:%22vm2%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
			注：与文档说明返回不一致？			
		
		// hybrid
		添加Rule: http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=59-region-test&session=accessid1&sign=xx
			{"code":-2402,"msg":"RuleNotSupport"} //compact lb 不能添加rule
			http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=60-region-test&session=accessid1&sign=xx
			hybrid:http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool2%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","rule_id":"1-region-test"},{"name":"rule2","rule_id":"2-region-test"}]},"msg":"successful"}
		配置Rule: http://localhost:8080/slb/api?action=config_rule&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}
		查询Rule: http://localhost:8080/slb/api?action=query_rule_info&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","domain":"www.xxx.com","rs_pool_name":"rspool2","rule_id":"1-region-test","scheduler":"wrr","private_header":{"key2":"value2","key1":"value1"}},{"name":"rule2","domain":"www.abc.com","rs_pool_name":"rspool2","rule_id":"2-region-test","scheduler":"wrr"}]},"msg":"successful"}
		删除Rule: http://localhost:8080/slb/api?action=delete_rule&rule_name_list=[%22rule1%22]&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}

		// compact
		添加rs pool: http://localhost:8080/slb/api?action=create_rs_pool&name=rspool1&protocol=http&port=80&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"name":"rspool1","protocol":"http","port":80},"msg":"successful"}
			http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool2&protocol=http&port=80&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"name":"rspool2","protocol":"http","port":80},"msg":"successful"}
		查询RS POOL列表: http://localhost:8080/slb/api?action=list_rs_pool&vm_name=vm2&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":-2502,"msg":"RealServerParseError"}
			http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=60-region-test&region_no=region-test&session=cao.yin&sign=xx
			{"code":-2502,"msg":"RealServerParseError"} //SLB 后端bug，待修改
		添加rs 到 rs pool: http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool1&rs_list=[{%22vm_name%22:%22vm2%22}]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool2&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		从rs pool 删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool1&rs_list=[%22vm-tes1%22,%22vm-test2%22]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
		删除rs pool:http://localhost:8080/slb/api?action=delete_rs_pool&rs_pool_name=rspool2&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":-2505,"msg":"RspoolRuleExist"} //前提 删除rs pool配置的rule
		删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool2&rs_list=[%22ceqa-ag-0419160429%22]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		切换rs: http://localhost:8080/slb/api?action=switch_rs&rs_pool_name=rspool2&old_rs=[%22ceqa-ag-0419160429%22]&new_rs=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day33 Wednesday, May 02, 2012

1. 
	* SLB API action测试
		- vm 与 ip的转换，slbapi库的rs表ip与vm是一对一还是一对多？ select * from rs; ，一对一
	* 


2.系统错误提醒设计细化
	错误码提示易定位，人性化
	从总体设计异常提示。

3. 懂业务测试效率更高，特别对于具有依赖关系逻辑的测试。
	slb api测试中，不少用例的测试都是具有依赖关系的，需要前提条件满足才能继续下一个用例的测试
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day34 Thursday, May 03, 2012

1. 
	* slb api需要和vm api交互的地方，参看 云服务器api说明4.0版本
		比如用户调用slb api传递的是vm的名称，slb api层需要将name转换为ip传给slb后端，slb后端返回的数据中将vm的ip消息转换为vm的名称。
			vm api的测试账户？key ，id
			vm_name = DotProject-4661  / ceqa-ag-0419160429
				cao.yin
				cao.yin
				ec.api.url=http://10.230.204.65/open/services?
	* 上面替换的需求，需要定义查找的key名称，可以统一到常量中，避免硬编码 ？
	* jce open api 修改action时也同时需要到open api表去修改action的名称，哪里会先处理action的正确性。
	* 在 add rs vm,delete rs vm,switch rs vm 时本地rs表的数据是否正确变化也需要测试通过？
	* 一些依赖导致的错误，比如add_rs时需要先add_vm这样在rs表里会有ip与name的对应数据，否则报错，此时应该细化这个错误提示，不都是 sysytemerror ，客户端或者
	开发者自己也不便于debug
	* rs ,vm 删除时都要去删除rs表的记录，也要查询是否有冲突？
2. slb api需要做vm ip和vm name转换的地方，对比slb后端api与slb api
	add_vm //done
	delete_vm //done
	switch_vm //done
	query_vm_info //done
	query_vip_healthcheck //done
	add_rs //done
	delete_rs //done
	switch_rs //done
	query_rs_pool_info  (list_rs_pool) //done
	delete_rs_pool //done

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day35 Friday, May 04, 2012

1. 
	* 配置slb api日志，调用日志，业务日志分开
		api调用日志记录调用前后时间，按照设计的日志格式输出。可以在拦截器中记录调用日志
	* slb api配上签名验证
		测试例子：http://localhost:8080/slb/api?sign=kxUxw8Op%2B8TsTemi6qrknQ%3D%3D&timestamp=2012-05-04%2014%3A53%3A51&session=cao.yin&action=query_loadbalancer_info&lb_id=25-region-test&region_no=region-test&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-region-test","frontend_port":[],"eip":"42.120.64.225","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day36 Monday, May 07, 2012

1. 
	* slb api日志记录在log拦截器执行 
	* 在 10.230.204.24机子上部署测试
		目录为 /home/admin/slbapi
		编译: build/build.sh
		关闭/启动tomcat: bin/tomcatctl stop/start
		eg:
			http://10.230.204.24/slb/api?sign=7kes%2FcmCqF5ofzJkpsI7rg%3D%3D&timestamp=2012-05-07%2015%3A21%3A13&session=cao.yin&lb_id=8-region-test&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":-2610,"msg":"LbIdNotExist"}
			http://10.230.204.24/slb/api?sign=pp9LAo7fjImc9ge4NoIbmg%3D%3D&timestamp=2012-05-08%2009%3A43%3A35&session=cao.yin&lb_id=25-AT03-HOUYI1&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-AT03-HOUYI1","frontend_port":[],"eip":"42.120.64.197","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
	* 日志实现改为 将各处log项存入localthread中，最后记录log时，把log对象tostring即可。
		参考 http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLogHolder.java 实现
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLog.java
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.framework/src/main/java/com/aliyun/openapi/interceptor/LogInterceptor.java
	* slb api的region_no 问题
		AT03-HOUYI1,region-test 此值从slbapi库的region_mapping表中查询得到；将客户传递来的vm region转换为slb的region，对外统一用vm的region
	* rs表操作的测试，事务一致性测试
	* slb api上线需要做的工作：

2. slb api上线需要做的工作：部署
	(1)建库，建表，表订正
		slbapi库，表有：
			region(region_no ,region_name ,url ,status) slb api的region表，表示slb 的region(区别于vm的region)
			region_mapping(region_no ,vm_region_no) slb的region与vm region的映射关系表，根据vm的region找到slb的region
			rs(vm_name ,ip) 用来做负载均衡的vm服务器的名称对应的ip映射表(用户请求的vm名称通过调用vm的api得转换为其ip调用slb后端，slb后端返回时根据此表将ip转换回vm名称，即对外只提供vm名称的操作隐藏vm的ip)
			user( user_id ,user_name ,service_secret_key ,service_access_id  ,status ,is_admin) slb用户
			lb流量接口表：（这个表会存在多个实例吗？）
				monitor_datasource slb后端提供
		配置数据源：
			- slb api库数据源配置(库slbapi)
			- slb后端业务数据数据库源配置(xuanyuan)
			- 上面的 monitor_datasource 表中配置slb后端计量数据数据库源
	(2) svn下载默认目录结构，地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api/deploy-env
	(3) 将上面目录中的 slbapi 目录cp到 /home/admin 下
	(4) 进入 slbapi 目录
		cd /home/admin/slbapi
	(5) 执行build并部署: sh build/build.sh
	(6) 启动容器: sh bin/tomcattrl start/stop

3. rs的一些操作事务一致性测试
	参看文档，那些地方需要事务保证？
	* 涉及到rs表操作的地方 ，文档中有vm_name, vm_list 相关的地方，据此查到action
		query_vip_healthcheck
		add_vm
		delete_vm
		query_vm_info
		switch_vm
		add_rs
		delete_rs
		switch_rs
		query_rs_pool_info
	* 注意： -tip- sprint事务配置 ，配置方式 + 触发回滚方式: 异常抛出，异常回滚
			spring的事务回滚下面的配置是依据异常抛出来触发回滚的，如果catch了异常，没有抛出，则事务不会回滚，这点在
		程序逻辑上要控制好，适当的抛出需要回滚的异常。
	* spring事务配置例子：
	
		<?xml version="1.0" encoding="UTF-8"?>
		<beans xmlns="http://www.springframework.org/schema/beans"
			xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
			xmlns:aop="http://www.springframework.org/schema/aop"
			xmlns:jee="http://www.springframework.org/schema/jee" 
			xmlns:tx="http://www.springframework.org/schema/tx"
			xsi:schemaLocation="http://www.springframework.org/schema/beans 
			http://www.springframework.org/schema/beans/spring-beans.xsd
			http://www.springframework.org/schema/aop 
			http://www.springframework.org/schema/aop/spring-aop.xsd
			http://www.springframework.org/schema/jee
			http://www.springframework.org/schema/jee/spring-jee-2.5.xsd
		    http://www.springframework.org/schema/tx 
		    http://www.springframework.org/schema/tx/spring-tx-2.5.xsd">
		<tx:advice id="txAdvice4Ip" transaction-manager="transactionManager">
			<tx:attributes>
				<tx:method name="get*" read-only="true" />
				<tx:method name="assign*" rollback-for="Throwable" />
				<tx:method name="release*" rollback-for="Throwable" />
				<tx:method name="modify*" rollback-for="Throwable" />
				<tx:method name="bind*" rollback-for="Throwable" />
				<tx:method name="unBind*" rollback-for="Throwable" />
			</tx:attributes>
		</tx:advice>
		<aop:config>
			<aop:pointcut
				expression="execution(* com.aliyun.houyi.service.impl.IpAddressServiceImpl.*(..))"
				id="ipAddressPointCut" />
			<aop:advisor advice-ref="txAdvice4Ip" pointcut-ref="ipAddressPointCut" />
		</aop:config>
		<aop:config>
			<aop:pointcut id="instanceStatusPointcut"
				expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
			<aop:advisor advice-ref="instanceStatusInterceptor"
				pointcut-ref="instanceStatusPointcut" order="10" />
		</aop:config>
		...
		
		spring 编程式事务：
			-------
			...
				DefaultTransactionDefinition def = new DefaultTransactionDefinition(
						TransactionDefinition.PROPAGATION_REQUIRED);// 事务定义类

				String[] results = null;
				TransactionStatus status = transactionManager.getTransaction(def);
				try
				{
					results = InstanceServiceHelper.createInstances(this.instanceDao,
							noGenerator, this.instancePassworder, instance, count);
					transactionManager.commit(status);
				} catch (DuplicateNameException e)
				{
					transactionManager.rollback(status);
					throw e;
				} catch (Throwable e)
				{
					transactionManager.rollback(status);
					throw new BizException("创建VM发生错误！", e);
				}
			...
			-------
	* 

4. rs 增加删除混乱？	
	目前是有问题的：
		比如，进行更新rs的操作
	是否每次将每个action自己的vm name 与ip关系保存到当前线程中，用好即抛弃？
	可行性：
		是否每次action查询的vm name 与ip映射都满足当前操作。根据文档分析
		会存在返回其他ip的情况

	第二种方式：
		维护vm name 与ip的表，从houyi库里取得，只做查询，更新，不修改？

	
	有个业务前提：
			rs表删除某个记录(vm name - ip address mapping)时，在slb后端已经事先删除了，即在后续查询中，除了再插入这个映射记录，
		否则后端不会返回此ip。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day37 Tuesday, May 08, 2012

1. 
	* rs 重复add操作时，会无判断插入rs表记录，需要判断下，已有的话就跳过记录插入操作。
	* delete_rs_pool 操作如果poo不存在，返回什么？文档需要定义此返回值，现根据slb后端返回来处理 ，先后端也没定义，只是返回 systembusy 
	* slb backend文档修改 ，查看
	* 目前对action的参数合法性没有进行验证，直接调用了slb后端？
		需要实现 ActionValidator 接口，对每个action的参数验证，
		slb api 具有自己的错误码和msg ，还是依赖slb后端的错误码，只是桥接？
		slb后端也会进行验证，可参考


2. rs重复操作测试例子：
	删除没有执行成功，slb后端不是按照json格式解析rslist字段，只返回当前的rs配置。slb后端修改

	http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
	{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool3&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool3","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"} // 返回值为更新后的rs列表。如果传入列表中有已经添加的rs，直接忽略，不会报错
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}

	一个vm对应在多个rs pool中，此时在某个pool中删除这个vm，另一个pool的vm返回正确吗？
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool4&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool4","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool4&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool4","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	再执行一次：
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2100,"msg":"SystemError"} //后端对不存在的rs直接忽略，返回最新的rs列表

	http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2003,"msg":"system exception"}
3. action validator


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day38 Wednesday, May 09, 2012

1. 
	* action 的业务参数验证，由于slb后端会做业务参数验证，slb api不做验证
		如果要对每个action做各自的验证，可以在设计action时，提供公用方法通过spring IOC注入自己的validator，此时验证在执行action前操作；
		或者在拦截器层处理，可以在拦截器的上配置action名称对应的validator类。
	* slb api 文档与slb 后端文档在返回码参数定义上一致修正；compact，hybird文档独立
	* rs表在多个rs pool上都有同一个vm时，执行某个pool上删除此vm，导致其他pool再删除此vm时，ip映射不到name，
		解决：细化rs表，加入rs_pool_name ,lb_id分别用于rs操作和vm操作的ip映射,一标识各自的映射数据
			alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
			alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	* 单元测试 ,slb 后端调用加上单元测试
		在有改动时，便于发现问题 ，对于易变部分的逻辑更能体现其作用 ~
	* bug id #41
		由于cacheManage为null导致错误，系统用到cacheManage的地方暂不用。
		搜素整个project，处理
2. alter table
	修改表字段定义：
		sql server:
			alter table table_name alter column column_name varchar(200)
		mysql:
			alter table table_name modify column column_name varchar(100) 

	-- alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
	-- alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	-- alter table rs add id int(10) unsigned NOT NULL COMMENT '@desc id'
	-- alter table rs add vm_name varchar(32) NOT NULL COMMENT '@desc vm name'

	-- delete from rs;

	-- alter table rs modify column rs_pool_name varchar(100) COMMENT '@desc rs pool name'
	-- alter table rs modify column lb_id varchar(32) COMMENT '@desc lb_id'

	修改主键
	-- alter table rs drop column vm_name
	-- alter table rs add id int(10) unsigned NOT NULL AUTO_INCREMENT primary key COMMENT '@desc id'
	
3. remote debug跳不过去，地址不是同一地址 ~~~


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day39 Thursday, May 10, 2012

1.
	* 单元测试补充
		junit
			mock
			数据库测试
			执行顺序
	* 文档修改查看
2. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day40 Friday, May 11, 2012

1. 
	* create_vip
		delete_vip 后端参数名称修改：frontend_port 改为 frontend_port_list
	delete_vm文档定义需要修改 ，address参数不需要，weight不需要？

2. linux系统不同权限账户操作同一目录时注意，可以对导致其他用户不能访问，权限高账户创建的内容，导致任务失败。
比如root创建了某个文件，其他没权限的账户就不能删除，导致文件没有更新。-tip-
	例子：
		root账户编译部署了web应用，换个admin账户去做同样操作时，root创建的文件不能被更新。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day41 Monday, May 14, 2012

1. 
	* 大region了解
		数据中心随着业务增长，当前region不能放入更多vm，需要跨region，但逻辑上他们还是属于同一region，这样上层下发规则时，能对应到同region的vm。
		当前解决方式，把region规则上提到api层，在这层统一region。
	* houyi api 在vm迁移时需要刷新cache中的region信息以映射到新的region，在region定位接口，提供清楚指定资源的cache接口。 clear_cache

		缓存：AbstractResourceLocator 类的 resourceRegionCache 方法 (定位用)

		com.aliyun.houyi.service.ResourceLocator
			DefaultResourceLocator 和 AbstractResourceLocator中实现(/houyi-console-service)
			然后添加一个action(包位置：com.aliyun.houyi.openapi.control.vm)，并配置(/houyi-console-openapi):在spring里配置action这个bean，至于action请求映射配置由于用了
			代理方式依据配置bean的name来执行，故不用再到struts.xml中配置(只配置一个代理的访问入口)。
		action bean名为clear_cache
		需要定义接口说明，传递参数，返回值，状态码说明等。
			参考houyi api文档
			cache_key: vm名称
			cache_type:instance,ip,.. 要删除的cache实例类型，目前有instance,ip_segment,group,ip_address四种类型，默认为instance类型

			ClearCacheErrorMessage
			状态码可复用已有的比如vm中的vm_name验证状态码：VmErrorMessage
				-200	vm name must set	没有指定VM的名称
				-205	vm not exists	待操作的VM 不存在
			对于cache type需要另外定义：
				-283 cache类型不存在
				-284 清除cache失败
			resourceNO根据不同的cache类型对应不同的值，需要处理。
2. open jce bug fix 
	pojo属性拷贝错位。
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (RestOpenApiService.java:76) - JCE OpenAPI called , paramsMap={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]} siteId=wwg
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (OpenApplicatonControllerImpl.java:95) - set App Start Args is called. params={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]}
	2012-05-11 22:55:13,937   INFO [1700182798@qtp-980075617-11] (OpenApiFacadeServiceImpl.java:225) - openapi called. action: setAppStartArgs, siteId: wwg, params: com.aliyun.cloudengine.openapi.model.SetAppStartArgsParamExt@28e2b1e1[appId=66,startArgs=66]

3. vm api 测试地址
	http://10.230.204.65/open/services
	签名 ，vm name和slb一致

	例子：http://10.230.204.65/open/services?sign=gMnnRDw0%2FIu05Yr9NpM0SA%3D%3D&timestamp=2012-05-14%2020%3A41%3A56&cache_type=instance&session=cao.yin&cache_key=AT03-HOUYI1&action=clear_cache&format=json
		{"code":-284,"data":null,"msg":"cache of this key not exist"}
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day42 Tuesday, May 15, 2012

1. 
	* slb api 加入流量查询接口2个，参考v1的文档：
		指定时间段查询负载均衡流量 query_loadbalancer_flow
		指定时间段批量获取负载均衡流量 list_loadbalancer_flows
		从数据库获取，参考v1版本，不需要调用slb后端

	* jce open api api表修改配置错误，并检查其他配置是否有误
	* slb 后端文档修改：
		- 查询vm接口删除，把其原先返回内容放到查询loadbalance信息接口的返回结果中
		- 查询rs信息接口删除，同时修改了查询rs pool信息的uri

2. lb流量查询的数据源
	是否和slb open api的库一致，还是需要再配个数据源？需要配置到数据库中，每个slb都有一个库；和操作slb后端api地址一样，每个slb是不同的地址。
	先根据基本datasource配置（维护monitor_datasource表(需要订正维护)，和rs表同在一个库中），取得所有region的datasource配置，然后动态返回对应region_no的数据源(slb后端的数据源)。

	* 验证上面到slb后端取数据的sql字段是否与slb后端的表结构一致，参考slb后端数据库表。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day43 Wednesday, May 16, 2012

1. 
	* slb api
		- 流量接口sql与后端表核对
		- 从slb后端得到region的数据源地址配置，并配置到monitor_datasource表中
			10.230.130.1 root/654123 xuanyuan_monitor
			insert  into monitor_datasource 
				(url,username,passwd,region_no) 
			values('jdbc:mysql://10.230.130.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8','root','654123','AT03-HOUYI1')
		- api文档修改
		- regionno从vm转为lb的region
	* slb api部署 day36

2. lb region ，slb api这层的region概念
	lb region在slbapi库region表里管理

3. 测试新加入的lb流量接口
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+10%3a10%3a10&end_time=2012-05-06+12%3a10%3a10&lb_id=31-region-test&&session=cao.yin&sign=xx

4. sql 对照
	LBMonitor.queryL4Flow —— vip_stats_xxx
	LBMonitor.queryL7Flow —— haproxy_rule_stats_xxx
	LBMonitor.loadBalancerCount —— loadbalancer
	
	lb_id 改为 lb_global_id
	
	loadbalancer 表在哪里?
	
5. tomcat报错一例，uri参数格式错误
	invalid chunk starting at byte
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&=4
6. jdbc url 过个空格 ，报错 
	Cannot create JDBC driver of class 'com.mysql.jdbc.Driver' for connect URL ' jdbc:mysql://10.230.130
	.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8'
	java.sql.SQLException: No suitable driver

	一个简单问题，复杂了太多，源于告知 No suitable driver == 驱动没找对 ，忽略了 url错误也是报这个错 ，汗
	+无语

6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day44 Thursday, May 17, 2012

1. 
	* 测试
	* slb后端分计量数据的库 和 业务数据的库
		即在LB流量接口的查询中，用到这两个库
			业务库配置：
				mysql -uroot -p654123 -h10.230.130.129 xuanyuan

		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；

	* lb后端创建lb时，去掉name参数，api需要做相应修改，api文档修改
	* 了解大region需求

	* vm api 之前实现了清除cache的action，现在需要确认是否也能把预加载的region去掉？
		houyi-console-openapi
		
2. 
	select sum(in_bytes) as tcp_internet_rx,lb_global_id      
	from  `vip_stats_20120506`      
	where lb_global_id='57-tr' 
	and user_id=235 
	and (gmt_create between '2012-05-06 05:10:10' and '2012-05-06 12:10:10')        
	group by lb_global_id

	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"tcp_internet_bandwidth":0,"http_internet_rx":0,"end_time":"2012-05-06 23:10:10","http_internet_bandwidth":0,"tcp_internet_tx":0,"lb_id":"83-tr","start_time":"2012-05-06 05:10:10","http_internet_tx":0,"tcp_internet_rx":477},"msg":"successful"}

	http://localhost:8080/slb/api?action=list_loadbalancer_flows&page_no=1&page_size=10&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"total":32,"page_size":10,"end_time":"2012-05-06 23:10:10","start_time":"2012-05-06 05:10:10","page_no":1,"loadbalancers":[{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"1","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"2","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"3","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"4","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"5","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"6","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"7","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"8","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"9","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"10","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0}]},"msg":"successful"}

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day45 Friday, May 18, 2012

1. 
	* slb api cache region启用修改
		bug 41 继续报错

	* houyi防火墙规则了解，大region相关业务点熟悉
	* slb后端api user_id必选，rs_type参数名改为mode ，对api这层做相应调整(代码+文档)

2. 虚拟化
	防火墙规则



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day46 Monday, May 21, 2012
1. 
	* vm 内部接口文档整理
	* 大region设计预查看
		对比加入大region前后 vm api流程操作的区别，比如 create_img，原来逻辑哪里需要修改？预分析
		首先要了解原来的流程

	* vm region cache 清除接口是否需要做操作控制？
		属于某个用户的vm的缓存自己能清除，否则某个用户可以把别的缓存清除。再或者只留给内部调用，不需要控制。
	* slb后端文档修改，slb api文档也做相应修改：健康检查查询接口frontend_port必选之后，url也应相应变化
	* 

2. 新浪云计算(关于配额系统，系统稳定摘取)：sina app engine
		日志和统计中心：负责对用户所使用的所有服务进行统计和资源计费，并设定的分钟配额，来判定是否有非正常的使用。
	分钟配额描述了资源消耗的速度，当资源消耗的速度到达一个预警阈值时，SAE通知系统会提前向用户发出一个警告，提醒用
	户应用在某个服务上的使用可能存在问题，需要介入关注或处理，配额系统是SAE用来保证整个平台稳定的措施之一；日志中心
	负责将用户所有服务的日志汇总并备份，并提供检索查询服务。

	配额细化到每个调用者(用户)，以保证稳定持久的服务。

3. 消息中间件 MQ
	云服务器api
	/houyi-console-message

	<dependency>
		<groupId>com.rabbitmq</groupId>
		<artifactId>amqp-client</artifactId>
	</dependency>

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day47 Tuesday, May 22, 2012

1. 
	* big region 分3此迭代开发(测试尽早介入)  —— 具体见邮件
		对开发部分，做设计文档说明(程序流程，控制)，便于测试
		对于设计文档：
			- 参考已有文档说明及程序实现
		数据库：
			xuanyuan
	* big region 需求评审会议
		处理开发迭代1/3涉及的接口修改。
	* big region
		项目管理页面：http://redmine.aliyun-inc.com/projects/vm wb_shen.chengs 域密码
	* slb v2换build，此次改动较大，请前端注意查看最新的文档
		1) rs_type->mode; 2) 去掉rule_name(待修改文档？)
		
2. 业务
	云服务器 产品 - 通过api操作操作云服务器
	ACE云引擎产品 - 目前包含php,node.js,java(JCE)应用环境，基于云服务器产品之上

3.迭代一修改的地方列表如下：
	背景信息
	
	* cluster_id
			之前用户传入小region，以给api查找region；现在用户传入大region，api需要定位到小region，通过用户传入的cluster_id
		在zone表里找到对应的region_no。
			api操作需要定位到region，然后执行操作。

	* API 数据库在zone表增加cluster_id的初始化，记录每个zone_no对应的cluster_id。
		device_no改成：cluster_id-device_no；
		snapshot_id改成：cluster_id-device_no-snapshot_id；
		nc_id改成：cluster_id-nc_id
	* action的执行从AbstractExecuteAction的doExecute()方法开始，具体实现由子类action的execute方法处理。
		
	- snapshotid等格式设计(API)
	- add_disk时解析并拆分用户传入的snapshot_id
		处理请求的snapshot_id和响应结果中的device_no
		cluster_id由用户传递过来，那个地方需要用到？
		AddDiskExecuteAction

	- 查询VM设备接口，返回的device_no格式变成cluster_id-device_no
		query_vm_device
		QueryVmDeviceExecuteAction

	- 创建snapshot接口，解析并拆分传递的device_no参数
		CreateSnapshotExecuteAction
	- 取消创建snapshot接口，解析并拆分传递的snapshot_id参数
		CancelCreateSnapshotExecuteAction

	- 查询设备已有的快照接口(list_snapshot)，解析并拆分传递的device_no参数，并修改返回值中snapshot_id的格式
		ListSnapshotExecuteAction
	- 查询快照详情接口，解析并拆分传递的snapshot_id参数，并修改返回值中snapshot_id格式
		DetailSnapshotExecuteAction
	- 删除快照接口，解析并拆分传递的snapshot_id,device_no参数
		RemoveSnapshotExecuteAction
	- 回滚快照接口，解析并拆分传递的snapshot_id,device_no参数
		RollbackSnapshotExecuteAction
	- 保留快照接口，解析并拆分传递的snapshot_id,device_no参数
		RetainSnapshotExecuteAction
	- 查看已挂载的快照接口(list_mounted_snapshot),修改返回值中device_no格式
		ListMountedSnapshotExecuteAction
	- 挂载快照接口(mount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		MountSnapshotExecuteAction
	- 卸载快照接口(unmount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		UnmountSnapshotExecuteAction
	- 在线迁移接口( live_migrate_vm),解析并拆分传递的nc_id参数
		VmLiveMigrateExecuteAction
	- 故障迁移接口，解析并拆分参数destination_nc,destination_rack，并修改返回值中nc_id格式
		recover_vm
		VmRecoverExecuteAction
		
	- 查询可切换的nc接口，修改返回值中nc_id格式
		QueryAvaliableNcsExecuteAction
	- 查询nc详情(detail_nc)接口，解析并拆分传递的nc_id参数，并修改返回值中nc_id格式
		到houyi-openapi.xml找对应关系
		SingleNcResourceAction
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day48 Wednesday, May 23, 2012

1. 
	* big region需求分解，要做哪些工作？
		- 拦截器处理region时，根据： cluster_id-device_no； cluster_id-device_no-snapshot_id； cluster_id-nc_id
		   得到cluster_id，再到zone表查询得到region_no,再到region表得到小region信息(对外大region，内部暂还是小region)。
		- 设计文档

	* slb后端文档修改：
		create_rule: rule_list中去掉rule_name字段
			相关的delete_rule的修改：
				去掉原来的rule_name_list 改为 domain_list
			query_rule_info文档说明修改
		config_rule: domain由可选改为必选

		open api文档需要做相应修改
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day49 Thursday, May 24, 2012

1. 
	* 继续迭代1文档及action流程整理


2. select * from `group`
group是mysql的关键词

3. visio描述简单流程图


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day50 Friday, May 25, 2012

1. 
	* 文档整理，今天整理结束
		文档根据项目模板文档要求修改
	* uml seq图流程基本类似，修改相应地方即可
	* slb后端 待？
	昨天跟aliyun.com的同事讨论之后，对query_healthcheck这个接口做了比较大的调整。已经提交了。你们注意相应的修改。
	另外 之前讨论所提到的“将一个rs从slb中删除”的接口(release_rs)，一直漏了，今天也添加到文档中了。
2. 业务关键点 理解 大region
	add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过snapshot_id得到其所属的region，然后进行相应操作

	这也是大region需要参数修改，参数如是修改的目的。-tip-

	大region需求分析：
		小region时,open api根据用户传入的资源（region_no）来定位region信息，后续的操作都是在此小region内执行的，即不跨region调用。
		随着业务增长，小region已不能满足业务上需要容纳更多的vm的需求，现需要在open api层实现跨region调用，这样对外就是一个大region，
	open api下一层还是小region结构。
		由上面跨region调用的需求结合内部是小region实现，现通过修改接口参数（在参数上携带cluster_id）以便open api通过请求参数定位资源
	所在的region，从而完成跨region操作。（比如：add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过
	snapshot_id得到其所属的region，然后进行相应操作），同时对应返回结果也做相应调整。


3. houyi open api部分在内部文档，或者过期文档中
	比如：list_mounted_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Monday, May 28, 2012

1. 
	* big region 参数修改文档再修订，加入4个接口修改说明
		修改文档
	* slb release_rs接口实现包含测试用例，并修改相应文档
	* meeting，修改文档
	
2. 添加4个接口
	解析并拆分创建VM（create_vm）接口用户传入的nc_id和rack_id参数
		
	解析并组装list_vm_status接口返回的nc_id
		
	解析并组装detail_vm接口返回的rack_id，nc_id
		
	解析并拆分调用remove_disk接口用户传入的device_no参数
		
		
3. spring 编程式事务

4. 业务 概念 清晰
	VM	Virtual Machine	虚拟机	通过物理服务器，采用虚拟化技术虚拟出来的计算机
	RS	Real server	后端服务器	用来做负载均衡的VM服务器

	2个对比，理解rs即用于slb的vm，实际就是vm。
	
	add_rs即添加一个vm作为slb负载均衡用~ 
	release_rs即在负载均衡集群中去掉一台vm（这里的去掉应该就是删除vm自身，具体看下面说明）

	delete_rs是从rspool删除rs，release rs是前端删掉一台vm后，清掉所有与他相关的slb配置，
	包括rspool里的rs，也包括loadbalancer里的vm
	
	zone属于某个region，是多对一的关系，cluster_id和region_no是一对一

	houyi api部分涉及权限的操作是在zone内进行的，即不跨zone，比如：迁移，

5. NIO
	解决同步IO资源耗尽问题 ，open api 等场景部分优化
	消息
	并发处理
	阻塞操作
	http://www.cnblogs.com/phoebus0501/archive/2010/12/05/1897245.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Tuesday, May 29, 2012

1. 
	* 在处理参数时，注意新老存储的调用兼容性 ，比如老存储的api调用是没有snapshot_id参数的，如果解析抽象出来要
	考虑到这个情况。
	
2. 
	几个概念
		cluster	一个集群
		rack		机架
		region	数据中心	代表一个数据中心或者Houyi集群，不同数据中心的VM不能相互访问
		zone		安全域		代表一个安全域，不同安全域的VM不能进行数据迁移
		group	安全组		VM相关的安全组，一个VM一定属于某个安全控制组

	之间的关系理清楚？
		* 一个cluster对应一个region(小region)，多个region对外统一为一个大region
		* region和zone是一对多的关系？zone是网络用的概念，一个region下有多个zone，zone和cluster_id是一对一关系
		* region与group是一对多关系 ( group表中有region_no,user_id字段)
		* 从user层面看，user_id与group是一对多关系，某个user_id的group可以跨region
			目前，权限是对group授权(后面再加上到vm的授权)，
			授权源group的某个端口可以在公网(或者私网)网口通过某种协议访问目标group的某个端口的规则(accept，drop，reject)。
		* 
	tip：
		可以从库表中反应它们间一定的关系 :)
	
	api层只有region的概念，houyi后端有cluster_id概念？
	
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day52 Wednesday, May 30, 2012

1. 
	* 基于参数修改设计文档，设计逻辑实现：
		- 对于组合参数的解析，提供静态一个工具类方法，传入参数值和预知的组合个数，返回参数值依据“-”分割
			 后的结果数组
		- 封装一个service用于查询从cluster_id得到region_no
		- 返回值的处理封装：在action层统一处理，实现方式：
			在action的父类里实现，提供一个公用的方法处理。
		- 尽量避免不必要的网络交互（eg：访问数据库，访问网络上的其他service服务）
		- 
	* 整理houyi open api定位到region的规则
			现有2个api，北京那边api（不升级），杭州这边api（要升级），准备在2个api之上，用一个类似路由程序来统一接受访问api的请求，
		并根据预定规则，将请求转发给老api或者新api，故需要整理这个路由的规则，让其能判断某个请求是到老api还是新api的？
			新老版本如何共享一个DB？
				有没有表操作冲突，看数据库的改动。
			规则分析如下：
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				可供识别的条件有：（类似RegionAwareIntercept定位region的逻辑）
					- 首先根据所查询的资源(open api库)
						1) vm_name - 根据vm_name查询instance表
							select
								d.instance_id,d.instance_no,d.image_id,d.status,d.status_comment,d.ip_address,d.group_id,d.node_id,d.mount_type,d.type_id,d.usage_type,
								d.user_id,d.kernel_id,d.ramdisk_id,d.platform,d.passwd,d.start_to_passwd,d.gmt_modified,d.gmt_create,d.remark,d.zone_id,d.vlan_no,d.region_no,
								d.group_no,d.bps,d.rx,d.tx,d.rx_pub,d.tx_pub,d.cores,d.mem,d.disk,d.image_device_no,d.recoverable,d.ballon_enable,d.recover_policy,d.rack_id,d.safety_quota,d.intensive_io,
								d.hostname,d.intensive_cpu,d.intensive_net,a.image_no,a.image_name,a.location as image_location,a.version as image_version,a.services_sign as image_servicesSign,
								a.image_size,a.base_image_id,a.snapshot_id,a.sys_driver,a.region_no as image_region_no,a.iso_id as iso_id,b.image_no as kernel_no,b.image_name as kernel_name,b.location as kernel_location,c.image_no as ramdisk_no,c.image_name as ramdisk_name,
								c.location as ramdisk_location,k.key_pair_id,k.key_pair_name,k.public_key,d.nc_id,d.machine_no,d.machine_no,d.is_balloon,d.is_migrate,d.is_upgrade,d.startup_mode
							from instance d
							left outer join image a on d.image_id=a.image_id
							left outer join image b on d.kernel_id=b.image_id
							left outer join image c on d.ramdisk_id=c.image_id 
							left outer join key_pair k on d.key_pair_id=k.key_pair_id 
							where d.instance_no=#value#
							?instance_no不是region_no

						2)  ip - 根据ip查询zone_ip表得出ip所在的段的记录，从而得到其所属region
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #value# and ip_end >= #value#
							limit 1

						3)  group_no  根据group_no,user_id,region_no查询group表（由于需要region_no，故此资源的操作可被region_no代替）
							select 
								group_id,
								group_no,
								user_id,
								description,
								region_no 
							from `group` 
							where user_id=#userId# and group_no=#groupNo# and region_no=#regionNo#
							order by region_no,group_no desc

						4)  ip_segment 根据CIDR地址ip地址查询zone_ip表
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #ipBegin# and ip_end >= #ipEnd#
							limit 1
							结果例子：
								| zone_id       | region_no   | zone_ip_segment | ip_begin  | ip_end    |
								+---------------+-------------+-----------------+-----------+-----------+
								| region-test-a | region-test | 10.249.130.0/24 | 184123904 | 184124159 
					- 根据用户请求参数region_no
						region_no - 根据region_no查询
					- 根据调用者（user）
						比如query_region接口只能通过user信息定位region，user信息可以根据session参数查询houyi open api数据库得到
						但是，用户会在北京region和杭州region都有vm吗？

					上面，只是得到了用户所要请求的是那个region，还需要判断这个region是老api的，还是新api的？
						背景：
							原来api只有一个入口一个版本，现在api会有2个入口且版本不一致但DB公用；路由层需要一个映射——根据region转发请求到相应的api。

						是不是需要维护一张region和api地址的映射表，路由根据region_no从此表找到转发地址？

						
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				还要考虑到用户传错参数的情况
				
				结果：
					优先根据region_no定位老api（北京）还是新api（杭州）
					再根据vm_name
					最后根据user所在的region

					要维护region和其对应的是老api，还是新api类型的映射关系表，不然只能到各自数据中心的region表查询是否存在，目前只部署一个点，
					故可以从唯一的库中查询。

2. 对于修改设计的实现设计部分细节分析
	* 返回值修改
			现有逻辑，已有一个从后端调用结果到api结果pojo对象转换的逻辑(在action层中，有的是map方式转，格局返回类型不同转换方式各异)，
		可以考虑在后端数据类型转换为api pojo时，进行我们需要的参数修改需求。eg: SnapshotApi
			现在，在那个位置统一处理好？影响小，透明化，易理解，好维护
				- 现定义在返回执行统一转换
				- 被转换的源类型包含多种(map,list,其他)
					通过方法多态，提供通用几种类型的方法，对于参数个数不一致，通过可变长参数实现
				- 被转换参数一个或者多个

			
3. houyi open api常量类设计分析
		对于一些常量，状态值的设计定义，减少硬编码：通过枚举定义一些常量，或者一组状态；通过一个接口定义枚举
	基本机构。
		* 枚举定义一些基本常量 eg: InstanceStatus定义vm的状态（待启动，启动中，运行中等）
		* 如果在上面基础上需要组合一组常量，为一个状态，通过往枚举的构造总放入数组即可
			eg: InstanceStatusSet定义vm可启动状态集合（包含：待启动，启动失败，已停止3个状态）

4. api操作权限控制 acl	
	通过注解设置service操作权限，再通过在spring里配置此注解到pointcut，拦截操作，判断权限
	
	spring + annotation + aop 实现权限与业务分离，注解配置权限点，通过aop拦截包含这些注解的方法的执行，校验权限，继续执行。
	被操作的对象（比如instance）有属性InstanceStatus（instance状态常量定义枚举）标记其状态，拦截器判断被操作的instance是否在允许的
	状态中，以判断操作是否可进行（比如mount_disk操作，instance只能在特定的状态下）。

	key words: expression="@annotation(
	
	<bean id="resourceQueryFacade" class="com.aliyun.houyi.acl.ResourceQueryFacade"/>
	
	<bean id="resourceSurveyor" class="com.aliyun.houyi.acl.ResourceSurveyor">
    		<property name="resourceQueryFacade" ref="resourceQueryFacade"></property>
	</bean>

	<bean id="instanceStatusInterceptor" class="com.aliyun.houyi.service.rule.InstanceStatusInterceptor">
		<property name="resourceSurveyor" ref="resourceSurveyor"/>
	</bean>

	<aop:config>
		<aop:pointcut id="instanceStatusPointcut"
			expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
		<aop:advisor advice-ref="instanceStatusInterceptor"
			pointcut-ref="instanceStatusPointcut" order="10" />
	</aop:config>	
	
	参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day53 Thursday, May 31, 2012

1. 
	* region定位规则，并细化步骤，便于路由部分参考
		实现可以不一样，逻辑基本一致。
	* 除了db公用冲突分析外，是否还有其他地方需要考虑？
		考虑大region关于open api的需求还有那些地方可能会影响？
			迭代2,3需要评估
	* 后端mock：
		调用houyi后端的mock实现。
		对 ApsaraCommandExecutor 进行mock
			保证传递进去的参数是正确的，mock出预期的返回，便于测试。
	* 迭代2

	* slb release_rs接口url及参数名称修改 done
	
2. 
	分析迭代2部分需求：
			原来的概念，上了大region都会改变，比如原来查询某个region下某个zone中的vlan信息，大region后
		要查询的就是这个用户在大数据中心所有的zone下的vlan信息。
	

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day54 Friday, June 01, 2012

1. 
	* 迭代1新增需求分析
		1）不停机升级云服务器配置，重启生效	API对modify_vm接口操作的VM前置状态增加running条件 1
		2）SLB的L4 VIP不能配置健康检查的问题 1
		3）因为machine_no（随机字段）这个值存在重复性，启用新的算法(类似于UUID类的算法)，保证生成的machine_no是不会重复的 2
		4）支持动态添加新region信息，不需要重启 1  动态添加新region信息
			是否有添加region这个接口？
				houyi.region表是手动插入记录
				没有这个接口，需要设计方案；RegionValuesFactory里的region缓存，如何在region表手动插入记录时，更新RegionValuesFactory里region
				缓存？
					a. 定时刷新
					b. 缓存找不到就去数据库找，若找到则加入缓存，找不到则返回相应的结果。




	* 迭代2需求，各接口流程梳理
	* 查询slb后端业务表的数据源，可能有多个的情况，配置在数据库中，根据不同的slb region调用不同的数据源。？待
2. 
	slb 测试环境：
		
		mysql
			mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi

	http://workflow.it.alibaba-inc.com/StartWorkflow.ashx?wfid=dfdd6d75-e539-4cb6-a289-a01eaaa5b426
	服务类型，新开令牌；需求权限，内网默认权限

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day55 Monday, June 04, 2012

1. 
	* 迭代1新增需求分析 见day54第1条
		详见迭代一新增需求文档（doc）
	* 将分支：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_btc_migrate/中clear_cache接口代码加到分支	
	   http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_update_struts上。
		拉api_update_struts的代码，并更新上clear_cache接口
	* slb后端会部署多个slb，每个slb对应一个计量库，一个业务库； 参考day42 slb 流量
		一个slb对应多个vm，每个vm可能位于不同的region。
		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；
		？
		monitor_datasource表，就是保存了每个slb，其region_no对应的取流量数据库的地址映射。
			monitor_datasource的region_no指的是slb的region，不能和vm的混淆；region表里都是slb的信息，唯一vm和slb region有关系的就是region_mapping表，表示了vm region和slb
			region的映射。

		参考解决方案：
			1）在monitor_datasource表加个type字段，用以标识slb后端数据库类型（0-业务库；1-计量库）；在LBMonitorSqlMapTemplateFactory里，
			     初始化slb region对应的2个库的sqlmapclient实例。
			2）slb后端提供查询接口，这样传入user_id，分页参数即可（region表定义了到那个url上去取数据）
	* slb open api bugfix
		delete_loadbalance 接口，同时清除LoadBalancer相关的配置——对应open api层也要清理rs表。

2. redmine 任务列表
	拉分支 ：
	【代码SVN路径】
		houyi-api: http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_big_region
		控制系统：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/houyi/branches/ec_big_region
	
	list_vlan 第三周期？

3. cache不便于查找 缓存方案 cache方案
	RegionValuesFactory - CachedRegionValuesFactory 
	region 缓存

	如果系统有多处需要使用cache，可以考虑使用一种cache框架，统一cache使用方案。-tip-
		参考：http://www.cnblogs.com/ieage/archive/2012/05/20/2509454.html

4. maven 跳过test ？
	No goals needed for project - skipping


5. LB,RS,RS_POOL,VIP之间什么关系？待
	从delete_loadbalance接口需要删除那些相关东西入手
	
	看下面query_rs_ pool_info的结果截取：
		{
		"name":"testpool1",
		"protocol":"http",
		"port":80,
		"vips":[{"lb_id":"1377236b076-region1","frontend_port":80,"rules":["www.wqwqwq2.com","www.wqwqwq1.com","www.wqwqwq3.com"]}],
		"realservers":[{"address":"192.168.1.28","weight":100}]
		}
	一个rs pool对应多个vip，多个rs
	删除LB,是否也删除rs_pool？不用，rs pool为用户自己管理
	删除rs pool时，需要删除rs。
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day56 Tuesday, June 05, 2012

1. 
	* 迭代一开发 开始
	* slb open api bugfix
		表修改：
			alter table rs modify column vm_name varchar(50);
			alter table rs modify column ip varchar(15);
			alter table rs modify column lb_id varchar(110);
	
2. 迭代一开发记录
	结果处理：
		操作成功才需要修改返回内容，操作失败时，只返回错误码和状态，没有结果。
	返回码修改：
		由于参数格式修改，需要修改部分返回码的错误提示。
	结合jtester框架测试
		service层mock后端执行的返回值：mock后端返回值
			后端返回格式，参考每个command里的代码，比如：CreateSnapshotCommand ，这些命令都继承自 AbstractCommand
	service层的测试，对于内部私有类，可以通过替sprintg配置来实现mock。
		如果mock返回的类型不是预期，可以考虑让mock类实现相应的接口。
	测试环境
		测试依赖的配置文件，有一部分在用户目录下，需要在spring配置文件中配置正确。

	- 4.2	查询VM的设备接口（query_vm_device）
		* /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/InstanceServiceImpl.java
			queryDevice方法修改
		* zonedaoimpl
		* ZoneDaoImplTest
			jtester测试通过
		* zoneservice / zoneserviceimpl
		* /houyi-console-model/src/main/java/com/aliyun/houyi/entity/Zone.java 加上clusterId属性
		* zone表加cluster_id字段【sql 修改】
			alter table zone add cluster_id varchar(32) NOT NULL;
		* /houyi-console-util/src/main/java/com/aliyun/houyi/util/ResultParseUtil.java 工具类 ，处理返回值装配
		* QueryVmDeviceExecuteAction
			取得cluster_id，修改返回值
			待测
				dao
				service
				action
				util工具类
					单元测试通过
	- 4.3	磁盘创建snapshot接口（create_snapshot）
		* 修改错误码：
			SnapshotErrorMessage
			DEVICE_IS_NULL(-900, "device No. is null"), ——》 改为：DEVICE_IS_NOT_ILLEGAL(-900, "device No. is not illegal"),
		* CreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"), DOC
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		* 修改错误码：
			SNAPSHOT_IS_NULL(-920, "snapshot is null"), ——》改为： SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"),
		* CancelCreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
	- 4.1	add_disk接口
		* AddDiskExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
		

3. maven 跨项目test
	独自测试依赖问题？

4. jtester测试 参考： * jtester

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day57 Wednesday, June 06, 2012

1. 
	* 迭代一开发
	* slb bugfix
		slb后端对于错误的url就直接返回原始错误，比如404之类；这样，open api这里需要保证url的准确性。

2. 迭代一开发记录
	- 4.5	查询设备已有的快照接口(list_snapshot)
		ListSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),  DOC
	- 4.6	查询快照详情接口（detail_snapshot）
		SnapshotService
			mock测试
			主要是mock每个action相应的command执行结果，这个结果参考相应action的command中处理返回值的代码。比如：此接口参考 QuerySnapshotCommand （由于缺少后端接口说明）结果处理，处理结果
			？

		DetailSnapshotExecuteAction 
			待测
		状态码修改：
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法			
	- 4.7	删除快照接口（remove_snapshot）
		AbstractSnapshotExecuteAction 涉及deviceNo，需要修改
		RemoveSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法	
	- 4.8	回滚快照接口（rollback_snapshot）
		RollbackSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法		
	- 4.9	保留快照接口（retain_snapshot）
		SnapshotService
		RetainSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法

3. spring，资源文件加载 问题
	如果导入资源文件的配置文件没有初始化，提前处理调用资源文件会报错：
		eg: jtester抽象父类，初始化spring context时。

	mock复杂的私有内部类时，通过新建一个类（继承原来的类）来mock，配置时初始化由于早于属性文件导入，报了错。放到属性文件加载之后即可。

4. 设计中测试的考虑


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day58 Thursday, June 07, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		SnapshotService
		ListMountedSnapshotExecuteAction
			待测
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotService
		MountSnapshotExecuteAction
		？snapshot 和 snapshot_id混用？
			String snapshot = ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT);
			if(StringUtils.isEmpty(snapshot)){
				 snapshot=ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT_ID);
			}
			—— 查看过期API，是因为兼容老api，snapshot已废弃被snapshot_id替代
				按照当前逻辑，如果新旧参数都传了，还是以旧参数为准 ，其他接口一样，这点要注意。（以最新参数为准较好？）
		状态码修改：
			ILLEGAL_DEVICE_NO(-901,"illegal device no") DOC
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id ") DOC
	- 4.13	在线迁移接口( live_migrate_vm)
		InstanceService
		VmLiveMigrateExecuteAction
		状态码修改：
			增加错误码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), 表示迁移时需要在同一个region中 ？ DOC
					迁移目标NC和当前instance不在同一个region中
					注：这个与对外是一个大region矛盾，是否处理可迁移的nc列表，不包含不可迁移的nc？还是只供内部用？
				ILLEGAL_NC(-731,"illegal nc"),
			待测
	- 4.15	查询可切换的nc接口（query_available_nc）
		QueryAvaliableNcsExecuteAction
			待测
	- 4.16	查询nc详情(detail_nc)接口 (houyi-openapi.xml)
		NodeControlService
		SingleNcResourceAction
		状态码修改：NcErrorMessage 
				NC_NO_IS_NULL(-730, "nc_no is null"), —— 》NC_NO_IS_NOT_ILLEGAL(-730, "nc_no is not illegal"), DOC
			待测
	- 4.17	创建VM（create_vm）接口 
		VmCreateExecuteAction
			逻辑在getInstanceInfo方法里
		RackServiceImpl
		状态码修改：
			增加状态提示：
				GlobalErrorMessage NO_IN_THE_SAME_REGION (-142, "not in the same region"), DOC
				当rack的region和nc的region不一致时报错。
			待测
	- 4.14	故障切换接口（recover_vm）
		状态码修改：
			增加状态码：
				NcErrorMessage RACK_ID_NOT_ILLEGAL(-719,"rack is not illegal"), DOC
					rack_id格式不合法（destination_rack）
			增加状态码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), DOC
					nc region 和intance region不一致。
		InstanceServiceImpl
		VmRecoverExecuteAction
			待测
	- query_racks action也要改动？ 多态一个，此接口暂不变。

3. 对于service层的 public CommandExecutor commandExecutor; mock费了不少时间，由于此属性的注入方式是通过一个工厂（CommandExecutorFactory）获得（spring的beanfactory接口的实现）
mock这个工厂取得commandExecutor对应的实例对象时，返回的却是这个工厂的类型，不是CommandExecutor的实现类。
		工厂内部通过一个私有内部类来得到真正的CommandExecutor实现类（不便mock），最后通过把这个工厂类的配置单独提出来，写一个mock类继承CommandExecutorFactory，并测试时
	配置为工厂的mock类，这样测试能通过。
		但是这个工厂需要根据场景返回不同的CommandExecutor实现类，不便于每次测试去修改mock类。
		debug发现在测试类中再去mock一下这个mock类时，返回的是其自身，转型时不能转为CommandExecutor类型，于是让这个工厂mock类实现CommandExecutor接口。
4. 
	拦截器mock
		如果不便于mock，则找到其内部关键点进行mock。
	mock里面嵌套mock 是否可行？不必要，正确mock了某个类，可以忽略其内部逻辑。

5. mock 与 expections 结合 jmockit ,jtester
	mock对象，编写期望 expections 。
		-------
		...
			@SpringBeanByName
			QueryVmDeviceExecuteAction query_vm_device;
			
		//	@Mocked
		//	@SpringBeanFor
		//	InstanceService instanceService;
			
			@Mocked
			@SpringBeanFor
			ZoneService zoneService;
			
			@SuppressWarnings("unchecked")
			@Test
			public void testExecute() throws Throwable{

				final Result<PagingInfo<DeviceEx,DeviceEx>> expectedDeviceResult = new Result<PagingInfo<DeviceEx,DeviceEx>>();
				expectedDeviceResult.setSuccessful(true);
				expectedDeviceResult.setResultInfo(new PagingInfo<DeviceEx, DeviceEx>(){
					@Override
					public List<DeviceEx> getItems() {
						List<DeviceEx> list = new ArrayList<DeviceEx>();
						list.add(new DeviceEx(10,1024,"System"));
						list.add(new DeviceEx(11,512,"System"));
						list.add(new DeviceEx(12,256,"System"));
						return list;
					}
				});
				
				final String expectedClusterId = "testClusterId";
				final ResultMessage expected = ResultMessage.SUCCESSFUL;
				
				final Instance instance = new Instance();
				instance.setInstanceNo("testNo");
				instance.setStatus(InstanceStatus.Running);
				
				final ResultDomain resultDomain = new ResultDomain(200, "successful");
				
				UserHolder.setCurrentUser(new User());
				RegionHolder.setCurrentRegion(new Region());
				
			new Expectations(){
				{
		//        		when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
					when(zoneService.queryClusterIdByZoneId(anyString)).thenReturn(expectedClusterId);
				}
				@Mocked(methods="queryDevice")
				InstanceService instanceService;
				{
					when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
				}

			};
				
				ResultMessage result = query_vm_device.execute(instance, null, resultDomain);
				
				Assert.assertEquals(result, expected);
				Assert.assertEquals(((List<DeviceApi>)resultDomain.getData().get("devices")).get(0).getDevice_no(), expectedClusterId+"-10");
			}
		...
		-------
	分析上面的测试用例代码的 instanceService 部分：
		如果要mock instanceService的某个方法，可以在属性里定义mock；如果只是想测试一个调用期望，可以写在expections里（录制-重现），以验证是否被调用。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day59 Friday, June 08, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 继续 create_vm接口
		
	- 继续nc详情
	- 

3. mock 测试 
	代码里计量显式的传递变量，尽量少与第三方的代码耦合，否则耦合度高，同时也不利于单元测试。
		比如struts框架的 ServletActionContext 便于读取action的上下文，尽量只在入口处调用，不是每个地方都去调用这个类。逻辑尽量紧凑。

		即尽量减少与容器耦合。否则那些个特殊类都需要去mock（eg:session.rquest,respone....）

	测试一个action时，可通过mock其父类的方法来便于测试。
		利用mock框架的只对特定方法mock能力。

	mock某个类，那么spring 的注入就失效了（=null）

	* 对于静态方法，全局变量，可以再运行时设置进去。
		比如struts2的actoncontext，可以自己注入一个用于测试：
			ActionContext.setContext(new ActionContext(params));
	
			ActionContext.getContext().setParameters(params);

			mock代码：
				Map<String,Object> params = new HashMap<String, Object>();
				ActionContext.setContext(new ActionContext(params));
	
	* 下面2个方法的声明，就关于params参数的设置，看哪个好测试？
	（1）
		@Override
		public ResultMessage execute(Instance instance, Map<String, Object> params,
				ResultDomain resultHolder)
		{
	（2）
		@Override
		public ResultMessage execute()
		{
			Map<String, Object> params = ActionContext.getContext().getParamters();
		很明显，第一个测试时传入即可，第二个却要去自己访问第三方类，设置值，如果不方便设置就囧了~~~
		对于确实依赖第三方的地方，可以统一包装使用（通过参数传递进来），不零散调用。比如抽取到工具类中去。朝着低耦合，高内聚的目标走
4. 问题
	VmCreateExecuteAction.
		try{
			 image = super.getResources(Image.class, imageNo);
		}catch(ResourceUnfoundedException e){
			 image = imageService.queryCustomImageByImageNo(imageNo);
		} 
		？异常做逻辑处理？
	或者抛出，结束执行，或者捕获，日志，继续执行。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day60 Monday, June 11, 2012

1. 
	* 迭代一开发
	* 补偿迭代一单元测试
	* SLB open api原查询后端业务表的逻辑修改：
		不查询SLB后端业务表，改为从查询LoadBalancer列表(list_lb)接口获取需要的信息：
			a. 
			b. 

2. 开发记录
	- 4.18	查询用户所有VM状态（list_vm_status）接口  ？ 当前还只是返回指定region下的所有vm状态，待到后面迭代实现返回大region下信息
		QueryVmListInfoExecuteAction

	- 4.20	删除云硬盘(remove_disk)接口
		RemoveDiskExecuteAction
		InstanceService
		状态码修改：
			增加：SnapshotErrorMessage DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), 错误码  DOC
	4.19	查询VM详情（detail_vm）接口
		VmQueryExecuteAction
		InstanceService修改queryInstanceAtNc方法
		InstanceService修改queryInstancePublicIp方法
		

3. 单元测试补充记录
	- CancelCreateSnapshotExecuteAction
		SnapshotService 的cancelCreateSnapshot方法 done
	- CreateSnapshotExecuteAction
		snapshotService.createSnapshot
	..具体见redmine

4.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day61 Tuesday, June 12, 2012

1. 
	* 迭代一开发 +　单元测试补偿
	* 迭代一接口的状态码修改，更新到设计文档中 ？待
	
	* SLB OPEN API bug修改
		检查请求后端的URL的正确性，比如某些关键参数为空的话，则URL请求返回404等错误，后端没有处理，open api需要处理。
		monitorInfoService 已处理一个方法，还有个得到分页的user lbs方法 待？
			listLoadBalancerFlows 接口：
				- slb流量接口，当前逻辑是查询统计所有流量数据，如何根据lb_id分页匹配数据，响应client。
					后面可以优化根据需要查询的lb_id的流量进行真分页查询。？
						先得到分页的lb_id列表，然后到后端流量表一次性查询对应的流量数据。
				- 此接口获取lb_ids的逻辑改为从list_loadbalances接口间接获取，排序后分页，返回。


2.  开发记录
	新增接口修改：没有列入参数修改设计文档，根据redmine开发：
	vlan_no 改为 cluster_id-vlan_no 涉及到 create_vm 也要修改
	- 查询虚拟网络信息（list_vlans），修改返回值(vlan_no改成cluster_id-vlan_no)
		VlanQueryAction

3. mock 测试			   * mock
	测试框架提供了部分，常用J2EE框架的mock类 比如 ：HttpServletRequestSimulator ，用于测试struts时模拟request对象。 mock request对象
		-------
			HttpServletRequestSimulator requestMock =new HttpServletRequestSimulator(new ServletContextSimulator());
			requestMock.addParameter(IpAddressParameter.IP.getName(), "10.1.1.1");
			ServletActionContext.setRequest(requestMock);
		-------

4. 设计 ，id，name ，。。。命名统一，或者叫id或者统一name。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day62 Wednesday, June 13, 2012

1. 
	* slb bug fix
	* 迭代一接口的状态码修改，更新到设计文档中 doing
	* 迭代一  补充接口处理	redmine没录入？
		- 4.12	卸载快照接口(unmount_snapshot)
	* SLB后端数据格式修改？
		查询用户lb列表：
			{\"code\":200,\"msg\":\"successful\",\"lbs\":[\"lb1\",\"lb2\"]}"); 由统一的data字段表示数据，改为lbs 。？

	* houyi open api 参数修改部分，某些参数不是必选的？逻辑需要考略 
		参考原有逻辑，处理可选参数。
	* 状态码修改补充
		原状态码不变（尽量减小对客户端的影响），新增需要的状态码：
			device_no is illegal	device_no参数格式不合法
			nc_no is illegal	nc_no格式不合法（cluster_id-nc_no）
			not in the same region	xxx的region和xxx的region不一致
			rack is illegal	xxx rack格式不合法（cluster_id-xxxrack）
			snapshot id is illegal	snapshot_id格式不合法

			device_no is illegal  device_no参数格式不合法
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),

			 nc_no is illegal nc_no格式不合法（cluster_id-nc_no）
			ILLEGAL_NC(-731,"illegal nc"),

			 rack is illegal    xxx rack格式不合法（cluster_id-xxxrack）
			ILLEGAL_RACK_ID(-721, "illegal rack id") ;

			 snapshot id is illegal         snapshot_id格式不合法
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "),

			vlan_no
			ILLEGAL_VLAN_NO(-191, "illegal vlan_no"),;

	之前的状态码修改 ，修改为上面的格式。
	
2. 文档管理

3. 数组操作
	Arrays 工具类 collections 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day63 Thursday, June 14, 2012

1. 
	* 迭代一单元测试补充
	* umount_snapshot接口实现
	* slb  api bugfix
		及文档修改
			错误提示都修改为驼峰式。eg: NameIsEmpty 
	* 迭代一
		可选参数，逻辑处理检查 done

2. 补充
	- umount_snapshot 卸载快照接口
		UnmountSnapshotExecuteAction
		SnapshotServiceImpl
		状态码增加：
			-901	illegal device no	device_no格式不合法 DOC
			-921	illegal snapshot id	snapshot_id格式不合法 DOC
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day64 Friday, June 15, 2012

1. 
	* 动态添加region，不重启 ,
		具体需求为：添加region表的信息，添加region对应的monitor_datasource信息
		day54 no.1		
		RegionValuesFactory
			单元测试（region缓存初始化后，往数据库插一条新region记录，验证缓存中不存在就去数据库查找并存入缓存的逻辑）
		下半部分需求分析：
			- DefaultClcEndpointLoader （通过regionDao得到region_no与nuwa地址的map）
			- CommandExecutorFactory 根据上面的map，初始化 executors：
				this.executors = new HashMap<String, CommandExecutor>();
			- 上面的 executors 每次调用时根据regionNO返回对应的操作后端的 ApsaraCommandExecutor
				CommandExecutor executor = executors.get(regionNo);
			
			所以，更新 executors 即可将新region的monitor_datasource添加到缓存中。
				由于对外没有提供修改 executors 变量的入口，考虑通过反射来动态设置 executors 。
				这个逻辑的触发放到哪里？
					谁最先知道有了新region？
					分析代码知道，RegionAwareInterceptor 最先执行（需要通过 RegionValuesFactory 来查询用户请求中的region信息），所以，上面的逻辑触发
					放到 RegionValuesFactory 动态加region信息的逻辑中。
			方案：
				在 RegionValuesFactory 处理新增region的缓存逻辑中，同时增加更新CommandExecutorFactory的executors属性，加上新region的调用对象的逻辑。
			例外情况：
				手动加region表记录和加monitor_datasource记录是不同步的，或者可以理解2者没关系。
				所以上面的触发逻辑，分别处理各自在查找cache的逻辑中实现动态更新。

				此需求，在RegionAwareInterceptor中更新CommandExecutorFactory的executors属性逻辑部分，由于采用新的缓存类cacheservice，于是无法触发原更新缓存逻辑(大region项目reversion:487318)，导致加入新region后，
				调master报region找不到错误。
					解决方法：
						在同一cacehservice服务类处理新增region的逻辑中，加上更新endpoint的逻辑即可。
		
		monitor_datasource和 region，至少2者有各自的作用：
			MonitorSqlMapTemplateFactory 的 monitorDatasources 变量
				ConsistentCircle

	* houyi open api 测试环境
		http://10.250.6.33/open/services?
		key:lisw,secret:lisw

	* houyi open api 
		涉及snapsho的接口，原部分接口逻辑在操作快照时没有对用户是否有权限操作快照做约束，现需要判断：
			- 快照的owner和当前用户是否一致。
			（image是有visibility使用权限设置的，可以设置为私有或公有或者其他定义的类型，快照为私有）

			- 增加判断权限的单元测试
			- 参考 InstanceServiceImpl 的 mountDisk 方法
			- 修改范围：
				迭代一中涉及用户对snapshot操作的接口
			- 验证错误报：
				CLCErrorCode.SnapshotNoPrivilege

2. snapshot权限验证 （对snap操作时都应该验证owner，或是查询或取消创建或删除或挂载。。。）
	然后，上面的验证逻辑是在open api层还是控制层？
		是api自己去一次次查询再验证，还是把需要的参数给后端(user_id,snapshot_id etc..)，让后端来校验并返回给api？
	
	查询快照时，返回前判断快照是否属于这个user：

		DetailSnapshotExecuteAction
			if (!snapshotExt.getOwnerId().equals(
					String.valueOf(UserHolder.getCurrentUserId())))
			{
				ResultMessage message = SnapshotErrorMessage.SNAPSHOT_NO_PRIVILEGE;
				ResultDomain resultDomain = new ResultDomain(message);
				return resultDomain;
			}
	
	？ 需要确认，后端那些做了验证，那些没做验证？

	- 4.1	add_disk接口 done
		InstanceServiceImpl 的mountDisk方法
			done
			判断逻辑：
				snapshotExt = (SnapshotExt) result.getResultInfo();

				/** check permission **/
				if(snapshotExt.getOwnerId().equals(String.valuseOf(UserHolder.getCurrentUserId()))){
					return new Result<Object>(CLCErrorCode.SnapshotNoPrivilege);
				}			
		unit test
			done
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		？此接口没有查询快照，直接传递snapshot_id给后端，执行取消快照创建 ，是否需要先查询，判断owner正确，再取消创建？ 待
			或者是后端会根据snapshot_id结合instance信息，判断是否有操作权限？后端确认，“无文档”，验证较好，权限体系
		若api层做验证，参考4.1实现。
	- 4.5	查询设备已有的快照接口(list_snapshot)
		？同4.4，返回的快照列表是否可能是其他用户的快照
			如果后端没验证，open api需要验证
		ListSnapshotExecuteAction
	- 4.6	查询快照详情接口（detail_snapshot）
		DetailSnapshotExecuteAction
		原逻辑已验证，跳过
	- 4.7	删除快照接口（remove_snapshot）
		？同4.4 ，原逻辑也是传递snapshotId给后端，是否需要先查询，再执行
		部分代码：
			RemoveSnapshotCommand command = new RemoveSnapshotCommand(instance, deviceNo, snapshotId);
			return commandExecutor.execute(command,snapshotRegionNo);
	- 4.8	回滚快照接口（rollback_snapshot）
		？同4.4
	- 4.9	保留快照接口（retain_snapshot）
		？同4.4
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		？同4.4
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotServiceImpl > mountSnapshot
			done
		unit test
			done
	- 4.12	卸载快照接口(unmount_snapshot)
		SnapshotServiceImpl
			done
		unit test 
			done
			


3. api调控制系统的设计
	采用command模式，每个接口都定义为一个command对象，封装了endpoint，参数，处理返回值等逻辑。

	统一由一个执行对象执行。

	action中处理返回值的逻辑，是否可以移到command的处理防护值方法中 职责划分

4. houyi open api 系统
	InstanceServiceImpl > mountDisk
		this.instanceDao.updateInstanceConfig(instance); //没返回值，没log，非理想情况如何处理
	mock？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day65 Monday, June 18, 2012

1. 
	* slb bug fix
		严格按照文档说明来开发，编写单元测试（基于文档）
		- 流量接口 pageNO,pageSize可选，空的话采用默认值。依据文档说明
		- 目前OPENAPI的RS表没有user_id字段，虽然lb_id是全局唯一的，但是rs_pool_name却是用户唯一的，所以光凭rs_pool_name无法唯一确定一个rs_pool，可能会有重复的情况出现。
			rs表加user_id字段，增加删除时都带上这个筛选字段。lb_id ，rs_pool_name都带上对应的user_id
			sql修改
				alter table rs add user_id int(10) unsigned;
	* big region
		svn提交格式：
			fix bug #3243 修复某问题的comments
2. 设计
action的参数验证，可以抽象出来，不用在acton的方法里详细验证

3. 基于文档 ，每个条件/参数都提供测试用例，测试用例覆盖每个错误状态
	理想状态用例
	参数不合法用例
	。。。
4. 实现 ApplicationContextAware 接口的类，在spring初始化时初始化应用的一些缓存等操作时，bean需要配置，以便spring来实例化
	

5. linux部署时，会由于权限问题导致，部署失败，或者部署时，有部分文件没被更新。
需要注意。

6. 整理 slbapi 操作rs表的接口及其操作rs的逻辑（增加逻辑/删除逻辑）
	- add_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
	- delete_rs
		根据vm_name,rs_pool_name和user_id删除rs表记录
	- switch_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
		根据vm_name,rs_pool_name和user_id删除rs表记录
	-add_vm
		根据vm_name,lb_id和user_id增加rs表记录
	-delete_vm
		根据vm_name,lb_id和user_id删除rs表记录
	- switch_vm
		根据vm_name,lb_id和user_id增加rs表记录
		根据vm_name,lb_id和user_id删除rs表记录
	- delete_lb
		根据lb_id和user_id删除记录
	- release_backend
		根据vm_name 和user_id删除rs表记录
	- delete_rs_pool
		根据rs_pool_name和user_id删除rs表记录


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day66 Tuesday, June 19, 2012

1. 
	* big region 动态添加regin，更新monitor datasource信息
		？更新缓存接口
		逻辑实现 + 测试
		触发条件：
				需要用到各自region的SqlMapClientOperations操作的dao层，都是通过MonitorSqlMapTemplateFactory的 getMonitorDatasource 方法取到 SqlMapClientOperations 进行后续操作，
			故，以 getMonitorDatasource 方法作为触发加载新region monitor datasource的点。
		修改点：
			MonitorSqlMapTemplateFactory 
				public SqlMapClientOperations getMonitorDatasource(String regionNo, String instanceNo){
	* slb rs表测试
	* big region ,根据cluster_id查询region_no时，如果region_no不存在应该报错 ？ 添加验证逻辑
		返回码设计：
			根据不同参数的cluster_id查询region，设计相应的返回码
			- cluster_id-device_no-snapshot_id
				报snapshot_id不存在
			- cluster_id-device_no
				报device_no不存在
			- cluster_id-nc_id
				报nc_di不存在
			- cluster_id-rack_id
				报rack_id不存在
			- cluster_id-vlan_no
				报vlan_no不存在

	* mysql case sensitive
		mysql 区分大小写
		参看下面：
				The default character set and collation are latin1 and latin1_swedish_ci, so nonbinary string comparisons are case insensitive by default. This means that if you search with col_name LIKE 'a%', 
			you get all column values that start with A or a. To make this search case sensitive, make sure that one of the operands has a case sensitive or binary collation. For example, if you are comparing a 
			column and a string that both have the latin1 character set, you can use the COLLATE operator to cause either operand to have the latin1_general_cs or latin1_bin collation:
				col_name COLLATE latin1_general_cs LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_general_cs
				col_name COLLATE latin1_bin LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_bin
				If you want a column always to be treated in case-sensitive fashion, declare it with a case sensitive or binary collation.
			from:http://stackoverflow.com/questions/5629111/mysql-case-sensitive-string-comparison
		2种方式实现mysql支持大小写区分
			1) 查询时通过操作符 COLLATE
			2) 建表时声明
		此处选择建表时声明列区别大小写：
			-- 此为更新语句 sql修改
			alter table region_mapping modify column vm_region_no varchar(32) binary NOT NULL COMMENT '@desc vm region_no';  
			alter table region_mapping modify column region_no varchar(32) binary NOT NULL COMMENT '@desc slb region_no';  
			alter table region modify column region_no varchar(32) binary NOT NULL;  
			alter table rs modify column vm_name varchar(50) binary NOT NULL COMMENT '@desc vm name';
			alter table rs modify column rs_pool_name varchar(100) binary COMMENT '@desc rs pool name';
			alter table rs modify column lb_id varchar(110) binary COMMENT '@desc lb_id';
			alter table monitor_datasource modify column region_no varchar(32) binary NOT NULL;

			建表语句类似上面。
				  `region_no` varchar(32) binary NOT NULL COMMENT '@desc slb region_no',

2. monitor datasource相关修改点，测试点
	- monitorDatasource.xml 增加根据region_no查询记录的select语句定义
		MonitorSqlMapTemplateFactory 直接用了这个映射文件（充当dao层）
			测试时测试这个类即可
				测试新增的select
	- MonitorSqlMapTemplateFactory修改 getMonitorDatasource 方法
	
3. bug提交格式 
	fix bug #3243 修复某问题的comments

4. 单元测试覆盖程序的逻辑，覆盖关键点越细，工作量越大，但代码健壮性越强。
	slb这边测试用例只测试几个正常的场景，对一些例外没有写用例，导致qa测试bug。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day67 Wednesday, June 20, 2012

1. 
	*  slb bug fix #122
		先新建lb，然后重现问题
		原因：
			hybird类型 query_loadbalance_info时，返回值中没有vm_list字段
	* slbapi rs表加region_no字段（slb的region），目的在操作rs_pool_name记录时，处理多个slb region_no的rs_pool_name重名情况
		每个rs记录都记录region_no
		sql修改
			alter table rs add region_no varchar(32) DEFAULT NULL  COMMENT '@DESC slb region no';
	* 迭代一 参数修改部分 ，新增2个接口需要修改
		
2. slbapi 测试环境
	mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
3. slb测试
	测试的条件能重现，就可以在本地debug

4. SystemError 2100
	slbapi在处理 ip2name时会报这个异常
5. rs表加region_no字段 —— 只在操作rs_pool_name时考虑这个字段
	rs.xml
6. 部署没更新问题
	删除部署的内容后，重新build再部署。
7. 接口测试，单元测试中，可能没有细致到返回结果处理的测试用例，隐藏了
	a. 调用成功
	b. 返回值正确
	c. 处理返回的相应正确

	一套单元测试用例很重要，打好基础，再变更时，处理就很方便；否则，未知数太多，需要QA或运行时才能暴露问题。

8. 迭代一 参数修改 新增接口 文档说明整理
	- 4.22	query_nc_resources接口
		ClusterNcResourceListAction

	- 4.23	query_racks接口
		RackQueryAction

		哪怕是那寥寥几个字节的注释，也能鼓起我看完这漫长代码的勇气~，如果连这点也剥夺，那也就只好苦逼的被一行行、一遍遍的摧残了

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day68 Thursday, June 21, 2012

1.
	* big region 迭代一bug处理
	* big region 迭代一新增2个接口开发
	* big region 测试环境
		请求api的client 位置：
			/houyi-console-openapi/src/test/java/com/aliyun/houyi/openapi/util
		10.242.209.4  api地址
		10.242.209.1 api db
		日志 /home/admin/houyi/service/logs/openapi
		10.250.8.214环境 admin操作
			cd /home/admin/houyi/service
			sh build/build.sh 
			sh bin/reloadws_alone 
			tail -f logs/openapi/jboss_stdout.log 
		配置文件：
			/home/admin/.houyi/

		dev开发测试环境：
			AT-HOUYIDEV-AG 10.250.6.27
			HOUYI-MASTER:10.250.8.212
			HOUYI-NETC:/10.250.6.32
			API:10.250.6.33
			DB:10.250.6.27

			

2. big region 迭代一bug处理
	- detail_vm 返回的vlan_no格式错误 http://bugfree.corp.taobao.com/bug/175626
		原因：设计时丢了vlan_no的格式转换（vlan_no为后续增加待修改参数）
		修改：
			VmQueryExecuteAction
			VmQueryExecuteActionTest
	- 

3.  big region 迭代一新增2个接口开发
	- 4.22	query_nc_resources 接口
		修改：
			ClusterNcResourceListAction
				zone_id的获取？
					AbstractExecuteAction 提供2个重载的 getCurrentZone 方法供action调用，采用哪个无参的方法。（即请求中无zone_no，则取用户默认的zone）
			ClusterNcResourceListActionTest
	- 4.23	query_racks接口
		修改：
			RackQueryAction
			RackQueryActionTest

4. 问题排查
	请求内容 + 错误返回内容 + 日志内容


5. 迭代一 cluster_id 修改整理：	 from mail
	3）cluster_id是否存在需要判断（nc_id,rack_id,vlan_no,device_no,snapshot_id）
	DEVICE_NOT_EXISTS(-905, "device not exists at vm"),
	SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
	NC_NOT_EXISTS(-700, "nc not exists"),
	RACK_NOT_EXISTS(-160, "rack not exits"),
	NC_NOT_EXISTS(-161, "nc not exits"),
	VLAN_NOT_EXISTS(-190, "Virtual Lan not exits")
	4）涉及新device_no，新snapshot_id中都需要判断格式中的device_no是否一致，若不存在，错误码是SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
		 这个问题建议使用以前的错误码。
		如recover_vm接口，在vm_name和destination_rack 或destination_nc的cluster_id的region不匹配时，复用以前的错误码  -283（not in same zone of vm）
		如list_snapshot接口，在vm_name和device_no的cluster_id的region不匹配时，复用以前的错误码 -905（device not exists at vm ）

	5）需要判断涉及cluster_id与vm_name对应的region是否一致，这个错误码待考虑？
	以下4、5是在不跨region使用snapshot,disk情况下，API层作的权限验证。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day69 Monday, June 25, 2012

1. 
	* 迭代一cluster_id，device_no 验证bug修复
	* slbapi回归bug
		ip转name时，传入了lbId去查询，数据库中lb_id为null，导致ip转name错误；ip转name可以减少限定条件 只根据 vm_name,ip,region_no确定，如果多条记录报错，记录log，对外报SystemError
			select distinct vm_name region_no=xxx and ip=xxx
	* 职责
		谁操作，谁知道，谁负责校验。

2. bug 修复
	1）修改设计文档
	2）基于文档，修改程序
	3）test
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
		-283, not in same zone of vm
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),
		-917,snapshot not at the device
	修改记录：
		- add_disk
			AddDiskExecuteAction
			AddDiskExecuteActionTest
			InstanceServiceImpl
		- create_snapshot
			CreateSnapshotExecuteAction
			CreateSnapshotExecuteActionTest
		- cancel_create_snapshot
			CancelCreateSnapshotExecuteAction
			CancelCreateSnapshotExecuteActionTest
		- list_snapshot
			ListSnapshotExecuteAction
			ListSnapshotExecuteActionTest
		- detail_snapshot
			DetailSnapshotExecuteAction
			DetailSnapshotExecuteActionTest
		- remove_snapshot
			RemoveSnapshotExecuteAction
			RemoveSnapshotExecuteActionTest
		- rollback_snapshot
			RollbackSnapshotExecuteAction
			RollbackSnapshotExecuteActionTest
			RollbackSnapshotExecuteActionTestTest
		- retain_snapshot
			RetainSnapshotExecuteAction
		- mount_snapshot
			MountSnapshotExecuteAction
		- unmount_snapshot
			UnmountSnapshotExecuteAction
		- live_migrate_vm
			VmLiveMigrateExecuteAction
			
			
		if(!vmClusterId.equals(deviceClusterId)){//check same region
			logger.error("vmCluster and deviceClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		if(!vmClusterId.equals(snapshotClusterId)){//check same region
			logger.error("vmCluster and snapshotClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		String snapshotRegionNo = instance.getRegionNo();
		if(deviceNo!=null&&!deviceNo.equals(snapshotDeviceNo)){//check same device
			logger.error("deviceNo and snapshotDeviceNo is not equal");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(SnapshotErrorMessage.SNAPSHOT_NOT_AT_THE_DEVICE);
			return result;
		}

3. 测试环境 部署时
	打开远程debug，便于分析bug。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day70 Tuesday, June 26, 2012

1. 
	* 文档review，
		修改部分内容，修改相应程序逻辑
	* 迭代一bug fix
		@Entry(action = Action.VM, resource = @Resource(argNo = 5)) }) 由于加了参数资源位置发生改变，需要更新
	* slb v2 测试环境 monitor库地址修改：
		10.230.204.24 slbapi monitor_datasource表 
	* big region
		状态码重复：							clear_cache接口状态码与现有重复
			CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
			NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

			CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
			NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
			-288
			-292
			ClearCacheErrorMessage
	* cluster_id ,device_no,vm的校验方案修改：
		方案改为：
			1）cluster_id校验是否存在，报相应id不存在
			2）nc_id,rack_id,vlan_no，vm校验cluster_id一致
			3）nc_id,rack_id,vlan_no同时传时，取最小的
			4）这5个参数的校验顺序：便于case
				snapshot_id
				device_no
				nc_id
				rack_id
				vlan_no
2. 资源位置改变更新bug修改点
	SnapshotServiceImpl
		unmountSnapshot
3. big region api&houyi avalible
	API:10.250.6.33
	DB:10.250.6.27
4. 错误码 ，调试时，错误码+log
	-283 ,not in same zone of vm
	-917,snapshot not existed at the device
5. 根据修改的文档，继续day69第2条任务
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),

6. 
	# web console staff
	cd `dirname $0`/..
	BASE_HOME=`pwd`

	#rm -rf $BASE_HOME/src/*
	svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api $BASE_HOME/src
	cd $BASE_HOME/src
	mvn clean package -Dmaven.test.skip=true 


	# HOUYI API
	cd $BASE_HOME
	./bin/tomcatctl stop
	cd $BASE_HOME/.default/webapps
	rm -rf slb
	rm -rf slb.war
	ln -s $BASE_HOME/src/target/slb.war

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day71 Wednesday, June 27, 2012

1. 
	* 迭代一，cluster_id等校验规则重新设计，见文档
		开发+测试用例
	* 迭代一 sql调整整理
	* action的validator方法
		会提前验证 参数的格式，需要修改为匹配新格式
			nc_id		NcParameter.NC_NO("nc_no",new RegularValidator("^[0-9]{0,75}$"),null),
			snapshot_id	SnapshotParameter.NAPSHOT_ID("snapshot_id",null), 
			device_no		SnapshotParameter.DEVICE_NO("device_no", null), 
			InstanceParameter
				RACK_ID("rack_id", null),
				NC_ID("nc_id", null),
				VLAN_NO("vlan_no", null),
	* list_snapshot 接口文档返回以删除部分字符串，以实际返回为准
				<rsp>
		  <code>200</code>
		  <msg>successful</msg>
		  <data>
		    <snapshotExts list="true">
		      <snapshotExt>
			<snapshot_id>27-703-520318</snapshot_id>
			<snapshot_name></snapshot_name>
			<progress>37%</progress>
			<create_time>2012-06-27 20:24:54</create_time>
			<image_no>windows2008_64_alibase_v02.vhd</image_no>
			<owner>149</owner>
		      </snapshotExt>
		    </snapshotExts>
		    <device_no>27-703</device_no>
		    <vm_name>wysh-627-a</vm_name>
		    <snapshots>
		      <snapshot>520318</snapshot>
		    </snapshots>
		    <vm_status>Running</vm_status>
		  </data>
		</rsp>
	* aghell05a10.250.6.27 hy create_vm_f vm_conf/windows_vm  wysh-627-a shell脚本执行操作，命名操作名称  ，参数

2. 修改记录
	- add_disk 
		AddDiskExecuteAction @ -
		AddDiskExecuteActionTest @
		InstanceServiceImpl
	- create_snapshot 
		CreateSnapshotExecuteAction @ -
		CreateSnapshotExecuteActionTest @
	- cancel_create_snapshot 
		CancelCreateSnapshotExecuteAction @ -
		CancelCreateSnapshotExecuteActionTest @
	- list_snapshot 
		ListSnapshotExecuteAction @ -
		ListSnapshotExecuteActionTest @
	- detail_snapshot 
		DetailSnapshotExecuteAction @ -
		DetailSnapshotExecuteActionTest @
	- remove_snapshot 
		RemoveSnapshotExecuteAction @ - result返回设置
		RemoveSnapshotExecuteActionTest @
	- rollback_snapshot
		RollbackSnapshotExecuteAction @ -
		RollbackSnapshotExecuteActionTest @
	- retain_snapshot
		RetainSnapshotExecuteAction @ -
		RetainSnapshotExecuteActionTest @
	- mount_snapshot
		MountSnapshotExecuteAction @ -
		MountSnapshotExecuteActionTest @
	- unmount_snapshot
		UnmountSnapshotExecuteAction @ -
		UnmountSnapshotExecuteActionTest @
	- live_migrate_vm
		VmLiveMigrateExecuteAction	@ -
		VmLiveMigrateExecuteActionTest @
	- recover_vm
		VmRecoverExecuteAction @ -
		VmRecoverExecuteActionTest @
		NodeControlServiceImpl @
	- detail_nc
		SingleNcResourceAction @ -
		SingleNcResourceActionTest @
	- create_vm 
		VmCreateExecuteAction @ -
	- remove_disk
		RemoveDiskExecuteAction @ -
		RemoveDiskExecuteActionTest @

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day72 Thursday, June 28, 2012

1. 
	* bugfix 
	* 项目单元测试报错问题
		- 如果是junit，它会去执行带Test开头或结尾的类去执行测试，类不用耦合junit的类，junit会根据自己的规则去找测试类，
		找到了，但类中没有测试方法会报：No runnable methods
		- mvn skip的原因
			原因为：testng框架在初始化时报错，对于依赖的测试用例都将skip
			解决：解决初始化问题，比如spring容器初始化错误等
				暂时先注释houyicontext重复加载抛错
				设置 houyi.openapi.test=true 标识
	* -90 system error 错误
		原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
			com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
				instance找到了，


2. sql整理
	houyi,zone表
	alter table zone add cluster_id varchar(32) NOT NULL;
	SELECT	region_no	FROM zone WHERE cluster_id=#clusterId#
	SELECT	cluster_id	FROM zone WHERE zone_id=#zoneId#	
	select 
		url,
		username,
		passwd,
		region_no,
		index_at_region,
		driver_class,
		min_idle,
		max_active,
		max_idle,
		validation_query
	from monitor_datasource
	where region_no=#regionNO#
3. bugfix
	- bug #177163 live_migrate_vm接口：nc_id为‘-’或者‘--’时，统一返回-90
		
4. mvn test
	mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	big region ，重复设置houyi上下文，导致spring初始化失败

5. -90 system error 错误
	原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
		instance.xml
		instance.selectInstanceDetailByNo
		com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
			instance找到了，left outer join 去找image时，image的记录是不存在的，但这种join方式，还是返回了vm存在的记录，只是image的字段都是空的。
			可以在 join 时，如果image找不到则不匹配，返回空。
			OR
			image对象字段都有默认值，但能判断是否存在。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day73 Friday, June 29, 2012

1. 
	* create_vm接口测试用例补充
		
	* web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
	* big region 状态码重复 修改

2. 

3. jtester 解析wiki文件时，会判断文件的编码格式 参考 jtester部分源码 [源码]
	org.jtester.utility.ResourceUtil	
		String encoding = ResourceUtil.getFileEncodingCharset(file);

	/* inputstream to string */
	public static String convertStreamToString(InputStream is, String encoding) {
		BufferedReader reader = null;
		String line = null;
		try {
			StringBuilder buffer = new StringBuilder();
			reader = new BufferedReader(new InputStreamReader(is, encoding));
			while ((line = reader.readLine()) != null) {
				buffer.append(line + "\n");
			}
			return buffer.toString();
		} catch (IOException e) {
			throw new RuntimeException(e);
		} finally {
			close(reader);
			close(is);
		}
	}
	/* 异常统一捕获，减少遍布try/catch的情况 */
	public static void close(Reader reader) {
		if (reader == null) {
			return;
		}
		try {
			reader.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	public static void close(InputStream is) {
		if (is == null) {
			return;
		}
		try {
			is.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	ResourceUtil中的其他工具方法，开源框架的工具类代码风格

4. web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
		对于不同的web服务器，或web框架都提供错误url处理方式。
			java web项目可以再web.xml里针对异常或错误码配置error page
				<error-page>
					<error-code>404</error-code>
					<location>index.jsp</location>
				</error-page>
		或者通过配置代理服务器，将非法url指向到错误页面。

	生产环境的系统，要处理应用层的非法请求，还要处理服务器层的非法请求（比如，tomcat，apache处理非法请求的指向）；
		比如服务器层的非法请求处理，下面以tomcat为例，在$TOMCAT_HOM/conf/web.xml中配置：
			<error-page>
				<error-code>404</error-code>
				<location>/index.html</location>
			</error-page>			
		其他web服务器，可以参照其文档说明，找到配置点，配置即可。

	实验了下，baidu，等网站对于域名下非法url指向到首页。

5.  big region
	状态码重复：
		CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

		CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
		NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
		-288
		-292
		ClearCacheErrorMessage

	暂不改


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day74 Monday, July 02, 2012

1. 
	* big region参数修改bug fix
		创建    unmount_snapshot API超时返回-95
		创建    API参数调整设计文档中未提及create_image接口
		query_available_ncs: vm用户非法情况，API报-90
		query_available_ncs: vm状态为destroyed的情况下，API报-90
	* 关键性log，记录并打印关键内容 ，便于后续查找log排查问题。个人感觉，log需要记录关键性的原生请求内容，比如请求参数，返回内容等
		进入拦截器打个日志，这样在某些关键点打日志就可以从日志中大致判断那个地方报错了。
	* live_migrate_vm接口nc_id是否为必须？
		待确定，代码里验证为必须。
		
2. big region参数修改bug fix
	qa环境不在6.33上，看日志需要到qa测试机查看 10.242.209.4 （改为 10.230.204.19）
	
	创建    unmount_snapshot API超时返回-95
	创建    API参数调整设计文档中未提及create_image接口			  done
		修改设计文档
		CreateImgExecuteAction
		ImageServiceImpl
	query_available_ncs: vm用户非法情况，API报-90
	query_available_ncs: vm状态为destroyed的情况下，API报-90	   （控制系统destory，api这层为release状态）
		在根据vm_name查找instance时（为了查询资源的regionNo），dao层sql语句报错，和之前一样，let join的表没数据，但result这个字段又是必须，故报ibatis设置result map错误，程序没有捕捉这个错误。
			应该报这个错，日志没记录：
				com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
		解决：
			捕捉这个错误，打出log。
		注：
			错误日志找了半天找不到（根据请求内容，返回结果），原因在于 log里没有打印请求相关的内容，不好根据请求内容匹配，建议可以适当打印请求的一些关键内容，便于排查错误。 【日志内容设计，建议】
				2012-07-02 14:12:13,249 ERROR [com.aliyun.houyi.openapi.interceptor.ParameterInterceptor] - [业务参数校验有问题，请检查原因：com.aliyun.houyi.openapi.exception.ParameterException: 协议参数校验不通过，参数名称：timestamp！]

				2012-07-02 14:35:38,204 ERROR [com.aliyun.houyi.openapi.interceptor.RegionAwareInterceptor] - [查询资源信息时发生错误!]
				就这条日志，导致error错误发生，log里没有明确的内容标识本此请求，故通过即时重现来得到log输出。这里可以适当打印一些请求内容，便于后续排查错误。

3. 日志打个唯一tag，再结合用户标识等唯一标识以及时间，可以从日志中统计出每个用户每次调用的所有有序日志输出。think it


4. debug 代码不一致，不是部署错了，就是自己的代码没更新，排查呀排查 。。。 呵呵

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day75 Tuesday, July 03, 2012

1. 
	* region转换需求分析 redmine
	*迭代三 开发需求分析
	* slb v1,v2的vm的小region转为大region	 需求分析


2. 迭代三任务
	- [ID:175057]兼容用户使用小region调用
		a. 兼容用户使用小Region的调用(用户传入的小region统一转成大region，用户输入小region,API返回小region)
			需求理解为：（需要review）
				1. 兼容用户使用小Region的调用(用户传入的小region统一转成大region)
				2. 用户传入小region，步骤1中转换为大region，即使用户传入小region，api实际返回的还是大region下的内容
				3. api只返回大region的region_no

				原则：
				所谓兼容，指的是用户可以传入小region_no，但api都转换为大region_no处理，包括返回的也统一为大region_no			
		b. 查询用户所有VM状态接口(list_vm_status)，根据用户输入的大Region返回大Region信息
			需求理解为：（需要review正确与否）
				1. 根据用户输入的大Region返回大Region下用户所有VM状态，返回大region_no
				2. 若传入小region,查询小region下用户所有VM状态,返回小region_no
				QA:
				1. 大小region_no如何区分？
					表region_alias记录小region与大region的关系
						region_no
						real_region_no
					参考：弹性计算大Region项目_调度设计_API部分__20120628.docx

			QueryVmListInfoExecuteAction
			InstanceDaoImpl

3. SLB V1版本，V2版本所使用region_no全部换成大region_no
	前提：现在vm的大region和slb的region是一对一的，即vm的大region都对应slb的一个region。
	有了上面的前提，v2版本的slb api项目要修改的地方：
		1）配置vm的大region对应slb的region的映射关系，保证大region传递过来能正确调用到slb的region。
		2）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day76 Wednesday, July 04, 2012

1. 
	* 迭代三
		region_alias表big_region_no字段增加
	* 小region改为大region，涉及到的command中region属性判断需要设置为目标region。doing
		参考：CreateInstanceCommand
	* 迭代一的根据zoneId取clusterId逻辑，改为从cache中取，参考    QueryVmListInfoExecuteAction	       getRegionValuesFactory().getClusterIdByZoneId(xx)		  待
			

2. 迭代三
	- list_vm_status
		QueryVmListInfoExecuteAction
			转换nc_id时，要考虑到不同region取出的nc的cluster_id是不一致的。
			设计时，如果每个转换都查db，性能很低sql很简单当连接耗时，考虑缓存zone_id,cluster_id映射数据。
				在RegionValuesFactory存放此缓存 缓存设计（总体设计，类设计，更新策略，。。。）
					系统有多处小cache，是否设计一种通用方式，不用每个cache都自己去写个类，去clean等共性操作。
						抽象出缓存操作接口层，不论底层是什么缓存工具，接口的实现来实现细节。上层应用只调用接口，在配置中配置具体实现。应用系统缓存设计
			在处理每个nc不同的cluster_id前缀时，处理方式改为在原有逻辑循环中，从clusterId缓存中取得后设置。
		InstanceDaoImpl
		instance.xml 增加新查询，已有查询不动（避免影响已有调用）
		RegionValuesFactory
			getClusterIdByZoneId
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		QueryUnassignedIpsExecuteAction

		此接口需要根据 zone_id取到对应的小region_no，查询houyi时，指定在这个小region上操作。
		
3. dbfit 测试用的wiki文件，直接从sql检索结果贴过来，会有很多空格，可以用空来替换空格，再补上必要的空格，省去删空格的繁琐。
	替换功能帮助不小
4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day77 Thursday, July 05, 2012

1. 
	* 迭代三开发


2. 迭代三
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		由于zone_id是必选，原有逻辑不变，不跨小region。
		QueryUnassignedIpsExecuteAction
		QueryUnassignedIpsExecuteActionTest
	- [ID:175055]查询可用的ISO接口(query_available_isos)，根据大Region参数该大Region下的所有资源
		QueryAvaliableIsosExecuteAction 
			region_no参数没用到 ，iso_resource表加入region_no字段待确定？ 这样iso就属于某个小region
				iso_resource 加region_no（小region_no）字段
				sql修改
					alter table iso_resource add region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的小region_no';
				相应要修改的点：
					iso.xml
						对region_no字段加入，需要修改的sql
					IsoDaoImpl 修改 selectUserAvailableIsos方法

3. 对于兼容的地方，文档应尽量说明，便于理解。
	比如一个必选的参数，但没传也ok，容易误解。文档描述与程序逻辑的一致。

4. 
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction

4. big region ,houyi api 代码中多处用到java对象的址传递方式来，从一个方法中取得多个结果
	比如：声明一个变量，传入到方法参数中，执行好后，方法返回一个结果，参数中对象也保存了结果

	这样的现象出现的原因？有何优缺点？
		原因还是对方法的结果没有更好的封装对象，需要
		弱封装，一个方法包含多个功能 

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day78 Friday, July 06, 2012

1. 
	* 迭代三开发
		- 根据写的开发修改文档
		- region表增加big_region_no字段，和region_alias表（real_region_no字段由于存储2个region_no对应同一个存储，
			在imge接口里，为了区分用）的big_region_no一致
			sql修改：
				alter table region add big_region_no varchar(32)  NOT NULL COMMENT '@desc 小region_no对应的大region_no';
			相应点的修改
			测试用例，wiki文件修改 待？

			注：7月9号，取消上面的修改，region表不增加big_region_no字段。
				通过svn版本还原各个修改点。

	* 缓存使用
		- 系统多处地方，频繁调用数据库，结合简单缓存service，将某些查询缓存起来。在查询缓存命中时，免去数据库操作，提高性能。
		- 提高公共缓存服务，可以根据类型操作各自缓存；便于扩展，加入新缓存类型
		- 缓存的更新，若缓存没命中，则继续到数据库中找，找到就放到缓存中，并返回
		- 缓存的过期清除，不用的缓存，命中率低的缓存，能自动清除或调整
		- 缓存总大小限制，控制无限增大缓存(个数控制，。。。)
		

2. 迭代三记录
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction
		  VmTopNMonitorExecuteActionTest
		  MonitorServiceImplTest

		  norm值，判断指标在指定的region是否支持，大region_no如何处理？
			内部判断region是否为大二层网络，因为现在到以后都会是大二层网络，故这个判断可以忽略。

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day 79 Monday, July 09, 2012

1. 
	* region表取消big_region_no字段，相应修改
	* 迭代三开发

2. 迭代三
	- 查询可用的ISO接口(query_available_isos
		修改补充
	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		VmPageMonitorExecuteAction
		InstanceMonitorInfoDaoImpl
		InstanceMonitorInfoDaoImplTest
	- list_vm_status		
		
	- query_rack
		RackQueryAction
		RackQueryActionTest
		AbstractExecuteAction
	- ID:175051]大region下list_vlans接口
		VlanQueryAction
		VlanQueryActionTest
	- [ID:175052]大region下 query_zones 接口
		返回的region_no改为大region_no
		ZoneQueryAction
		ZoneQueryActionTest
	- ID:175053]大region下 query_regions 接口
		文档返回结果说明需要修改，现在返回的是大region_no
			返回值格式不修改，用大region_no字符串构造region对象，返回；向前兼容
		RegionQueryAction
	- 大region下 add_ip_segment 接口，同时增加zone_no参数
		AddIpSegmentExecuteAction
		IpSegmentService


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day80 Tuesday, July 10, 2012

1. 
	* monitor_vm_topn 接口修改
		VmTopNMonitorExecuteAction
		排序
			Collections
			Arrays
	* 用户体系修改review
		关联到的slb v2用户改造
	* region缓存修改问题
		RegionValuesFactory
	* slb v2 slb region那些地方用到？
	* ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		需求分析

	* ibatis的sql注入问题：在使用##时，采用预编译可以避免sql注入，但用$$时要程序避免sql注入
		order by b.$orderBy$ $order$ 
	* cache修改，涉及到丢失修改的测试用例修改
		openapi模块


2. slb v2 slb region那些地方用到
	- 请求slb后端，需要slb region_no,定位后端请求信息（url之类）
	- 查询流量接口，需要根据slb region_no，调用其对应的monitor库
	- 操作api的rs表时用到slb region_no

3. ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	需求分析 
	slb v2 api ，在region_mapping表通过vm的region_no得到slb的region_no
	，然后，在调用slb后端和查询流量数据时用到这个slb region_no。

	slb v1 版本代码在houyi api的一个包中，属于houyi api project：
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day81 Wednesday, July 11, 2012

1. 
	* 迭代三开发
	* -1007,"desc":  "ip segment is used
		控制系统这个错误码，api层没有定义相应的错误映射，以默认-95，system error返回。暂不改

	* 接口兼容


2. 迭代三
	- ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		前提:
			一个vm大region_no对应slb的一个region_no，他们是一对一关系
		需求分析
		请求参数中region_no为大region_no时	   ，只要在region_mapping表找到对应的slb region_no即可：
			SLB V1用到slb region_no的地方有(houyi库)：
				a. slb流量查询接口，
					slb_monitor_datasource（此表region_no为vm的region_no）
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。

				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					slb_region
			SLB V2 用到slb region_no的地方有（slbapi库）：
				a. slb流量查询接口，
					monitor_datasource
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。
				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					region
	数据订正：
		SLB V1（houyi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
			2）slb_monitor_datasource 表
				订正region_no为大region_no（原来此列值为小region_no）
		SLB V2（slbapi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
	代码修改：
		SLB V1 : 部分代码需要修改，涉及到从vm的region_no得到slb region_no的地方


3. 全局变量设计 ，控制使用范围
	系统全局变量设计时要考虑好，尽量不用或少用，用的不好导致系统各个地方充斥着全局变量调用或设置，
	维护，调试比较麻烦，可通过在上层用，下层通过传参传递，这样也知道一个方法用到哪些参数，不是上层不知道的情况下，
	调用了一个全局变量。个人见解

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day82 Thursday, July 12, 2012

1. 
	* 迭代三修改点 与QA review
	* SLB V2中根据vm的region_no查询slb region_no部分逻辑代码修改
	* SLB V1,V2用户体系分析，新项目准备工作
	* 提测前准备工作：
		HOUYI API , SLB V1 API ,SLB V2 API
		- 表订正

	* iso_resource表增加的小region_no，修改为增加大region_no
		sql修改
			alter table iso_resource add big_region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的大region_no';
		相应要修改的点：
			iso.xml
				对region_no字段加入，需要修改的sql
			IsoDaoImpl 修改 selectUserAvailableIsos方法		
		
	      待改数据库并svn提交 ？
2. 

										     

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day83 Friday, July 13, 2012

1. 
	* 用户体系改造项目设计review
	* houyi api 接口调用用例编写，便于测试
	* 
		
2. vm状态 vm status
	Pending(1, "待启动") 
	Starting(2, "启动中") 
	Running(3, "运行中"), 
	StartFailure(4, "启动失败") 
	Shutting(5, "停止中") 
	ShutFailure(6, "停止失败"), 
	Shutted(7, "已停止"), 
	Released(8, "已释放"), 	     释放后instance表记录保留
	Resetting(9, "重置中") 
	ResetFailure(10, "重置失败"),
	Transferring(11, "迁移中");

3. houyi api 接口调用用例编写，便于测试
	- create_vm接口返回值region_no为小region_no？   是否还有其他的也需要检查
	- 创建的vm，调start_vm状态为pengding，数据库为startfail
	- start_vm start fail 原因？控制系统
		看api调用此接口传递给控制系统的参数，isoName参数为空，因为iso_resource表增加了big_region_no，开发环境没有更新此表。
	- houyi api对取消创建快照接口，控制系统报 cancel failed错误时，api没有映射对应的错误，统一以-95报错	 ，或者是控制系统状态码错误？	
		注：确认为控制系统没有对错误码归类，比如不同错误可能都报-1码 ，有待控制系统返回特定码。
		result: {"code":  -1,"desc":  "cancel failed","isSuccess":  "FALSE"}。
		-95，invoke houyi system error
	- 同上，卸载快照接口，
		code":  -1,"desc":  "umount device from vm failed
		-95，invoke houyi system error
	- query_available_imgs 查询可用的镜像接口，返回值snapshot_id格式没更改	?
		   文档注明返回值中snapshot_id部分废弃，本次代码不动，后续将去掉这个值
	- list_vlans
		-95，invoke houyi system error
		Caused by: com.alibaba.apsara.kuafu.KuafuException: Exception: Message is dropped by KFC, server does not exist
		控制系统服务不正常，在重启

	qa测试：
		cd /home/admin/lix/lix-src/tools  or /home/admin/lix/lix-src/tools/houyiTestFrame/houyiTestFrame
		python2.7 houyiframe.py cases/release_test/bvt_ci.xml test vm_test		or python2.7 houyiframe.py cases/release_test/bvt_ci.xml 22:22
		[root@AT-HOUYIDEV-AG]$me
		Local_Address: 10.250.6.27

		涉及到参数值修改在: bvt_ci.xml test vm_test 中
			cluster_id=27


ZoneServiceImpl


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day84 Monday, July 16, 2012

1. 
	   *  qa bvt测试 ，开发自测
	   * big region项目中，缓存reload接口
		目前有，region，zone，clusterId三块缓存，根据指定的key，reload对应的缓存（用于源数据被修改后，需要同时更新缓存值的目的）
	   
2. bvt测试
	具体执行环境参考day83第3条

3. reload缓存接口，根据缓存类型，调用接口实现对应类型的缓存reload	    ，内部调用接口
	region，zone，clusterId三块缓存
	命名：
		action名： reload_cache
		ReloadCacheAction
		ReloadCacheService
		ReloadCacheServiceImpl
		ClearCacheParameter
			CACHE_MODULE("cache_module",NotEmptyValidator.instance)
		CacheModuleType
			REGION(1),
			ZONE(2),
			CLUSTER_ID(3);
		ServerErrorMessage			  新的错误码，到这里定义
			CACHE_MODULE_IS_EMPTY(-7100,"cache module is empty"),
			CACHE_MODULE_IS_ILLEGAL(-7101,"cache module is illegal"),
			RELOAD_CACHE_MODULE_FAILED(-7102,"reload cache module failed or cache module not found");			
		houyi-spring-action.xml
		houyi-spring-service.xml
			

4. 从StringUtils工具类的选用，看代码耦合 系统设计 工具类设计
	这个工具类在好多第三方包中都有，是直接用还是通过自己项目的工具类再包装下使用？
		为了减少耦合，建议自己做层简单封装，这样对第三方库通过一个入口来管理，即使以后换了实现，也只需要改一个地方即可，不用面临侵入代码
		各个地方的情况。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day85 Tuesday, July 17, 2012

1. 	
	* detail_vm接口 region_no返回为大region_no ？
		修改为大region_no
	* slb v2 用户体系改造
	* slb v1接口测试
		query_available_vips
		QueryAvailableVipsExecuteAction
		IpAddressServiceImpl
			slbRegionService没有注入
		vm region_no找不到slb region_no,报：-95，invoke houyi system error ？
	* list_vm_status
		QueryVmListInfoExecuteAction
		此接口，由于instance对应的image不存在报-90错误
		？是否修改sql，对于image数据错误的记录不返回
		instance.xml 中设置image属性默认值

2. slb v2 用户体系改造 需求分析
	1）代码修改
		支持原有用户验证；并支持新的AliyunIDKP用户方式。
		AliyunIDKP方式：
			请求中有此参数且不为空，表示已鉴权；
			到数据库user表查询此AliyunIDKP，若找不到则新增
		用户信息缓存起来，减少数据库io次数。
	2）数据订正
		涉及的表：user, rs：
			user表的user_id订正为AliyunIDKP的值，订正依据由portal提供，提供原user_id，key,id组合和AliyunIDKP的对应关系；
			rs表，portal提供原user_id，新AliyunIDKP，和rs_pool_name的关系
		订正方式：
			提供执行工具，根据上面的映射关系来更新表
		订正过程：
			（1）依据portal提供的映射关系表（文本方式,格式类似下面，具体格式见实际文本）
				user_id	aliyunIDKP	rs_pool_name
				144		1366		pool1
				144		1366		pool3
				144		1367		pool2
				144		1368		pool4
			（2）通过脚本（python，shell,...）解析上面文本
			（3）执行
				a. 读取第一行，
				b. 取到aliyunIDKP值，
				c. 到user表查询user_id字段是有此 aliyunIDKP
				d. 有则跳过，没有则插入此记录（user_id | user_name | service_secret_key        | service_access_id         | status | is_admin | billing），除了user_id为此	 aliyunIDKP的值外，其他字段和原user_id对应的值一致
				e. 取到 rs_pool_name 值
				f. 到rs表查询此rs_pool_name对应的记录
				g. 无则跳过，有记录，则更新此记录中的user_id值为步骤b得到的aliyunIDKP值，有多条则更新多条（循环执行）
				h. 读取下一行
				i. 继续从步骤b执行 
				j. 循环至末行处理结束

3. python表订正工具
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day86 Wednesday, July 18, 2012

1. 
	*   query_available_vips 接口
		查询时，没有将小region_no转换为大region_no
		QueryAvailableVipsExecuteAction										 s
		IpAddressServiceImpl
	* 用户体系改造项目
		 - 分支见redmine
		 - 订正工具（python脚本实现）
		 - 设计文档
	* 用户体系项目分支
		slb v2 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		houyi api http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_user_reform

2. 

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day87 Thursday, July 19, 2012

1. 
	* 账户体系改造SLB V2相关设计文档编写
	* big region bug fix
	* jteser事务测试
		注意测试框架的事务会影响测试代码事务

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day88 Friday, July 20, 2012

1. 
	* 会议
		防火墙，调度
	* SLB V2用户体系改造设计
	
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day89 Monday, July 23, 2012

1. 
	* SLB V2用户体系改造，根据邮件给出的prd文档，分析
	* big region后续bug提交方式，通过下面的地址建立子任务，并建立对应的bug进行提交：
		http://redmine.aliyun-inc.com/issues/2648
	* 单元测试严格划分职能，对于数据库测试，wiki文件只应出现在dao层中，service层不应该出现（信任dao层），层层完成自己的验证，层间依赖信任
		集成测试情况会跨多个层
	* big region
		- 迭代一周期 ，由于后续变动，需要更新redmine文档
		- device，snapshot，vmAPI这边的权限验证，代码实现  ，具体见redmine新任务 待？

		
2. houyi api白名单
	在配置文件定义白名单ip，spring注入到拦截器等需要校验的地方。
	配置时，多个ip间以“,”逗号隔开，spring注入时，调用set方法注入，在set方法里编写逻辑将ip字符串处理为Map。（通过重写set方法实现指定注入转换）

	也可通过直接在spring配置中配置Map数据。

3.  SLB V2用户体系改造，根据邮件给出的prd文档		  本周完成下面子任务
	- 白名单参考houyi api的实现
		slbapi.properties 配置白名单ip
		AgreementParameter 平台参数验证，session验证改为aliyun_idkp验证
		CheckUserSignInterceptor 白名单验证，注掉以前user_id验证
		GlobalErrorMessage
			新增错误码：ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),


		ServerErrorMessage 错误码定义
			------

				/** server error code **/
				/** -3000 ~ -3099 **/
				
				/** vm FAIL **/
				/** -3100 ~ -3999 **/

				/** snapshot error code **/
				/** -4000 ~ -4999 **/
				
				/** ip error code **/
				/** -5000 ~ -5999 **/

				/**group error code **/
				/** -6000 ~ -6999 **/

				/** admin error code **/
				/** -7000 ~ -7999 **/
			------

		原来用到user的地方需要修改：
			LogInterceptor
				SlbApiLog
			AbstractService
				Rs
				slbapi.sql rs表的user_id字段值为aliyunIDKP，原来是long类型的user_id，故重新定义字段，依据houyi api的user表user_id字段定义：
					aliyun_idkp` varchar(32) DEFAULT NULL, 待确认？
				RsService
				RsServiceImpl
				RsDao
				RsDaoImpl
			LoadBalancerServiceImpl
			查询SLB流量接口
				MonitorInfoDaoImpl
			调用houyi api改动
				ECServiceImpl


	- 原校验机制注释，只采用AliyunIDKP验证机制，是否涉及错误码改动？待检查
	- user表废弃
	- 数据订正：rs表的user_id和rs_pool_name
	- 调用houyi api部分，去掉原有签名（user表已废弃），通过aliyunIDKP方式调用houyi api（houyi api需要将slb api v2加入白名单中）
	- 对于关键点，类编写测试用例
		CheckUserSignInterceptorTest 


4. 设计中，对于id这类的字段，虽然目前是long，后面可能会改为string，设计pojo时最好设计为string类型，
否则后续类型改动，需要改相应接口及实现 设计
	对于某些可预知，后续字段数据类型可能发生变化的场景，设计pojo时考虑好类型，方便后续变动。

5. big region
	校验逻辑梳理：
		
 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day90 Tuesday, July 24, 2012

 1. 
	* 用户体系改造-SLB V2 API
	*  device，snapshot，vmAPI这边的权限验证
		API有user和vm的所属关系（houyi instance表）
		控制系统有VM，device，snapshot之间的所属关系
	* houyi API 与控制系统状态保持
		控制系统状态变化会通知rabbit MQ，API从MQ中得到消息，进行同步 ？	    Message模块中
		通过rabbitMQ java开发包实现
		eg：start_vm控制系统接到后返回200，过一段时间vm启动后，控制系统发消息到MQ,API读取消息，更新vm状态
	* 控制系统重启，导致部分操作成功，部分失败：
		结果之一：一个vm已经stop，但vm表的状态为starting，导致状态不一致。
	* start_vm 控制系统对于vm不存在的情况，不返回结果，API超时返回
	* VmCreateExecuteAction ，在createVM返回空时，instance = (Instance) result.getResultInfo(); 返回了快照对象，导致类型转换错误？
		待修改提交 

 2. 用户体系改造
	- 什么时候可以测试环境连调测试？
		SLB后端
		houyi API
		SLB V2 API
			流量接口
			调用SLB后端
			调用houyi API
	- 数据订正谁来做，portal数据什么时候提供？	     由其他同学负责
	- 测试类
	- 后面的问题在于测试
	- 修改点
		UserDaoImpl.		      废弃
		User			废弃
		UserStatus		废弃
		slbapi-ibatis-config.xml 修改
		UserServiceImpl 废弃
		RequestContext 修改
		UserService  废弃
		LoadBalancerServiceImplTest  修改
		AbstractServiceTest 修改
		User.xml 废弃
		spring-dao.xml 修改
		spring-service.xml 修改

 3.  device，snapshot，vmAPI这边的权限验证
	下面3个接口，暂定由API将必要消息传给控制系统，控制系做资源所属验证：
		a. API层验证user和vm的所属关系。
		b. 由控制系统来判断资源间的所属关系（vm，device，snapshot）

	- [ID:182636 ]retain_snapshot 安全风险 用户可retain其他用户的snapshot
		RetainSnapshotExecuteAction

		需求：用户进行retain快照操作时，检查快照是属于当前用户的
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		此接口，只传递了device_id和snapshot_id
			修改，将vm_name也传递到控制系统，由控制系统来验证vm，device，snapshot之间的所属关系

	- [ID:182495]remove_snapshot 安全风险 可以删除其他用户的snapshot
		RemoveSnapshotExecuteAction
		需求：用户只能删除自己的snapshot
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		[call houyi system. method:RemoveSnapshot,parameter:{"snapshot":"520322test","vmName":"mytestvm2012-2","deviceId":"817"}]
			给控制系统有VM名称,快照ID和设备ID
	- [ID:182101]cancel_create_snapshot时传入的vm_name和snapshot_id不匹配时没有报错
		CancelCreateSnapshotExecuteAction
		[call houyi system. method:CancelSnapshot,parameter:{"snapshotId":"520322","vmName":"mytestvm2012-2"}]
			传给控制系统 快照ID和VM名称，是否应该控制系统验证所属关系？API去验证的话就需要多一步查询控制系统步骤，最后验证还是由控制系统决定。
	- detail_snapshot需要判断snapshot是否属于该用户
		经查看代码，已有验证，跳过
	- umount_snapshot需要判断vm与device判断，device与snapshot判断
		UnmountSnapshotExecuteAction
		经查代码（region.isUpgrade() ==1），已有验证（跳过detail_snapshot接口去控制系统查询了下，这个接口vmName也是传递给控制系统的，对于这种有vmName的情况，
		vm对应的资源所属验证统一交由控制系统处理，API只保证
		user和vm的所属关系？）
		region的isUpgrade判断目的是什么？
			确定的是没有升级的region，快照没有userId字段，不需要验证快照与user的关系

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day91 Wednesday, July 25, 2012

1. 
	* big region
		list_mounted_snapshot接口，返回值中，snapshot_name内容是snapshot_id，如何转换为3元组？
		
	* 用户体系改造
		加入jtester测试框架，便于单元测试
			

	
			
2. list_mounted_snapshot 接口处理snapshot_name为cluster_id-device_no-snapshot_id三元组方式
	确认为API返回的snapshot_name值为snapshot_id，三元组构成，可以通过从控制系统返回结果中得到snapshot的deviceNo，
			从vm得到其clusterId，构造成：cluster_id-device_no-snapshot_id三元组整体返回。
			问题：
				返回结果中的deviceNo是快照挂载上去后，生成的新device的deviceNo,不是快照原来的deviceNo，这样对于用户来说，snapshot_id发生了变化，故不能从返回值的deviceNo拼接三元组
			解决：
				根据控制系统返回的快照id去查询其deviceNo,以拼接三元组返回？
					去detail_snapshot,
						具体见邮件：增加一个snapshot_id的属性，为了兼容性考虑目前保持snapshot_name与snapshot_id一致
	ListMountedSnapshotExecuteAction
		？待测

3. 可用的image ，测试
	select 
		image.image_no,
		image.region_no as imageRegionNo,
		inst.region_no as instanceRegionNo 
	from image image,instance inst 
	where image.image_id=inst.image_id limit 1,2;
	加上user，大region条件，筛选可用image。

4. 高亮显示光标所在字符或字符串
	命令行模式下：
		*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。

	和 /text 方式查询类似，但可根据文本内多次直接搜索，不需输入检索字符串。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day92 Thursday, July 26, 2012

1. 
	* big region 测试用例验证，修改
		http://10.250.8.214:81/surefire-report-dao.html		   fixed
		http://10.250.8.214:81/surefire-report-service.html	   
		提交ID:
			[ID:183748]完善测试用例
	* list_mounted_snapshot接口测试用例修改，提交代码
	* houyi api
		控制系统返回的对象类型定义在各自的command实现类中，可以查看API与控制系统交互的数据格式
		确认rpc返回的pojo类类型。
	* SLB API V2用户体系改造，调用SLB后端的user_id名称不变，只是值为aliyun_idkp
	* SLB API V2流量查询接口，查询的时间早于计量库保存记录的时间点，导致计量库找不到对应的表，API报：
		code":-2001,"msg":"backend service exception
		是否要修改？要知道计量库的表设计逻辑，比如保存几天的记录表？这里跨系统访问数据库，不是接口，导致此类依赖问题
			接口说明是7天，那么需要判断从当前时间往前6天供7天的表是有的，超出这个范围的是没有记录的，API需要做判断，并加入对应的状态码？
				或者超出时间的直接返回空？
				计量库 原lb_global_id改回为lb_id?
					这是旧的库，新库地址：
						mysql -uhouyi_odbs -phouyi_odbs -hmy3306.mysql.aliyun.com xuanyuan

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day93 Friday, July 27, 2012

1. 
	* 用户体系改造	
		涉及到list_vm_status接口改动
	* 	业务熟悉
		技术：多线程，并发，性能，服务器编程，重构
		
	* houyi api 数据推送模块后续重构
		考虑使用独立的缓存系统（比如，memcached），可以在API上抽象出操作缓存的接口，
		可以针对不同的缓存框架使用对应的实现，比如通过操作memcached的接口，操作memcached缓存
	* detail_vm接口问题
		当vm release过后，调detail_vm接口报：-90 system error
		文档没有说明不能查询released的vm
		原因为代码处理问题导致空指针。fixed
		
2.  用户体系改造
	- portal查询vm状态接口，由于此次用户改造，原有的根据144大用户取得其卖出的所有vm状态信息的功能已经不能用（已拆分为子用户，然后没有用户组等关系来
		判断子用户属于哪个大用户；目前，vm主要包含portal和万网的vm，还有少量的其他用户的vm，暂定为在查询用户所有vm状态的接口逻辑里，以硬编码aliyunIDKP方式判断是portal的请求还是
		万网的请求，portal的请求就返回除了万网的所有vm信息，万网的请求只返回万网的vm信息）
	
		问题：
			如何区分IDKP是不是portal来的IDKP？
				设置专门对原144的IDKP值，API根据此值可以知道是否为portal的请求。

		需求变动，验证方式为key方式+白名单方式，即先需要经过key验证（通过在user表继续保留144账户），
		然后判断是否有AliyunIDKP值，如果有继续处理，如果没有处理逻辑待定（判断为管理调用，返回所有接口的所有内容？）
			上面的返回所有内容问题缘于之前是144用户的所有数据，现在切分为一个个独立的IDKP对应的数据，现在要返回这个大用户下所有IDKP账户对应的数据。这样portal需要遍历每个
			IDKP去Houyi API取数据，原来一次即可，如何解决？
				提供一个接口，能根据portal传递过来的IDKP列表批量返回对应的数据。							

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day94 Saturday, July 28, 2012

1. 
	* big region
		排查涉及 RegionHolder.getCurrentRegion() 语句的代码，此代码得到的小region_no可能为用户默认region_no。
			eg：用户为HZ用户，需要到BZ的大region中create_vm，传入的是BZ的大region_no，而小region_no却默认到HZ了？
				可以根据大region_no得到其默认操作的小region_no（）
				检查用到用户小region_no的点
	* 用户体系改造，user表加入代理商ID字段，标识子用户属于哪个代理商
		- 所有请求都需要先经过签名认证
		- 白名单配置代理商ID（IP会存在改变的问题）
		- 没有传AliyunIDKP值，则用户类型为代理商用户，返回结果时需要处理，返回代理商下所有子用户的数据（涉及到的接口由PD整理）
		- 传递了AliyunIDKP的	 ，判断user表是否已有记录，没有则增加记录（代理商ID根据白名单配置），有则继续操作。
2. 
													      


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day95 Monday, July 30, 2012

1. 
	* 用户体系改造，流程图ok
	* big region 
		- RegionAwareInterceptor 的region缓存替换为RegionCacheManage的统一方式
		- RegionAwareInterceptor中，用户传入大region_no时，设置小region不能用user的默认小region,改为从大region的小region列表中取第一个。
			排查代码用用到regionHolder中默认小region的点。
				RegionHolder.getCurrentRegion().isUpgrade()
				boolean isBigEtherNetwork = RegionHolder.getCurrentRegion().isBigEtherNetwork()
				list_vlans接口
					有region_no和zone_no
					ZoneServiceImpl
			提交修改后，在开发环境验证功能
				
	* SLB V2 用户体系改造，构建目录，deploy目录设置好，便于部署
		http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/build.sh

		svn checkout 部署目录：			nginx+tomcat
			在/home/admin/slbapi目录下：
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi
				sh build/build.sh
				sh bin/tomcatctl start
		
		部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
			
			小结：
					当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
				启动失败了，即服务器是起来了，但应用确没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
				ok的情况下极可能就是应用启动失败）。
					这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。
			
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day96 Tuesday, July 31, 2012

1. 
	* big region bug fix
		- 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。

	* 用户体系改造，SLB API build脚本
		当前的方式，需要在部署机去build，可能会因为网络不通等问题导致依赖找不到，编译失败，通过先build再分发的方式解决此问题，也是build机的用意。
		参考已有build过程
	* 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	* big region
		create_vm等接口流程（在原有基础上加上了调度，防火墙的逻辑）
	* SLB V2 在大region项目中的变动
		兼容用户小region_no请求？待
		维护小region_no到大region_no的映射，在请求传入时，将小region_no转换为大region_no。
	* big region
		计量推送，region_no改为大region_no？待
	* 10.230.204.24 部署slb v2 user_reform环境
		在slbapi-user-reform目录
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi .
			删除src目录下的所有内容
		修改build/build.sh的svn地址为 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		sh build/build.sh
		修改spring配置文件中的属性文件路径：默认为 ${user.home}/slbapi/conf目录下
			在src下修改spring配置，然后mvn build
		配置白名单
			slbapi.properties
		通过各自项目的nginx.conf,mime.type文件，启动自己的应用监听。	    （不推荐，这样会导致端口修改，2个独立的nginx进程不能共享同一个端口）
		下面，通过配置转发规则，让多个应用公用80端口：
		 ---------
			  ...
				   server {
					listen       80;
					server_name  openapi.aliyun.com;

					charset UTF-8;

					proxy_connect_timeout 600;
					proxy_read_timeout 600;
					proxy_send_timeout 600;

					#access_log  logs/host.access.log  main;

					if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
					{ 
					  set $domain $1; 
					  set $new_uri /openapi/$domain$request_uri;
					} 

					location /{
					    proxy_set_header        X-Real-IP $remote_addr;
					    proxy_set_header        Host $host;
					    proxy_pass http://127.0.0.1:8080$new_uri;
					
					}

				       location /slb/api{
						   proxy_set_header        X-Real-IP $remote_addr;
						   proxy_set_header        Host $host;
			...
			---------
			此方式，先验证后端服务启动正常，再验证nginx转发正常，因为后端的错误可能不能从nginx的相应内容中直接看到，比如后端tomcat返回404，nginx给你的可能就是
			空白。

2. 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。
	AbstractExecuteAction
	SingleNcResourceAction
	SingleNcResourceActionTest
	CancelCreateSnapshotExecuteAction
	CancelCreateSnapshotExecuteActionTest
	CreateSnapshotExecuteAction
	CreateSnapshotExecuteActionTest
	DetailSnapshotExecuteAction
	DetailSnapshotExecuteActionTest
	ListSnapshotExecuteAction
	ListSnapshotExecuteActionTest
	MountSnapshotExecuteAction
	MountSnapshotExecuteActionTest
	RemoveSnapshotExecuteAction
	RemoveSnapshotExecuteActionTest
	RetainSnapshotExecuteAction
	RetainSnapshotExecuteActionTest
	RollbackSnapshotExecuteAction
	RollbackSnapshotExecuteActionTest
	UnmountSnapshotExecuteAction
	UnmountSnapshotExecuteActionTest
	VmCreateExecuteAction
	VmCreateExecuteActionTest

3. 用户体系改造 houyi api
	user表修改，sql修改：
	alter table user add is_agent tinyint default 0 COMMENT '@desc 0 不是代理商，默认为0;1 是代理商';
	alter table user add agent_id int(10) unsigned DEFAULT null COMMENT '@desc 代理商ID，表示子用户属于哪个代理商';
	alter table user add image_using_mode int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted;1 : only private image permitted';
	alter table  user  add  image_using_mode  int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted ; 1 : only private image permitted';

4. userholder 加标识isGent，标识用户身份。
	user插入逻辑确定：

5. 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	- user表增加字段，参看第3条
	- 修改user表改动涉及的类改动，mapping文件改动
		user.xml
		User
	- UserHolder不变，存入的是代理商用户还是最终用户需要根据user的isgent属性判断
	- 老userId方式调用时，订正表时，isagent要标记为0，即非agent用户（比如万网）
	- 兼容老userId方式调用（isgent=0，但agent_id为空），新aliyunIDKP调用，管理接口调用（取得对应的子aliyunIDKP账号）
	- 新aliyunIDKP插入user记录，字段定义：
		aliyun_idkp
		key
			沿用其代理商的key，自己的key字段为空
				由于原user表字段约束，某些字段必须设置值（或者修改表约束，暂定位不动约束）
				user默认值：insertSql = " insert into  user ( default_region , default_zone , aliyun_idkp ,  user_name ,  md5_password ,  service_secret_key , email ,  service_access_id ,  status ,  gmt_last_login, agent_id ) 
											values('cn-hangzhou-1','cn-hangzhou-1-a', $idkp, $idkp, $idkp, $idkp, 'developer@aliyun.com', $idkp, 0, now(), 144) ; "
		region_no
		zone_no

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day97 Wednesday, August 01, 2012

1. 
	* 用户体系改造，houyi api
	* 用户体系改造，SLB V2 api
	* 大region，slb v2兼容小region

2. 用户体系改造，houyi api
	- 是否为管理接口调用的判定？在白名单且aliyunidkp值为空
	- 在判断IDKP是否为空前，增加判断，请求的接口是否必须IDKP参数值
		在哪里判断？通过配置文件还是其他方式标识
	- 搭建 houyi api user_reform版本开发环境， doing
		10.250.8.214
	- 	- 万网等非白名单用户，数据表订正时，标识为非agent用户，即isagent=0（万网等非白名单用户，和以前一样没有切分子用户）


		
3.  用户体系改造，SLB V2 api
		需求待确定，SLB v2都需要做签名验证？
			user表存基本的验证必须字段，aliyunIDKP透传和调用。
			slb v2 api请求vm api和原来一样，走签名

4. 大region，slb v2兼容小region
	兼容用户大小region_no请求，小region_no转换为大region_no；
	传递给SLB后端为大region_no；
	后端接受的是大regionNo,对其数据推送影响？待确定
	- sql修改
		alter table region_mapping add vm_big_region_no varchar(32) NOT NULL COMMENT '@desc vm big region no',
		一个vm小region_no对应一个vm大region_no，一个vm大region_no对应一个slb region_no。
		修改约束，slb region_no与 vm_big_region_no联合主键：
			alter table region_mapping drop primary key
			alter table region_mapping add constraint primary key (region_no,vm_big_region_no);
		region_mapping表维护：
			vm小region_no和vm 大region_no关系，
			加上vm大region_no和slb region_no关系，2种关系。
			
	- region拦截器中中处理大小vm region_no请求兼容问题：
		将小vm region_no转换为大vm region_no后放入threadlocal中，
	- SLB API调用需要lb所属的vm region_no，SLB API调用SLB后端只在create_loadbalance接口传入了vm的region_no。8/1/20128/1/20128/1/2012
	- 兼容大小vm regionNo调用程序要处理的有两个地方：
		a. 由vm regionNo取到对应的slb reigon，从而知道slb region调用信息
		b. create_loadbalance接口需要将vm大region_no传递给SLB后端
	- bug id：[ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	- 修改结束后，用 AbstractServiceTest 类测试几个接口，验证修改逻辑。	
	- 大region中SLB V2 API没有分支，提交的代码需要回滚，重新拉分支提交，待处理？


sudo bash root

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day98 Thursday, August 02, 2012

1. 
	* 用户体系改造 houyi api
		提供管理者调用功能，
		修改的点：
			- 签名验证逻辑实现完善
			- 白名单userid配置，以区别是idkp调用还是老接口调用及是
				配置到spring文件中（List便于判断是否存在）
			- 配置必需待IDKP参数的接口，即不提供管理功能的接口
				配置到spring文件中（List便于判断是否存在）
				必须带IDKP参数的接口，在拦截器中就判断后，如果没带返回错误；对于业务接口调用不用修改、
				业务接口不需修改的接口列表：
					1) 创建VM 
					2) 创建自定义image  ： A, 用户自定义image， idkp为用户id；B,对外售卖的自定义镜像， idkp指定为：26842
					3) 新增硬盘 
					4) 创建Group
					5) 创建快照 
					6) 创建Key Pair
			- 对于其他接口，都需要处理管理接口调用
				业务接口需要修改
			- 资源check类中（instance,ip,...ResourceChecker ），增加代理商调用处理逻辑，如果是代理商调用，且资源所属用户的代理商
				check列表：
					InstanceChecker
					GroupChecker
					ImageUseChecker
					IpAddressChecker

			- 对于有管理功能接口的修改，支持返回代理商下面所有用户对应原接口的数据
				以list_vm_status接口为例。
				查询数据时，原来根据user_id筛选；现在对于代理商调用，需要返回代理商下所有用户的数据。
			- 对于接口返回值，代理商调用和最终用户调用（老user_id方式比如万网，待IDKP值的用户）的区别
				类似detail_vm(指定了vm)，list_snapshot（指定了device）接口，指定了资源操作的接口，返回的是资源所属的信息（不存在跨代理商的子用户）
				类似list_vm_status（指定用户），指定用户去操作用户的数据的接口，代理商去调用时，返回或操作的是代理商下所有用户的数据
			- 对于代理商，也分配有IDKP，如果传入的是代理商自身的IDKP，视为最终用户处理
				在返回代理商所有用户的数据时，还需加上代理商自身的数据（能否通过将代理商的agent_id设置为其自身一个sql解决？）
			- 对于万网这些没有进行用户改造的用户，数据订正时，标识为非代理商用户。
			- session拦截器取到用户后，需要判断其is_agent值为1（是代理商），这层check是因为最终用户的session_id列也是有值的（现在订正为用户的idkp），如果其传session_id为自身
			的idkp时，会误认为其实代理商。
				上面方式兼容万网等老用户调用有问题（万网is_agent=0）,判断代理商条件修改为：能根据session_id找到用户且其service_secret_key值不为空
				
			- houyi api数据库的user表，service_secret_key字段去掉不为空约束，对于代理商的子用户，此字段为空
			- 配置白名单和action必须带IDKP的配置文件为：/houyi-console-openapi/src/main/resources/houyi-openapi.xml


	* 用户体系改造 SLB V2 API需求列表：
		- 所有请求都需签名验证（和用户体系改造前的验证一样）
		- 只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的key）
		- 原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
		- rs表数据订正

2. 用户体系改造 houyi api  —— 参考第一条说明
	管理接口修改：
		- detail_vm
			VmQueryExecuteAction
			getInstanceService().viewInstanceAtNc(instance); 做权限验证（注解方式），需要修改：
				修改check包下对应的 InstanceChecker 
				
			ResourceChecker抽象类中加入user cache，便于子checker调用。

			InstanceChecker 修改，后面vm验证所属用户操作都会用这个checker，不再做说明
			
		- list_vm_status
			先
	
	acl模块与service模块相互引用，导致依赖循环，如何解决？
			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day99 Friday, August 03, 2012

1. 
	* 用户体系改造，houyi api
		- 解决maven循环依赖问题，将依赖的接口独立到一个接口模块中，接口的实现在其他模块中
			mvn a
		- cache方式，
	* 大region项目
		涉及SLB V2 API改动点，需要另开分支提交，不在下面分支提交，对已提交的兼容大小region_no调用修改进行回滚：
			http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 用户体系改造 SLB V2 api 代码回滚，提交后，将需要修改的地方再reversion回来
		

2. 用户体系改造 houyi api 
	    管理接口修改
		check修改
			ipAddressChecker
				isBinary 判断ip是否为网段
		- list_vm_status			列表接口
			限定条件：
				region_no	必选	string		云服务器所属于的Region
				zone_no	必选	string		云服务器所属的可用域
					zone如果没传，取代理商的默认zone，保持原接口一致
			QueryVmListInfoExecuteAction
				是代理商时，去掉一些限定参数（如zone_id）	      ,不去掉，代理商也需要传
			instance.xml
				where条件里加上代理商查询条件，关联user表，查询出代理商所有子用户的数据
					传参时需要处理
			InstanceServiceImpl. 的 queryOwnInstances方法
				涉及传入user筛选条件的地方需要修改（处理代理商调用条件）。			
					数据订正逻辑？万网关联user_id字段，得到其instance列表；传入IDKP值的用户，也是关联user_id字段？
						数据订正案例：业务方提供aliyun_idkp和vm_name的映射表，订正工具到user表加入此idkp对应的用户（user_id为自增值）记录（如果没有的话），然后
						把user_id这个自增值更新到instance表对应vm_name的记录。
			修改的sql是否会被多个dao层调用，加入了agent_id筛选条件是否会影响其他调用此sql的逻辑？
				控制传入agetn_id的入口，即agent_id是显式的传入的，调用者知道传入agent_id会返回什么样的结果。
					当前设计，只好在dao层还去取user信息，后续需要重构，参数从service传过来，dao层不做过多依赖 -tip-
						在原有的statement上在加上分支查询逻辑，不利于维护，后续需要修改。
			InstanceDaoImpl
		- start_vm
			VmStartExecuteAction
			InstanceServiceImpl
				addUrlCallback方法中，当是代理商调用时，不能取UserHolder.getCurrentUserId()用户，暂定用instance对象的user_id属性，待确认？
					后面需要搜索整个项目用到：UserHolder.getCurrentUserId() 和 UserHolder.getCurrentUser() 的地方，确认调用是否ok？
				每个操作过后，把回调信息存入houyidb的url_callback表。
		- stop_vm
			VmStopExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法
		- restart_vm
			VmRestartExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法


3. 用户体系改造bugfree
	http://bugfree.corp.taobao.com/bug/list/156?productmodule_id=12215


4. 系统设计tip
	- maven开发时，模块划分，在依赖方便需要设计好，可以剥离接口和实现到不同模块，避免交叉依赖问题
	 - 方法的参数设计，需要利于扩展，比如增加或减少参数，或不同类型的参数等需求。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day100 Saturday, August 04, 2012

1. 
	* 
2. 用户体系改造 houyi api 
	重要：
		- 原用到UserHolder.getCurrentUser() 或 UserHolder.getCurrentUserId()的地方，都需要考虑user不是最终用户的情况了。	     （幽灵般的userholder~~~）
		- 代理商调用时，regionNo需要模拟最终用户的调用，否则会取代理商自身的默认region去操作。
		- describe_vip接口属于slb v1接口，不需要处理
	管理接口修改
	- release_vm
		VmReleaseExecuteAction
		InstanceServiceImpl
			releaseInstances方法，释放的VIP时需要传入user_id
				暂改为instance的user_id，即销毁vm时，vm的vip和vm的user_id一致。
			修改的点：
				GetVIPInfoCommand
				IpAddressServiceImpl
				IpAddressService
	- reset_vm
		VmResetExecuteAction
		ImageDaoImpl
			selectImageByNos方法在dao层，调用了threadlocal中的user，建议从调用层传参过来，避免各层充斥这全局变量。
			修改多个点：
				实现查询资源带user信息
		InstanceServiceImpl
			getInstanceService().addUrlCallback(instance, url,Message.statusSync);
	- reset_passwd
		VmResetPasswdExecuteAction	       
	- modify_vm
		VmModifyExecuteAction
	- modify_flow_limit
		VmModifyFlowLimitExecuteAction
	- modify_hostname
		ModifyVmHostNameAction
	- create_image
		CreateImgExecuteAction
		因为必带IDKP值，故userholder中的user为end user，业务逻辑代码不需修改
	- remove_image  ？
		先查询image和user关系，然后删除，代理商去查询image是否存在时，是否会存在返回多个image的情况，
		即：imageNo+end userId是唯一的，imageNo+agent userId不唯一，可能会删除过个子用户同名的image，待确认？
			加个参数标识代理商所操作的用户ID？targetAliyunIdkp
				加个resource_owner参数（值为IDKP），以便代理商告知api其操作资源的目标用户是谁
					错误提示：resource_owner不能为空
						RESOURCE_OWNER_IS_EMPTY(-8000,"resource_owner must set")	resource_owner参数值为空或没传
						RESOURCE_OWNER_NOT_EXISTS(-8005,"resource_owner not exists") resource_owner对应的用户找不到
		RemoveImgExecuteAction
			if(image.getUserId() != UserHolder.getCurrentUser().getUserId()){ 修改增加处理代理商调用逻辑
		ImageServiceImpl
			增加方法：queryImageDetailByImageNo(String image_no,Long userId)
	- recover_vm
		VmRecoverExecuteAction
	- query_available_ncs
		QueryAvaliableNcsExecuteAction
	- query_available_isos	 列表接口
		QueryAvaliableIsosExecuteAction
		IsoServiceImpl 
			加入代理商查询逻辑
				新增代理商查询业务接口
			修改点：
				IsoDao
				IsoDaoImpl
	- mount_iso
		VmMountIsoExecuteAction
			
		


3. 通过方法拦截器结合注解来实现权限验证，设计的好，是个好的方式。	   设计 -tip-
		将日志记录，性能统计，安全控制，事务处理，异常处理等代码从业务逻辑代码中划分出来，通过对这些行为的分离，
	我们希望可以将它们独立到非指导业务逻辑的方法中，进而改变这些行为的时候不影响业务逻辑的代码。

4. 业务逻辑堆在action层，导致依赖变动复杂
	

5. 读取Houyi配置信息发生错误，装载Endpoint信息不能为空
	houyi api启动时会初始化到控制系统的endpoint对象，需要提前在数据库配置好。
	at java.lang.Thread.run(Thread.java:619)
Caused by: com.aliyun.houyi.clc.CLCConfigException: 读取Houyi配置信息发生错误，装载Endpoint信息不能为空！
        at com.aliyun.houyi.service.support.CommandExecutorFactory.afterPropertiesSet(CommandExecutorFactory.java:88)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1369)

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day101 Monday, August 06, 2012

1. 
	* big region bug fix
		调用cancel_create_snapshot时传入的vm和snapshot不匹配时，报-95
	* 用户体系改造-houyi api修改
	* 用户体系改造，slb api 需求列表，最后修改整理说明，便于调用方知晓 待？

2. 用户体系改造-houyi api修改
	- mount_iso
		VmMountIsoExecuteAction
			增加处理代理商操作逻辑，此类验证逻辑代码后续可以移到service层，或者再抽取，提到切面中去。-tip-
	- unmount_iso
		VmUnMountIsoExecuteAction
	- add_disk
		AddDiskExecuteAction
	- remove_disk
		RemoveDiskExecuteAction
	- shift_disk
		ShiftDiskExecuteAction
		------
		...
		@Authority(
			{ @Entry(action = Action.VM),
					@Entry(action = Action.VM, resource = @Resource(argNo = 1)) })
			@InstanceStatusConstraint(statusSet = InstanceStatusSet.canRecover)
			public Result<?> shiftDisk(Instance instance, Instance srcInstance,	  权限验证，多个entry，后续指定位置
		...
		-------
	- detail_vm
		VmQueryExecuteAction
	- query_vm_security
		QueryVMSecurityExecuteAction
	- query_available_imgs			     列表接口
		是否需要带目标用户去查？
		查询代理商可用的image，这个结果是否为业务方需要的结果？
			暂定返回代理商下所有的
		ImgQueryExecuteAction
		ImageServiceImpl 增加代理商查询可用image逻辑
		imageUsingMode对结果的筛选逻辑？	代理商查询时，设置默认
			0 : default 可以使用公有image和自建image   1 : 只使用自己的image
	- query_unassigned_ips			 列表接口
		QueryUnassignedIpsExecuteAction
		user_id需要传给控制系统，结果如何返回？分页返回	，代理商调用返回public的ips
		注意：ip相关接口，user_id都传递给了控制系统，api层不能通过代理商调用
	- assign_ip  ？
		确认houyi db的subnet表，原user_id=144的记录，是否都订正为public？如果是这样，那么传递代理商ID给控制系统即可。
			这样接口就不需要修改，代理商传递代理商的userId给控制系统
		AssignIpExecuteAction
		IpAddressServiceImpl
			assignIpAddressCommand 需要带user_id	   ？？
			ipStatusCanOperate方法代理商调用逻辑添加
	- release_ip	？
		ReleaseIpExecuteAction
		ReleaseIpAddressCommand 需要带user_id操作，必须传IDKP？
	- bind_ip	    ？
		BindIpExecuteAction
		BindIpAddressCommand 需要user_id到控制系统		？
	- unbind_ip     ？
		UnBindIpExecuteAction
		UnbindIpAddressCommand 需要user_id传递给控制系统 ？
	- open_ftp_pasv
		OpenFtpPasvExecuteAction
		IpAddressServiceImpl
			非大二层网络下，需要判断用户是否可用ip
				ipStatusCanOperate方法，增加代理商调用处理逻辑
	- add_ip_segment			 ？
		AddIpSegmentExecuteAction
		大二层，AddIpSegmentCommand需要传user_id到控制系统，代理商如何调用	      ？
		非大二层，IpSegmentServiceImpl 的addIpSegment方法执行添加操作时，需要user_id ？
		解决：
			类似create_vm接口，必须传IDKP？
	- add_dns_alias
		AddDnsAliasExecuteAction
	- del_dns_alias
		RemoveDnsAliasExecuteAction
	- monitor_vm
		VmMonitorDataQueryExecuteAction
	- monitor_vm_topn	       doing
		VmTopNMonitorExecuteAction
		需要到monitor库去查询，哪里的表没有agent_id字段，只能在api层遍历agent对应的所有user，然后去查询
		monitorInfo.xml

	- create_group
		必须传IDKP
	- authorize_group		  
		AuthorizeGroupExecuteAction
		AbstractGroupAuthExecuteAction
		需要知道用户所拥有的group，代理商调用没有目标用户标识？
			根据之前查询出来的group，找到userId，保证源group都是属于这个userId的（原逻辑是直接传userHOlder.getCurrentUser().getUserId()）
	- revoke_group 撤销group规则	     
		RevokeGroupExecuteAction
	- adjust_group_auth
		AdjustGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 方法增加代理商查询子用户数据逻辑
	- remove_group
		RemoveGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 
	- detail_group
		DetailGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupWithAuthes方法增加代理商调用处理逻辑
	- query_groups			   列表接口
		QueryGroupsExecuteAction
		GroupServiceImpl
			viewOwnGroups方法增加代理商调用逻辑
	- guard_ddos
		GuardDDoSExecuteAction
		对ip进行操作
		IpAddressQuerier 查询出ip资源（需要user_id）	     结合ipaddresschecker
			public Map<String, IpAddress> query(String[] businessCodes) {
	- unguard_ddos
		UnguardDDosExecuteAction
	- query_vm_device
		QueryVmDeviceExecuteAction
	-  create_snapshot
		必须带IDKP
	- cancel_create_snapshot
		CancelCreateSnapshotExecuteAction
	- retain_snapshot
		RetainSnapshotExecuteAction
	- list_snapshot device的所有snapshot列表
		ListSnapshotExecuteAction
	- detail_snapshot
		DetailSnapshotExecuteAction
	- list_mounted_snapshot
		ListMountedSnapshotExecuteAction
	- remove_snapshot		imageService没注入？	     spring在配置文件中声明自动注入
		RemoveSnapshotExecuteAction
	- rollback_snapshot
		RollbackSnapshotExecuteAction
	- mount_snapshot
		MountSnapshotExecuteAction
	- unmount_snapshot
		UnmountSnapshotExecuteAction
	- query_nc_resources	 查询集群的nc资源信息（regionNo中的zone_id范围）
		ClusterNcResourceListAction
	- detail_nc
		SingleNcResourceAction
	- query_regions		？
		 RegionQueryAction
		 RegionSQL.xml 的 Region_listRegion 块带了分页参数，接口中无分页参数说明？
	- query_zones	  查询指定集群下的Zone信息
		ZoneQueryAction
	- query_racks 查询指定region,，指定zone下rack列表
		RackQueryAction
	- list_vlans	  查询指定集群的Zone下的VLan信息 ？
		VlanQueryAction
		GetVlanListCommand 需要传递user_id？
	- query_instance_type	  查询云服务器类型
		QueryInstanceTypeAction
	- create_key_pair
		必须传IDKP
	- remove_key_pair
		KeyPairRemoveExecuteAction
		KeyPairServiceImpl
			public ErrorCode removeOwnKeyPair(String keyPairName) { 增加代理商处理逻辑。
	- describe_key_pair
		KeyPairDescribeExecuteAction
		KeyPairServiceImpl
			修改describeOwnKeyPair方法，增加代理商调用逻辑
	
3. image ,iso,snapshot三者关系
	image为用户自定义image，系统盘
	iso镜像为数据镜像，可以被挂载。

		image为系统盘，iso可以是数据盘，也可以是系统盘，可以挂在到vm上

		vm基于image创建,imagej基于系统盘快照创建，iso就是系统光盘具有配置脚本，image没有配置脚本；vm通过iso修复。

		业务：iso类似系统光盘，挂在在光驱上，只读

4. 权限	，权限体系结构之一
	级联权限关系
		有了vm的操作权限，默认就有对vm已有资源的操作权限，比如卸载快照，查询其ip信息等

5. pojo
       BaseDomain中的动态字段，维护一个map，动态添加字段，这种方式用pojo传递动态新增的属性值到其他层。
	dynamicFileds

6. 用户体系改造，houyi api测试环境
	http://10.250.8.214/open/service?action=detail_vm
	部署的tomcat报内部错误：
		500 
		The server encountered an internal error () that prevented it from fulfilling this request.
		java.lang.NullPointerException
	org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
	com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
	org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
	org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
	com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
	org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
	org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
	org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
	org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
	是不是服务器文件不完整？
	请求路径错误，应用的struts拦截器抛错，没有log，定位struts没找到执行的action，
	nginx + tomcat
		nginx负责把符合要求的uri请求转发给tomcat，tomcat自己配置接受处理的uri。

	MQ配置
		message.properties
	EC配置（控制系统）

	配置文件目录
		/home/admin/.houyi/
	EC日志查看
		root@houyi-vm17.dev.sd.aliyun.com # vim /var/log/houyi/master/HouyiMaster.LOG
		10.250.8.212
7. nginx + tomcat
	请求uri设置，在nginx的conf配置文件里，告诉那些uri需要proxy_pass到目标应用服务器地址即可，nginx直接把请求转发给应用服务器。

8. ip,vlan 资源的userId在控制系统维护，依赖性增加

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day102 Tuesday, August 07, 2012

1. 
	* 用户体系改造 hoiuyi api
		remove_image最终定为加上 resource_owner标识最终用户
	
2. 处理day101第2条带问号的接口
	
3. linux + tomcat7 + houyi api		  ，500 internal error 1990 
	http://10.250.8.214/open/services
		正确URI
	http://10.250.8.214/open/service
		这个路径由于struts没有配置此action（请求的uri找不到映射的action，即找不到servlet），导致在struts的自带拦截器：
			 <interceptor name="prepare" class="com.opensymphony.xwork2.interceptor.PrepareInterceptor"/>
			执行时，浏览器报：500 java.lang.NullPointerException 空指针错误，
			错误如下：
				----------
					HTTP Status 500 -
					type Exception report
					message
					description The server encountered an internal error () that prevented it from fulfilling this request.
					exception
					java.lang.NullPointerException
						org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
						com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
						org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
						org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
						com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
						org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
						org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
						org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
						org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
				----------
			debug进入源码分析：
				----------
				    protected void prepare() {
					String profileKey = "create DefaultActionProxy: ";
					try {
					    UtilTimerStack.push(profileKey);
					    config = configuration.getRuntimeConfiguration().getActionConfig(namespace, actionName);

					    if (config == null && unknownHandlerManager.hasUnknownHandlers()) {
						config = unknownHandlerManager.handleUnknownAction(namespace, actionName);
					    }
					    if (config == null) {
						throw new ConfigurationException(getErrorMessage());
					    }		
				----------		
				在找不到  config 时抛出了ConfigurationException。

		从上面错误结果看，程序已经执行到houyi api应用中，在struts框架中报了错，找不到action的config信息。

		然后看houyi api的action配置，地址为services ，struts找不到action，prepare拦截器执行时就抛出了异常，可能是设置原因，应用和服务器都没有对应log，囧。

		实际struts.xml配置的action路径为services。

		小结：-tip-
			先判断问题出在哪个层次/部分，有log依据log，实在没log，debug源码，查找是什么原因导致抛出问题

4. vim 查找替换
	vi/vim 中可以使用 :s 命令来替换字符串
	:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
	:s/vivian/sky/g 替换当前行所有 vivian 为 sky
	:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
	:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
	n 为数字，若 n 为 .，表示从当前行开始到最后一行
	:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
	:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
	可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
	:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	


5. 用户体系改造-houyi api白名单暂放到 houyi.properties中

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
typhoon

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day103 Thursday, August 09, 2012

1. 
	*  用户体系改造-houyi api
		集成测试
			
	* 用户体系改造-slb api
		rs表订正
			portal提供 lb_id ,IDKP映射表，订正lb_id不为null的记录中的user_id为IDKP值
			另外订正lb_id为null的记录的user_id为指定的测试用IDKP值
	* big region
		流量接口bigregion查询检查

2. 本机ip地址是通过dhcp获取的，测试环境调用本地mysql，需要调整ip。 houyi apidev测试环境（8.214）

3. 用户体系改造-houyi api
	不支持管理员是个最终用户
		比如不能创建vm
	集成测试
		白名单userId,
			管理接口
				299代理商操作其子用户数据
					比如detail_vm （属于275用户）
				调用必传IDKP接口时，报错
			最终用户
				299的一个子用户调用
			万网老用户调用	       （没进行用户体系改造，is_agent=0,agent_id=null）
				is_agent=0
	接口修改
		  monitor_vm_topn
		VmTopNMonitorExecuteAction

4. spring抽象类注入，spring接口注入有区别 * spring
	抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	还是尽量面向接口编程
5. 测试 create_vm保证image对应的快照是存在的
	表查看，找快照id
	detail_snapshot 查询快照详情（有快照id值）	
	15-147019-137.vhd                           |          1 |      21 | 428         | AT03-HOUYI1
6. monitor计量数据	  业务
	根据是否大二层网络，对应的数据在不同的库中，表结构不一致。
		rx - rx_intra
7. slb 8.214测试
	http://10.250.8.214/slb/api?
	houyi api
	http://10.250.8.214/open/services?


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day104 Friday, August 10, 2012

1. 
	* 用户体系改造 slb api处理
		query_monitor_vms 
			VmPageMonitorExecuteAction

	* 用户体系改造　houyi api bug fix
		
2. 用户体系改造 slb api处理						  slb v2 api
	用户体系改造 SLB V2 API需求和关键点列表：
	1）所有请求都需签名验证（和用户体系改造前的验证一样）
	2）只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的签名信息）
	3）原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
	4）rs表数据订正
	5）slb api透传aliyun_id值给slb后端，参数名和原来一致（即user_id）

	对照上面需求点，处理SLB api代码

	修改点：
		新增错误码：
			ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),
3. mysql数据dump
	mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
	source /home/xx.sql

4. 
	8.214开发测试环境的slb环境，新建slb后端的计量库便于测试，地址在本机
	houyi api 的db改用big region的db（6.27的db）


	http://www.cnblogs.com/lovecindywang/archive/2012/08/06/2624678.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day105

1. bug fix


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day106 Monday, August 13, 2012

1. 
	* 用户体系改造 houyi api bug fix
		- live_migrate_vm 接口修改（需求时文档未列出此接口）
		- create_vm接口
			处理user_image_mode的逻辑，  只用自己的image还是可用自己的和公有的	   （0可用自己和公有的image；1只能用属于自己的image）
		- reset_vm
			处理user_image_mode的逻辑，只用自己的image还是可用自己的和公有的
		- release_ip
			控制系统新增接口，根据ips得到vm_names，api根据vm_name验证是否有release_ip权限。
			
	* 
2. 

3.  Linux查看程序端口占用情况，占用的程序
	Tomcat 8080端口起不来，老提示端口已经被占用。
	使用命令：
	ps -aux | grep tomcat
	发现并没有8080端口的Tomcat进程。
	使用命令：netstat –apn
	查看所有的进程和端口使用情况。发现下面的进程列表，其中最后一栏是PID/Program name 
	clip_image002
	发现8080端口被PID为9658的Java进程占用。
	进一步使用命令：ps -aux | grep java，或者直接：ps -aux | grep pid 查看
	clip_image004
	就可以明确知道8080端口是被哪个程序占用了！然后判断是否使用KILL命令干掉！
	方法二：直接使用 netstat   -anp   |   grep  portno
	即：netstat –apn | grep 8080

4. houyi api db业务
	iso表
		user_iso - 标识iso是用户上传还是管理员上传的，用户查询iso时，不会返回user_iso=0的iso，
		visibility标识iso可见性，0为公有（此时忽略user_id），1为私有
	image表
		visibility 0为公有（忽略user_id），1为私有
	
	资源所属校验时，处理这些逻辑。不仅筛选user_id条件，还需处理公有私有情况等。

	remove_image
		删除image，用户必须为image所属的user_id，或其代理商
	
	user表
		image_user_mode 0可用自己和公有的image；1只能用属于自己的image
5. 根据ips返回names
	http://10.250.6.111/wiki/index.php/QueryVmByIp

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day107 Tuesday, August 14, 2012

1. 
	* 用户体系改造 - houyi api
		release_ip
		ReleaseIpExecuteAction
		需求：
			修复用户可以release状态为public的ip，控制系统提供根据ip列表找到vmName列表接口，api判断vm与用户的所属关系后执行release操作。

		IpAddressServiceImpl的 public Result<Object> releaseIpAddress(String ipAddress) 方法，注解判断权限
		@Authority(
		{ @Entry(action = Action.IpUse, actAtNetwork = HouyiNetworkSetting.nonBigEther, resource = @Resource(identify = Resource.Identify.QByCode, argNo = 0)) })
		对于以“，”隔开的ip，根据注解配置找到其资源查询类，验证每个ip的权限
		
		增加错误码：
			IP_ADDRESS_UNAUTHORIZED(-5008,"has no privilege to release ip"),
		release_ip
			ip为多个ip用“,”隔开时，根据资源定位region时报错-90。
			那个版本修复？
	* x
2. 签名时api去掉了某些字段，然后进行服务端签名，再与用户签名比对
	去掉 app_key,sign,sign_type，
		app_key

3. houyi api bug fix
	- bug id：187183
		UNIQUE KEY `key_pair` (`key_pair_name`,`user_id`) ，key_pair表key_pair_name不唯一

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day108 Wednesday, August 15, 2012

1. 
	*　用户体系改造 houyi api
		remove_key_pair
			KeyPairRemoveExecuteAction
			增加错误码：
				ILLEGAL_RESOURCE_OWNER(-8007,"illegal resource_owner")		   
					resource_owner表示的IDKP不是最终用户或不是当前代理商的子用户
		describe_key_pair
			KeyPairDescribeExecuteAction
			2个接口都增加 resource_owner 参数，标识代理商操作资源所属的用户标识，和remove_image类似。
		release_ip
			控制系统对于没分配的ip，vm_name值为0，此为控制系统的业务，返回给api应该为空。
			api判断ip没找到vm。
2. 

3. 业务
	资源No定位region，zone_ip表通过ip的long格式映射其对应的zone。

4. 
	 * @deprecated
	 * @param keyPairName
	 */
	public

5. 日志级别定义
	info
	debug
	error
	fatal
	对各种异常的日志级别设置
		系统级错误打error
		业务级别，用户级别打info
		调试用的打debug

6. rpc同步，异步调用 （封装rpc调用包，内部提供调用接口，对外屏蔽调用细节） aos
	线程池调用
	ThreadPoolExecutor
		java concurrent包
	
	每个请求封装为一个个工作任务（task，workitem），交给工作线程池去处理。
	
	接口开发，面向接口开发、
	
	合适的工具
7. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Wednesday, August 16, 2012 - Wednesday, August 26, 2012
missing by svn revert operation
补加：

* svn 代码合并(tortoiseSVN)
	- 打patch，合并patch
		通过svn工具将原来此bugId的修改保存为patch/diff，然后apply patch到新项目中 apply patch
			打patch时注意，若patch生成时所基于的版本与将要apply到的版本不同，即中间不一致则apply时会有冲突，需要手工解决。
	- 
	eg：branch合并到trunk
		将trunk代码check out到本地，在其目录中调用merger命令，选择相应的选项，可先预览合并结果，进行合并；
		合并好后，通过diff工具(kdiff)对比branch目录，验证合并是否正确。
		kdiff 
			对比时可设置参数，比如忽略的文件或目录等，然后比较。
		合并好后，svn commit
		QA测试(提测)
	对于2个并行的分支都做了大量交叉的修改的情况，要尽量避免；如果已发生（big region&user reform)通过工具理解2个支的逻辑人肉合并并加全量回归测试。

* 发布步骤整理及演练，发布失败回滚方案设计
	保证正式发布顺利和优化发布流程

	发布步骤细化到每个命令，具体到能直接执行。

		服务停止
		数据订正
			大数据量，关联复杂时，订正方式，订正语句的优化
		代码发布
		回归测试

	多系统联合发布，需要全盘考虑。
* 系统全局变量使用设计
	在mvc架构中，全局变量控制在c层即控制层，比如action层，保证其他层的逻辑不会意外的从全局变量中去取值，导致控制层对逻辑的不可控，不利于后续的
	扩展和维护。
	userholder控制范围，就不会出现不走到dao的执行层（参数交给ibatis）都不敢保证最终传入的参数的担心，它可能在dao层从userholder取了userId传入的~
		不利于统一验证user的逻辑，而需要

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day118 Monday, August 27, 2012
1. 
	* big region+user_reform check go on
		对user_reform改动到的接口，big region和进来后，再进行review，是否满足user_reform需求？
		根据之前列出的修改接口列表查看：
			

	* 权限验证优化重构，aop，切面编程，方法拦截器
		可通过注解，将必要的参数放到方法的参数中，通过拦截器来处理这些注解，来验证用户操作资源的权限，这种设计，需要将待验证的资源显式的定义出来，比如
		通过放在方法的参数中（一般在service层），通过方法拦截，进行权限验证；从而，避免验证逻辑充斥业务代码，也利于维护和扩展。-tip-
			eg：
				现有的vm和user的验证就是通过方法拦截器，解析service层操作资源的方法中的参数（由注解定义check类型和check的arg）来验证用户操作vm的权限。

		验证能不能操作（比如现有的vm和user所属）和根据用户类型不同调用不同逻辑需要区分开，将功能分类；比如start_vm只需验证能否操作，后续操作管理接口和end user是一样的。

		小节下权限分类：
			不同系统有不同的权限体系，用户权限体系中，有角色权限（不同的角色对应的可访问功能不一样），资源权限/数据权限(对资源或数据用户是否有权限查看或操作)。
		
		user_reform项目由于接口设计，不便于

2. big region+user_reform check go on
	- 合并好的代码与big region比较，分析user_reform的修改点 ，是否正确
		无
	- 合并好的代码与user_reform比较，分析big_region的修改点，并分析是否需要再修改
	查看big region的代码是否有需要对应user_reform进行修改？
		- SnapshotServiceImpl
		     mountSnapshot方法，快照校验所属用户需要修改？
		- SnapshotServiceImpl.
		     unmountSnapshot方法
		- AdjustGroupExecuteAction
		     executeAdjust方法查找group传入的userId
			       Group group1 = groupControlService.viewOwnGroupBaseInfo(resourceOwnerUserId, source, bigRregionNo);
			
		- AuthorizeGroupExecuteAction
		     原groupService替换为big region的groupcontrulservice，user部分需要修改        ？如果userId只用来生成lock，不进行比较所属，是否不需要修改？
		     建议，从group取userId不从userHolder取。
		- ReviseVmToolsAction
		     可忽略
		- QueryGroupVmInfoExecuteAction
		     user_reform没修改，遗漏？
		- GlobalErrorMessage
		     -191错误码重复
		- JoinGroupAction        还有其他big region加入涉及取userHolder取user操作的新接口
		     此为新增接口，不修改，根据代理商找不到group。
		  
3.  big region+user_reform check go on

	- release_vm
		GroupControlServiceImpl
			private boolean leaveAllGroups(Instance instance, List<Group> groups) {
			long ownerId = instance.getUserId();//此处替换从userholder取user
		测试验证释放VIP是否正确
	- remove_image
		imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId()))
		userholder中取user改为显式传参
	- bind_ip
		houyi-spring-action.xml
		action配置修改：
			<property name="limit" value="780"/> 改为：<property name="limit" value="5000"/>
	- authorize_group		  
		AuthorizeGroupExecuteAction
		groupControlService.addGroupAuth(currentUserId, group, groupAuth)
			此处user只用来取锁，代理商也ok，或者直接改为用group对象中的userId来做锁？谭总确认：已确认锁的逻辑不受影响
	- adjust_group_auth
		AdjustGroupExecuteAction
		private ResultDomain executeAdjust(String bigRregionNo, String groupNo, String adjust) {
		查询group时，显式的带userId过去查，替换原来从userholder中取的方式
	- remove_group
		RemoveGroupExecuteAction
			groupControlService.deleteGroup(resourceOwnerUserId, bigRegionNo, groupNo);	      //此为新方法，用了userholder.getUser()
			修改：
				GroupControlServiceImpl
					public OperationResult deleteGroup(long ownerId, String bigRegionNo, String groupNo) {
	- mount_snapshot
		MountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),	      -913状态码废弃
	- unmount_snapshot
		UnmountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day119 Tuesday, August 28, 2012

1. 
	* 
2. 

3. 服务器性能检查
	netstat

4. lb

5. tcp状态
	eg：在6.33上打开一个访问8.214的mysql命令行终端
	在8.214上查看网络连接情况：
	netstat -n | grep 3306
	tcp        0      0 10.250.8.214:3306           10.250.6.33:45378           ESTABLISHED
	表示一个打开的连接

* TCP/IP
	tcp状态：
	LISTEN：侦听来自远方的TCP端口的连接请求
	SYN-SENT：再发送连接请求后等待匹配的连接请求
	SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认
	ESTABLISHED：代表一个打开的连接
	FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认
	FIN-WAIT-2：从远程TCP等待连接中断请求
	CLOSE-WAIT：等待从本地用户发来的连接中断请求
	CLOSING：等待远程TCP对连接中断的确认
	LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认
	TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认
	CLOSED：没有任何连接状态

6. 网络性能监控
	netperf
		is  a  benchmark that can be used to measure various aspects of networking performance.
	netserver
		a network performance benchmark server, listens  for  connections  from a benchmark, and responds accordingly.
	http://www.netperf.org/netperf/

7. grep -v 查看不匹配的行
	eg：
		tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'

8. pangu 存储
	k-v
	rds

	写入速度快，保证写入成功，除非

9. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day120 Wednesday, August 29, 2012

1. 
	* 通过工具模拟大量并发请求，重现socket red 问题（服务访问缓慢甚至返回500错误）
		然后分析原因
	* big region合到trunk后，数据库表的改动对mapping文件中sql的影响排查
		执行dao单元测试
	* 大region对sql的修改，用户体系改造需检查是否有对应的修改
		eg ：image.xml查询用户可用image sql

		svn对比big region对mapping文件做了哪些修改点

		*inBigRegion(xxx的方法都需要考虑从新加入user_reform逻辑。
		byagentid 是否已换成新方法？
			inbigregion的方法，还是用此方法，加入user_reform逻辑
				没有对应的byagentid方法，就是从原有的方法中取需要的逻辑
			byagentid还是用byagentid方法，加入bigregion逻辑
		
		daoimpl类中搜索 inbigregion ， byagentid

		所有byagentid的sql加上big region逻辑。
			
		- remove_image
			RemoveImgExecuteAction
			用imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId())查询是否正确？
	
			

2. 通过工具模拟大量并发请求，重现socket red 问题
	- 并发请求，重现socketread问题
		ab -n10000 -c300 http://xxxx

	- jstack dump堆栈信息 （以时间段dump多份便于对比）
		jstack 1345 > dump1
		----------
		java的线程状态值有：定义在 java.lang.State中
			A thread state. A thread can be in one of the following states: 

			NEW
				A thread that has not yet started is in this state. 
			RUNNABLE
				A thread executing in the Java virtual machine is in this state. 
			BLOCKED
				A thread that is blocked waiting for a monitor lock is in this state. 
			WAITING
				A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 
			TIMED_WAITING
				A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. 
			TERMINATED
				A thread that has exited is in this state. 
			
			A thread can be in only one state at a given point in time. These states are virtual machine states which do not reflect any operating system thread states.
		----------


		分析运行的细节
3. linux help
	svn --help
	svn co --help
4. jboss ,tomcat
	tomcat报 NoClassDefFoundError: org/slf4j/impl/StaticLoggerBinder ，表示缺少对应的jar或找不到
	但，jboss却正常，是不是在不同的jar中有了这个实现？

5. ibatis映射
	返回值中无此参数和表中无此字段的报错的区别？
		select中无此字段：
		org.springframework.jdbc.BadSqlGrammarException: SqlMapClient operation; bad SQL grammar []; nested exception is com.ibatis.common.jdbc.exception.NestedSQLException:   
		--- The error occurred in ibatis/iso.xml.  
		--- The error occurred while applying a result map.  
		--- Check the iso.isoMap.  
		--- Check the result mapping for the 'bigRegionNo' property.  
		--- Cause: java.sql.SQLException: Column 'big_region_no' not found.
		
		select有此字段，表中无此字段：
		？

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day121 Thursday, August 30, 2012

1. 
	* bug fix test 
	* houyi api 需要 slf4j-log4j12-1.5.8.jar依赖
		jboss可不要？
	* slb v2 ，houyi api
		cache梳理，是否提供reload方法？


2. bug fix test 

	create_vm
		image使用
	reset_vm
		image的检查
	create_image	     (create_snapshot)
		
	remove_image

	start_vm后，收到MQ的状态改变可确定vm是否启动成功。

3. 控制系统维护vmName?
	报vm exists

4. create_snapshot过程中，master重启
	ec master reboot ,but agent at nc is still working ,they send the latest message to db or master 
5. slb v2 ，houyi api cache梳理，是否提供reload方法？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day122 Friday, August 31, 2012

1. 
	* user_reform & big region test
		instance
		image
		iso


	* 缓存方案 ，简单缓存方案(需要有缓存更新机制)
		缓存超时



2. mysql执行计划，sql执行计划
	mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

	mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

3. 既然使用这些载体或工具，要想发挥其应有的能力，就需要去了解它，熟悉它，会用工具，用好工具，让它们帮忙我们更好的实现目标。-tip-
	linux iptables
	....
4. Customized Image
	from System Snapshot

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day123 Saturday, September 01, 2012

1. 
	* 

2. 

3. slb
	临时预发布环境信息：

	ag 10.250.6.36

	master 192.168.1.16

	lvs: 192.168.1.111 - 112

	haproxy: 192.168.1.113

			192.168.1.115

	rs: 192.168.1.116-119

	db: mysql -h 10.250.6.1 -uroot

	qa回归用机器：10.250.6.37


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day124 Monday, September 03, 2012

1. 
	* code，msg采用英文编码，避免中文问题
	* 测试用户默认region为非大二层region，能正常调用接口

2. linux进程系统参数
	ps aux | grep -i java 

	cat /proc/7314/limits | grep 'open files'
	Max open files            655360               655360               files     

	进程打开最大文件数：655360
3. 测试用户默认region为非大二层region，能正常调用接口	  (新老api share db，非空字段的地方是否ok？)
	8.214上
	用户未非大二层region
	region表加入此region
	zone表加入zone

	259 ，229的子用户，设置非大二层region，测试：
		detail_vm
		list_snapshot
		query_vm_device
		create_snapshot
		detail_snapshot
		mount_snapshot
		list_mounted_snapshot
		unmount_snapshot
		restart_vm
		stop_vm
		remove_snapshot
			在mount快照过后执行remove_snapshot操作，报状态不对删除不了；再unmount_snapshot，执行删除同样问题；
			<rsp>
			  <code>-912</code>
			  <msg>device or snapshot is not ready</msg>
			</rsp>

		query_available_isos
		list_vm_status
		monitor_vm 无数据（vm监控数据）
		monitor_vm_topn 同上

		query_nc_resources
		query_vm_security.

		add_disk
		remove_disk
		detail_nc
		query_instance_type
		query_available_ncs
		list_vlans
		query_zones
		query_regions
		release_ip
		assign_ip
		query_available_imgs
		query_unassigned_ips

		rollback_snapshot
		list_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day125 Tuesday, September 04, 2012

1. 
	* big region 
		历史bug
	* api_user_reform在加入了大region的db修改后，接口测试



2. 业务
	mount_snapshot
		vm1的快照，挂载到vm2，需要验证vm1，vm2的关系
	pending,startfail
		master第一次启动失败pending，成功后为stop
		api根据MQ和显示调用更新状态，pending只能通过MQ收到，故detail_vm会从starting到pending。


3. api_user_reform在加入了大region的db修改后，接口测试
	query_regions
	query_zones
	list_vlans
	query_instance_type

	detail_vm
	query_vm_device
	query_available_isos
	list_vm_status

	monitor_vm（无数据）
	monitor_vm_topn

	create_snapshot
		控制系统返回-1的码，api统一报-95，如快照名称重复
	detail_snapshot
	cancel_create_snapshot
		已cancel的再去cancel，控制系统报：
		-1,"desc":  "cancel failed
		-95给用户
	mount_snapshot
	list_mounted_snapshot
	unmount_snapshot
	remove_snapshot
	restart_vm
	stop_vm
	rollback_snapshot
	query_unassigned_ips
	query_available_imgs
	assign_ip
	release_ip
	query_available_ncs
	detail_nc
	add_disk
	query_vm_security
	query_nc_resources



4. fdisk	   linux分区	    * fdisk
	fdisk -l
	fdisk /dev/hda
	n
	1
	10
	w
	reboot
	fdisk -l
	vgcreate guestvol /dev/hda6
		No physical volume label read from /dev/hda6
		Physical volume "/dev/hda6" successfully created
		Volume group "guestvol" successfully created
	lvcreate -nubuntu01 -L5.4G /dev/guestvol
		Rounding up size to full physical extent 5.40 GB
		Logical volume "ubuntu01" created


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day126 Wednesday, September 05, 2012

1. 
	* 线上环境，vm创建后起不来原因定位，无pending？


2. 线上环境，vm创建后起不来原因定位，无pending？
		已定位为资源不足

3. 业务,日志查看，控制系统日志，问题排查
	iso在nuwa本地pangu，image同步工具
	nuwa(master日志)
		从reigon找nuwa地址，ssh上去，/apaxxx/nuwa/xxx.Log查看 日志，控制系统日志

	api-kfc(httpd-record service name and address,do forward)-master/netc-agent-operate

	控制系统角色查看 (AG上查看)/apsara/deploy/Fuxisrvd -v houyi status 	       （ag作为master访问入口admin gateway）
	master、netc
	history |grep status
	/apsara/deploy/Fuxisrvd -v houyi status
		查看控制系统，集群的角色（由多少nc组成，有哪些服务角色，各自在那个ip上）
	ps axf |grep master
	vim /var/log/houyi/master/HouyiMaster.LOG
	vim /var/log/houyi/netc/HouyiNetcLOG

	vim /var/log/xen/xend.log
	
	eg：
		在6.33的api，看nuwa，找ag，看master日志

	pending状态需要结合配置，保证start_vm ok。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day127 Thursday, September 06, 2012

1. 
	*  wiki
	* 6.33日志
		release_vm时master调netc释放ip失败，在ag 6.27上找到netc地址，上去看log


2. 
	
		
3. 抛砖引玉的效果
	demo

4. /apaxx目录下熟悉各组件，总线服务
	nuwa
	pangu
	...

5. lvs			       * tcpdump
	tcpdump -n -i any port 80		   tcp包查看

	eg:
	------
	Examples
		To print all packets arriving at or departing from devo:
		tcpdump host devo
		1. To print traffic between gil and either devo or bevo:
		tcpdump ip host gil and \(devo bevo\)
		2. To print all IP packets between bevo and any host except gil:
		tcpdump ip host bevo and bevo gil
		3. To print all traffic between local hosts and hosts on network 192.100.192:
		tcpdump net 192.100.192
		4. To print traffic neither sourced from nor destined for local hosts:
		tcpdump ip and not net localnet
		5. To print the start and end packets (the SYN and FIN packets) of each TCP conversation that
		involves a non-local host:
		tcpdump \(tcp[13] \& 3 !=0 and not src and dst net localnet\)
		6. To print all ICMP packets that are not echo requests or replies (not ping packets):
		tcpdump \(icmp[0] !=8 and icmp[0] !=0\)
		7. To immediately print packet information, enter
		tcpdump -I
		8. To specify the token-ring interface to listen on, enter:
		tcpdump -i tr0
		9. To print packet information to the file TraceInfo, enter:
		tcpdump -wTraceInfo
	------


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day128 Friday, September 07, 2012

1. 
	* wanwang 连调
		缓存deviceNo等数据，重新生成缓存
	* 

					

2. wanwang 连调 ，业务
	release_vm失败丢失group信息。
	vm stopped，group

	join group多次fail，no log


														
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day129 Monday, September 10, 2012

1. 
	* big region连调支持
		a. 环境原因导致的netc调用释放ip超时
		b. image的版权问题，密码问题
		c. 老master的无资源启动问题
		d. vm的连通性授权访问问题（默认规则不能访问，参考api文档）
		e. 


	* ec了解
	* 新项目讨论
		a. 计费需求(安全提供查询接口)
		b. ace4j
		c. big region项目2新增接口进行user reform改造
		d. big region包括api和master的bug fix
		e. houyi计量推送优化
		f. houyi api优化，部分重构；本地cache的优化（统一cache实现，提供cache更新方案-自动或被动调用）
	* ace4j(lxc)需要api提供几个防火墙的接口，看master提供的接口说明
		添加ip白名单（ip放行）
		删除ip白名单
		查询ip白名单列表
			补偿描述
		http://10.250.6.111/wiki/index.php/Firewall_add_white_list
		
	* 并发测试
		环境
	* 双开发布
		region查询存在的limit 1问题。
		

2. 联调 big region
	api log > master log (master位置从ag中调用命令查看)> nc log(xen log)	nc_id位置从master的log中确定，nc ip从api接口中查询

	liveMigrateFailed 不对外，统一报-95

3. 数据库索引，数据库优化

	从数据库的查询方式分析优化方案，参考数据库提供的优化功能，比如各种索引等。

	指导方针：
			要了解跑在数据库上的应用程序/用户，使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，
		如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day130 Tuesday, September 11, 2012

1. 
	* ace4j对houyi api的需求背景说明
		master提供的3个接口熟悉，对应api的接口设计
	* openstack分享
		中心授权，组件化运行，MQ消息

		loadbalance，分布式存储



2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day131 Wednesday, September 12, 2012

1. 
	* big region发布
		数据模拟订正，slbv1表检查   region_mapping

2. 底层
	/home/admin/apasara

3. pssh
	python实现，便于从一台nc批量执行命令到其他多个nc等需要。

4. 系统
	API，命名服务，master，xx，分布式kv存储

	cluster规模逐渐增大后，程序的维护，更新及发布，需要自动化，面对的是大量的nc节点，除了配置信息操作基本一致。
	执行前check，执行后check，最终check，需要自动化更高的手段。
		抽象出过程中可以独立的操作，做为一个执行单元（可以包含准备，执行，检查等）

	这样的工具开发，采用高级语言认为还是很合适的，比如python（pssh工具）。
		依据脚本和配置自动化执行nc操作。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day132 Thursday, September 13, 2012

1. 
	* big region release值守
	

2. 系统
	youchao Structured  Data Processing,pangu Storage,fuxi Scheduler,shennong Monitor,nuwa Naming, kuafu Communication,  cangjie Language,Security

	shennong : 
		A distributed data collecting system that collects data from both system and user programs, aggregates them according to customizable rules, 
		and provides them according to user requirements. 

3.部署实践 -tip-
	- 建议将配置文件与安装目录分离
		便于日后升级版本的时候配置文件不被覆盖，减少我们对配置文件的维护
	- 

4. kv存储如monodb，以键值对方式存储数据，区别于分布式存储系统(文件系统，如HDFS)，两者有区别有联系。
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day133 Friday, September 14, 2012

1. 
	* 


2. /etc/hosts	      主机名 ，host name ，ssh互通
	127.0.0.1               localhost.localdomain localhost
	10.250.1.199    mydev.test.com.cn	

	ssh-keygen生成密钥对，对公钥末尾部分的host名修改为hosts中设置的名称
	拷贝到需要连到本机的主机的ssh auth文件中。

	本机生成密钥对，将公钥拷贝到目标机的ssh授权文件中，这样就能无密码ssh从本机登陆到目标机（注意用户角色和host解析）。

	保证目标机对host名的正确解析（可以在目标机的host定义文件中定义host名到ip的映射关系）

3. SLB 
	lvs test
	2 vm,lvs
	using LVS as a module as this approach is easier and more exible.
	kernel: http://www.kernel.org/pub/linux/kernel/v2.6/longterm/v2.6.34/linux-2.6.34.13.tar.bz2
	ipvs: http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz
	Compiling ipvsadm on different Linux distributions:
		http://kb.linuxvirtualserver.org/wiki/Compiling_ipvsadm_on_different_Linux_distributions
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day134 Monday, September 17, 2012

1. 
	* ace4j Firewall
		prd会

2. ace4j防火墙接口
	LXC内部网络跨vm访问，跨过arp FireWall，支持LXC每个容器一个私网IP(此私网为LXC的网络)。
	arp FireWall -> ip FireWall

	lxc网络规划(internal)

	一些接口参数校验：
		ip，ip段，ip range - 合法性（格式，范围）
		PRD讨论，暂只支持单个ip

	定义返回结果pojo类的xml映射
		XStream		

	具体验证，设计时考虑

3. parse pojo to xml
	eg: XStream

	定义返回结果pojo类的xml映射 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day135 Tuesday, September 18, 2012

1. 
	* ace4j firewall kick off
		create wiki
	



2. Ace4j firewall
	TODO:
		- Call set firewall operation after add or remove white ip list ,like join or leave group.
			add white ip list > call master set firewall	(new command)
			remove white ip list > call master set friewall (new command)

			 VM_PUSH_ACL(1),

		- 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day136 Wednesday, September 19, 2012

1. 
	* 快照
	* 主备切换/读写分离

2. keepalived
	失败恢复ok
	主备切换？
		linu防火墙的问题，导致主备切换失败，可能是阻止了lvs机之间的vrrp交互。

	测试成功
	后面针对keepalived的防火墙要求，做细化控制，不关闭防火墙 待？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day137 Thursday, September 20, 2012

1. 
	* wiki
	* slb
		lvs
		keepalived
		haproxy

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day138 Friday, September 21, 2012

1. 
	* slb测试通过后，测试slb下的mysql负载均衡(读负载均衡) -tip-
		数据库部分部分应用读的压力大于写的压力，通过mysql的主从复制，读写分离实现db层的高可用，高并发。
	* mysql
		主从复制，
		主备切换/failover，    通过vip漂移（如：keepalived）
		读写分离
		
	
2. lvs主备切换
	/etc/init.d/iptables stop

	lvs主备切换如果工作不正常，确认是不是防火墙的原因（防火墙阻止了keepalived的功能），下面是查找主备不切换，每个lvs启动后都是master状态：
	------
		Hi,

		I found that it is always best if possible to turn off the firewall and see if it works,
		then turn on the firewall.

		On 05/24/2012 08:16 AM, lakshmi priya wrote: 
	------
	from : http://comments.gmane.org/gmane.linux.keepalived.devel/3864

	根据上面的提示，测试成功，确实是linux防火墙导致keepalived的主备切换功能失效，具体应该是vrrp协议的交互受阻，下面是测试成功的log：
		Sep 20 02:46:39 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 added
		Sep 20 02:46:40 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 added
		Sep 20 02:46:45 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Received higher prio advert
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering BACKUP STATE
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) removing protocol VIPs.
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 removed
		Sep 20 02:49:26 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 removed
	
	ps：
		iptalbles全部关闭不建议，可以查看keepalived的端口占用说明，开放其需要的端口即可。

3. lvs+keepalived负载均衡测试
	分摊请求

4. mysql
	参考：http://www.blogjava.net/dongbule/archive/2010/08/22/329602.html
	log
		/var/log/mysqld.log

	yum install mysql.i386
	1) 主服务器上进行的操作
	/opt/mysql/init.d/mysql start
	/opt/mysql/bin/mysql -uroot -p'new-password'
	
	授权给从数据库服务器192.168.10.131
	mysql> GRANT REPLICATION SLAVE ON *.* to 'rep1'@'192.168.10.131' identified by 'password';

	查询主数据库状态
	Mysql> show master status;
		+------------------+----------+--------------+------------------+
		| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |
		+------------------+----------+--------------+------------------+
		| mysql-bin.000005 | 261 | | |
		+------------------+----------+--------------+------------------+
	记录下 FILE 及 Position 的值，在后面进行从服务器操作的时候需要用到。

	2)从服务器操作


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day139 Monday, September 24, 2012

1. 
	* 梳理user_reform的api proxy转发规则
	升级到大region需要做的修改：
		

2. 梳理user_reform的api proxy转发规则（定位region）
	根据vm_name
	根据ip
	根据region_no
	根据aliyun_idkp/session_id

	对应接口是否都处理了的问题，可对照文档。
	
	join_group/		region_no
	leave_group/		region_no
	query_group_vm/	region_no
	reload_cache/		无vm_name,ip,region_no	      ，不关注
	set_master_region/	region_no
	refresh_vm_acls/	vm_name
	touch_master/		region_no
	flush_control_ip_chain/	vm_name

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day140 Tuesday, September 25, 2012

1. 
	* ace4j kick off
	* api proxy 接口根据api文档与qa确认
	* 9.27 design doc send mailz 

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day141 Wednesday, September 26, 2012

1. 
	* 大region二期
		ace4j
			详细设计文档
				补充接口逻辑处理说明
		快照计费，aliyun_idkp透传master(快照接口)
			

2. 大region二期
	
	ace4j
		拉分支
		详细文档细化程序处理流程逻辑
		代码：
			command参考 VmPushAclSetFireWallCommand
	快照计费
		api需求分析
			快照相关接口列出(需要传aliyun_idkp)
				create_snapshot
			是否调用了master
				message_vm ？
			控制系统是否要修改接口，相应的对api的影响
		idkp只做标识，不做验证？	    透传master
	OSS存储打通
		整理需要跨小region操作的接口，API是否支持或需要支持，master是否支持或需要支持
			add_disk 已支持
			mount_snapshot
			rollback_snapshot
			create_vm


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day142 Thursday, September 27, 2012

1. 
	* 大region二期
		create_snapshot接口透传aliyun_idkp
		mount_snapshot等接口中snapshot跨region使用，需要将cluster_id等消息传给master	       （oss大region内互通[http]）
			已传入快照cluster_id
		add_disk已实现跨region的快照使用,带入了快照的cluster_id到master	 (AddDiskCommand)	- 忽略	      
	* 线上bug处理
		nic=INTERNET
2. 
	mount_snapshot
		snapshot clusterId
	add_disk
		snapshot clusterId
	start_vm
		imageClusterId=snapshot clusterId
	reset_vm
		imageClusterId=snapshot clusterId
	create_vm
		imageClusterId=snapshot clusterId

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day143 Friday, September 28, 2012

1. 
	* 大region二期kick off
	* 老版本api，启动模式问题
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/tags/20120426_473751_trunk trunk上打的tag

		create_vm没设置启动模式参数

		原因：
			sql是旧版本，创建default值为init类型

			sql版本维护的问题？

2. 
防火墙
	消息给master

3. 老api

	  InstanceStartupMode.java
	public static InstanceStartupMode getInstance(String name)
	{
		for (InstanceStartupMode mode : InstanceStartupMode.values())
		{
			if (mode.getName().equals(name))
			{
				return mode;
			}
		}
		return InstanceStartupMode.NORMAL;
	}
	若模式没找到，则返回normal=0

	创建vm时，为0，找不到也为0，直接传递给master为0

	确认创建时，startup_mode为3，不为0

	故，此版本start_vm需要传 startup_mode=init

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day144 Saturday, September 29, 2012

1. 
	* 线上问题处理
		报image找不到
			饶入一个偏题			
				最终，由于使用的账户问题，image_using_mode自能用自己的。

2. 发布管理，版本管理（相关API，master等的版本），文档管理，工具管理
	后面查询时，有统一的地方可查。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day145 Monday, October 08, 2012

1. 
	* ace4j
		pojo
			nic，command	  ,api返回pojo，
		
	* 大region二期task见redmine
		设计文档下周一评审，内容包括：
			a. 取消快照数据推送逻辑
			b. 创建快照接口带入用户标识
			c. 确认快照相关接口已带入cluster_id，若没有则需要带入
			
		http://redmine.aliyun-inc.com/issues?set_filter=1&f%5B%5D=status_id&op%5Bstatus_id%5D=o&v%5Bstatus_id%5D%5B%5D=1&f%5B%5D=project_id&op%5Bproject_id%5D=%3D&v%5Bproject_id%5D%5B%5D=214&f%5B%5D=assigned_to_id&op%5Bassigned_to_id%5D=%3D&v%5Bassigned_to_id%5D%5B%5D=me&f%5B%5D=&c%5B%5D=project&c%5B%5D=tracker&c%5B%5D=priority&c%5B%5D=subject&c%5B%5D=author&c%5B%5D=assigned_to&c%5B%5D=updated_on&c%5B%5D=fixed_version&c%5B%5D=start_date&c%5B%5D=due_date&c%5B%5D=done_ratio&group_by=
	* new wiki
		http://10.250.6.111/wiki/index.php
			API接口wiki说明由PD维护。

2. 项目各种文件版本管理
	PRD
	需求文档
	数据库变更

	项目管理软件管理(redmine)？wiki管理？svn管理？
		eg: redmine管理

3. houyi.json
	后羿角色的配置	 cc,nc,netc,master,monitor

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day146 Tuesday, October 09, 2012

1. 
	* ace4j development
		nic error define
			GroupErrorMessage
			ServerErrorMessage
	* image跨小region调用
		原来通过region_alias表的字段实现image可以在打通KFC的小region间使用，现在不需要KFC打通实现的
		image跨小region调用，而是大region内的http方式调用。API层需要修改使用image时过滤条件？
		
2. 接口设计，参数设计
	OO思想，参数对象化
	结果统一处理
		配置状态码对应返回值
		command自封装内部处理，对外统一结构返回
		参数对象化，验证逻辑封装（常用验证-按功能，按业务逻辑的封装后统一调用），类似struts的form bean
		验证逻辑与主业务逻辑分开，主逻辑只处理参数正常的情况
	统一调用

	系统优化：-tip-
		参考struts，在action处理请求时，将请求参数注入到到定义的参数对象中，无需在action类中再去取键对应的值。

3. jtester
	commandexecute进行mock测试时，注意spring配置实用mock的executor来测试。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day147 Wednesday, October 10, 2012

1. 
	* ace4j今天提测
		service层单元测试补充(add已ok)
		补上其他action(add已ok)
		action层单元测试

		与master连调

		ace4j关于大region业务，用户体系改造业务分析：
			大region业务已处理；
			用户体系改造，代理商逻辑，在vm统一验证时已处理，即支持代理商调用。
		
		-tip-
			程序各层逻辑分明，单元测试保证单元逻辑测试通过，层层独立分工，保证整体逻辑清晰准确。

		开发环境搭设API服务，准备和master进行连调测试
			10.250.8.214
			打包已有部署目录：tar -cvf ../houyi-ace4j/service.tar service/
			清楚旧项目日志，程序等内容
			修改，svn地址
			修改apache配置文件httpd.conf，以本项目的conf文件启动
				配置access_log
					<IfModule log_config_module>
					    #
					    # The following directives define some format nicknames for use with
					    # a CustomLog directive (see below).
					    #
					    # LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
					    # LogFormat "%h %l %u %t \"%r\" %>s %b" common

					    LogFormat "\"%{X-Forwarded-For}i\" %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{Host}i\" \"%{Accept-Encoding}i\"" common
					    CustomLog "/home/admin/houyi-ace4j/service/logs/openapi/access_log" common

					    <IfModule logio_module>
					      # You need to enable mod_logio.c to use %I and %O
					      # LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" %I %O" combinedio
					    </IfModule>

					</IfModule>					
			修改项目配置文件
				job.properties
			编译，部署，运行

			集成测试类（ApiTest）中加入上面3个接口的测试用例

				

	* big region二期项目
		大region内，跨小region使用image，snapshot需求
			现有API限制image不跨小region使用(KFC打通并在region_alias配置能跨小region使用的region除外)。
				上面的逻辑变动要进入到设计文档中：涉及使用image的接口整理对应的改动

				根据api文档中，有image_no参数的接口列出待检查的接口：
					create_vm
					reset_vm
					create_image	     image_no已保证表内唯一
					remove_image	     已在大region范围删除image
					revise_vm

					selectParentImage没有原有kfc打通可跨小region使用image逻辑
					
2. 设计 系统api
	通过visitor或者factory来实现bean，pojo的生产

3. test
	add_firewall_whitelist 
	remove_firewall_whitelist 
	list_firewall_whitelist

	集成测试：
		正常流程
		异常流程
			参数错误
			操作不允许

4. 业务，系统业务
	kfc对应参数格式错误的情况会自己捕获，并抛出异常，但不做response，这样api在参数发送错误时，报kfc超时异常。
		eg: api to nuwa to netc 
			可以看netc的日志，报参数格式错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day148 Thursday, October 11, 2012

1. 
	* ace4j测试用例评审
		白名单无限加问题
		vm状态控制问题(非released的vm)
			代码已修改提交
	*　tdc设计评审
		device - tdc子进程
		oss存储 bucket
	*　
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day149 Friday, October 12, 2012

1. 
	* ace4j,计量，mac-net项目周会
		项目需求阶段，需要考虑测试环境问题（特别对于依赖）
	* ace4j计量
		增加，删除白名单接口，不支持nic=all的类型
	* 大region二期设计文档初评审
		

2. 系统业务			      * master
	master: 总控模块，负责调度/与cc连接状态监控
	cc : 路由模块，同时负责监控与nc连接情况
	nc: vm管理模块，负责最终对vm的操作
	network controller : 负责网络安全，group互通管理

	命名服务
3. ace4j改动
	reversion：625581
	ace4j项目改动：
	1）3个接口都增加vm状态限制，released状态的vm调用时会报错，详细说明见设计文档
	2）增加，删除白名单接口，不支持nic=all的类型，只支持nic=internet和nic=intranet
4. 大region二期设计文档初评审，需求变动及增加点
	1)  部分使用快照的接口需要从master查询快照后，将新增的字段 snapshot_type 再传给master
		修改点：
			增加snapshot_type涉及接口改动：
				detail_snapshot 返回值增加snapshot_type值
				list_snapshot 返回值增加snapshot_type值
				create_snapshot 返回值增加snapshot_type值
			需要传递snapshot_type涉及接口改动：
				mount_snapshot 增加传递快照的snapshot_type给master
				add_disk 同上
				start_vm 同上
				reboot_vm 同上
				reset_vm 同上
				rollback_snapshot 同上
				recover_vm 同上
	2) image可以在大region下跨小region使用后，对于老image（非buckut方式存储、http方式访问的image，本次项目上线前已有的image）将不能被使用，master新增对应的错误码，
	API需处理此错误码


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day150 Monday, October 15, 2012

1. 
	* 大region二期设计评审
		
	
		
		

2. 大region二期设计评审
	1）对于KFC打通可以跨小region使用image的逻辑，现定为在本项目发布前，通过线上变更将kfc下线掉。API不修改逻辑，在image
	同步工具同步了需要同步的image后，更新houyi库去掉kfc打通的表关系记录。
	2）跨小region操作快照时，原有vm，device，snapshot所属关系的检查master将不能check，如何解决？
		方案一：废弃已不再使用的参数（文档标记为过时），API只做必要的check，下面列出涉及的接口：
			mount_snapshot	去掉snapshot_at_vm,device参数，只验证snapshot_id和vm_name的user是否为同一用户（类似add_disk，只传递snapshot_id，API验证user即可）
			add_disk			已有check
	3）API使用image的调度策略考虑到老image不可用，master报错误的情况？
		避免用户体验下降
	4）snapshot_type参数现定为由控制系统自己维护，不需要API将此参数传递给master，如此相关接口无需改动。


3. 业务
	 跨region的image的流程如下：
		0、启动vm
		1、传递image id -> open api
		2、open api查询 -> houyi.image； 找出snapshot id
		3、open api查询snapshot对应的OSS -> 通过houyi master（image所在的集群）查询 -> houyidb.snapshot
		4、open api把启动参数（包括上面查出的快照参数） -> houyi master
		5、houyi master -> houyi nc
		6、houyi nc用给的快照参数 -> 启动tdc
	·from:http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=7209612

	OSS中的Object源信息和数据文件都是存放在KV Engine上，在kv存储上封装一个API层，开放调用。

	kfc
		 is the communication component in ApsaraOS. It is the fundamental communication layer of Apsara services like Fuxi, Pangu, Nuwa, etc. 
		It provides a remote procedure call (RPC) interface and enables developers to easily build network-distributed applications.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day151 Tuesday, October 16, 2012

1. 
	* 大region二期设计评审修改后再评审
		确认问题方案

		create_vm选择image逻辑
			原有逻辑调度（region，zone）需要考虑image可用性（本小region，kfc打通跨小region，即调度源region列表来自可用region列表），、
			现有逻辑大region下小region间都可使用

			master在查询快照接口提供snapshot_type参数，供API在image调度时保证image可用和保证调度的小region列表为可用image的小region列表。
				若为bucket类型，调度候选小region列表为大region下所有的小region
				若为hash_on_kfc，调度候选小region列表为当前region和kfc打通region

				查询image时，只根据image_no条件得到image及可使用region的map列表
		

		

2. 业务
	if any of the zone,rack,vlan_no,nc is not setted，then need schedule
	VM调度
		大region > 小region > zone > rack > NC > VM；
		其中小region有优先级，优先级region.weight越高，小region越优先被使用。
		将NC按照nc_resource.priority[0,99]分成若干梯度,值越高，NC越优先被使用。
		nc_resource.health[0,5]表示NC的健康程度，在startvm成功时+1,失败则-1。

		将多个小region在逻辑上进行资源统一调度，视作一个大region。
		多个梯度之间做密集调度。
		单个梯度之内做NC的均摊调度。
		VM对region间的选择由API做出。
		控制系统负责VM在region内的调度，选择目标NC。

	]调度方法（从API到控制系统）
		API在启动VM时，优先选择region.weight数值高的集群。
		API发现有多个region.weight一样时，分别让多个控制系统计算库存值并上报，库存值是指每个zone的每个梯度内能启动指定配置VM的库存个数。
		根据汇总的库存值信息，API优先选择高梯度的NC资源，选择高梯度中NC资源最充足的zone，并向这个zone发送create_vm指令。
		控制性收到create_vm信息后，根据nc_r.priority > nc_r.health > nc_load的优先顺序选择一个NC使用，并扣除资源，创建一个pending状态的VM。
		控制系统优先使用权值高的NC，保留低权值的NC资源。
		如果多个NC梯度一致，优先使用健康度（health）高的NC。
		在其他因素一样的情况下，同一梯度、同样健康的的NC资源，优先选择空闲的使用。

	涉及的接口
		api：create_vm
		rpc: CreateVm，QueryVmVolume(vcpus,memory,diskSize)
		nc_resource.priority, region.weight值需要手动设置DB
	
	from：http://10.250.6.111/wiki/index.php/VM%E5%9C%A8%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98

	原有逻辑调度考虑image可用性（本小region，kfc打通跨小region），现有逻辑大region下小region间都可使用

3. 业务
	上传的image和自定义image的区别？
		自定义image基于snapshot
		从image表的字段分析：
			
4. BSS 业务
	快照系统: 虚拟机的快照系统
	BlockStorageServices

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day152 Wednesday, October 17, 2012

1. 
	* 二期设计文档问题梳理，以及

2. 
	create_vm image调度

		先根据image_no查找parent image，因为parent image大region内只有一个，其他的都是为了同步到其他region而复制的，如果删除任意一个，则包括
		parent image及其子image都被删除。故使用时，要确保parent image是存在的。（houyi.image）

		查询出parent image
		根据parent image填充instance的imge基本信息
		调度image具体在那个小region起


		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day153 Thursday, October 18, 2012

1. 
	* 大region二期设计文档问题
		老快照兼容性问题（不能跨小region）
		image调度问题（是否将image的存储类型，存入API作为冗余字段，减少跨系统查询次数）
	* 大region二期已确定需要开发


2. create_vm
	若没有指定zone创建vm：
		原有逻辑是查询出image_no可以被使用的region列表，然后根据算法得出最优的region以及其对应的zone，若没资源或不可用则选择下一梯度，
		直到找到可用的zone（此为已有大region调度逻辑）

		然后从选出的这个最优region中查询（先从本地找，若没有则从KFC找）出对应的image作为启动vm的image	

	能否在image表增加存储类型字段，标识image存储类型，避免跨系统查询。

3. 业务
	新的快照，在大region中只有一份，通过http方式跨小region使用；基于其的image将也是新image
	上线有device订正操作，后面打的快照将都是bucket类型的
		device迁移
	原有的快照不变，即老快照还是存在

	新proxy方案，新老快照都能用。大master？

4. 
snapshot_type取值为int   :    1（HASH_ON_KFC），2（BUCKET_ON_KFC），3（BUCKET_ON_HTTP）


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day154 Friday, October 19, 2012

1. 
	* big region二期开发
		dao层单元测试，jtest注意
			程序jdbc配置在当前用户的目录中；测试框架配置在各自项目jtester配置文件中。
		
2. big region二期开发
	修改原有方法，对应的单元测试方法，在提交时检查是否都修改正确。

3. region别名表，kfc region查询业务说明
	select 
		region_no 
	from region_alias alias 
	where exists (select 1 
			from region_alias 
			where region_no='AT-HOUYIDEV' 
			and real_region_no=alias.real_region_no);	


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day155 Monday, October 22, 2012

1. 
	* 大region二期需求变动
		snapshot_type值在API这边保存一份冗余
			image表，非空，hash或kfc
			涉及的相关改动

		数据库变动，需要DBA review通过
	* 大region二期灰度发布		   需求
		master的小region，按阶段分批升级，API目前是大region升级，需要考虑小region的灰度发布。
		之前的方案：
			- 新存储，大二层网络等通过简单的代码hack方式
			- 通过上层proxy转发，部署不同版本
			- OR 从架构设计上支持灰度发布？

		API和master各自梳理，分析可行性。（proxy方式）

	* 二期，参数废弃待PD确认？


2. 大region二期灰度发布接口整理及支持
	create_vm		老image不跨小region；新快照的image可跨小region
		兼容新老master的调用
	reset_vm		老image不跨小region；新快照的image可跨小region
		参数：vm_name
	mount_snapshot	校验快照user ; 老快照不跨小region，新快照可跨小region ；snapshot_at_vm,device_no文档标注废弃；API到master不再传递snapshot_at_vm和device_no参数;
		参数：vm_name
	unmount_snapshot	校验快照user ; snapshot_at_vm,device_no文档标注废弃 ; API到master不再传递snapshot_at_vm和device_no参数 ; 
		参数：vm_name
	detail_snapshot		master返回值增加snapshot_type
	list_snapshot		master返回值增加snapshot_type ; 
	list_mounted_snapshot	master返回值增加snapshot_type ; 
	create_snapshot	传递aliyun_idkp到master
	add_disk			校验快照user ; 老快照不跨小region，新快照可跨小region ; snapshot_at_vm,device_no文档标注废弃 ; 
	
	
	问题：
		master给出灰度发布带来的影响（比如未发布的小region是否能用http的快照？） - 控制系统整理
		proxy将region没有升级的调用（vm_name对应的vm所在的region是否升级）发送到老的API上。
		新API调老master
		参数废弃
	
3. 设计，规范，编码规范
	参数传递时，封装为对象OR通过多个原子参数来传递？
		封装面向对象，但在中间层不能明显知道底层逻辑和上层逻辑
		单独参数传递，参数个数增加，但条件明显

		参看，开源系统
4. sql修改
	image表：
		alter table image add snapshot_type int(4) NOT NULL COMMENT DEFAULT 1 '@desc 快照存储类型 1-hash_on_kfc;2-bucket_on_kfc';

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day156 Tuesday, October 23, 2012

1. 
	* 大region二期，部分开发继续
	* 二期灰度发布方案讨论，目前两种方案
		- API兼容新老master，以及是否支持新老KFC
		- master兼容新老TDC
		

2. 

3. mysql * mysql myisam ,innodb
	myisam不支持事务，建表语句，show create命令查看表的存储引擎类型是Myisam，改为Innodb类型即可

	jtester db模块插入数据没有回滚，小不解了一番。。。

4. ibatis属性转换，自定义转换
	通过在mapping文件中直接定义或者统一定义
	（1）各自的mapping文件中	（sqlMap）
		<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
		<typeAlias alias="snapshotStorageTypeHandler" type="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>	
		<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER" typeHandler="snapshotStorageTypeHandler"/>
	（2）在config文件中统一配置（sqlMapConfig）
		<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
		<typeHandler javaType="snapshotStorageType" callback="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>

		<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER"/>

	ibatis参数对象，返回对象的定义问题，注意坑啊。。。

5. 

		     image.xml
		     /houyi-console-dao/src/main/resources/ibatis/image.xml


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day157 Wednesday, October 24, 2012

1. 
	* 二期灰度发布方案
	* 二期开发连调环境搭设
		

2. 设计
	灰度发布功能与业务逻辑剥离，即灰度发布对业务程序是透明的。可有好的方案或设计？灰度发布的粒度问题，API是大region粒度，master是小region粒度。
		根据粒度范围进行灰度，如API是以大region为粒度的，在

alter table 

3. 系统 代码风格 代码规范 重构 优化
	houyi api
		查询快照等的逻辑调用其service层即可，无需再实现。
		commandexecute无需mock

4. 二期开发连调环境搭设
	API ：
		APIf访问地址：6.32
		数据库地址：6.32
		数据库数据：qa测试环境API的数据库
			'mysql -uhouyi -phouyiat03 -h10.230.204.19 houyi --auto-rehash --default-character-set=utf8'
	master环境：
		进入方式：6.27 admin go2houyi1 >  go2houyi3
		ag: 10.230.204.19
		Local_nuwa: 10.230.204.24
		Local_mysql: 10.230.204.19
	MQ：message.properties 
		houyi.message.host=10.230.204.67
		#10.249.38.101  
		houyi.message.port=5672
		houyi.message.username=guest
		houyi.message.password=guest
		houyi.message.queueName=queue1
		houyi.message.retryTime=10
		houyi.message.flag=false
		white.ip=10.230.204.24,10.249.195.162
		lb.server.url=http://10.249.182.102:8088		

	操作：
		拷贝6.33的环境：
			service目录，去掉log等文件；
			/usr/ali/下jboss ，maven，httpd等需要的程序
		修改6.32的环境变量 PATH HOME等
		取到数据库：
			mysqldump -hxx -uxx -pxx dbname > ./xx.sql
			修改相应的表：（保证数据可用）
				region
					at03
				zone
					cluster=3
				region_alias
				master_region

			修改新API的jdbc配置指向到上面的新库
		MQ配置修改：配置mq地址，访问账户，端口等

		bigRegionNo=cn-hangzhou-xy2-test01

		houyimonitor0过大，mysql报：ERROR 1030 (HY000): Got error 28 from storage engine			


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day158 Thursday, October 25, 2012

1. 
	* 二期灰度方案讨论
		API做代码兼容的方案
	* slb api文档内部评审
		准备对外开放
		流量接口带宽，计量库存最近时间带宽瞬时值，API给出为时间段的平均带宽
	* create_vm		 系统
		ballon参数校验

2. 二期灰度方案讨论
	API做代码兼容的方案
		- 二期涉及的接口兼容问题
		- 原有的接口是否能兼容的评估
	
		
3. 参数废弃问题基于灰度方案的确定
	- API兼容新老master则，废弃参数需要在master都升级完时公布，返回值废弃可发布开始后公布；
	- master兼容底层时，废弃参数和返回值废弃都可在发布时公布

 select image_no,user_id from image where region_no='AT03-HOUYI3' and status=0 and image_no not like '%lyytest%' and user_id=229;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day159 Friday, October 26, 2012

1. 
	* 二期灰度方案3API修改代码评估
	* 
		

2. 看jdk源码一个方法的写法     源码学习 方法引用 deprecated

	javax.management.MBeanServerFactory.findMBeanServer(String agentId)

	/**
	* <p>Return a list of registered MBeanServer objects.  A
	* registered MBeanServer object is one that was created by one of
	* the <code>createMBeanServer</code> methods and not subsequently
	* released with <code>releaseMBeanServer</code>.</p>
	*
	* @param agentId The agent identifier of the MBeanServer to
	* retrieve.  If this parameter is null, all registered
	* MBeanServers in this JVM are returned.  Otherwise, only
	* MBeanServers whose id is equal to <code>agentId</code> are
	* returned.  The id of an MBeanServer is the
	* <code>MBeanServerId</code> attribute of its delegate MBean.
	*
	* @return A list of MBeanServer objects.
	*
	* @exception SecurityException if there is a SecurityManager and the 
	* caller's permissions do not include or imply <code>{@link
	* MBeanServerPermission}("findMBeanServer")</code>.
	*/
	public synchronized static ArrayList<MBeanServer> findMBeanServer(String agentId) {
		....
	}				
	方法名；参数说明；返回值；异常返回都定义的清楚明了，看到这些说明这个方法如何用也就一目了然了。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day160 Monday, October 29, 2012

1.
	* ace4j发布
	* 大region二期
		cache部分，可提供内部管理用接口，只供内部调用
		接口粒度的访问控制（是否可访问与访问频度），通过前端OR内部支持？
	* 二期delay（错开飞天发布）
	* 飞天升级前拆除KFC
		步骤：
			- 同步kfc通的image
			- 订正device数据，houyi库
			- 跨kfc使用image订正，跨打快照订正
			- 拆kfc

2. 二期delay（飞天发布）
	当前开发状态：
		- 参数废弃部分，需求待确定，代码没变动
		- 灰度发布，改动一部分代码
			从create_vm开始（未修改完）

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day161 Tuesday, October 30, 2012

1. 
	* bugfix项目需求
	* API优化部分
		缓存方案统一，功能完善 待
	* 

2. 

3. 问题分析与解决方案 -tip-
	若小region不能访问（断电，网络异常等），导致大量后端请求超时，耗尽web服务器的线程资源，最终正常region的请求服务不可用。
		瞬时操作与耗时操作分开线程池执行？如何区别是否耗时？
		continue机制，非堵塞机制
	
	region有status状态属性来标识region是否可用，但region拦截器查询时没有加入status状态。
		region的状态提供HA机制（如果可访问则状态为可访问，若检测结果确认为不可访问状态则置为不可访问），然后程序调用前判断此状态即可。减少无谓的超时等待。
		通过程序来check服务可用性结合是否可用的配置，尽量减少可感知的超时等待消耗。

	region拦截器查询region逻辑是否要修改？是否有接口可运行region关闭时操作

	全部down过后的恢复问题
		服务启动步骤，大量服务并发启动要考虑的问题等
	
	严重异常问题的提前考虑：
		目标保证服务可用。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day162 Wednesday, October 31, 2012

1. 
	* 问题分析
	* AOne2.0培训
	* 
2. 

3. jstack ，kill -3
	执行sudo kill -3 PID获取thread dump log（PID是第一步获取）。 
	注意：在不同的linux环境下执行输出的日志的地方可能不同。在IBM的PowerPC小型机上的linux上执行kill -3 pid会在工作目录下产生类似javacore.20100409.161739.7614.0001.txt的文件。JBOSS默认环境下，thread dump log输出到jboss console，所以thread dump信息会输出到个人定义的控制台(如jboss的控制台log)打印log中。 
	部分示例如下所以：

	man java  jvm通过SIGQUIT信号产生线程dump（来自java的man说明）
		Sun’s JVM uses SIGQUIT to perform thread dumps

	线程死锁堆栈数据分析：
	------------
		"ajp-0.0.0.0-8009-1504" daemon prio=10 tid=0x00007f81a518f800
		nid=0x6554 waiting for monitor entry [0x00007f8142c29000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.numBuffers(RAMFile.java:79)
			- waiting to lock <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:87)
			at org.apache.lucene.store.RAMInputStream.readBytes(RAMInputStream.java:73)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:82)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.MultiTermQueryWrapperFilter.getDocIdSet(MultiTermQueryWrapperFilter.java:131)
			at org.apache.lucene.search.ConstantScoreQuery$ConstantWeight.scorer(ConstantScoreQuery.java:139)
			at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:298)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:391)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)

		we have 1172 threads in same state.

		there are two threads which already lock the object:

		"ajp-0.0.0.0-8009-548" daemon prio=10 tid=0x00007f81a510b000
		nid=0x1c64 waiting for monitor entry [0x00007f81897d5000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.getBuffer(RAMFile.java:75)
			- locked <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:97)
			at org.apache.lucene.store.RAMInputStream.readBytes(RAMInputStream.java:73)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:82)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.TermCollectingRewrite.collectTerms(TermCollectingRewrite.java:40)
			at org.apache.lucene.search.TopTermsRewrite.rewrite(TopTermsRewrite.java:58)
			at org.apache.lucene.search.MultiTermQuery.rewrite(MultiTermQuery.java:296)
			at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:378)
			at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:378)
			at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:589)
			at org.apache.lucene.search.Searcher.createNormalizedWeight(Searcher.java:167)
			at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:661)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)


		"ajp-0.0.0.0-8009-663" daemon prio=10 tid=0x00007f81c503d800
		nid=0x225b waiting for monitor entry [0x00007f8182462000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.numBuffers(RAMFile.java:79)
			- locked <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:87)
			at org.apache.lucene.store.RAMInputStream.readByte(RAMInputStream.java:63)
			at org.apache.lucene.store.DataInput.readVInt(DataInput.java:105)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:64)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.FilteredTermEnum.setEnum(FilteredTermEnum.java:56)
			at org.apache.lucene.search.WildcardTermEnum.<init>(WildcardTermEnum.java:65)
			at org.apache.lucene.search.WildcardQuery.getEnum(WildcardQuery.java:59)
			at org.apache.lucene.search.MultiTermQueryWrapperFilter.getDocIdSet(MultiTermQueryWrapperFilter.java:103)
			at org.apache.lucene.search.ConstantScoreQuery$ConstantWeight.scorer(ConstantScoreQuery.java:139)
			at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:298)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:391)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)
	------------
	上面第一个线程在等待锁，下面两个线程已经拿到锁。如果拿到锁的一直不释放，则等待锁的线程将BLOCKED在哪里，随着时间推移，线程池中资源将被耗尽~~

4. java.net.socketinputstream.socketread0 hangs thread
	socket read一直hang住，原因：
		- 依赖服务不稳定
		- 数据量太大，处理时候很长。
	解决方案：
		- 提升服务稳定性
		- 调用者设定超时


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day163 Thursday, November 01, 2012

1. 
	* 6.33搭设ace4j API+6.27master
		更新api包
	* slbapi问题
		db断线后，请求过来，导致too many open files
		jdbc配置域名，mysql命令行可连上mysql，java程序报 java.net.UnknownHostException

		java dns缓存
		重启服务OR命令行中配置不缓存
	* bugfix项目需求讨论

2. 

3. 禁用Java DNS缓存-Disable DNS caching
	http://itindex.net/blog/2007/01/22/1169462290428.html

	java命令中加上参数：Dsun.net.inetaddr.ttl=0 


4. too many open files 问题
	场景：
		linux打开大量socket
		socket没有正常关闭。为了定位问题是否由Java进程引起，通过Java进程号查看当前进程占用文件描述符情况： 
		Java代码  
		lsof -p $java_pid 每个文件描述符的具体属性  
		lsof -p $java_pid | wc -l  当前Java进程file descriptor table中FD的总量  
		ls /proc/$PID/fd | wc -l
		ls /proc/8633/fd/ -al |grep socket 查看进程打开的socket数

			分析命令的结果，可判断问题是否由非正常释放资源所引起。


5. nuwa命名服务
	kuafu http proxy http_proxy
	kfc协议的支持需要同cluster，规模受限，通过proxy方式，跨cluster

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day164 Friday, November 02, 2012

1. 
	* 

2. 

3. wiki维护
	API线上问题：
		http://wiki.ec.alibaba-inc.com/index.php/API/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98
4. nslookup


5. 域名不能解析，mysql命令行却能访问的问题
	测试场景：
		6.33 API
			JDBC的数据库地址配域名指向6.32
			启动API,访问正常
			修改/etc/hosts
			修改上面指向6.32的域名
			大量调用API访问数据库，API错误日志再大量请求时会报：Caused by: java.net.UnknownHostException: xxx；但是，请求量小时，不会报上面的错误
				是因为连接池中，有指向原来域名指向的IP，新建的连接由于域名改变，不能解析，出现的条件是，请求量大到需要再建立连接时报错，对API启动时已
				创建的连接不影响。

		6.32 DB

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
November 05, 2012 - November 07, 2012
take some days off



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day165 Thursday, November 08, 2012

1. 
	* bugfix项目
		http proxy替换
		join/leave group接口支持用户体系改造逻辑
	* SLB的大region兼容改造&发布计划
		数据订正check
	* 
2. 
	项目管理从redmine迁移到aone
		http://aone.alibaba-inc.com/aone2/project/134/task?_token=e18619aa-95f5-4590-9fda-b88be2554147
	bugfix API branch：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bugfix_201211
	http proxy doc：
		http://wiki.ec.alibaba-inc.com/index.php/Http_proxy%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0#HA.E6.9C.BA.E5.88.B6.EF.BC.9A
		http proxy的功能 http proxy http_proxy kuafu 
			取代并兼容目前kfc内置的http服务器	
				kuafu协议支持的集群规模有限，通过proxy层来实现跨集群访问
			从houyiAPI接收http请求，转化为kfc request

3. resourceChecker
	instanceServiceImplTest

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day166 Friday, November 09, 2012

1. 
	* bugfix项目开发
		
	* 
		

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day167 Monday, November 12, 2012

1. 
	* bugfix项目
		remove_disk接口使用问题：
			新增mount,unmount disk接口，并修改查询disk接口的返回值，带上挂载状态便于remove_disk接口确认待删除的盘。
			mount_disk
			unmount_disk
			detail_disk
	* 双11，线上问题
	* list_mounted_snapshot
		返回值中：device_no是原snapshot基于的device
	* 网络存储
		并发IO问题(如第一次的读取ISO，有限制)

2. 线上问题
	-----
	问题1：创建VM（AY12111011204528c1514），控制系统在执行以下操作时存在deadlock
	【API收到控制系统返回】：
	2012-11-11 00:33:00,665  ERROR [ajp-127.0.0.1-8109-25] (ApsaraCommandExecutor.java:79) - failed to call houyi system,command:CreateVm, parameters: {"rackId":"","recoverable":0,"imageUrl":"","isoName":"","vcpus":1,"intranetRx":-1,"canBalloon":0,"baseUrl":"","ioValue":5,"ncId":"","userId":"29629","hostName":"AY12111011204528c1514","deviceId":"","vType":"","imageDeviceId":"70000006","internetRx":-1,"cpuValue":5,"startupMode":"init","imageClusterId":"1007","kernelId":"","ramdiskUrl":"","baseSize":0,"kernelUrl":"","vmName":"AY12111011204528c1514","isBlind":0,"imageVersion":"1","baseVersion":"","vlanId":"","intranetTx":-1,"imageSnapshotId":"259911","imageId":"centos5u4_32_20G_alibase_v01.vhd","mountType":1,"rate":-1,"lbType":"","baseType":0,"ballonEnable":0,"baseId":"","dataAvail":1,"imageSize":20,"internetTx":1024,"memory":1536,"snapshotSize":20,"zoneId":"cn-hangzhou-dg108-a","canMigrate":0,"groupId":"142837","initPasswd":"acff3fd1","pubKey":"","netValue":5,"ramdiskId":"","isoPath":"","imageType":2,"diskSize":40}; result: {"code":  -5025,"desc":  "mysql error","isSuccess":  "FALSE"}.

	【控制系统内部日志】：
	[2012-11-11 00:33:00.641520] [ERROR] [15519] [build/debug64/houyi/common/houyi_metadata_process.cpp:2700] [method=update MAC]:update MAC fail[sql=update mac set name='AY12111011204528c1514', scope = 2, gmt_modify='2012-11-11 00:33:00' where mac='00:16:3e:12:12:1b']:[mysql error=Deadlock found when trying to get lock; try restarting transaction]


	问题2：补偿重试创建VM（AY12111011204528c1514）时，控制系统报存在该VM的数据。
	PS:该VM第一次创建时，控制系统提示“mysql error“，API收到控制系统创建失败的信息，对该VM记录进行了回滚，但控制系统的VM记录并没有回滚。

	【API收到控制系统返回】：
	2012-11-11 01:14:13,336  ERROR [ajp-127.0.0.1-8109-3] (ApsaraCommandExecutor.java:79) - failed to call houyi system,command:CreateVm, parameters: {"rackId":"","recoverable":0,"imageUrl":"","isoName":"","vcpus":1,"intranetRx":-1,"canBalloon":0,"baseUrl":"","ioValue":5,"ncId":"","userId":"29629","hostName":"AY12111011204528c1514","deviceId":"","vType":"","imageDeviceId":"70000006","internetRx":-1,"cpuValue":5,"startupMode":"init","imageClusterId":"1007","kernelId":"","ramdiskUrl":"","baseSize":0,"kernelUrl":"","vmName":"AY12111011204528c1514","isBlind":0,"imageVersion":"1","baseVersion":"","vlanId":"","intranetTx":-1,"imageSnapshotId":"259911","imageId":"centos5u4_32_20G_alibase_v01.vhd","mountType":1,"rate":-1,"lbType":"","baseType":0,"ballonEnable":0,"baseId":"","dataAvail":1,"imageSize":20,"internetTx":1024,"memory":1536,"snapshotSize":20,"zoneId":"cn-hangzhou-dg108-a","canMigrate":0,"groupId":"142837","initPasswd":"acff3fd1","pubKey":"","netValue":5,"ramdiskId":"","isoPath":"","imageType":2,"diskSize":40}; result: {"code":  -15017,"desc":  "this vm name already exists","isSuccess":  "FALSE"}. 

	问题3：API后台日志看到存在distributed_flag_lock表的Deadlock异常

	Caused by: com.ibatis.common.jdbc.exception.NestedSQLException:
	--- The error occurred in ibatis/distributed_flag_lock.xml.
	--- The error occurred while applying a parameter map.
	--- Check the distributed_flag_lock.unLockAllLockedRecordsBeforeDate-InlineParameterMap.
	--- Check the statement (update failed).
	--- Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction
		at com.ibatis.sqlmap.engine.mapping.statement.MappedStatement.executeUpdate(MappedStatement.java:107)
		at com.ibatis.sqlmap.engine.impl.SqlMapExecutorDelegate.update(SqlMapExecutorDelegate.java:457)
		at com.ibatis.sqlmap.engine.impl.SqlMapSessionImpl.update(SqlMapSessionImpl.java:90)
		at org.springframework.orm.ibatis.SqlMapClientTemplate$10.doInSqlMapClient(SqlMapClientTemplate.java:413)
		at org.springframework.orm.ibatis.SqlMapClientTemplate.execute(SqlMapClientTemplate.java:209)
		... 18 more
	Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction

	问题4：VM（AY12111112291654c6269）第一次启动失败(失败原因的日志如下)，第二次启动是成功的
	【NC日志】：
	[2012-11-11 01:36:06.145832] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:617] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:AddRule failed ret:-1
	[2012-11-11 01:36:06.146052] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:128] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:SetControlIpChain failed ret:-1
	[2012-11-11 01:36:06.146104] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:186] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:SetInternetAllFireWall fail
	[2012-11-11 01:36:06.238157] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2059] config redhat ip 00:16:3e:12:15:7d eth1 42.121.53.76 255.255.252.0 42.121.55.254:0:success
	[2012-11-11 01:36:06.422903] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2086] config redhat default_gw 42.121.55.254:0:success
	[2012-11-11 01:36:06.573502] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2114] config redhat route 192.168.0.0 16 10.200.127.254 eth0:0:success
	[2012-11-11 01:36:06.663574] [INFO] [16733] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:967] Msg:vm[iso-AY12111112291654c6269] stopped 5 second after shutdown
	[2012-11-11 01:36:06.683631] [ERROR] [16733] [build/debug64/houyi/nc/handlers/nc_vm_handler.cpp:733] [vmname=AY12111112291654c6269]:init vm failed, do not start vm
	[2012-11-11 01:36:06.693163] [DEBUG] [16733] [build/debug64/houyi/nc/handlers/nc_handler.cpp:29] Msg:succeed to send response:StartVmRsp:sequence:4358921489341223957
	[2012-11-11 01:36:06.710829] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2114] config redhat route 172.16.0.0 12 10.200.127.254 eth0:0:success

	-----

3. 组件化
	组件化设计 模块热插拔 模块化 
		面向统一的接口，热部署组件（功能）
	OSGI 
		类似eclipse，可以通过插件的方式增加其功能。
	openfire

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day168 Tuesday, November 13, 2012

1. 
	* 
	* slb v2 
		cache ，mark in doc
	* slb v2
		region_no参数传递问题：定位slb后端地址，是否在api层维护lbId和region_no关系，除创建LbId，其他接口可不传region_no？待分析
	* kfc拆除c，d，API的instance缓存需要清除（缓存了image_id）
		
		
	

2. slb 生产环境 slb api
	10.250.6.37 
	sarah.wangq@shterm.aliyun-inc.com
	slb api
	slbapi(mysql)		       go2

	check
		update vm region_no to bigRegionNo(1 to 1)
	原多个vm region对一个lb region，现一个vm big region对应一个lb region
	
3. too many open files

	--------
	2012-10-16 21:05:14,658 ERROR [com.aliyun.slb.api.service.impl.RsServiceImpl] - [error occur] java.net.SocketException: Too many open files
		at java.net.Socket.createImpl(Socket.java:397)
		at java.net.Socket.getImpl(Socket.java:460)
		at java.net.Socket.bind(Socket.java:577)
		at sun.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.commons.httpclient.protocol.ReflectionSocketFactory.createSocket(ReflectionSocketFactory.java:139)
		at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:125)
		at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
		at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
		at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
		at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
		at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
		at com.aliyun.slb.api.util.http.HttpUtil.sendRequest(HttpUtil.java:52)
		at com.aliyun.slb.api.service.impl.RsServiceImpl.queryIpByName(RsServiceImpl.java:42)
	--------
	场景：
		master服务不可用，并发请求 queryIpByName且超时过长或不超时，导致sock打开过多？ 待验证

		java的socket实现类会根据需要创建TCP或者UDP socket（具体创建由native方法去做）	- 参考 java.net.Socket.createImpl	* 本地方法 JNI (java native interface)JNA(java native access)

		本地方法设置socket超时例子： java.net.PlainSocketImpl private native void socketConnect(InetAddress address, int port, int timeout) 


	总结：
		对于系统依赖部分逻辑，需要考虑超时问题，避免因为第三方服务不稳定影响自身服务的稳定。
		打开的流要关闭
		根据并发量配置linux进程打开文件数属性：ulimit -a ；ulimit -n 4096 ；修改/etc/security/limits.conf 添加如下一行：	      * - nofile 1006154 修改/etc/pam.d/login添加如下一行 session required /lib/security/pam_limits.so

4. timeout问题 超时问题 socket超时
	apache的commons-httpclient-3.1.jar封装的socket默认超时为0，即不会超时，需要显示的设置超时时间。
	设置超时说明为：Sets the default socket timeout (SO_TIMEOUT) in milliseconds which is the timeout for waiting for data

	比如设置超时30s，在一定的并发下可保证服务的稳定，一旦超过一个阀值，连接池被耗尽，再继续并发，大量socket拥堵达到文件打开数上限（待验证）

	ulimit -a 配置信息
	ulimit -p $PID 查看PID打开的文件数
5. find . "*.log" | xargs grep -H "UnknownHostException: my3320.mysql.aliyun.com"
	linux查询字符串，查询文本，查询内容

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day169 Wednesday, November 14, 2012

1. 
	* bugfix201211
		release_ip
		modify_flow_limit
	* 连调测试
		

2. log4j配置
	web.xml
	<context-param>
		<param-name>log4jConfigLocation</param-name>
		<param-value>file:${user.home}/.houyi/log4j.xml</param-value>
	</context-param>
	<!-- 配置重加载 -->
	<context-param>
		<param-name>log4jRefreshInterval</param-name>
		<param-value>10000</param-value>
	</context-param>

	log4j放在上下文中的属性。其他方式。。

3. log日志不更新小问题 -tip-
	java web服务以admin起动，但是之前以root启动过，导致log等文件的权限都是root的，这样java服务是ok的，但log始终不会更新，排除了log4j的配置问题和其他可能，最后定为是
	linux系统文件写权限问题，囧。。。。

	chown -hR admin:admin logs/

	修改后，若不重启java服务，日志还是不会更新（why？），重启即可。

4. 频度控制 -tip-
	对于API接口的频度控制：基于IP，基于调用者?
		独立于API之外的服务来控制调用频度/调用频率

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day170 Thursday, November 15, 2012

1. 
	* bugfix201211连调
		modify_flow_limit
			shutted状态问题？
		query_group_vm 此接口不支持用户体系改造，是否修改？
			确定修改

	* slb api httpclient连接关闭问题
2. maven clean时，linux中若文件被ln连接引用，需要删除引用（如target中的war包被引用）


3. too many open files错误
	httpclient的连接别样被关闭？
		slb v2 设置了连接超时，等待数据超时
		但是没有关闭connection
		假设，系统在设定的时间过后，关闭socket

		测试：
			系统回收socket时间周期内，发送超过操作系统限制的进程打开文件数，抛出异常。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day171 Friday, November 16, 2012

1. 
	* 连调
		query_group_vm接口单元测试编写
2. 

3. CLOSE_WAIT
	TCP/IP协议说明，由于被动关闭连接会产生CLOSE_WAIT状态。
	测试httpclient：
		测试sendRequest方法
		参数：url=www.baidu.com,method=get
		循环次数：num=1000
		执行好后sleep 2min
		
		测试2种场景：
			1）关闭连接
				HttpClient httpClient = new HttpClient(new SimpleHttpConnectionManager(true));
			2）不关闭连接
				HttpClient httpClient = new HttpClient();				

		对比上面两种场景的检测数据：
			ps -ef | grep java 找到当前测试运行的java进程PID
			netstat -anpc |grep 220.181.111.148 |grep CLOSE_WAIT - 查看CLOSE_WAIT状态的连接

		分析结果：
			场景1）中，没有CLOSE_WAIT瞬时状态
				执行好后，没有到www.baidu.com的socket连接	，netstat -anpc |grep 220.181.111.148为空
			场景2）中保持有170个的CLOSE_WAIT状态的socket，直到测试进程结束才会断开socket。
			netstat -anpc |grep 220.181.111.148

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day172 Monday, November 19, 2012

1. 
	* API事务lock分析
		pool exhausted ？
			有慢数据库连接
	* review代码阅读
		id=182672 kelude
		=173658
2. API事务lock分析
	pool exhausted ？
		有慢数据库连接占满pool
		maxactive数不够
		pool中的连接有问题
		工具自身bug
3. shell

4. starting状态  业务
	一直处于starting状态的原因之一：master重启，导致状态不一致


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day173 Tuesday, November 20, 2012

1. 
	* slb api数据检查
	* houyi api
		并发add_disk,remove_disk的问题
		40 (+ 5 + 5 - 5 concurrent) = 45 ？50

		http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9252783


	* httpclient3.1
		CLOST_WAIT过多问题
	
		(1) 通过设置请求头参数：
			httpMethod.setRequestHeader("connection", "close"); //此消息头参数参考：http://www.ietf.org/rfc/rfc2616.txt Hypertext Transfer Protocol -- HTTP/1.1	第14.10节
				----
				HTTP/1.1 defines the "close" connection option for the sender to signal that the connection will be closed after completion of the response. For example,
				Connection: close
				in either the request or the response header fields indicates that the connection SHOULD NOT be considered `persistent' (section 8.1) after the current request/response is complete.
				----
				from: http://www.ietf.org/rfc/rfc2616.txt
		(2) 通过httpclient中simpleconnnectionmanager的带参构造函数实现，单元测试ok，但运行时计量推送逻辑有问题，报错如下：
			Caused by: java.lang.NoSuchMethodError: org.apache.commons.httpclient.SimpleHttpConnectionManager.<init>(Z)V
			at com.aliyun.houyi.util.HttpUtil.sendRequest(HttpUtil.java:48)
			根据错误，是找不到对应的方法。？

		连接复用与多线程并发问题：连接复用，连接保持，connection persistence
			可以通过httpclient提供的			
	* master(java) 无状态 ，多个平级master管理一个多nc的大region
		选型 
			Dubbo http://baike.baidu.com/view/6901431.htm

2. slb api数据检查
	当前slb api数据库，
	DB地址:	10.242.252.41 slbapi
	139dc81f48f-cn-hangzhou-dg-a01,10.241.2.118	(rs表没有此lb_id，也没有此ip)
	13a0a5e12cc-cn-hangzhou-dg-a01,10.200.2.34	(rs表有这个lb_id，但没有这个ip的记录)
	13ae9d4087f-cn-hangzhou-dg-a01,10.200.115.236	 (rs表没有此lb_id，也没有此ip)

	根据上面的分析，“上述三个lb – rs(ip)的对应关系不存在于api的数据库中”

3. 同时修改同一数据的问题
	select instance_no,disk from instance where instance_no='mytest2012-11-1' for update;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day174 Wednesday, November 21, 2012

1. 
	* slb v2 聚石塔项目slb后端api有变动，api分析是否需要相应的变动，详见邮件
	* bugfix201211代码review
	* user_reform后代理商自己的vm的释放问题
	* slb后端直接配置的vip，现需要通过slb api来配置，对应的slb api数据库订正问题
	* slb api线上日志分析，add_rule报错
		
2.  代码review
	(1) create_vm的disk参数，如果传入了非空，但却没有校验（大小范围，格式）？	  还是这个值就该废弃，即用户指定disk时会有问题
		后面有不为空时的参数校验，此处ok
	(2) 
3. user_reform后代理商自己的vm的释放问题
	release_vm时API要做的处理：
	1) 退出 vm 所在的所有组
		- 根据instanceId查询出vm所在的groupId列表：
			SELECT group_id
			FROM group_instance
			WHERE instance_id = #instanceId#
		- 根据group所在的bigRegionNo找到其对应的masterRegion	作为目标regionNo
			SELECT
					 id,
					big_region_no,
					master_region_no,
					gmt_create,
					gmt_modify
			FROM master_region
			WHERE big_region_no = #bigRegionNo#
		- 生成一条设置防火墙规则到api数据库，返回messageId(主键)
			sfw_command表：event=6(leaveGroup)，data={"groupId":xxx,"instanceId":xxx}，target=xxxRegionNo(instance.getRegionNo())，gmt_create=xxx,gmt_modify=xxx
			返回 messageId
		- 构造leaveGroup的RPC请求：
			ExitGroup 
			regionNo=上面的目标regionNo
			messageId，groupId，vmName
			发送到netc
		- 上面leaveGroup的RPC成功调用后，删除group_instance表对应的记录
			delete from group_instance 
			where group_id = #groupId# 
			and instance_id = #instanceId#
		- 构造下发防火墙的RPC请求
			SetFireWall
			messageId=xxx（上面的主键ID），type=6，data={groupId=xxx,vmName=xxx}(Map)
			发送到netc
			 regionNo=
				根据bigRegionNo找到其对应的小reginNo列表，依次遍历得到的小region并调用上面的RPC下发防火墙（只记录失败，不回滚操作）			
	2) 释放IP
		- RPC查询vm的公网ip列表(List<String>) ，得到公网ip列表
			GetPublicIpsByName
			regionNo=instance.getRegionNo()
			vmName=intance.getIntanceNo()

			结果处理：（是否已有此RPC功能的脚本命令？）
				取publicIpList对应的内容，ip列表
		- RPC查询vm的vip列表(List<String>)，得到vip列表和port列表
			GetMemberInfo
			vmName=instance.getInstanceNo()
			port=-1
			发送到netc
		-RPC调用释放vm的公网ip和vip
			RemovePublicIp
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			发送到netc
	3) 释放VM(兼容处理控制系统是否有此vm)
		- RPC查询vm，判断vm在控制系统是否存在
			GetVmInfo
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			发送到master
		- 若上面的返回成功（取json串的isSuccess的值-true/false），RPC调用控制系统释放vm，(CLC释放？)
			DestroyVm
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			clearDatabase=0
			发送到master
	4) 释放VM后，检出待释放的VIP
		- RPC遍历查询步骤2)得到的vip地址列表，去掉列表中不存在的vip-port
			GetVipInfo						
			vip=xxx
			vipPort=xxx
			userId=instance.getUserId()
			发送到netc
		- 合并步骤2)得到的ip列表和上面处理过的vip列表（没有使用？）
	5) 更新API数据库的vip表
		delete from `vip`
		where instance_no=#instanceNo#
	6) 更新API数据库的instance信息
		instance表：
			statusComment=""
			status=8
			instanceNo=instance.getInstanceNo()

	具体操作的工具实现通过脚本：
		python		

4. slb后端直接配置的vip，现需要通过slb api来配置，对应的slb api数据库订正问题
	
5. slb api线上日志分析，add_rule报错
	http://10.200.219.250/slb/api?action=add_rule&aliyun_idkp=146&frontend_port=80
	&lb_id=13a8663a28d-cn-hangzhou-dg-a01%0D%0A&region_no=cn-hangzhou-dg-a01
	&rule_list=%5B%7B%22domain%22%3A%22tzm123456.aliapp.com%22%2C%22rs_pool_name%22%3A%22tzm123456.aliapp.comace4j%22%7D%5D
	&session=b9ALSaJIBZaMJd3UwH%2BAFw%3D%3D&timestamp=2012-11-20+19%3A34%3A13&sign=nHwrhyW%2BOUcmCSIr42b%2BVA%3D%3D&sign_type=MD5

	13a8663a28d-cn-hangzhou-dg-a01%0D%0A 
		这里后面多了个换行符 "\r\n"	utf-8 = %0D%0A
	
	请求到slb api时，lb_id作为参数，末尾带了 \r\n 是允许的；但api提供的rest接口，在用lb_id构造uri后，请求此uri时报错。
		api需要捕获这个异常，即透明构造请求后端的url时，需要做基本的校验，便于用户知道哪里错了？
			构造uri时需要校验参数，保证uri是合法的。

	http://10.250.8.214/open/services%0D%0A?
		500 tomcat错误页面
			需要包装下。
			比如，上面的uri不合法，是否在nginx层就拦截掉并指向到友好的界面？
				还是服务器自己定位吧，nginx只转发，职责清晰。

6. 错误处理 -tip-
	错误重定向，比如对500,503等错误定向到友好的提醒页面（对于uri不合法的错误定向）
		
	系统建议

7. slb后端绕过api陪的vip重新从api走，db订正
	insert into xx (vm_name,ip,rs_pool_name,user_id,lb_id,region_no) values('vmName','10.241.48.113','1313-80-http',39314,'1394c332d0a-cn-hangzhou-dg-a01','cn-hangzhou-dg-a01');
	...
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day175 Thursday, November 22, 2012

1. 
	* bugfix201211 review
	* 事务
	* api并发接口测试，Full GC导致TPS抖动问题


2. 事务 中间状态 并发控制
	接口操作的事务控制，比如并发去start_vm，release_vm时，并发修改vm的状态需要控制。
	可以用悲观锁来串行化修改状态的操作，然后释放锁，这个状态在操作完成后再更新。

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day176 Friday, November 23, 2012

1. 
	* TIME_WAIT状态
	* Full GC问题



2. 大量TIME_WAIT状态的问题		       * TIME_WAIT
		客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口
	状态为TIME_WAIT
	 
	是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？
	有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？
	 
	主动关闭的一方在发送最后一个ack 后
	就会进入TIME_WAIT 状态 停留2MSL（max segment lifetime）时间
	这个是TCP/IP必不可少的，也就是“解决”不了的。
	也就是TCP/IP设计者本来是这么设计的

	通过设置系统socket相关参数，比如linux下：
		调整内核参数解决，
		vi /etc/sysctl.conf

		编辑文件，加入以下内容：
		net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
		net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
		net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
		net.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间
		 
		然后执行 /sbin/sysctl -p 让参数生效。
		
	TIME_WAIT状态的意义：
		主动关闭的一方在发送最后一个ack 后
		就会进入TIME_WAIT 状态 停留2MSL（max segment lifetime）时间
		这个是TCP/IP必不可少的，也就是“解决”不了的。
		也就是TCP/IP设计者本来是这么设计的
		主要有两个原因
		1。防止上一次连接中的包，迷路后重新出现，影响新连接
		  （经过2MSL，上一次连接中所有的重复包都会消失）
		2。可靠的关闭TCP连接
		  在主动关闭方发送的最后一个ack(fin) ，有可能丢失，这时被动方会重新发
		  fin, 如果这时主动方处于CLOSED 状态 ，就会响应rst 而不是ack。所以
		  主动方要处于TIME_WAIT 状态，而不能是CLOSED 。
		TIME_WAIT 并不会占用很大资源的，除非受到攻击。
		还有，如果一方send 或recv 超时，就会直接进入CLOSED 状态

3. java DNS缓存  java dns * dns缓存
	不缓存DNS		
	-Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0

	通过在 JAVA_OPTS 参数中设置值(执行shell时设置一些参数)：
		export JAVA_OPTS="-Xms128m -Xmx1024m -XX:MaxPermSize=256m -Xrunjdwp:transport=dt_socket,address=8788,server=y,suspend=n -Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0 $JAVA_OPTS"

		$JAVA_OPTIONS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n
			注意：这里suspend参数表示启动时是否挂住等待调试连接，一般设置为n，若需要启动时就进行调试可以设置为y

	
4. agent's vm
	set its own user_id as agent_id to release vm.

5. Full GC问题
	目标减少full gc：
		full gc的触发是由于年轻代被耗尽，中老两代空间也被用完。
		年轻代，年老代，
	造成full gc的原因：
		主要原因可能为，程序代码所致（产生大量的对象，忘记释放资源等）
		再者可能与框架有关

	分析办法：
		可通过排除法，从最简单的逻辑，通过测试排除来找到导致频繁full gc的原因。
6. nc资源被耗尽
	xm list
7. 零拷贝(zero-copy)和环形队列缓存队列问题 队列结构的实现
	
	BlockingQueue
	ConsistentHashMap

	参考：http://www.cnblogs.com/wanderxjtu/archive/2009/04/25/1443518.html Zero Copy I: User-Mode Perspective
	
8. jetty continuation & servlet3.0(NIO)
	"Continuations will be replaced by standard Servlet-3.0 suspendable requests once the specification is finalized. Early releases of Jetty-7 are now available that implement the proposed standard suspend/resume API"
	from: http://docs.codehaus.org/display/JETTY/Continuations

	continuaton缺点，导致编程模型复杂，需要切分io操作。
	
	continuation and servlet3.0 ：http://webtide.intalio.com/2009/07/continuations-to-continue-2/
	
	Servlet3.0
		Tomcat7支持

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day177 Monday, November 26, 2012

1. 
	* 验证java DNS缓存参数配置，不缓存域名到ip的映射
	* 数组，链表，零拷贝(zero-copy) 数据结构  对象拷贝
		在数组等基本数据结构上，再封装的列表等数据结构
			list结构，内部实现为数组，在扩容时，要重新分配一个数组并进行拷贝；队列等结果也通过数组实现，插入效率高，知道下标时访问快速，
			但查找/删除慢其容量固定，特别是在数组指定位置（如头尾之间加或减）（内部通过System类的arraycopy方法实现数组复制）
		...
	参考书籍：
		Data Structures and Algorithms in Java (Robert Lafore)

2. 验证java DNS缓存参数配置，不缓存域名到ip的映射
	-Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0

	8.214 slbapi
	验证：当域名指向的IP被修改时，能正确连接到新的IP

	slb api数据库连接不上，报user illegal？不合适

	验证通过：
		通过在命令行中设置上述参数后，测试时，服务器启动后请求API，API调用了数据库，并在sql日志中可以看到；
		此时，将jdbc中域名指向的ip改为其他的ip（此时，需要将原来IP指向的机子的mysql服务需要停掉~），再次调用API，API日志是否正确打出日志；结合 mysql的命令show processlist；
		以确认数据库调用是否正确切换了IP，根据测试结果，加入上述参数后，API能正确切换IP。
	小节：
		在切换IP时被坑，原因是不了解java内部处理域名IP映射关系的更新机制，目前来看是在原域名指向的IP服务不可用时才会重新解析域名。
			这个现象是否与web程序缓存了数据库连接池有关系？
		另外，若ttl不配置，jvm默认不是永久缓存dns信息，而是缓存30秒（在jdk/jre/lib/java.security文件中有说明）



3. slbapi启动日志查看及一些warning的排除(tomat+nginx+slbapi)		  * log4j * 日志
	tomcat日志 开发环境 linux tomcat7
		- 权限问题导致的某些日志，临时文件夹没有访问权限（修改权限，并以admin来操作）
		- 报maxThread这个配置找不到对应的属性（属性名错误，应该为maxThreads）
		 - log4j:WARN No appenders could be found for logger (org.springframework.web.context.ContextLoader). —— 未配置spring的这个装载器的日志项，可以配置在root中，或者专门一个spring的appender。
			log4j的配置，appender可以有多个（可以定向到文件或标准console），logger定义了实际需要记录日志并使用前面定义的appender
			（全局logger记录自定义logger未包含的部分的日志输出，比如自定义的logger并没有定义spring的log输出，则可以在root级别定义其日志或其中框架的日志。例子见下面）。
	
	目的：
		启动日志无异常情况或非正常warning

	log4j配置例子：
	------
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">
		<log4j:configuration xmlns:log4j="http://jakarta.apache.org/log4j/">
			<appender name="stdout" class="org.apache.log4j.ConsoleAppender">
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d  %5p [%t] (%F:%L) - %m%n" />
				</layout>
			</appender>

			<!--sql debug log file -->
			<appender name="SQL_DEBUG"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/debug.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="debug" />
					<param name="LevelMax" value="debug" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--sql info log file -->
			<appender name="SQL_INFO"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/info.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="info" />
					<param name="LevelMax" value="info" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--sql error log file -->
			<appender name="SQL_ERROR"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/error.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="error" />
					<param name="LevelMax" value="error" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slb.api debug log file -->
			<appender name="APP_DEBUG"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/debug.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="debug" />
					<param name="LevelMax" value="debug" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slbapi info log file -->
			<appender name="APP_INFO"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/info.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="info" />
					<param name="LevelMax" value="info" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slbapi error log file -->
			<appender name="APP_ERROR"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/error.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="error" />
					<param name="LevelMax" value="error" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!-- api called log-->
			<appender name="openapi_all" class="org.apache.log4j.RollingFileAppender">
				<param name="file" value="logs/slbapi/all.log" />
				<param name="MaxFileSize" value="1000KB" />
				<param name="MaxBackupIndex" value="100" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
			</appender>


			<!--other debug log file-->                                                                                                                                
			<appender name="OTHER_DEBUG" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                 
				<param name="File" value="logs/slbapi/other/other_debug.log"/>                                                                                
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="debug"/>                                                                                                 
					<param name="LevelMax" value="debug"/>                                                                                                 
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>                                                                                                                                            
																					       
			<!--other info log file-->                                                                                                                                 
			<appender name="OTHER_INFO" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                  
				<param name="File" value="logs/slbapi/other/other_info.log"/>                                                                                 
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="info"/>                                                                                                  
					<param name="LevelMax" value="info"/>                                                                                                  
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>                                                                                                                                            
																					       
			<!--other error log file-->                                                                                                                                
			<appender name="OTHER_ERROR" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                 
				<param name="File" value="logs/slbapi/other/other_error.log"/>                                                                                
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="error"/>                                                                                                 
					<param name="LevelMax" value="error"/>                                                                                                 
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>
			 
			<logger name="com.aliyun.slb.api.interceptor" additivity="false">
				<level value="all" />
				<appender-ref ref="openapi_all"/>
			</logger>
			<!--java.sql assign to sql log-->
			<logger name="java.sql" additivity="false">
				<level value="debug"/>
				<appender-ref ref="SQL_DEBUG"/>
				<appender-ref ref="SQL_INFO"/>
				<appender-ref ref="SQL_ERROR"/>
			</logger>
			<!--ibatis assign to sql log 这个有问题，日志出不来-->
			<logger name="com.ibatis" additivity="false">
				<level value="debug" />
				<appender-ref ref="SQL_DEBUG" />
				<appender-ref ref="SQL_INFO" />
				<appender-ref ref="SQL_ERROR" />
			</logger>

			<!--com.aliyun.slb.api assign to app log -->
			<logger name="com.aliyun.slb.api" additivity="false">
				<!--com.aliyun.slb.api assign to app log -->
				<level value="debug" />
				<appender-ref ref="APP_DEBUG" />
				<appender-ref ref="APP_INFO" />
				<appender-ref ref="APP_ERROR" />
			</logger>

			<!--other class assign to other log-->
			<root>
				<level value="info"/>
				<appender-ref ref="OTHER_DEBUG"/>
				<appender-ref ref="OTHER_INFO"/>
				<appender-ref ref="OTHER_ERROR"/>
			</root>

		</log4j:configuration>
	------
	上面的配置，spring（struts等框架及其他组件）的日志会在  OTHER_DEBUG，	 OTHER_INFO  ，OTHER_ERROR中输出。
			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day178 Tuesday, November 27, 2012

1. 
	* bugfix201211预发布
	* houyi api
		resetfailed
		startfailed
			master不保存此状态，通过MQ，api得到状态变化
	* master重构 ？待201301
		设置houyi api计量数据部分：
			计量数据由nc采集 (以python替换cpp)，然后直接写入(或者做缓冲层或错开并发)到OMS，采集并保存过程完成。
			API从OMS取需要的数据：
				涉及，与OMS沟通：
					是否满足简单的查询需求（根据现有的数据库查询逻辑）
					性能上大量nc同时写入是否ok，tps能否满足，上限是多少？（会影响nc是直接写入OMS还是需要缓存层，降低OMS压力）
  
  2. 

3. java nio包中缓存类的实现
	Buffer(Abstract) -> DoubleBuffer(Abstract) -> HeapDoubleBuffer(Class) -> HeapDoubleBufferR(Class read-only)
		内部通过数组结构实现；内存复用(减少内存拷贝)；

4. 走不通？绕一绕。。。 -tip-
	release_vm接口mock控制系统进行测试。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day179 Wednesday, November 28, 2012

1. 
	* api region 找不到问题分析

2. 清代理商自己的VM
	- 模拟用户体系改造前用户角色，创建VM（加入组等其他操作）
	- 对上面用户进行用户体系改造并重启API，但对vm没有订正数据（测试结果vm将不能被释放，代理商不允许有自己的资源）
	- 模拟上面用户的一个子用户创建VM，便于验证不影响子用户的操作。
	- 将用户的agent_id值指向自己，再重启API
		确认这样的代理商(agent_id指向自己)，不影响子用户正常操作   （测试不影响，agent_id指向自己只在判断是否user一致时起作用）
		也不影响此代理商正常操作（测试通过，detail_vm子用户的vm；不能创建资源）
		最后，调用release_vm操作（可以debug去走，保证过程都ok）（测试结果：）

3. region找不到错误分析
	API日志记录：
		2012-11-27 19:47:29,193  ERROR [ajp-127.0.0.1-8109-260] (RegionAwareInterceptor.java:100) - regionNo: not exist
			这里regionNo为空，报了找不到（RegionAwareInterceptor.java 100行，根据vm找region时报错），action中继承的查找region的方法没有将region设置到regionHolder中？，

	vm_name=AD1211270747158d19115
		创建vm成功后，
		调start_vm报vm not exists - 根据vm_name找region时，找region ,失败
		再调start_vm报resource has no corresponding region
		再调start_vm报resource has no corresponding region
	vm_name=AT121127073000bec4779
		创建vm成功后
		调assign_ip，报resource has no corresponding region - 找不到region

	定位start_vm时，action根据vm_name找到的regionNo=""，即为空（不是null）。

	找region的顺序：
		拦截器先调用action的找region逻辑来查找regionNo，并在找不到且为null的情况下报vm not exists，拦截器判断action的查找结果，若失败（如报：vm not exists）则报error日志：查询资源信息时发生错误!，
		拦截器判断action找regionNo成功，则以regionNo为键从缓存中取对应的region对象。（但regionNo可能是个空字符串，此时校验时拦截器报：regionNo:" +regionNo + " not exist）

	AbstractResourceLocator类的locateRegion(Class<T> type, String resourceNo)方法可能有问题？
		有一个缓存Map，区分group,instance,ipAddress，ipSegment，以前面4种资源的No(instance_no,group_no,...)作为key，并将各自资源的dao查询到对应的region，存入各自的map缓存中。

		resourceRegionCache这个缓存map，如果在创建vm时，regionNo还没有确定下来，这时数据库的region_no为空，此时若有更新这个map缓存的操作进来，比如detail_vm，就会导致，将
		vm_name和regionNo=‘’的映射存入缓存。下次根据vm_name找regionNo时，直接从map缓存返回空，导致错误，报-141 resource has no corresponding region。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day180 Thursday, November 29, 2012

1. 
	* vm_name&regionNo缓存问题小节
		整理现场日志
			
	* 服务器端无阻塞编程
		阻塞的地方有哪些，有什么方式实现无阻塞，系统提供了什么，编程模型提供了什么，什么场景都适用吗？

2. API线上问题记录及分析
	- 数据库数据不一致（数据同步）
		不同时间段查看时，同样的查询数据不一致
		AD1211270747158d19115这个vm的创建时间和更新时间28号看是一样的（异常值），29号就不一样（正常值），其29号的创建时间和28号的创建时间都不一致，why？

	- create_vm用时1分16秒
		vm_name=AD1211270747158d19115
	- vm_name=AT1211270647235655446
		regionNo=''
		创建时间，更新时间相同：2012-11-27 18:48:13
		info，error日志没有此vm_name对应的字符串，可能确实没有包含vm_name的日志输出，但在instance表有记录且数据由问题，在日志中应该有其他错误日志？

		调度：disk=40 ,mem=512,cores=1

		定位：
			又出现regionNo=''的记录，定位到数据库在主备切换，导致数据丢失。



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day181 Friday, November 30, 2012

1. 
	* key，pair 生成user的key和id ==	    签名
		UserService
	* python
		monitor计量重构

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day182 Monday, December 03, 2012

1. 
	* DB HA alternate problem
	* dubbo test
	* big region extend project
		go on design and development
		time to commit to QA at about 20
	* slb v2 requirement


2. DB HA alternate problem
	
	What's the problem that cause the HA Switching bettween master DB and backup DB frequently.？
		HA architecture：
			2Mysql(1 master,1 backup)
			vip

3. dubbo test
	follow by readme
	svn co http://code.alibabatech.com/svn/dubbo/trunk dubbo
	mvn clean install -Dmaven.test.skip=false
	... see readme doc
	
4. slb v2 requirement
	commit to QA at 12/15/2012
	requirement list: http://aone.alibaba-inc.com/aone2/req/productReq/339?_token=c849d35a-2347-4912-a520-e19b18249dbd
	- 计量数据接口，SLB后端计量库表名修改，相应API需要修改
		表名修改
			这次ospf项目中，计划对monitor库的变动主要在修改表的名称，表结构没变：

			haproxy_stats_${DATE} => proxy_stats_${DATE}
			haproxy_rule_stats_${DATE} => proxy_rule_stats_${DATE}
			haproxy_rule_hourly_stats_$DATE_MONTH => proxy_rule_hourly_stats_$DATE_MONTH
			haproxy_daily_stats_$DATE_YEAR => proxy_daily_stats_$DATE_YEAR

			对于haproxy_rule_stats_xxx的查询也需要改一下表名称了。

	- API使用的httpclient的socket关闭问题。
		使用不复用connection的方式
	- 前端调用的参数包含非法字符(如/r/n)，导致API构造出的请求后端的URI不合法，报错：-2001,"msg":"backend service exception"
		确保请求后端的URI格式合法，验证lb_id值的格式合法性（对lbId进行URL编码，这样）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day183 Tuesday, December 04, 2012

1. 
	* slb v2 requirement development
		httpclient的连接复用问题，若每次都创建连接，耗性能；超时释放
	* 大region二期
		设计文档再梳理，
	* api发布小版本(分布式lock问题)

			

2. slb v2的httpclient3使用MultiThreadedHttpConnectionManager，复用
	//这种方式，每次都新建连接，如果并发非常大，延迟高时，同一时间有大量请求时，是否会超过socket数上限？待验证
	//但连接毕竟还是会回收，在达到socket最大值后，那些请求将不能被处理
	HttpClient httpClient = new HttpClient(new SimpleHttpConnectionManager(true));


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day184 Wednesday, December 05, 2012

1. 
	* slb v2
		补充加入需求：
			 java启动参数设置不缓存DNS信息
				-Dsun.net.inetaddr.ttl=0(地址不缓存) -Dsun.net.inetaddr.negative.ttl=0(域名错误信息不缓存)
	* 大region二期
	* python
	* 灰度发布功能设计
		相关的表设计，逻辑实现设计，目标为加入配置实现灰度发布。业务强耦合的问题，如何抽象为统一模型？

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day185 Thursday, December 06, 2012

1. 
	* big region二期再kick off
		流量推送需求取消，在bugfix201211项目中做
		快照和image都会同步到其他region，这个对快照的跨region使用的影响？
			了解快照同步，image同步的逻辑：
				快照同步过后，API到指定的region上去detail_snapshot时，返回的快照的cluster_id应该就是本region的cluster_id？快照同步到各个小region后，对应的
				cluster_id都为各自region的cluster_id；同步后在不同region的同一个快照，可以视为独立的快照，只是他们的快照内容是一样的；
			image同步逻辑同快照同步逻辑。
				image同步后，有src_image_id字段标识image是源image还是由源image同步出来的。
			
			按照上面逻辑，说快照不能跨小region使用是ok的。

			在大region下查询某个image_no对应的源image_no时，可能会重？
				imageNo,userId,bigRegionNok
				imageNo,userId,region_no,

			需要考虑这个问题		
			image_no="windows2003cnstdr2.32.20110926.01.vhd" and src_image_id=0; 
			image_no="windows2008r2stden.64.20110605.01.vhd" and src_image_id=0;

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day186 Friday, December 07, 2012

1. 
	* bigregion二期，将原branch修改merger到基于最新trunk拉的分支上。
	* 数据库培训
		taobao数据库演化，自动化运维（自动切换的数据丢失问题，自动扩容，迁移，合并），余量模型
	* python



2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day187 Monday, December 10, 2012

1. 
	* slb api准备连调测试 8.214
		master 10.250.6.45:8088
		monitor db

	* 大region二期，补充细化控制系统兼容的设计文档及开发
	* 大region下，imageNo,user_id,bigRegionNo不能唯一确定一个image,这样对外的query_available_imgs接口可能返回2个或以上重名的imageNo，对用户
	会有歧义；api已保证通过api接口创建的image在大region下唯一，上传工具需要修改，也保证这点。


2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day188 Tuesday, December 11, 2012

1. 
	* 大region二期设计评审及问题讨论
		- list_mounted_snapshot控制系统返回值增加cluster_id，便于api识别其region
		- bucket类型image，以hash_on_kfc类型同步到老region，保证发布过程中bucket类型的imageNo在老region可使用
			即满足大region下，相同imageNo对应的存储类型bucket和hash_on_kfc可共存
			大regionNo，userId,imageNo对应的记录可以多条但必须保证为同一个image（其他的为副本）
		- region调度时，bucket类型返回所有new的region，再加上有hash_on_kfc的region，作为源调度列表
		- 使用image，优先bucket类型

	* slb api连调


2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day189 Wednesday, December 12, 2012

1. 
	* 大region二期开发
		基于C,D的kfc去掉前提，去掉原代码中kfc逻辑
	* 大region二期，工具评审，与api相关部分的确认
	* slb连调，表部分改动
		ok
	* 系统间交互，超时设置梳理，避免第三方服务影响主要业务的稳定性 -tip-

2. 

	select distinct r_alias.region_no,image.snapshot_type  
	from region_alias r_alias
	left join image image on image.region_no=r_alias.region_no
	where  r_alias.big_region_no='cn-hangzhou2' 
	and image.image_no = '' 
	and (image.user_id=0 or image.visibility=1)

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day190 Thursday, December 13, 2012

1. 
	* 大region二期开发
		- 基于vm1大的快照snapshot1，挂载到vm2上后，对应vm2上生成新device2，master限制此device2不能再打快照，只能使用。
		这样clusterId-deviceNo-snapshotId中快照和device有相同的clusterId。
		- 设计部分修改：新增兼容性接口修改
		master返回码待定



2. 设计
	pojo类设计
		系统对接的地方pojo类设计，本系统的pojo定义，接收第三方系统的pojo定义，分别定义构成映射，利于扩展。snapshot,snapshotExt


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day191 Friday, December 14, 2012

1. 
	* 大region二期开发
		及单元测试用例编写
		ERROR_SNAPSHOT_TYPE_NOT_SUPPORT = -30005 master快照不支持

	* slb api提测前检查及验证

	* linux生成core文件 -tip-
		本次由于关闭web服务时，java命令行多指定了远程调试参数，报端口被占用ERROR，ulimit -a 没有关闭core文件，于是每次关闭时生成core文件。
		core文件可通过gdb命令来查看

2. /etc/hosts文件配置错误，导致jboss启动失败		      -tip-
	Caused by: java.lang.RuntimeException: Exception creating identity: pangu_master_3: pangu_master_3
	[MainDeployer] Could not create deployment: file:/home/admin/houyi-ace4j/service/.default-open/conf/jboss-service.xml
	-------
	...
		Caused by: javax.management.MBeanRegistrationException: preRegister() failed: [ObjectName='jboss.remoting:service=NetworkRegistry', Class=org
	.jboss.remoting.network.NetworkRegistry (org.jboss.remoting.network.NetworkRegistry@23e45a5c)]
		at org.jboss.mx.server.registry.BasicMBeanRegistry.invokePreRegister(BasicMBeanRegistry.java:713)
		at org.jboss.mx.server.registry.BasicMBeanRegistry.registerMBean(BasicMBeanRegistry.java:211)
		at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.jboss.mx.interceptor.ReflectedDispatcher.invoke(ReflectedDispatcher.java:155)
		... 51 more
	Caused by: java.lang.RuntimeException: Exception creating identity: pangu_master_3: pangu_master_3
		at org.jboss.remoting.ident.Identity.get(Identity.java:211)
	...
	-------

	看上面的错误， Exception creating identity: pangu_master_3: pangu_master_3,在创建标识时报错，是因为本地回环(127.0.0.1)没有配置上上面这个hostname（pangu_master_3），
	配置上如下一项即可：
		127.0.0.1               pangu_master_3

	ref: https://community.jboss.org/thread/63869?tstart=0		

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day192 Monday, December 17, 2012

1. 
	* 大region二期
		- 6.33设置开发测试环境，部分连调
		- 单元测试用例
		- master多次发布，API是否需要重启的问题验证
			reload缓存接口


	* python
	* houyi api user 表
		access_id有unique约束，创建user时有默认值

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day193 Tuesday, December 18, 2012

1. 
	* 大region二期，自测，连调（master环境未完全ok）
		create_snapshot
		create_image
		...
	* 2013目标会
		目标及任务
			大控制系统重构
				nc上部分工具用python替换cpp实现，简化复杂度和维护成本（基于对性能要求不高）
		vpc分享
			自定义网络，网络层间通过网关交互

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day194 Wednesday, December 19, 2012

1. 
	* 大region二期，单元测试 ，连调
	* python
		python的GC，与java的GC对比 垃圾回收算法
			都提供标记-清除算法 mark-and-sweep
			
			其他：
				引用计数回收
				分代回收
				等等

				JVM参数设置不同的方式，或者自动根据情况选择GC回收算法


	* mysql主备切换，读写分离，一主多备，主库HA 自动切换 （根据现有的业务压力和需求决定是否需要这么做，一般主备切换是基本的）
		ref: http://code.google.com/p/mysql-master-ha/

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day195 Thursday, December 20, 2012

1. 
	* 大region二期连调
		aliyunIdkp=alisys_vms 用于oss测试环境账号(否则创建bucket失败)
		mount_snpashot接口，deviceNo传给master保持不变，值来自快照ID
			-tip- 改进，对master少传参数的情况，可以报错，等待超时返回太耗性能...
		
		- 27,28左右新API老master连调结束

	* python
		mark-and-sweep 有应用短时间不可用和内存碎片问题    GC
		引出，stop-and-copy回收算法,解决内存碎片问题需要2倍的heap内存且只能真正使用其中的一半(ref: http://www.brpreiss.com/books/opus7/html/page428.html)
		引出，Mark-and-Compact
			The mark-and-compact algorithm consists of two phases: In the first phase, it finds and marks all live objects. The first phase is called the mark phase. In the second phase, 
			the garbage collection algorithm compacts the heap by moving all the live objects into contiguous memory locations. The second phase is called the compaction  phase. 
	
		print "\n".join(["%s:%s" % (k,v) for k,v in gc.__dict__.items()])
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day 196 Friday, December 21, 2012

1. 
	* 大region二期连调
		快照接口：create_snapshot

2. 大region二期连调
	快照接口：
		add_disk,create_snapshot
		创建系统盘快照

		create_image
		mount_snapshot 挂自己的快照，挂用户其他vm的快照
		unmount_snapshot 卸载快照

		retain_snapshot
		rollback_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day197 Monday, December 24, 2012

1. 
	* houyi api连调
	* houyi api返回xml格式时，data标签的问题
		有data时，即使数据为空，标签需要返回；
		若本就没有data数据，不出现data标签
	* 数据库切换功能的支持问题
		rds提供数据库自动切换，需要与应用统一，即应用需要支持数据库动态切换的功能。
			针对API，清楚数据库动态切换需要做什么工作？DNS缓存
	* 数据库查询缓存问题	      * 数据库缓存架构	      查询结果进行缓存 查询缓存		       * ibatis结合memcached * ibatis扩展
		目标：减小数据库load
		对于大数据查询，重复查询等，考虑加一个查询缓存，减小数据库的load
			是否考虑用memcached做统一缓存，这其中涉及memcached集群及HA问题
			or tair系统？
		
		解决方法：
		ibatis提供了CacheController接口，当不满足于内置的缓存实现时，可扩展自定义的缓存实现。
			CacheController接口的设计

		在web服务各层缓存中，本次考虑的缓存为：
			数据库查询缓存

		延伸：
			web服务的各层都可以缓存，最佳实践有哪些？

			再延伸：
				框架或插件，一般都在设计时针对实现会改变的地方会提供扩展的能力，会用和用好是不同的层次，给我感觉是要熟悉你所使用的东西

2. 

Merry Christmas !

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day198 Tuesday, December 25, 2012

1. 
	* 大region二期连调
		detail_snapshot接口snapshot_id的deviceNo检查问题？
			API不检查，给master只有snapshot_id无法检查，master都返回200，只是snapshot_id是否为空的不同。
			API是否需要校验deviceNo来判断snapshot是否存在，或者交给master校验？
	* memcached java客户端gwhalin实现分析
		cosistent hash 一致性哈希
			避免key在服务节点列表上的重新发分布；
			部分算法还实现了虚拟节点，缓存在节点间的分布更加均匀
			tree-map实现，Entry的left，right属性用于在环中定位相邻Entry
				基于Red-Black tree实现
		socket pool
		health check
		server weight
				   
		目标：* 设计
			许多Web 应用程序都将数据保存到RDBMS中，应用服务器从中读取数据并在浏览器中显示。但随着数据量的增大，访问的集中，就会出现REBMS的负担加重，
			数据库响应恶化，网站显示延迟等重大影响。  Memcached是高性能的分布式内存缓存服务器。一般的使用目的是通过缓存数据库查询结果，减少数据库的访问次数，
			以提高动态Web 应用的速度、提高扩展性。
	
	* vm信息收集推送逻辑预整理
		原逻辑实现：master->nc->vm_info_catcher.cpp

2. 连调问题？
	快照ID中deviceNo校验问题，大region遗留问题
	
	影响接口：(需要传入snapshot_id到API)
		mount_snapshot
		unmount_snapshot
		add_disk(传snapshot_id时)
		remove_snapshot
		rollback_snapshot
		cancel_create_snapshot
		retain_snapshot
		create_image

	解决方案：
		1）API传入必要参数给master，master来判断快照是否存在(master自身查询唯一快照的必要参数)，对应API映射到一个错误码即可
		2）API使用快照的接口，查询出快照后，比对deviceNo的一致性，判断快照是否存在
	
	还有一个相关的问题，同时有device_no和snapshot_id时，还需比较deviceNo一致性，涉及接口如下：
		rollback_snapshot
		remove_snapshot  直接将deviceNo给master，没查询快照；若API校验，API自身接口需要变动
		retain_snapshot

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day199 Wednesday, December 26, 2012

1. 
	* 大region二期连调
		- add_disk			  (补单元测试)
			指定snapshot_id
		- detail_snapshot接口API到master接口变动
			增加传入快照的clusterId和所基于的deviceNO，master判断快照是否存在（并新快照不存在的错误码）

			上面修改，API需要兼容新老master的情况

		- 同时传deviceNO,snapshot_id给API的接口，API需要比较2个devieNO是否一致，否则报快照不存在：
			-910, "snapshot id not exists" (master错误码为：-30006,snapshot not exist)

			确认增加上面的校验，不会影响老master（没做兼容处理）
		- 查询快照的逻辑，零散发布，改为统一调用快照service层 待？
			

	* slb api
		去掉alisoft-xplatform-asf-cache.jar，没有使用，也没找到反射的引用
		xmlsec.jar修改，从：
			<dependency>
				<groupId>org.apache</groupId>
				<artifactId>xmlsec</artifactId>
				<version>1.4.3</version>
			</dependency>
		改为：
			<dependency>
				<groupId>org.apache.santuario</groupId>
				<artifactId>xmlsec</artifactId>
				<version>1.4.3</version>
			</dependency>
		houyi api已替换。
	
	* slb api并发性能优化问题
		以list_loadbalancers接口为例
			1）http连接保持，多线程并发

2. mount_iso问题
	running mount_iso (bug),shutted mount_iso
	for fix use
3. 整理deviceNO校验需求变动，更新到设计文档

4. API问题 ？？
	查询快照逻辑，统一接口调用，不应该各处有独立的实现


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day200 Thursday, December 27, 2012

1. 
	* deviceNo校验问题
		影响的接口，单元测试的修改
		连调

	* remove_snapshot接口，判断快照是否能删除问题
		若快照被自定义为image，则不能删除(可先删除image，再去删除快照)
		API的判断快照是否为image逻辑有问题：
			1) snapshot_id在大region内不唯一，会查出其他集群的snapshot
			2) image 可以update的,image.snapshot_id可以upadte,如果之前的 snapshot_id已经在VM上使用了，删除该快照，下次reset_vm会有问题

	* 拉末日曙光项目代码，与大region二期比较，评估合并代码风险	
	* SLB API兼容新老SLB后端问题
		除去本次流量接口修改不兼容，保证其他接口都兼容（master有2个版本）
	* SLB API并发性能问题 待？
		节后分析
		从压测的某些接口入手，找到原因以及优化方案：
			需要：
				压测环境（SLB API + MASTER）开发集成环境
			slb api通过拦截器，记录了请求进来到处理结束的时间差记录，便于分析性能瓶颈
	* master环境切换
		/apsarapangu/disk4/apsara-0.8.6/houyi-bigregion
		sh ../build-deploy-start-houyi.sh
	* houyi api打包名改变，对应提测模板改变，大region二期提测时需注意（若在末日曙光项目提测之后提测则没问题）
	* houyi api空指针问题 -tip-										 ？待修复
		platform数据有问题时，没有判断null
			如：数据库记录了错误的类型值，程序找不到对应的类型。

		程序对于空指针的判断需要处理好，对于存在空指针可能的逻辑都需要做判断，保证程序的健壮性。
	
	* jetty环境熟悉
		配置
		性能

			


2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day201 Friday, December 28, 2012

1. 
	* 大region二期连调，单元测试修改提交
	* 通过vnc登陆到VM
		ip:port
		username
		password

		进入vm检查add_disk
			df -a
			df -k
				显示挂载到的位置
			mount
			fdisk -l

	* 状态同步
		主动同步(显示调用更新状态)
		被动同步（通过消息机制，如MQ）
	* vm磁盘挂载，mount add_disk	    * linux挂载硬盘
		添加磁盘
		找到磁盘
			fdisk -l
		分区
			fidsk /dev/xxx
			n
			w
			...
		格式化
			mkfs -t ext3 /dev/xxx
		创建目录，并挂载上面的分区
			mkdir /disk
			mount /dev/xxx /disk
		验证挂载情况
			df -k
		设置开机自动挂载
			vi /etc/fstab
			/dev/xxx               /disk                 ext3    defaults        0 0
	
	* 大region二期与末日曙光项目合并风险检查
		检出末日曙光代码
		将大region二期代码merger到上面的代码中
		test
		
		测试合并结果，冲突不多
		
		
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day202 Saturday, January 04, 2013

1. 
	大雪，在家办公


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day203 Saturday, January 05, 2013

1. 
	* slb api性能问题
		slb api + slb后端
		针对个别接口，通过slbapi日志分析性能瓶颈
		性能测试方案

	* 看master关于vm监控数据部分逻辑
		source insight
		cpp
		namespace
			class
				

2. slb api集成测试环境	      slb测试环境
	10.250.6.32
	ssh root@10.230.130.1
	go2v2api

3. 缓存框架，缓存系统，缓存模块
	应用自身设计缓存接口，包含各种缓存操作
	根据接口，针对不同的缓存实现提供各自的接口实现

4. 使用image的条件，imageNo+userId+bigRegonNo 唯一
	api
	image工具



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day204 Sunday, January 06, 2013

1. 
	* nc上vm监控数据工具逻辑
		VmWrapper -> VmXenWrapper -> connect to Xen Supervisitor(libvirt库virConnectPtr) -> get info
		通过libvirt API来访问xen hypervistor，libvirt库为统一抽象的虚拟化API，支持多种不同hypervistor，对外提供统一API管理接口
		这样，通过libvirt API对应的python sdk调用即可？
			根据libvirt官网说明：
				Bindings for other languages: Libvirt supports C and C++ directly, and has bindings available for other languages:

				Python: Libvirt comes with direct support for the Python language.
					If your libvirt is installed as packages, rather than compiled by you from source code, ensure you have the appropriate package installed.
					This is named libvirt-python on RHEL/Fedora, python-libvirt on Ubuntu, and may be named differently on others.
				直接支持python，但需要安装 libvirt-python 包(RHEL/Fedora系统上)，当然也提供了其他语言的调用支持。

				For usage information：http://libvirt.org/python.html 使用说明
				There is not much to comment about it, it really is a straight mapping from the C API, the only points to notice are:
					1) the import of the module called libvirt
					2) getting a connection to the hypervisor, in that case using the openReadOnly function allows the code to execute as a normal user.
					3) getting an object representing the Domain 0 using lookupByName
					4) if the domain is not found a libvirtError exception will be raised
					5) extracting and printing some information about the domain using various methods associated to the virDomain class.
			
			libvirt-python包



2. zookeeper
	应用
		命名服务
		集群管理
		配置管理   发布&订阅服务
		共享锁服务
		队列管理

	实践

3. python访问libvirt API
	需要 libvirt-python 包
	例子：
	--------
		import libvirt
		import sys

		conn = libvirt.openReadOnly(None)
		if conn == None:
		    print 'Failed to open connection to the hypervisor'
		    sys.exit(1)

		try:
		    dom0 = conn.lookupByName("Domain-0")
		except:
		    print 'Failed to find the main domain'
		    sys.exit(1)

		print "Domain 0: id %d running %s" % (dom0.ID(), dom0.OSType())
		print dom0.info()
	--------

	安装libvirt-python包，安装时注意选择正确的python版本，可能同时存在多个python版本，需要指定安装位置到要使用的版本上，比如python2.7

	yum install libvirt-python.x86_64 --installroot=/user/xxx
	安装好，对应的python版本即可导入 libvirt
		import libvirt

	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day205 Monday, January 07, 2013

1. 
	* 大region二期上线步骤准备及数据订正脚本
	* python访问libvirt API
	* 周四kickoff MSS改造
		目标：替换agent取监控数据上报所有逻辑
			API只是调用者
			嫦娥系统也需要查询监控数据
		要做的工作
			原业务-永生，祥云

		时间安排
			
		
2. 上线订正脚本
	参考：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/tools/trunk/fix_data/ec_big_region2
	用python实现订正脚本，完成订正过程：
		订正数据  （订正脚本只涉及插入数据/更新数据，表结构修改或增加由DBA执行订正脚本不负责这个）
		验证

	导入已有python库的db封装: pypet库，地址：http://svn.simba.taobao.com/svn/luban/houyiops/pet/trunk/lib/pypet
		from pypet.houyi import db

3. python访问lbivirt API
	正确安装好 libvirt-python 包后
	import libvirt
	参考API说明，编写逻辑

4. 根据API代码规范编写		   改进
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day206 Tuesday, January 08, 2013

1. 
	* 大region二期，数据订正脚本完善，需要review
		发布相关问题，参考：末日曙光项目上线步骤	
		

	* MSS项目kick off文档整理
		时间规划图，visio->项目日程->时间线
		需求整理
		任务整理

	* 原nc agent采集上报monitor，monitor写入库的逻辑分析
	* MSS将VM监控数据推送到OTS可行性分析
		读写性能要求
		查询要求
		OTS文档？
		从OTS存入的数据，是否可以通过OMS获取？

		* OTS Open Table Service

	* 大region二期，sql相关修改整理，需要DBAreview ？ 待
	* 大region二期，上线步骤分析 ，API不重启
		API目前不允许region表的region是不可用，即关闭的；这样调用到关闭的region时会等超时。？待解决
		解决：
			API在根据imageNO找可用region时（ImageService的listRegionsByImageNo方法），排除掉关闭的region再做调度。
		
2. nc采集vm监控数据逻辑分析
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day207 Wednesday, January 09, 2013

1. 
	* 大region二期发布步骤
		API不重启，Master一个个单独发布
		订正脚本放到：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/tools/trunk/fix_data/ec_big_region2/API
		需要注意：
			用到pypet库，具体执行时确认所使用的python的版本已安装此库
				python xxx.py
			有2个订正脚本，一个更新image表：订正所有的image的snapshot_type为1，即都为老hash类型image
				w-image
			另一个插入region_status表

	* MSS重构
		OTS文档说明
		OTS Python SDK
		与PE确认VM监控数据的调用方式&频率：
			万网，portal
		存入OTS的数据，不能从OMS直接读取，如何处理？待
	* 大region二期API代码review
		整理review结果
		处理review结果
			ImageServiceImplTest
			代码修改	 doing
			单元测试修改 doing

2. 大region二期发布步骤
	- API Proxy来拦截小region发布时，对应此region的调用直接返回友好提示；
	- 对于个别错误的跨region调用的情况(vmName所在region是运行的，但操作的其他资源的region已关闭的情况)，	还是会报系统错误，只在少数
	- HouyiAPI在create_vm接口调度region时，在待调度region列表中去掉status=0即状态不可用的region。  （保证create_vm接口允许某个或某些region关闭）
	- 调用Master的接口处，初始化region endpoint时，已保证region状态为可用
		但对于status=0即状态不可用的region直接抛异常不合适，可以细化为region找不到，还是region状态不可用。？待
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day208 Thursday, January 10, 2013

1. 
	* 大region二期review结果处理
		
	* 大region二期，开发测试环境搭建及新老master兼容测试工作		  测试环境
		从QA处借用一个老region，结合开发自用的新region，组成一个集成环境
			regionNo=AT03-HOUYI2
			AG:
				6.27		
				go2houyi1
				go2houyi2		
			
		api配置数据库信息

	* rabbitmp
		6.33
		配置
		启动
	* 下周一 MSS项目kick off
		预定会议室
		人员

2. 新老master兼容测试
	使用image
	使用snpashot

3. create_vm
	原调度region逻辑，在查询region资源时，若发生错误将不会将此region及其zone加入调度；大region二期，加上region状态判断，不可用时直接移出待调度列表。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day209 Friday, January 11, 2013

1. 
	* 发布脚本review处理
	* 大region连调
	* 集群安装，批量部署，批量更新方法 ？待
	* MSS重构与OTS确认性能是否满足？
		


2. 大region连调
	环境：
		2个已升级的region
		大regin二期API
	测试场景：
		VM调度场景
		1) 验证create_vm逻辑调度时排除status=0的region
			修改region表，关闭一个region
			更新缓存 PASS
			create_vm，不指定zone
			观察日志，应该查询到可用的master，不应该去查询status=0的master PASS
			结果应该为创建成功 PASS

		2) region状态从不可用更新为正常后，create_vm会将其加入待调度列表中
			更新region表
			更新缓存
			create_vm，不指定zone
			观察API日志，到master查询此region的资源信息 PASS

		快照使用场景（注意：create_vm时，保证使用本region的image，开发测试环境底层lazyload可能有问题，不影响测试跨region使用snapshot）			
		1) mount_snapshot接口-新region不能挂载其他region的老快照，否则报找不到
			新region，用老image创建vm（对于2个region都升级时，可修改region_status表来强制使用老imge），add_disk（先更新region状态为已升级后）后打一个新快照 (前置条件A)


	问题：
		master开发测试环境，使用远程的image时，lazyload会有问题，先通过使用本地的image方式继续测试
			更新region状态为未升级
			更新缓存
			指定老zone，会使用本地image
		

3. 终端小tip 测试环境
	MySql,API,AG(可临时跳到Nc等其他地方),Master
		go2nc
		go2houyi
		go2xxx

4. python的output/input,file python输入与输出，命令行参数
					
	Command-Line Arguments
		sys.argv is the list of command-line arguments
		len(sys.argv) is the number of command-line arguments(aka argc)
	from: core python programming.2nd,edition

5. 快照类型与image新老没关系 业务
	只有升级前的为老，后面都为新快照。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day210 Monday, January 14, 2013

1. 
	* 大region二期API发布步骤wiki整理				  
	* MSS重构monitor逻辑
		cpp
		vm_xen_wrapper.cpp
			DoGetAllVmInfo方法
				连接hypervisitor；从API获取所有domain的id数组；遍历domId数组并根据id调用API查询domain；若domain存在则再调用API获取其info；
				调用API取得domain的name

	* MSS重构OTS表的设计
	* 大region二期兼容性连调
		环境
			新master打老快照，修改device的状态为old即可

	* 大region二期，API发布不停机方案
		通过转移访问流量的方式，实现API热部署，分析可行性；对于一套API不同版本不能同时提供服务，比如必选参数不一致的情况。
	* 大region二期，开发测试环境，新增一个二期版本的region
		AG=10.250.8.211
		region，region_alias，region_status,zone
		regon_no=atdev (可取与集群名称一致)
		cluster_id=15
		zone_no=cn-qd-aa-a,cn-qd-aa-b
		nuwa=10.250.8.211

2. 大region二期API发布步骤wiki整理
	http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#.E5.9B.9E.E6.BB.9A.E6.96.B9.E6.A1.88
	准备工作：
		修改imge表结构
		创建region_status表，并初始化数据
	发布
		xxx		
	
3. MSS重构OTS表的设计
	查询场景：
		1) 流量计费，如定时任务，查询条件为：
			定时(每隔一小时)查询一个时间段所有记录的部分列(vm流量相关的几个列)，以时间(time_stamp)作为范围条件，并根据name分组
		2) 监控数据，有业务方会定时(3~10min)调用API来获取指定时间点vm的所有监控数据
			- 万网目前为10min取一次(后续可能调整为3min)，取上一个10min对应时间点vm的所有监控数据；
			- portal 是5分钟取一次监控数据，每次取的是前一个5min对应时间点vm产生的所有监控数据。
		查询条件为：
			query_monitor_vms接口：
				查询指定时间点当前用户下所有vm监控数据的记录，并按照某些列进行排序name,cores,mem
			monitor_vm_topn接口：
				查询指定时间点根据TOPn的排序指标排序(参数值可以为：cpu、memory、tx_intranet、rx_intranet、tx_internet、rx_internet、flow、bandwidth)后，位于排序
				前几名的vm的监控数据。
			monitor_vm接口
				查询指定时间点当前用户下某个vm监控数据的记录，并按照某些列进行排序name,cores,mem
		上面的查询，由于有多种排序方式，考虑用OTS的视图来加速查询速度，根据OTS的文档，需要将待排序的列加入主键的列中方可成为视图主键

		结合OTS提供的查询功能，根据其API中的GetRowsByRange，GetRow方法说明，传入对应的主键列进行数据过滤及查询;
		GetRowsByRange调用返回的最大数据量	1MB	一次GetRowsByRange请求如果返回超过1MB的用户数据，OTS会返回错误给应用。如果应用需要读取超过1MB的数据，
		请升级Java/Python SDK的版本改用带NextToken的GetRowsByRange接口分多次读取数据。

		与业务方邮件确定调用方式后，在OTS邮件中确认表设计讨论 ？ 待
	数据分片键：
		time_stamp	不合适，所有VM在某个时间点的数据都在一个数据分片中，达不到分片的目的
		name	建议采用，vmName为字符串varchar(80)，且唯一
		user_id	不合适（目前就几个（2个）用户）
		选择name作为分片键
	主键：
		time_stamp
		name
		user_id
		3个列的联合主键

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day211 Tuesday, January 15, 2013

1. 
	* MSS重构表设计
		如果查询VM监控数据的业务方需要根据region来查询，则表中需要增加region_no/cluster_id字段，以及nc如何获取此字段？
	* API发布脚本，模板化，可定制
		--prepare
			sub task
		--deploy
			sub task
	* 大region二期API发布步骤整理
		
2. 大region二期API发布步骤整理 go on
	二期wiki：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#API.E5.87.86.E5.A4.87.E5.B7.A5.E4.BD.9C	
	参考：http://wiki.ec.alibaba-inc.com/index.php/AY13B%E5%8D%87%E7%BA%A7API/%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F#.E5.8F.91.E5.B8.83.E9.98.B6.E6.AE.B5
	流程：
		1) 发布中心
			取所有需要的包
		2) 准备阶段
			数据订正
				region_status表数据导入
				region表status字段修改（Master后续发布时，API不停，Master停）

		3) 发布阶段
			备份
			部署
		4) 回滚方案
			回滚


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day212 Wednesday, January 16, 2013

1. 
	* 大region二期发布步骤
		增加更新region表status字段的python脚本
			用于master发布前，修改对应region的状态为不可用，master发布完成后修改状态为可用
	* MSS重构
		整理监控参数及其获取方式
	* deploy.py根据之前发布的项目使用
	有svn地址

2. 大region二期发布步骤
	设置maserRegion，reloadCache都通过go2houyiapi来执行

3. fuxi上的http_proxy作为桥梁，解决kuafu不能跨各个小集群访问的问题(kuafu自带了一个http proxy服务接口，只支持同步调用)	     http proxy
	可到fuxi机器查看proxy的状态（me）
4. osgi
	
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day213 Thursday, January 17, 2013

1. 
	* 大region二期提测
		其他项目修改了API的pom，本项目配管打包时找不到包，对应修改pom即可
	* MSS重构
		pync：一个python实现的框架，
			提供服务注册（定时任务注册，注册一个定时器，并配置触发策略）、
				心跳服务
				采集推送服务
			方法调用（master调用nc）
		OTS多机房部署问题确认？
			以及关联到的定时任务多机房部署&安全数据是否多机房部署&OMS是否需要多机房部署
			
			问题源于：
				OTS是否需要多机房部署，如果需要

	* 大region二期API发布步骤
		杭州云配置目录:http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/outer-pro-env
		测试环境配置目录：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/test-env
		双开环境配置目录：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/inner-pro-env
		参考：http://wiki.ec.alibaba-inc.com/index.php/Bugfix11%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF%E6%AD%A5%E9%AA%A4

2. 

3. edit plus开发python的配置
	参考：http://blog.csdn.net/hendyyou/article/details/4694973

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day214 Friday, January 18, 2013

1. 
	* MSS重构
		监控项及其生成逻辑整理
	* fab发布工具 fab 					  * fab
		6.27
		/home/admin/fabdeploy
		svn:
			http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/fabdeploy
		发布工具fab作者：鱼总
		使用步骤：
			source env_profile && fab houyiapi.api_prepare:url=http://xx,md5=xxx
				备份原API部署目录，并拉取待发布的API包并校验MD5值
			source env_profile && fab -H 10.249.243.62 houyiapi.api_stop
				停API
			source env_profile && fab -H 10.249.243.62 houyiapi.api_deploy
				部署新API包
			source env_profile && fab -H xx.xx.xx.xx houyiapi.api_start
				启动API
		
		帮助查看：
			先source env_profile
			然后 fab --list
			Avaliable command:
				apiproxy.first_install  first full install, example: "fab -R [ROLE] apiproxy.first_install"
				apiproxy.proxy_deploy   proxy deploy, example: "fab -R [ROLE] apiproxy.proxy_deploy:branch=[BRANCH],version=[VERSION]"
				apiproxy.proxy_reload   proxy reload, example: "fab -R [ROLE] apiproxy.proxy_reload"
				apiproxy.proxy_start    proxy start, example: "fab -R [ROLE] apiproxy.proxy_start"
				apiproxy.proxy_stop     proxy stop, example: "fab -R [ROLE] apiproxy.proxy_stop"
				apitask.deploy          apitask deploy, example: "fab -R [ROLE] apitask.deploy"
				apitask.prepare         download zip into local, example: "fab apitask.prepare:url=[URL],md5=[MD5]"
				apitask.start           apitask start, example: "fab -R [ROLE] apitask.start"
				apitask.stop            apitask start, example: "fab -R [ROLE] apitask.stop"
				houyiapi.api_deploy     push open.war to houyiapi server, example: "fab -R [ROLE] houyiapi.api_deploy"
				houyiapi.api_prepare    download tar.gz into local, example: "fab houyiapi.api_prepare:url=[URL],md5=[MD5]"
				houyiapi.api_rollback   rollback open.war, example: "fab -R [ROLE] houyiapi.api_rollback:[WAR]"
				houyiapi.api_start      start houyiapi service, example: "fab -R [ROLE] houyiapi.api_start"
				houyiapi.api_stop       stop houyiapi, example: "fab -R [ROLE] houyiapi.api_stop"
		
		prepare的输出如下：
		-------
			--2013-02-27 10:13:21--  http://jenkins.aliyun-inc.com/package/houyi/ec/openapi_trunk-1.0.19.1457720/openapi_trunk-1.0.19.1457720.tar.gz
			正在解析主机 jenkins.aliyun-inc.com... 10.230.226.113
			正在连接 jenkins.aliyun-inc.com|10.230.226.113|:80... 已连接。
			已发出 HTTP 请求，正在等待回应... 200 OK
			长度： 20584872 (20M) [application/x-gzip]
			正在保存至: “openapi_trunk-1.0.19.1457720.tar.gz”

			100%[=================================================================================================>] 20,584,872  11.2M/s   花时 1.8s  

			 
			2013-02-27 10:13:22 (11.2 MB/s) - 已保存 “openapi_trunk-1.0.19.1457720.tar.gz” [20584872/20584872])

			[localhost] local: md5sum openapi_trunk-1.0.19.1457720.tar.gz | awk '{print $1}'
			[localhost] local: mv open.war open.war.20130227101322
			[localhost] local: tar zxf openapi_trunk-1.0.19.1457720.tar.gz
			[localhost] local: mv openapi_trunk-1.0.19.1457720 open.war

			Done. 
		-------
	* 新项目
		工信部数据上报项目，houyi API提供符合要求的VM数据给数据上报中心，由数据上报中心负责将数据给工信部。

2. http chunk
	http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html
	http://www.cnblogs.com/jcli/archive/2012/10/19/2730440.html http协议之Transfer-Encoding及HttpCore实现

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day215 Monday, January 21, 2013

1. 
	* MSS重构暂停，优先上报项目
	* 工信部上报项目，上报数据项整理以及是否需要增加与master的接口分析      doing	
	* 工信部上报项目，拉分支基于1/22/2013号发布的项目 待
	* 工信部上报项目，增加系统维护中状态，对应region关闭状态（涉及调用到关闭region的情况，报状态）
		若需求调整，则时间不定	
	* 工信部上报项目，增加缓存重构需求
		将regionNo对应控制系统地址的缓存重构，使之支持reload缓存接口
	* http chunk (http1.1 protocol) 方式实现接口提供大量数据
	* 与上报中心确认houyi api提供的接口？
		邮件已发出，待确认
	* 需要变的配置，需要从项目部署包中拉出来，发布都是以war包或jar包为单位，不便于修改配置

2. 工信部上报项目，上报数据项整理以及是否需要增加与master的接口分析
	尽快确定houyi api给出的接口是否满足要求？
	评估API取数据对Master的变化需求？

3. 通过socket实现简单的http server与http client来测试http chunked
	
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day216 Tuesday, January 22, 2013

1. 
	* httpclient文档说明，支持chunked
		socket模拟http server，测试chunked

	* 上报中心项目基于
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bandwidth_fix 发布后从trunk啦分支

2. httpclient
	StringEntity entity = new StringEntity("important message",
	"text/plain; charset=\"UTF-8\"");
	entity.setChunked(true);
	HttpPost httppost = new HttpPost("http://localhost/acrtion.do");
	httppost.setEntity(entity);

3. http响应
	一个简单的HTTP响应体：
	"HTTP/1.0 200 OK[\r][\n]"
	"Server: a simple java httpServerContent-type: text/html[\r][\n]"
	"Content-Length: 24[\r][\n]"
	"[\r][\n]"
	"<html>hello world</html>"	

	也可基于servlet来返回chunked响应
		根据maven内置archtype中的java web类型创建maven支持的web project
			创建servlet，配置servlet，访问测试

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day217 Wednesday, January 23, 2013

1. 
	* DCISP数据上报项目新开分支申请
	* DCISP数据上报项目，数据项逻辑整理
		
	* MSS重构
		定时任务，嫦娥等查询VM监控数据都为统计用，数据量打，请求频繁；只有API的查询监控数据接口，是只返回原始数据不做统计，
		这样是否考虑采用RDS或其他支持简单统计功能的存储产品？
	* SLB API聚石塔项目发布 (新搭集群)
		1.24号发布支持， API改动，数据库表初始化及更新(青岛slb master地址改动)
		发布wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9256383
		环境：ssh sarah.wangq@shterm.aliyun-inc.com
	* 大region二期，周五前合并代码，周五再次提测
		API合并代码 merger代码 代码merger
			将trunk上的改动合并到branch上，最好是每一个版本发布改动都及时合如branch
			步骤：
				1）拉后续发布的trunk代码
				2）将trunk上的变化合并到当前branch上
				3）提交合入当前branch的修改到当前branch支上
				
				合入的其他项目的修改，在再次合并到trunk上时会有冲突，这种方式不合适，可基于最新的trunk再开一个分支，
				将本branch的修改合并入此新分支，后续基于此新分支继续开发。
			
			后面，此分支再merger到trunk时，步骤为：
				1）拉trunk最新代码
				2）将当前branch变化merger到上面的trunk上    （对于trunk上已删除的内容？）
				3）提交修改后的trunk代码到trunk上

			从trunk拉个分支，带上当时trunk的reversion，不好？
				根据邮件时间来猜分支基于trunk那个revision拉的，结合比较工具，重新拉下来比较

			方案3，合并时，拉最新的trunk，将当前branch修改合并到trunk上，前提是冲突不多的情况。
2. 

3. 标签 ，tag
	归类内容

4. chunked
	边接收边处理
	对于xml，html服务端如何分解chunk以及客户端如何一个个chunk去处理？
		每个chunk都是一个完整的文档格式，比如xml格式，每个chunk都是标准的xml格式，有头和尾。带来的问题，处理chunk数据ok，但
		所有chunk的汇总数据是格式不可用的。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day218 Thursday, January 24, 2013

1. 
	* 工信部上报IDCISP项目
	* MSS重构项目
	* 大region二期	
	* SLB API聚石塔项目	
	* 线上SLB API的nginx access log中有大量空的日志，分析产生原因？
		100.100.100.2 - - [27/Jun/2012:02:10:52 +0800] "-" 400 0 "-" "-" "-"
	
2. 大region二期
	- 对于API，如果后续有项目对trunk做大量改动，和二期的版本有大量冲突，可以考虑现在基于最新trunk再拉一个分支，
		将二期的修改合入新分支中，后续基于此新分支提交。？

2. MSS重构项目
	- 与OTS分析适用场景，并与RDS讨论是否可用RDS来方便调用方的统计需求（分布式RDS？），与RDS人员评估使用RDS做为存储
	VM监控数据的源是否合适
	- RDS对于大量短连接并发会有压力，需要加个中间层，也不建议每次都查询原始数据来扫描，而是有个数据归并功能，来自动归并数据，便于统计类的查询。
		
	这样若选择OTS，也可以另外起个归并任务来归并数据并再存入OTS中供统计查询用
	
3. 工信部上报IDCISP项目
	- 确认工信部上报IDCISP项目分支
	- 并对已确认需求的进行修改
	- PD确认上报中心与API的需求 今天？
		邮件已确认并增加2个字段nc.hostname,nc.ip，修改好接口文档后，再邮件发出
	- 以http chunked方式提供数据返回接口，只提供json格式，不提供xml格式（涉及xml头和尾的问题）

4. SLB API聚石塔项目
	 -  在线支持 晚11:30
		发布步骤wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9256383
		SLB API 目前管理不同版本的后端，对于表名的修改，在老库上以别名方式来兼容API的修改。

		聚石塔slb后端升级，slb api现管2个后端，另一个不升级，对于表名改动通过别名来兼容。？这里应该是视图，即通过创建视图来兼容来的表名的查询
		注意修改启动脚本，加入java参数：-Dsun.net.inetaddr.ttl=5 -Dsun.net.inetaddr.negative.ttl=5
			由于线上脚本和api svn上的配置有不同的地方，为减小不同点，此处发布可以在发布时修改线上的脚本，在tomcatctl脚本的export JAVA_OPTS="xxxx"内容下增加
			一行：export JAVA_OPTS="$JAVA_OPTS -Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0"

	- API运维wiki整理		
		http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9251044
		相应的简要发布步骤整理

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day219 Friday, January 25, 2013

1. 
	* MSS重构		
		OTS归并 统计需求
	* IDCISP项目
		

	* 提测模板介绍
		项目，脚本，sql变化都有对应的项可填
		项目发布完，通知配管，更新发布信息
		弹性计算-后羿-提测模板介绍 http://wiki.qa.aliyun-inc.com/index.php?title=弹性计算-后羿-提测模板介绍
		
2. MSS重构
	选择OTS作为数据源来存储VM监控数据，对监控数据的查询场景主要有2种：
		一种是根据条件比如vmName，timestamp，返回相应的记录（内容和原始数据基本一致，不需要再做统计，如API的计量查询接口）；
		另一种，是根据小时，或天查询出需要的数据来做统计，比如定时任务，嫦娥。
	对于第一种场景，与OTS同学确认是可以支持的；对第二种场景，由于频繁的查询出大量的数据且只为做统计用，消耗大量OTS和调用者的性能及带宽。
	为此，与大家讨论后建议可以增加一个归并任务，根据业务需要从OTS取出原始数据按小时、或天或更大周期做归并，然后再存回OTS中。这样，对于
	统计类的查询，直接查询归并的数据即可无需几时查询大量数据做统计用。
		根据上面说明，这个归并任务适合由那个角色来担当，即由谁来做这个工作，请大家献策 

3. IDCISP项目
	   邮件确认接口定义 done
	   部分开发工作可以进行
	   接口确认过后，设计与Master的接口定义



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day220 Monday, January 28, 2013

1. 
	* MSS重构
		数据存储到OTS后，houyi定时任务采集回去并整合进安全的数据，	再推送到OMS，OMS在归并推到BOSS；这里也有个归并过程，
		是否和MSS所需的归并连同考虑
	* IDCISP上报项目
		开发，单元测试，jetty容器调试
	* java.net.SocketException: Software caused connection abort: recv failed
		httpclient请求错误
		curl请求ok


2. MSS重构
	确认数据调用方
		houyi任务，嫦娥，houyi api，（boss，portal？）
	从而确认归并的问题

3. IDCISP项目
	GlobalErrorMessage系统对外错误码定义
	CLCErrorCode系统与Master交互内部错误码定义
	通过ErrorMessageUtils将内部错误码映射为对外错误码
		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day221 Tuesday, January 29, 2013

1. 
	* IDCISP上报
	* 大region二期
		
2. IDCISP上报
	测试环境部署，调试
	任务开发
	region查询时，若region没有设置任何属性，则ibatis的动态构造where时将会带入int的默认值0，注意这点。

3. 大region二期
	拉出新分支，将二期的API修改合并入此新分支中，？待

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day222 Wednesday, January 30, 2013

1. 
	* IDCISP项目
		加入user缓存支持reload功能
	* 大region二期

2. IDCISP项目
	开发


3. 大region二期
	- 加入需求，指定imageNo去reset_vm时，保证所使用的image所在的集群为可用状态，尽量保证reset_vm成功  待分析？
		region已升级，使用bucket类型image时，需要判断image所在的region是否可用，若不可用则找本地hash类型image。
	- 将二期修改合入新branch：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bigregion2_base0102upgrade
		并测试基本功能是否ok
		开发测试环境部署（换容器jetty）

		原来apache与jboss通过ajp协议，现在nginx与jetty通过http or what others?	   在httpd.conf中配置			
			1) 暂且直接配置为http方式通讯：
				<IfModule proxy_module>
					ProxyPass /open http://127.0.0.1:8080/open #静态文件的请求不需要转发，由apache直接返回，需要配置DocumentRoot 为程序目录(为防止冲突，建议配虚拟机)
				</IfModule> 
			2) 若需要，也可以配置为ajp方式通讯，主要配置如下：
				加载需要的模块：
					LoadModule proxy_module modules/mod_proxy.so
					LoadModule proxy_ajp_module modules/mod_proxy_ajp.so
					LoadModule proxy_balancer_module modules/mod_proxy_balancer.so
				配置httpd.conf：
					<IfModule proxy_ajp_module>
						ProxyPass open ajp://127.0.0.1:8190/open
						#ProxyPassReverse /open ajp://127.0.0.1:8080/open/api #rewrite if need
					</IfModule>
				确保backend的ajp端口与上面配置的一致（8190）。

4. 

5. URL rewrite URL重写 伪静态页
	apache的rewrite module，jboss，....

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day223 Thursday, January 31, 2013

1. 
	* IDCISP上报
		开发
	* 大region二期
		测试
	* OTS培训
2. IDCISP上报
	idcisp pojo 类 -> instance扩展信息service类 -> Dao类 -> command类 ->IP段等处理工具类 ->  action类 -> spring配置 -> 单元测试


3. OTS培训 pangu	* OTS
	内存写，多份内存数据保证可靠（多份ok，才能成功），不考虑小概率事件
	写比读快
	REDO Log
		全量Data
	Shard

	web portal展示监控数据，以及统计图表展示
	预发环境

	表，视图，需要在开始时创建，可动态加普通列，不能动态加主键列

	分片键设计，均匀分摊到多个分片，减少热点，也利于并发查询。

	倒入大量数据，建议多线程并发，调用者保证每个线程只操作一个分片来加快导入速度
	
	建议大数据表；不建议小表

	架构：
		基于飞天(pangu存储，nuwa命名，fuxi调度,shennong监控)

	与mongodb比较
		内存数据，与disk数据不一致问题

	+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	day224 Friday, February 01, 2013

	1. 
		* IDCISP上报
			2/20/2013号连调
			与Master连调，在开发测试环境临时部署此版本来测试
		* 
	2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day225 Monday, February 04, 2013

1. 
	* IDCISP上报
		
	* 

2. IDCISP上报
	- IP转换
		IP转为long类型 整型
		IP段
	- 返回值对象的设计 设计 返回值设计 return object design * 设计 返回值设计 pojo设计
		既要返回正常情况下的数据流，
		又要返回下层各个调用发生错误时，错误结果的返回、

		这时，需要设计一个综合的结果类，返回对象，来封装正确的数据返回和异常的错误返回，上层根据是否成功来判断结果是数据结果还是异常结果并
		做相应处理即可。

		Result<R>
			code
			isSuccess
			resultData
			...
		
		还有一种方式，通过方法的返回值来封装正确的数据调用返回；通过地址的参数传递方式来获取方法的其他返回信息（比如讲错误信息放到对象参数中返回）。
	- 返回view的设计
		可以在resultdomain中加上一个viewtype属性来标识action需要指向到的result

3. abstract action可以多做些公用的逻辑 建议
	比如使用struts框架时，获取request对象，请求参数等，这些逻辑在一个抽象类里搞定即可，无需再侵入到子类中。	

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day226 Tuesday, February 05, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	20号提测
		自测，与Master连调
	单元测试，自测
		API一些配置信息都移到env.properties文件，且API源码中无此文件，需要在测试环境或其他环境中拷贝一份下来 ，源码中有test.env.properties只是一个测试用的，内容为空？

	service ，action，dao，util工具类单元测试

	zone访问的权限控制？
		user角色

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day227 Wednesday, February 06, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	- API调用计量库部分缓存支持reload，或被动reload
		从而支持动态添加region时，无需重启API
			关闭region时，计量数据查询？
	 - jetty continuation方式增加region状态判断，可在request请求对象的参数中传递信息。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day228 Thursday, February 07, 2013

1. 
	* IDCISP项目	

2. IDCISP项目
	- chunked方式读取测试
	- regionNo到计量库数据源缓存的更新
		新增region时，更新region缓存，调用到计量查询逻辑时，应该触发cache更新操作，可查看日志验证


3. API到Master的通讯
	API-(rpc)-Http Proxy-(kuafu)-Nuwa-(kuafu)-Master-(kuafu)-Nuwa-(kuafu)-cc-...


4. command，要具体执行到那个region，可以将目标regionNo作为Command的属性，这样工具类就可以从这里获取，而无需一层层传递regionNo。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day229 Saturday, February 16, 2013

1. 
	* IDCISP

2. IDCISP
	-
	chunked输出测试，输出时设定等待时间来达到一块块的给	
	httpclient在获取输出流时，以chunked方式来处理
	若输出流为非chunked方式则需要读取到流结束才能解析，由于未说明content-length
	 - continuation方式的region状态判断 参考day227第2条
	VmDetailExecuteAction类的execute方法处独立判断region状态？
	- spring的AOP方法执行拦截，通过suspend注解避免显式的suspend
		<aop:config>
			<aop:pointcut id="continuation"
			<aop:advisor advice-ref="continuationBeforeAdvice"
			...
		Continuation处理步骤	* Continuation	jetty Continuation
		1）Proxy Action处设置当前线程的Continuation对象
		2）进入Action
		3）调用Service方法(方法有Suspend注解且Service类已实现ContinuationListener类)，并处理Advice
			spring配置此注解需要在Service方法执行前执行，以suspend请求及其他操作，如下：
			continuation.addContinuationListener(listener);
			continuation.setTimeout(getTimeout(target));//Service类实现ContinuationTimeoutHolder接口设置
			continuation.suspend();//挂起并等待异步响应事件
				Service类和Listener合并是否合适？易误解
		4）上述Advice处理好后，请求挂起，进入Service方法体逻辑
			处理业务并在完成时调用Continuation的complete方法以通知处理完成
				判断是否完成通过在Continuation中设置键来判断
			Service业务逻辑处理ok后（通过回调实现业务逻辑调用处理），触发Continuation的complete方法
		5）Continuation的complete方法触发后，Service的onComplete方法监听到此事件并处理
			（之前spring AOP的MethodBeforeAdvice类中已经将Service类这个Listener设置到Continuation的监听器属性中）
		6）在onComplete方法中向Response写入返回结果

		确定Continuation方式下判断region状态的方案：
			在ApsaraCommandExecutor2的类中增加判断region状态，并将错误结果放到回调函数的onException方法中，Service中处理回调逻辑时，判断异常的类型，若为CLC异常
			则在Continuation中设置错误结果；然后在onComplete方法中取到此结果输出给用户。
		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day230 Sunday, February 17, 2013

1. 
	* IDCISP
	* MSS

2. IDCISP
	- 在Service逻辑中判断region状态，若为不可用则将错误信息放到Continuation中，在Continuation注册的Listener的onComplete方法中
		返回给用户。	
		每个按照当前Continuation方式实现的Service处都需要判断region的状态。

	- 连调环境确定，确保有环境可用于连调，邮件确认
	- 连调后准备提测
		
	- 开始准备发布步骤
		参考最新项目的发布步骤：（svn log）
			api_bugfix_201212
				双开发布步骤：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%8C%E5%BC%80%E5%8F%91%E5%B8%83%E6%AD%A5%E9%AA%A4
				Bugfix12项目上线步骤：http://wiki.ec.alibaba-inc.com/index.php/Bugfix12%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF%E6%AD%A5%E9%AA%A4
		步骤整理地址：
			http://wiki.ec.alibaba-inc.com/index.php/IDCISP%E6%95%B0%E6%8D%AE%E4%B8%8A%E6%8A%A5%E9%A1%B9%E7%9B%AE



3. MSS
		青岛OTS有计划部署，但北京OTS可能需要到，2012年4,5月的样子，这样，会存在杭州，青岛都是OTS提供监控数据查询，北京还是原有的数据库的方式，这样涉及到查询监控数据的
	调用方（如：houyi api，定时任务，嫦娥等）需要处理北京云的数据源还是老的数据源方式的逻辑。

4. java事务
	本地事务
	分布式事务
		MQ，分布式锁
	http://www.cnblogs.com/CloudTeng/archive/2013/02/16/2913694.html Java事务处理全解析（一）——Java事务处理的基本问题
5. java concurrent包
	与原有的同步方式相比较	
	切入点：memcached java客户端的优化
		http://www.infoq.com/cn/articles/memcached-java
		通过jprofiler分析性能

6. rss的实现

7. java NIO
	
8. struts2的interceptor部分异常问题
	可能导致无log输出·

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day231 Monday, February 18, 2013

1. 
	* IDCISP上线步骤
	* python

2. IDCISP
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day232 Tuesday, February 19, 2013

1. 
	* IDCISP
	* python
	* HouyiAPI增加根据小regionNo和控制系统命令名称来判断调用是否允许

2. IDCISP上线步骤
	
	发布工具+项目发布脚本
	
	发布工具：	
		http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/fabdeploy

	Master的python发布脚本位置：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_controller/
	HouyiAPI的python发布脚本位置：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/

3. HouyiAPI增加根据小regionNo和控制系统命令名称来判断调用是否允许
	若为不允许，则返回维护中状态码
	需求场景：
		飞天升级，涉及region中OSS相关操作将不可用（影响创建快照和lazyload），但其他操作允许以减小影响时间
	控制系统影响到的接口如下：
		CreateSnapshot
		RollbackSnapshot
		MountSnapshot
		ResetVm
	根据上面控制系统影响到的接口整理出影响到的API接口如下：
		create_snapshot
		rollback_snapshot
		mount_snapshot
		reset_vm
	实现方式：
		- PD给出那些region的那些控制系统命令不可调用，HouyiAPI在数据库中维护这个(regionNo,Command名称)关系，表示
		某个小region下某些接口不可用，调用时报维护中状态码
		- region增加升级中这个状态，只有这个状态的调用才去过滤哪些接口不能调（性能考虑）
		- region状态为关闭时，所有接口调用都返回维护中状态码
	配置方式：
		- 升级某个或某几个小region时，若要过滤某些接口不可调用但其他接口可调用，则需要将哪些region的哪些接口不能调用的黑名单记录记录到HouyiAPI
		数据库中，然后调用接口reload对应的cache以生效。；
		- 升级结束，黑名单中的命令可调用时，需要从数据库中去掉这些记录，然后调用接口reload对应的cache以生效。
			
	项目Aone：
		http://aone.alibaba-inc.com/aone2/project/701/portal

	问题确认：PD
		


4. HouyiAPI返回json格式data键的值为null的缺陷 QA记录
	{"code":-95,"data":null,"msg":"invoke houyi system error"}
5. 
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day233 Wednesday, February 20, 2013

1. 
	* IDCISP
		原-100,no small region改为-131
	* 开路先锋项目

2. 开路先锋项目 2.28发布
	- 合并原IDCISP项目中加入维护中状态的代码修改到此新项目中（提前发布）
		（通过svn工具将原来此bugId的修改保存为patch/diff，然后apply patch到新项目中 apply patch；）不推荐
		直接merger branch方便，用patch后续有冲突，merger时使用场景为：
		对一个branch有多个版本的修改，现在需要对这多个版本的修改合并到其他branch上 -tips-
			打patch时注意，若patch生成时所基于的版本与将要apply到的版本不同，即中间不一致则apply时会有冲突，需要手工解决。
				打patch时的版本要与应用patch到的版本一致即可无冲突
					从打patch的原理来理解
			
	- 由于region增加维护中状态，需要调用Master那部分的region缓存可更新，故需要合入调Master缓存支持reload的代码patch
		merger tow different trees
	- 需要屏蔽的控制系统命令根据邮件继续更新

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day234 Thursday, February 21, 2013

1. 
	* 开路先锋项目
	* IDCISP连调时间
		下下周
	* SLB朝阳门项目API设计文档阅读
		
2. 开路先锋项目
	开发+自测
	2.28号发布于前端涅槃项目冲突，暂定在其后面发，具体时间PD先确认涅槃项目发布结束时间点。
	6.33部署测试 部分

list_vm_status接口这样跨多个region查询的情况，有一个在维护中，则返回维护中。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day235 Friday, February 22, 2013

1. 
	* IDCISP
	* 开路先锋
	* 确保开路先锋项目早于IDCISP项目先发布，然后在发IDCISP项目
2. IDCISP项目
	- 去掉已移到开路先锋项目发布的需求
		调用Master部分的cache支持reload
		访问关闭的region时，返回-100维护中错误码
	- 协助连调

3. 开路先锋项目
	- 2.28号发布延迟，安排在前端涅槃项目之后
		2.29周五紧急发布

	- 脚本工具提供
		python
	- 发布
		wiki地址：http://wiki.ec.alibaba-inc.com/index.php/开路先锋项目
		确认将要发布的集群
			所有集群？
			顺序，双开环境飞天已经升级，可排到后面发布，飞天升级到的region，API对应都需要升级。

		 参考：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%8C%E5%8D%87%E9%A1%B9%E7%9B%AE 简单通用API发布步骤
		 线上发布AY32C_AG、双开发布采用AY03NEW_AG

		分内部生产、线上生产。

		数据订正工具：
			svn地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/
				在这里提交工具文件

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day236 Monday, February 25, 2013

1. 
	* 开路先锋
	* IDCISP
2. 开路先锋
	- 集群发布计划
		此计划，PE周五会整理，作为下周发布计划，PM需要在发布前一周整理好
		http://wiki.ec.alibaba-inc.com/index.php/集群发布计划
			发布开始时间，结束时间与PE确认
	- 上线步骤整理
		脚本编写自测
			svn：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20130228trailbreaker
				根据已有的工具所放地址来参考
	- 邮件确认建表语句和SQL
	- 提测（提前自测）
		邮件提测
			
		代码合并，合并到trunk
			修改少且可控可直接合Trunk来测试，否则先Branch，然后合入Thunk回归。
				本次合并入Trunk来测试
	- 发布相关
		周一提测
			提测好后，配管会对应给出出包说明的wiki，build地址：   http://scm.aliyun-inc.com/view/builds/
			发布步骤中的包信息来自配管的wiki
		周一到周三完成脚本
			PE负责reload cache
			脚本负责更新DB
		周四发双开 21:00
		周五发线上 21:00 （此时间点与涅槃项目错开，涅槃项目是否周四发布待确认）
	- 代码Review
		周三 2.27 定会议室
		邮件发布Review申请 待？
	- 数据订正工具
		依赖pypet来访问数据库（MySql）
		在不同集群发布时，需要确认好对应的pypet


3. IDCISP
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day237 Tuesday, February 26, 2013

1. 
	* 开路先锋项目
	* IDCISP项目
	* 大region二期
	* 周五，工作周报

2. 开路先锋项目
	- 脚本工具
		pypet如何切换不同集群的数据库？
			线上集群AG,内部集群AG，各自选取一个AG，在此AG上执行，pypet库保证其连接到正确的houyi库
				选择AY03-NEW-AG作为内部集群发布操作houyi库的AG
				选择AY41A-AG作为线上集群发布操作houyi库的AG
		工具开发及自测
		脚本不允许关闭Region或设置Region在升级中状态，提示Master region不能修改状态，需要切换其他Region为Master region，然后再修改此Region的状态。
			切换Master region的工具？地址

	- 代码Review邮件
	- 实现步骤整理好后
		DBA
			PE将表结构变动及新增通过窗口提交给DBA，作为数据订正工单处理
		PE
		相关人员代码Review
			会议室
		邮件确认

3. IDCISP项目
	- regionNo返回为大regionNo
		修改并提交
	- 去掉已移入开路先锋项目的需求部分代码修改
		houyi.console.service/src/test/java/com/aliyun/houyi/service/support/MasterEndpointCacheManageTest.java	D
		houyi.console.service/src/main/java/com/aliyun/houyi/service/support/MasterEndpointCacheManage.java	D	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day238 Wednesday, February 27, 2013

1. 
	* 开路先锋项目
	* IDCISP项目


2. 开路先锋项目
	- 确认飞天升级延期到3.14，确认涅槃项目在3.28，确认上面的过后，开路先锋项目建议3.4号发布
	- 代码Review
	- 本周四双开
	下周2，线上及其他内部集群

3. IDCISP项目
	提测准备


4. concurrent包，NIO ,Servlet3.0,Comet
	- concurrent包
		-  ReentrantLock
		   A reentrant mutual exclusion Lock with the same basic behavior and semantics as the implicit monitor lock accessed using synchronized methods and statements, but with extended capabilities. 
5. jetty,tomcat
	架构
	使用NIO等的剖析
	tomcat架构：
		ref： http://www.cnblogs.com/tinylittlebunny/archive/2012/08/24/2654705.html
6. java对象的hashcode方法
	与集合类的关系
7. 一致性hash
	解决某些场景下hash重新计算问题

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day239 Thursday, February 28, 2013

1. 
	* 开路先锋项目

2. 开路先锋项目
	19:00发布

3. tomcat ,nio,comet
	结合tomcat源码分析NIO
		Http11NioProtocol

4. nginx做反向代理
	转发规则：轮询
5. jprofiler
	http://yufeimen.iteye.com/blog/70721 利用JProfiler对应用服务器内存泄漏问题诊断一例（转）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day240 Friday, March 01, 2013

1. 
	* 大region二期
	* IDCISP项目
	* 开路先锋

2. IDCISP项目
	提测 时间点定于开路先锋线上发布过后，避免冲突
		用户缓存支持reload

3. 大region二期
	上线步骤整理：
		http://wiki.ec.alibaba-inc.com/index.php/Bigregion2%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#.E5.8D.87.E7.BA.A7.E6.80.BB.E4.BD.93.E6.80.9D.E8.B7.AF

4. 开路先锋
	设置region状态和黑名单的工具，在关闭Master Region时不是强制不允许关闭，而是给出警告，并提示是否继续操作。