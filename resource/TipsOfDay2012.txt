*
本机ip 10.1.171.132
-tip-
-idea-
通过svn管理记录文件 eg google code  TortoiseSVN
搭建centos测试系统(vmware7) ssh连接
wiki scheng 
Linux Container - LXC	
openapi rds  (关系型数据库服务)
	ref: http://www.ibm.com/developerworks/linux/library/l-lxc-containers/
test
	https://my-javaweb-project-demo.googlecode.com/svn
google 检索 apache： site:*.apache.org 高级搜索
	site:cnblogs.com 工厂
multi-boxing hotkeynet 
	http://kittykittyboomboom.wordpress.com/2012/01/04/basic-guide-to-multi-boxing-world-of-warcraft/
	octopus http://www.ownedcore.com/forums/world-of-warcraft/world-of-warcraft-guides/249823-multiboxing-guide-1-pc-5-accounts.html
tmp
ft2013-04-22
* 佳丽摄影

* 6843 ft75
* What Are the Differences Between ISO and IMG Files?

	The Facts
	ISO and IMG are both archival formats. Each file contains a copy of the contents of the original disc the archive was made from, plus information about the file structure of the disc. 
	They are designed to make archiving the disc easier and make creating an exact duplicate copy easier. However, while there is only one version of the ISO format, IMG comes in two versions: 
	compressed and uncompressed.
	from: http://www.ehow.com/info_8075301_differences-between-iso-img-files.html



Read more: http://www.ehow.com/info_8075301_differences-between-iso-img-files.html#ixzz2aWDD6SsV
* div+css
	1) li 左右分开对其
	-----
	<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
	<HTML>
	 <HEAD>
	 </HEAD>
	 <BODY>
	<style>
	#list li { text-align: left; }
	#list span { float: right; }
	#list a { float: right; }
	</style>
	<ul id="list">
		<li>4-8<span>&nbsp;&nbsp;123&nbsp;&nbsp; </span><a href="list.asp">111111111111111</a></li>
		<li>4-9<span>&nbsp;&nbsp;321&nbsp;&nbsp;</span><a href="list.asp">222222222222222</a></li>
	</ul>
	 </BODY>
	</HTML>
	-----
* 幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。
	幂等有以下几种定义：
	对于单目运算/函数，如果一个运算/函数对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算/函数是幂等的。比如绝对值运算就是一个例子，在实数集中，有abs(a)=abs(abs(a))，[1]
* 云端存储 文件同步
	SkyDrive

* openstack
	
* SSO Single Sigh On 单点登录
	- 异构系统单点登录 SSO（single-sign-on）技术
		-----
		在 QQ 已经登录的情况下，手动输入网址打开 QQ 邮箱 或者 QQ 空间 等腾讯网站，可以看到网页已经检测到本地 QQ 客户端已经登录，于是用户可以很方便
		地一键登录网站而不必再输入用户名密码。这实际上是典型的异构系统单点登录 SSO（single-sign-on）技术

		有这么一个神奇的链接，http://xui.ptlogin2.qq.com/cgi-bin/qlogin 你一点开，它就检测到你登录了 QQ。通过查看页面源代码，我们可以发现一个关于 ptlogin 的 js 文件，
		这段代码中，描述了使用 ActivexObject 浏览器插件的过程，于是一切了然。

		可是 ActiveX 是 IE 的插件呀，我们使用 Chrome 或者 FireFox 也是可以直接登录的，这是怎么回事呢？

		原来，QQ 使用了历史很悠久的 NPAPI（Netscape Plugin Application Programming Interface）接口。NPAPI 几乎支持所有主流浏览器，包括 FireFox、Chrome、Opera（
		IE 从 5.5 后停止支持 NPAPI，转而使用 ActiveX）。

		打开 chrome://plugins/ 我们可以发现自动登录的有关插件，而在路径 C:\Program Files (x86)\Common Files\Tencent\TXSSO 下就可以找到关于 SSO 的相关动态链接库。

		Tencent_SSO_plugin

		np 插件一般命名都会加np前缀 如 QQ 的这个 npSSOAxCtrlForPTLogin.dll，只要按照标准的写法，放在浏览器会加载的地方，用的时候写个标签就可以在 js 里面调用了。
		于是跨浏览器（无视 IE）的插件开发变得相当可行。运行在 NPAPI 插件中的代码拥有当前用户的所有权限，不在沙箱中运行，所以它的扩展程序在被 Chrome 网上
		应用店接受前要求人工审核。
		-----
		ref: http://www.lovelucy.info/tencent-sso.html

	- 单点登录系统的原理思考
	-----

	单点登录系统的原理思考  
      	引子
	昨天在网上看到一个帖子，帖子的内容大概是说领导要求一个苦B程序员实现一个单点登录的系统，将各个业务系统联系起来，但不能修改其他业务系统的源码。
	其实，在企业信息化过程中，通常有多个应用系统，每个应用系统中，有独立用户管理模块，用来保存每个用户对应的账号，权限等信息，为了减少每个人登录系统时，
	记忆密码的麻烦，经常会用到单点登录功能。
	我们公司用的就是CAS单点登录系统，我们抛开CAS这种成熟的单点登录系统，从头开始思考和设计一下单点登录如何实现。


	需求简述
	单点登录系统保存了用户的登录名和密码，上网用户在单点登录系统中认证成功后，就可以直接登录各个业务系统。
	这个需求看似简单，但实际暗藏玄机：
	1). 用户访问任何一个业务系统时，如果已经在单点登录服务器中认证成功，那么可以获取对应的权限，访问对应的界面。
	2). 用户如果在其中任何一个业务系统中点击“注销”按钮后，那么不能继续访问其他业务系统，如果访问，必须重新登录
	3). 用户访问任何一个业务系统时，如果尚未在单点登录服务器中认证成功，那么需要跳转到单点登录界面，输入用户名密码，校验成功后，再回到原来的访问界面
	4). 用户关闭浏览器后，再次打开，不能继续访问其他业务系统


	实现方案
	根据上述需求，我们可以考虑出很多套实现方案，这些方案各有优缺点，根据各个方案的比较，选出实现最简单、功能最完善、性能最优化的方案，作为最终的实现方案。

	我们知道用户点击业务系统中的各个连接，访问业务系统时，可能存在以下场景
	场景1：用户尚未在单点登录系统中完成登录，此时单点登录系统没有当前用户的在线信息
	场景2：用户已经在单点登录系统中完成登录，但尚未在当前业务系统中完成登录，当前业务系统中没有此用户的在线信息
	场景3：用户已经在单点登录系统中完成登录，并且也在当前业务系统中完成登录
	场景4：用户已经在单点登录系统中注销，但在当前业务系统中尚未注销

	对于场景1，此时业务系统应该拦截用户的访问请求，并且将用户重定向到单点登录系统中，当用户在单点登录系统中完成登录后，再在当前业务系统中执行用户登录的操作，
	再重定向到用户上次访问的界面，让用户能够正常访问业务系统
	对于场景2，此时业务系统应该拦截用户的访问请求，并且与单点登录系统通信，获取当前用户的在线状态后，在当前业务系统中执行登录操作，再向用户返回上次请求的结果
	界面，让用户能够正确访问业务系统
	对于场景3，此时业务系统应该拦截用户的访问请求，并且与单点登录系统通信，校验用户是否在线，再向用户返回上次请求的结果界面，让用户能够正确访问业务系统
	对于场景4，此时业务系统应该拦截用户的访问请求，并且与单点登录系统通信，校验用户是否在线，因为此时用户已下线，所以在当前业务系统中完成注销操作，并且将用户
	跳转到单点登录的登录界面，后续处理与情况1一致。

	方案一

	    方案描述

	    1). 用户访问业务系统时，业务系统可以根据HTTP请求的源IP，去单点登录系统中查询
		1). 如果此IP对应的用户尚未认证，跳转到单点登录系统的登录界面，要求输入用户名和密码进行认证
		2). 如果此IP对应的用户已经认证，业务系统认为此用户登录成功，允许其继续访问业务系统
	    2). 在单点登录系统的登录界面或后台session中，需要保存用户上次访问的URL，以便于用户认证成功后，能够再次回到上次访问的界面
	    3). 用户在单点登录系统的登录界面输入用户名密码登录成功后，单点登录系统记录此用户的身份以及对应的IP地址，再将浏览器重定向到上次访问的URL中，这样就回到了步骤1，
	    此时用户已经认证成功，可以访问业务系统。
	    4). 用户在任意业务系统中单击注销按钮时，业务系统完成系统自身的注销操作后，将界面重定向到单点登录系统的注销URL中，并自动在单点登录系统中注销用户信息

	    优点

	    1). 只要浏览器支持基本的重定向功能，就可以按照本方案实现

	    缺点

	    1). 要实现上述需求，需要修改业务系统的代码，对于.net和java编写的业务系统，需要两套不同的代码

	    安全性

	    1). 根据用户的IP地址进行用户身份的判定，会带来以下安全问题：

		1). 如果用户IP修改后，需要重新认证才能继续访问业务系统

		2). 如果用户恶意仿冒领导的IP地址，那么可以越权访问自己没有权限的业务系统
		3). 在公共的PC中，前一个用户关闭浏览器，没有点击注销按钮，那么后续使用这台PC的所有人，都可以直接使用前一个人的账号访问业务系统

	    性能

	    每次访问业务系统的任何一个URL，都需要与单点登录系统联动，如果用户量很大，单点登录系统会成为瓶颈


	方案二

	    方案描述

	    1). 用户使用单点登录系统的登录界面，输入用户名和密码登录成功后，单点登录系统为用户浏览器安装一个cookie，cookie的值是一个全局唯一的字符串（下文称为ticket），
	    理论上这个唯一值永远不能重复，用来标识用户的一次成功的登录请求。同一个用户，在同一个时刻登录两次，得到的ticket值应该完全不同。

	    2. 用户访问业务系统时，如果当前用户尚未在业务系统中登录，就将界面重定向到单点登录系统中，这时访问的URL前缀是单点登录系统的前缀

		1).如果用户已经在单点登录系统中完成登录，那么此时用户访问单点登录URL时，就会带上步骤1中的ticket，单点登录系统识别出此ticket，知道当前用户已经认证过，
		将用户界面再次跳转到业务系统中，并且携带上述ticket，业务系统也将此ticket安装到cookie中，后续对于此业务系统的所有访问，都直接根据ticket去单点登录系统中查询
		用户是否在线就可以了

		2).如果用户尚未在单点登录系统中完成登录，那么此时用户访问单点登录URL时，无法携带上步骤1中的ticket，单点登录系统为展示登录界面，用户输入用户名和密码
		登录成功后，将用户界面再次跳转到业务系统中，并且携带上述ticket，业务系统也将此ticket安装到cookie中，后续对于此业务系统的所有访问，都直接根据ticket去单点
		登录系统中查询用户是否在线就可以了

	    3). 用户访问业务系统时，如果当前用户已经在业务系统中登录，那么访问业务系统的cookie中，会携带单点登录ticket，业务系统根据此ticket，去单点登录系统中查询用户
	    是否已经在线，如果已经在线，就允许继续访问，否则就执行注销操作

	    4). 用户在任意一个业务系统中执行注销操作时，业务系统在拦截注销操作，并且与单点登录系统联动，在单点登录系统中完成注销后，再跳转回业务系统的注销界面

	    优点

	    1). 单点登录系统的整套拦截和转发流程，可以封装成为公共组件，只需少许修改业务系统代码

	    2). 所有业务系统都可以使用上述方案增加与单点登录系统的联动功能

	    缺点

	    上述单点登录功能，依赖浏览器的cookie功能，如果浏览器不支持cookie，将无法使用

	    安全性

	    1). 用户恶意仿冒他人IP，也无法获取对应业务系统的访问权限，安全性比方案一高

	    2). 恶意用户拦截HTTP请求，获取cookie中进行仿冒，同样可以获取他人对于业务系统的访问权限

	    性能

	    当业务系统很多、上网用户很多时，每次访问业务系统的任何一个链接，都需要与单点登录系统联动，查询用户是否在线，单点登录系统可能成为瓶颈 


	方案比较
	上述方案，都需要对于现有系统进行一些修改，但方案二的安全性相对较高
	方案二中提到的安全性问题，可以通过定期更新ticket值，或每次访问都生成不同的ticket值来进行规避。
	上述方案，因为涉及对于单点登录系统的大量访问，所以会使得单点登录系统成为瓶颈，可以采用如下方案在安全性不降低很多的情况下规避性能问题：
	方案一：业务系统记录上次与单点登录系统联动，获取用户状态的时间，并且n分钟内，所有用户对于业务系统的情况，都不和单点登录系统联动
	方案二：业务系统和单点登录系统之间采用性能更高的网络协议，例如UDP协议进行在线状态的交互，按照现有经验，因为UDP报文头部较小，报文有效内容比例大，
	同时报文长度短，比现有的HTTP协议性能可以提高1～2个数量级，每秒支撑1000次查询请求，是没有问题的。


	总结
	上述方案二，是借鉴CAS单点登录系统的实现进行描述的。
	对于第一章节提到的那种对于现有业务系统不进行任何修改的方
	-----
	PS: http://blog.163.com/among_1985/blog/static/27500523201262683541321/
	落日弓SSO基于公用的第二种方案实现，有心跳检测

	
* CDN Content Delivery Network 内容分发网络
	原理：

	例子：
		Amazon的CloudFront
* cname
	CNAME指别名记录也被称为规范名字。这种记录允许您将多个名字映射到同一台计算机。 通常用于同时提供WWW和MAIL服务的计算机。
	例如，有一台计算机名为“host.mydomain.com”（A记录）。 它同时提供WWW和MAIL服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：
	WWW和MAIL。 这两个别名的全称就是“www.mydomain.com”和“mail.mydomain.com”。实际上他们都指向“host.mydomain.com”。

	在linux上使用BIND建立DNS服务器

* 集群监控
	Ganglia
* personal web
	dynamic DNS resolve动态域名解析服务（Dynamic Domain Name Server）
		花生壳等（每次动态公网IP发生变化时，将新的IP更新到动态域名解析服务商的数据库中，这样每次域名都指向到新的IP）
		http://www.pubyun.com/
	虚拟服务器，DMZ主机（开放所有端口，不建议）

* webkit
	WebKit 是一个开源的浏览器引擎，与之相对应的引擎有Gecko（Mozilla Firefox 等使用）和Trident（也称MSHTML，IE 使用）。同时WebKit 也是苹果Mac OS X 系统引擎
	框架版本的名称，主要用于Safari，Dashboard，Mail 和其他一些Mac OS X 程序。WebKit 前身是 KDE 小组的 KHTML，WebKit 所包含的 WebCore 排版引擎和 JSCore 引擎
	来自于 KDE 的 KHTML 和 KJS，当年苹果比较了 Gecko 和 KHTML 后，仍然选择了后者，就因为它拥有清晰的源码结构、极快的渲染速度。Apple将 KHTML 发扬光大，
	推出了装备 KHTML 改进型 WebKit 引擎的浏览器 Safari。
	ref: http://baike.baidu.com/view/1510583.htm

* java java基本数据类型和byte[] 之间的转换   类型转换 字节到long long到字节
	----
	/**
	 * 字节与Java基本类型的相互转换 
	 */
	public class DataChange {
		/**
		 * @param args
		 */
		public static void main(String[] args) {
			int testTime = 100;// 测试次数

			short sValue = 256;
			int iValue = -99999;
			long lValue = -99999;
			double dValue = -99999999999.99999999d;
			float fValue = -9999999999.9999f;

			outPut(shortToByte(sValue));
			try {

				System.out.println(byteToShort(shortToByte(sValue)));
			} catch (DataTranslateException e1) {
				e1.printStackTrace();
			}

			outPut(intToByte(iValue));
			try {
				System.out.println(byteToInt(intToByte(iValue)));
			} catch (DataTranslateException e) {
				e.printStackTrace();
			}

			outPut(longToByte(lValue));
			try {
				System.out.println(byteToLong(longToByte(lValue)));
			} catch (DataTranslateException e) {
				e.printStackTrace();
			}

			outPut(doubleToByte(dValue));
			try {
				System.out.println(byteToDouble(doubleToByte(dValue)));
			} catch (DataTranslateException e) {
				e.printStackTrace();
			}

			outPut(floatToByte(fValue));
			try {
				System.out.println(byteToFloat(floatToByte(fValue)));
			} catch (DataTranslateException e) {
				e.printStackTrace();
			}

		}

		private static void outPut(byte[] bytes) {
			System.out.println(new String(bytes));
		}

		/**
		 * short转换到字节数组
		 * 
		 * @param number
		 * @return
		 */
		public static byte[] shortToByte(short number) {
			byte[] b = new byte[2];
			for (int i = 1; i >= 0; i--) {
				b[i] = (byte) (number % 256);
				number >>= 8;
			}
			byte bb = (byte) 12922;

			return b;
		}

		/**
		 * 字节到short转换
		 * 
		 * @param b
		 * @return
		 * @throws DataTranslateException
		 */
		public static short byteToShort(byte[] b) throws DataTranslateException {
			if (b.length != 2)
				throw new DataTranslateException();

			return (short) ((((b[0] & 0xff) << 8) | b[1] & 0xff));
		}

		/**
		 * 整型转换到字节数组
		 * 
		 * @param number
		 * @return
		 */
		public static byte[] intToByte(int number) {
			byte[] b = new byte[4];
			for (int i = 3; i >= 0; i--) {
				b[i] = (byte) (number % 256);
				number >>= 8;
			}
			return b;
		}

		/**
		 * 字节数组到整型转换
		 * 
		 * @param b
		 * @return
		 * @throws DataTranslateException
		 */
		public static int byteToInt(byte[] b) throws DataTranslateException {
			if (b.length != 4)
				throw new DataTranslateException();
			return (int) ((((b[0] & 0xff) << 24) | ((b[1] & 0xff) << 16)
					| ((b[2] & 0xff) << 8) | ((b[3] & 0xff) << 0)));
		}

		/**
		 * long转换到字节数组
		 * 
		 * @param number
		 * @return
		 */
		public static byte[] longToByte(long number) {
			byte[] b = new byte[8];
			for (int i = 7; i >= 0; i--) {
				b[i] = (byte) (number % 256);
				number >>= 8;
			}
			return b;
		}

		/**
		 * 字节数组到整型的转换
		 * 
		 * @param b
		 * @return
		 * @throws DataTranslateException
		 */
		public static long byteToLong(byte[] b) throws DataTranslateException {
			if (b.length != 8)
				throw new DataTranslateException();
			return ((((long) b[0] & 0xff) << 56) | (((long) b[1] & 0xff) << 48)
					| (((long) b[2] & 0xff) << 40) | (((long) b[3] & 0xff) << 32)
					| (((long) b[4] & 0xff) << 24) | (((long) b[5] & 0xff) << 16)
					| (((long) b[6] & 0xff) << 8) | (((long) b[7] & 0xff) << 0));
		}

		/**
		 * double转换到字节数组
		 * 
		 * @param d
		 * @return
		 */
		public static byte[] doubleToByte(double d) {

			byte[] bytes = new byte[8];
			long l = Double.doubleToLongBits(d);
			for (int i = 0; i < bytes.length; i++) {
				bytes[i] = new Long(l).byteValue();
				l = l >> 8;
			}
			return bytes;
		}

		/**
		 * 字节数组到double转换
		 * 
		 * @param b
		 * @return
		 * @throws DataTranslateException
		 */
		public static double byteToDouble(byte[] b) throws DataTranslateException {
			if (b.length != 8)
				throw new DataTranslateException();
			long l;
			l = b[0];
			l &= 0xff;
			l |= ((long) b[1] << 8);
			l &= 0xffff;
			l |= ((long) b[2] << 16);
			l &= 0xffffff;
			l |= ((long) b[3] << 24);
			l &= 0xffffffffl;
			l |= ((long) b[4] << 32);
			l &= 0xffffffffffl;

			l |= ((long) b[5] << 40);
			l &= 0xffffffffffffl;
			l |= ((long) b[6] << 48);
			l &= 0xffffffffffffffl;

			l |= ((long) b[7] << 56);

			return Double.longBitsToDouble(l);
		}

		/**
		 * float转换到字节数组
		 * 
		 * @param d
		 * @return
		 */
		public static byte[] floatToByte(float d) {

			byte[] bytes = new byte[4];
			int l = Float.floatToIntBits(d);
			for (int i = 0; i < bytes.length; i++) {
				bytes[i] = new Integer(l).byteValue();
				l = l >> 8;
			}
			return bytes;
		}

		/**
		 * 字节数组到float的转换
		 * 
		 * @param b
		 * @return
		 * @throws DataTranslateException
		 */
		public static float byteToFloat(byte[] b) throws DataTranslateException {
			if (b.length != 4)
				throw new DataTranslateException();
			int l;
			l = b[0];
			l &= 0xff;
			l |= ((long) b[1] << 8);
			l &= 0xffff;
			l |= ((long) b[2] << 16);
			l &= 0xffffff;
			l |= ((long) b[3] << 24);
			l &= 0xffffffffl;
			return Float.intBitsToFloat(l);
		}

		/**
		 * 字符串到字节数组转换
		 * 
		 * @param s
		 * @return
		 */
		public static byte[] stringToByte(String s) {
			return s.getBytes();
		}

		/**
		 * 字节数组带字符串的转换
		 * 
		 * @param b
		 * @return
		 */
		public static String byteToString(byte[] b) {
			return new String(b);

		}
	}

	class DataTranslateException extends Exception {
		/**
		 * 数据转换异常
		 */
		private static final long serialVersionUID = -1549549583129122004L;

	}
	----
	ref: http://hi.baidu.com/wangkaijiangg/item/d3d825dfd36081f492a97406
* MD5
	MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。
	将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4。

	MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被"压缩"成一种保密的格式（就是把一个任意长度的字节串变换成一定长的十六进制数字串）。
	除了MD5以外，其中比较有名的还有sha-1、RIPEMD以及Haval等

	MD5将任意长度的“字节串”映射为一个128bit的大整数，并且是通过该128bit反推原始字符串是困难的，换句话说就是，即使你看到源程序和算法描述，也无法将一个MD5的值变换回原始的字符串，从数学原理上说，是因为原始的字符串有无穷多个，这有点象不存在反函数的数学函数。所以，要遇到了md5密码的问题，比较好的办法是：你可以用这个系统中的md5（）函数重新设一个密码，如admin，把生成的一串密码的Hash值覆盖原来的Hash值就行了。

	ref: http://baike.baidu.com/view/7636.htm
	PS: 
		把一个任意长度的字节串变换成一定长的十六进制数字串，128Bit的大整数

		后面涉及到将128Bit字节数组转为long类型。MD5

* 算法
	排序算法
		快速排序
		冒泡排序
		插入排序

	查找算法
		二分查找（binary search algorithm）
		java.util.Arrays类提供了支持Binary Search的静态方法（需要待查找数组为升序排列的数组）

* 个人站点 站长 草根站长 技术站点 	      -tip-
	专业，全面的java代码分享站 http://www.javaniu.com/
	系统架构分析 http://www.sudone.com/	   友情链接到多个牛站哦~
	开源中国社区
* IM
	- 服务器端编程
	 如openfire spark
		openfire为服务端，spark为客户端，C/S架构，服务端提供了web管理支持，jetty容器启动
	Openfire: openfire/trunk	http://fisheye.igniterealtime.org/browse/openfire/trunk
	Spark: spark/trunk	http://fisheye.igniterealtime.org/browse/spark/trunk
	SparkWeb: sparkweb/trunk	http://fisheye.igniterealtime.org/browse/sparkweb/trunk

* 线程状态 对象锁
	------
	线程在一定条件下，状态会发生变化。线程变化的状态转换图如下：
	　　1) 新建状态(New)：新创建了一个线程对象。
	　　2) 就绪状态(Runnable)：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。
	　　3) 运行状态(Running)：就绪状态的线程获取了CPU，执行程序代码。
	　　4) 阻塞状态(Blocked)：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：
	　　(一)、等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。
	　　(二)、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
	　　(三)、其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、
	或者I/O处理完毕时，线程重新转入就绪状态。
	　　5) 死亡状态(Dead)：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。
		状态图：

	小小的作下解释： 
	1) 线程的实现有两种方式，一是继承Thread类，二是实现Runnable接口，但不管怎样，当我们new了这个对象后，线程就进入了初始状态； 
	2) 当该对象调用了start()方法，就进入可运行状态； 
	3) 进入可运行状态后，当该对象被操作系统选中，获得CPU时间片就会进入运行状态； 
	4) 进入运行状态后情况就比较复杂了 
		4.1) run()方法或main()方法结束后，线程就进入终止状态； 
		4.2) 当线程调用了自身的sleep()方法或其他线程的join()方法，就会进入阻塞状态（该状态既停止当前线程，但并不释放所占有的资源）。当sleep()结束或join()结束后，
		该线程进入可运行状态，继续等待OS分配时间片； 
		4.3) 线程调用了yield()方法，意思是放弃当前获得的CPU时间片，回到可运行状态，这时与其他进程处于同等竞争状态，OS有可能会接着又让这个进程进入运行状态； 
		4.4) 当线程刚进入可运行状态（注意，还没运行），发现将要调用的资源被synchroniza（同步），获取不到锁标记，将会立即进入锁池状态，等待获取锁标记（这时的锁池里
		也许已经有了其他线程在等待获取锁标记，这时它们处于队列状态，既先到先得），一旦线程获得锁标记后，就转入可运行状态，等待OS分配CPU时间片； 
		4.5) 当线程调用wait()方法后会进入等待队列（进入这个状态会释放所占有的所有资源，与阻塞状态不同），进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()
		或notifyAll()方法才能被唤醒（由于notify()只是唤醒一个线程，但我们由不能确定具体唤醒的是哪一个线程，也许我们需要唤醒的线程不能够被唤醒，因此在实际使用时，一般都用
		notifyAll()方法，唤醒有所线程），线程被唤醒后会进入锁池，等待获取锁标记。 
	------
	from: http://hi.baidu.com/guessa/item/a50014c95b17d30fad092f93

* Reactor：构建JVM异步应用的基础框架
　　Spring 社区今天推出了一个名为 Reactor 的基础框架，主要用于帮助开发者创建基于 JVM 的异步应用程序。该框架提供了 Java、Groovy 等 JVM 语言的抽象，
	使得开发者构建事件/数据驱动的应用程序更加容易。 

* CRC32 * CRC-32(Cyclic redundancy check)	循环冗余校验
	- http://www.52rd.com/Blog/Detail_RD.Blog_zx_zx_13124.html
	- 
		ref: http://en.wikipedia.org/wiki/Cyclic_redundancy_check
	- 循环冗余校验 CRC的算法分析和程序实现
		通信的目的是要把信息及时可靠地传送给对方，因此要求一个通信系统传输消息必须可靠与快速，在数字通信系统中可靠与快速往往是一对矛盾。为了解决可靠性，
		通信系统都采用了差错控制。本文详细介绍了循环冗余校验CRC（Cyclic Redundancy Check）的差错控制原理及其算法实现。

		关键字：通信 循环冗余校验  CRC-32  CRC-16  CRC-4



	from: http://www.cnblogs.com/Qia_sky/archive/2005/03/07/114493.html
	
* java基本数据类型所占字节，unicode编码
	byte  1个字节（8个bit）
	short 2个字节
	char  2个字节
	int   4个字节
	long  8个字节
	float 4个字节
	double 8个字节
* 不只是为求一份工作而读书
	Hard learing not just for a job!
* 强烈的求知欲
* linux pipe 管道
	 Pipes
	The common Linux shells all allow redirection. For example
	$ ls | pr | lpr
	pipes the output from the ls command listing the directory's files into the standard input of the pr command which paginates them. Finally the standard output from the 
	pr command is piped into the standard input of the lpr command which prints the results on the default printer. Pipes then are unidirectional byte streams which 
	connect the standard output from one process into the standard input of another process. Neither process is aware of this redirection and behaves just as it would 
	normally. It is the shell which sets up these temporary pipes between the processes.


* IPC Mechanisms (Inter-Process Communication Mechanisms) 进程间通信机制 MQ消息 rabbitmq客户端jar实现用到此机制
	- Explain difference between IPC mechanisms? 各种IPC机制类型的区别
		----------
		ipc mechanisms are mianly 5 types

		1) pipes:it is related data only send from one pipe output is giving to another pipe input to share resouses pipe are used
			drawback:itis only related process only communicated
		2) message queues:message queues are un related process are also communicate with message queues
			drawback:user dont know which process curently works
		3) share memory:memory shared in distributed systems some memory wants to share some files that time it is use full
		4) semaphores
		semaphore is integer type and in semaphore resourses give coding like negetive value means process are wants to use perticular resource waiting only
		and 0 means no process is waiting
		and 1 means one resource is free

		and

		5) sockets:sockets also ipc it is comunicate clients and server
		with socket system calls connection oriented and connection less also
		---------- 另一个解释版本，相互补充
		PIPE: Only two related (eg: parent & child) processess can be communicated. Data reading would be first in first out manner.

		Named PIPE or FIFO : Only two processes (can be related or unrelated) can communicate. Data read from FIFO is first in first out manner.

		Message Queues: Any number of processes can read/write from/to the queue.  Data can be read selectively. (need not be in FIFO manner)

		Shared Memory:  Part of process's memory is shared to other processes. other processes can read or write into this shared memory area based on the permissions. 
			Accessing Shared memory is faster than any other IPC mechanism as this does not involve any kernel level switching(Shared memory resides on user memory area).

		Semaphore: Semaphores are used for process synchronisation. This can't be used for bulk data transfer between processes. 
		PS: java的concurrent包的java.util.concurrent.locks.AbstractQueuedSynchronizer提供实现此机制的支持

		----------
		from: http://www.geekinterview.com/question_details/20720

	- MQ的实现，涉及到IPC Mechanisms实现类型中的Message Queue，通过消息队列实现

	- linux系统中提供IPC mechanism支持的方式
		Processes communicate with each other and with the kernel to coordinate their activities. Linux supports a number of Inter-Process Communication (IPC) mechanisms. 
		Signals and pipes are two of them but Linux also supports the System V IPC mechanisms named after the Unix TM release in which they first appeared.
		ref: http://tldp.org/LDP/tlk/ipc/ipc.html Interprocess Communication Mechanisms

* 进程与线程 区别和联系
	-----
	进程与线程的一个简单解释
	　　进程（process）和线程（thread）是操作系统的基本概念，但是它们比较抽象，不容易掌握。
	　　最近，我读到一篇材料，发现有一个很好的类比，可以把它们解释地清晰易懂。
	　　1).
	　　计算机的核心是CPU，它承担了所有的计算任务。它就像一座工厂，时刻在运行。
	　　2).
	　　假定工厂的电力有限，一次只能供给一个车间使用。也就是说，一个车间开工的时候，其他车间都必须停工。背后的含义就是，单个CPU一次只能运行一个任务。
	　　3).
	　　进程就好比工厂的车间，它代表CPU所能处理的单个任务。任一时刻，CPU总是运行一个进程，其他进程处于非运行状态。
	　　4).
	　　一个车间里，可以有很多工人。他们协同完成一个任务。
	　　5).
	　　线程就好比车间里的工人。一个进程可以包括多个线程。
	　　6).
	　　车间的空间是工人们共享的，比如许多房间是每个工人都可以进出的。这象征一个进程的内存空间是共享的，每个线程都可以使用这些共享内存。
	　　7).
	　　可是，每间房间的大小不同，有些房间最多只能容纳一个人，比如厕所。里面有人的时候，其他人就不能进去了。这代表一个线程使用某些共享内存时，
	其他线程必须等它结束，才能使用这一块内存。
	　　8).
	　　一个防止他人进入的简单方法，就是门口加一把锁。先到的人锁上门，后到的人看到上锁，就在门口排队，等锁打开再进去。这就叫"互斥锁"（Mutual exclusion，缩写 Mutex），
	防止多个线程同时读写某一块内存区域。
	　　9).
	　　还有些房间，可以同时容纳n个人，比如厨房。也就是说，如果人数大于n，多出来的人只能在外面等着。这好比某些内存区域，只能供给固定数目的线程使用。
	　　10).
	　　这时的解决方法，就是在门口挂n把钥匙。进去的人就取一把钥匙，出来时再把钥匙挂回原处。后到的人发现钥匙架空了，就知道必须在门口排队等着了。这种做法
	叫做"信号量"（Semaphore），用来保证多个线程不会互相冲突。
	　　不难看出，mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，
	还是采用这种设计。
	　　11).
	　　操作系统的设计，因此可以归结为三点：
	　　（1）以多进程形式，允许多个任务同时运行；
	　　（2）以多线程形式，允许单个任务分成不同的部分运行；
	　　（3）提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。
	-----
	from: http://kb.cnblogs.com/page/176246/

	-------
	线程与进程的区别可以归纳为以下几点：
	1）地址空间和其它资源（如打开文件）：进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。
	2）通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。
	3）调度和切换：线程上下文切换比进程上下文切换要快得多。
	4）在多线程OS中，进程不是一个可执行的实体（每一个程序都至少有一个线程，若程序只有一个线程，那就是程序本身）。
	-------
	from: http://baike.baidu.com/view/1053.htm

* 
	The best way to learn is to practice!
* 数据库连接池 * dbcp * c3p0
	- dbcp
		1）实现DataSource接口，提供支持连接池功能的DataSource实现，工厂模式，面向抽象编程
		ConnectionFactory根据driver，url，username ，password等构建一个获取raw physical connections连接的工厂
			工厂的设计： ConnectionFactory 为工厂接口，定义了一个抽象方法createConnection返回一个java.sql.Connection；针对上面的接口提供了
			DataSourceConnectionFactory（DataSource.getConnection方法），DriverConnectionFactory（Driver.connect方法），DriverManagerConnectionFactory（
			DriverManager.getConnection方法）三个获取连接的实现。另外，XAConnectionFactory接口继承ConnectionFactory，在其基础上扩展了基于事务管理器
			环境的连接管理，接口说明如下：
			-----
			 org.apache.commons.dbcp.managed.XAConnectionFactory
			DOC 
			---------
			XAConnectionFactory is an extension of ConnectionFactory used to create connections in a transaction managed environment. The XAConnectionFactory opperates 
			like a normal ConnectionFactory except an TransactionRegistry is provided from which the XAResource for a connection can be obtained. This allows the existing DBCP 
			pool code to work with XAConnections and gives a the ManagedConnection a way to enlist a connection in the the transaction.
			-----

		2）创建存放数据库连接connection的pool，dbcp池的设计：public class GenericObjectPool extends BaseObjectPool implements ObjectPool，
			ObjectPool：
				A pooling interface. 
				ObjectPool defines a trivially simple pooling interface. The only required methods are borrowObject, returnObject and invalidateObject. 

			BaseObjectPool：
				A simple base implementation of ObjectPool. Optional operations are implemented to either do nothing, return a value indicating it is unsupported 
				or throw UnsupportedOperationException.

			GenericObjectPool：
				A configurable ObjectPool implementation. 

				When coupled with the appropriate PoolableObjectFactory, GenericObjectPool provides robust pooling functionality for arbitrary objects. 

				A GenericObjectPool provides a number of configurable parameters: 

				maxActive controls the maximum number of objects that can be allocated by the pool (checked out to clients, or idle awaiting checkout) at a given time. When non-positive, 
					there is no limit to the number of objects that can be managed by the pool at one time. When maxActive is reached, the pool is said to be exhausted. The default setting 
					for this parameter is 8. 
				maxIdle controls the maximum number of objects that can sit idle in the pool at any time. When negative, there is no limit to the number of objects that may be idle at one time. 
					The default setting for this parameter is 8. 
				whenExhaustedAction specifies the behavior of the borrowObject method when the pool is exhausted: 
					When whenExhaustedAction is WHEN_EXHAUSTED_FAIL, borrowObject will throw a NoSuchElementException 
					When whenExhaustedAction is WHEN_EXHAUSTED_GROW, borrowObject will create a new object and return it (essentially making maxActive meaningless.) 
					When whenExhaustedAction is WHEN_EXHAUSTED_BLOCK, borrowObject will block (invoke Object.wait()) until a new or idle object is available. If a positive 
						maxWait value is supplied, then borrowObject will block for at most that many milliseconds, after which a NoSuchElementException will be thrown. If maxWait 
						is non-positive, the borrowObject method will block indefinitely. 
					The default whenExhaustedAction setting is WHEN_EXHAUSTED_BLOCK and the default maxWait setting is -1. By default, therefore, borrowObject will block 
						indefinitely until an idle instance becomes available. 
				When testOnBorrow is set, the pool will attempt to validate each object before it is returned from the borrowObject method. (Using the provided factory's PoolableObjectFactory.
					validateObject method.) Objects that fail to validate will be dropped from the pool, and a different object will be borrowed. The default setting for this parameter is false. 
				When testOnReturn is set, the pool will attempt to validate each object before it is returned to the pool in the returnObject method. (Using the provided factory's PoolableObjectFactory.
					validateObject method.) Objects that fail to validate will be dropped from the pool. The default setting for this parameter is false. 
				Optionally, one may configure the pool to examine and possibly evict objects as they sit idle in the pool and to ensure that a minimum number of idle objects are available. This is 
					performed by an "idle object eviction" thread, which runs asynchronously. Caution should be used when configuring this optional feature. Eviction runs require an exclusive synchronization lock on the pool, so if they run too frequently and / or incur excessive latency when creating, destroying or validating object instances, performance issues may result. The idle object eviction thread may be configured using the following attributes: 

				timeBetweenEvictionRunsMillis indicates how long the eviction thread should sleep before "runs" of examining idle objects. When non-positive, no eviction thread will be 
					launched. The default setting for this parameter is -1 (i.e., idle object eviction is disabled by default). 
				minEvictableIdleTimeMillis specifies the minimum amount of time that an object may sit idle in the pool before it is eligible for eviction due to idle time. When non-positive, no 
					object will be dropped from the pool due to idle time alone. This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The default setting for this parameter is 30 minutes. 
				testWhileIdle indicates whether or not idle objects should be validated using the factory's PoolableObjectFactory.validateObject method. Objects that fail to validate will be 
					dropped from the pool. This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The default setting for this parameter is false. 
				softMinEvictableIdleTimeMillis specifies the minimum amount of time an object may sit idle in the pool before it is eligible for eviction by the idle object evictor (if any), with the 
					extra condition that at least "minIdle" object instances remain in the pool. When non-positive, no objects will be evicted from the pool due to idle time alone. This setting has no 
					effect unless timeBetweenEvictionRunsMillis > 0. and it is superceded by minEvictableIdleTimeMillis (that is, if minEvictableIdleTimeMillis is positive, then softMinEvictableIdle
					TimeMillis is ignored). The default setting for this parameter is -1 (disabled). 
				numTestsPerEvictionRun determines the number of objects examined in each run of the idle object evictor. This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The 
					default setting for this parameter is 3. 

				The pool can be configured to behave as a LIFO queue with respect to idle objects - always returning the most recently used object from the pool, or as a FIFO queue, where 
					borrowObject always returns the oldest object in the idle object pool. 

				lifo determines whether or not the pool returns idle objects in last-in-first-out order. The default setting for this parameter is true. 
				GenericObjectPool is not usable without a PoolableObjectFactory. A non-null factory must be provided either as a constructor argument or via a call to setFactory before the pool is used. 

				Implementation note: To prevent possible deadlocks, care has been taken to ensure that no call to a factory method will occur within a synchronization block. See POOL-125 and 
					DBCP-44 for more information.
		3）statement pool 预编译语句缓存，如果配置为true
		4）poolable connection factory设置，构造PoolableConnectionFactory，可以池化连接的工厂，用以缓存并管理数据库连接
			这里可池化工厂的设计：
				PoolableObjectFactory接口（与ObjectPool结合使用，管理其提供对象的生命周期），
					org.apache.commons.pool.PoolableObjectFactory
					DOC
					---------
					An interface defining life-cycle methods for instances to be served by an ObjectPool. 

					By contract, when an ObjectPool delegates to a PoolableObjectFactory, 

					1) makeObject is called whenever a new instance is needed. 
					2) activateObject is invoked on every instance that has been passivated before it is borrowed from the pool. 
					3) validateObject is invoked on activated instances to make sure they can be borrowed from the pool. validateObject may also be used to test an instance 
					being returned to the pool before it is passivated. It will only be invoked on an activated instance. 
					4) passivateObject is invoked on every instance when it is returned to the pool. 
					5) destroyObject is invoked on every instance when it is being "dropped" from the pool (whether due to the response from validateObject, or for reasons specific 
					to the pool implementation.) There is no guarantee that the instance being destroyed will be considered active, passive or in a generally consistent state. 

					PoolableObjectFactory must be thread-safe. The only promise an ObjectPool makes is that the same instance of an object will not be passed to more than one method 
					of a PoolableObjectFactory at a time.

				PoolableConnectionFactory实现上面的接口，用于创建 PoolableConnections

			
			
			

			





* ivy * apache ivy
	apache Ivy™ is a popular dependency manager focusing on flexibility and simplicity.

*  WeakReference java.lang.ref.WeakReference<ThreadLocal>
	DOC
	--------
	Weak reference objects, which do not prevent their referents from being made finalizable, finalized, and then reclaimed. Weak references are most often 
	used to implement canonicalizing mappings. 

	Suppose that the garbage collector determines at a certain point in time that an object is weakly reachable. At that time it will atomically clear all weak references to that 
	object and all weak references to any other weakly-reachable objects from which that object is reachable through a chain of strong and soft references. At the same time 
	it will declare all of the formerly weakly-reachable objects to be finalizable. At the same time or at some later time it will enqueue those newly-cleared weak references
	that are registered with reference queues.


* ThreadLocal
	- initialValue方法说明：若没有set对象，重写此方法以返回默认对象；若此方法也没被重写也没set对象，则返回null
		Returns the current thread's "initial value" for this thread-local variable. This method will be invoked the first time a thread accesses the variable with the get method, unless the 
		thread previously invoked the set method, in which case the initialValue method will not be invoked for the thread. Normally, this method is invoked at most once per thread, 
		but it may be invoked again in case of subsequent invocations of remove followed by get. 
		
		This implementation simply returns null; if the programmer desires thread-local variables to have an initial value other than null, ThreadLocal must be subclassed, and this method 
		overridden. Typically, an anonymous inner class will be used.

	- 
		DOC
		------------
		java.lang.ThreadLocal<T>

		This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, 
		independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID). 

		For example, the class below generates unique identifiers local to each thread. A thread's id is assigned the first time it invokes UniqueThreadIdGenerator.getCurrentThreadId() and 
		remains unchanged on subsequent calls. 

		 import java.util.concurrent.atomic.AtomicInteger;

		 public class UniqueThreadIdGenerator {

		     private static final AtomicInteger uniqueId = new AtomicInteger(0);

		     private static final ThreadLocal < Integer > uniqueNum = 
			 new ThreadLocal < Integer > () {
			     @Override protected Integer initialValue() {
				 return uniqueId.getAndIncrement();
			 }
		     };
		 
		     public static int getCurrentThreadId() {
			 return uniqueId.get();
		     }
		 } // UniqueThreadIdGenerator
		 
		Each thread holds an implicit reference to its copy of a thread-local variable as long as the thread is alive and the ThreadLocal instance is accessible; after a thread goes away, all 
		of its copies of thread-local instances are subject to garbage collection (unless other references to these copies exist). 
		------------
		PS: 建议声明为private static final ThreadLocal < T> xx=xxx，在set对象时ThreadLocal实例会根据当前线程来存入值，以实现线程独享的目的

	 - 
		Threadlocal通过弱连接来保存线程范围的变量，每个线程有独立的ThreadLocalMap，存入时以threadlocal对象作为key，以dataValue作为value：
		java.lang.ThreadLocal.ThreadLocalMap
		DOC
		--------
		ThreadLocalMap is a customized hash map suitable only for maintaining thread local values. No operations are exported outside of the ThreadLocal class. 
		The class is package private to allow declaration of fields in class Thread. To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys. 
		However, since reference queues are not used, stale entries are guaranteed to be removed only when the table starts running out of space.

	- 
		每个Thread线程都有个ThreadLocalMap类型的实例变量threadlocals，用来存放与此线程相关的ThreadLocal变量。再来看ThreadLocal保存数据的set方法，代码如下
			public   void  set(T value) {
			Thread t = Thread.currentThread();
			ThreadLocalMap map = getMap(t);
			 if  (map !=  null  )
			    map.set(  this  , value);//以当前threadlocal实例作为key，一个线程可能有多个threadlocal实例以存放不同的变量
			 else
			    createMap(t, value);//当前线程的ThreadLocalMap属性为null，初始化一个并set值
			}
			...
			void createMap(Thread t, T firstValue) {
				t.threadLocals = new ThreadLocalMap(this, firstValue);
			}
			...
		首先获取当前的线程t，由getMap方法获取当前线程的threadLocals属性map，然后保存键值对。在保存的时候采用this对象做为键，同样在获取数据的时候，
		也是以this作为键来获取相应的数据。因为一个线程可能有多个由ThreadLocal对象保存的变量，采用this作为key，可以实现这样不同ThreadLocal对象之间的区分。
		from:	 http://www.cnblogs.com/javawebsoa/archive/2013/04/21/3034421.html

* tcpdump * wirkshak
	-------
		Linux tcpdump命令详解
		简介
		用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。

		 

		实用命令实例
		默认启动

		tcpdump
		普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包。

		 

		监视指定网络接口的数据包

		tcpdump -i eth1
		如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。　

		 

		监视指定主机的数据包

		打印所有进入或离开sundown的数据包.

		tcpdump host sundown
		也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包

		tcpdump host 210.27.48.1 
		打印helios 与 hot 或者与 ace 之间通信的数据包

		tcpdump host helios and \( hot or ace \)
		截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信

		tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 \) 
		打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.

		tcpdump ip host ace and not helios
		如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：

		tcpdump ip host 210.27.48.1 and ! 210.27.48.2
		截获主机hostname发送的所有数据

		tcpdump -i eth0 src host hostname
		监视所有送到主机hostname的数据包

		tcpdump -i eth0 dst host hostname
		 

		监视指定主机和端口的数据包

		如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令

		tcpdump tcp port 23 host 210.27.48.1
		对本机的udp 123 端口进行监视 123 为ntp的服务端口

		tcpdump udp port 123 
		 

		监视指定网络的数据包

		打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为'Berkeley网络'的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包)

		tcpdump net ucb-ether
		打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析)

		tcpdump 'gateway snup and (port ftp or ftp-data)'
		打印所有源地址或目标地址是本地主机的IP数据包

		(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字)

		tcpdump ip and not net localnet
		 

		监视指定协议的数据包

		打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字))

		tcpdump 'tcp[tcpflags] & (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'
		打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习)

		tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'
		(nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&0xf)<<2)表示ip数据包包头的长度(ip[0]&0xf代表包中的IHL域, 而此域的单位为32bit, 要换算

		成字节数需要乘以4,　即左移2.　(tcp[12]&0xf0)>>4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&0xf0) >> 4)　<<　２,　
		即 ((tcp[12]&0xf0)>>2).　((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去
		tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的'Payload Length' 与 'tcp头的长度'的差值, 并且其中表达方式'ip[]'需换成'ip6[]'.)

		打印长度超过576字节, 并且网关地址是snup的IP数据包

		tcpdump 'gateway snup and ip[2:2] > 576'
		打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报

		tcpdump 'ether[0] & 1 = 0 and ip[16] >= 224'
		打印除'echo request'或者'echo reply'类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 .
		(nt: 'echo reuqest' 与 'echo reply' 这两种类型的ICMP数据包通常由ping程序产生))

		tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply'
		 

		tcpdump 与wireshark

		Wireshark(以前是ethereal)是Windows下非常简单易用的抓包工具。但在Linux下很难找到一个好用的图形化抓包工具。
		还好有Tcpdump。我们可以用Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在Windows 里分析包。

		tcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap
		(1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型
		(2)-i eth1 : 只抓经过接口eth1的包
		(3)-t : 不显示时间戳
		(4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包
		(5)-c 100 : 只抓取100个数据包
		(6)dst port ! 22 : 不抓取目标端口是22的数据包
		(7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24
		(8)-w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析

		 

		使用tcpdump抓取HTTP包

		tcpdump  -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854
		0x4745 为"GET"前两个字母"GE",0x4854 为"HTTP"前两个字母"HT"。

		 

		tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。

		 

		输出信息含义
		首先我们注意一下，基本上tcpdump总的的输出格式为：系统时间 来源主机.端口 > 目标主机.端口 数据包参数

		tcpdump 的输出格式与协议有关.以下简要描述了大部分常用的格式及相关例子.

		链路层头
		对于FDDI网络, '-e' 使tcpdump打印出指定数据包的'frame control' 域, 源和目的地址, 以及包的长度.(frame control域
		控制对包中其他域的解析). 一般的包(比如那些IP datagrams)都是带有'async'(异步标志)的数据包，并且有取值0到7的优先级;
		比如 'async4'就代表此包为异步数据包，并且优先级别为4. 通常认为,这些包们会内含一个 LLC包(逻辑链路控制包); 这时,如果此包
		不是一个ISO datagram或所谓的SNAP包，其LLC头部将会被打印(nt:应该是指此包内含的 LLC包的包头).

		对于Token Ring网络(令牌环网络), '-e' 使tcpdump打印出指定数据包的'frame control'和'access control'域, 以及源和目的地址,
		外加包的长度. 与FDDI网络类似, 此数据包通常内含LLC数据包. 不管 是否有'-e'选项.对于此网络上的'source-routed'类型数据包(nt:
		意译为:源地址被追踪的数据包,具体含义未知,需补充), 其包的源路由信息总会被打印.


		对于802.11网络(WLAN,即wireless local area network), '-e' 使tcpdump打印出指定数据包的'frame control域,
		包头中包含的所有地址, 以及包的长度.与FDDI网络类似, 此数据包通常内含LLC数据包.

		(注意: 以下的描述会假设你熟悉SLIP压缩算法 (nt:SLIP为Serial Line Internet Protocol.), 这个算法可以在
		RFC-1144中找到相关的蛛丝马迹.)

		对于SLIP网络(nt:SLIP links, 可理解为一个网络, 即通过串行线路建立的连接, 而一个简单的连接也可看成一个网络),
		数据包的'direction indicator'('方向指示标志')("I"表示入, "O"表示出), 类型以及压缩信息将会被打印. 包类型会被首先打印.

		类型分为ip, utcp以及ctcp(nt:未知, 需补充). 对于ip包,连接信息将不被打印(nt:SLIP连接上,ip包的连接信息可能无用或没有定义.
		reconfirm).对于TCP数据包, 连接标识紧接着类型表示被打印. 如果此包被压缩, 其被编码过的头部将被打印.
		此时对于特殊的压缩包,会如下显示:
		*S+n 或者 *SA+n, 其中n代表包的(顺序号或(顺序号和应答号))增加或减少的数目(nt | rt:S,SA拗口, 需再译).
		对于非特殊的压缩包,0个或更多的'改变'将会被打印.'改变'被打印时格式如下:
		'标志'+/-/=n 包数据的长度 压缩的头部长度.
		其中'标志'可以取以下值:
		U(代表紧急指针), W(指缓冲窗口), A(应答), S(序列号), I(包ID),而增量表达'=n'表示被赋予新的值, +/-表示增加或减少.

		比如, 以下显示了对一个外发压缩TCP数据包的打印, 这个数据包隐含一个连接标识(connection identifier); 应答号增加了6,
		顺序号增加了49, 包ID号增加了6; 包数据长度为3字节(octect), 压缩头部为6字节.(nt:如此看来这应该不是一个特殊的压缩数据包).

		ARP/RARP 数据包

		tcpdump对Arp/rarp包的输出信息中会包含请求类型及该请求对应的参数. 显示格式简洁明了. 以下是从主机rtsg到主机csam的'rlogin'
		(远程登录)过程开始阶段的数据包样例:
		arp who-has csam tell rtsg
		arp reply csam is-at CSAM
		第一行表示:rtsg发送了一个arp数据包(nt:向全网段发送,arp数据包）以询问csam的以太网地址
		Csam（nt:可从下文看出来, 是Csam）以她自己的以太网地址做了回应(在这个例子中, 以太网地址以大写的名字标识, 而internet
		地址(即ip地址)以全部的小写名字标识).

		如果使用tcpdump -n, 可以清晰看到以太网以及ip地址而不是名字标识:
		arp who-has 128.3.254.6 tell 128.3.254.68
		arp reply 128.3.254.6 is-at 02:07:01:00:01:c4

		如果我们使用tcpdump -e, 则可以清晰的看到第一个数据包是全网广播的, 而第二个数据包是点对点的:
		RTSG Broadcast 0806 64: arp who-has csam tell rtsg
		CSAM RTSG 0806 64: arp reply csam is-at CSAM
		第一个数据包表明:以arp包的源以太地址是RTSG, 目标地址是全以太网段, type域的值为16进制0806(表示ETHER_ARP(nt:arp包的类型标识)),
		包的总长度为64字节.

		TCP 数据包
		(注意:以下将会假定你对 RFC-793所描述的TCP熟悉. 如果不熟, 以下描述以及tcpdump程序可能对你帮助不大.(nt:警告可忽略,
		只需继续看, 不熟悉的地方可回头再看.).


		通常tcpdump对tcp数据包的显示格式如下:
		src > dst: flags data-seqno ack window urgent options

		src 和 dst 是源和目的IP地址以及相应的端口. flags 标志由S(SYN), F(FIN), P(PUSH, R(RST),
		W(ECN CWT(nt | rep:未知, 需补充))或者 E(ECN-Echo(nt | rep:未知,　需补充))组成,
		单独一个'.'表示没有flags标识. 数据段顺序号(Data-seqno)描述了此包中数据所对应序列号空间中的一个位置(nt:整个数据被分段,
		每段有一个顺序号, 所有的顺序号构成一个序列号空间)(可参考以下例子). Ack 描述的是同一个连接,同一个方向,下一个本端应该接收的
		(对方应该发送的)数据片段的顺序号. Window是本端可用的数据接收缓冲区的大小(也是对方发送数据时需根据这个大小来组织数据).
		Urg(urgent) 表示数据包中有紧急的数据. options 描述了tcp的一些选项, 这些选项都用尖括号来表示(如 <mss 1024>).

		src, dst 和 flags 这三个域总是会被显示. 其他域的显示与否依赖于tcp协议头里的信息.

		这是一个从trsg到csam的一个rlogin应用登录的开始阶段.
		rtsg.1023 > csam.login: S 768512:768512(0) win 4096 <mss 1024>
		csam.login > rtsg.1023: S 947648:947648(0) ack 768513 win 4096 <mss 1024>
		rtsg.1023 > csam.login: . ack 1 win 4096
		rtsg.1023 > csam.login: P 1:2(1) ack 1 win 4096
		csam.login > rtsg.1023: . ack 2 win 4096
		rtsg.1023 > csam.login: P 2:21(19) ack 1 win 4096
		csam.login > rtsg.1023: P 1:2(1) ack 21 win 4077
		csam.login > rtsg.1023: P 2:3(1) ack 21 win 4077 urg 1
		csam.login > rtsg.1023: P 3:4(1) ack 21 win 4077 urg 1
		第一行表示有一个数据包从rtsg主机的tcp端口1023发送到了csam主机的tcp端口login上(nt:udp协议的端口和tcp协议的端
		口是分别的两个空间, 虽然取值范围一致). S表示设置了SYN标志. 包的顺序号是768512, 并且没有包含数据.(表示格式
		为:'first:last(nbytes)', 其含义是'此包中数据的顺序号从first开始直到last结束，不包括last. 并且总共包含nbytes的
		用户数据'.) 没有捎带应答(nt:从下文来看，第二行才是有捎带应答的数据包), 可用的接受窗口的大小为4096bytes, 并且请求端(rtsg)
		的最大可接受的数据段大小是1024字节(nt:这个信息作为请求发向应答端csam, 以便双方进一步的协商).

		Csam 向rtsg 回复了基本相同的SYN数据包, 其区别只是多了一个' piggy-backed ack'(nt:捎带回的ack应答, 针对rtsg的SYN数据包).

		rtsg 同样针对csam的SYN数据包回复了一ACK数据包作为应答. '.'的含义就是此包中没有标志被设置. 由于此应答包中不含有数据, 所以
		包中也没有数据段序列号. 提醒! 此ACK数据包的顺序号只是一个小整数1. 有如下解释:tcpdump对于一个tcp连接上的会话, 只打印会话两端的
		初始数据包的序列号,其后相应数据包只打印出与初始包序列号的差异.即初始序列号之后的序列号,　可被看作此会话上当前所传数据片段在整个
		要传输的数据中的'相对字节'位置(nt:双方的第一个位置都是1, 即'相对字节'的开始编号).　'-Ｓ'将覆盖这个功能,　
		使数据包的原始顺序号被打印出来.

		 

		第六行的含义为:rtsg 向 csam发送了19字节的数据(字节的编号为2到20，传送方向为rtsg到csam). 包中设置了PUSH标志. 在第7行,
		csam 喊到， 她已经从rtsg中收到了21以下的字节, 但不包括21编号的字节. 这些字节存放在csam的socket的接收缓冲中, 相应地,
		csam的接收缓冲窗口大小会减少19字节(nt:可以从第5行和第7行win属性值的变化看出来). csam在第7行这个包中也向rtsg发送了一个
		字节. 在第8行和第9行, csam 继续向rtsg 分别发送了两个只包含一个字节的数据包, 并且这个数据包带PUSH标志.

		如果所抓到的tcp包(nt:即这里的snapshot)太小了，以至tcpdump无法完整得到其头部数据, 这时, tcpdump会尽量解析这个不完整的头,
		并把剩下不能解析的部分显示为'[|tcp]'. 如果头部含有虚假的属性信息(比如其长度属性其实比头部实际长度长或短), tcpdump会为该头部
		显示'[bad opt]'. 如果头部的长度告诉我们某些选项(nt | rt:从下文来看， 指tcp包的头部中针对ip包的一些选项, 回头再翻)会在此包中,
		而真正的IP(数据包的长度又不够容纳这些选项, tcpdump会显示'[bad hdr length]'.


		抓取带有特殊标志的的TCP包(如SYN-ACK标志, URG-ACK标志等).

		在TCP的头部中, 有8比特(bit)用作控制位区域, 其取值为:
		CWR | ECE | URG | ACK | PSH | RST | SYN | FIN
		(nt | rt:从表达方式上可推断:这8个位是用或的方式来组合的, 可回头再翻)

		现假设我们想要监控建立一个TCP连接整个过程中所产生的数据包. 可回忆如下:TCP使用3次握手协议来建立一个新的连接; 其与此三次握手
		连接顺序对应，并带有相应TCP控制标志的数据包如下:
		1) 连接发起方(nt:Caller)发送SYN标志的数据包
		2) 接收方(nt:Recipient)用带有SYN和ACK标志的数据包进行回应
		3) 发起方收到接收方回应后再发送带有ACK标志的数据包进行回应


		0 15 31
		-----------------------------------------------------------------
		| source port | destination port |
		-----------------------------------------------------------------
		| sequence number |
		-----------------------------------------------------------------
		| acknowledgment number |
		-----------------------------------------------------------------
		| HL | rsvd |C|E|U|A|P|R|S|F| window size |
		-----------------------------------------------------------------
		| TCP checksum | urgent pointer |
		-----------------------------------------------------------------

		一个TCP头部,在不包含选项数据的情况下通常占用20个字节(nt | rt:options 理解为选项数据，需回译). 第一行包含0到3编号的字节,
		第二行包含编号4-7的字节.

		如果编号从0开始算, TCP控制标志位于13字节(nt:第四行左半部分).

		 

		0 7| 15| 23| 31
		----------------|---------------|---------------|----------------
		| HL | rsvd |C|E|U|A|P|R|S|F| window size |
		----------------|---------------|---------------|----------------
		| | 13th octet | | |

		让我们仔细看看编号13的字节:

		| |
		|---------------|
		|C|E|U|A|P|R|S|F|
		|---------------|
		|7 5 3 0|


		这里有我们感兴趣的控制标志位. 从右往左这些位被依次编号为0到7, 从而 PSH位在3号, 而URG位在5号.

		 

		提醒一下自己, 我们只是要得到包含SYN标志的数据包. 让我们看看在一个包的包头中, 如果SYN位被设置, 到底
		在13号字节发生了什么:

		|C|E|U|A|P|R|S|F|
		|---------------|
		|0 0 0 0 0 0 1 0|
		|---------------|
		|7 6 5 4 3 2 1 0|


		在控制段的数据中, 只有比特1(bit number 1)被置位.

		假设编号为13的字节是一个8位的无符号字符型,并且按照网络字节号排序(nt:对于一个字节来说，网络字节序等同于主机字节序), 其二进制值
		如下所示:
		00000010

		并且其10进制值为:

		0*2^7 + 0*2^6 + 0*2^5 + 0*2^4 + 0*2^3 + 0*2^2 + 1*2^1 + 0*2^0 = 2(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更
		清楚些, 即把原来表达中的指数7 6 ... 0挪到了下面来表达)

		接近目标了, 因为我们已经知道, 如果数据包头部中的SYN被置位, 那么头部中的第13个字节的值为2(nt: 按照网络序, 即大头方式, 最重要的字节
		在前面(在前面,即该字节实际内存地址比较小, 最重要的字节,指数学表示中数的高位, 如356中的3) ).

		表达为tcpdump能理解的关系式就是:
		tcp[13] 2

		从而我们可以把此关系式当作tcpdump的过滤条件, 目标就是监控只含有SYN标志的数据包:
		tcpdump -i xl0 tcp[13] 2 (nt: xl0 指网络接口, 如eth0)

		这个表达式是说"让TCP数据包的第13个字节拥有值2吧", 这也是我们想要的结果.


		现在, 假设我们需要抓取带SYN标志的数据包, 而忽略它是否包含其他标志.(nt:只要带SYN就是我们想要的). 让我们来看看当一个含有
		SYN-ACK的数据包(nt:SYN 和 ACK 标志都有), 来到时发生了什么:
		|C|E|U|A|P|R|S|F|
		|---------------|
		|0 0 0 1 0 0 1 0|
		|---------------|
		|7 6 5 4 3 2 1 0|

		13号字节的1号和4号位被置位, 其二进制的值为:
		00010010

		转换成十进制就是:

		0*2^7 + 0*2^6 + 0*2^5 + 1*2^4 + 0*2^3 + 0*2^2 + 1*2^1 + 0*2 = 18(nt: 1 * 2^6 表示1乘以2的6次方, 也许这样更
		清楚些, 即把原来表达中的指数7 6 ... 0挪到了下面来表达)

		现在, 却不能只用'tcp[13] 18'作为tcpdump的过滤表达式, 因为这将导致只选择含有SYN-ACK标志的数据包, 其他的都被丢弃.
		提醒一下自己, 我们的目标是: 只要包的SYN标志被设置就行, 其他的标志我们不理会.

		为了达到我们的目标, 我们需要把13号字节的二进制值与其他的一个数做AND操作(nt:逻辑与)来得到SYN比特位的值. 目标是:只要SYN 被设置
		就行, 于是我们就把她与上13号字节的SYN值(nt: 00000010).

		00010010 SYN-ACK 00000010 SYN
		AND 00000010 (we want SYN) AND 00000010 (we want SYN)
		-------- --------
		= 00000010 = 00000010

		我们可以发现, 不管包的ACK或其他标志是否被设置, 以上的AND操作都会给我们相同的值, 其10进制表达就是2(2进制表达就是00000010).
		从而我们知道, 对于带有SYN标志的数据包, 以下的表达式的结果总是真(true):

		( ( value of octet 13 ) AND ( 2 ) ) ( 2 ) (nt: value of octet 13, 即13号字节的值)

		灵感随之而来, 我们于是得到了如下的tcpdump 的过滤表达式
		tcpdump -i xl0 'tcp[13] & 2 2'

		注意, 单引号或反斜杆(nt: 这里用的是单引号)不能省略, 这可以防止shell对&的解释或替换.


		UDP 数据包
		UDP 数据包的显示格式，可通过rwho这个具体应用所产生的数据包来说明:
		actinide.who > broadcast.who: udp 84

		其含义为:actinide主机上的端口who向broadcast主机上的端口who发送了一个udp数据包(nt: actinide和broadcast都是指Internet地址).
		这个数据包承载的用户数据为84个字节.

		一些UDP服务可从数据包的源或目的端口来识别，也可从所显示的更高层协议信息来识别. 比如, Domain Name service requests(DNS 请求,
		在RFC-1034/1035中), 和Sun RPC calls to NFS(对NFS服务器所发起的远程调用(nt: 即Sun RPC)，在RFC-1050中有对远程调用的描述).

		UDP 名称服务请求

		(注意:以下的描述假设你对Domain Service protoco(nt:在RFC-103中有所描述), 否则你会发现以下描述就是天书(nt:希腊文天书,
		不必理会, 吓吓你的, 接着看就行))

		名称服务请求有如下的格式:
		src > dst: id op? flags qtype qclass name (len)
		(nt: 从下文来看, 格式应该是src > dst: id op flags qtype qclass? name (len))
		比如有一个实际显示为:
		h2opolo.1538 > helios.domain: 3+ A? ucbvax.berkeley.edu. (37)

		主机h2opolo 向helios 上运行的名称服务器查询ucbvax.berkeley.edu 的地址记录(nt: qtype等于A). 此查询本身的id号为'3'. 符号
		'+'意味着递归查询标志被设置(nt: dns服务器可向更高层dns服务器查询本服务器不包含的地址记录). 这个最终通过IP包发送的查询请求
		数据长度为37字节, 其中不包括UDP和IP协议的头数据. 因为此查询操作为默认值(nt | rt: normal one的理解), op字段被省略.
		如果op字段没被省略, 会被显示在'3' 和'+'之间. 同样, qclass也是默认值, C_IN, 从而也没被显示, 如果没被忽略, 她会被显示在'A'之后.

		异常检查会在方括中显示出附加的域:　如果一个查询同时包含一个回应(nt: 可理解为, 对之前其他一个请求的回应), 并且此回应包含权威或附加记录段,　
		ancount, nscout, arcount(nt: 具体字段含义需补充) 将被显示为'[na]', '[nn]', '[nau]', 其中n代表合适的计数. 如果包中以下
		回应位(比如AA位, RA位, rcode位), 或者字节2或3中任何一个'必须为0'的位被置位(nt: 设置为1), '[b2&3]=x' 将被显示, 其中x表示
		头部字节2与字节3进行与操作后的值.

		UDP 名称服务应答

		对名称服务应答的数据包，tcpdump会有如下的显示格式
		src > dst: id op rcode flags a/n/au type class data (len)
		比如具体显示如下:
		helios.domain > h2opolo.1538: 3 3/3/7 A 128.32.137.3 (273)
		helios.domain > h2opolo.1537: 2 NXDomain* 0/1/0 (97)

		第一行表示: helios 对h2opolo 所发送的3号查询请求回应了3条回答记录(nt | rt: answer records), 3条名称服务器记录,
		以及7条附加的记录. 第一个回答记录(nt: 3个回答记录中的第一个)类型为A(nt: 表示地址), 其数据为internet地址128.32.137.3.
		此回应UDP数据包, 包含273字节的数据(不包含UPD和IP的头部数据). op字段和rcode字段被忽略(nt: op的实际值为Query, rcode, 即
		response code的实际值为NoError), 同样被忽略的字段还有class 字段(nt | rt: 其值为C_IN, 这也是A类型记录默认取值)

		第二行表示: helios 对h2opolo 所发送的2号查询请求做了回应. 回应中, rcode编码为NXDomain(nt: 表示不存在的域)), 没有回答记录,
		但包含一个名称服务器记录, 不包含权威服务器记录(nt | ck: 从上文来看, 此处的authority records 就是上文中对应的additional
		records). '*'表示权威服务器回答标志被设置(nt: 从而additional records就表示的是authority records).
		由于没有回答记录, type, class, data字段都被忽略.

		flag字段还有可能出现其他一些字符, 比如'-'(nt: 表示可递归地查询, 即RA 标志没有被设置), '|'(nt: 表示被截断的消息, 即TC 标志
		被置位). 如果应答(nt | ct: 可理解为, 包含名称服务应答的UDP数据包, tcpdump知道这类数据包该怎样解析其数据)的'question'段一个条
		目(entry)都不包含(nt: 每个条目的含义, 需补充),'[nq]' 会被打印出来.

		要注意的是:名称服务器的请求和应答数据量比较大, 而默认的68字节的抓取长度(nt: snaplen, 可理解为tcpdump的一个设置选项)可能不足以抓取
		数据包的全部内容. 如果你真的需要仔细查看名称服务器的负载, 可以通过tcpdump 的-s 选项来扩大snaplen值.

		SMB/CIFS 解码
		tcpdump 已可以对SMB/CIFS/NBT相关应用的数据包内容进行解码(nt: 分别为'Server Message Block Common', 'Internet File System'
		'在TCP/IP上实现的网络协议NETBIOS的简称'. 这几个服务通常使用UDP的137/138以及TCP的139端口). 原来的对IPX和NetBEUI SMB数据包的
		解码能力依然可以被使用(nt: NetBEUI为NETBIOS的增强版本).


		tcpdump默认只按照最简约模式对相应数据包进行解码, 如果我们想要详尽的解码信息可以使用其-v 启动选现. 要注意的是, -v 会产生非常详细的信息,
		比如对单一的一个SMB数据包, 将产生一屏幕或更多的信息, 所以此选项, 确有需要才使用.

		关于SMB数据包格式的信息, 以及每个域的含义可以参看www.cifs.org 或者samba.org 镜像站点的pub/samba/specs/ 目录. linux 上的SMB 补丁
		(nt | rt: patch)由 Andrew Tridgell (tridge@samba.org)提供.


		NFS 请求和回应

		tcpdump对Sun NFS(网络文件系统)请求和回应的UDP数据包有如下格式的打印输出:
		src.xid > dst.nfs: len op args
		src.nfs > dst.xid: reply stat len op results

		以下是一组具体的输出数据
		sushi.6709 > wrl.nfs: 112 readlink fh 21,24/10.73165
		wrl.nfs > sushi.6709: reply ok 40 readlink "../var"
		sushi.201b > wrl.nfs:
		144 lookup fh 9,74/4096.6878 "xcolors"
		wrl.nfs > sushi.201b:
		reply ok 128 lookup fh 9,74/4134.3150

		第一行输出表明: 主机sushi向主机wrl发送了一个'交换请求'(nt: transaction), 此请求的id为6709(注意, 主机名字后是交换
		请求id号, 而不是源端口号). 此请求数据为112字节, 其中不包括UDP和IP头部的长度. 操作类型为readlink(nt: 即此操作为读符号链接操作),
		操作参数为fh 21,24/10.73165(nt: 可按实际运行环境, 解析如下, fd 表示描述的为文件句柄, 21,24 表示此句柄所对应设
		备的主/从设备号对, 10表示此句柄所对应的i节点编号(nt:每个文件都会在操作系统中对应一个i节点, 限于unix类系统中),
		73165是一个编号(nt: 可理解为标识此请求的一个随机数, 具体含义需补充)).

		第二行中, wrl 做了'ok'的回应, 并且在results 字段中返回了sushi想要读的符号连接的真实目录(nt: 即sushi要求读的符号连接其实是一个目录).

		第三行表明: sushi 再次请求 wrl 在'fh 9,74/4096.6878'所描述的目录中查找'xcolors'文件. 需要注意的是, 每行所显示的数据含义依赖于其中op字段的
		类型(nt: 不同op 所对应args 含义不相同), 其格式遵循NFS 协议, 追求简洁明了.

		 

		如果tcpdump 的-v选项(详细打印选项) 被设置, 附加的信息将被显示. 比如:
		sushi.1372a > wrl.nfs:
		148 read fh 21,11/12.195 8192 bytes @ 24576
		wrl.nfs > sushi.1372a:
		reply ok 1472 read REG 100664 ids 417/0 sz 29388

		(-v 选项一般还会打印出IP头部的TTL, ID， length, 以及fragmentation 域, 但在此例中, 都略过了(nt: 可理解为,简洁起见, 做了删减))
		在第一行, sushi 请求wrl 从文件 21,11/12.195(nt: 格式在上面有描述)中, 自偏移24576字节处开始, 读取8192字节数据.
		Wrl 回应读取成功; 由于第二行只是回应请求的开头片段, 所以只包含1472字节(其他的数据将在接着的reply片段中到来, 但这些数据包不会再有NFS
		头, 甚至UDP头信息也为空(nt: 源和目的应该要有), 这将导致这些片段不能满足过滤条件, 从而没有被打印). -v 选项除了显示文件数据信息, 还会显示
		附加显示文件属性信息: file type(文件类型, ''REG'' 表示普通文件), file mode(文件存取模式, 8进制表示的), uid 和gid(nt: 文件属主和
		组属主), file size (文件大小).

		如果-v 标志被多次重复给出(nt: 如-vv)， tcpdump会显示更加详细的信息.

		必须要注意的是, NFS 请求包中数据比较多, 如果tcpdump 的snaplen(nt: 抓取长度) 取太短将不能显示其详细信息. 可使用
		'-s 192'来增加snaplen, 这可用以监测NFS应用的网络负载(nt: traffic).

		NFS 的回应包并不严格的紧随之前相应的请求包(nt: RPC operation). 从而, tcpdump 会跟踪最近收到的一系列请求包, 再通过其
		交换序号(nt: transaction ID)与相应请求包相匹配. 这可能产生一个问题， 如果回应包来得太迟, 超出tcpdump 对相应请求包的跟踪范围,
		该回应包将不能被分析.


		AFS 请求和回应
		AFS(nt: Andrew 文件系统, Transarc , 未知, 需补充)请求和回应有如下的答应

		src.sport > dst.dport: rx packet-type
		src.sport > dst.dport: rx packet-type service call call-name args
		src.sport > dst.dport: rx packet-type service reply call-name args

		elvis.7001 > pike.afsfs:
		rx data fs call rename old fid 536876964/1/1 ".newsrc.new"
		new fid 536876964/1/1 ".newsrc"
		pike.afsfs > elvis.7001: rx data fs reply rename

		在第一行, 主机elvis 向pike 发送了一个RX数据包.
		这是一个对于文件服务的请求数据包(nt: RX data packet, 发送数据包 , 可理解为发送包过去, 从而请求对方的服务), 这也是一个RPC
		调用的开始(nt: RPC, remote procedure call). 此RPC 请求pike 执行rename(nt: 重命名) 操作, 并指定了相关的参数:
		原目录描述符为536876964/1/1, 原文件名为 '.newsrc.new', 新目录描述符为536876964/1/1, 新文件名为 '.newsrc'.
		主机pike 对此rename操作的RPC请求作了回应(回应表示rename操作成功, 因为回应的是包含数据内容的包而不是异常包).

		一般来说, 所有的'AFS RPC'请求被显示时, 会被冠以一个名字(nt: 即decode, 解码), 这个名字往往就是RPC请求的操作名.
		并且, 这些RPC请求的部分参数在显示时, 也会被冠以一个名字(nt | rt: 即decode, 解码, 一般来说也是取名也很直接, 比如,
		一个interesting 参数, 显示的时候就会直接是'interesting', 含义拗口, 需再翻).

		这种显示格式的设计初衷为'一看就懂', 但对于不熟悉AFS 和 RX 工作原理的人可能不是很
		有用(nt: 还是不用管, 书面吓吓你的, 往下看就行).

		如果 -v(详细)标志被重复给出(nt: 如-vv), tcpdump 会打印出确认包(nt: 可理解为, 与应答包有区别的包)以及附加头部信息
		(nt: 可理解为, 所有包, 而不仅仅是确认包的附加头部信息), 比如, RX call ID(请求包中'请求调用'的ID),
		call number('请求调用'的编号), sequence number(nt: 包顺序号),
		serial number(nt | rt: 可理解为与包中数据相关的另一个顺信号, 具体含义需补充), 请求包的标识. (nt: 接下来一段为重复描述,
		所以略去了), 此外确认包中的MTU协商信息也会被打印出来(nt: 确认包为相对于请求包的确认包, Maximum Transmission Unit, 最大传输单元).

		如果 -v 选项被重复了三次(nt: 如-vvv), 那么AFS应用类型数据包的'安全索引'('security index')以及'服务索引'('service id')将会
		被打印.

		对于表示异常的数据包(nt: abort packet, 可理解为, 此包就是用来通知接受者某种异常已发生), tcpdump 会打印出错误号(error codes).
		但对于Ubik beacon packets(nt: Ubik 灯塔指示包, Ubik可理解为特殊的通信协议, beacon packets, 灯塔数据包, 可理解为指明通信中
		关键信息的一些数据包), 错误号不会被打印, 因为对于Ubik 协议, 异常数据包不是表示错误, 相反却是表示一种肯定应答(nt: 即, yes vote).

		AFS 请求数据量大, 参数也多, 所以要求tcpdump的 snaplen 比较大, 一般可通过启动tcpdump时设置选项'-s 256' 来增大snaplen, 以
		监测AFS 应用通信负载.

		AFS 回应包并不显示标识RPC 属于何种远程调用. 从而, tcpdump 会跟踪最近一段时间内的请求包, 并通过call number(调用编号), service ID
		(服务索引) 来匹配收到的回应包. 如果回应包不是针对最近一段时间内的请求包, tcpdump将无法解析该包.


		KIP AppleTalk协议
		(nt | rt: DDP in UDP可理解为, DDP, The AppleTalk Data Delivery Protocol,
		相当于支持KIP AppleTalk协议栈的网络层协议, 而DDP 本身又是通过UDP来传输的,
		即在UDP 上实现的用于其他网络的网络层，KIP AppleTalk是苹果公司开发的整套网络协议栈).

		AppleTalk DDP 数据包被封装在UDP数据包中, 其解封装(nt: 相当于解码)和相应信息的转储也遵循DDP 包规则.
		(nt:encapsulate, 封装, 相当于编码, de-encapsulate, 解封装, 相当于解码, dump, 转储, 通常就是指对其信息进行打印).

		/etc/atalk.names 文件中包含了AppleTalk 网络和节点的数字标识到名称的对应关系. 其文件格式通常如下所示:
		number name

		1.254 ether
		16.1 icsd-net
		1.254.110 ace

		头两行表示有两个AppleTalk 网络. 第三行给出了特定网络上的主机(一个主机会用3个字节来标识,
		而一个网络的标识通常只有两个字节, 这也是两者标识的主要区别)(nt: 1.254.110 可理解为ether网络上的ace主机).
		标识与其对应的名字之间必须要用空白分开. 除了以上内容, /etc/atalk.names中还包含空行以及注释行(以'#'开始的行).


		AppleTalk 完整网络地址将以如下格式显示:
		net.host.port

		以下为一段具体显示:
		144.1.209.2 > icsd-net.112.220
		office.2 > icsd-net.112.220
		jssmag.149.235 > icsd-net.2

		(如果/etc/atalk.names 文件不存在, 或者没有相应AppleTalk 主机/网络的条目, 数据包的网络地址将以数字形式显示).

		在第一行中, 网络144.1上的节点209通过2端口,向网络icsd-net上监听在220端口的112节点发送了一个NBP应用数据包
		(nt | rt: NBP, name binding protocol, 名称绑定协议, 从数据来看, NBP服务器会在端口2提供此服务.
		'DDP port 2' 可理解为'DDP 对应传输层的端口2', DDP本身没有端口的概念, 这点未确定, 需补充).

		第二行与第一行类似, 只是源的全部地址可用'office'进行标识.
		第三行表示: jssmag网络上的149节点通过235向icsd-net网络上的所有节点的2端口(NBP端口)发送了数据包.(需要注意的是,
		在AppleTalk 网络中如果地址中没有节点, 则表示广播地址, 从而节点标识和网络标识最好在/etc/atalk.names有所区别.
		nt: 否则一个标识x.port 无法确定x是指一个网络上所有主机的port口还是指定主机x的port口).

		tcpdump 可解析NBP (名称绑定协议) and ATP (AppleTalk传输协议)数据包, 对于其他应用层的协议, 只会打印出相应协议名字(
		如果此协议没有注册一个通用名字, 只会打印其协议号)以及数据包的大小.


		NBP 数据包会按照如下格式显示:
		icsd-net.112.220 > jssmag.2: nbp-lkup 190: "=:LaserWriter@*"
		jssmag.209.2 > icsd-net.112.220: nbp-reply 190: "RM1140:LaserWriter@*" 250
		techpit.2 > icsd-net.112.220: nbp-reply 190: "techpit:LaserWriter@*" 186

		第一行表示: 网络icsd-net 中的节点112 通过220端口向网络jssmag 中所有节点的端口2发送了对'LaserWriter'的名称查询请求(nt:
		此处名称可理解为一个资源的名称, 比如打印机). 此查询请求的序列号为190.

		第二行表示: 网络jssmag 中的节点209 通过2端口向icsd-net.112节点的端口220进行了回应: 我有'LaserWriter'资源, 其资源名称
		为'RM1140', 并且在端口250上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号.

		第三行也是对第一行请求的回应: 节点techpit 通过2端口向icsd-net.112节点的端口220进行了回应:我有'LaserWriter'资源, 其资源名称
		为'techpit', 并且在端口186上提供改资源的服务. 此回应的序列号为190, 对应之前查询的序列号.


		ATP 数据包的显示格式如下:
		jssmag.209.165 > helios.132: atp-req 12266<0-7> 0xae030001
		helios.132 > jssmag.209.165: atp-resp 12266:0 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:1 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:2 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:6 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp*12266:7 (512) 0xae040000
		jssmag.209.165 > helios.132: atp-req 12266<3,5> 0xae030001
		helios.132 > jssmag.209.165: atp-resp 12266:3 (512) 0xae040000
		helios.132 > jssmag.209.165: atp-resp 12266:5 (512) 0xae040000
		jssmag.209.165 > helios.132: atp-rel 12266<0-7> 0xae030001
		jssmag.209.133 > helios.132: atp-req* 12267<0-7> 0xae030002

		第一行表示节点 Jssmag.209 向节点helios 发送了一个会话编号为12266的请求包, 请求helios
		回应8个数据包(这8个数据包的顺序号为0-7(nt: 顺序号与会话编号不同, 后者为一次完整传输的编号,
		前者为该传输中每个数据包的编号. transaction, 会话, 通常也被叫做传输)). 行尾的16进制数字表示
		该请求包中'userdata'域的值(nt: 从下文来看, 这并没有把所有用户数据都打印出来 ).

		Helios 回应了8个512字节的数据包. 跟在会话编号(nt: 12266)后的数字表示该数据包在该会话中的顺序号.
		括号中的数字表示该数据包中数据的大小, 这不包括atp 的头部. 在顺序号为7数据包(第8行)外带了一个'*'号,
		表示该数据包的EOM 标志被设置了.(nt: EOM, End Of Media, 可理解为, 表示一次会话的数据回应完毕).

		接下来的第9行表示, Jssmag.209 又向helios 提出了请求: 顺序号为3以及5的数据包请重新传送. Helios 收到这个
		请求后重新发送了这个两个数据包, jssmag.209 再次收到这两个数据包之后, 主动结束(release)了此会话.

		在最后一行, jssmag.209 向helios 发送了开始下一次会话的请求包. 请求包中的'*'表示该包的XO 标志没有被设置.
		(nt: XO, exactly once, 可理解为在该会话中, 数据包在接受方只被精确地处理一次, 就算对方重复传送了该数据包,
		接收方也只会处理一次, 这需要用到特别设计的数据包接收和处理机制).


		IP 数据包破碎
		(nt: 指把一个IP数据包分成多个IP数据包)

		碎片IP数据包(nt: 即一个大的IP数据包破碎后生成的小IP数据包)有如下两种显示格式.
		(frag id:size@offset+)
		(frag id:size@offset)
		(第一种格式表示, 此碎片之后还有后续碎片. 第二种格式表示, 此碎片为最后一个碎片.)

		id 表示破碎编号(nt: 从下文来看, 会为每个要破碎的大IP包分配一个破碎编号, 以便区分每个小碎片是否由同一数据包破碎而来).
		size 表示此碎片的大小 , 不包含碎片头部数据. offset表示此碎片所含数据在原始整个IP包中的偏移((nt: 从下文来看,
		一个IP数据包是作为一个整体被破碎的, 包括头和数据, 而不只是数据被分割).

		每个碎片都会使tcpdump产生相应的输出打印. 第一个碎片包含了高层协议的头数据(nt:从下文来看, 被破碎IP数据包中相应tcp头以及
		IP头都放在了第一个碎片中 ), 从而tcpdump会针对第一个碎片显示这些信息, 并接着显示此碎片本身的信息. 其后的一些碎片并不包含
		高层协议头信息, 从而只会在显示源和目的之后显示碎片本身的信息. 以下有一个例子: 这是一个从arizona.edu 到lbl-rtsg.arpa
		途经CSNET网络(nt: CSNET connection 可理解为建立在CSNET 网络上的连接)的ftp应用通信片段:
		arizona.ftp-data > rtsg.1170: . 1024:1332(308) ack 1 win 4096 (frag 595a:328@0+)
		arizona > rtsg: (frag 595a:204@328)
		rtsg.1170 > arizona.ftp-data: . ack 1536 win 2560

		有几点值得注意:
		第一, 第二行的打印中, 地址后面没有端口号.
		这是因为TCP协议信息都放到了第一个碎片中, 当显示第二个碎片时, 我们无法知道此碎片所对应TCP包的顺序号.

		第二, 从第一行的信息中, 可以发现arizona需要向rtsg发送308字节的用户数据, 而事实是, 相应IP包经破碎后会总共产生512字节
		数据(第一个碎片包含308字节的数据, 第二个碎片包含204个字节的数据, 这超过了308字节). 如果你在查找数据包的顺序号空间中的
		一些空洞(nt: hole,空洞, 指数据包之间的顺序号没有上下衔接上), 512这个数据就足够使你迷茫一阵(nt: 其实只要关注308就行,
		不必关注破碎后的数据总量).

		一个数据包(nt | rt: 指IP数据包)如果带有非IP破碎标志, 则显示时会在最后显示'(DF)'.(nt: 意味着此IP包没有被破碎过).


		时间戳
		tcpdump的所有输出打印行中都会默认包含时间戳信息.
		时间戳信息的显示格式如下
		hh:mm:ss.frac　(nt: 小时:分钟:秒.(nt: frac未知, 需补充))
		此时间戳的精度与内核时间精度一致,　反映的是内核第一次看到对应数据包的时间(nt: saw, 即可对该数据包进行操作).　
		而数据包从物理线路传递到内核的时间, 以及内核花费在此包上的中断处理时间都没有算进来.

		 

		命令使用
		tcpdump采用命令行方式，它的命令格式为：


		tcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ]
			   [ -C file_size ] [ -F file ]
			   [ -i interface ] [ -m module ] [ -M secret ]
			   [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]
			   [ -W filecount ]
			   [ -E spi@ipaddr algo:secret,...  ]
			   [ -y datalinktype ] [ -Z user ]
			   [ expression ]

		tcpdump的简单选项介绍

		-A  以ASCII码方式显示每一个数据包(不会显示数据包中链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据(nt: 即Handy for capturing web pages).

		-c  count
		    tcpdump将在接受到count个数据包后退出.

		-C  file-size (nt: 此选项用于配合-w file 选项使用)
		    该选项使得tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)

		-d  以容易阅读的形式,在标准输出上打印出编排过的包匹配码, 随后tcpdump停止.(nt | rt: human readable, 容易阅读的,通常是指以ascii码来打印一些信息. compiled, 编排过的. packet-matching code, 包匹配码,含义未知, 需补充)

		-dd 以C语言的形式打印出包匹配码.

		-ddd 以十进制数的形式打印出包匹配码(会在包匹配码之前有一个附加的'count'前缀).

		-D  打印系统中所有tcpdump可以在其上进行抓包的网络接口. 每一个接口会打印出数字编号, 相应的接口名字, 以及可能的一个网络接口描述. 其中网络接口名字和数字编号可以用在tcpdump 的-i flag 选项(nt: 把名字或数字代替flag), 来指定要在其上抓包的网络接口.

		    此选项在不支持接口列表命令的系统上很有用(nt: 比如, Windows 系统, 或缺乏 ifconfig -a 的UNIX系统); 接口的数字编号在windows 2000 或其后的系统中很有用, 因为这些系统上的接口名字比较复杂, 而不易使用.

		    如果tcpdump编译时所依赖的libpcap库太老,-D 选项不会被支持, 因为其中缺乏 pcap_findalldevs()函数.

		-e  每行的打印输出中将包括数据包的数据链路层头部信息

		-E  spi@ipaddr algo:secret,...

		    可通过spi@ipaddr algo:secret 来解密IPsec ESP包(nt | rt:IPsec Encapsulating Security Payload,IPsec 封装安全负载, IPsec可理解为, 一整套对ip数据包的加密协议, ESP 为整个IP 数据包或其中上层协议部分被加密后的数据,前者的工作模式称为隧道模式; 后者的工作模式称为传输模式 . 工作原理, 另需补充).

		    需要注意的是, 在终端启动tcpdump 时, 可以为IPv4 ESP packets 设置密钥(secret）.

		    可用于加密的算法包括des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, 或者没有(none).默认的是des-cbc(nt: des, Data Encryption Standard, 数据加密标准, 加密算法未知, 另需补充).secret 为用于ESP 的密钥, 使用ASCII 字符串方式表达. 如果以 0x 开头, 该密钥将以16进制方式读入.

		    该选项中ESP 的定义遵循RFC2406, 而不是 RFC1827. 并且, 此选项只是用来调试的, 不推荐以真实密钥(secret)来使用该选项, 因为这样不安全: 在命令行中输入的secret 可以被其他人通过ps 等命令查看到.

		    除了以上的语法格式(nt: 指spi@ipaddr algo:secret), 还可以在后面添加一个语法输入文件名字供tcpdump 使用(nt：即把spi@ipaddr algo:secret,... 中...换成一个语法文件名). 此文件在接受到第一个ESP　包时会打开此文件, 所以最好此时把赋予tcpdump 的一些特权取消(nt: 可理解为, 这样防范之后, 当该文件为恶意编写时,不至于造成过大损害).

		-f  显示外部的IPv4 地址时(nt: foreign IPv4 addresses, 可理解为, 非本机ip地址), 采用数字方式而不是名字.(此选项是用来对付Sun公司的NIS服务器的缺陷(nt: NIS, 网络信息服务, tcpdump 显示外部地址的名字时会用到她提供的名称服务): 此NIS服务器在查询非本地地址名字时,常常会陷入无尽的查询循环).

		    由于对外部(foreign)IPv4地址的测试需要用到本地网络接口(nt: tcpdump 抓包时用到的接口)及其IPv4 地址和网络掩码. 如果此地址或网络掩码不可用, 或者此接口根本就没有设置相应网络地址和网络掩码(nt: linux 下的 'any' 网络接口就不需要设置地址和掩码, 不过此'any'接口可以收到系统中所有接口的数据包), 该选项不能正常工作.

		-F  file
		    使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.

		-i  interface

		    指定tcpdump 需要监听的接口.  如果没有指定, tcpdump 会从系统接口列表中搜寻编号最小的已配置好的接口(不包括 loopback 接口).一但找到第一个符合条件的接口, 搜寻马上结束.

		    在采用2.2版本或之后版本内核的Linux 操作系统上, 'any' 这个虚拟网络接口可被用来接收所有网络接口上的数据包(nt: 这会包括目的是该网络接口的, 也包括目的不是该网络接口的). 需要注意的是如果真实网络接口不能工作在'混杂'模式(promiscuous)下,则无法在'any'这个虚拟的网络接口上抓取其数据包.

		    如果 -D 标志被指定, tcpdump会打印系统中的接口编号，而该编号就可用于此处的interface 参数.

		-l  对标准输出进行行缓冲(nt: 使标准输出设备遇到一个换行符就马上把这行的内容打印出来).在需要同时观察抓包打印以及保存抓包记录的时候很有用. 比如, 可通过以下命令组合来达到此目的:
		    ``tcpdump  -l  |  tee dat'' 或者 ``tcpdump  -l   > dat  &  tail  -f  dat''.(nt: 前者使用tee来把tcpdump 的输出同时放到文件dat和标准输出中, 而后者通过重定向操作'>', 把tcpdump的输出放到dat 文件中, 同时通过tail把dat文件中的内容放到标准输出中)

		-L  列出指定网络接口所支持的数据链路层的类型后退出.(nt: 指定接口通过-i 来指定)

		-m  module
		    通过module 指定的file 装载SMI MIB 模块(nt: SMI，Structure of Management Information, 管理信息结构MIB, Management Information Base, 管理信息库. 可理解为, 这两者用于SNMP(Simple Network Management Protoco)协议数据包的抓取. 具体SNMP 的工作原理未知, 另需补充).

		    此选项可多次使用, 从而为tcpdump 装载不同的MIB 模块.

		-M  secret  如果TCP 数据包(TCP segments)有TCP-MD5选项(在RFC 2385有相关描述), 则为其摘要的验证指定一个公共的密钥secret.

		-n  不对地址(比如, 主机地址, 端口号)进行数字表示到名字表示的转换.

		-N  不打印出host 的域名部分. 比如, 如果设置了此选现, tcpdump 将会打印'nic' 而不是 'nic.ddn.mil'.

		-O  不启用进行包匹配时所用的优化代码. 当怀疑某些bug是由优化代码引起的, 此选项将很有用.

		-p  一般情况下, 把网络接口设置为非'混杂'模式. 但必须注意 , 在特殊情况下此网络接口还是会以'混杂'模式来工作； 从而, '-p' 的设与不设, 不能当做以下选现的代名词:'ether host {local-hw-add}' 或  'ether broadcast'(nt: 前者表示只匹配以太网地址为host 的包, 后者表示匹配以太网地址为广播地址的数据包).

		-q  快速(也许用'安静'更好?)打印输出. 即打印很少的协议相关信息, 从而输出行都比较简短.

		-R  设定tcpdump 对 ESP/AH 数据包的解析按照 RFC1825而不是RFC1829(nt: AH, 认证头, ESP， 安全负载封装, 这两者会用在IP包的安全传输机制中). 如果此选项被设置, tcpdump 将不会打印出'禁止中继'域(nt: relay prevention field). 另外,由于ESP/AH规范中没有规定ESP/AH数据包必须拥有协议版本号域,所以tcpdump不能从收到的ESP/AH数据包中推导出协议版本号.

		-r  file
		    从文件file 中读取包数据. 如果file 字段为 '-' 符号, 则tcpdump 会从标准输入中读取包数据.

		-S  打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号.(nt: 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距,比如, 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2. 而如果此时-S 选项被设置, 对于后来接收到的第2个, 第3个数据包会打印出其绝对顺序号:232324, 232325).

		-s  snaplen
		    设置tcpdump的数据包抓取长度为snaplen, 如果不设置默认将会是68字节(而支持网络接口分接头(nt: NIT, 上文已有描述,可搜索'网络接口分接头'关键字找到那里)的SunOS系列操作系统中默认的也是最小值是96).68字节对于IP, ICMP(nt: Internet Control Message Protocol,因特网控制报文协议), TCP 以及 UDP 协议的报文已足够, 但对于名称服务(nt: 可理解为dns, nis等服务), NFS服务相关的数据包会产生包截短. 如果产生包截短这种情况, tcpdump的相应打印输出行中会出现''[|proto]''的标志（proto 实际会显示为被截短的数据包的相关协议层次). 需要注意的是, 采用长的抓取长度(nt: snaplen比较大), 会增加包的处理时间, 并且会减少tcpdump 可缓存的数据包的数量， 从而会导致数据包的丢失. 所以, 在能抓取我们想要的包的前提下, 抓取长度越小越好.把snaplen 设置为0 意味着让tcpdump自动选择合适的长度来抓取数据包.

		-T  type
		    强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包.  目前已知的type 可取的协议为:
		    aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用),
		    cnfp (Cisco  NetFlow  protocol),  rpc(Remote Procedure Call), rtp (Real-Time Applications protocol),
		    rtcp (Real-Time Applications con-trol protocol), snmp (Simple Network Management Protocol),
		    tftp (Trivial File Transfer Protocol, 碎文件协议), vat (Visual Audio Tool, 可用于在internet 上进行电
		    视电话会议的应用层协议), 以及wb (distributed White Board, 可用于网络会议的应用层协议).

		-t     在每行输出中不打印时间戳

		-tt    不对每行输出的时间进行格式处理(nt: 这种格式一眼可能看不出其含义, 如时间戳打印成1261798315)

		-ttt   tcpdump 输出时, 每两行打印之间会延迟一个段时间(以毫秒为单位)

		-tttt  在每行打印的时间戳之前添加日期的打印

		-u     打印出未加密的NFS 句柄(nt: handle可理解为NFS 中使用的文件句柄, 这将包括文件夹和文件夹中的文件)

		-U    使得当tcpdump在使用-w 选项时, 其文件写入与包的保存同步.(nt: 即, 当每个数据包被保存时, 它将及时被写入文件中,而不是等文件的输出缓冲已满时才真正写入此文件)

		      -U 标志在老版本的libcap库(nt: tcpdump 所依赖的报文捕获库)上不起作用, 因为其中缺乏pcap_cump_flush()函数.

		-v    当分析和打印的时候, 产生详细的输出. 比如, 包的生存时间, 标识, 总长度以及IP包的一些选项. 这也会打开一些附加的包完整性检测, 比如对IP或ICMP包头部的校验和.

		-vv   产生比-v更详细的输出. 比如, NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码.

		-vvv  产生比-vv更详细的输出. 比如, telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面,
		      其相应的图形选项将会以16进制的方式打印出来(nt: telnet 的SB,SE选项含义未知, 另需补充).

		-w    把包数据直接写入文件而不进行分析和打印输出. 这些包数据可在随后通过-r 选项来重新读入并进行分析和打印.

		-W    filecount
		      此选项与-C 选项配合使用, 这将限制可打开的文件数目, 并且当文件数据超过这里设置的限制时, 依次循环替代之前的文件, 这相当于一个拥有filecount 个文件的文件缓冲池. 同时, 该选项会使得每个文件名的开头会出现足够多并用来占位的0, 这可以方便这些文件被正确的排序.

		-x    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据(但不包括连接层的头部).总共打印的数据大小不会超过整个数据包的大小与snaplen 中的最小值. 必须要注意的是, 如果高层协议数据没有snaplen 这么长,并且数据链路层(比如, Ethernet层)有填充数据, 则这些填充数据也会被打印.(nt: so for link  layers  that pad, 未能衔接理解和翻译, 需补充 )

		-xx   tcpdump 会打印每个包的头部数据, 同时会以16进制打印出每个包的数据, 其中包括数据链路层的头部.

		-X    当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据(但不包括连接层的头部).这对于分析一些新协议的数据包很方便.

		-XX   当分析和打印时, tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据, 其中包括数据链路层的头部.这对于分析一些新协议的数据包很方便.

		-y    datalinktype
		      设置tcpdump 只捕获数据链路层协议类型是datalinktype的数据包

		-Z    user
		      使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID(nt: tcpdump 此处可理解为tcpdump 运行之后对应的进程)

		      此选项也可在编译的时候被设置为默认打开.(nt: 此时user 的取值未知, 需补充)

		tcpdump条件表达式
		  该表达式用于决定哪些数据包将被打印. 如果不给定条件表达式, 网络上所有被捕获的包都会被打印,否则, 只有满足条件表达式的数据包被打印.(nt: all packets, 可理解为, 所有被指定接口捕获的数据包).

		  表达式由一个或多个'表达元'组成(nt: primitive, 表达元, 可理解为组成表达式的基本元素). 一个表达元通常由一个或多个修饰符(qualifiers)后跟一个名字或数字表示的id组成(nt: 即, 'qualifiers id').有三种不同类型的修饰符:type, dir以及 proto.


		type 修饰符指定id 所代表的对象类型, id可以是名字也可以是数字. 可选的对象类型有: host, net, port 以及portrange(nt: host 表明id表示主机, net 表明id是网络, port 表明id是端而portrange 表明id 是一个端口范围).  如, 'host foo', 'net 128.3', 'port 20', 'portrange 6000-6008'(nt: 分别表示主机 foo,网络 128.3, 端口 20, 端口范围 6000-6008). 如果不指定type 修饰符, id默认的修饰符为host.

		dir 修饰符描述id 所对应的传输方向, 即发往id 还是从id 接收（nt: 而id 到底指什么需要看其前面的type 修饰符）.可取的方向为: src, dst, src 或 dst, src并且dst.(nt:分别表示, id是传输源, id是传输目的, id是传输源或者传输目的, id是传输源并且是传输目的). 例如, 'src foo','dst net 128.3', 'src or dst port ftp-data'.(nt: 分别表示符合条件的数据包中, 源主机是foo, 目的网络是128.3, 源或目的端口为 ftp-data).如果不指定dir修饰符, id 默认的修饰符为src 或 dst.对于链路层的协议,比如SLIP(nt: Serial Line InternetProtocol, 串联线路网际网络协议), 以及linux下指定'any' 设备, 并指定'cooked'(nt | rt: cooked 含义未知, 需补充) 抓取类型, 或其他设备类型,可以用'inbound' 和 'outbount' 修饰符来指定想要的传输方向.

		proto 修饰符描述id 所属的协议. 可选的协议有: ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp以及 upd.(nt | rt: ether, fddi, tr, 具体含义未知, 需补充. 可理解为物理以太网传输协议, 光纤分布数据网传输协议,以及用于路由跟踪的协议.  wlan, 无线局域网协议; ip,ip6 即通常的TCP/IP协议栈中所使用的ipv4以及ipv6网络层协议;arp, rarp 即地址解析协议,反向地址解析协议; decnet, Digital Equipment Corporation开发的, 最早用于PDP-11 机器互联的网络协议; tcp and udp, 即通常TCP/IP协议栈中的两个传输层协议).

		    例如, `ether src foo', `arp net 128.3', `tcp port 21', `udp portrange 7000-7009'分别表示 '从以太网地址foo 来的数据包','发往或来自128.3网络的arp协议数据包', '发送或接收端口为21的tcp协议数据包', '发送或接收端口范围为7000-7009的udp协议数据包'.

		    如果不指定proto 修饰符, 则默认为与相应type匹配的修饰符. 例如, 'src foo' 含义是 '(ip or arp or rarp) src foo' (nt: 即, 来自主机foo的ip/arp/rarp协议数据包, 默认type为host),`net bar' 含义是`(ip  or  arp  or rarp) net bar'(nt: 即, 来自或发往bar网络的ip/arp/rarp协议数据包),`port 53' 含义是 `(tcp or udp) port 53'(nt: 即, 发送或接收端口为53的tcp/udp协议数据包).(nt: 由于tcpdump 直接通过数据链路层的 BSD 数据包过滤器或 DLPI(datalink provider interface, 数据链层提供者接口)来直接获得网络数据包, 其可抓取的数据包可涵盖上层的各种协议, 包括arp, rarp, icmp(因特网控制报文协议),ip, ip6, tcp, udp, sctp(流控制传输协议).

		    对于修饰符后跟id 的格式,可理解为, type id 是对包最基本的过滤条件: 即对包相关的主机, 网络, 端口的限制;dir 表示对包的传送方向的限制; proto表示对包相关的协议限制)

		    'fddi'(nt: Fiber Distributed Data Interface) 实际上与'ether' 含义一样: tcpdump 会把他们当作一种''指定网络接口上的数据链路层协议''. 如同ehter网(以太网), FDDI 的头部通常也会有源, 目的, 以及包类型, 从而可以像ether网数据包一样对这些域进行过滤. 此外, FDDI 头部还有其他的域, 但不能被放到表达式中用来过滤

		    同样, 'tr' 和 'wlan' 也和 'ether' 含义一致, 上一段对fddi 的描述同样适用于tr(Token Ring) 和wlan(802.11 wireless LAN)的头部. 对于802.11 协议数据包的头部, 目的域称为DA, 源域称为 SA;而其中的 BSSID, RA, TA 域(nt | rt: 具体含义需补充)不会被检测(nt: 不能被用于包过虑表达式中).

		  除以上所描述的表达元('primitive')， 还有其他形式的表达元, 并且与上述表达元格式不同. 比如: gateway, broadcast, less, greater以及算术表达式(nt: 其中每一个都算一种新的表达元). 下面将会对这些表达元进行说明.

		  表达元之间还可以通过关键字and, or 以及 not 进行连接, 从而可组成比较复杂的条件表达式. 比如,`host foo and not port ftp and not port ftp-data'(nt: 其过滤条件可理解为, 数据包的主机为foo,并且端口不是ftp(端口21) 和ftp-data(端口20, 常用端口和名字的对应可在linux 系统中的/etc/service 文件中找到)).

		  为了表示方便, 同样的修饰符可以被省略, 如'tcp dst port ftp or ftp-data or domain' 与以下的表达式含义相同'tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain'.(nt: 其过滤条件可理解为,包的协议为tcp, 目的端口为ftp 或 ftp-data 或 domain(端口53) ).

		  借助括号以及相应操作符,可把表达元组合在一起使用(由于括号是shell的特殊字符, 所以在shell脚本或终端中使用时必须对括号进行转义, 即'(' 与')'需要分别表达成'\(' 与 '\)').

		  有效的操作符有:

		 否定操作 (`!' 或 `not')
		 与操作(`&&' 或 `and')
		 或操作(`||' 或 `or')
		  否定操作符的优先级别最高. 与操作和或操作优先级别相同, 并且二者的结合顺序是从左到右. 要注意的是, 表达'与操作'时,

		  需要显式写出'and'操作符, 而不只是把前后表达元并列放置(nt: 二者中间的'and' 操作符不可省略).

		  如果一个标识符前没有关键字, 则表达式的解析过程中最近用过的关键字(往往也是从左往右距离标识符最近的关键字)将被使用.比如,
		    not host vs and ace
		  是以下表达的精简:
		    not host vs and host ace
		  而不是not (host vs or ace).(nt: 前两者表示, 所需数据包不是来自或发往host vs, 而是来自或发往ace.而后者表示数据包只要不是来自或发往vs或ac都符合要求)

		  整个条件表达式可以被当作一个单独的字符串参数也可以被当作空格分割的多个参数传入tcpdump, 后者更方便些. 通常, 如果表达式中包含元字符(nt: 如正则表达式中的'*', '.'以及shell中的'('等字符)， 最好还是使用单独字符串的方式传入. 这时,整个表达式需要被单引号括起来. 多参数的传入方式中, 所有参数最终还是被空格串联在一起, 作为一个字符串被解析.

		 

		附录:tcpdump的表达元
		(nt: True 在以下的描述中含义为: 相应条件表达式中只含有以下所列的一个特定表达元, 此时表达式为真, 即条件得到满足)

		dst host host
		如果IPv4/v6 数据包的目的域是host, 则与此对应的条件表达式为真.host 可以是一个ip地址, 也可以是一个主机名.
		src host host
		如果IPv4/v6 数据包的源域是host, 则与此对应的条件表达式为真.
		host 可以是一个ip地址, 也可以是一个主机名.
		host host

		如果IPv4/v6数据包的源或目的地址是 host, 则与此对应的条件表达式为真.以上的几个host 表达式之前可以添加以下关键字:ip, arp, rarp, 以及 ip6.比如:
		ip host host
		也可以表达为:
		ether proto \ip and host host(nt: 这种表达方式在下面有说明, 其中ip之前需要有\来转义,因为ip 对tcpdump 来说已经是一个关键字了.)

		如果host 是一个拥有多个IP 的主机, 那么任何一个地址都会用于包的匹配(nt: 即发向host 的数据包的目的地址可以是这几个IP中的任何一个, 从host 接收的数据包的源地址也可以是这几个IP中的任何一个).

		ether dst ehost
		如果数据包(nt: 指tcpdump 可抓取的数据包, 包括ip 数据包, tcp数据包)的以太网目标地址是ehost,则与此对应的条件表达式为真. Ehost 可以是/etc/ethers 文件中的名字或一个数字地址(nt: 可通过 man ethers 看到对/etc/ethers 文件的描述, 样例中用的是数字地址)

		ether src ehost
		如果数据包的以太网源地址是ehost, 则与此对应的条件表达式为真.

		ether host ehost
		如果数据包的以太网源地址或目标地址是ehost, 则与此对应的条件表达式为真.

		gateway host
		如果数据包的网关地址是host, 则与此对应的条件表达式为真. 需要注意的是, 这里的网关地址是指以太网地址, 而不是IP 地址(nt | rt: I.e., 例如, 可理解为'注意'.the Ethernet source or destination address, 以太网源和目标地址, 可理解为, 指代上句中的'网关地址' ).host 必须是名字而不是数字, 并且必须在机器的'主机名-ip地址'以及'主机名-以太地址'两大映射关系中 有其条目(前一映射关系可通过/etc/hosts文件, DNS 或 NIS得到, 而后一映射关系可通过/etc/ethers 文件得到. nt: /etc/ethers并不一定存在 , 可通过man ethers 看到其数据格式, 如何创建该文件, 未知,需补充).也就是说host 的含义是 ether host ehost 而不是 host host, 并且ehost必须是名字而不是数字.
		目前, 该选项在支持IPv6地址格式的配置环境中不起作用(nt: configuration, 配置环境, 可理解为,通信双方的网络配置).

		dst net net
		如果数据包的目标地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.
		net 可以是从网络数据库文件/etc/networks 中的名字, 也可以是一个数字形式的网络编号.

		一个数字IPv4 网络编号将以点分四元组(比如, 192.168.1.0), 或点分三元组(比如, 192.168.1 ), 或点分二元组(比如, 172.16), 或单一单元组(比如, 10)来表达;

		对应于这四种情况的网络掩码分别是:四元组:255.255.255.255(这也意味着对net 的匹配如同对主机地址(host)的匹配:地址的四个部分都用到了),三元组:255.255.255.0, 二元组: 255.255.0.0, 一元组:255.0.0.0.

		对于IPv6 的地址格式, 网络编号必须全部写出来(8个部分必须全部写出来); 相应网络掩码为:
		ff:ff:ff:ff:ff:ff:ff:ff, 所以IPv6 的网络匹配是真正的'host'方式的匹配(nt | rt | rc:地址的8个部分都会用到,是否不属于网络的字节填写0, 需接下来补充), 但同时需要一个网络掩码长度参数来具体指定前面多少字节为网络掩码(nt: 可通过下面的net net/len 来指定)

		src net net
		如果数据包的源地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.

		net net
		如果数据包的源或目的地址(IPv4或IPv6格式)的网络号字段为 net, 则与此对应的条件表达式为真.

		net net mask netmask
		如果数据包的源或目的地址(IPv4或IPv6格式)的网络掩码与netmask 匹配, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt: 比如 src net net mask 255.255.255.0).该选项对于ipv6 网络地址无效.

		net net/len
		如果数据包的源或目的地址(IPv4或IPv6格式)的网络编号字段的比特数与len相同, 则与此对应的条件表达式为真.此选项之前还可以配合src和dst来匹配源网络地址或目标网络地址(nt | rt | tt: src net net/24, 表示需要匹配源地址的网络编号有24位的数据包).

		dst port port
		如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口为port, 则与此对应的条件表达式为真.port 可以是一个数字也可以是一个名字(相应名字可以在/etc/services 中找到该名字, 也可以通过man tcp 和man udp来得到相关描述信息 ). 如果使用名字, 则该名字对应的端口号和相应使用的协议都会被检查. 如果只是使用一个数字端口号,则只有相应端口号被检查(比如, dst port 513 将会使tcpdump抓取tcp协议的login 服务和udp协议的who 服务数据包, 而port domain 将会使tcpdump 抓取tcp协议的domain 服务数据包, 以及udp 协议的domain 数据包)(nt | rt: ambiguous name is used 不可理解, 需补充).

		src port port
		如果数据包的源端口为port, 则与此对应的条件表达式为真.

		port port
		如果数据包的源或目的端口为port, 则与此对应的条件表达式为真.

		dst portrange port1-port2
		如果数据包(包括ip/tcp, ip/udp, ip6/tcp or ip6/udp协议)的目的端口属于port1到port2这个端口范围(包括port1, port2), 则与此对应的条件表达式为真. tcpdump 对port1 和port2 解析与对port 的解析一致(nt:在dst port port 选项的描述中有说明).

		src portrange port1-port2
		如果数据包的源端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真.

		portrange port1-port2
		如果数据包的源端口或目的端口属于port1到port2这个端口范围(包括 port1, port2), 则与此对应的条件表达式为真.

		以上关于port 的选项都可以在其前面添加关键字:tcp 或者udp, 比如:
		tcp src port port
		这将使tcpdump 只抓取源端口是port 的tcp数据包.

		less length
		如果数据包的长度比length 小或等于length, 则与此对应的条件表达式为真. 这与'len <= length' 的含义一致.

		greater length
		如果数据包的长度比length 大或等于length, 则与此对应的条件表达式为真. 这与'len >= length' 的含义一致.

		ip proto protocol
		如果数据包为ipv4数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.
		Protocol 可以是一个数字也可以是名字, 比如:icmp6, igmp, igrp(nt: Interior Gateway Routing Protocol,内部网关路由协议), pim(Protocol Independent Multicast, 独立组播协议, 应用于组播路由器),ah, esp(nt: ah, 认证头, esp 安全负载封装, 这两者会用在IP包的安全传输机制中 ), vrrp(Virtual Router Redundancy Protocol, 虚拟路由器冗余协议), udp, or tcp. 由于tcp , udp 以及icmp是tcpdump 的关键字,所以在这些协议名字之前必须要用\来进行转义(如果在C-shell 中需要用\\来进行转义). 注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来(nt: 实际上只会打印指定协议的一些头部信息, 比如可以用tcpdump -i eth0 'ip proto \tcp and host 192.168.3.144', 则只打印主机192.168.3.144 发出或接收的数据包中tcp 协议头所包含的信息)

		ip6 proto protocol
		如果数据包为ipv6数据包并且其协议类型为protocol, 则与此对应的条件表达式为真.
		注意此表达元不会把数据包中协议头链中所有协议头内容全部打印出来

		ip6 protochain protocol
		如果数据包为ipv6数据包并且其协议链中包含类型为protocol协议头, 则与此对应的条件表达式为真. 比如,
		ip6 protochain 6

		将匹配其协议头链中拥有TCP 协议头的IPv6数据包.此数据包的IPv6头和TCP头之间可能还会包含验证头, 路由头, 或者逐跳寻径选项头.
		由此所触发的相应BPF(Berkeley Packets Filter, 可理解为, 在数据链路层提供数据包过滤的一种机制)代码比较繁琐,
		并且BPF优化代码也未能照顾到此部分, 从而此选项所触发的包匹配可能会比较慢.

		ip protochain protocol
		与ip6 protochain protocol 含义相同, 但这用在IPv4数据包.

		ether broadcast
		如果数据包是以太网广播数据包, 则与此对应的条件表达式为真. ether 关键字是可选的.

		ip broadcast
		如果数据包是IPv4广播数据包, 则与此对应的条件表达式为真. 这将使tcpdump 检查广播地址是否符合全0和全1的一些约定,并查找网络接口的网络掩码(网络接口为当时在其上抓包的网络接口).

		如果抓包所在网络接口的网络掩码不合法, 或者此接口根本就没有设置相应网络地址和网络， 亦或是在linux下的'any'网络接口上抓包(此'any'接口可以收到系统中不止一个接口的数据包(nt: 实际上, 可理解为系统中所有可用的接口)),网络掩码的检查不能正常进行.


		ether multicast
		如果数据包是一个以太网多点广播数据包(nt: 多点广播, 可理解为把消息同时传递给一组目的地址, 而不是网络中所有地址,后者为可称为广播(broadcast)), 则与此对应的条件表达式为真. 关键字ether 可以省略. 此选项的含义与以下条件表达式含义一致:`ether[0] & 1 != 0'(nt: 可理解为, 以太网数据包中第0个字节的最低位是1, 这意味这是一个多点广播数据包).

		ip multicast
		如果数据包是ipv4多点广播数据包, 则与此对应的条件表达式为真.

		ip6 multicast
		如果数据包是ipv6多点广播数据包, 则与此对应的条件表达式为真.

		ether proto protocol
		如果数据包属于以下以太协议类型, 则与此对应的条件表达式为真.
		协议(protocol)字段, 可以是数字或以下所列出了名字: ip, ip6, arp, rarp, atalk(AppleTalk网络协议),
		aarp(nt: AppleTalk Address Resolution Protocol, AppleTalk网络的地址解析协议),
		decnet(nt: 一个由DEC公司所提供的网络协议栈), sca(nt: 未知, 需补充),
		lat(Local Area Transport, 区域传输协议, 由DEC公司开发的以太网主机互联协议),
		mopdl, moprc, iso(nt: 未知, 需补充), stp(Spanning tree protocol, 生成树协议, 可用于防止网络中产生链接循环),
		ipx（nt: Internetwork Packet Exchange, Novell 网络中使用的网络层协议）, 或者
		netbeui(nt: NetBIOS Extended User Interface，可理解为, 网络基本输入输出系统接口扩展).

		protocol字段可以是一个数字或以下协议名之一:ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat,
		mopdl, moprc, iso, stp, ipx, 或者netbeui.
		必须要注意的是标识符也是关键字, 从而必须通过'\'来进行转义.

		(SNAP：子网接入协议 （SubNetwork Access Protocol）)

		在光纤分布式数据网络接口(其表达元形式可以是'fddi protocol arp'), 令牌环网(其表达元形式可以是'tr protocol arp'),
		以及IEEE 802.11 无线局域网(其表达元形式可以是'wlan protocol arp')中, protocol
		标识符来自802.2 逻辑链路控制层头,
		在FDDI, Token Ring 或 802.1头中会包含此逻辑链路控制层头.

		当以这些网络上的相应的协议标识为过滤条件时, tcpdump只是检查LLC头部中以0x000000为组成单元标识符(OUI, 0x000000
		标识一个内部以太网)的一段'SNAP格式结构'中的protocol ID 域, 而不会管包中是否有一段OUI为0x000000的'SNAP格式
		结构'(nt: SNAP, SubNetwork Access Protocol,子网接入协议 ). 以下例外:

		iso tcpdump 会检查LLC头部中的DSAP域(Destination service Access Point, 目标服务接入点)和
		SSAP域(源服务接入点).(nt: iso 协议未知, 需补充)

		stp 以及 netbeui
		tcpdump 将会检查LLC 头部中的目标服务接入点(Destination service Access Point);

		atalk
		tcpdump 将会检查LLC 头部中以0x080007 为OUI标识的'SNAP格式结构', 并会检查AppleTalk etype域.
		(nt: AppleTalk etype 是否位于SNAP格式结构中, 未知, 需补充).

		此外, 在以太网中, 对于ether proto protocol 选项, tcpdump 会为 protocol 所指定的协议检查
		以太网类型域(the Ethernet type field), 但以下这些协议除外:

		iso, stp, and netbeui
		tcpdump 将会检查802.3 物理帧以及LLC 头(这两种检查与FDDI, TR, 802.11网络中的相应检查一致);
		(nt: 802.3, 理解为IEEE 802.3, 其为一系列IEEE 标准的集合. 此集合定义了有线以太网络中的物理层以及数据
		链路层的媒体接入控制子层. stp 在上文已有描述)

		atalk
		tcpdump 将会检查以太网物理帧中的AppleTalk etype 域 ,　同时也会检查数据包中LLC头部中的'SNAP格式结构'
		(这两种检查与FDDI, TR, 802.11网络中的相应检查一致)

		aarp tcpdump 将会检查AppleTalk ARP etype 域, 此域或存在于以太网物理帧中, 或存在于LLC(由802.2 所定义)的
		'SNAP格式结构'中, 当为后者时, 该'SNAP格式结构'的OUI标识为0x000000;
		(nt: 802.2, 可理解为, IEEE802.2, 其中定义了逻辑链路控制层(LLC), 该层对应于OSI 网络模型中数据链路层的上层部分.
		LLC 层为使用数据链路层的用户提供了一个统一的接口(通常用户是网络层). LLC层以下是媒体接入控制层(nt: MAC层,
		对应于数据链路层的下层部分).该层的实现以及工作方式会根据不同物理传输媒介的不同而有所区别(比如, 以太网, 令牌环网,
		光纤分布数据接口(nt: 实际可理解为一种光纤网络), 无线局域网(802.11), 等等.)

		ipx tcpdump 将会检查物理以太帧中的IPX etype域, LLC头中的IPX DSAP域，无LLC头并对IPX进行了封装的802.3帧,
		以及LLC 头部'SNAP格式结构'中的IPX etype 域(nt | rt: SNAP frame, 可理解为, LLC 头中的'SNAP格式结构'.
		该含义属初步理解阶段, 需补充).

		decnet src host
		如果数据包中DECNET源地址为host, 则与此对应的条件表达式为真.
		(nt:decnet, 由Digital Equipment Corporation 开发, 最早用于PDP-11 机器互联的网络协议)

		decnet dst host
		如果数据包中DECNET目的地址为host, 则与此对应的条件表达式为真.
		(nt: decnet 在上文已有说明)

		decnet host host
		如果数据包中DECNET目的地址或DECNET源地址为host, 则与此对应的条件表达式为真.
		(nt: decnet 在上文已有说明)

		ifname interface
		如果数据包已被标记为从指定的网络接口中接收的, 则与此对应的条件表达式为真.
		(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))

		on interface
		与 ifname interface 含义一致.

		rnr num
		如果数据包已被标记为匹配PF的规则, 则与此对应的条件表达式为真.
		(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))

		rulenum num
		与 rulenum num 含义一致.

		reason code
		如果数据包已被标记为包含PF的匹配结果代码, 则与此对应的条件表达式为真.有效的结果代码有: match, bad-offset,
		fragment, short, normalize, 以及memory.
		(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))

		rset name
		如果数据包已被标记为匹配指定的规则集, 则与此对应的条件表达式为真.
		(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))

		ruleset name
		与 rset name 含义一致.

		srnr num
		如果数据包已被标记为匹配指定的规则集中的特定规则(nt: specified PF rule number, 特定规则编号, 即特定规则),
		则与此对应的条件表达式为真.(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为
		OpenBSD中的防火墙程序))

		subrulenum num
		与 srnr 含义一致.

		action act
		如果包被记录时PF会执行act指定的动作, 则与此对应的条件表达式为真. 有效的动作有: pass, block.
		(此选项只适用于被OpenBSD中pf程序做过标记的包(nt: pf, packet filter, 可理解为OpenBSD中的防火墙程序))

		ip, ip6, arp, rarp, atalk, aarp, decnet, iso, stp, ipx, netbeui
		与以下表达元含义一致:
		ether proto p
		p是以上协议中的一个.

		lat, moprc, mopdl
		与以下表达元含义一致:
		ether proto p
		p是以上协议中的一个. 必须要注意的是tcpdump目前还不能分析这些协议.

		vlan [vlan_id]
		如果数据包为IEEE802.1Q VLAN 数据包, 则与此对应的条件表达式为真.
		(nt: IEEE802.1Q VLAN, 即IEEE802.1Q 虚拟网络协议, 此协议用于不同网络的之间的互联).
		如果[vlan_id] 被指定, 则只有数据包含有指定的虚拟网络id(vlan_id), 则与此对应的条件表达式为真.
		要注意的是, 对于VLAN数据包, 在表达式中遇到的第一个vlan关键字会改变表达式中接下来关键字所对应数据包中数据的
		开始位置(即解码偏移). 在VLAN网络体系中过滤数据包时, vlan [vlan_id]表达式可以被多次使用. 关键字vlan每出现一次都会增加
		4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移).

		例如:
		vlan 100 && vlan 200
		表示: 过滤封装在VLAN100中的VLAN200网络上的数据包
		再例如:
		vlan && vlan 300 && ip
		表示: 过滤封装在VLAN300 网络中的IPv4数据包, 而VLAN300网络又被更外层的VLAN封装


		mpls [label_num]
		如果数据包为MPLS数据包, 则与此对应的条件表达式为真.
		(nt: MPLS, Multi-Protocol Label Switch, 多协议标签交换, 一种在开放的通信网上利用标签引导数据传输的技术).

		如果[label_num] 被指定, 则只有数据包含有指定的标签id(label_num), 则与此对应的条件表达式为真.
		要注意的是, 对于内含MPLS信息的IP数据包(即MPLS数据包), 在表达式中遇到的第一个MPLS关键字会改变表达式中接下来关键字所对应数据包中数据的
		开始位置(即解码偏移). 在MPLS网络体系中过滤数据包时, mpls [label_num]表达式可以被多次使用. 关键字mpls每出现一次都会增加
		4字节过滤偏移(nt: 过滤偏移, 可理解为上面的解码偏移).

		例如:
		mpls 100000 && mpls 1024
		表示: 过滤外层标签为100000 而层标签为1024的数据包

		再如:
		mpls && mpls 1024 && host 192.9.200.1
		表示: 过滤发往或来自192.9.200.1的数据包, 该数据包的内层标签为1024, 且拥有一个外层标签.

		pppoed
		如果数据包为PPP-over-Ethernet的服务器探寻数据包(nt: Discovery packet,
		其ethernet type 为0x8863),则与此对应的条件表达式为真.
		(nt: PPP-over-Ethernet, 点对点以太网承载协议, 其点对点的连接建立分为Discovery阶段(地址发现) 和
		PPPoE 会话建立阶段 , discovery 数据包就是第一阶段发出来的包. ethernet type
		是以太帧里的一个字段，用来指明应用于帧数据字段的协议)

		pppoes
		如果数据包为PPP-over-Ethernet会话数据包(nt: ethernet type 为0x8864, PPP-over-Ethernet在上文已有说明, 可搜索
		关键字'PPP-over-Ethernet'找到其描述), 则与此对应的条件表达式为真.

		要注意的是, 对于PPP-over-Ethernet会话数据包, 在表达式中遇到的第一个pppoes关键字会改变表达式中接下来关键字所对应数据包中数据的
		开始位置(即解码偏移).

		例如:
		pppoes && ip
		表示: 过滤嵌入在PPPoE数据包中的ipv4数据包

		tcp, udp, icmp
		与以下表达元含义一致:
		ip proto p or ip6 proto p
		其中p 是以上协议之一(含义分别为: 如果数据包为ipv4或ipv6数据包并且其协议类型为 tcp,udp, 或icmp则与此对
		应的条件表达式为真)

		iso proto protocol
		如果数据包的协议类型为iso-osi协议栈中protocol协议, 则与此对应的条件表达式为真.(nt: [初解]iso-osi 网络模型中每
		层的具体协议与tcp/ip相应层采用的协议不同. iso-osi各层中的具体协议另需补充 )

		protocol 可以是一个数字编号, 或以下名字中之一:
		clnp, esis, or isis.
		(nt: clnp, Connectionless Network Protocol, 这是OSI网络模型中网络层协议 , esis, isis 未知, 需补充)

		clnp, esis, isis
		是以下表达的缩写
		iso proto p
		其中p 是以上协议之一


		l1, l2, iih, lsp, snp, csnp, psnp
		为IS-IS PDU 类型 的缩写.
		(nt: IS-IS PDU, Intermediate system to intermediate system Protocol Data Unit, 中间系统到
		中间系统的协议数据单元. OSI(Open Systems Interconnection)网络由终端系统, 中间系统构成.
		终端系统指路由器, 而终端系统指用户设备. 路由器形成的本地组称之为'区域'（Area）和多个区域组成一个'域'（Domain）.
		IS-IS 提供域内或区域内的路由. l1, l2, iih, lsp, snp, csnp, psnp 表示PDU的类型, 具体含义另需补充)

		vpi n
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,
		如果数据包为ATM数据包, 并且其虚拟路径标识为n, 则与此对应的条件表达式为真.
		(nt: ATM, Asychronous Transfer Mode, 实际上可理解为由ITU-T(国际电信联盟电信标准化部门)提出的一个与
		TCP/IP中IP层功能等同的一系列协议, 具体协议层次另需补充)

		vci n
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,
		如果数据包为ATM数据包, 并且其虚拟通道标识为n, 则与此对应的条件表达式为真.
		(nt: ATM, 在上文已有描述)

		lane
		如果数据包为ATM LANE 数据包, 则与此对应的条件表达式为真. 要注意的是, 如果是模拟以太网的LANE数据包或者
		LANE逻辑单元控制包, 表达式中第一个lane关键字会改变表达式中随后条件的测试. 如果没有
		指定lane关键字, 条件测试将按照数据包中内含LLC(逻辑链路层)的ATM包来进行.

		llc
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 ,
		如果数据包为ATM数据包,　并且内含LLC则与此对应的条件表达式为真

		oamf4s
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是Segment OAM F4 信元(VPI=0 并且 VCI=3), 则与此对应的条件表达式为真.

		(nt: OAM, Operation Administration and Maintenance, 操作管理和维护,可理解为:ATM网络中用于网络
		管理所产生的ATM信元的分类方式.

		ATM网络中传输单位为信元, 要传输的数据终究会被分割成固定长度(53字节)的信元,
		(初理解: 一条物理线路可被复用, 形成虚拟路径(virtual path). 而一条虚拟路径再次被复用, 形成虚拟信道(virtual channel)).
		通信双方的编址方式为:虚拟路径编号(VPI)/虚拟信道编号(VCI)).

		OAM F4 flow 信元又可分为segment 类和end-to-end 类, 其区别未知, 需补充.)

		oamf4e
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是 end-to-end OAM F4 信元(VPI=0 并且 VCI=4), 则与此对应的条件表达式为真.
		(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位)

		oamf4
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.
		(nt: OAM 与 end-to-end OAM F4 在上文已有描述, 可搜索'oamf4s'来定位)

		oam
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是 end-to-end 或 segment OAM F4 信元(VPI=0 并且 VCI=3 或者 VCI=4), 则与此对应的条件表达式为真.
		(nt: 此选项与oamf4重复, 需确认)

		metac
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'元信令线路'(nt: VPI=0 并且 VCI=1, '元信令线路', meta signaling circuit, 具体含义未知, 需补充),
		则与此对应的条件表达式为真.

		bcc
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'广播信令线路'(nt: VPI=0 并且 VCI=2, '广播信令线路', broadcast signaling circuit, 具体含义未知, 需补充),
		则与此对应的条件表达式为真.

		sc
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'信令线路'(nt: VPI=0 并且 VCI=5, '信令线路', signaling circuit, 具体含义未知, 需补充),
		则与此对应的条件表达式为真.

		ilmic
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'ILMI线路'(nt: VPI=0 并且 VCI=16, 'ILMI', Interim Local Management Interface , 可理解为
		基于SNMP(简易网络管理协议)的用于网络管理的接口)
		则与此对应的条件表达式为真.

		connectmsg

		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,
		Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真.
		(nt: Q.2931 为ITU(国际电信联盟)制定的信令协议. 其中规定了在宽带综合业务数字网络的用户接口层建立, 维护, 取消
		网络连接的相关步骤.)

		metaconnect
		如果数据包为ATM数据包, 则与此对应的条件表达式为真. 对于Solaris 操作系统上的SunATM设备 , 如果数据包为ATM数据包
		并且是来自'元信令线路'并且是Q.2931协议中规定的以下几种消息: Setup, Calling Proceeding, Connect,
		Connect Ack, Release, 或者Release Done. 则与此对应的条件表达式为真.

		expr relop expr
		如果relop 两侧的操作数(expr)满足relop 指定的关系, 则与此对应的条件表达式为真.
		relop 可以是以下关系操作符之一: >, <, <=, =, !=.
		expr 是一个算术表达式. 此表达式中可使用整型常量(表示方式与标准C中一致), 二进制操作符(+, -, *, /, &, |,
		<<, >>), 长度操作符, 以及对特定数据包中数据的引用操作符. 要注意的是, 所有的比较操作都默认操作数是无符号的,
		例如, 0x80000000 和 0xffffffff 都是大于0的(nt: 对于有符号的比较, 按照补码规则, 0xffffffff
		会小于0). 如果要引用数据包中的数据, 可采用以下表达方式:
		proto [expr : size]

		proto 的取值可以是以下取值之一:ether, fddi, tr, wlan, ppp, slip, link, ip, arp, rarp,
		tcp, udp, icmp, ip6 或者 radio. 这指明了该引用操作所对应的协议层.(ether, fddi, wlan,
		tr, ppp, slip and link 对应于数据链路层, radio 对应于802.11(wlan,无线局域网)某些数据包中的附带的
		"radio"头(nt: 其中描述了波特率, 数据加密等信息)).
		要注意的是, tcp, udp 等上层协议目前只能应用于网络层采用为IPv4或IPv6协议的网络(此限制会在tcpdump未来版本中
		进行修改). 对于指定协议的所需数据, 其在包数据中的偏移字节由expr 来指定.

		以上表达中size 是可选的, 用来指明我们关注那部分数据段的长度(nt:通常这段数据
		是数据包的一个域)， 其长度可以是1, 2, 或4个字节. 如果不给定size, 默认是1个字节. 长度操作符的关键字为len,
		这代码整个数据包的长度.

		例如, 'ether[0] & 1 != 0' 将会使tcpdump 抓取所有多点广播数据包.(nt: ether[0]字节的最低位为1表示
		数据包目的地址是多点广播地址). 'ip[0] & 0xf != 5' 对应抓取所有带有选项的
		IPv4数据包. 'ip[6:2] & 0x1fff = 0'对应抓取没被破碎的IPv4数据包或者
		其片段编号为0的已破碎的IPv4数据包. 这种数据检查方式也适用于tcp和udp数据的引用,
		即, tcp[0]对应于TCP 头中第一个字节, 而不是对应任何一个中间的字节.

		一些偏移以及域的取值除了可以用数字也可用名字来表达. 以下为可用的一些域(协议头中的域)的名字: icmptype (指ICMP 协议头
		中type域), icmpcode (指ICMP 协议头code 域), 以及tcpflags(指TCP协议头的flags 域)

		以下为ICMP 协议头中type 域的可用取值:
		icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert,
		icmp-routersolicit, icmp-timx-ceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply,
		icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply.

		以下为TCP 协议头中flags 域的可用取值:tcp-fin, tcp-syn, tcp-rst, tcp-push,
		tcp-ack, tcp-urg.
	-------
	from: http://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html

* 日志切割 access_log文件过大
	- nginx的日志切割
		Nginx产生的日志都是存在一个文件，随着网站运行时间越长，日志文件的大小也在不断增长，这对我们想分析当天日志非常的不方便，
		所以需要每天把日志文件分割出来，并以时间命名。

		创建日志分割脚本

		1、登录SSH，创建cut_logs.sh文件

		vi /root/cut_logs.sh
		2、粘贴下面代码到cut_logs.sh，并保存

		#!/bin/bash
		# The Nginx logs path
		logs_path="/home/wwwlogs/"
		mkdir -p ${logs_path}$(date -d "yesterday" +"%Y")/$(date -d "yesterday" +"%m")/
		mv ${logs_path}www.juzihc.com.log ${logs_path}$(date -d "yesterday" +"%Y")/$(date -d "yesterday" +"%m")/juzihc_$(date -d "yesterday" +"%Y%m%d").log
		kill -USR1 $(cat /usr/local/nginx/logs/nginx.pid)
		3、添加cut_logs.sh执行权限

		chmod +x /root/cut_logs.sh
		设置cut_logs.sh启动时间

		执行命令crontab -e进入编辑状态
		添加如下代码,每天0点01分启动。

		01 00 * * * /root/cut_logs.sh
		这样每天定时分割日志文件就设置成功了。当然如果你担心日志文件占太多空间，还可以执行压缩tar,并设置删除多少天前的日志文件。
		from: http://www.centos.bz/2011/03/split-nginx-logfile-eveyday/
* 站点
	http://www.beej.us/ 技术站点

* Ethernet,internet,intranet,extranet 
	THE INTERNET
	The Internet is a new world. The Internet is not only "The Big Picture," it also offers a global perspective. By providing connectivity to anyone with a computer and a telephone line, 
	the Internet is the networking breakthrough of our lifetime. It includes everything from universal e-mail to transactions between individuals and between companies. Of course, 
	this now includes commerce as well as information exchanges and new directories (such as search engines) that provide phone book-style accessibility for digital communications. 

	Some of the most important results of this networking revolution are new forms of marketing and outreach, new connections between customers and collaborators, new sources 
	for news and research, and opportunities for new kinds of distribution of products (as well as of information). But because the Internet is the broadest information super-highway, 
	it lacks some of the security and privacy that's needed for the internal workings of business organizations. Advanced features like multimedia are also more likely to be limited because 
	most individuals are still using dial-up connections and, as a result, have very limited data bandwidth. 

	INTRANETS
	Intranets are new kinds of internal networks. Think of "Intra" as it is used in Intramural sports. Intranets tend to resemble the architecture of a closed-circuit video network as 
	opposed to the Internet which is more like broadcasting in terms of its reach. Intranets are used for more private communications, connectivity among work groups and larger 
	organizations. For example, some companies use Intranets to offer corporate services such as benefits programs and other kinds of corporate communications. Also, Intranets 
	enable information sharing that empowers employees who might otherwise be left "out of the loop." (See "Groupware" below.) 

	Because of their limited geographic range, Intranets offer more bandwidth, frequently Ethernet's 10Kbps or better. As a result of this bandwidth and the "closed loop" structure, 
	more advanced networking features such as video and multimedia, as well as more technological control, are possible. For example, a company can specify that a specific web 
	browser and even a specific version of that browser (licensed by the company) be used on its network. This enables a consistent and more dependable user experience than is 
	possible on the Internet. Even Internet related services such as Pointcast can be customized for a particular company and its Intranet. 

	EXTRANETS
	Extranets are a more complex implementation of the wired world. Just because an employee is telecommuting doesn't mean she shouldn't have access to the company Intranet. 
	Sales people on the road are just as critical to a corporation's success as those who sit behind desks. And in today's world of virtual work groups, suppliers and other vendors 
	are frequently critical members of the team and they may need an insider's degree of access. Extranet's provide these important networking "bridges" by combining the Internet 
	with the Intranet. 

	By extending the corporate network to include the Internet, team members get the best of both worlds -- mobility with exclusivity. Because of the necessary security involved, 
	Extranets frequently require the development of custom applications. For example, in order to give a remote sales person access to corporate sales statistics, the user needs 
	remote access to a database that cannot be made visible to the competition. Most often, for something this sensitive, encryption is involved because password protection is not sufficient. 

	In most cases, Extranets do not involve high bandwidth applications like video and multimedia because of the limited bandwidth of remote users who most frequently use dial 
	up connections. 

	Ethernet is the most widely-installed local area network ( LAN) technology. Specified in a standard, IEEE 802.3, Ethernet was originally developed by Xerox from an earlier 
	specification called Alohanet (for the Palo Alto Research Center Aloha network) and then developed further by Xerox, DEC, and Intel. An Ethernet LAN typically uses coaxial 
	cable or special grades of twisted pair wires. Ethernet is also used in wireless LANs. The most commonly installed Ethernet systems are called 10BASE-T and provide transmission 
	speeds up to 10 Mbps. Devices are connected to the cable and compete for access using a Carrier Sense Multiple Access with Collision Detection (CSMA/CD ) protocol. 
	Fast Ethernet or 100BASE-T provides transmission speeds up to 100 megabits per second and is typically used for LAN backbone systems, supporting workstations with 
	10BASE-T cards. Gigabit Ethernet provides an even higher level of backbone support at 1000 megabits per second (1 gigabit or 1 billion bits per second). 10-Gigabit Ethernet 
	provides up to 10 billion bits per second. 

	Ethernet was named by Robert Metcalfe, one of its developers, for the passive substance called "luminiferous (light-transmitting) ether" that was once thought to pervade the universe, 
	carrying light throughout. Ethernet was so- named to describe the way that cabling, also a passive medium, could similarly carry data everywhere throughout the network.

* TCP_NODELAY (disable/enable Nagle's algorithm)
	- 介绍
			在网络拥塞控制领域，我们知道有一个非常有名的算法叫做Nagle算法（Nagle algorithm），这是使用它的发明人John Nagle的名字来命名的，
		John Nagle在1984年首次用这个算法来尝试解决福特汽车公司的网络拥塞问题（RFC 896），该问题的具体描述是：如果我们的应用程序一次
		产生1个字节的数据，而这个1个字节数据又以网络数据包的形式发送到远端服务器，那么就很容易导致网络由于太多的数据包而过载。比如，
		当用户使用Telnet连接到远程服务器时，每一次击键操作就会产生1个字节数据，进而发送出去一个数据包，所以，在典型情况下，传送一个只
		拥有1个字节有效数据的数据包，却要发费40个字节长包头（即ip头20字节+tcp头20字节）的额外开销，这种有效载荷（payload）利用率极其低下
		的情况被统称之为愚蠢窗口症候群（Silly Window Syndrome）。可以看到，这种情况对于轻负载的网络来说，可能还可以接受，但是对于重负载的
		网络而言，就极有可能承载不了而轻易的发生拥塞瘫痪。
			针对上面提到的这个状况，Nagle算法的改进在于：如果发送端欲多次发送包含少量字符的数据包（一般情况下，后面统一称长度小于MSS的数据包
		为小包，与此相对，称长度等于MSS的数据包为大包，为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS的包），则发送端会
		先将第一个小包发送出去，而将后面到达的少量字符数据都缓存起来而不立即发送，直到收到接收端对前一个数据包报文段的ACK确认、或当前字符
		属于紧急数据，或者积攒到了一定数量的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）等多种情况才将其组成一个较大的数据包
		发送出去，具体有哪些情况，我们来看看内核实现：
		from: http://bbs.chinaunix.net/thread-3767363-1-1.html

	- channel.socket().setTcpNoDelay(true);
	
* Servlet
	- servlet3.0异步支持
		------------
		异步处理支持
			Servlet 3.0 之前，一个普通 Servlet 的主要工作流程大致如下：首先，Servlet 接收到请求之后，可能需要对请求携带的数据进行一些预处理；接着，
		调用业务接口的某些方法，以完成业务处理；最后，根据处理的结果提交响应，Servlet 线程结束。其中第二步的业务处理通常是最耗时的，这主要体现在数据库操作，
		以及其它的跨网络调用等，在此过程中，Servlet 线程一直处于阻塞状态，直到业务方法执行完毕。在处理业务的过程中，Servlet 资源一直被占用而得不到释放，
		对于并发较大的应用，这有可能造成性能的瓶颈。对此，在以前通常是采用私有解决方案来提前结束 Servlet 线程，并及时释放资源。
			Servlet 3.0 针对这个问题做了开创性的工作，现在通过使用 Servlet 3.0 的异步处理支持，之前的 Servlet 处理流程可以调整为如下的过程：首先，Servlet 接收到请求
		之后，可能首先需要对请求携带的数据进行一些预处理；接着，Servlet 线程将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，此时 Servlet 还没有
		生成响应数据，异步线程处理完业务以后，可以直接生成响应数据（异步线程拥有 ServletRequest 和 ServletResponse 对象的引用），或者将请求继续转发给其它 Servlet。
		如此一来， Servlet 线程不再是一直处于阻塞状态以等待业务逻辑的处理，而是启动异步线程之后可以立即返回。
			异步处理特性可以应用于 Servlet 和过滤器两种组件，由于异步处理的工作模式和普通工作模式在实现上有着本质的区别，因此默认情况下，Servlet 和过滤器并没有
		开启异步处理特性，如果希望使用该特性，则必须按照如下的方式启用：
			对于使用传统的部署描述文件 (web.xml) 配置 Servlet 和过滤器的情况，Servlet 3.0 为 <servlet> 和 <filter> 标签增加了 <async-supported> 子标签，该标签的默认取值为 false，
		要启用异步处理支持，则将其设为 true 即可。以 Servlet 为例，其配置方式如下所示：
		<servlet> 
		    <servlet-name>DemoServlet</servlet-name> 
		    <servlet-class>footmark.servlet.Demo Servlet</servlet-class> 
		    <async-supported>true</async-supported> 
		</servlet> 

		对于使用 Servlet 3.0 提供的 @WebServlet 和 @WebFilter 进行 Servlet 或过滤器配置的情况，这两个注解都提供了 asyncSupported 属性，默认该属性的取值为 false，
		要启用异步处理支持，只需将该属性设置为 true 即可。以 @WebFilter 为例，其配置方式如下所示：
		@WebFilter(urlPatterns = "/demo",asyncSupported = true) 
		public class DemoFilter implements Filter{...} 

		一个简单的模拟异步处理的 Servlet 示例如下：
		@WebServlet(urlPatterns = "/demo", asyncSupported = true)
		public class AsyncDemoServlet extends HttpServlet {
		    @Override
		    public void doGet(HttpServletRequest req, HttpServletResponse resp)
		    throws IOException, ServletException {
			resp.setContentType("text/html;charset=UTF-8");
			PrintWriter out = resp.getWriter();
			out.println("进入Servlet的时间：" + new Date() + ".");
			out.flush();

			//在子线程中执行业务调用，并由其负责输出响应，主线程退出
			AsyncContext ctx = req.startAsync();
			new Thread(new Executor(ctx)).start();

			out.println("结束Servlet的时间：" + new Date() + ".");
			out.flush();
		    }
		}

		public class Executor implements Runnable {
		    private AsyncContext ctx = null;
		    public Executor(AsyncContext ctx){
			this.ctx = ctx;
		    }

		    public void run(){
			try {
			    //等待十秒钟，以模拟业务方法的执行
			    Thread.sleep(10000);
			    PrintWriter out = ctx.getResponse().getWriter();
			    out.println("业务处理完毕的时间：" + new Date() + ".");
			    out.flush();
			    ctx.complete();
			} catch (Exception e) {
			    e.printStackTrace();
			}
		    }
		}

		除此之外，Servlet 3.0 还为异步处理提供了一个监听器，使用 AsyncListener 接口表示。它可以监控如下四种事件：
		异步线程开始时，调用 AsyncListener 的 onStartAsync(AsyncEvent event) 方法；
		异步线程出错时，调用 AsyncListener 的 onError(AsyncEvent event) 方法；
		异步线程执行超时，则调用 AsyncListener 的 onTimeout(AsyncEvent event) 方法；
		异步执行完毕时，调用 AsyncListener 的 onComplete(AsyncEvent event) 方法；
		要注册一个 AsyncListener，只需将准备好的 AsyncListener 对象传递给 AsyncContext 对象的 addListener() 方法即可，如下所示：
		AsyncContext ctx = req.startAsync(); 
		ctx.addListener(new AsyncListener() { 
		    public void onComplete(AsyncEvent asyncEvent) throws IOException { 
			// 做一些清理工作或者其他
		    } 
		    ... 
		}); 

		...

		@MultipartConfig
		该注解主要是为了辅助 Servlet 3.0 中 HttpServletRequest 提供的对上传文件的支持。该注解标注在 Servlet 上面，以表示该 Servlet 希望处理的请求的 MIME 类型
		是 multipart/form-data。另外，它还提供了若干属性用于简化对上传文件的处理。具体如下：

		表 5. @MultipartConfig 的常用属性
		属性名	类型	是否可选	描述
		fileSizeThreshold	int	是	当数据量大于该值时，内容将被写入文件。
		location	String	是	存放生成的文件地址。
		maxFileSize	long	是	允许上传的文件最大值。默认值为 -1，表示没有限制。
		maxRequestSize	long	是	针对该 multipart/form-data 请求的最大数量，默认值为 -1，表示没有限制。

		可插性支持
			如果说 3.0 版本新增的注解支持是为了简化 Servlet/ 过滤器 / 监听器的声明，从而使得 web.xml 变为可选配置， 那么新增的可插性 (pluggability) 支持则将 Servlet 配置
		的灵活性提升到了新的高度。熟悉 Struts2 的开发者都知道，Struts2 通过插件的形式提供了对包括 Spring 在内的各种开发框架的支持，开发者甚至可以自己为 Struts2 
		开发插件，而 Servlet 的可插性支持正是基于这样的理念而产生的。使用该特性，现在我们可以在不修改已有 Web 应用的前提下，只需将按照一定格式打成的 JAR 包
		放到 WEB-INF/lib 目录下，即可实现新功能的扩充，不需要额外的配置。
			Servlet 3.0 引入了称之为“Web 模块部署描述符片段”的 web-fragment.xml 部署描述文件，该文件必须存放在 JAR 文件的 META-INF 目录下，该部署描述文件可以
		包含一切可以在 web.xml 中定义的内容。JAR 包通常放在 WEB-INF/lib 目录下，除此之外，所有该模块使用的资源，包括 class 文件、配置文件等，只需要能够
		被容器的类加载器链加载的路径上，比如 classes 目录等。
			现在，为一个 Web 应用增加一个 Servlet 配置有如下三种方式 ( 过滤器、监听器与 Servlet 三者的配置都是等价的，故在此以 Servlet 配置为例进行讲述，过滤器和监听器
		具有与之非常类似的特性 )：
			编写一个类继承自 HttpServlet，将该类放在 classes 目录下的对应包结构中，修改 web.xml，在其中增加一个 Servlet 声明。这是最原始的方式；
			编写一个类继承自 HttpServlet，并且在该类上使用 @WebServlet 注解将该类声明为 Servlet，将该类放在 classes 目录下的对应包结构中，无需修改 web.xml 文件。
			编写一个类继承自 HttpServlet，将该类打成 JAR 包，并且在 JAR 包的 META-INF 目录下放置一个 web-fragment.xml 文件，该文件中声明了相应的 Servlet 配置。
			web-fragment.xml 文件示例如下：
		<?xml version="1.0" encoding="UTF-8"?>
		<web-fragment 
		    xmlns=http://java.sun.com/xml/ns/javaee
		    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="3.0"
		    xsi:schemaLocation="http://java.sun.com/xml/ns/javaee
		    http://java.sun.com/xml/ns/javaee/web-fragment_3_0.xsd"
		    metadata-complete="true">
		    <servlet>
			<servlet-name>fragment</servlet-name>
			<servlet-class>footmark.servlet.FragmentServlet</servlet-class>
		    </servlet>
		    <servlet-mapping>
			<servlet-name>fragment</servlet-name>
			<url-pattern>/fragment</url-pattern>
		    </servlet-mapping>
		</web-fragment>

		从上面的示例可以看出，web-fragment.xml 与 web.xml 除了在头部声明的 XSD 引用不同之外，其主体配置与 web.xml 是完全一致的。
			由于一个 Web 应用中可以出现多个 web-fragment.xml 声明文件，加上一个 web.xml 文件，加载顺序问题便成了不得不面对的问题。Servlet 规范的专家组
		在设计的时候已经考虑到了这个问题，并定义了加载顺序的规则。
			web-fragment.xml 包含了两个可选的顶层标签，<name> 和 <ordering>，如果希望为当前的文件指定明确的加载顺序，通常需要使用这两个标签，<name> 主要
		用于标识当前的文件，而 <ordering> 则用于指定先后顺序。一个简单的示例如下：
		<web-fragment...>
		    <name>FragmentA</name>
		    <ordering>
			<after>
			    <name>FragmentB</name>
			    <name>FragmentC</name>
			</after>
		    <before>
			<others/>
		    </before>
		    </ordering>
		    ...
		</web-fragment>

		如上所示， <name> 标签的取值通常是被其它 web-fragment.xml 文件在定义先后顺序时引用的，在当前文件中一般用不着，它起着标识当前文件的作用。
			在 <ordering> 标签内部，我们可以定义当前 web-fragment.xml 文件与其他文件的相对位置关系，这主要通过 <ordering> 的 <after> 和 <before> 子标签来实现的。
		在这两个子标签内部可以通过 <name> 标签来指定相对应的文件。比如：
		<after> 
		    <name>FragmentB</name> 
		    <name>FragmentC</name> 
		</after> 

		以上片段则表示当前文件必须在 FragmentB 和 FragmentC 之后解析。<before> 的使用于此相同，它所表示的是当前文件必须早于 <before> 标签里所列出的 web-fragment.xml 文件。
			除了将所比较的文件通过 <name> 在 <after> 和 <begin> 中列出之外，Servlet 还提供了一个简化的标签 <others/>。它表示除了当前文件之外的其他
		所有的 web-fragment.xml 文件。该标签的优先级要低于使用 <name> 明确指定的相对位置关系。

		ServletContext 的性能增强
			除了以上的新特性之外，ServletContext 对象的功能在新版本中也得到了增强。现在，该对象支持在运行时动态部署 Servlet、过滤器、监听器，
			以及为 Servlet 和过滤器增加 URL 映射等。以 Servlet 为例，过滤器与监听器与之类似。ServletContext 为动态配置 Servlet 增加了如下方法：
			ServletRegistration.Dynamic addServlet(String servletName,Class<? extends Servlet> servletClass)
			ServletRegistration.Dynamic addServlet(String servletName, Servlet servlet)
			ServletRegistration.Dynamic addServlet(String servletName, String className)
			<T extends Servlet> T createServlet(Class<T> clazz)
			ServletRegistration getServletRegistration(String servletName)
			Map<String,? extends ServletRegistration> getServletRegistrations()
			其中前三个方法的作用是相同的，只是参数类型不同而已；通过 createServlet() 方法创建的 Servlet，通常需要做一些自定义的配置，然后使用 addServlet() 方法
		来将其动态注册为一个可以用于服务的 Servlet。两个 getServletRegistration() 方法主要用于动态为 Servlet 增加映射信息，这等价于在 web.xml( 抑或 web-fragment.xml) 
		中使用 <servlet-mapping> 标签为存在的 Servlet 增加映射信息。
			以上 ServletContext 新增的方法要么是在 ServletContextListener 的 contexInitialized 方法中调用，要么是在 ServletContainerInitializer 的 onStartup() 方法中调用。
			ServletContainerInitializer 也是 Servlet 3.0 新增的一个接口，容器在启动时使用 JAR 服务 API(JAR Service API) 来发现 ServletContainerInitializer 的实现类，
		并且容器将 WEB-INF/lib 目录下 JAR 包中的类都交给该类的 onStartup() 方法处理，我们通常需要在该实现类上使用 @HandlesTypes 注解来指定希望被处理的类，
		过滤掉不希望给 onStartup() 处理的类。

		HttpServletRequest 对文件上传的支持
			此前，对于处理上传文件的操作一直是让开发者头疼的问题，因为 Servlet 本身没有对此提供直接的支持，需要使用第三方框架来实现，
		而且使用起来也不够简单。如今这都成为了历史，Servlet 3.0 已经提供了这个功能，而且使用也非常简单。为此，HttpServletRequest 提供了
		两个方法用于从请求中解析出上传的文件：
		Part getPart(String name)
		Collection<Part> getParts()
		前者用于获取请求中给定 name 的文件，后者用于获取所有的文件。每一个文件用一个 javax.servlet.http.Part 对象来表示。该接口提供了处理文件的简易方法，
		比如 write()、delete() 等。至此，结合 HttpServletRequest 和 Part 来保存上传的文件变得非常简单，如下所示：
		Part photo = request.getPart("photo"); 
		photo.write("/tmp/photo.jpg"); 
		// 可以将两行代码简化为 request.getPart("photo").write("/tmp/photo.jpg") 一行。

			另外，开发者可以配合前面提到的 @MultipartConfig 注解来对上传操作进行一些自定义的配置，比如限制上传文件的大小，以及保存文件的路径等。
		其用法非常简单，故不在此赘述了。
		需要注意的是，如果请求的 MIME 类型不是 multipart/form-data，则不能使用上面的两个方法，否则将抛异常。

		总结
			Servlet 3.0 的众多新特性使得 Servlet 开发变得更加简单，尤其是异步处理特性和可插性支持的出现，必将对现有的 MVC 框架产生深远影响。
		虽然我们通常不会自己去用 Servlet 编写控制层代码，但是也许在下一个版本的 Struts 中，您就能切实感受到这些新特性带来的实质性改变。
		------------
		from: http://www.ibm.com/developerworks/cn/java/j-lo-servlet30/index.html?ca=drs-cn-0423	Servlet 3.0 新特性详解

	- The Java Servlet API v.3.0 is a required API of the Java Platform, Enterprise Edition,v.61.
		servlet是javaee的一部分
	- servlet处理流程
		--------
		1) A client (e.g., a Web browser) accesses a Web server and makes an HTTP request.
		2) The request is received by the Web server and handed off to the servlet container.
		The servlet container can be running in the same process as the host Web server,
		in a different process on the same host, or on a different host from the Web server
		for which it processes requests.
		3) The servlet container determines which servlet to invoke based on the
		configuration of its servlets, and calls it with objects representing the request and
		response.
		4) The servlet uses the request object to find out who the remote user is, what HTTP
		POST parameters may have been sent as part of this request, and other relevant
		data. The servlet performs whatever logic it was programmed with, and generates
		data to send back to the client. It sends this data back to the client via the
		response object.
		5) Once the servlet has finished processing the request, the servlet container ensures
		that the response is properly flushed, and returns control back to the host Web
		server.
		--------
		from: servlet-3_0-final-spec

	- Java Servlet Technology Overview
	------------------------------------
	Servlets are the Java platform technology of choice for extending and enhancing Web servers. Servlets provide a component-based, platform-independent method for building 
	Web-based applications, without the performance limitations of CGI programs. And unlike proprietary server extension mechanisms (such as the Netscape Server API or Apache modules), 
	servlets are server- and platform-independent. This leaves you free to select a "best of breed" strategy for your servers, platforms, and tools. 

	Servlets have access to the entire family of Java APIs, including the JDBC API to access enterprise databases. Servlets can also access a library of HTTP-specific calls and receive 
	all the benefits of the mature Java language, including portability, performance, reusability, and crash protection. 

	Today servlets are a popular choice for building interactive Web applications. Third-party servlet containers are available for Apache Web Server, Microsoft IIS, and others. Servlet 
	containers are usually a component of Web and application servers, such as BEA WebLogic Application Server, IBM WebSphere, Sun Java System Web Server, Sun Java System 
	Application Server, and others. 

	You might want to check out the latest information on JavaServer Pages (JSP) technology. JSP technology is an extension of the servlet technology created to support authoring of HTML 
	and XML pages. It makes it easier to combine fixed or static template data with dynamic content. Even if you're comfortable writing servlets, there are several compelling reasons to investigate 
	JSP technology as a complement to your existing work.
	------------------------------------
	from: oracle website

	PS: Servlet是一个规范，定义了一个提供web服务的描述，内部有多个部分的定义，其中servlet是其中一个构件，接收上层包装好的对象来处理，并调用业务逻辑，然后输出（还会经过
	规范定义的其他部分，比如Filter等，可以看servlet API规范）

	- 
	------
	A servlet is a Java™ technology-based Web component, managed by a container,
	that generates dynamic content. Like other Java technology-based components,
	servlets are platform-independent Java classes that are compiled to platform-neutral
	byte code that can be loaded dynamically into and run by a Java technology-enabled
	Web server. Containers, sometimes called servlet engines, are Web server extensions
	that provide servlet functionality. Servlets interact with Web clients via a
	request/response paradigm implemented by the servlet container.
	------
	from: servlet-3_0-final-spec
	PS: Servlet通过规范定义的request/response paradigm与servlet容器交互，容器负责连接接收和相应，servlet负责逻辑

* java
	- java路径，类路径，相对路径，绝对路径
		this.getClass().getClassLoader().getResource("//").getPath() 获取类路径，即classes所在路径
		参考：
		-----
		 J2EE项目相对路径、绝对路径获取

		servletstringtreejspwebpath
		　　在写java程序时不可避免要获取文件的路径…总结一下，遗漏的随时补上

		　　1.可以在servlet的init方法里

		　　String path = getServletContext()。getRealPath("/");

		　　这将获取web项目的全路径

		　　例如 :E:\eclipseM9\workspace\tree\

		　　tree是我web项目的根目录

		　　2.你也可以随时在任意的class里调用

		　　this.getClass()。getClassLoader()。getResource("/")。getPath();

		　　这将获取 到classes目录的全路径

		　　例如 : E:\eclipseM9/workspace/tree/WEB-INF/classes/

		　　这个方法也可以不在web环境里确定路径，比较好用

		　　3.request.getContextPath();

		　　获得web根的上下文环境

		　　如 /tree

		　　tree是我的web项目的root context

		　　1. 可以在servlet的init方法里

		　　String path = getServletContext()。getRealPath("/");

		　　这将获取web项目的全路径

		　　例如 :E:\eclipseM9\workspace\tree\

		　　tree是我web项目的根目录

		　　2

		　　jsp 获取文件路径

		　　2008-08-06 16:57

		　　<%@ page contentType="text/html; charset=gb2312" language="java" import="java.io.*" errorPage="" %>


		　　当前WEB应用的物理路径：<%=application.getRealPath("/")%>
		　　当前你求请的JSP文件的物理路径：<%=application.getRealPath(request.getRequestURI())%>
		　　<%

		　　String path=application.getRealPath(request.getRequestURI());

		　　String dir=new File(path)。getParent();

		　　out.println("当前JSP文件所在目录的物理路径"+dir);

		　　%>

		　　String virtPath = request.getServletPath();//虚拟路径

		　　String realPath = request.getRealPath(virtPath);//物理路径

		　　JSP中获得当前应用的相对路径和绝对路径

		　　根目录所对应的绝对路径：request.getRequestURI()

		　　文件的绝对路径 :application.getRealPath(request.getRequestURI());

		　　当前web应用的绝对路径 :application.getRealPath("/");

		　　取得请求文件的上层目录：new File(application.getRealPath(request.getRequestURI()))。getParent()

		　　Servlet中获得当前应用的相对路径和绝对路径

		　　根目录所对应的绝对路径：request.getServletPath();

		　　文件的绝对路径 :request.getSession()。getServletContext()。getRealPath

		　　(request.getRequestURI())

		　　当前web应用的绝对路径 :servletConfig.getServletContext()。getRealPath("/");

		　　(ServletContext对象获得几种方式：

		　　Javax.servlet.http.HttpSession.getServletContext()

		　　Javax.servlet.jsp.PageContext.getServletContext()

		　　Javax.servlet.ServletConfig.getServletContext()

		　　)
		-----
		from: http://blog.csdn.net/icecream0/article/details/7387622

	- javaee servet技术中的Filter
		 javax.servlet.Filter
		 DOC
		 --------------------


		A filter is an object that performs filtering tasks on either the request to a resource (a servlet or static content), or on the response from a resource, or both. 

		Filters perform filtering in the doFilter method. Every Filter has access to * a FilterConfig object from which it can obtain its initialization parameters, a * reference to the ServletContext which it can use, for example, to load resources * needed for filtering tasks. * 

		* Filters are configured in the deployment descriptor of a web application * 

		* Examples that have been identified for this design are
		* 1) Authentication Filters 
		* 2) Logging and Auditing Filters 
		* 3) Image conversion Filters 
		* 4) Data compression Filters 
		* 5) Encryption Filters 
		* 6) Tokenizing Filters 
		* 7) Filters that trigger resource access events 
		* 8) XSL/T filters 
		* 9) Mime-type chain Filter 
		--------------------

	- java se tutorial jdk tutorial
		ref: http://docs.oracle.com/javase/specs/jls/se5.0/html/j3TOC.html

	- 接口中定义的方法都为抽象方法，若不显示声明abstract，编译器会加上；接口是一种特殊的抽象类；
	- 注释DOC
		链接
		/**
		 *@see <a href="https://weblogs.java.net/blog/2007/11/27/consistent-hashing">consistent-hashing</a>
		 */
		
		引用
		 * @see {@link ChunkedOutputStream} and {@link ChunkedInputStream}
		 <br>
		 <p>
		 etc
		
		 预定义格式，带边框
			 * <pre style="border:solid thin; padding: 1ex;"
			 * > Object obj = <code style="color:#00C">null</code>;
			 * Object key = <code style="color:#C00">"Key"</code>;
			 *
			 * <code style="color:#00C">try</code> {
			 *     obj = pool.borrowObject(key);
			 *     <code style="color:#0C0">//...use the object...</code>
			 * } <code style="color:#00C">catch</code>(Exception e) {
			 *     <code style="color:#0C0">// invalidate the object</code>
			 *     pool.invalidateObject(key, obj);
			 *     <code style="color:#0C0">// do not return the object to the pool twice</code>
			 *     obj = <code style="color:#00C">null</code>;
			 * } <code style="color:#00C">finally</code> {
			 *     <code style="color:#0C0">// make sure the object is returned to the pool</code>
			 *     <code style="color:#00C">if</code>(<code style="color:#00C">null</code> != obj) {
			 *         pool.returnObject(key, obj);
			 *     }
			 * }</pre>

* java 数组 tomact nio实现
	pollers = new Poller[getPollerThreadCount()];
	pollers[i] = new Poller();		
* java assert jdk1.4
	源自：sun.nio.ch.WindowsSelectorImpl类的implDereg方法，判断： assert (i >= 0);

	 J2SE 1.4在语言上提供了一个新特性，就是assertion功能，它是该版本在Java语言方面最大的革新。 
	 从理论上来说，通过 assertion方式可以证明程序的正确性，但是这是一项相当复杂的工作，目前还没有太多的实践意义。 
	 在实现中，assertion就是在程序中的一条语句，它对一个boolean表达式进行检查，一个正确程序必须保证这个boolean表达式的值为true；如果该值为false，
	 说明程序已经处于不正确的状态下，系统将给出警告或退出。一般来说，assertion用于保证程序最基本、关键的正确性。assertion检查通常在开发和测试时开启。
	 为了提高性能，在软件发布后，assertion检查通常是关闭的。
	 <p>
	 参数 -esa和 -dsa：<br>
	 
	 它们含义为开启(关闭)系统类的assertion功能。由于新版本的Java的系统类中，也使了assertion语句，因此如果用户需要观察它们的运行情况，
	 就需要打开系统类的assertion功能 ，我们可使用-esa参数打开，使用 -dsa参数关闭。 -esa和-dsa的全名为-enablesystemassertions和
	 -disenablesystemassertions，全名和缩写名有同样的功能。
	 <p>
	 参数 -ea和 -ea：<br>
	 
	 它们含义为开启(关闭)用户类的assertion功能：通过这个参数，用户可以打开某些类或包的assertion功能，同样用户也可以关闭某些类和包的assertion功能。
	 打开assertion功能参数为-ea;如果不带任何参数，表示打开所有用户类;如果带有包名称或者类名称，表示打开这些类或包;如果包名称后面跟有三个点，代表这个包及其子包;
	 如果只有三个点，代表无名包。关闭assertion功能参数为-da，使用方法与-ea类似。
	 -ea和-da的全名为-enableassertions和-disenableassertions，全名和缩写名有同样的功能。
	 下面表格表示了参数及其含义，并有例子说明如何使用。
	 -ea java -ea 打开所有用户类的assertion
	 <p>
	 EG:<br>
	   java -dsa:MyClass1:pkg1 关闭MyClass1和pkg1包的assertion 
	   java -esa:MyClass1:pkg1 开启MyClass1和pkg1包的assertion 
	   
	   java -da:MyClass1:pkg1 关闭MyClass1和pkg1包的assertion 
	   java -ea:MyClass1:pkg1 开启MyClass1和pkg1包的assertion 
	 
	 From: http://zhidao.baidu.com/question/355255108.html
* Paxos	分布式选举算法	Paxos最大的用途就是保持多个节点数据的一致性
	- 
	paxos 实现
	from: http://rdc.taobao.com/blog/cs/?p=162

	http://www.spnguru.com/2010/08/zookeeper%E5%85%A8%E8%A7%A3%E6%9E%90%E2%80%94%E2%80%94paxos%E7%9A%84%E7%81%B5%E9%AD%82/?spm=0.0.0.0.loG8SU

	- google chubby
		-----
			一般来说，一个Chubby cell由五台server组成，可以支持一整个数据中心的上万台机器的lock service。cell中的每台server我们称之为replicas（副本）。

			当 Chubby工作的时候，首先它需要从这些replicas中选举出一个master。注意，这其实也是一个distributed consensus problem，也就是说Chubby也存在着
		分布式的一致性问题。Chubby是通过采用consensus protocol（很可能就是Paxos算法）来解决这个问题的。所以，Chubby的client用Chubby提供的lock service
		来解决一致性问题，而Chubby系统内部的一致性问题则是用consensus protocol解决的。

			每个master都具有一定的期限，成为master lease。在这个期限中，副本们不会再选举一个其它的master。

			为 了安全性和容错的考虑，所有的replicas（包括master）都维护的同一个DB的拷贝。但是，只有master能够接受client提交的操作对 DB进行读和写，
		而其它的replicas只是和master进行通信来update它们各自的DB。所以，一旦一个master被选举出来后，所有的 client端都之和master进行通信（如图所示），
		如果是读操作，那么master一台机器就搞定了，如果是写操作，master会通知其它的 replicas进行update。这样的话，一旦master意外停机，那么其它的replicas
		也能够很快的选举出另外一个master。
		....
		最后谈谈client与cell的交互部分

		这里大致包含两部分的内容：cache的同步机制和KeepAlive握手协议。

			为 了降低client和cell之间通信的压力和频率，client在本地会保存一个和自己相关的Chubby文件的cache。例如如果client通过 Chubby library在cell上创建了一个文件，
		那么在client本地，也会有一个相同的文件在cache中创建，这个cache中的文件的内容和cell 上文件的内容是一样的。这样的话，client如果想访问这个文件，就可以
		直接访问本地的cache而不通过网络去访问cell。
		
			cache有两个状态，有效和无效。当 有一个client要改变某个File的时候，整个修改会被master block，然后master会发送无效标志给所有cache了这个数据的client
		（它维护了这么一个表），当其它client端收到这个无效标志 后，就会将cache中的状态置为无效，然后返回一个acknowledge；当master确定收到了所有的acknowledge
		之后，才完成整个 modification。

			需要注意的是，master并不是发送update给client而是发送无效标志给client。这是因为如果发送update给client，那么每 一次数据的修改都需要发送一大堆的update，
		而发送无效标示的话，对一个数据的很多次修改只需要发送一个无效标示，这样大大降低了通信量。

			至于KeepAlive协议，则是为了保证client和master随时都保持着联系。client和master每隔一段时间就会KeepAlive 一次，这样的话，如果master意外停机，client
		可以很快的知道这个消息，然后迅速的转移到新的master上。并且，这种转移对于client 端的application是透明的，也就是说application并不会知道master发生了错误。
		关于cache和KeepAlive还有很多的 细节，想了解的读文献[1]吧。
		-----
		http://blog.csdn.net/historyasamirror/article/details/3870168	Google利器之Chubby
		PS: keepalive处理心跳部分，保证节点的上下线和服务器的上下线能即时通知需要知道的角色

	- 介绍
			Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，
		每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法
		”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的
		研究就没有停止过。节点通信存在两种模型：共享内存（Shared memory）和消息传递（Messages passing）。Paxos 算法就是一种基于消息传递模型的一致性算法。

			不仅只用在分布式系统，凡是多个过程需要达成某种一致性的都可以用到Paxos 算法。一致性方法可以通过共享内存（需要锁）或者消息传递实现，
		Paxos 算法采用的是后者。下面是Paxos 算法适用的几种情况：一台机器中多个进程/线程达成数据一致；分布式文件系统或者分布式数据库中多客户端并发读写数据；
		分布式存储中多个副本响应读写请求的一致性。

			Lamport 最初Paxos 算法的论文The Part-Time Parliament 在理解起来比较有挑战性，个人认为部分原因是Lamport 通过故事的方式来表述、解释这个问题，所以在阅读文章
		的时候读者需要透过故事讲的本身看到作者想说明什么。比如文章中会有很多讲到Paxon 文明没有被发现和考证的，这些映射到实际系统中往往是简单、大家都
		心知肚明的基础，但如果读者苦于想知道这些内容是什么时，就上当了。下面章节安排如下：第二节对应原文的1.1-2.1。第三节对应原文2.2-3.2。[1]
	- ZooKeeper并不是遵循Paxos协议，而是基于自身设计并优化的一个2 phase commit的协议
		因此它的理论[6]并未经过完全证明。但由于ZooKeeper在Yahoo!内部已经成功应用在HBase, Yahoo! Message Broker, Fetch Service of Yahoo! crawler等系统上，
		因此完全可以放心采用。
		from: http://www.cnblogs.com/ychellboy/archive/2009/12/28/1634443.html

* 线程协作 wait&notify wait notify wait()
	使用wait()与notify()/notifyAll()可以使得多个任务之间彼此协作。
	1) wait()与notify()/notifyAll()
		调用sleep()和yield()的时候锁并没有被释放，而调用wait()将释放锁。这样另一个任务（线程）可以获得当前对象的锁，从而进入它的synchronized方法中。
	可以通过notify()/notifyAll()，或者时间到期，从wait()中恢复执行。
		只能在同步控制方法或同步块中调用wait()、notify()和notifyAll()。如果在非同步的方法里调用这些方法，在运行时会抛出IllegalMonitorStateException异常。
		因为，必须取到对象锁才能调用上面的方法，notify()方法说明如下：
		----
		This method should only be called by a thread that is the owner of this object's monitor. A thread becomes the owner of the object's monitor in one of three ways: 

		By executing a synchronized instance method of that object. 执行对象的同步方法
		By executing the body of a synchronized statement that synchronizes on the object. 执行对象中同步块中的语句
		For objects of type Class, by executing a synchronized static method of that class. 执行对象所属类的静态同步方法时

		Only one thread at a time can own an object's monitor.  在任一时刻，只能有一个线程拥有对象的锁
		----

	2) 模拟单个线程对多个线程的唤醒
		模拟线程之间的协作。Game类有2个同步方法prepare()和go()。标志位start用于判断当前线程是否需要wait()。Game类的实例首先启动所有的Athele类实例，
	使其进入wait()状态，在一段时间后，改变标志位并notifyAll()所有处于wait状态的Athele线程。
	ref: http://zhangjunhd.blog.51cto.com/113473/71387/

	3) Java多线程sleep(),join(),interrupt(),wait(),notify()
	关于Java多线程知识可以看看《Thinking in Java 》中的多线程部分和《Java网络编程》中第5章多线程的部分

	以下是参考<<Java多线程模式>>的 
	(1). sleep() & interrupt() 
	    线程A正在使用sleep()暂停着: Thread.sleep(100000); 
	    如果要取消他的等待状态,可以在正在执行的线程里(比如这里是B)调用 
		a.interrupt(); 
	    令线程A放弃睡眠操作,这里a是线程A对应到的Thread实例 
	    执行interrupt()时,并不需要获取Thread实例的锁定.任何线程在任何时刻,都可以调用其他线程interrupt().当sleep中的线程被调用interrupt()时,就会放弃暂停的状态.
	    并抛出InterruptedException.丢出异常的,是A线程. 

	(2). wait() & interrupt() 
	    线程A调用了wait()进入了等待状态,也可以用interrupt()取消. 
	    不过这时候要小心锁定的问题.线程在进入等待区,会把锁定解除,当对等待中的线程调用interrupt()时(注意是等待的线程调用其自己的interrupt()),会先重新获取锁定,再抛出异常.
	    在获取锁定之前,是无法抛出异常的. 

	(3). join() & interrupt() 		PS: join当前线程执行过程中，join进来另外一个线程，等待加进来这个线程执行完毕，再继续执行当前线程任务 * join()
	    当线程以join()等待其他线程结束时,一样可以使用interrupt()取消之.因为调用join()不需要获取锁定,故与sleep()时一样,会马上跳到catch块里. 注意是随调用interrupt()方法,一定是
	    阻塞的线程来调用其自己的interrupt方法.如在线程a中调用来线程t.join().则a会等t执行完后在执行t.join后的代码,当在线程b中调用来a.interrupt()方法,则会抛出InterruptedException

	4. interrupt()只是改变中断状态而已 
	    interrupt()不会中断一个正在运行的线程。这一方法实际上完成的是，在线程受到阻塞时抛出一个中断信号，这样线程就得以退出阻塞的状态。更确切的说，如果线程被
	    Object.wait, Thread.join和Thread.sleep三种方法之一阻塞，那么，它将接收到一个中断异常（InterruptedException），从而提早地终结被阻塞状态。 
	    如果线程没有被阻塞，这时调用interrupt()将不起作用；否则，线程就将得到异常（该线程必须事先预备好处理此状况），接着逃离阻塞状态。 
	    线程A在执行sleep,wait,join时,线程B调用A的interrupt方法,的确这一个时候A会有InterruptedException异常抛出来.但这其实是在sleep,wait,join这些方法内部会不断检查中断状态的值,
	    而自己抛出的InterruptedException。 
	    如果线程A正在执行一些指定的操作时如赋值,for,while,if,调用方法等,都不会去检查中断状态,所以线程A不会抛出InterruptedException,而会一直执行着自己的操作.当线程A终于执行
	    到wait(),sleep(),join()时,才马上会抛出InterruptedException. 
	    若没有调用sleep(),wait(),join()这些方法,或是没有在线程里自己检查中断状态自己抛出InterruptedException的话,那InterruptedException是不会被抛出来的. 

	顺便加个与Thread.sleep()相同效果的代码: 
	public static void amethod(long x) throws InterruptedExcetion{ 
	    if (x != 0) { 
		Object o = new Object(); 
		synchronized (o) { 
		    o.wait(x); 
		} 
	    } 
	} 
	ref: http://www.blogjava.net/fhtdy2004/archive/2009/06/08/280728.html Java多线程sleep(),join(),interrupt(),wait(),notify()



* 动名词
	network networking
	ref: http://baike.baidu.com/view/26625.htm
* OpenGrok
	OpenGrok is a source code search and cross reference engine. It helps programmers to search, cross-reference and navigate source code trees.
	It can understand various program file formats and version control histories like Monotone, SCCS, RCS, CVS, Subversion, Mercurial, Git, Clearcase and Bazaar.[1]
	The name comes from the term grok, a jargon term used in computing to mean "profoundly understand".
	OpenGrok is being developed mainly by Oracle Corporation (former Sun Microsystems) engineers with help from its community. OpenGrok is released under the terms of the Common Development and Distribution License (CDDL).
* web爬虫
	- heritrix http://sourceforge.net/projects/archive-crawle
	下载
	解压
	配置环境变量
		% export HERITRIX_HOME=/PATH/TO/BUILT/HERITRIX
	执行
		% chmod u+x $HERITRIX_HOME/bin/heritrix
		% $HERITRIX_HOME/bin/heritrix --help
	[admin@pangu_master.3]$sh bin/heritrix --admin=admin:123
	Wed Apr 10 14:32:20 CST 2013 Starting heritrix.....
	Heritrix 1.14.4 is running.
	Web console is at: http://127.0.0.1:8080
	Web console login and password: admin/123

	设置JMX需要的password文件密码
	/etc/hosts文件要ok，否则报：Local host name unknown: java.net.UnknownHostException: pangu_master.3: pangu_master.3
		
* hibernate
	复习
	一级缓存，session缓存，持久化层对象的缓存
		待补充？
	二级缓存，查询缓存，可以用第三方的缓存实现
		待补充？

* JDK
	1.6
		JDK1.6的新特性集中在网络操作和性能方面方面。如增加了对WebService的支持、线程调度、HttpServer等
		JAX-RS
		JAXB2
		StAX(DOM,SAX)

		一：Desktop类和SystemTray类

		在JDK6中 ,AWT新增加了两个类:Desktop和SystemTray。

		前者可以用来打开系统默认浏览器浏览指定的URL,打开系统默认邮件客户端给指定的邮箱发邮件,用默认应用程序打开或编辑文件(比如,用记事本打开以txt为后缀名的文件),用系统默认的打印机打印文档;后者可以用来在系统托盘区创建一个托盘程序.

		二:使用JAXB2来实现对象与XML之间的映射

		JAXB是Java Architecture for XML Binding的缩写，可以将一个Java对象转变成为XML格式，反之亦然。

		我们把对象与关系数据库之间的映射称为ORM, 其实也可以把对象与XML之间的映射称为OXM(Object XML Mapping). 原来JAXB是Java EE的一部分，在JDK6中，SUN将其放到了Java SE中，这也是SUN的一贯做法。JDK6中自带的这个JAXB版本是2.0, 比起1.0(JSR 31)来，JAXB2(JSR 222)用JDK5的新特性Annotation来标识要作绑定的类和属性等，这就极大简化了开发的工作量。

		实际上，在Java EE 5.0中，EJB和Web Services也通过Annotation来简化开发工作。另外,JAXB2在底层是用StAX(JSR 173)来处理XML文档。除了JAXB之外，我们还可以通过XMLBeans和Castor等来实现同样的功能。

		三:理解StAX

		StAX(JSR 173)是JDK6.0中除了DOM和SAX之外的又一种处理XML文档的API。

		StAX 的来历 ：在JAXP1.3(JSR 206)有两种处理XML文档的方法:DOM(Document Object Model)和SAX(Simple API for XML).

		由于JDK6.0中的JAXB2(JSR 222)和JAX-WS 2.0(JSR 224)都会用到StAX所以Sun决定把StAX加入到JAXP家族当中来，并将JAXP的版本升级到1.4(JAXP1.4是JAXP1.3的维护版本). JDK6里面JAXP的版本就是1.4. 。

		StAX是The Streaming API for XML的缩写，一种利用拉模式解析(pull-parsing)XML文档的API.StAX通过提供一种基于事件迭代器(Iterator)的API让程序员去控制xml文档解析过程,程序遍历这个事件迭代器去处理每一个解析事件，解析事件可以看做是程序拉出来的，也就是程序促使解析器产生一个解析事件然后处理该事件，之后又促使解析器产生下一个解析事件，如此循环直到碰到文档结束符；
		SAX也是基于事件处理xml文档，但却是用推模式解析，解析器解析完整个xml文档后，才产生解析事件，然后推给程序去处理这些事件；DOM采用的方式是将整个xml文档映射到一颗内存树，这样就可以很容易地得到父节点和子结点以及兄弟节点的数据，但如果文档很大，将会严重影响性能。

		四:使用Compiler API

		现在我 们可以用JDK6 的Compiler API(JSR 199)去动态编译Java源文件，Compiler API结合反射功能就可以实现动态的产生Java代码并编译执行这些代码，有点动态语言的特征。

		这个特性对于某些需要用到动态编译的应用程序相当有用， 比如JSP Web Server，当我们手动修改JSP后，是不希望需要重启Web Server才可以看到效果的，这时候我们就可以用Compiler API来实现动态编译JSP文件，当然，现在的JSP Web Server也是支持JSP热部署的，现在的JSP Web Server通过在运行期间通过Runtime.exec或ProcessBuilder来调用javac来编译代码，这种方式需要我们产生另一个进程去做编译工作，不够优雅而且容易使代码依赖与特定的操作系统；Compiler API通过一套易用的标准的API提供了更加丰富的方式去做动态编译,而且是跨平台的。

		五:轻量级Http Server API
		 
		JDK6 提供了一个简单的Http Server API,据此我们可以构建自己的嵌入式Http Server,它支持Http和Https协议,提供了HTTP1.1的部分实现，
		没有被实现的那部分可以通过扩展已有的Http Server API来实现,程序员必须自己实现HttpHandler接口,HttpServer会调用HttpHandler实现类
		的回调方法来处理客户端请求,在这里,我们把一个Http请求和它的响应称为一个交换,包装成HttpExchange类,HttpServer负责将HttpExchange
		传给 HttpHandler实现类的回调方法.

		六:插入式注解处理API(Pluggable Annotation Processing API)

		插入式注解处理API(JSR 269)提供一套标准API来处理Annotations(JSR 175)

		实际上JSR 269不仅仅用来处理Annotation,我觉得更强大的功能是它建立了Java 语言本身的一个模型,它把method, package, constructor, type, variable, enum, annotation等Java语言元素映射为Types和Elements(两者有什么区别?), 从而将Java语言的语义映射成为对象, 我们可以在javax.lang.model包下面可以看到这些类. 所以我们可以利用JSR 269提供的API来构建一个功能丰富的元编程(metaprogramming)环境.

		JSR 269用Annotation Processor在编译期间而不是运行期间处理Annotation, Annotation Processor相当于编译器的一个插件,所以称为插入式注解处理.如果Annotation Processor处理Annotation时(执行process方法)产生了新的Java代码,编译器会再调用一次Annotation Processor,如果第二次处理还有新代码产生,就会接着调用Annotation Processor,直到没有新代码产生为止.每执行一次process()方法被称为一个"round",这样整个Annotation processing过程可以看作是一个round的序列.

		JSR 269主要被设计成为针对Tools或者容器的API. 举个例子,我们想建立一套基于Annotation的单元测试框架(如TestNG),在测试类里面用Annotation来标识测试期间需要执行的测试方法。

		七:用Console开发控制台程序

		JDK6中提供了java.io.Console 类专用来访问基于字符的控制台设备. 你的程序如果要与Windows下的cmd或者Linux下的Terminal交互,就可以用Console类代劳. 但我们不总是能得到可用的Console, 一个JVM是否有可用的Console依赖于底层平台和JVM如何被调用. 如果JVM是在交互式命令行(比如Windows的cmd)中启动的,并且输入输出没有重定向到另外的地方,那么就可以得到一个可用的Console实例.

		八:对脚本语言的支持如: ruby, groovy, javascript.

		九:Common Annotations
	1.7新特性

* 
杭州市西湖区文三路398号东方通信大厦1724室
* 622848 032323 8928010
* 耀江广厦 a 6#
* 有专精有覆盖面 -tip-
	special skill
* dubbo
	wiki: http://code.alibabatech.com/wiki/display/dubbo/Home-zh
	svn co http://code.alibabatech.com/svn/dubbo/trunk dubbo
	See README file in the source code directory

	- 简介
		那么，Dubbo是什么？
		Dubbo[]是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。

		其核心部分包含:

		远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。
		集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。
		自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。
		Dubbo能做什么？
		透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。
		软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。
		服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。

* 问题排查 * 运维
	- 问题排查，性能查看 相关命令和工具
	
		gdb 
		top - Display Linux tasks
		free - Display amount of free and used memory in the system
		sar - system active report
		df/du
			查看各分区使用情况:  df -h
			查看指定目录的大小: du -sh		目录大小 文件大小
		ulimit

		iostat IO状态查看
			Report Central Processing Unit (CPU) statistics and input/output statistics for devices and partitions.
		
		java相关：
			- Memory Map
			---------
			观察运行中的jvm物理内存的占用情况。
			参数如下：
			-heap：打印jvm heap的情况
			-histo：打印jvm heap的直方图。其输出信息包括类名，对象数量，对象占用大小。
			-histo：live ：同上，但是只答应存活对象的情况
			-permstat：打印permanent generation heap情况

			命令使用：
			jmap -heap 2083
			可以观察到New Generation（Eden Space，From Space，To Space）,tenured generation,Perm Generation的内存使用情况
			例子：
			-----
			$jmap -heap 607
			Attaching to process ID 607, please wait...
			Debugger attached successfully.
			Server compiler detected.
			JVM version is 14.2-b01

			using thread-local object allocation.
			Parallel GC with 4 thread(s)

			Heap Configuration:
			   MinHeapFreeRatio = 40
			   MaxHeapFreeRatio = 70
			   MaxHeapSize      = 2147483648 (2048.0MB)
			   NewSize          = 838860800 (800.0MB)
			   MaxNewSize       = 838860800 (800.0MB)
			   OldSize          = 5439488 (5.1875MB)
			   NewRatio         = 2
			   SurvivorRatio    = 6
			   PermSize         = 134217728 (128.0MB)
			   MaxPermSize      = 134217728 (128.0MB)

			Heap Usage:
			PS Young Generation
			Eden Space:
			   capacity = 829751296 (791.3125MB)
			   used     = 303288752 (289.2386932373047MB)
			   free     = 526462544 (502.0738067626953MB)
			   36.55176598844384% used
			From Space:
			   capacity = 4521984 (4.3125MB)
			   used     = 2260992 (2.15625MB)
			   free     = 2260992 (2.15625MB)
			   50.0% used
			To Space:
			   capacity = 4521984 (4.3125MB)
			   used     = 0 (0.0MB)
			   free     = 4521984 (4.3125MB)
			   0.0% used
			PS Old Generation
			   capacity = 1308622848 (1248.0MB)
			   used     = 380483832 (362.85765838623047MB)
			   free     = 928139016 (885.1423416137695MB)
			   29.075132883512058% used
			PS Perm Generation
			   capacity = 134217728 (128.0MB)
			   used     = 45552840 (43.44257354736328MB)
			   free     = 88664888 (84.55742645263672MB)
			   33.93951058387756% used
			-----

			jmap -histo 2083 ｜ jmap -histo:live 2083
			可以观察heap中所有对象的情况（heap中所有生存的对象的情况）。包括对象数量和所占空间大小。
			注意：使用了histo:live选项后，JVM会进行FGC(full gc)，这是为了得到更清晰的结果(从jmap的java源码分析可看到)。

			写个脚本，可以很快把占用heap最大的对象找出来，对付内存泄漏特别有效。
			---------
			from: http://www.blogjava.net/stone2083/archive/2008/02/25/182081.html	JVM监控工具介绍
				jps - Java Virtual Machine Process Status Tool
					列出所有的jvm实例
					实例：
					jps
					列出本机所有的jvm实例

					jps 192.168.0.77
					列出远程服务器192.168.0.77机器所有的jvm实例，采用rmi协议，默认连接端口为1099
					（前提是远程服务器提供jstatd服务）
				jinfo
					观察运行中的java程序的运行环境参数：参数包括Java System属性和JVM命令行参数
				jstat - Java Virtual Machine Statistics Monitoring Tool

					jstat -gccause -t 28323 100 3
						-t 时间 100毫秒间隔 打印3次

					最后要重点介绍下这个命令。
					这是jdk命令中比较重要，也是相当实用的一个命令，可以观察到classloader，compiler，gc相关信息
					具体参数如下：
					-class：统计class loader行为信息
					-compile：统计编译行为信息
					-gc：统计jdk gc时heap信息
					-gccapacity：统计不同的generations（不知道怎么翻译好，包括新生区，老年区，permanent区）相应的heap容量情况
					-gccause：统计gc的情况，（同-gcutil）和引起gc的事件
					-gcnew：统计gc时，新生代的情况
					-gcnewcapacity：统计gc时，新生代heap容量
					-gcold：统计gc时，老年区的情况
					-gcoldcapacity：统计gc时，老年区heap容量
					-gcpermcapacity：统计gc时，permanent区heap容量
					-gcutil：统计gc时，heap情况
					-printcompilation：不知道干什么的，一直没用过。
				
				visual vm / visualvm
				ref: http://visualvm.java.net/download.html
				设置jdk路径，再启动(etc/visualvm.conf)
					通过jstatd或jmx连接到远程jvm上
						jstatd - Virtual Machine jstat Daemon
						jstatd xxx xxx.policy



		jstack - 打印java线程堆栈信息

	


* 性能调优
	log系统调优，如log4j
		log4j.appender.monitorAppender.BufferedIO=true
		log4j.appender.monitorAppender.BufferSize=8192
		这 个选项用于告诉log4j输出日志的时候采用缓冲的方式，而不是即时flush方式，并且设定了缓冲为8K，8K是默认值，可以根据日志输出的情况来修 改。
		这个选项很重要，在测试中发现，当并发访问很高，例如每一秒100个并发以上，使用缓存跟不使用缓冲差距很大。具体数字我这里就不列出来了。
		另外我想说的是，log4j输出缓冲日志是以8K为单位的，因为磁盘的一个block为8K，这样可以减少碎片，也就是说假设你设置缓存为18K，log4j在
		16K（8K*2)的时候就会输出），而不是18K。
		ref: http://www.blogjava.net/conans/articles/345083.html


* user
ftian20130102

* 学习的载体 -tip-
	如tomcat源码：NIO，Servlet3.0，comet,classloader，服务器编程，JMX and etc.
* 编码
	ref: http://baike.corp.taobao.com/index.php/编码规范最佳实践
		
* Comet技术
	适用场景：
		适合事件驱动的 Web 应用，以及对交互性和实时性要求很强的应用，如股票交易行情分析、聊天室和 Web 版在线游戏等。
	起源：
		AJAX应用中存在一个致命的缺陷无法满足传统桌面系统的需求。那就是“服务器发起的消息传递(Server-Initiated Message Delivery)”。
		B/S架构中由于HTTP的无状态，只能通过轮询(Polling)技术不断刷新页面来获得最新的数据(见图18-5)。这种方式不但浪费服务器的资源，最重要的是每次建立(或关闭)新的HTTP连接
		都有一定的延迟，这种延迟使得频繁信息传递的应用无法忍受。于是就产生了“服务器推送技术”。
	实现：
		下面将介绍两种 Comet 应用的实现模型。
		1）基于 AJAX 的长轮询（long-polling）方式	
		2）基于 Iframe 及 htmlfile 的流（streaming）方式

* 取模 模运算
	取模运算即模运算，模运算即求余运算。“模”是“Mod”的音译，模运算多应用于程序编写中。 Mod的含义为求余。模运算在数论和程序设计中
	都有着广泛的应用，从奇偶数的判别到素数的判别，

	求余的结果小于等于被乘数

	2%3=2
	10%3=1

	ref: http://baike.baidu.com/view/4887065.htm
* 位运算 << 左移运算 >> 右移运算
	ref：http://www.cnblogs.com/highriver/archive/2011/08/15/2139600.html

	
* java hashcode equal方法
	java中hashcode方法的引入，是为了集合数据结构而出现，比如Map结构，用来计算哈希值并作为键以提高性能
	下面是JDK包中HashMap类的put方法部分：
	------
	public V put(K key, V value) {
		if (key == null)
		    return putForNullKey(value);
		int hash = hash(key.hashCode());//再hash，避免冲突
		int i = indexFor(hash, table.length);
		for (Entry<K,V> e = table[i]; e != null; e = e.next) {
		    Object k;
		    if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
			V oldValue = e.value;
			e.value = value;
			e.recordAccess(this);
			return oldValue;
		    }
		}

		modCount++;
		addEntry(hash, key, value, i);
		return null;
	}
	------
	PS: hash方法的说明：
		-----
		Applies a supplemental hash function to a given hashCode, which defends against poor quality hash functions. This is critical because HashMap uses power-of-two 
		length hash tables, that otherwise encounter collisions for hashCodes that do not differ in lower bits. Note: Null keys always map to hash 0, thus index 0.
		-----
		降低原生hash算法产生值时的冲突
	
* 发布
	在AG执行
* java 集合数据结构的适用场景
	----
		1) ArrayList

	　　基于数组方式实现，无容量的限制。

	　　在执行插入元素时可能要扩容，在删除元素时并不会减少数组的容量。

	　　如果希望相应的缩小数组容量，可以调用trimToSize()

	　　在查找元素时要遍历数组，对于非null的元素采取equals的方式寻找。

	　　非线程安全。

	　　2) LinkedList

	　　基于双向链表机制实现。

	　　元素的插入、移动较快。

	　　非线程安全。

	　　3) Vector

	　　基于Object数组的方式来实现的。

	　　基于synchronized实现的线程安全的ArrayList。

	　　在插入元素时容量扩充的机制和ArrayList稍有不同：

	　　如果capcacityIncrement > 0, 则Object数组的大小扩大为现有size加上capcacityIncrement；

	　　如果capcacityIncrement < 0, 则Object数组的大小扩大为现有size的两倍；

	　　4) Stack

	　　基于Vector实现，支持LIFO。

	　　5) HashSet

	　　基于HashMap实现，无容量限制。

	　　不允许元素重复。

	　　非线程安全。

	　　6) TreeSet

	　　基于TreeMap实现，支持排序。

	　　非线程安全。

	　　7) HashMap

	　　采用数组方式存储key、value构成的Entry对象，无容量限制。

	　　基于key hash寻找Entry对象存放到数组的位置，对于hash冲突采用链表的方式来解决。

	　　在插入元素时可能会扩大数组的容量，在扩大容量时会重新计算hash，并复制对象到新的数组中。

	　　非线程安全。

	　　8) TreeMap

	　　基于红黑树实现，无容量限制。

	　　非线程安全。

	　　-----------------------------------

	　　适用场景：

	　　对于查找和删除较为频繁，且元素数量较多的应用，Set或Map是更好的选择；

	　　ArrayList适用于通过为位置来读取元素的场景；

	　　LinkedList 适用于要头尾操作或插入指定位置的场景；

	　　Vector 适用于要线程安全的ArrayList的场景；

	　　Stack 适用于线程安全的LIFO场景；

	　　HashSet 适用于对排序没有要求的非重复元素的存放；

	　　TreeSet 适用于要排序的非重复元素的存放；

	　　HashMap 适用于大部分key-value的存取场景；

	　　TreeMap 适用于需排序存放的key-value场景。
	----
* 项目管理工具
	项目构建
		maven
		ant
	版本控制
		svn
	bugfree
		缺陷跟踪系统
		new > open > fixed > closed
	wiki系统
		mediawiki
		页面自身的连接地址修改在移动标签功能中。
		删除重定向页这个对象，即可删除重定向到的页面
	项目管理
		redmine
	
* nginx	
	- nginx转发配置
		 ---------
		  ...
			   server {
				listen       80;
				server_name  openapi.aliyun.com;

				charset UTF-8;

				proxy_connect_timeout 600;
				proxy_read_timeout 600;
				proxy_send_timeout 600;

				#access_log  logs/host.access.log  main;

				if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
				{ 
				  set $domain $1; 
				  set $new_uri /openapi/$domain$request_uri;
				} 

				location /{
				    proxy_set_header        X-Real-IP $remote_addr;
				    proxy_set_header        Host $host;
				    proxy_pass http://127.0.0.1:8080$new_uri;
				
				}

			       location /slb/api{
					   proxy_set_header        X-Real-IP $remote_addr;
					   proxy_set_header        Host $host;
		...
		---------
		部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
				
		小结：
				当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
			启动失败了，即服务器是起来了，但应用却没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
			ok的情况下极可能就是应用启动失败）。
				这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。
	- nginx常用操作命令
		------
		#!/bin/sh

		cd `dirname $0`/..
		BASE_HOME=`pwd`
		NGINX_HOME=/usr/ali/nginx

		ARGV="$@"

		# the path to your nginx binary, including options if necessary
		NGINXD=$NGINX_HOME/sbin/nginx

		ERROR=0
		if [ "x$ARGV" = "x" ] ; then
		    ARGV="-h"
		fi

		case $ARGV in
		#指定nginx home位置启动
		start)
		    $NGINXD -p $BASE_HOME/
		    ;;
		stop)
		    $NGINXD -s quit  -p $BASE_HOME/
		    ;;
		restart|graceful)
		     $NGINXD -s quit -p $BASE_HOME/
		     $NGINXD -p $BASE_HOME/
		    ;;
		start|stop|graceful-stop)
		    $NGINXD   $ARGV  -p $BASE_HOME/
		    ERROR=$?
		    ;;
		configtest)
		    testconfig
		    ;;
		*)
		    $NGINXD $OPTIONS $ARGV
		    ERROR=$?
		esac

		exit $ERROR
		------
	-  nginx实现负载均衡
		nginx不单可以作为强大的web服务器，也可以作为一个反向代理服务器，而且nginx还可以按照调度规则实现动态、静态页面的分离，可以按照轮询、ip哈希、
		URL哈希、权重等多种方式对后端服务器做负载均衡，同时还支持后端服务器的健康检查。

		如果只有一台服务器时,这个服务器挂了,那么对于网站来说是个灾难.因此，这时候的负载均衡就会大显身手了,它会自动剔除挂掉的服务器.

		下面简单的介绍下我使用Nginx做负载的体会

		下载---安装Nginx这些不介绍了,前篇有介绍.

		windows和Linux下配置Nginx负载的写法一样,故不分开介绍.

		Nginx负载均衡一些基础知识:

		nginx 的 upstream目前支持 4 种方式的分配 
		1)、轮询（默认） 
			每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 
		2)、weight 
			指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 
		2)、ip_hash 
			每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。  
		3)、fair（第三方） 
			按后端服务器的响应时间来分配请求，响应时间短的优先分配。  
		4)、url_hash（第三方）

		配置nginx实现负载均衡
		以下面nginx.conf为例
			--------
			Xml代码  
			#user  nobody;  
			worker_processes  1;  
			  
			error_log  logs/error.log;  
			  
			events {  
			    worker_connections  1024;  
			}  
			  
			  
			http {  
			    include       mime.types;  
			    default_type  application/octet-stream;  
			  
			    sendfile        on;  
			    keepalive_timeout  65;  
			  
			    #gzip  on;  
			    upstream  www.docyeah.com   {  
				      server   192.168.1.11:8080 down;  
				      server   192.168.1.101:8080 weight=2;  
      				      server   192.168.1.102:8080 backup;  
			    }  
			    server {  
				listen       80;  
				server_name  www.docyeah.com;  
				charset utf-8;  
				location / {  
				    root   html;  
				    index  index.html index.htm;  
				    proxy_pass        http://www.docyeah.com;  
				    proxy_set_header  X-Real-IP  $remote_addr;  
				    client_max_body_size  100m;  
				}  
			  
			  
				location ~ ^/(WEB-INF)/ {   
				deny all;   
				}   
			  
				error_page   500 502 503 504  /50x.html;  
				location = /50x.html {  
				    root   html;  
				}  
			  
			    }  
			}  
			--------
			from: http://www.cnblogs.com/xiaogangqq123/archive/2011/03/04/1971002.html

* RSS
		RSS是在互联网上被广泛采用的内容包装和投递协议。网络用户可以在客户端借助于支持RSS的新闻工具软件，在不打开网站内容页面的情况下，
	阅读支持RSS输出的网站内容。
	1) RSS文件结构
		示例：
	<?xml version="1.0" encoding="gb2312" ?> 
	<rss version="2.0">　
	<channel> 
	　　<title>我的Blog</title>                 //channel的标题
	　　<description>与我自己的技术Blog相关联</description>   //channel的介绍
	　　<link>http://counter.csdn.net/pv.aspx?id=72</link>     //channel的url
	　　<item> 
	　　<title><!-- 项标题 --></title>           //item的标题
	　　<link><!-- 项 URL --></link>           //item的url
	　　<description><!-- 简要描述 --></description>        //item的介绍
	　　<!-- 可选的/可扩展的元素 -->        //item的其他属性，比如更新时间
	　　</item> 
	　　<item>
	　　<!-- 可多个<item>项目-->           //一个channel有多个item
	　　</item>
	</channel>
	</rss>
		RSS是两级结构，第一级结构是channel，相当于blog系统中某人的blog，第二级结构是item，相当于blog中的文章。属性中最重要的是title、description和link，
	title是标题，description是介绍，link是与其相关的url。 

	2) RSS的使用
		有的网站提供了RSS自动发现机制，可以很方便地把RSS的URL添加到RSS阅读器中。如果没有自动发现，那么可以手动把RSS链接的URL添加到RSS阅读器中，
	这样就加入了一个用户订阅的频道。在RSS阅读器中可以更新频道列表或点击一个item链接打开该item的页面。 

	3) RSS的工作机制
			内容提供者在其网站上添加RSS的链接，以提供RSS订阅功能，当打开这个链接时，传送过去了一些频道信息，比如：blog的作者名。
			一种做法是，RSS链接URL指向的是一个空内容的页面，该页面后台程序通过传过来的频道信息访问数据库，获取频道列表，用Response.Write向该空页面
		写出XML格式的文件。
			另一种做法是，RSS链接URL指向的是一个xml文件，该文件由服务器的程序事先生成好的，放在服务器上，访问时静态获取，服务器在作者每添加一个频道列表
		时自动更新该xml文件。
			第一种做法的优点是管理方便，因为不需要为每个频道生成xml文件，所有的RSS请求都由一个后台页面处理，接口统一，但每次访问RSS链接时，都要动态地
		写出RSS频道列表，访问效率相对较低，第二种做法的优点是访问时，只是返回一个静态的xml文件，不需要访问数据库来临时生成，所以访问效率相对较高，但
		每更新一次频道列表中的项时，就要自动地重新生成xml文件以保证RSS文件的最新，这样就降低了更新的效率。本系统中采用的是第一种方法。 

	4) RSS的实现
	RSS有两大部件：RSS链接和RSS阅读器

* google reader
	rss订阅
		将outlook的rss源或google reader中的rss源导出为OPML文件，这样其他rss工具就可直接导入
* 泛型
	- java 泛型的使用 ，抽象类和接口都这样表达继承&实现的关系: Class<? extends ICake> cakeClass ,Class<? extends AbstractDuck>
		少去了类型转换的代码
	- 
	泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类。可以把类型参数看作是使用
	参数化类型时指定的类型的一个占位符，就像方法的形式参数是运行时传递的值的占位符一样。

	可以在集合框架（Collection framework）中看到泛型的动机。例如，Map 类允许您向一个 Map 添加任意类的对象，即使最常见的情况是在给定映射
	（map）中保存某个特定类型（比如 String）的对象。

	因为 Map.get() 被定义为返回 Object，所以一般必须将 Map.get() 的结果强制类型转换为期望的类型，如下面的代码所示：

	Map m = new HashMap();
	m.put("key", "blarg");
	String s = (String) m.get("key");

	要让程序通过编译，必须将 get() 的结果强制类型转换为 String，并且希望结果真的是一个 String。但是有可能某人已经在该映射中保存了不是 String 的东西，
	这样的话，上面的代码将会抛出 ClassCastException。

	理想情况下，您可能会得出这样一个观点，即 m 是一个 Map，它将 String 键映射到 String 值。这可以让您消除代码中的强制类型转换，同时获得一个附加的
	类型检查层，该检查层可以防止有人将错误类型的键或值保存在集合中。这就是泛型所做的工作。
	from: http://www.cnblogs.com/panjun-Donet/archive/2008/09/27/1300609.html

* ICMP协议
	简介
		ICMP是（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。
	控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递
	起着重要的作用。
		ICMP协议是一种面向连接的协议，用于传输出错报告控制信息。它是一个非常重要的协议，它对于网络安全具有极其重要的意义。
		它是TCP/IP协议族的一个子协议,属于网络层协议,主要用于在主机与路由器之间传递控制信息,包括报告错误、交换受限控制和状态信息等。当
	遇到IP数据无法访问目标、IP路由器无法按当前的传输速率转发数据包等情况时，会自动发送ICMP消息。

	ICMP原理
		ICMP提供一致易懂的出错报告信息。发送的出错报文返回到发送原数据的设备，因为只有发送设备才是出错报文的逻辑接受者。发送设备随后
	可根据ICMP报文确定发生错误的类型，并确定如何才能更好地重发失败的数据包。但是ICMP唯一的功能是报告问题而不是纠正错误，纠正错误的任务由发送
	方完成。
		我们在网络中经常会使用到ICMP协议，比如我们经常使用的用于检查网络通不通的Ping命令（Linux和Windows中均有），这个“Ping”的过程实际上就是
	ICMP协议工作的过程。还有其他的网络命令如跟踪路由的Tracert命令也是基于ICMP协议的。
	from: http://baike.baidu.com/view/30564.htm
	
	死亡之Ping
		在IP协议规范中规定了一个IP包的最大尺寸，而大多数的包处理程序又假设包的长度超过这个最大尺寸这种情况是不会出现的。因此，包的重组代码
	所分配的内存区域也最大不超过这个最大尺寸。这样，超大的包一旦出现，包当中的额外数据就会被写入其他正常区域。这很容易导致系统进入非稳定状态，
	是一种典型的缓存溢出（Buffer Overflow）攻击。在防火墙一级对这种攻击进行检测是相当难的，因为每个分片包看起来都很正常。
		由于使用ping工具很容易完成这种攻击，以至于它也成了这种攻击的首选武器，这也是这种攻击名字的由来。当然，还有很多程序都可以做到这一点，
	因此仅仅阻塞ping的使用并不能完全解决这个漏洞。预防死亡之ping的最好方法是对操作系统打补丁，使内核将不再对超过规定长度的包进行重组。
* ARP
	- 在之前的一篇文章，TCP/IP链路层协议中说到，在以太网链路传输中，必需是以48比特位的网络接口硬件地址建立连接的，而我们应用程序之间的通信
	是以32比特位的IP地址建立连接的，这就需要我们把32比特的IP地址映射到48比特的硬件地址（MAC地址）。ARP（address resolution protocol）,RARP(
	reverse address resolution protocol),就是针对这一功能定义的协议规范。

	以太网目的地址和以太网源地址分别是指6字节，48bit的硬件地址。当「以太网目的地址」为：FF：FF：FF：FF：FF：FF，即全部为1时，则表示这是个
	广播地址，所有的以太网接口都要接收这个帧数据。当发送ARP请求数据帧时，因为是要请求查找指定的IP地址所映射的硬件地址，所以会广播所有的
	网络上的主机，则此时的目的以太网地址就是：FF：FF：FF：FF：FF：FF
* 环回接口 
	 环回接口（Loopback Interface）
	 大家都熟知「127.0.10.1」或者「localhost」，也知道它们主要是同一台主机上两个应用进行TCP/IP通信的IP地址或主机名。这就是「环回接口」的相关概念。
	NOTE：
	1) 一个传给环回接口的IP数据报不能出现在任何网络上
	2) 传给广播地址或多播地址的数据报复制一分给环回接口，然后才送到以太网上。这是因为广播和多播传送本身就包括主机本身
	3) 任何传给该主机IP地址的数据均送到环回接口
	from:		http://www.cnblogs.com/jcli/archive/2013/01/27/2874091.html

* new 
	http://www.aliway.com/read.php?fid=73&tid=188016
	做一个名医的病人，相关的事可以咨询

* IP IP转换 IP地址 IP段 IP Segment
	- IP概述 http://www.cnblogs.com/jcli/archive/2013/02/03/2880671.html
	- 所谓IP地址就是给每个连接在Internet上的主机分配的一个32bit地址。按照TCP/IP协议规定，IP地址用二进制来表示，每个IP地址长32bit，比特换算成字节，
	就是4个字节。例如一个采用二进制形式的IP地址是“00001010000000000000000000000001”，这么长的地址，人们处理起来也太费劲了。为了方便人们的使用，
	IP地址经常被写成十进制的形式，中间使用符号“.”分开不同的字节。于是，上面的IP地址可以表示为“10.0.0.1”。IP地址的这种表示法叫做“点分十进制表示法”，
	这显然比1和0容易记忆得
	from: http://zhidao.baidu.com/question/282553232.html
	PS: 也可转换为16进制、长整型等

	C0-A8-0A-11  是IPArr转换为string类型时的输出结果，也是192 168 10 17 的16进制285911232 是IPArr转换为整数的结果,C0是最低位，也就是说该整数是由 
	11-0A-A8-C0转换成10进制的来的
	
	- IP转换为long的例子：
		------
		IPV4 {
					public Long ip2Long(String strIP) {
						long[] ip = new long[4];
						int position1 = strIP.indexOf(".");
						int position2 = strIP.indexOf(".", position1 + 1);
						int position3 = strIP.indexOf(".", position2 + 1);
						ip[0] = Long.parseLong(strIP.substring(0, position1));
						ip[1] = Long.parseLong(strIP
								.substring(position1 + 1, position2));
						ip[2] = Long.parseLong(strIP
								.substring(position2 + 1, position3));
						ip[3] = Long.parseLong(strIP.substring(position3 + 1));
						Long ip2Long = (ip[0] << 24) + (ip[1] << 16) + (ip[2] << 8)
								+ ip[3];
						return ip2Long;
					}
		------
		每个IP用二进制表示，长度为32bit，

* virtual host
	- 介绍
		The term Virtual Host refers to the practice of running more than one web site (such as company1.example.com and company2.example.com) on a single machine. 
		Virtual hosts can be "IP-based", meaning that you have a different IP address for every web site, or "name-based", meaning that you have multiple names running on each IP address. 
		The fact that they are running on the same physical server is not apparent to the end user.
	- apache支持virtual host：
		Apache was one of the first servers to support IP-based virtual hosts right out of the box. Versions 1.1 and later of Apache support both IP-based and name-based virtual 
		hosts (vhosts). The latter variant of virtual hosts is sometimes also called host-based or non-IP virtual hosts.
		
* rewrite技术 伪静态技术	URL rewrite技术	 URL重写
	- URL rewrite
		URL 重写是截取传入 Web 请求并自动将请求重定向到其他 URL 的过程 
			将http://www.new.com/work/index.php?action=list&para1=test&para2=test2
			转换为：
			http://work.new.com/list/para1/test/para2/test2
	参考：http://www.itlearner.com/code/apache2.2/rewrite/rewrite_guide.html  初级URL重写指南
		http://www.baidu.com/link?url=jCVVGJqjJ4zBBpC8yDF8xDhgsCi-AJZjCGkIr62EKcS52ktxVCl-tMokRHKqpDjN4om
	静态技术，便于搜索引擎收录页面。
	。。。
	
* apache apache2
	- virtual host配置
		httpd.conf
		--------
			Listen 80

			<VirtualHost *:80> 
			#   General setup for the virtual host
			DefaultType text/xml

			DocumentRoot "/home/admin/houyi_directory_backup/houyi/service/"

			ErrorLog /home/admin/houyi_directory_backup/houyi/service/logs/openapi/error_log

			<Directory />
			    Options FollowSymLinks
			#    Options None
			    AllowOverride None
			    Order allow,deny
			    Allow from all
			</Directory>

			<Directory "/home/admin/houyi_directory_backup/houyi/service/">
			    Options FollowSymLinks
			#    Options None
			    AllowOverride None
			    Order allow,deny
			    Allow from all
			</Directory>

			<FilesMatch "^\.ht">
			    Order allow,deny
			    Deny from all
			</FilesMatch>
			AccessFileName .htaccess
			</VirtualHost>
		--------
		建议单独配置virtual host到httpd-vhost.conf中。

	- apache作为反向代理后端为jetty配置
		参考：http://blog.csdn.net/zhuying_linux/article/details/6600071   Apache +Jetty的负载均衡与集群配置（上）

		例子：
		原来apache与jboss通过ajp协议，现在nginx与jetty通过http or what others?	   在httpd.conf中配置 apache+jetty 负载均衡			
			1) 暂且直接配置为http方式通讯：
				<IfModule proxy_module>
					ProxyPass /open http://127.0.0.1:8080/open #静态文件的请求不需要转发，由apache直接返回，需要配置DocumentRoot 为程序目录(为防止冲突，建议配虚拟机)
				</IfModule> 
			2) 若需要，也可以配置为ajp方式通讯，主要配置如下：
				加载需要的模块：
					LoadModule proxy_module modules/mod_proxy.so
					LoadModule proxy_ajp_module modules/mod_proxy_ajp.so
					LoadModule proxy_balancer_module modules/mod_proxy_balancer.so
				配置httpd.conf：
					<IfModule proxy_ajp_module>
						ProxyPass open ajp://127.0.0.1:8190/open
						#ProxyPassReverse /open ajp://127.0.0.1:8080/open/api #rewrite if need
					</IfModule>
				确保backend的ajp端口与上面配置的一致（8190）。
	- proxy_ajp_module 模块
		apache的httpd.conf文件配置module信息，proxy_ajp_module模块用于ajp协议的通讯，需要mod_proxy模块，即proxy_ajp_module模块是一个
		AJP support module for mod_proxy。
		摘自官网的usage：
		-------
			Usage

			This module is used to reverse proxy to a backend application server (e.g. Apache Tomcat) using the AJP13 protocol. The usage is similar to an HTTP reverse proxy, 
			but uses the ajp:// prefix:

			#Simple Reverse Proxy
			ProxyPass /app ajp://backend.example.com:8009/app		 //简单配置
			Balancers may also be used:

			#Balancer Reverse Proxy
			<Proxy balancer://cluster>								      //根据权重负载均衡，可用性考虑？	    mok_jk?
				BalancerMember ajp://app1.example.com:8009 loadfactor=1
				BalancerMember ajp://app2.example.com:8009 loadfactor=2
				ProxySet lbmethod=bytraffic
			</Proxy>
			ProxyPass /app balancer://cluster/app

			Note that usually no ProxyPassReverse directive is necessary. The AJP request includes the original host header given to the proxy, and the application server can be 
			expected to generate self-referential headers relative to this host, so no rewriting is necessary.	  //ProxyPassReverse配置说明，只有当proxy接收的url与后端的不一致时才需要配置此项，否则不建议

			The main exception is when the URL path on the proxy differs from that on the backend. In this case, a redirect header can be rewritten relative to the original host URL (
			not the backend ajp:// URL), for example:

			Rewriting Proxied Path

			ProxyPass /apps/foo ajp://backend.example.com:8009/foo
			ProxyPassReverse /apps/foo http://www.example.com/foo
			However, it is usually better to deploy the application on the backend server at the same path as the proxy rather than to take this approach.
		-------
		详见官网的module说明：http://httpd.apache.org/docs/2.2/mod/mod_proxy_ajp.html

	
* InfoQ ArchSummit全球架构师峰会 腾讯大讲堂 PPT 
	
* 数据仓库 data warehouse
	数据分析
	数据统计 数据统计方案 数据汇总分析 数据汇总分析方案
	数据挖掘
	BI 商业智能
 
* 统计需求 月统计 天统计
	通过提前归并的方式，避免即时扫描，对于大量数据的情况尤其需要考虑
	如果是关系型数据库，大量表扫描也耗性能，需要归并，分布式RDS即DRDS？
	如果是nosql数据量大的统计也代价高，需要归并，支持水平扩展
* google code svn
	google code 提供svn服务，但页面上不便于svn操作，比如添加分支，添加目录等，可通过svn工具来操作，如 TortoiseSVN，来建立新目录等等。

* 代码合并    svn merger merger代码 * svn
	- svn提交报错
		Server sent unexpected return value (405 Method Not Allowed) in response to MKACTIVITY
		PS: 试着将http改为https

	- 冲突解决
		update代码后，通过工具对冲突进行编辑及解决
		Tortoise SVN为到冲突的文件上右键打开编辑冲突功能，编辑好后，再右键选择Resolved即可

	- 对于修改了同一分支同一文件产生的冲突，update本地代码后，产生冲突文件，通过svn diff解决冲突，删除冲突文件并提交来解决
	- svn合并代码特殊场景之一
		从A点的trunk拉出新branch B1开发，在B点时trunk上合入了其他项目的代码，在C点时B1合并trunk的修改到本branch，在D点时B1需要合入trunk，此时会有冲突
		通过merge a range of revisions方式合并，并手工解决冲突（trunk和branch有相同的修改，只要保留trunk上的即可）
	- branch上的多次修改要合并到新拉的branch上
		直接merger branch方便，用patch后续有冲突，merger时使用场景为：
			对一个branch有多个版本的修改，现在需要对这多个版本的修改合并到其他branch上
	- 基于trunk拉分支并提交修改到分支后，若中间没有并行项目，分支合并到主干时，可拉最新的trunk，将分支修改合并进来，再提交即可
	- 基于trunk拉分支并提交修改到分支后，若中间有其他项目发布且已合并到trunk，可在每次trunk修改后，将trunk修改合并到分支上，避免后面合并多个
	项目的多处修改冲突的风险。
		此方法不能避免并行项目做了大量修改导致其他分支合并到trunk时出现大量冲突的问题。需要在项目启动时考虑到这些问题。尽量避开交叉修改的项目并行
		进行。

* RX TX TX RX
	TX: transmit 传送
	RX: receive 接收 

	tx是发送（transport），rx是接收(receive)。以ros为中心。   比如你的外网网卡，wan,rx是wan接受ISP的
	传输数据， 即下载速度。wan的tx,是工作站经ros wan网卡向isp上传的速度，既上传速度。
	内网网卡lan的rx，应该是ros接受来之内网工作站的上传，既是上传速度。tx是lan网卡传给工作站的速
	度，即工作站经内网网卡下载的速度 （以ros为中心）。
	有没有分啊
	tx rx 每个版本都不一样的啊
	而且相对于外网和内网的解释又是相反的
	你就记住一般RX外网指的是下载，TX指的是上传
	而内网相反就行了
	from: http://www.ubooo.com/rou/2009/0324/111.html

* http chunk http chunked	 * chunked
	- web服务器通过输出流来写入chunked格式的数据，若中间存在代理时，需要注意验证代理是否支持chunked输出。比如nginx默认不支持chunked输出，导致
	测试时，误认为chunked输出有问题（在简单的servlet测试时，chunked输出却正常）。-tip-
		查找不支持chunked输出时，确认输出流已经flush，那么web服务应该直接输出了数据，但chunked客户端却读取不到。开始还猜测是struts2框架还是容器的
		那个部分还在继续缓存而没有真正将输出流输出到客户端，

		nginx可以配置不缓存后端数据，但会影响性能；还提供了后端返回指定特定nginx的header来不启用缓存以免chunk无法输出到client，这里是否能优化到正好一个chunk
		的大小为nginx buffer的大小？

		proxy_buffering off;
		上面这种配置方式，会导致所有proxy的转发都禁用buffer，影响性能。

		如果只是个别接口需要关闭buffer来支持chunked输出，可以在发送方设置一个请求头X-Accel-Buffering : no来告诉
		nginx此请求不进行buffer即可。

	- jetty client处理chunked输出
		---------
			HttpClient client = new HttpClient();
			client.setConnectorType(HttpClient.CONNECTOR_SELECT_CHANNEL);
			try {
				client.start();
			} catch (Exception e) {
				e.printStackTrace();
			}

			// create the exchange object, which lets you define where you want to
			// go
			// and what you want to do once you get a response
			ContentExchange exchange = new ContentExchange() {
				// define the callback method to process the response when you get
				// it back
				protected void onResponseComplete() throws IOException {
					// super.onResponseComplete();
					String responseContent = this.getResponseContent();

					// do something with the response content
					System.out.println(responseContent);
				}

				@Override
				protected synchronized void onResponseContent(Buffer content)
						throws IOException {

					System.out.println(content);
				}
			};
			String url = "http://localhost:8080/javaweb/chunked";
			exchange.setMethod("GET");
			exchange.setURL(url);

			// start the exchange
			try {
				client.send(exchange);
				exchange.waitForDone();
			} catch (Exception e) {
				e.printStackTrace();
			}
		---------
		from: http://aliali.iteye.com/blog/405444

	- chunked服务端
		边处理边返回。
	- httpclient读取chunked输出时，根据/r/n来判断chunk结束，根据读取开始位置到读到/r/n所读的长度作为chunked的长度。将协议中chunkSize作为了chunk内容的
	一部分。
	验证上面的分析：
		

	- 例子：
		https://github.com/netty/netty/tree/3.5/src/main/java/org/jboss/netty/example/http/snoop
		
		git clone https://github.com/mar200851/netty.git sign in first

	- 测试chunked输出	 
	
	注意：每写一个chunk，要 Flush 输出流 OutputStream.flush()

		通过线程的睡眠模拟大量数据按块发送和处理的过程。例子如下：
			------
			/* 1) Write by byte */
			//size of first chunk
			out.write(Integer.toHexString(trunk1.length()*2).getBytes());
			out.write(CRLF);
			//send first chunk
			out.write(trunk1.getBytes());
			out.write(trunk1.getBytes());
			out.write(CRLF);
			out.flush();
			sleep();
			//size of second chunk
			out.write(Integer.toHexString(trunk2.length()).getBytes());
			out.write(CRLF);
			//send second chunk
			out.write(trunk2.getBytes());
			out.write(CRLF);
			out.flush();
			sleep();
			//send chunked data end flag
	//		out.write(ZERO);
			out.write(ZERO);
			out.write(CRLF);
			//send CRLF
			out.write(CRLF);
			out.flush();
			------
			注意，每发送一个chunked结束去手动flush下输出流，否则可能导致等待缓存满了才输出。

	- servlet返回chunked响应例子
		------
		@Override
			protected void doGet(HttpServletRequest req, HttpServletResponse resp)
					throws ServletException, IOException {
				resp.setHeader("Pragma", "No-cache");
				resp.setHeader("Cache-Control", "no-cache");
				resp.setDateHeader("Expires", 0);
				
				resp.setHeader("Transfer-Encoding", "chunked");
				
				OutputStream out = resp.getOutputStream();//与使用write的区别，少了流转换的开销？
				String trunk1 = "chunk1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
				String trunk2 = "chunk2";
				//size of first chunk
				out.write(Integer.toHexString(trunk1.length()*2).getBytes());
				out.write(CRLF);
				//send first chunk
				out.write(trunk1.getBytes());
				out.write(trunk1.getBytes());
				out.write(CRLF);
				//size of second chunk
				out.write(Integer.toHexString(trunk2.length()).getBytes());
				out.write(CRLF);
				//send second chunk
				out.write(trunk2.getBytes());
				out.write(CRLF);
				//send chunked data end flag
				out.write(ZERO);
				out.write(CRLF);
				//send CRLF
				out.write(CRLF);
			}
		------
	- 优势
		能一边接受数据一边处理已接收的数据，如果只是一次性取到所有的再去处理，则体现不出chunked的优势

	- 对于返回内容不能立即取到大小，返回是一个过程时，每次只返回可用数据的一块（完整可解析的一个块）。
	参考：http://www.cnblogs.com/jcli/archive/2012/10/19/2730440.html

		一般http通信时会使用content_length头信息来表示服务器发送的文档内容长度，该头信息定义域http1.0协议RFC 1945 10.4章节中，浏览器接收到此头信息后
	接受完content_length中定义的产度字节后开始解析页面，但是如果服务器端有部分数据延迟发送则会出现浏览器白屏，用户体验差。
		解决方案是在http1.1协议中EFC 2616中14.41章节中定义的Transfer_encoding：chunked的头信息。chunked编码定义在3.6.1中，所有HTTP1.1都应该支持使用
	chunked编码动态的提供body内容的长度的方式。进行chunked编码传输的http数据要在消息头部设置transfer_encoding：chunked表示content body将用chunked编码
	传输内容。根据定义，浏览器不需要等到内容字节全部下载完成，只要接收到一个chunked块就可以解析页面，并可以下载html中定义的页面内容，包括js，
	css，image等
		
		采用chunked编码有两种选择一种是设定server的IO buffer长度让server自动flush buffer中的内容另一种是手动调用IO中的flush函数，不同的语言IO中都有flush功能：
		
		php：ob_flush();flush()
		perl:STDOUT->autoflush(1);
		java:out.flush()
		python:sys.stout.flush()
		ruby:stdout.flush
		
		采用http1.1的transfer_encoding：chunked并且把IO的buffer flush下来，一遍浏览器更早的下载页面配套资源，不可能在头中包含content_length域来指明报文体长度，
	此时就需要通过transfer_encoding域来确定报文体长度
	from: http://blog.csdn.net/ruby1098/article/details/6730424

	- http1.1支持
	----------
		Chunked Transfer Coding

		The chunked encoding modifies the body of a message in order to transfer it as a series of chunks, each with its own size indicator, followed by an OPTIONAL trailer 
		containing entity-header fields. This allows dynamically produced content to be transferred along with the information necessary for the recipient to verify that it has 
		received the full message.

		       Chunked-Body   = *chunk
					last-chunk
					trailer
					CRLF
		       chunk          = chunk-size [ chunk-extension ] CRLF
					chunk-data CRLF
		       chunk-size     = 1*HEX
		       last-chunk     = 1*("0") [ chunk-extension ] CRLF
		       chunk-extension= *( ";" chunk-ext-name [ "=" chunk-ext-val ] )
		       chunk-ext-name = token
		       chunk-ext-val  = token | quoted-string
		       chunk-data     = chunk-size(OCTET)
		       trailer        = *(entity-header CRLF)
		The chunk-size field is a string of hex digits indicating the size of the chunk. The chunked encoding is ended by any chunk whose size is zero, followed by the trailer, which is terminated 
		by an empty line.

		The trailer allows the sender to include additional HTTP header fields at the end of the message. The Trailer header field can be used to indicate which header fields are included 
		in a trailer (see section 14.40).

		A server using chunked transfer-coding in a response MUST NOT use the trailer for any header fields unless at least one of the following is true:

		a)the request included a TE header field that indicates "trailers" is acceptable in the transfer-coding of the response, as described in section 14.39; or,

		b)the server is the origin server for the response, the trailer fields consist entirely of optional metadata, and the recipient could use the message (in a manner acceptable to the origin server) 
		without receiving this metadata. In other words, the origin server is willing to accept the possibility that the trailer fields might be silently discarded along the path to the client.

		This requirement prevents an interoperability failure when the message is being received by an HTTP/1.1 (or later) proxy and forwarded to an HTTP/1.0 recipient. It avoids a situation 
		where compliance with the protocol would have necessitated a possibly infinite buffer on the proxy.

		An example process for decoding a Chunked-Body is presented in appendix 19.4.6.

		All HTTP/1.1 applications MUST be able to receive and decode the "chunked" transfer-coding, and MUST ignore chunk-extension extensions they do not understand.
	----------

	下面为对chunked编码的decode方式说明：
	----------
		19.4.6 Introduction of Transfer-Encoding

		HTTP/1.1 introduces the Transfer-Encoding header field (section 14.41). Proxies/gateways MUST remove any transfer-coding prior to forwarding a message via a MIME-compliant protocol.

		A process for decoding the "chunked" transfer-coding (section 3.6) can be represented in pseudo-code as:

		       length := 0
		       read chunk-size, chunk-extension (if any) and CRLF
		       while (chunk-size > 0) {
			  read chunk-data and CRLF
			  append chunk-data to entity-body
			  length := length + chunk-size
			  read chunk-size and CRLF
		       }
		       read entity-header
		       while (entity-header not empty) {
			  append entity-header to existing header fields
			  read entity-header
		       }
		       Content-Length := length
		       Remove "chunked" from Transfer-Encoding
	----------

	from: http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html rfc2616 Hypertext Transfer Protocol -- HTTP/1.1

* IOPS (Input/Output Operations Per Second)
	即每秒进行读写（I/O）操作的次数，多用于数据库等场合，衡量随机访问的性能。存储端的IOPS性能和主机端的IO是不同的，
	IOPS是指存储每秒可接受多少次主机发出的访问，主机的一次IO需要多次访问存储才可以完成。例如，主机写入一个最小的数据块，
	也要经过“发送写入请求、写入数据、收到写入确认”等三个步骤，也就是3个存储端访问。
	from: http://baike.baidu.com/view/2302083.htm
* bps
	byte per second
* linux kernel
	http://www.makelinux.net/kernel_map/

	- 

* 服务总线 消息总线 ESB EMB
* 化整为零 -tip-
	太多太杂，晕头转向？试试化整为零
* 文档
	http://www.ishare.sina.com.cn
	http://www.slideshare.net/
* 红黑树 Red-Black tree
	TreeMap基于红黑树实现 jdk1.6

	SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...));
	
	A red–black tree is a type of self-balancing binary search tree, a data structure used in computer science, typically used to implement associative arrays.
	from: http://en.wikipedia.org/wiki/Red%E2%80%93black_tree	 

	相关点：
	Binary tree 二叉树
			In computer science, a binary tree is a tree data structure in which each node has at most two child nodes, usually distinguished as "left" and "right". Nodes with children are parent nodes, and child nodes may contain references to their parents. Outside the tree, there is often a reference to the "root" node (the ancestor of all nodes), if it exists. Any node in the data structure can be reached by starting at root node and repeatedly following references to either the left or right child. A tree which does not have any node other than root node is called a null tree. In a binary tree a degree of every node is maximum two. A tree with n nodes has exactly n−1 branches or degree.
		Binary trees are used to implement binary search trees and binary heaps.
		from: http://en.wikipedia.org/wiki/Binary_tree

* tair
	-
	Tair是什么
　　	Tair是一个分布式的key/value系统。

　　Tair有四种引擎：
		mdb, rdb, kdb和ldb。分别基于四种开源的key/value数据库：memcached, Redis, Kyoto Cabinet和leveldb。Tair可以让你更方便地使用这些KV数据库。比如Redis没有提供sharding操作，
		如果有多个Redis Server，你需要自己写代码实现sharding，Tair帮你封装了这些。

　　Tair有以下优点：
　　1) 统一的API。无论底层使用何种引擎，上层的API是一样的。
　　2) Tair将集群操作封装起来，解放了开发者。淘宝内部在使用Tair时，一般都是双机房双集群容错，利用invalid server保证两个集群间的一致性，这些对于开发者都是透明的。

	Tair使用场景
	1.) 非持久化(mdb,rdb)
		数据可以以key/value的形式存储
		数据可以接受丢失
		访问速度要求很高
		单个数据大小不是很大，一般在KB级别
		数据量很大，并且有较大的增长可能性
		数据更新不频繁
	2) 持久化(kdb,ldb)
		数据可以以key/value的形式存储
		数据需要持久化
		单个数据大小不是很大，一般在KB级别
		数据量很大，并且有较大的增长可能性
		数据的读写比例较高
	
	Tair的架构
	　　Tair是Master/Slave结构。Config Server管理Data Server节点、维护Data Server的状态信息；Data Server负责数据存储，按照Config Server的指示完成数据复制和迁移工作，
		并定时给Config Server发送心跳信息。Config Server是单点，采用一主一备的方式保证可靠性

	Tair的功能
	1) 动态增加或减少data server
	　　Config Server使用Hash算法将数据桶均匀分布到不同的Data Server。当某个Data Server发生故障时，Config Server会察觉这一情况，重新计算一张数据桶的分布表，并将到故障Data Server的访问转到别的DataServer上。这个过程中，有可能因为负载平衡出现数据迁移。Config Server会检查Data Server的负载，将数据迁移到负载较小的节点上。迁移过程中，Config Server会保证路由表的正确性，使得客户端能够得到数据。
	　　客户端连接Config Server时，会下载最新的路由表。如果连接某个Data Server不成功（可能宕机了），客户端会重新连接Config Server以获得最新的路由表。
	2) 数据桶分布策略
	　　数据桶的分布策略有两种：负载平衡优先和位置安全优先。负载平衡不用说。安全位置优先是指同一个桶的两个duplication要分布在不同的机房。
	3)客户端
	　　Tair Server使用C++编写，利用socket通信。原则上只要支持socket的语言都可以连接，目前只提供Java和C++客户端。
* java GC
	 Java GC 算法

	当一个对象不再被引用的时候，内存回收它占领的空间，以便空间被后来的新对象使用。除了释放没用的对象，垃圾收集也可以清除内存记录碎片。

	1、 引用计数法(Reference Counting Collector)

	    引用计数法是唯一没有使用根集的垃圾回收的法，该算法使用引用计数器来区分存活对象和不再使用的对象。一般来说，堆中的每个对象对应一个引用计数器。当每一次创建一个对象并赋给一个变量时，引用计数器置为1。当对象被赋给任意变量时，引用计数器每次加1当对象出了作用域后(该对象丢弃不再使用)，引用计数器减1，一旦引用计数器为0，对象就满足了垃圾收集的条件。
	    基于引用计数器的垃圾收集器运行较快，不会长时间中断程序执行，适宜地必须 实时运行的程序。但引用计数器增加了程序执行的开销，因为每次对象赋给新的变量，计数器加1，而每次现有对象出了作用域生，计数器减1。
	　　
	ps：用根集的方法（既有向图的方法）进行内存对象管理，可以消除循环引用的问题．就是说如果有三个对象相互引用，只要他们和根集是不可达的，gc也是可以回收他们．根集的方法精度很高，但是效率低．计数器法精度低（无法处理循环引用），但是执行效率高．

	2、tracing算法(Tracing Collector)

	    tracing算法是为了解决引用计数法的问题而提出，它使用了根集的概念。基于tracing算法的垃圾收集器从根集开始扫描，识别出哪些对象可达，哪些对象不可达，并用某种方式标记可达对象，例如对每个可达对象设置一个或多个位。在扫描识别过程中，基于tracing算法的垃圾收集也称为标记和清除 (mark-and-sweep)垃圾收集器。

	3、compacting算法(Compacting Collector)

	    为了解决堆碎片问题，基于tracing的垃圾回收吸收了Compacting算法的思想，在清除的过程中，算法将所有的对象移到堆的一端，
	    堆的另一端就变成了一个相邻的空闲内存区，收集器会对它移动的所有对象的所有引用进行更新，使得这些引用在新的位置能识别原来 的对象。
	    在基于Compacting 算法的收集器的实现中，一般增加句柄和句柄表。

	4、copying算法(Coping Collector)

	    该算法的提出是为了克服句柄的开销和解决堆碎片的垃圾回收。
	    将内存分为两个区域(from space和to space)。所有的对象分配内存都分配到from space。在清理非活动对象阶段，把所有标志为活动的对象，
	    copy到to space，之后清楚from space空间。然后互换from sapce和to space的身份。既原先的from space变成to sapce，原先的to space变成from space。
	    每次清理，重复上述过程。

	    优点：copy算法不理会非活动对象，copy数量仅仅取决为活动对象的数量。并且在copy的同时，整理了heap空间，即，to space的空间使用始终是连续的，内存使用效率得到提高。
	    缺点：划分from space和to space，内存的使用率是1／2。收集器必须复制所有的活动对象，这增加了程序等待时间。

	5、generation算法(Generational Collector)

	    来自IBM的一组统计数据：98％的java对象，在创建之后不久就变成了非活动对象；只有2％的对象，会在长时间一直处于活动状态。

	     (1)young generation

	    年轻代分三个区。一个Eden区，两个Survivor区。大部分对象在 Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor区也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制到 tenured generation。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来对象，和从前一个 Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。
	    young generation的gc称为minor gc。经过数次minor gc，依旧存活的对象，将被移出young generation，移到tenured generation

	    (2)tenured generation

	    生命周期较长的对象，归入到tenured generation。一般是经过多次minor gc，还 依旧存活的对象，将移入到tenured generation。（当然，在minor gc中如果存活的对象的超过survivor的容量，放不下的对象会直接移入到tenured generation）
	tenured generation的gc称为major gc，就是通常说的full gc。
	    采用compaction算法。由于tenured generaion区域比较大，而且通常对象生命周期都比较长，compaction需要一定时间。所以这部分的gc时间比较长。
	    minor gc可能引发full gc。当eden＋from space的空间大于tenured generation区的剩余空间时，会引发full gc。这是悲观算法，要确保eden＋from space的对象如果都存活，必须有足够的tenured generation空间存放这些对象。

	    (3)permanent generation

	    该区域比较稳定，主要用于存放classloader信息，比如类信息和method信息。
	对于spring hibernate这些需要动态类型支持的框架，这个区域需要足够的空间。(这部分空间应该存在于方法区而不是heap中)。

	6、adaptive算法(Adaptive Collector)

	    在特定的情况下，一些垃圾收集算法会优于其它算法。基于Adaptive算法的垃圾收集器就是监控当前堆的使用情况，并将选择适当算法的垃圾收集器。
	from: http://blog.csdn.net/salahg/article/details/5912101Molator's Downloads


* OS
	MLXOS
		Multitask Layered eXecution Operating System
	What is MLXOS ?
		MLXOS is a microkernel operating system, including μ-kernel, user space drivers and utilities.
	from: http://www.mlxos.org/mlxos.html

* HBase * nosql
	- 简介
	HBase(Hadoop Database)，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。
	
	HBase是Google Bigtable的开源实现，类似Google Bigtable利用GFS作为其文件存储系统，HBase利用Hadoop HDFS作为其文件存储系统；Google运行MapReduce来
	处理Bigtable中的海量数据，HBase同样利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用 Chubby作为协同服务，HBase利用Zookeeper作为对应。

	上图描述Hadoop EcoSystem中的各层系统其中,HBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase
	提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。

	此外，Pig和Hive还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 Sqoop则为HBase提供了方便的RDBMS数据导入功能，使得
	传统数据库数据向HBase中迁移变的非常方便。	
	from: http://baike.baidu.com/view/1993870.htm

	- 官网 http://hbase.apache.org/
	- BI，大规模分布式计算，分布式存储


* VPC * Amazon Virtual Private Cloud (Amazon VPC) 自定义网络 
	- Amazon VPC
		允许您在 Amazon Web Services (AWS) 云中预配置一个专用、隔离的部分，让您能够在定义的虚拟网络中启动 AWS 资源。借助 Amazon VPC，
	您可以定义与自己的数据中心运行的传统网络非常相似的虚拟网络拓扑。您可以完全掌控您的虚拟联网环境，包括选择自有的 IP 地址范围、创建子网，以及配置路由表和网关。
	您可以轻松自定义 Amazon VPC 的网络配置。例如，您可以为可访问 Internet 的 Web 服务器创建公有子网，而将数据库或应用程序服务器等后端系统放在不能访问 Internet 的私有子网中。
	您可以利用安全组和网络访问控制列表等多种安全层，帮助对各个子网中 Amazon EC2 实例的访问进行控制。
	此外，您也可以在公司数据中心和 VPC 之间创建硬件虚拟专用网络 (VPN) 连接，将 AWS 云用作公司数据中心的扩展。



* linux core文件 gdb调试
	当一个程序崩溃时，在进程当前工作目录的core文件中复制了该进程的存储图像。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。
	ref: http://blog.csdn.net/fengxinze/article/details/6800175

	ulimet -a 查看系统配置

* 
* 远程调试 jar 远程调试 jar调试
	远程调试 Java 应用程序
	如果您还没安装该程序，请下载 Eclipse V3.4（Ganymede）。在 Ganymede 中，套接字（socket）监听连接器被添加到 Remote Java Application 启动配置类型。Eclipse 最新的套接字监听连接器允许您打开 Java 调试器，它能够监听特定套接字上的连接。可以从命令行选项打开被调试的程序，并将其连接到调试器。在 Ganymede 发布之前，仅有一个连接套接字的连接器，被调试的程序所在的机器必须是一个与调试器相连的调试主机。由于受到内存和 CPU 不足的限制，要想让移动设备充当主机是不现实的。
	为了进行远程调试，必须使用 Java Virtual Machine (JVM) V5.0 或更新版本，比如 IBM® J9 或 Sun Microsystem 的 Java SE Development Kit（JDK）。

	JPDA 简介
	Sun Microsystem 的 Java Platform Debugger Architecture (JPDA) 技术是一个多层架构，使您能够在各种环境中轻松调试 Java 应用程序。JPDA 由两个接口（分别是 JVM Tool Interface 和 JDI）、
	一个协议（Java Debug Wire Protocol）和两个用于合并它们的软件组件（后端和前端）组成。它的设计目的是让调试人员在任何环境中都可以进行调试。JPDA 不仅能够用于桌面系统，
	而且能够在嵌入式系统上很好地工作。
	JVM Tool Interface (JVMTI) 规定必须为调试提供 VM（编辑注：从 Java V5 开始，将用 JVMTI 代替 Java V1.4 中的 JVMDI）。Java Debug Wire Protocol (JDWP) 描述调试信息的格式，
	以及在被调试的进程和调试器前端之间传输的请求，调试器前端实现 JDI，比如 Eclipse、Borland JBuilder 等。根据 Sun 的 JPDA 规范，被调试的程序常常称为 debuggee。JDI 是一个高级的接口，
	它定义用于远程调试的信息和请求。下面给出了调试器的架构。

	常用缩写词
	JDI — Java 调试接口（Java Debug Interface）
	JDT — Java 开发工具（Java Development Tools）
	JDWP — Java 调试网络协议（Java Debug Wire Protocol）
	JPDA — Java 平台调试器架构（Java Platform Debugger Architecture）
	JVM — Java 虚拟机（Java Virtual Machine）
	JVMDI — JVM 调试接口（JVM Debug Interface）
	JVMTI — JVM 工具接口（JVM Tool Interface）
	VM — 虚拟机（Virtual Machine）

	JDWP 包含许多参数，用于为远程 Java 应用程序调用所需的程序。以下是本文用到的一些参数。
	-Xdebug
		启用调试特性。
	-Xrunjdwp:<sub-options>
		在目标 VM 中加载 JDWP 实现。它通过传输和 JDWP 协议与独立的调试器应用程序通信。下面介绍一些特定的子选项。
		从 Java V5 开始，您可以使用 -agentlib:jdwp 选项，而不是 -Xdebug 和 -Xrunjdwp。但如果连接到 V5 以前的 VM，只能选择 -Xdebug 和 -Xrunjdwp。下面简单描述 -Xrunjdwp 子选项。
	transport
		这里通常使用套接字传输。但是在 Windows 平台上也可以使用共享内存传输。
	server
		如果值为 y，目标应用程序监听将要连接的调试器应用程序。否则，它将连接到特定地址上的调试器应用程序。
	address
		这是连接的传输地址。如果服务器为 n，将尝试连接到该地址上的调试器应用程序。否则，将在这个端口监听连接。
	suspend
	如果值为 y，目标 VM 将暂停，直到调试器应用程序进行连接。
	要获得每个调试设置的详细解释，请参考 JPDA 文档（参见 参考资料）。
	清单 2 是一个示例，显示如何在调试模式下启动 VM 并监听端口 8765 的套接字连接。

	清单 2. 作为调试服务器的目标 VM
					
		-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8765

	清单 3 显示如何使用位于 8000 端口的主机 127.0.0.1 上的套接字连接运行中的调试器应用程序。

	清单 3. 作为调试客户机的目标 VM
					
		-Xdebug -Xrunjdwp:transport=dt_socket,address=127.0.0.1:8000

	from: http://www.ibm.com/developerworks/cn/opensource/os-eclipse-javadebug/
* 
	http://www.yake.org
	http://slashdot.org/story/06/04/21/213221/simple-open-source-3d-game-engines
	Vega Strike
		开源中国搜索
		http://zh.wikipedia.org/wiki/Vega_Strike
			相关链接
	http://dev.ryzom.com/projects/ryzom/wiki good have 
		http://www.cnblogs.com/xiaop/

		* ryzom
			模块化，组件化的设计。核心框架和业务无关，各自发展
			http://blog.sina.com.cn/s/articlelist_1850874464_0_4.html
		* doom3 engine开源
	sourceforge
		game category

* java dns 缓存
	%JAVA_HOME/jre/lib/security/java.security
	dns默认缓存30s，负值表示永久缓存，修改此值可能导致下面攻击：
		DNS spoofing attack/Cache poisoning attacks DNS欺骗攻击
		from: http://en.wikipedia.org/wiki/DNS_cache_poisoning
			
* 前端
	js测试工具：testacular	https://github.com/vojtajina/testacular/wiki
* 服务器端的无阻塞编程
	找到阻塞的点
	实现
	AIO(Async IO) ,EPOLL,TCP

	实现复杂性与性能的兼顾考虑
* IO模型
	linux IO模型
	阻塞I/O	非阻塞I/O	I/O复用	信号驱动I/O	异步IO
	see: http://www.cnblogs.com/aHuner/archive/2013/05/31/3110337.html

* SSL
	- SSL协议详解 http://kb.cnblogs.com/page/162080/
	- SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。
		TLS与SSL在传输层对网络连接进行加密。
	
* 格式化输出
	java提供工具类方便格式化输出

* 数据结构
	时间复杂度	
		　算法复杂度分为时间复杂度和空间复杂度。其作用： 时间复杂度是度量算法执行的时间长短；而空间复杂度是度量算法所需存储空间的大小
	随机存取（相对于顺序存取）
		是随机存储结构，意思就是你想找第几个数可以用下标直接找到
		而链式存储就不行，你想找第几个数必须一个一个地数过去，所以不是随机存储
	硬盘连续读写与随机读写
		

* 网络攻击
	- TMD = Theatre Missile Defense System (战区导弹防御系统)
		
	- CC攻击
	原理：
		CC攻击的原理就是攻击者控制某些主机不停地发大量数据包给对方服务器造成服务器资源耗尽，一直到宕机崩溃。CC主要是用来攻击页面的，
	每个人都有这样的体验：当一个网页访问的人数特别多的时候，打开网页就慢了，CC就是模拟多个用户（多少线程就是多少用户）不停地进行
	访问那些需要大量数据操作（就是需要大量CPU时间）的页面，造成服务器资源的浪费，CPU长时间处于100%，永远都有处理不完的连接直至
	就网络拥塞，正常的访问被中止。
		CC攻击可以归为DDoS攻击的一种。他们之间的原理都是一样的，即发送大量的请求数据来导致服务器拒绝服务，是一种连接攻击。
	CC攻击又可分为代理CC攻击，和肉鸡CC攻击。代理CC攻击是黑客借助代理服务器生成指向受害主机的合法网页请求，实现DOS，和伪装就叫：
	cc（Challenge Collapsar）。而肉鸡CC攻击是黑客使用CC攻击软件，控制大量肉鸡，发动攻击，相比来后者比前者更难防御。因为肉鸡可以模拟正常
	用户访问网站的请求。伪造成合法数据包。

	防御CC攻击可以通过多种方法，禁止网站代理访问，尽量将网站做成静态页面，限制连接数量等。
	from: http://baike.baidu.com/view/662394.htm

	- DDOS

	- 慢连接攻击 HTTP慢速连接攻击 Slowloris  HTTP POST Attack
		通过nginx等反向代理工具，防御部分慢连接攻击
		
		这个攻击的基本原理如下：
		针对任意HTTP Server，建立一个连接，指定一个比较大的content-length，然后以很低的速度发包，比如10-100s发一个字节，hold住这个连接不断开。
		如果客户端持续建立这样的连接，那么服务器上可用的连接将很快被占满，从而导致DOS.
		这一攻击引起我注意的原因有这几点：
		1) 它可以针对任意Web服务。HTTP协议在接收到request之前是无法对请求内容作校验的，所以即使你的Web应用没有可用form表单，这个攻击一样有效。
		2) 廉价。在客户端以单线程方式建立较大数量的无用连接，并保持持续发包的代价非常低廉。实际试验中一台普通PC可以建立的Socket连接在3000个以上。
		这对一台普通的web server，将是致命的打击。更不用说结合肉鸡群做分布式DOS了。
		http://blog.csdn.net/dcsno1/article/details/7180863 HTTP POST慢速DOS攻击初探
		
		http://lwn.net/Articles/418017/ Using HTTP POST for denial of service

	- SYN攻击	 SYN Flood	
		1) 原理
			在黑客攻击事件中，SYN攻击是最常见又最容易被利用的一种攻击手法。
		SYN攻击属于DoS攻击的一种，它利用TCP协议缺陷，通过发送大量的半连接请求，耗费CPU和内存资源。SYN攻击除了能影响主机外，还可以危害路由器、
		防火墙等网络系统，事实上SYN攻击并不管目标是什么系统，只要这些系统打开TCP服务就可以实施。服务器接收到连接请求（syn= j），将此信息加入未连接队列，
		并发送请求包给客户（syn=k,ack=j+1），此时进入SYN_RECV状态。当服务器未收到客户端的确认包时，重发请求包，一直到超时，才将此条目从未连接队列删除。
		配合IP欺骗，SYN攻击能达到很好的效果，通常，客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送syn包，服务器回复确认包，并等待客户的确认，
		由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，目标系统运行缓慢，严重者引起
		网络堵塞甚至系统瘫痪。	

		2) 检测syn攻击

		检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。
		我们使用系统自带的netstat 工具来检测SYN攻击：
		# netstat -n -p TCP
		tcp　0　 0 10.11.11.11:23　124.173.152.8:25882　 SYN_RECV　-
		tcp　0　 0 10.11.11.11:23　236.15.133.204:2577　 SYN_RECV　-
		tcp　0　 0 10.11.11.11:23　127.160.6.129:51748　 SYN_RECV　-
		...
		上面是在LINUX系统中看到的，很多连接处于SYN_RECV状态（在WINDOWS系统中是SYN_RECEIVED状态），源IP地址都是随机的，
		表明这是一种带有IP欺骗的SYN攻击。
		我们也可以通过下面的命令直接查看在LINUX环境下某个端囗的未连接队列的条目数：
		#netstat -n -p TCP | grep SYN_RECV | grep :22 | wc -l
		324
		显示TCP端囗22的未连接数有324个，虽然还远达不到系统极限，但应该引起管理员的注意。
		from: http://baike.baidu.com/view/488528.htm

		3) 防范技术
		关于SYN攻击防范技术，人们研究得比较早。归纳起来，主要有两大类，一类是通过防火墙、路由器等过滤网关防护，另一类是通过加固TCP/IP协议栈防范.
		但必须清楚的是，SYN攻击不能完全被阻止，我们所做的是尽可能的减轻SYN攻击的危害，除非将TCP协议重新设计。

	　　(1)过滤网关防护

		　　这里，过滤网关主要指明防火墙，当然路由器也能成为过滤网关。防火墙部署在不同网络之间，防范外来非法攻击和防止保密信息外泄，它处于客户端和服务器
		之间，利用它来防护SYN攻击能起到很好的效果。过滤网关防护主要包括超时设置，SYN网关和SYN代理三种。

		　　■网关超时设置：防火墙设置SYN转发超时参数（状态检测的防火墙可在状态表里面设置），该参数远小于服务器的timeout时间。当客户端发送完SYN包，服务端
		发送确认包后（SYN＋ACK），防火墙如果在计数器到期时还未收到客户端的确认包（ACK），则往服务器发送RST包，以使服务器从队列中删去该半连接。值得注意的是，
		网关超时参数设置不宜过小也不宜过大，超时参数设置过小会影响正常的通讯，设置太大，又会影响防范SYN攻击的效果，必须根据所处的网络应用环境来设置此参数。

		　　■SYN网关：SYN网关收到客户端的SYN包时，直接转发给服务器；SYN网关收到服务器的SYN/ACK包后，将该包转发给客户端，同时以客户端的名义给服务器发ACK确认包。
		此时服务器由半连接状态进入连接状态。当客户端确认包到达时，如果有数据则转发，否则丢弃。事实上，服务器除了维持半连接队列外，还要有一个连接队列，如果发生SYN攻击
		时，将使连接队列数目增加，但一般服务器所能承受的连接数量比半连接数量大得多，所以这种方法能有效地减轻对服务器的攻击。

		　　■SYN代理：当客户端SYN包到达过滤网关时，SYN代理并不转发SYN包，而是以服务器的名义主动回复SYN/ACK包给客户，如果收到客户的ACK包，表明这是正常的访问，
		此时防火墙向服务器发送ACK包并完成三次握手。SYN代理事实上代替了服务器去处理SYN攻击，此时要求过滤网关自身具有很强的防范SYN攻击能力。
		 　
		　　(2)加固tcp/ip协议栈
							                                                                    
		　　防范SYN攻击的另一项主要技术是调整tcp/ip协议栈，修改tcp协议实现。主要方法有SynAttackProtect保护机制、SYN cookies技术、增加最大半连接和缩短超时时间等。tcp/ip协议栈
		的调整可能会引起某些功能的受限，管理员应该在进行充分了解和测试的前提下进行此项工作。

		　　■SynAttackProtect机制

		　　为防范SYN攻击，win2000系统的tcp/ip协议栈内嵌了SynAttackProtect机制，Win2003系统也采用此机制。SynAttackProtect机制是通过关闭某些socket选项，增加额外的连接指示和
		减少超时时间，使系统能处理更多的SYN连接，以达到防范SYN攻击的目的。默认情况下，Win2000操作系统并不支持SynAttackProtect保护机制，需要在注册表以下位置增加
		SynAttackProtect键值：

		　　HKLM\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters

		　　当SynAttackProtect值（如无特别说明，本文提到的注册表键值都为十六进制）为0或不设置时，系统不受SynAttackProtect保护。

		　　当SynAttackProtect值为1时，系统通过减少重传次数和延迟未连接时路由缓冲项（route cache entry）防范SYN攻击。
	from: http://www.yesky.com/SoftChannel/72356665495650304/20040202/1764824_2.shtml

		

* 事务 数据库事务 
	- 事务并发问题：
		1) 脏读：包含未提交数据的读取。例如，事务1 更改了某行。事务2 在事务1 提交更改之前读取已更改的行。
			如果事务1 回滚更改，则事务2 便读取了逻辑上从未存在过的行。
		2) 不可重复读取：当某个事务不止一次读取同一行，并且一个单独的事务在两次（或多次）读取之间修改该行时，
			因为在同一个事务内的多次读取之间修改了该行，所以每次读取都生成不同值，从而引发不一致问题。
		3) 幻象：通过一个任务，在以前由另一个尚未提交其事务的任务读取的行的范围中插入新行或删除现有行。
			带有未提交事务的任务由于该范围中行数的更改而无法重复其原始读取。 
	- 根据隔离级别的不同，DBMS为并行访问提供不同的互斥保证。在SQL Server数据库中，提供四种隔离级别：
	未提交读、提交读、可重复读、可串行读。这四种隔离级别可以不同程度地保证并发的数据完整性：
		隔离级别	脏 读	不可重复读取	幻 像
		未提交读	是		是				是
		提交读		否		是				是
		可重复读	否		否				是
		可串行读	否		否				否
	
	解决办法：
		原则，能不用数据库锁就不用
		1) 若只是简单的更新，可直接在update语句中完成，而不是读出来修改后再写进去(如：update test set sum=sum+1)
		2) 若更新操作简单，在关键的更新处做是否成功判断来解决并发问题，如：
			问题：要抽出20个奖，可是最后并发多抽出了30个
			if (有未中奖的名额)  {
			    update(奖品状态为中奖);
			    insert(写入中奖列表);
			    echo(你中奖了！);
			} 
			
			修改为：
			if (有未中奖的名额)  {
			    if (update(奖品状态为中奖)) {
				insert(写入中奖列表);
				echo(你中奖了！);
			    }
			}
		3) 数据库锁


* windows下命令格式
	- netstat -an 1 |grep 220.181.111.148
	- 

11.18.2012 
* jvm dump堆栈
	- java命令行中配置jvm参数
		* set JVM parameters for head dump when OOM happens
		 * -XX:+HeapDumpOnOutOfMemoryError
		 * -XX:HeapDumpPath=d:\\tmp
		 * 
		 * set at run configure(+ is add,- is remove ,be care)
		 * 
		 * eg output:
		 * 
		 * java.lang.OutOfMemoryError: Java heap space
			Dumping heap to d:\\tmp\java_pid4608.hprof ...
			Heap dump file created [68393251 bytes in 0.462 secs]
			Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
				at java.util.HashMap.<init>(HashMap.java:187)
				at java.util.HashMap.<init>(HashMap.java:199)
				at test.OOM.testOOM.main(testOOM.java:28)
	- 主动获取堆栈
		 jstack dump堆栈信息 （以时间段dump多份便于对比）
			jstack 1345 > dump1

		windows系统
			tasklist
			jstack -l $PID
* IPMI
	- 智慧平台管理接口（Intelligent Platform Management Interface）原本是一种Intel架构的企业系统的周边设备所采用的一种工业标准。IPMI亦是一个开放的免费标准，使用者无需支付额外的费用即可使用此标准。
	IPMI 能够横跨不同的操作系统、固件和硬件平台，可以智慧型的监视、控制和自动回报大量服务器的运作状况，以降低服务器系统成本。
	from: http://zh.wikipedia.org/wiki/IPMI

	使用 ipmi 的先决条件——想要实现对服务器的 ipmi 管理，必须在硬件、OS、管理工具等几个方面都满足：
	from: http://www.chinahost.org/page-3490-1-1.html?fw=bipmi IPMI操作指南

	华为IMana管理程序对许多IPMI的传统功能支持更不在话下，如系统引导、控制台重定向、虚拟介质、传感器监控、电源控制、系统日志等等(eg: Tecal RH2285)

* select for update
	注意锁的级别，尽量减小锁的范围
	需要在事务中进行

	一个事物开启后，对记录进行了select for update查询
	另一个事物也需要进行select for update操作时需要等待前面一个事物的提交；或者等待锁超时，报：
	mysql> select * from region where region_no='test-region' for update;
	ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction

	尽可能让所有数据检索都通过索引来完成，从而避免InnoDB因为无法通过索引键加锁而升级为表级锁定。

	用乐观锁来实现数据库锁会锁定表的场景（非索引查询）；

* 缓存 缓存系统 cache 分布式缓存 缓存方案
	Cacheonix :
		Cacheonix is an open source clustered cache and distributed data management framework for Java that allows its users to scale Java applications 
		in a cluster while preserving the simplicity of design and coding in a single Java VM.
		主要特点：
			可靠的分布式 Java 缓存
			通过复制实现高可用性
			支持泛型的缓存 API
			可与 ORM 框架集成
			使用数据分区实现负载均衡
			支持非多播网络
			高性能计算
			快速的本地 Java 缓存
			分布式锁机制
		from: http://www.cacheonix.com/
* 产品
	产品的管理
	产品升级（迭代发布OR其他）
	运维管理
		产品的发布
			分级别发布（降低风险）
	
* 分布式事务 * distribute transaction
	例子
	JTA(java transaction api)
	JTOM：
		JOTM is an open source Transaction Manager implemented in java. It supports several transaction models and specifications providing transaction support for clients 
		using a wide range of middleware platforms (J2EE, CORBA, Web Services, OSGi).
		http://jotm.ow2.org/xwiki/bin/view/Main/

	
* http trunk

* jmonkeyengine

* apache common包
	老版本源码下载，有老版本区：
		http://archive.apache.org/dist/commons/dbcp/

* jetty http client	jetty httpclient
	- doc
		ref: http://www.eclipse.org/jetty/documentation/current/http-client-api.html

	- client通过装饰器模式Decorator，使用jdk5的ThreadPoolExecutor作为线程池调度
		 org.eclipse.jetty.util.thread.ExecutorThreadPool
		DOC
		-----
		Jetty ThreadPool using java 5 ThreadPoolExecutor This class wraps a ExecutorService(java.util.concurrent.ExecutorService) as a ThreadPool and LifeCycle interfaces 
		so that it may be used by the Jetty org.eclipse.jetty.server.Server

	- client的可配置项及其作用
		1）setConnectorType,设置client使用的connector类型，有socket和select两种
			SocketConnector
			SelectConnector
	- ref: http://blog.csdn.net/pwlazy/article/details/7389204
	- 介绍
		--------
		Introduction
			HttpClient is the Jetty component that allows to make requests and interpret responses to HTTP servers.
			This tutorial takes you through the steps necessary to use the HttpClient in the most effective way.

		Details
			The HttpClient is by its nature asynchronous. This means that the code that sends the request does not wait for the response to arrive before continuing. Instead, 
		the request is sent concurrently to your code, and the response is interpreted also concurrently with your code.
			The HttpClient API offers you callbacks to interact with the request-response lifecycle. These callbacks will be called by the HttpClient implementation to allow further 
		actions to be performed during each request-response event.
		
		A request-response unit is called exchange, and represent the exchange of information with the HTTP server.
		
		There are two main classes in the HttpClient API:
			org.eclipse.jetty.client.HttpClient, which manages the thread pooling, the proxy setting, the authentication settings, the connector type (blocking or non-blocking), the SSL 
		settings and the timeouts. HttpClient manages the configuration that does not depend on a particular exchange.
			org.eclipse.jetty.client.HttpExchange, which is the base class that you normally have to subclass that represent the exchange with the HTTP server, and manages HTTP 
		method, the request URI, HTTP headers, request content, HTTP response code, HTTP response headers and response content.
		
		HttpClient Setup

		Before exchanging requests/responses with the HTTP server, you need to setup the HttpClient and then start it:

		HttpClient client = new HttpClient();
		client.setConnectorType(HttpClient.CONNECTOR_SELECT_CHANNEL);
		client.start();
		You can also choose to setup the maximum number of connections per address (connections are pooled up to that maximum number), or to specify the thread pool, or the timeout:

		HttpClient client = new HttpClient();
		client.setConnectorType(HttpClient.CONNECTOR_SELECT_CHANNEL);
		client.setMaxConnectionsPerAddress(200); // max 200 concurrent connections to every address
		client.setThreadPool(new QueuedThreadPool(250)); // max 250 threads
		client.setTimeout(30000); // 30 seconds timeout; if no server reply, the request expires
		client.start();
		Remember to configure the HttpClient before starting it, or the settings will not have effect.

		Since HttpClient does not have any settings related to a particular address, it can be used to exchange requests/responses with several HTTP servers. You normally 
		need one HttpClient instance for all your needs, even if you plan to connect to multiple HTTP servers.

		Asynchronous Exchanges

		Once the HttpClient has been setup, exchanges may be initiated by using the HttpClient.send(HttpExchange exchange) method.

		The exchange must be configured with two mandatory fields: the address to connect to, and the request URI, or equivalently with an absolute URL:

		HttpExchange exchange = new HttpExchange();
		 
		// Optionally set the HTTP method
		exchange.setMethod("POST");
		 
		exchange.setAddress(new Address("ping.host.com", 80));
		exchange.setURI("/ping");
		// Or, equivalently, this:
		exchange.setURL("http://ping.host.com/ping");
		 
		client.send(exchange);
		 
		System.out.println("Exchange sent");

			The most important thing to remember is that the send() method returns immediately after dispatching the exchange to a thread pool for execution, so the System.out is executed 
		immediately after the send() method. It may be well true that the System.out is executed well before the exchange is actually executed, as well as it may be well true that the 
		System.out is executed after the exchange is completely executed (when even the request has been received).

		Beware of not assuming anything about the status of the exchange just because you called send().

		Controlling the Exchange Progress

		Because we used the HttpExchange class directly, without subclassing it, we have neither control nor notifications about the status of the exchange. The HttpExchange class exposes the following 
		callback methods to be overridden to be notified of the status of the exchange:

		onRequestCommitted(), called when the request line and the request headers have been sent to the HTTP server.
		onRequestComplete(), called when the request content has been sent to the HTTP server.
		onResponseStatus(Buffer httpVersion, int statusCode, Buffer statusMessage), called when the response line has been processed; the three parameters hold, respectively, 
			the HTTP version string (e.g. "HTTP/1.1"), the response status code (e.g. 200) and the response status message (e.g. "OK").
		onResponseHeader(Buffer name, Buffer value), called for each response header that has been processed; the parameters hold the name of the header (e.g. "Content-Length") 
			and the value of the header (e.g. "16384").
		onResponseHeaderComplete(), called when all response headers have been processed.
		onResponseContent(Buffer content), called multiple times for each chunk of the response content; the parameter holds the chunk of the content that has been received.
		onResponseComplete(), called when the response content has been completely received.
		Additionally four more methods can be overridden to be notified of non-normal conditions:

		onConnectionFailed(Throwable x), called when it is not possible to connect to the address specified in the exchange; the parameter holds the exception received while trying to connect.
		onException(Throwable x), called when a connection was possible, but an error happened later; the parameter holds the exception happened.
		onExpire(), called when the server did not respond before the timeout configured in the HttpClient.
		onRetry(), called when the exchange is resent (e.g. after an attempt to authenticate with no credentials).
		
		You can of course extend HttpExchange directly, but it's probably best to use Jetty's built-in class org.eclipse.jetty.client.ContentExchange. This class overrides most of the callback
		methods above to allow easy retrieval of the response status code, response headers and response body.

		Most of the times, you want to override onResponseComplete() to allow your business logic to read the response information (e.g. response status code or response body) and perform additional operations:

		ContentExchange exchange = new ContentExchange(true)
		{
		    protected void onResponseComplete() throws IOException
		    {
			int status = getResponseStatus();
			if (status == 200)
			    doSomething();
			else
			    handleError();
		    }
		};
		Synchronous Exchanges

		While asynchronous exchanges offer the most in term of performances, sometimes it is necessary to perform a synchronous exchange without the hassle of overriding methods to be 
		notified of response completion. This is possible by using the HttpExchange.waitForDone() method:

		HttpClient client = new HttpClient();
		client.start();
		 
		ContentExchange exchange = new ContentExchange(true);
		exchange.setURL("http://foobar.com/baz");
		 
		client.send(exchange);
		 
		// Waits until the exchange is terminated
		int exchangeState = exchange.waitForDone();
		 
		if (exchangeState == HttpExchange.STATUS_COMPLETED)
		    doSomething();
		else if (exchangeState == HttpExchange.STATUS_EXCEPTED)
		    handleError();
		else if (exchangeState == HttpExchange.STATUS_EXPIRED)
		    handleSlowServer();
		The waitForDone() method waits until the exchange state is in a "final" state, which could be that the exchange terminated successfully, or an exception was thrown or it expired.

		SSL Connections

		In order to configure HttpClient to validate SSL certificates and/or to supply a client certificate to the server, follow the instructions in SSL Connectors Reference to configure a 
		SslContextFactory object and pass it as a parameter to the HttpClient's constructor.
		--------
		from: http://wiki.eclipse.org/Jetty/Tutorial/HttpClient	jetty http client tutorial



* jetty
	- 架构
		connector,handler,threadpool
	- 起多个jetty实例用于web服务，设置不同端口
		
	- 配置远程调试时，应用启动错误
		JAVA_OPTIONS="$JAVA_OPTIONS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=y"	
		suspend=y 表示启动时进入调试

	- jetty支持ajp协议，加载jetty-ajp.xml配置即可，实现jetty外面一层反向代理层。如apache+jetty
		or haproxy+jetty ,nginx+jetty
	- jetty web结构及部署实践
		jetty-maven-plugin
		1）下载jetty7或更高版本
		2）解压
		3）mv到安装目录，并用ln -s命令起个连接
		jetty安装完毕
		通过bin下的脚本来执行启动关闭等操作

		下载api的jetty运行目录，里面配置了基本信息，通过此目录来起停api
			etc目录自己管理，start.ini配置启动项


	- jetty介绍
		Jetty provides an HTTP server, HTTP client, and javax.servlet container. These components are open source and available for commercial use and distribution.
		Jetty is used in a wide variety of projects and products. Jetty can be embedded in devices, tools, frameworks, application servers, and clusters. See the Jetty Powered page 
	for more uses of Jetty.
		The core Jetty project is hosted by the Eclipse Foundation. The codehaus provides Jetty accessories , integrations, and extensions, as well as hosting older versions of Jetty. 
	See the About page for information about the project structure.
	from: http://jetty.codehaus.org/jetty/


* Jetty7 Continuation
	- API注释中对continuation的说明：
		Continuation. A continuation is a mechanism by which a HTTP Request can be suspended and restarted after a timeout or an asynchronous event has occurred. 
	- 异步HTTP

自行车 钢货架
* code source code
	http://www.codeproject.com/
* jprofiler ,MAT, 内存分析工具，性能分析工具，检测工具
	- jprofiler测试
		可通过模拟场景来使用JProfiler分析，比如模拟内存溢出，模拟死锁等各种情况。	    反向方式来学习JProfiler的使用
		
	- Memory Analyzer (MAT)
		The Eclipse Memory Analyzer is a fast and feature-rich Java heap analyzer that helps you find memory leaks and reduce memory consumption.
			Use the Memory Analyzer to analyze productive heap dumps with hundreds of millions of objects, quickly calculate the retained sizes of objects, 
		see who is preventing the Garbage Collector from collecting objects, run a report to automatically extract leak suspects.
		http://www.eclipse.org/mat/
* excel单元格换行（手动）
	ALT + Enter
* ESB enterprise service bus
	企业级服务总线
	SOA

* ethtool
	
	tso、gso
	------
		Large segment offload
		From Wikipedia, the free encyclopedia


		Dialogue box showing offload TCP segmentation settings for an Intel Pro 1000 NIC
		In computer networking, large segment offload (LSO) is a technique for increasing outbound throughput of high-bandwidth network connections by reducing CPU overhead. It works by queuing up large buffers and letting the network interface card (NIC) split them into separate packets. The technique is also called TCP segmentation offload (TSO) when applied to TCP, or generic segmentation offload (GSO).
		The inbound counterpart of large segment offload is large receive offload (LRO).
		[edit]Operation

		When large chunks of data are to be sent over a computer network, they need to be first broken down to smaller segments that can pass through all the network elements like routers and switches between the source and destination computers. This process is referred to as segmentation. Segmentation is often done by the TCP protocol in the host computer. Offloading this work to the NIC is called TCP segmentation offload (TSO).
		For example, a unit of 64KB (65,536 bytes) of data is usually segmented to 46 segments of 1448 bytes each before it is sent over the network through the NIC. With some intelligence in the NIC, the host CPU can hand over the 64 KB of data to the NIC in a single transmit request, the NIC can break that data down into smaller segments of 1448 bytes, add the TCP, IP, and data link layer protocol headers -- according to a template provided by the host's TCP/IP stack -- to each segment, and send the resulting frames over the network. This significantly reduces the work done by the CPU. Many new NICs on the market today support TSO.
		Some network cards implement TSO generically enough that it can be used for offloading fragmentation of other transport layer protocols, or by doing IP fragmentation for protocols that don't support fragmentation by themselves, such as UDP.
	------
	
	ref: http://en.wikipedia.org/wiki/Large_segment_offload

* 灰度发布 灰度发布引擎 , 不同版本兼容问题设计
		灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部用户继续用A，一部分用户开始用B，
	如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、
	调整问题，以保证其影响度。
	from：http://baike.baidu.com/view/2563299.htm

* keluda * 组件化 组件化系统设计，架构设计
	当前只使用缺陷管理模块，取代原来的bugfree（不便于统计和bug全局管理）

	
* JVM配置，jvm优化
	------
		Java HotSpot VM Options

		XML 
		This document provides information on typical command-line options and environment variables that can affect the performance characteristics of the Java HotSpot Virtual Machine. 
		Unless otherwise noted, all information in this document pertains to both the Java HotSpot Client VM and the Java HotSpot Server VM.

		Categories of Java HotSpot VM Options
		  
		Standard options recognized by the Java HotSpot VM are described on the Java Application Launcher reference pages for Windows, Solaris and Linux. This document deals exclusively 
		with non-standard options recognized by the Java HotSpot VM:

		Options that begin with -X are non-standard (not guaranteed to be supported on all VM implementations), and are subject to change without notice in subsequent releases of the JDK.
		Options that are specified with -XX are not stable and are subject to change without notice.
		Users of JDKs older than 1.3.0 who wish to port to a Java HotSpot VM, should see Java HotSpot Equivalents of Exact VM flags.

		Some Useful -XX Options
		  
		Default values are listed for Java SE 6 for Solaris Sparc with -server. Some options may vary per architecture/OS/JVM version. Platforms with a differing default value are listed in the description.

		Boolean options are turned on with -XX:+<option> and turned off with -XX:-<option>.
		Numeric options are set with -XX:<option>=<number>. Numbers can include 'm' or 'M' for megabytes, 'k' or 'K' for kilobytes, and 'g' or 'G' for gigabytes (for example, 32k is the same as 32768).
		String options are set with -XX:<option>=<string>, are usually used to specify a file, a path, or a list of commands
		Flags marked as manageable are dynamically writeable through the JDK management interface (com.sun.management.HotSpotDiagnosticMXBean API) and also through JConsole. In Monitoring and Managing Java SE 6 Platform Applications, Figure 3 shows an example. The manageable flags can also be set through jinfo -flag. 

		The options below are loosely grouped into categories.

		Behavioral options change the basic behavior of the VM.
		Garbage First (G1) Garbage Collection Options
		Performance tuning options are knobs which can be used to tune VM performance.
		Debugging options generally enable tracing, printing, or output of VM information.
		  
		Behavioral Options

		Option and Default Value	Description
		-XX:-AllowUserSignalHandlers	Do not complain if the application installs signal handlers. (Relevant to Solaris and Linux only.)
		-XX:AltStackSize=16384	Alternate signal stack size (in Kbytes). (Relevant to Solaris only, removed from 5.0.)
		-XX:-DisableExplicitGC	Disable calls to System.gc(), JVM still performs garbage collection when necessary.
		-XX:+FailOverToOldVerifier	Fail over to old verifier when the new type checker fails. (Introduced in 6.)
		-XX:+HandlePromotionFailure	The youngest generation collection does not require a guarantee of full promotion of all live objects. (Introduced in 1.4.2 update 11) [5.0 and earlier: false.]
		-XX:+MaxFDLimit	Bump the number of file descriptors to max. (Relevant  to Solaris only.)
		-XX:PreBlockSpin=10	Spin count variable for use with -XX:+UseSpinning. Controls the maximum spin iterations allowed before entering operating system thread synchronization code. (Introduced in 1.4.2.)
		-XX:-RelaxAccessControlCheck	Relax the access control checks in the verifier. (Introduced in 6.)
		-XX:+ScavengeBeforeFullGC	Do young generation GC prior to a full GC. (Introduced in 1.4.1.)
		-XX:+UseAltSigs	Use alternate signals instead of SIGUSR1 and SIGUSR2 for VM internal signals. (Introduced in 1.3.1 update 9, 1.4.1. Relevant to Solaris only.)
		-XX:+UseBoundThreads	Bind user level threads to kernel threads. (Relevant to Solaris only.)
		-XX:-UseConcMarkSweepGC	Use concurrent mark-sweep collection for the old generation. (Introduced in 1.4.1)
		-XX:+UseGCOverheadLimit	Use a policy that limits the proportion of the VM's time that is spent in GC before an OutOfMemory error is thrown. (Introduced in 6.)
		-XX:+UseLWPSynchronization	Use LWP-based instead of thread based synchronization. (Introduced in 1.4.0. Relevant to Solaris only.)
		-XX:-UseParallelGC	Use parallel garbage collection for scavenges. (Introduced in 1.4.1)
		-XX:-UseParallelOldGC	Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC. (Introduced in 5.0 update 6.)
		-XX:-UseSerialGC	Use serial garbage collection. (Introduced in 5.0.)
		-XX:-UseSpinning	Enable naive spinning on Java monitor before entering operating system thread synchronizaton code. (Relevant to 1.4.2 and 5.0 only.) [1.4.2, multi-processor Windows platforms: true]
		-XX:+UseTLAB	Use thread-local object allocation (Introduced in 1.4.0, known as UseTLE prior to that.) [1.4.2 and earlier, x86 or with -client: false]
		-XX:+UseSplitVerifier	Use the new type checker with StackMapTable attributes. (Introduced in 5.0.)[5.0: false]
		-XX:+UseThreadPriorities	Use native thread priorities.
		-XX:+UseVMInterruptibleIO	Thread interrupt before or with EINTR for I/O operations results in OS_INTRPT. (Introduced in 6. Relevant to Solaris only.)

		Back to Options 
		  
		Garbage First (G1) Garbage Collection Options

		Option and Default Value	Description
		-XX:+UseG1GC	Use the Garbage First (G1) Collector
		-XX:MaxGCPauseMillis=n	Sets a target for the maximum GC pause time. This is a soft goal, and the JVM will make its best effort to achieve it.
		-XX:InitiatingHeapOccupancyPercent=n	Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes 'do constant GC cycles'. The default value is 45.
		-XX:NewRatio=n	Ratio of new/old generation sizes. The default value is 2.
		-XX:SurvivorRatio=n	Ratio of eden/survivor space size. The default value is 8.
		-XX:MaxTenuringThreshold=n	Maximum value for tenuring threshold. The default value is 15.
		-XX:ParallelGCThreads=n	Sets the number of threads used during parallel phases of the garbage collectors. The default value varies with the platform on which the JVM is running.
		-XX:ConcGCThreads=n	Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running.
		-XX:G1ReservePercent=n	Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10.
		-XX:G1HeapRegionSize=n	With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb.

		Back to Options 
		 
		Performance Options

		Option and Default Value	Description
		-XX:+AggressiveOpts	Turn on point performance compiler optimizations that are expected to be default in upcoming releases. (Introduced in 5.0 update 6.)
		-XX:CompileThreshold=10000	Number of method invocations/branches before compiling [-client: 1,500]
		-XX:LargePageSizeInBytes=4m	Sets the large page size used for the Java heap. (Introduced in 1.4.0 update 1.) [amd64: 2m.]
		-XX:MaxHeapFreeRatio=70	Maximum percentage of heap free after GC to avoid shrinking.
		-XX:MaxNewSize=size	Maximum size of new generation (in bytes). Since 1.4, MaxNewSize is computed as a function of NewRatio. [1.3.1 Sparc: 32m; 1.3.1 x86: 2.5m.]
		-XX:MaxPermSize=64m	Size of the Permanent Generation.  [5.0 and newer: 64 bit VMs are scaled 30% larger; 1.4 amd64: 96m; 1.3.1 -client: 32m.]
		-XX:MinHeapFreeRatio=40	Minimum percentage of heap free after GC to avoid expansion.
		-XX:NewRatio=2	Ratio of new/old generation sizes. [Sparc -client: 8; x86 -server: 8; x86 -client: 12.]-client: 4 (1.3) 8 (1.3.1+), x86: 12]
		-XX:NewSize=2m	Default size of new generation (in bytes) [5.0 and newer: 64 bit VMs are scaled 30% larger; x86: 1m; x86, 5.0 and older: 640k]
		-XX:ReservedCodeCacheSize=32m	Reserved code cache size (in bytes) - maximum code cache size. [Solaris 64-bit, amd64, and -server x86: 48m; in 1.5.0_06 and earlier, Solaris 64-bit and amd64: 1024m.]
		-XX:SurvivorRatio=8	Ratio of eden/survivor space size [Solaris amd64: 6; Sparc in 1.3.1: 25; other Solaris platforms in 5.0 and earlier: 32]
		-XX:TargetSurvivorRatio=50	Desired percentage of survivor space used after scavenge.
		-XX:ThreadStackSize=512	Thread Stack Size (in Kbytes). (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]
		-XX:+UseBiasedLocking	Enable biased locking. For more details, see this tuning example. (Introduced in 5.0 update 6.) [5.0: false]
		-XX:+UseFastAccessorMethods	Use optimized versions of Get<Primitive>Field.
		-XX:-UseISM	Use Intimate Shared Memory. [Not accepted for non-Solaris platforms.] For details, see Intimate Shared Memory.
		-XX:+UseLargePages	Use large page memory. (Introduced in 5.0 update 5.) For details, see Java Support for Large Memory Pages.
		-XX:+UseMPSS	Use Multiple Page Size Support w/4mb pages for the heap. Do not use with ISM as this replaces the need for ISM. (Introduced in 1.4.0 update 1, Relevant to Solaris 9 and newer.) [1.4.1 and earlier: false]
		-XX:+UseStringCache	Enables caching of commonly allocated strings.
		 
		-XX:AllocatePrefetchLines=1	Number of cache lines to load after the last object allocation using prefetch instructions generated in JIT compiled code. Default values are 1 if the last allocated object was an instance and 3 if it was an array. 
		 
		-XX:AllocatePrefetchStyle=1	Generated code style for prefetch instructions.
		0 - no prefetch instructions are generate*d*,
		1 - execute prefetch instructions after each allocation,
		2 - use TLAB allocation watermark pointer to gate when prefetch instructions are executed.
		 
		-XX:+UseCompressedStrings	Use a byte[] for Strings which can be represented as pure ASCII. (Introduced in Java 6 Update 21 Performance Release) 
		 
		-XX:+OptimizeStringConcat	Optimize String concatenation operations where possible. (Introduced in Java 6 Update 20) 
		 

		Back to Options 
		  
		Debugging Options

		Option and Default Value	Description
		-XX:-CITime	Prints time spent in JIT Compiler. (Introduced in 1.4.0.)
		-XX:ErrorFile=./hs_err_pid<pid>.log	If an error occurs, save the error data to this file. (Introduced in 6.)
		-XX:-ExtendedDTraceProbes	Enable performance-impacting dtrace probes. (Introduced in 6. Relevant to Solaris only.)
		-XX:HeapDumpPath=./java_pid<pid>.hprof	Path to directory or filename for heap dump. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)
		-XX:-HeapDumpOnOutOfMemoryError	Dump heap to file when java.lang.OutOfMemoryError is thrown. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)
		-XX:OnError="<cmd args>;<cmd args>"	Run user-defined commands on fatal error. (Introduced in 1.4.2 update 9.)
		-XX:OnOutOfMemoryError="<cmd args>; 
		<cmd args>"	Run user-defined commands when an OutOfMemoryError is first thrown. (Introduced in 1.4.2 update 12, 6)
		-XX:-PrintClassHistogram	Print a histogram of class instances on Ctrl-Break. Manageable. (Introduced in 1.4.2.) The jmap -histo command provides equivalent functionality.
		-XX:-PrintConcurrentLocks	Print java.util.concurrent locks in Ctrl-Break thread dump. Manageable. (Introduced in 6.) The jstack -l command provides equivalent functionality.
		-XX:-PrintCommandLineFlags	Print flags that appeared on the command line. (Introduced in 5.0.)
		-XX:-PrintCompilation	Print message when a method is compiled.
		-XX:-PrintGC	Print messages at garbage collection. Manageable.
		-XX:-PrintGCDetails	Print more details at garbage collection. Manageable. (Introduced in 1.4.0.)
		-XX:-PrintGCTimeStamps	Print timestamps at garbage collection. Manageable (Introduced in 1.4.0.)
		-XX:-PrintTenuringDistribution	Print tenuring age information.
		-XX:-TraceClassLoading	Trace loading of classes.
		-XX:-TraceClassLoadingPreorder	Trace all classes loaded in order referenced (not loaded). (Introduced in 1.4.2.)
		-XX:-TraceClassResolution	Trace constant pool resolutions. (Introduced in 1.4.2.)
		-XX:-TraceClassUnloading	Trace unloading of classes.
		-XX:-TraceLoaderConstraints	Trace recording of loader constraints. (Introduced in 6.)
		-XX:+PerfSaveDataToFile	Saves jvmstat binary data on exit.
		-XX:ParallelGCThreads=n	Sets the number of garbage collection threads in the young and old parallel garbage collectors. The default value varies with the platform on which the JVM is running.
		-XX:+UseCompressedOops	Enables the use of compressed pointers (object references represented as 32 bit offsets instead of 64-bit pointers) for optimized 64-bit performance with Java heap sizes less than 32gb.
		-XX:+AlwaysPreTouch	Pre-touch the Java heap during JVM initialization. Every page of the heap is thus demand-zeroed during initialization rather than incrementally during application execution.
		-XX:AllocatePrefetchDistance=n	Sets the prefetch distance for object allocation. Memory about to be written with the value of new objects is prefetched into cache at this distance (in bytes) beyond the address of the last allocated object. Each Java thread has its own allocation point. The default value varies with the platform on which the JVM is running.
		-XX:InlineSmallCode=n	Inline a previously compiled method only if its generated native code size is less than this. The default value varies with the platform on which the JVM is running.
		-XX:MaxInlineSize=35	Maximum bytecode size of a method to be inlined.
		-XX:FreqInlineSize=n	Maximum bytecode size of a frequently executed method to be inlined. The default value varies with the platform on which the JVM is running.
		-XX:LoopUnrollLimit=n	Unroll loop bodies with server compiler intermediate representation node count less than this value. The limit used by the server compiler is a function of this value, not the actual value. The default value varies with the platform on which the JVM is running.
		-XX:InitialTenuringThreshold=7	Sets the initial tenuring threshold for use in adaptive GC sizing in the parallel young collector. The tenuring threshold is the number of times an object survives a young collection before being promoted to the old, or tenured, generation.
		-XX:MaxTenuringThreshold=n	Sets the maximum tenuring threshold for use in adaptive GC sizing. The current largest value is 15. The default value is 15 for the parallel collector and is 4 for CMS.
		-Xloggc:<filename>	Log GC verbose output to specified file. The verbose output is controlled by the normal verbose GC flags.
		-XX:-UseGCLogRotation	Enabled GC log rotation, requires -Xloggc.
		-XX:NumberOfGClogFiles=1	Set the number of files to use when rotating logs, must be >= 1. The rotated log files will use the following naming scheme, <filename>.0, <filename>.1, ..., <filename>.n-1.
		-XX:GCLogFileSize=8K	The size of the log file at which point the log will be rotated, must be >= 8K.
	------
	from: http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html

* 代码review辅助工具 * review board
	- Code Review Tool
		Install Code Review Tool (only once):
		Open ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/ .
		Register to create your account.
		Use svn up to sync the latest code. The should be a bin directory under the repository root containing post-review and review.tmpl.
		Use cp review.tmpl review to create your version of review script. Modify review file by finding --username=your-name and replacing your-name with your account name registered in step 1. NOTE: Don't delete the space right after your name, otherwise you will encounter problem when you run review script with parameters.
		Modify your ~/.bashrc and add these lines:
			#export LANG=en_US.UTF-8
			#export LANGUAGE=en_US.UTF-8
			#export LC_ALL=en_US.UTF-8
			export PATH=$PATH:/<your repository path>/bin
		Open a new console to start using reviewboard.
		Use su to change to root account
		rpm -ivh ​http://yum.ops.aliyun-inc.com/application/5Server/x86_64/apsara/python-simplejson-2.0.3-3.el5.x86_64.rpm
		Use exit back to your account
		Review steps:
		Modify code.
		If there is new file created, type svn add <file-name>. Otherwise, the content will not be covered in the laterly generated diff file.
		Run review to submit a review item to Review Board.
		Use browser to login Review Board and find your review item draft.
		Add summary, reviewers, description for your item and publish.
		Waiting for review result and check in after approval.
		Apply diff to your local source tree:
		Start with a clean source tree. If you are editing some files in the current tree, use "svn co" to create another tree for code review.
		Click "Download Diff" in the Review Board UI. Save the diff file to your local disk.
		In the project root directory, use "patch -i diff_file -p2" to apply diff.
		(Notes: "-p2" will strip 2 leading slashes from each file name found in the diff_file. For example, supposing the file name in the diff_file was "/trunk/include/apsara/common/safeguard.h", setting -p2 gives "include/apsara/common/safeguard.h", -p0 gives the entire file name unmodified.)
		(Tips: su and apt-get install patch and exit if get 'patch: command not found' prompt)
		(Tips: please ensure the diff is created under the root directory of Apsara source code)
		(Tisp: -pNum means skip Num Slashes when do the patch, please refer to "man patch")
		Now your local source tree is modified according to the diff.
		When finished, use "svn revert . -R" (Do not doubt there is a flaw on your screen between "revert" and "-R". That is exact a dot indicating where the project root is) to revert changes.
		NOTE: This removes all your local changes on this patched copy of the project except for those newly created file by patch. So be sure not to do revert on your own working copy !
		NOTE:
		When you modified code according to a review comment, please use "add comment" to mark it as "done". If you made a different change or think the comment is wrong, also use "add comment" to take note, e.g. "done using a different implementation: ..." or "this is not a bug, because ...".
		When you finished modifying code, please update the review request with new code. Please don't create a new review request. Run 'review -r reviewNum' to update the previous request.
		3. Remember to close review requests (mark as 'submitted') when the code has been checked in.

		Manual steps if you don't use above script
		cd to your apsara root folder. e.g /home/<alias>/apsara
		CMD svn diff > mychange.diff
		login ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/
		click "New Review Request"
		in Base Diff path, input "trunk"
		in diff, browse and select diff file you just created.
		click "Create Review Request"
		in next page, input title for your review request, usually we use [Project]-[component name] as prefix, e.g: AOS-Fuxi ir AUC-XXXX.
		select people you want to send review to. then publish your review request.
		How to enable syntax highlighting for your code review
		Login your review board site.
		Navigate into my account page by the url ​http://reviewboard.dev.sd.aliyun.com/ReviewBoard/account/preferences/ .
		Choose the checkbox "Enable syntax highlighting in the diff viewer" and save it. The default status is unchecked.
		NOTE: If enabled, syntax highlighting will be used in the Diff Viewer. This offers improved readability of diffs, but takes longer time to render.	
		from: http://wiki.aliyun-inc.com/projects/apsara/wiki/ApsaraDevEnv#no1
	- 
		reviewboard.
			Take the pain out of code review
			http://www.reviewboard.org/docs/manual/1.0/
		python实现：
		项目主页：
			http://code.google.com/p/reviewboard/
		
		使用方法：
			1)   在飞天reviewboard上注册账号<http://reviewboard.dev.sd.aliyun.com/>
			2)   通过网页提交review requests或者使用post-review命令行提交(网页有坑，反正我是提交失败了)

			Post-review依赖于python2.7，需要设置下环境变量
			[root@AT-HOUYIDEV-AG]$ unalias  post-review    
			[root@AT-HOUYIDEV-AG]$ export PATH=/home/tops/bin:/usr/local/bin:$PATH
			[root@AT-HOUYIDEV-AG]$ cd /apsarapangu/disk4/apsara-0.8.6/ec_flow_billing
			[root@AT-HOUYIDEV-AG]$ post-review  --server=http://reviewboard.dev.sd.aliyun.com/ReviewBoard --summary='xxxx'  --username=xxx --revision-range=R1:R2
			会生产一个request链接，贴到浏览器里头，修改review request的相关描述并publish。

		通过review board页面提交或者通过post-review命令工具实现
			post-review命令参数说明，查看其.py源码，找到帮助，sudo post-review --help
	
* htttpd
	apache服务器，指定httpd.cof文件启动，在执行命令的目录下的confi文件夹中的，tpd.conf文件中配置~~。。。
* 设计模式
	- 工厂模式是创建型模式中最典型的模式，主要是用来创建对象，减少我们在使用某个对象时的new() 操作，我相信大家都有这样的困惑，
	目前我所在的项目都在程序开发的过程中，还是有很多的new()操作出现在表现层中，并没有通过工厂来创建对象，一方面可能是因为我们自身比较懒，
	不规范项目的编码形式，另外一方面也是由于项目的进度比较紧，没有那么多的时间去
	完成工厂的统一创建，当然对于这样的动态创建对象的工厂，推荐的做法还是我们后面会讲到的创建型模式--《抽象工厂模式》来解决吧。
	from: http://www.cnblogs.com/hegezhou_hot/archive/2010/11/30/1892227.html
	- 策略模式
	看springMVC的DispatcherServlet

* Megastore:
	Providing Scalable, Highly Available
Storage for Interactive Services
* jmx 监控 java监控 性能监控 性能
	java，javaee程序监控插件：http://code.google.com/p/javamelody/

* tomcat6			 tomcat源码分析 tomcat7
	- servlet3.0 tomcat7
		下载tomcat7 trunk源码
		查看其build.xml文件，已经定义了ide-eclipse target，方便将项目转为eclipse项目
		导入eclipse即可



	- 配置远程debug
		call "%EXECUTABLE%" start %CMD_LINE_ARGS%
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%
	- Comet support tomcat6
		Comet support allows a servlet to process IO asynchronously, receiving events when data is available for reading on the connection (rather than always 
		using a blocking read), and writing data back on connections asynchronously (most likely responding to some event raised from some other source).
		ref: http://localhost:8080/docs/aio.html
	- tomcat架构，组件层次
		最外层是Server，内部有多个Service，每个Service内部有多个Connector和多个Engine，每个Engine中可以有多个Host和，每个Host中可以有多个Context即webapp

		这个层次结构从tomcat的server.xml文件的层次中能看出，在其自带的文档关于架构部分也有说明。


		Apache Tomcat Architecture　ref: http://localhost:8080/docs/architecture/index.html 自带Doc中有关于架构的说明
			Overview - An overview of the Tomcat server architecture with key terms and concepts.
			Server Startup - A detailed description, with sequence diagrams, of how the Tomcat server starts up.
			Request Process Flow - A detailed description of how Tomcat handles a request.

	- tomcat6类加载器层次
		Bootstrap->System->Common-->Webapp1
								|->Webapp2
		说明：					
			Bootstrap — This class loader contains the basic runtime classes provided by the Java Virtual Machine, plus any classes from JAR files present in the System Extensions 
						directory ($JAVA_HOME/jre/lib/ext). Note: some JVMs may implement this as more than one class loader, or it may not be visible (as a class loader) at all.
			System — This class loader is normally initialized from the contents of the CLASSPATH environment variable. All such classes are visible to both Tomcat internal classes, 
						and to web applications. However, the standard Tomcat startup scripts ($CATALINA_HOME/bin/catalina.sh or %CATALINA_HOME%\bin\catalina.bat) totally ignore 
						the contents of the CLASSPATH environment variable itself, and instead build the System class loader from the following repositories:
				- $CATALINA_HOME/bin/bootstrap.jar — Contains the main() method that is used to initialize the Tomcat server, and the class loader implementation classes it depends on.
				- $CATALINA_BASE/bin/tomcat-juli.jar and $CATALINA_HOME/bin/tomcat-juli.jar — Logging implementation classes. These include enhancement classes to java.util.logging API, 
				known as Tomcat JULI, and a package-renamed copy of Apache Commons Logging library used internally by Tomcat. See logging documentation for more details.
				- $CATALINA_HOME/bin/commons-daemon.jar — The classes from Apache Commons Daemon project.

				The tomcat-juli.jar and commons-daemon.jar JARs in $CATALINA_HOME/bin are not present in the CLASSPATH built by catalina.bat|.sh scripts, but are referenced from 
				the manifest file of bootstrap.jar.

				If $CATALINA_BASE and $CATALINA_HOME do differ and $CATALINA_BASE/bin/tomcat-juli.jar does exist, the startup scripts will add it to CLASSPATH before bootstrap.jar, 
				so that Java will look into $CATALINA_BASE/bin/tomcat-juli.jar for classes before it will look into $CATALINA_HOME/bin/tomcat-juli.jar referenced by bootstrap.jar. It should work 
				in most cases but, if you are using such configuration, it might be recommended to remove tomcat-juli.jar from $CATALINA_HOME/bin so that only one copy of the file is present on the 
				classpath. The next version of Tomcat, Tomcat 7, takes different approach here.
			Common — This class loader contains additional classes that are made visible to both Tomcat internal classes and to all web applications.
				Normally, application classes should NOT be placed here. The locations searched by this class loader are defined by the common.loader property in 
				$CATALINA_BASE/conf/catalina.properties. The default setting will search the following locations in the order they are listed:
					- unpacked classes and resources in $CATALINA_BASE/lib
					- JAR files in $CATALINA_BASE/lib
					- unpacked classes and resources in $CATALINA_HOME/lib
					- JAR files in $CATALINA_HOME/lib
			WebappX — A class loader is created for each web application that is deployed in a single Tomcat instance. All unpacked classes and resources in the /WEB-INF/classes 
				directory of your web application, plus classes and resources in JAR files under the /WEB-INF/lib directory of your web application, are made visible to this web application, 
				but not to other ones.

		ref: http://localhost:8080/docs/class-loader-howto.html
	- 结合tomcat使用NIO来理解
		---------
			在web服务器上阻塞IO(BIO)与NIO一个比较重要的不同是，我们使用BIO的时候往往会为每一个web请求引入多线程，每个web请求一个单独的线程，
			所以并发量一旦上去了，线程数就上去了，CPU就忙着线程切换，所以BIO不合适高吞吐量、高可伸缩的web服务器；而NIO则是使用单线程(单个CPU)或者
			只使用少量的多线程(多CPU)来接受Socket，而由线程池来处理堵塞在pipe或者队列里的请求.这样的话，只要OS可以接受TCP的连接，web服务器就可以处理该请求。
			大大提高了web服务器的可伸缩性。

			从Tomcat6.0以后, Java开发者很容易就可以是用NIO的技术来提升tomcat的并发处理能力。

			<Connector port="8080" protocol="HTTP/1.1"
			connectionTimeout="20000"
			redirectPort="8443" />
			修改成：

			<Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol"
			connectionTimeout="20000"
			redirectPort="8443" />
			然后启动服务器，你会看到org.apache.coyote.http11.Http11NioProtocol start的信息，表示NIO已经启动
		---------
		ref: http://www.cnblogs.com/killbug/archive/2012/11/25/2787717.html

	- bootstrap
		org.apache.catalina.startup.Bootstrap
		main方法的：daemon.load(args); daemon.start(); 为主要启动过程，前面是初始化等工作
		
	-
	feature：NIO,MBEAN etc
	svn: http://svn.apache.org/repos/asf/tomcat/tc6.0.x/trunk/

	- tomcat源码分析 ant项目导入 导入ant项目
		--------
			Tomcat的体系结构或者源码，
			将Tomcat的源码导入到ide中，编写实例进行代码跟踪（debug）。

			准备：
			1.Tomcat源码下载

			这个里下载tomcat-6.0.33源码。
			2.ant安装，用于编译tomcat的源码。
			ant下载解压后将其bin添加到系统环境path中。
			3.IDE——选用Eclipse3.7。
			 
			=================================
			第一步：
			解压Tomcat源码，例如解压到D:\tomcat\apache-tomcat-6.0.33-src。
			第二步：
			2.1）使用ant编译tomcat源码，在编译之前需要下载相关的依赖项目。我们并不知道编译需要哪些依赖项目，怎么办？
			让ant来帮忙吧！我们只需要准备一个存放这些依赖项目的地方，例如d:\tomcat\basepath。
			2.2）要让ant工作起来，我们还要将apache-tomcat-6.0.33-src文件夹中的build.properties.default重命名为build.properties，
			并且打开它，修改base.path=d:\tomcat\basepath。
			2.3）下载依赖项目，进入命令控制台，进入目录D:\tomcat\apache-tomcat-6.0.33-src，执行命令：ant download。
			2.4）等依赖项目下载好后，就可以编译tomcat了。执行命令：ant。当编译完成后，我们可以查看目录D:\tomcat\apache-tomcat-6.0.33-src，
			可以发现里面多了一个文件夹：output。
			output文件夹的结构如下：

			我们会发现这个结构和从安装包里解压出来的tomcat结构一致。
			进入bin，启动tomcat成功，就说明——ant编译tomcat成功了！
			 
			=====================================
			将tomcat源码导入eclipse。
			第一步：
			在eclipse里新建一个java项目，例如：tomcat6。
			第二步：
			import->file system
			在From directory选择tomcat源码，选择java和test（如果你需要测试的话选择test），如下图：

			在into folder中选择我们刚新建的tomcat6，finish。
			note：将java、test设置成source folder，java build path ->Source->Add folder...->选择java和test。
			现在项目结构如下图所示：

			第三部：导入jar包。
			上面那些不爽的红叉是因为缺少jar的原因，我们现在需要那些jar包呢？
			test需要junit.jar，这个直接用eclipse里面的即可。
			java中需要：
			ant.jar
			jaxrpc.jar
			org.eclipse.jdt.core_3.3.1.v_780_R33x.jar
			wsdl4j-1.5.1.jar
			导入后就清爽了！

			第四步：
			在eclipse中启动tomcat。
			找到类：org.apache.catalina.startup包中的Bootstrap类。
			run as：在Arguments的VM arguments中设置
			-Dcatalina.home="d:\output\build"
			然后就可以启动了！
			 
			==========================================
			问题：
			为什么要设置-Dcatalina.home="d:\output\build"？
			首先说明output是什么——它就是ant编译出来的output文件夹，大家可以试试删除里面的东西看还是否可以成功启动。
			如果不配置这个参数又会发生什么情况呢？删除-Dcatalina.home="d:\output\build"，报错：
			2011-10-20 14:49:35 org.apache.catalina.startup.ClassLoaderFactory validateFile
			警告: Problem with directory [D:\myWorkSpace\tomcat6\lib], exists: [false], isDirectory: [false], canRead: [false]
			2011-10-20 14:49:35 org.apache.catalina.startup.ClassLoaderFactory validateFile
			警告: Problem with directory [D:\myWorkSpace\tomcat6\lib], exists: [false], isDirectory: [false], canRead: [false]
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina load
			警告: Can't load server.xml from D:\myWorkSpace\tomcat6\conf\server.xml
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina load
			警告: Can't load server.xml from D:\myWorkSpace\tomcat6\conf\server.xml
			2011-10-20 14:49:35 org.apache.catalina.startup.Catalina start
			严重: Cannot start server. Server instance is not configured.
			从中可以看出在项目的根目录下没有lib文件夹，没有conf文件夹，conf中没有server.xml，从而不能实例化server。
			那么按照他的提示做，在启动就ok了！
		--------
		from: http://www.cnblogs.com/huangfox/archive/2011/10/20/2218970.html

		从bootstrap处debug分析，debugtomcat的启动过程以及处理请求流程等。


* 旋风网页版
	离线download
* ant
	- build.xml
		<target>标签定义了ant的操作 ，如 #ant download ,#ant compile ,#ant clean
	- ivy ant的子项目，管理依赖
		从maven库下载依赖jar
	- 
		一个ant项目拿到，如何确认其使用的ant版本？
		已有编译的jar中查找(eg:MANIFEST.MF)

	- eclipse导入ant工程 ant项目 ant导入 导入ant
		----------
		不同于maven可以直接对IDE的支持(mvn eclipse:eclipse -DdownloadSources=true -DdownloadJavaDocs=true),ant并不具有这样的命令.这样如果eclipse需要import ant工程
		需要加入两个.classPath .project文件。如下: 
		.project 
		<?xml version="1.0" encoding="UTF-8"?> 
		<projectDescription> 
		<name>your_project-name</name> 
		<comment></comment> 
		<projects> 
		</projects> 
		<buildSpec> 
		  <buildCommand> 
		   <name>org.eclipse.jdt.core.javabuilder</name> 
		   <arguments> 
		   </arguments> 
		  </buildCommand> 
		</buildSpec> 
		<natures> 
		  <nature>org.eclipse.jdt.core.javanature</nature> 
		</natures> 
		</projectDescription> 


		.classpath 
		<?xml version="1.0" encoding="UTF-8"?> 
		<classpath> 
		    <classpathentry kind="src" path="src"/> 
		    <classpathentry kind="src" path="othersrc"/> 
		       <classpathentry kind="con" 
		path="org.eclipse.jdt.launching.JRE_CONTAINER"/> 
		    <!--<classpathentry kind="lib" path="lib/dom4j.jar"/>--> 
		    <classpathentry kind="output" path="classes"/> 
		</classpath> 

		方法2:可以导入为 
		导入的时候选new project-->Java Project From Existing Ant Buildfile 
		最后在你的workspace下面只有一个build.xml被导过去 
		前提是你的build.xml要正确包含需要的全部东西，比如你要用到的资源文件,类等等
		----------
		from: http://blog.csdn.net/screensky/article/details/7840893

		参考下面tomat6 ant项目的导入过程，搜索本文档  tomcat源码分析

* google应用
	https://drive.google.com/?authuser=0#my-drive		  google云端硬盘
		生态系统
			浏览器
			OS
			搜索
			社交 google+
			。。。

* md5 * 完整性验证
	md5码验证，或其他方式验证文件完整性(integrity of the files)。
	Verify the integrity of the files
	It is essential that you verify the integrity of the downloaded files using the PGP or MD5 signatures. Please read Verifying Apache Software Foundation Releases 
	for more information on why you should verify our releases.
	The PGP signatures can be verified using PGP or GPG. First download the KEYS as well as the asc signature file for the relevant distribution. 
	Make sure you get these files from the main distribution site, rather than from a mirror. Then verify the signatures using
	% pgpk -a KEYS
	% pgpv downloaded_file.asc
	or
	% pgp -ka KEYS
	% pgp downloaded_file.asc
	or
	% gpg --import KEYS
	% gpg --verify downloaded_file.asc
	Alternatively, you can verify the MD5 signature on the files. A unix program called md5 or md5sum is included in many unix distributions. It is also available as part of GNU Textutils. 
	Windows users can get binary md5 programs from here , here , or here.

* lua
	http://sourceforge.net/projects/luabinaries/files/5.2.1/Executables/

* 网卡绑定 网卡HA bond * linux双网卡绑定 网卡bond
	什么的linux系统？
	sles：
	# vi /etc/sysconfig/network/ifcfg-bond0 插入如下内容

	BOOTPROTO='static'
	IPADDR='10.34.81.21'
	NETMASK='255.255.255.0'
	STARTMODE='onboot'
	BONDING_MASTER='yes'
	BONDING_MODULE_OPTS='mode=1 miimon=200 use_carrier=1'
	BONDING_SLAVE0='eth1'
	BONDING_SLAVE1='eth2'

	检查# /etc/sysconfig/network/ 下有没有eth1、eth2的MAC地址配置，若有，则删除
	启动双网卡绑定# rcnetwork restart

	其中：BONDING_MODULE_OPTS='mode=1 为主备 0为负荷分担 

	redhat：

	创建一个ifcfg-bond0
	# vi /etc/sysconfig/network-scripts/ifcfg-bond0
	DEVICE=bond0
	BONDING_OPTS="mode=1 miimon=500"
	BOOTPROTO=none
	ONBOOT=yes
	BROADCAST=192.168.0.255
	IPADDR=192.168.0.180
	NETMASK=255.255.255.0
	NETWORK=192.168.0.0
	USERCTL=no
	其中：BONDING_OPTS="mode=1 为主备 0为负荷分担 

	修改/etc/sysconfig/ifcfg-ethX
	这里说的ethX指要加入绑定网卡的名称，本例中是eth0、eth1。
	# vi  /etc/sysconfig/ifcfg-eth0
	DEVICE=eth0 BOOTPROTO=none ONBOOT=yes MASTER=bond0 SLAVE=yes USERCTL=no
	# vi  /etc/sysconfig/ifcfg-eth1
	DEVICE=eth1BOOTPROTO=none ONBOOT=yes MASTER=bond0 SLAVE=yes USERCTL=no

	配置/etc/modprobe.conf，添加alias bond0 bonding
	# vi /etc/modprobe.conf
	alias eth0 pcnet32
	alias eth1 pcnet32
	alias scsi_hostadapter mptbase
	alias scsi_hostadapter1 mptspi
	alias bond0 bonding

	重启网络服务
	#service network restart

	from: http://zhidao.baidu.com/question/314912483.html&__bd_tkn__=74b942223728982e1751a83eb7fc2bbc951c80f48078338d51fed8133ea5c69d362ad36bb4bcda3b39bb3949f6bbe47087ac3af56e60b1f4e7eb60157b5df93b9c65adf05d0f03de0125277edc31b8084973e9027e22be84a139470b052c3b2abf6378313fb7d9deef0efaaccbdc8d03c93d24f146ac

* git，open source
	从git上，google code上也能看到开源项目
	facebook:
		https://github.com/facebook
	常用git命令
	git clone https://github.com/goagent/goagent.git
	然后checkout tag
	git tag
	git checkout $tagNum

	
*avahi
	/var/log/messages
		avahi-daemon[3329]: Host name conflict, retrying with <localhost-99>

	Avahi 是 zeroconf 协议的实现。它可以在没有 DNS 服务的局域网里发现基于 zeroconf 协议的设备和服务。它跟 mDNS 一样。除非你有兼容的设备或使用 zeroconf 协议的服务，
	否则应该关闭它

	Avahi
	Avahi 是Zeroconf规范的开源实现，常见使用在Linux上。包含了一整套多播DNS(multicastDNS)/DNS-SD网络服务的实现。它使用 的发布授权是LGPL。
	Zeroconf规范的另一个实现是Apple公司的Bonjour程式。Avahi和Bonjour相互兼容(废话，都走同一个 规范标准嘛，就象IE，Firefox，chrome都能跑HTTP1.1一样)。

	Avahi允许程序在不需要进行手动网络配置的情况 下，在一个本地网络中发布和获知各种服务和主机。例如，当某用户把他的计算机接入到某个局域网时，如果他的机器运行有Avahi服务
	，则Avahi程式自 动广播，从而发现网络中可用的打印机、共享文件和可相互聊天的其他用户。这有点象他正在接收局域网中的各种网络广告一样。

	Linux下系统实际启动的进程名，是avahi-daemon

	除非你有兼容的设备或使用 zeroconf 协议的服务，否则应该关闭它。  
	如果你用不到 把该服务直接关闭    
	/etc/init.d/avahi-daemon stop or service avahi-daemon  stop

* vpn,proxy ,brea k 
	https://trial5.securetrial.net/home

	web page proxy to access www

	http://www.gamesites200.com/wowprivate/
		set it up by yourself
	goagent
		https://code.google.com/p/goagent/
		gae
		
		配置svn客户端用proxy连接：
		eg: TortoiseSVN
			setting>network>proxy
				url port
				svn username
				svn password
		浏览器配置：
			firefox请安装FoxyProxy，Firefox需要导入证书，方法请见FAQ
			chrome请安装SwitchySharp插件，然后导入这个设置https://goagent.googlecode.com/files/SwitchyOptions.bak，或备份下载地址

* facebook
	http://www.facebook.com/note.php?note_id=76191543919&ref=mf
	开源项目在git：
		https://github.com/facebook

* 服务器端技术
	搭设服务器都需要的技术，架构，安全，维护，扩展

* 公开课
	http://open.163.com/
* kernel
	build kernel with lvs support: 
	1) Obtain and Unpack Kernel
	It is always easiest to start with a fresh kernel. You can obtain this from www.kernel.org.
	This example will use the 2.4.20 kernel. It can be unpacked using the following command
	which should unpack the kernel into the linux-2.4.20 directory.
	tar -jxvf linux-2.4.20.tar.bz2
	2) Obtain and Unpack LVS
	LVS can be obtained from www.linuxvirtualserver.org. This example will use 1.0.9. It
	can be unpacked using the following command which should pack the kernel into the
	ipvs-1.0.9 directory.
	tar -zxvf ipvs-1.0.9.tar.gz
	3) Apply LVS Patches to Kernel
	Two minor kernel patches are required in order for the LVS modules to compile. To
	apply these patches use the following:
	cd linux-2.4.20/
	patch -pq < ../ipvs-1.0.9/linuxkernel_ksyms_c.diff
	patch -pq < ../ipvs-1.0.9/linuxnet_netsyms_c.diff
	A third patch is applied to allow interfaces to be hidden. Hidden interfaces do not
	respond to ARP requests and are used on real servers with LVS direct routing.
	patch -pq < ../ipvs-1.0.9/contrib/patches/hidden-2.4.20pre10-1.diff
	4) Congure the kernel
	First ensure that the tree is clean:
	make mrproper
	Now congure the kernel. There are a variety of ways of doing this including make menuconfig,
	make xconfig and make config. Regardless of the method that you use, be sure to
	compile in netlter support, with at least the following options. It is suggested that
	where possible these options are built as modules.
	Networking options --->
	Network packet filtering (replaces ipchains)
	<m> IP: tunnelling
	IP: Netfilter Configuration --->
	<m> Connection tracking (required for masq/NAT)
	<m> FTP protocol support
	<m> IP tables support (required for filtering/masq/NAT)
	<m> Packet filtering
	<m> REJECT target support
	<m> Full NAT
	5
	<m> MASQUERADE target support
	<m> REDIRECT target support
	<m> NAT of local connections (READ HELP) (NEW)
	<m> Packet mangling
	<m> MARK target support
	<m> LOG target support
	5) Build and Install the Kernel
	As the kernel has been recongured the build dependencies need to be reconstructed.
	make dep
	The kernel and modules may now be build using:
	make bzImage modules
	To install the newly built modules and kernel run the following command. This should install
	the modules under /lib/modules/2.4.20/and the kernel in /boot/vmlinuz-2.4.20
	make install modules_install
	6) Update boot loader
	In the case of grub is used as the boot loader then a new entry should be added
	to /etc/grub.conf. This example assumes that the /boot partition is /dev/hda3.
	Existing entries in /etc/grub.conf should be used as a guide.
	title 2.4.20 LVS
	root (hd0,0)
	kernel /vmlinuz-2.4.20 ro root=/dev/hda3
	If the boot loader is lilo then a new entry should be added to /etc/lilo.conf. This
	example assumes that the / partition is /dev/hda2. Existing entries in /etc/lilo.conf
	should be used as a guide.
	image=/boot/vmlinuz-2.4.20
	label=2.4.20-lvs
	read-only
	root=/dev/hda2
	Once /etc/lilo.conf has been updated run lilo.
	lilo
	Added Linux-LVS *
	Added Linux
	Added LinuxOLD
	7) Reboot the system.
	At your boot loader's prompt be sure to boot the newly created kernel.	
* xStream框架
	xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换； 
	pojo转xml

* wsdl
	REST service wsdl

	WSDL的作用  
		原理：从XML-RPC和SOAP的使用我们可以看到， 请求消息都是根据服务提供方的服务接口来生成一个HTTP请求，在请求当中封装所要调用的方法，以及方法调用时的参数。
	　　客户端服务调用代码要完成的任务，也就是使用实现所提供的接口，来声明调用方所需要的方法名及参数，然后由实现根据用户的输入来组合HTTP请求。　　
	　 　这个过程可以这样来描述，首先获取用户输入，然后把输入变成实现所要求的存储格式，然后再把该格式变成HTTP请求。一般情况下，我们需要手工完成到第 二步，但是，
	这个过程显然是可以把他自动化的，自动化的效果就是用户不再需要书写这部分的代码，减少工作量和降低出错几率。　　
	　　自动化的过程就需要WSDL的参与，他提供了服务方服务的描述，调用方根据这个描述，就可以知道服务所需要的参数个数，然后向用户索取。得到输入以后，
	实现可以根据WSDL的要求来把输入转换成特定的存储格式，或者直接生成最后的HTTP请求。　　
	　 　对于每个服务，WSDL需要描述两部分的内容，一是接口，二是实现。接口描述了服务的格式，例如服务名，服务参数，服务结果。服务实现则描述了，
	用户所 对应提供的输入如何转换成符合某一实现协议的形式，一般情况下，我们使用SOAP作为实现协议，那么客户端在分析了WSDL文件以后，将会把用户的输入转 换成
	我们已经看到过的SOAP请求，之后的过程就与之前的完全一样。
	
	Describe REST Web services with WSDL 2.0 
		http://www.ibm.com/developerworks/webservices/library/ws-restwsdl/
	
	WSDL 简介
		WSDL是Web Service的描述语言，是一种接口定义语言，用于描述Web Service的接口信息等。
		WSDL文档可以分为两部分。顶部分由抽象定义组成，而底部分则由具体描述组成
	-----
		WSDL 文档结构
		WSDL 文档是利用这些主要的元素来描述某个 web service 的：
		元素	定义
		<portType>	web service 执行的操作
		<message>	web service 使用的消息
		<types>	web service 使用的数据类型
		<binding>	web service 使用的通信协议
		一个 WSDL 文档的主要结构是类似这样的：
		<definitions>

		<types>
		   definition of types........
		</types>

		<message>
		   definition of a message....
		</message>

		<portType>
		   definition of a port.......
		</portType>

		<binding>
		   definition of a binding....
		</binding>

		</definitions>
		WSDL 文档可包含其它的元素，比如 extension 元素，以及一个 service 元素，此元素可把若干个 web services 的定义组合在一个单一的 WSDL 文档中。
		如需完整的语法概述，请访问 WSDL 语法 这一节。
		WSDL 端口
		<portType> 元素是最重要的 WSDL 元素。
		它可描述一个 web service、可被执行的操作，以及相关的消息。
		可以把 <portType> 元素比作传统编程语言中的一个函数库（或一个模块、或一个类）。
		WSDL 消息
		<message> 元素定义一个操作的数据元素。
		每个消息均由一个或多个部件组成。可以把这些部件比作传统编程语言中一个函数调用的参数。
		WSDL types
		<types> 元素定义 web service 使用的数据类型。
		为了最大程度的平台中立性，WSDL 使用 XML Schema 语法来定义数据类型。
		WSDL Bindings
		<binding> 元素为每个端口定义消息格式和协议细节。
		WSDL 实例
		这是某个 WSDL 文档的简化的片段：
		<message name="getTermRequest">
		   <part name="term" type="xs:string"/>
		</message>

		<message name="getTermResponse">
		   <part name="value" type="xs:string"/>
		</message>

		<portType name="glossaryTerms">
		  <operation name="getTerm">
			<input message="getTermRequest"/>
			<output message="getTermResponse"/>
		  </operation>
		</portType>
		在这个例子中，<portType> 元素把 "glossaryTerms" 定义为某个端口的名称，把 "getTerm" 定义为某个操作的名称。
		操作 "getTerm" 拥有一个名为 "getTermRequest" 的输入消息，以及一个名为 "getTermResponse" 的输出消息。
		<message> 元素可定义每个消息的部件，以及相关联的数据类型。
		对比传统的编程，glossaryTerms 是一个函数库，而 "getTerm" 是带有输入参数 "getTermRequest" 和返回参数 getTermResponse 的一个函数。
	-----

* REST
	无状态通信
　　无状态通信是我要讲到的最后一个原则。首先，需要着重强调的是，虽然REST包含无状态性（statelessness）的观念，但这并不是说暴露功能的应用不能有状态——
　　事实上，在大部分情况下这会导致整个做法没有任何用处。REST要求状态要么被放入资源状态中，要么保存在客户端上。或者换句话说，服务器端不能保持除了单次请求之外的，
	任何与其通信的客户端的通信状态。这样做的最直接的理由就是可伸缩性——如果服务器需要保持客户端状态，那么大量的客户端交互会严重影响服务器的内存可用空间（footprint）。
	（注意，要做到无状态通信往往需要需要一些重新设计——不能简单地将一些session状态绑缚在URI上，然后就宣称这个应用是RESTful。）
	　　但除此以外，其它方面可能显得更为重要：无状态约束使服务器的变化对客户端是不可见的，因为在两次连续的请求中，客户端并不依赖于同一台服务器。一个客户端从某台
	服务器上收到一份包含链接的文档，当它要做一些处理时，这台服务器宕掉了，可能是硬盘坏掉而被拿去修理，可能是软件需要升级重启——如果这个客户端访问了从这台服务器
	接收的链接，它不会察觉到后台的服务器已经改变了。
	from: http://kb.cnblogs.com/page/132129/
	PS：部分截取

* zookeeper
	 - zookeeper源码分析
		下载trunk代码，通过其提供的build.xml文件定义的eclipse target将项目转为eclipse项目
		导入eclipse中



	 - zookeeper集群部署
		在HA集群中，ZooKeeper集群的压力一般不大，部署3~5个节点的集群就够用了。
		在此部署3个节点的ZooKeeper集群，假设三个节点分别为：host1、host2、host3。
		部署流程：
			解压zookeeper-3.4.5.tar.gz到自己指定的目录；
			创建配置文件：在zookeeper-3.4.5/conf/中创建zoo.cfg文件。在里面加上：
				tickTime=2000
				dataDir=/home/dir/zookeeper
				clientPort=30305
				initLimit=5
				syncLimit=2
			注：上述值可以根据自己需求修改。
			
			由ZooKeepe集群中每个节点都需要知道其他节点的信息，因此需要配置所有ZooKeeper Server的地址信息，在zookeeper-3.4.5/conf/zoo.cfg文件中加上所有Server的信息，
		格式： server.id=host:port:port
			其中个server.id这个参数由用户分配给每个ZooKeeper节点并放置在dataDir目录下的myid文件中（dataDir在zoo.cfg中配置的）。myid文件只有一行，里面是一个1-255的数字，
		必须保证唯一。
		如server 1的myid文件内保存“1”就够了。
		本例中，我们部署3个节点，因此在zookeeper-3.4.5/conf/zoo.cfg文件中加上如下信息：
			server.1 = host1:30306:30307
			server.2 = host2:30306:30307
			server.3 = host3:30306:30307
		注：端口号自己指定，只要所有节点一致并且不冲突就行。
		
		创建ZooKeeper的log目录：$ mkdir -p /home/dir/zookeeper/logs，然后在系统配置文件中加上$export ZOO_LOG_DIR=/home/dir/zookeeper/logs。
		注：也可以将配置写到bin/zkServer.sh文件中。
		3个节点都部署完成后就可以启动ZooKeeper了，在3个节点上执行：
		$bin/zkServer.sh start
		这样ZooKeeper就启动了，可以使用命令：$sh bin/zkServer.sh status来查看ZooKeeper状态，如果启动正确，则有2个节点状态为follower，一个为leader。
		可以在任一节点上使用命令$sh bin/zkCli.sh -server 127.0.0.1:30305 （端口是在zoo.cfg文件中配置的）来使用ZooKeeper文件系统。
		from: http://zhangjie.me/zookeeper_deploy/

	 - 脑裂/假死问题 avoid split brain split-brain
		Zookeeper和分布式环境中的假死脑裂问题  

		最近和同事聊天无意间发现他们的系统也存在脑裂的问题。想想当初在我们的系统中为了解决脑裂花了非常大的功夫，现在和大家一起讨论下脑裂，
		假死等等这些问题和解决的方法。
		在一个大集群中往往会有一个master存在，在长期运行过程中不可避免的会出现宕机等问题导致master不可用，在出现这样的情况以后往往会对系统产生很大的影响，
		所以一般的分布式集群中的master都采用了高可用的解决方案来避免这样的情况发生。
		master-slaver方式，存在一个master节点，平时对外服务，同时有一个slaver节点，监控着master，同时有某种方式来进行数据的同步。如果在master挂掉以后slaver能很快获知
		并迅速切换成为新的master。在以往master-slaver的监控切换是个很大的难题，但是现在有了Zookeeper的话能比较优雅的解决这一类问题。
											   master-slaver结构
		master-slaver实现起来非常简单，而且在master上面的各种操作效率要较其他HA解决方案要高，早期的时候监控和切换很难控制，但是后来zookeeper出现了，他的watch和
		分布式锁机制很好的解决了这一类问题。
		我们的系统和同事的系统都是这种模式，但是后来都发现由于ZooKeeper使用上的问题存在脑裂的问题。
		记得很久以前参加一个大牛的技术交流会他就提到过在集群中假死问题是一个非常让人头痛的问题，假死也是导致脑裂的根源。
		根据一个什么样的情况能判断一个节点死亡了down掉了，人可能很容易判断，但是对于在分布式系统中这些是有监控者来判断的，对于监控者来说很难判定其他的节点的状态，
		唯一可靠点途径的就是心跳，包括ZooKeeper就是使用心跳来判断客户端是否仍然活着的，使用ZooKeeper来做master HA基本都是同样的方式，每个节点都尝试注册一个
		象征master的临时节点其他没有注册成功的则成为slaver，并且通过watch机制监控着master所创建的临时节点，Zookeeper通过内部心跳机制来确定master的状态，一旦master出现
		意外Zookeeper能很快获悉并且通知其他的slaver，其他slaver在之后作出相关反应。这样就完成了一个切换。这种模式也是比较通用的模式，基本大部分都是这样实现的，但是
		这里面有个很严重的问题，如果注意不到会导致短暂的时间内系统出现脑裂，因为心跳出现超时可能是master挂了，但是也可能是master，zookeeper之间网络出现了问题，也同样
		可能导致。这种情况就是假死，master并未死掉，但是与ZooKeeper之间的网络出现问题导致Zookeeper认为其挂掉了然后通知其他节点进行切换，这样slaver中就有一个成为了master，
		但是原本的master并未死掉，这时候client也获得master切换的消息，但是仍然会有一些延时，zookeeper需要通讯需要一个一个通知，这时候整个系统就很混乱可能有一部分client已经
		通知到了连接到新的master上去了，有的client仍然连接在老的master上如果同时有两个client需要对master的同一个数据更新并且刚好这两个client此刻分别连接在新老的master上，就会出现很严重问题。
		出现这种情况的主要原因在与Zookeeper集群和Zookeeperclient判断超时并不能做到完全同步（这些还依赖于操作系统调度等，很难保证），也就是说可能一前一后，
		如果是集群先于client发现那就会
		出现上面的情况了。同时在发现并切换后通知各个客户端也有先后快慢。出现这种情况的几率很小，需要master与zookeeper集群网络断开但是与其他集群角色之间的网络没有问题，
		还要满足上面那些条件，但是一旦出现就会引发很严重的后果，数据不一致了。
		避免这种情况其实也很简单，在slaver切换的时候不在检查到老的master出现问题后马上切换，而是在休眠一段足够的时间，确保老的master已经获知变更并且做了相关
		的shutdown清理工作了然后再注册成为master就能避免这类问题了，这个休眠时间一般定义为与zookeeper定义的超时时间就够了，但是这段时间内系统可能是不可用的，
		但是相对于数据不一致的后果我想还是值得的。
		当然最彻底的解决这类问题的方案是将master HA集群做成peer2peer的，屏蔽掉外部Zookeeper的依赖。每个节点都是对等的没有主次，这样就不会存在脑裂的问题，
		但是这种ha解决方案需要使用两阶段，paxos这类数据一致性保证协议来实现，不可避免的会降低系统数据变更的系统，如果系统中主要是对master的读取操作很少更新就很适合了。
		from: http://backend.blog.163.com/blog/static/20229412620128911939110/

		PS:
			多个master的实现方案，通过Paxos协议
			
			更多见：* Paxos
		
		http://stackoverflow.com/questions/1106984/avoiding-split-brain-votes-and-quorum Avoiding split-brain, votes and quorum
	

	 - zookeeper HA
		多节点，一主多备的方式，一个为leader，其他为follower
	 - dubbo使用zookeeper registry   (安装好zookeeper后，dubbo的jar中有zookeeper registry模块来基于zookeeper实现registry)
		Install the zookeeper registry:

		cd ~
		wget http://www.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz
		tar zxvf zookeeper-3.3.3.tar.gz
		cd zookeeper-3.3.3/conf
		cp zoo_sample.cfg zoo.cfg
		vi zoo.cfg
		- edit: dataDir=/home/xxx/data
		cd ../bin
		./zkServer.sh start

		cd ~/dubbo/dubbo-demo-provider/conf
		vi dubbo.properties
		- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
		cd ../bin
		./restart.sh

		cd ~/dubbo/dubbo-demo-consumer/conf
		vi dubbo.properties
		- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
		cd ../bin
		./restart.sh

		cd ~/dubbo/dubbo-simple-monitor/conf
		vi dubbo.properties
		- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
		cd ../bin
		./restart.sh

	 - 实例
		ref: http://www.cnblogs.com/zhangzhang/archive/2013/01/16/2863339.html
	- 解决hadoop的单点故障(single point of failure of Name Node)，ZooKeeper能够用来leader选举,配置信息维护等。在一个分布式的环境中，
		我们需要一个Master实例或存储一些配置信息，确保文件写入的一致性等。目前ZooKeeper解决Hadoop的单点故障实现的是主备机方式（一主多备）。

		leader-follower模式

		Master选举
			-动态
			主备切换，一旦某个机器A挂了，马上能够通知到slave，然后slave能够在ZK指定节点上获取master最后的运行状态，然后就可以把自己标识为master了。

		ZooKeeper是Hadoop的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、命名服务、分布式同步、组服务等。
		ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

	- ZooKeeper 典型的应用场景
			Zookeeper 从设计模式角度来看，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，
		一旦这些数据的状态发生 变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式，关于 Zookeeper 的详细架构等
		内部细节可以阅读 Zookeeper的源码

		下面详细介绍这些典型的应用场景，也就是 Zookeeper 到底能帮我们解决那些问题？下面将给出答案。

		1) 统一命名服务（Name Service）

		分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住，通常情况下用树形的名称结构是一个理想的选择，树形 的名称结构是一个有层次的目录结构，
		既对人友好又不会重复。说到这里你可能想到了 JNDI，没错 Zookeeper 的 Name Service 与 JNDI 能够完成的功能是差不多的，它们都是将有层次的目录结构关联到一定资源上，但是 Zookeeper 
		的 Name Service 更加是广泛意义上的关联，也许你并不需要将名称关联到特定资源上，你可能只需要一个不会重复名称，就像数据库中产生一个唯一的数字主键一样。

		Name Service 已经是 Zookeeper 内置的功能，你只要调用 Zookeeper 的 API 就能实现。如调用 create 接口就可以很容易创建一个目录节点。

		2) 配置管理（Configuration Management） 发布&订阅服务

		配置的管理在分布式应用环境中很常见，例如同一个应用系统需要多台 PC Server 运行，但是它们运行的应用系统的某些配置项是相同的，如果要修改这些相同的配置项，
		那么就必须同时修改每台运行这个应用系统的 PC Server，这样非常麻烦而且容易出错。

		像这样的配置信息完全可以交给 Zookeeper 来管理，将配置信息保存在 Zookeeper 的某个目录节点中，然后将所有需要修改的应用机器监控配置信息的状态，一旦配置信息发生变化，
		每台应用机器就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中。

		3) 集群管理（Group Membership）

		Zookeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，
		集群中其它集群必须知道，从而做出调整重新分配服 务策略。同样当增加集群的服务能力时，就会增加一台或多台 Server，同样也必须让“总管”知道。

		Zookeeper 不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election。

		它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点(Ephemeral Nodes)，然后每个 Server 在它们创建目录节点的父目录节点上调用 getChildren (String  path, boolean watch) 方法并
		设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时getChildren 上的 Watch 将会被调用，所以
		其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。

		Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以
		它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，
		假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。
		这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题。

		4) 共享锁（Locks）

		共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，实现方式也是需要获得锁的 Server 创建一个 
		EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren 方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，如果正是自己创建的，
		那么它就获得了这个锁，如果不是那么它就调用 exists (String  path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，一直到自己创建的节点是列表中最小编号的目录节点，
		从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了。

		5) 队列管理

		Zookeeper 可以处理两种类型的队列：

		当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。
		队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。
		同步队列用 Zookeeper 实现的实现思路如下：

		创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是
		创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 / synchronizing 目录的所有目录节点，也就是 member_i。判断 i 的值是否已经是成员的个数，
		如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。

		用下面的流程图更容易理解：

		FIFO 队列用 Zookeeper 实现思路如下：

		实现的思路也非常简单，就是在特定的目录下创建 SEQUENTIAL 类型的子目录 /queue_i，这样就能保证所有成员加入队列时都是有编号的，出队列时通过 getChildren( ) 方法
		可以返回当前所有的队列中的元素，然后消费其中最小的一个，这样就能保证 FIFO。

		下面是生产者和消费者这种队列形式的示例代码，完整的代码请看附件：		
	
* ssh
	- key登陆,公钥认证登陆
		SSH设置
		在Hadoop启动以后，Namenode是通过SSH（Secure Shell）来启动和停止各个节点上的各种守护进程的，这就需要在节点之间执行指令的时候是不需要输入密码的方式，故我们需要配置SSH使用无密码公钥认证的方式。
		首先要保证每台机器上都装了SSH服务器，且都正常启动。实际中我们用的都是OpenSSH，这是SSH协议的一个免费开源实现。FC5中默认安装的OpenSSH版本是OpenSSH4.3P2。
		以本文中的三台机器为例，现在dbrg-1是主节点，它需要主动发起SSH连接到dbrg-2和dbrg-3，对于SSH服务来说，dbrg-1就是SSH客户端，而dbrg-2、dbrg-3则是SSH服务端，因此在dbrg-2，dbrg-3上需要确定sshd服务已经启动。简单的说，在dbrg-1上需要生成一个密钥对，即一个私钥，一个公钥。将公钥拷贝到dbrg-2，dbrg-3上，这样，比如当dbrg-1向dbrg-2发起ssh连接的时候，dbrg-2上就会生成一个随机数并用dbrg-1的公钥对这个随机数进行加密，并发送给dbrg-1；dbrg-1收到这个加密的数以后用私钥进行解密，并将解密后的数发送回dbrg-2，dbrg-2确认解密的数无误后就允许dbrg-1进行连接了。这就完成了一次公钥认证过程。

		对于本文中的三台机器，首先在dbrg-1上生成密钥对：
		[dbrg@dbrg-1:~]$ssh-keygen  -t  rsa
		这个命令将为dbrg-1上的用户dbrg生成其密钥对，询问其保存路径时直接回车采用默认路径，当提示要为生成的密钥输入passphrase的时候，直接回车，也就是将其设定为空密码。生成的密钥对id_rsa，id_rsa.pub，默认存储在/home/dbrg/.ssh目录下。然后将id_rsa.pub的内容复制到每个机器(也包括本机)的/home/dbrg/.ssh/authorized_keys文件中，如果机器上已经有authorized_keys这个文件了，就在文件末尾加上id_rsa.pub中的内容，如果没有authorized_keys这个文件，直接cp或者scp就好了，下面的操作假设各个机器上都没有authorized_keys文件。

		对于dbrg-1
		[dbrg@dbrg-1:.ssh]$cp id_rsa.pub authorized_keys

		对于dbrg-2（dbrg-3同dbrg-2的方法）
		[dbrg@dbrg-2:~]$mkdir .ssh
		[dbrg@dbrg-1:.ssh]$scp authorized_keys dbrg-2:/home/dbrg/.ssh/
		此处的scp就是通过ssh进行远程copy，此处需要输入远程主机的密码，即dbrg-2机器上dbrg帐户的密码，当然，你也可以用其他方法将authorized_keys文件拷贝到其他机器上

		[dbrg@dbrg-2:.ssh]$chmod 644 authorized_keys
		这一步非常关键，必须保证authorized_keys只对其所有者有读写权限，其他人不允许有写的权限，否则SSH是不会工作的。我就曾经在配置SSH的时候郁闷了好久。

		[dbrg@dbrg-2:.ssh]ls -la
		drwx------ 2 dbrg dbrg .
		drwx------ 3 dbrg dbrg ..
		 -rw-r--r-- 1 dbrg dbrg authorized_keys
		注意每个机器上的.ssh目录的ls -la都应该和上面是一样的

		接着，在三台机器上都需要对sshd服务进行配置(其实是可以不用配置的，完成了上面的那些操作了以后SSH就已经可以工作了)，在三台机器上修改文件/etc/ssh/sshd_config
		#去除密码认证
		PasswordAuthentication  no
		AuthorizedKeyFile   .ssh/authorized_keys

		至此各个机器上的SSH配置已经完成，可以测试一下了，比如dbrg-1向dbrg-2发起ssh连接
		[dbrg@dbrg-1:~]$ssh  dbrg-2
		如果ssh配置好了，就会出现以下提示信息
		The authenticity of host [dbrg-2] can't be established.
		Key fingerprint is 1024 5f:a0:0b:65:d3:82:df:ab:44:62:6d:98:9c:fe:e9:52.
		Are you sure you want to continue connecting (yes/no)?
		OpenSSH告诉你它不知道这台主机，但是你不用担心这个问题，因为你是第一次登录这台主机。键入“yes”。这将把这台主机的“识别标记”加到“~/.ssh/know_hosts”文件中。第二次访问这台主机的时候就不会再显示这条提示信息了。
		然后你会发现不需要输入密码就可以建立ssh连接了，恭喜你，配置成功了
		不过，别忘了测试本机ssh  dbrg-1
* pssh
	- 通过pssh或pscp工具操作时，对于维护的ip列表可以放到AG上，或一个统一的地方查询出来
	-
	pssh  is  a program for executing ssh in parallel on a number of hosts.  It provides features such as sending input to all of the pro-
	cesses, passing a password to ssh, saving output to files, and timing out.

	PSSH provides parallel versions of OpenSSH and related tools. Included are pssh, pscp, prsync, pnuke, and pslurp. The project includes psshlib which can be used within custom applications. 
	The source code is written in Python and can be cloned from:
	git clone http://code.google.com/p/parallel-ssh/ 

	eg:
		pssh -i -h /tmp/nc.list 'sudo python /tmp/virt_ops_release_20120829/virt_ops.py -m ruleset -f config_env -c /tmp/virt_ops_release_20120829/modules/ruleset_ops/config/ruleset_config_env.json'

		pssh -h /home/admin/.config_cluster/iplist_vm -i 'rm -rf /tmp/ops && cd /tmp && tar xzf /tmpxxx.tar.gz' | grep FAILURE
			到指定的ip列表中，执行命令，并grep返回内容(可以grep pssh执行错误时报的FAILURE)

	  ------
		pssh HOWTO

		Table of Contents
		1. Installation and Setup
		2. Preliminaries
		3. Examples
		3.1. pssh
		3.2. pscp
		3.3. pnuke
		4. Environment Variables
		5. Feedback
		1. Installation and Setup
		To install the software, become root on your machine and do the following (on RedHat systems): 

		   # rpm -ivh pssh-0.2.3-1.i386.rpm
		   Preparing...                ########################################### [100%]
		      1:pssh                   ########################################### [100%]
		 

		By default, the software installs itself in /usr/localbin and /usr/local/lib. Thus, you'll next want to modify your PATH if needed: 

		# export PATH=$PATH:/usr/local/bin

		--------------------------------------------------------------------------------

		2. Preliminaries
		All four programs will print their usage and give an example if no arguments are given. For example, with pssh: 

		   # pssh
		   Usage: pssh [OPTIONS] -h hosts.txt prog [arg0] ..
		   
		     -h --hosts   hosts file (each line "host[:port] [user]")
		     -l --user    username (OPTIONAL)
		     -p --par     max number of parallel threads (OPTIONAL)
		     -o --outdir  output directory for stdout files (OPTIONAL)
		     -t --timeout timeout in seconds to do ssh to a host (OPTIONAL)
		     -v --verbose turn on warning and diagnostic messages (OPTIONAL)
		     -O --options SSH options (OPTIONAL)
		   
		   Example: pssh -h ips.txt -l irb2 -o /tmp/foo uptime
		 
		And for pscp:

		   # pscp
		   Usage: pscp [OPTIONS] -h hosts.txt local remote
		   
		     -h --hosts     hosts file (each line "host[:port] [login]")
		     -r --recursive recusively copy directories (OPTIONAL)
		     -l --user      username (OPTIONAL)
		     -p --par       max number of parallel threads (OPTIONAL)
		     -t --timeout   timeout in seconds to do scp to a host (OPTIONAL)
		     -O --options   SSH options (OPTIONAL)
		   
		   Example: pscp -h hosts.txt -l irb2 foo.txt /home/irb2/foo.txt
		 
		Note that before using any of these tools, you will need to start ssh-agent! This can be done as follows (substitute zsh with your particular shell).

		   # ssh-agent zsh
		   # ssh-add
		   Enter passphrase for /x/bnc/.ssh/identity: 

		--------------------------------------------------------------------------------

		3. Examples
		3.1. pssh
		The following example runs hostname on three machines (IPs or hostnames) specified in the file ips.txt using login irb2 and saves the output in /tmp/foo. 

		   # cat ips.txt
		   128.112.152.122
		   18.31.0.190
		   128.232.103.201
		   
		   # pssh -h ips.txt -l irb2 -o /tmp/foo hostname
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # ls /tmp/foo
		   128.112.152.122  128.232.103.201  18.31.0.190
		   
		   # cat /tmp/foo/*
		   planetlab-1.cs.princeton.edu
		   planetlab1.xeno.cl.cam.ac.uk
		   planetlab1.lcs.mit.edu

		By default, pssh uses at most 32 ssh processes in parallel to ssh to the various nodes. (This is somewhat important if you're controlling hundreds or thousands of machines.) By default, it also uses a timeout of one minute to ssh to a node and obtain a result. For ssh commands that take longer than this (e.g., sleep 61), the -t option can be used. Note that pssh and pnuke have a default timeout of one minute. pscp and prsync have no default timeout, but one can be specified using the -t option.

		--------------------------------------------------------------------------------

		3.2. pscp
		Here's an example of using pscp to copy files in parallel to a set of machines.

		   # pscp -h ips.txt -l irb2 /etc/hosts /tmp/hosts
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22

		Using the -r option will perform a recursive copy for copying entire directories.
  
		--------------------------------------------------------------------------------

		3.3. pnuke
		The pnuke command is useful when you want to kill a bunch of processes on a set of machines. For example, suppose you've got a bunch of java processes running on three nodes that you'd like to nuke (let's use the three machines from the pssh example). Here you would do the following:

		   # pnuke -h ips.txt -l irb2 java
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22

		The result of the above is to send kill -9 to all processes owned by irb2 with the string java in their name (as reported by ps -ef).

		--------------------------------------------------------------------------------

		4. Environment Variables
		All four programs take similar sets of options. All of these options can be set using the following environment variables:

		   PSSH_HOSTS
		   PSSH_USER
		   PSSH_PAR
		   PSSH_OUTDIR
		   PSSH_VERBOSE
		   PSSH_OPTIONS

		Here are some example settings:

		   # export PSSH_HOSTS="/x/bnc/ips.txt"
		   # export PSSH_USER="irb2"
		   # export PSSH_PAR="32"
		   # export PSSH_OUTDIR="/tmp/bar"
		   # export PSSH_VERBOSE="0"
		   # export PSSH_OPTIONS="UserKnownHostsFile /tmp/known_hosts"

		Using the above settings, the examples can be executed succinctly as:

		   # pssh hostname
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # ls /tmp/bar
		   128.112.152.122  128.232.103.201  18.31.0.190
		   
		   # cat /tmp/bar/*
		   planetlab-1.cs.princeton.edu
		   planetlab1.xeno.cl.cam.ac.uk
		   planetlab1.lcs.mit.edu
		   
		   # pscp /etc/hosts /tmp/hosts
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
		   
		   # pnuke java  
		   Success on 128.112.152.122:22
		   Success on 18.31.0.190:22
		   Success on 128.232.103.201:22
	
		--------------------------------------------------------------------------------
	  ------

	参考：http://code.google.com/p/parallel-ssh

* Naming Service * 命名服务 * jndi
	命名服务(Naming Service)提供了一种为对象命名的机制，可以定位任何通过网络可以访问的机器上的对象，使得用户可以在无需知道对象位置的情况下获取和使用对象。 
	使用命名服务，首先要将对象在命名服务器上注册，然后用户就可以通过命名服务器的地址和该对象在命名服务器上注册的JNDI名找到该对象，获得其引用了。
	
	nuwa

	架构上，总线架构，各种服务通过总线相互通信，消息总线

* 数据库优化，索引 * 数据库相关 
	- 资源
		http://www.dbanotes.net
	 - SQL Server 索引
		 -------
			  SQL Server索引进阶第十五篇：索引的最佳实践

			    索引设计是数据库设计中比较重要的一个环节，对数据库的性能其中至关重要的作用，但是索引的设计却又不是那么容易的事情，性能也不是那么轻易就获取到的，很多的技术人员因为不恰当
			    的创建索引，最后使得其效果适得其反，可以说“成也索引，败也索引”


			    在本篇文章中，我们在学习了之前的知识之后，推荐14条指导方针。这14条指导方针可以帮助你更好的为数据库构建索引。

			    本篇文章的格式使用了由Addison Wesley出版社出版的<Framework Design Guidelines>中使用的格式。每一个最佳实践之前都使用了如下4个动词：要，考虑，避免、不要，分别代表如下意思:

			    要(Do):这个原则要坚决遵守

			    考虑(Consider):通常情况下都要遵循这个原则，但如果你对原则背后的原理有了深入了理解，可以根据实际情况不采用这个原则

			    避免(Avoid):考虑的反义词,意味着避免做某这类事，但同样，如果你了解了背后的原理，则可以根据实际情况做这类事。

			    不要(Do Not)：避免的增强版,意思是无论什么时候都不要做这类事。

			 
			指导方针

			要了解跑在数据库上的应用程序/用户

			    使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。

			    当然，如果你全程参与了程序的设计和开发，那再好不过。但这种情况少之又少，大多数情况都是你直接接手数据库和应用程序，这时你就需要两步走的了解你所接手的东西-通过外部和内部。

			    外部方法包括从用户那里了解程序相关的信息，观察他们使用程序的过程，阅读用户文档和交接文档。

			    内部方法是去看程序本身对数据库产生的操作。比如说Activity Monitor, Profiler等工具，也可以使用sys.dm_db_index usage_stats和sys.dm_db_missing_index_XXX系列DMV中找到所需信息，这些信息包
			    括用的最多的查询，用的最多的索引，用的少的索引以及本应建却没有建的索引。

			    通过找到拖累系统性能的查询，比如报表服务中用到的语句，agent中执行的T-SQL，SSIS中执行的T-SQL以及存储过程。找到这类信息就可以知道优化该从何处下手。

			    得到上面的信息后，就可以知道哪些索引应当存在，哪些索引应该删除。

			不要过度创建索引

			    过多的索引和太少的索引都不是好事。表中该有多少索引可不是一个固定的数字。当你为主键，候选键和外键建立了索引之后，剩下的索引该怎么建就需要谨慎分析后再做定夺了。

			要明白这点:同样的数据库在不同的环境下要有不同的索引

			    在忙时或是闲时；在OLTP环境或是OLAP环境下，所需要的索引是不同的。

			    比如每天晚上一次性大量更新数据的报表数据库在这时只需要少量索引，而在日间忙时则需要大量索引。数据库上跑少量查询要比数据库跑大量查询需要更少的索引。

			要给每个表设置主键

			    虽然SQL Server并不强制要求设置主键。但一个没有主键的表无论在OLTP还是OLAP环境下都是一件危险的事，因为没有主键就不能保证每行是唯一的。这时你就无法知道同一行数据是否在表
			    中存在两条，尤其是在你还没有足够的信息去分析这点时。

			    尽管SQL Server不强制要求设置主键，但主键是关系数据库的一个关键理论。如果没有主键约束，那么与之关联的唯一索引或是连接操作就有可能产生意料之外的性能问题。

			    除此之外，很多第三方开发工具或插件也要求表有主键，比如说吧，ADO.Net的SqlCommandBuilder和Entity Data Modeler都依赖表中存在主键约束。另外，主键约束会创建一个同名的唯一索引来保
			    证主键的唯一性。

			考虑给每个表设置聚集索引

			    本系列第三篇关于聚集索引的文章阐述了聚集索引带来的好处。使用聚集索引表中的数据就是按聚集索引键的顺序存在而不再以堆存放。使用聚集索引的好处是使得数据按照聚集索引键的顺序
			    存放，并使得后插入的元素依然保持这个顺序。

			    如果你遵循了上一个建议，那么每个表都应该有主键，因此，每一个表都应该有一个或多个索引，让其中的一个索引成为聚集索引。聚集索引本身并不会使得表上多了一个索引，而是让表的结
			    构更好的组织。

			    选择聚集索引键时，要记住第六篇文章中所说的，聚集索引键应该唯一，短和尽量不需要改动。

			考虑使用外键作为聚集索引键的最左列

			    将外键设置为聚集索引的最左列就是将表中的数据按照这列的值进行汇总和组织，这也是查询所需。比如说你用信用卡消费这个行为是和卡关联最强的的，而不是和你刷卡的商场以及处理这笔
			    消费的银行。则将信用卡号作为消费记录表中聚集索引的最左列，使得所有同一张卡的消费信息就会存在连续的页中。

			    当然了，你还需要另外一个很少变动的列和这个信用卡号列组合起来保证聚集索引键的唯一性。

			考虑为索引添加包含列

			    （译者注：这里作者文章有BUG，这段和上段一样，我就大胆的写一下原因吧。）为索引添加包含列的原因是减少对索引所在表的书签查找。因为包含列不会占用索引的非叶子节点空间，所以
			    不会影响B树的高度，通过在叶子节点附加上一些列，使得索引更容易的“覆盖”所请求的查询，从而减少了书签查找，降低了查询成本。

			    但同样，使用包含列使得非聚集索引占用的空间增加了，所以使用包含列时要综合考虑。

			避免为重复值很多的未过滤列创建非聚集索引

			    更早之前的一条建议“永远不要索引性别列”，是由于这列只会存在男性和女性两个值。当遇到WHERE Gender=的语句时使用表扫描要远远好于书签查找，查询优化器无法从这个索引中获益。

			考虑为列中重复值最多的值创建过滤索引

			    如果某列大量的行中都存在相同的值，这个值可以是NULL，那么使用过滤索引将这个值过滤掉，剩下的值所生成的索引就会更小，小索引使得查询优化器选择书签查找而不是表扫描，SQL 
			    Server也就更容易使用索引。

			考虑使用填充因子来面对未来的数据增长

			    假如一个表中只有几个月的数据，但这个表年底的数据已经可以估算出来时，重建索引的过程中将填充因子设置为7或8，这将使索引占用的页和年底占用的页大致相同，这可以更早的暴漏性能
			    问题，比如说表扫描时IO的占用。

			考虑使用填充因子来减少页分裂

			    加入表中的数据已经达到了页所能容纳的最大值。那么再插入数据就会导致页分裂了。因此重建索引时可以使用填充因子，如果数据库写大于读的话，设置填充因子为75，如果读写大致相等的
			    话，设置填充因子为90到95.

			要在创建非聚集索引之前，先创建聚集索引

			    与之对应的指导方针是：在删除聚集索引之前，先删除非聚集索引。如果你不按照这条方针做，则会导致无意义的重建非聚集索引。将表由聚集索引变为堆会使得表上的
			    非聚集索引重建，因为非聚集索引的书签由聚集索引键变为RID。

			要根据索引的使用频率定期整理索引碎片或是重建索引

		    如果一个索引经常用于扫描，正如我们在第11篇文章中所说，那么外部碎片对于性能的影响就变得非常大。这时你就需要考虑在外部碎片到达10%的时候整理索引了。
		    当外部碎片达到30%时就需要重建索引。对于OLTP环境来说，上面的值是一个分界点，这个点就是整理或重建索引的代价小于其带来的性能提升。
		 -------
	
* NFS services
	The Network File System (NFS) was developed to allow machines to mount a disk partition on a remote machine as if it were a local disk. It allows for fast, seamless sharing of files across a network. 
	
* 机器学习
	
* NAT
	网络地址转换（NAT）简介
	NAT概述
	　　NAT（Network Address Translation，网络地址转换）是将IP 数据包头中的IP 地址转换为另一个IP 地址的过程。在实际应用中，
	NAT 主要用于实现私有网络访问公共网络的功能。这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用IP 地址空间的枯竭。
	　　说明：
	　　私有 IP 地址是指内部网络或主机的IP 地址，公有IP 地址是指在因特网上全球唯一的IP 地址。
	　　RFC 1918 为私有网络预留出了三个IP 地址块，如下：
	　　A 类：10.0.0.0～10.255.255.255
	　　B 类：172.16.0.0～172.31.255.255
	　　C 类：192.168.0.0～192.168.255.255
	　　上述三个范围内的地址不会在因特网上被分配，因此可以不必向ISP 或注册中心申请而在公司或企业内部自由使用。
	NAT工作流程
	　　①如右图这个 client 的 gateway 设定为 NAT 主机，所以当要连上 Internet 的时候，该封包就会被送到 NAT 主机，这个时候的封包 Header 之 source IP 为 192.168.1.100 ；
	　　②而透过这个 NAT 主机，它会将 client 的对外联机封包的 source IP ( 192.168.1.100 ) 伪装成 ppp0 ( 假设为拨接情况 )这个接口所具有的公共 IP ，因为是公共 IP 了，
	所以这个封包就可以连上 Internet 了！同时 NAT 主机并且会记忆这个联机的封包是由哪一个 ( 192.168.1.100 ) client 端传送来的；
		注：这里NAT主机会记忆信息以区分不同client的包
	　　③由 Internet 传送回来的封包，当然由 NAT 主机来接收了，这个时候， NAT 主机会去查询原本记录的路由信息，并将目标 IP 由 ppp0 上面的公共 IP 改回原来的 192.168.1.100 ；
	　　④最后则由 NAT 主机将该封包传送给原先发送封包的 Client 。

	from: http://baike.baidu.com/view/16102.htm
* lvs DR			slb
	- 单臂
		lvs服务中，进流量走lvs，出流量不走lvs，俗称单臂
		区别FullNAT
	- 
	测试版本
		centos5 32 
			2.6.18-194.el5
		keepalived Keepalived v1.1.20
		ipvsadm v1.24

	- 检测vip漂移，failover
		ICMP包局域网内的其他主机也能收到
		lvs的主/备机通过发送arp包，来取得vip的所有权，要验证vip漂移正确，可通过在vip本机上ping vip，抓tcp的 ICMP 包来确定vip是否切换到对应的机子上。
		a. ping vip eg: ping 192.168.0.199
		b. 在2台lvs机上执行:
			#tcpdump | grep ICMP
		c. 根据lvs机的应答确定vip的位置
			如果vip在A机子上，则在A机上ping vip是不会有tcpdump的  ICMP包(ping本地地址不会广播ICMP包)

		 lvs主备切换 ，vip漂移问题，切换问题
			/etc/init.d/iptables stop

			lvs主备切换如果工作不正常，确认是不是防火墙的原因（防火墙阻止了keepalived的功能），下面是查找主备不切换，每个lvs启动后都是master状态：
			------
				Hi,

				I found that it is always best if possible to turn off the firewall and see if it works,
				then turn on the firewall.

				On 05/24/2012 08:16 AM, lakshmi priya wrote: 
			------
			from : http://comments.gmane.org/gmane.linux.keepalived.devel/3864

			根据上面的提示，测试成功，确实是linux防火墙导致keepalived的主备切换功能失效，具体应该是vrrp协议的交互受阻，下面是测试成功的log：
				Sep 20 02:46:39 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
				Sep 20 02:46:40 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 added
				Sep 20 02:46:40 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 added
				Sep 20 02:46:45 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Received higher prio advert
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering BACKUP STATE
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) removing protocol VIPs.
				Sep 20 02:49:26 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 removed
				Sep 20 02:49:26 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 removed
			
			ps：
				iptalbles全部关闭不建议，可以查看keepalived的端口占用说明，开发其需要的端口即可。

	- realserver
		---------
			在两台Web Server上执行realserver.sh脚本，为lo:0绑定VIP地址10.0.0.148、抑制ARP广播。

			[root@web1 ~]# cat realserver.sh
			复制代码

			#!/bin/bash
			#description: Config realserver

			VIP=10.0.0.148
			 
			/etc/rc.d/init.d/functions
			 
			case "$1" in
			start)
			       /sbin/ifconfig lo:0 $VIP netmask 255.255.255.255 broadcast $VIP
			       /sbin/route add -host $VIP dev lo:0
			       echo "1" >/proc/sys/net/ipv4/conf/lo/arp_ignore
			       echo "2" >/proc/sys/net/ipv4/conf/lo/arp_announce
			       echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
			       echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
			       sysctl -p >/dev/null 2>&1
			       echo "RealServer Start OK"
			       ;;
			stop)
			       /sbin/ifconfig lo:0 down
			       /sbin/route del $VIP >/dev/null 2>&1
			       echo "0" >/proc/sys/net/ipv4/conf/lo/arp_ignore
			       echo "0" >/proc/sys/net/ipv4/conf/lo/arp_announce
			       echo "0" >/proc/sys/net/ipv4/conf/all/arp_ignore
			       echo "0" >/proc/sys/net/ipv4/conf/all/arp_announce
			       echo "RealServer Stoped"
			       ;;
			*)
			       echo "Usage: $0 {start|stop}"
			       exit 1
			esac
			 
			exit 0
		---------
		此脚本在realserver上执行。

		注意，VIP是独立的，如果想将lvs服务与realserver放在同一台机子上测试的话，要保证vip是独立的（非lvs机的ip，也非rs机的ip）
		上面这个脚本设置VIP查找的，如果错用了lvs或rs自身的ip，则出服务异常。

		下面为一个测试例子：
			VIP=10.1.171.253
			2台VM，既充当LVS机，也充当RS机
				vm1:
					ip=10.1.171.140
				vm2:
					ip=10.1.171.148
			起keepalived：
				service keepalived start
			
			执行上面的shell脚本，绑定VIP的访问

			查看LVS，vip下rs状态列表
				[root@mydev2 home]# ipvsadm -L
				IP Virtual Server version 1.2.1 (size=4096)
				Prot LocalAddress:Port Scheduler Flags
				  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
				TCP  10.1.171.253:webcache rr persistent 50
				  -> mydev2.test.com.cn:http      Local   1      0          0         
				  -> mydev.test.com.cn:http       Masq    1      0          0      
				  
				  可以看到2个rs都正常服务了。

			测试场景：
				1）keepalived检查rs的健康情况，对于down掉的rs，从rs列表中去除(ipvsadm -L验证是否去除)
					关闭某台rs的http服务
				2）lvs vip漂移验证（也即LoadBalance主机和BackUP主机之间failover的实现）
					关闭某台lvs机的lvs服务，即关闭keepalived
					验证VIP转移到另一台lvs机上，访问正常。

			问题：上面的shell脚本，当rs正常访问后，ip add命令的结果中vip在eth0的信息中，即使删除lo:0也没用？	 若rs没启动成功此命令中eth0中不会有vip的信息
				#ip add
				1: lo: <LOOPBACK,UP,LOWER_UP> mtu 16436 qdisc noqueue 
				    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
				    inet 127.0.0.1/8 scope host lo
				    inet6 ::1/128 scope host 
				       valid_lft forever preferred_lft forever
				2: peth0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast qlen 1000
				    link/ether fe:ff:ff:ff:ff:ff brd ff:ff:ff:ff:ff:ff
				    inet6 fe80::fcff:ffff:feff:ffff/64 scope link 
				       valid_lft forever preferred_lft forever
				3: sit0: <NOARP> mtu 1480 qdisc noop 
				    link/sit 0.0.0.0 brd 0.0.0.0
				4: virbr0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether 00:00:00:00:00:00 brd ff:ff:ff:ff:ff:ff
				    inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0
				5: vif0.0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether fe:ff:ff:ff:ff:ff brd ff:ff:ff:ff:ff:ff
				    inet6 fe80::fcff:ffff:feff:ffff/64 scope link 
				       valid_lft forever preferred_lft forever
				6: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue 
				    link/ether 00:0c:29:93:bd:30 brd ff:ff:ff:ff:ff:ff
				    inet 10.1.171.140/25 brd 10.1.171.255 scope global eth0
				    inet 10.1.171.253/32 scope global eth0
				    inet6 fe80::20c:29ff:fe93:bd30/64 scope link 
				
				avahi-daemon服务影响lvs的vip漂移，待确定？
					lvs机切换master/backup时，vip不能正常漂移(从 /var/log/messages日志查看中分析出)
					关闭这个服务lvs主备正常切换。
			
	- lvs安装
		系统编译进内核方式，或者从源码编译安装
		源码安装好后，要修改系统加载（grub，lilo）配置，内核指向打了lvs的patch编译出的内核，启动时选择此内核。

		查看：ls /lib/modules/xxx

	- lvs实现的负载均衡方式
		1) DR 
			Direct Routing: Packets from end users are forwarded directly to the real server. The IP
			packet is not modified, so the real servers must be configured to accept traffic for the
			virtual server's IP address. This can be done using a dummy interface or packet filtering
			to redirect traffic addressed to the virtual server's IP address to a local port. The real
			server may send replies directly back to the end user. Thus, the linux director does not
			need to be in the return path.
				第一次需要修改，后续可以直接enduser和realservr通信
		2) NAT
			
		3) Tunnel
			类似DR，但realserver可以和LD不在同一网络。
	- lvs+keepalived
		http://www.cnblogs.com/mchina/archive/2012/08/27/2644391.html

* linux 系统信息 查看
	linux如何查看系统信息
	一：cpu
	   [root@srv /]# more /proc/cpuinfo | grep "model name"
	 model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	  model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo | cut -f2 -d:
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	二：内存
	[root@srv /]# grep MemTotal /proc/meminfo
	MemTotal:        614400 kB
	[root@srv /]# free -m
			   total        used        free    shared     buffers    cached
	Mem:          600       23       576           0           0           0
	-/+ buffers/cache:       23       576
	Swap:          0           0           0
	[root@srv /]# free -m |grep "Mem" | awk '{print $2}'
	600

	三：查看CPU位数(32 or 64)
	[root@srv /]# getconf LONG_BIT
	32

	四：查看linux版本
	[root@srv /]# more /etc/redhat-release
	CentOS release 5 (Final)
	[root@srv /]# more /etc/issue
	CentOS release 5 (Final)
	Kernel \r on an \m
	[root@srv /]# more /proc/version
	Linux version 2.6.18-92.1.18.el5.028stab060.2PAE ([email=root@rhel5-32-build-xemul]root@rhel5-32-build-xemul[/email]) (gc
	c version 4.1.2 20071124 (Red Hat 4.1.2-42)) #1 SMP Tue Jan 13 12:31:30 MSK 2009

	五：查看内核版本
	[root@srv /]# uname -r
	2.6.18-92.1.18.el5.028stab060.2PAE
	[root@srv /]# uname -a
	Linux srv.eddiechen.cn 2.6.18-92.1.18.el5.028stab060.2PAE #1 SMP Tue Jan 13 12:31:30 MSK 2009 i686 i686 i386 GNU/Linux

	六：查看时区
	[root@srv /]# date -R
	Wed, 25 Feb 2009 02:20:50 +0000
	[root@srv /]# mv /etc/localtime /etc/localtime.save
	[root@srv /]# cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
	[root@srv /]# date -R
	Wed, 25 Feb 2009 10:24:26 +0800

	七：主机名
	查看主机名
	[root@srv /]# hostname
	www.ifuoo.com
	修改主机名
	[root@srv /]# cat /etc/sysconfig/network
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	八：查看selinux情况
	[root@srv /]# sestatus
	SELinux status:                disabled

	九：网络
	IP
	[root@srv /]# ifconfig | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'
	207.154.202.216
	网关
	[root@srv /]# cat /etc/sysconfig/network
	NETWORKING="yes"
	GATEWAY="192.0.2.1"
	HOSTNAME="srv.eddiechen.cn"
	dns
	[root@srv /]# cat /etc/resolv.conf
	nameserver 208.74.168.131
	nameserver 208.74.168.132
	nameserver 4.2.2.1
	修改Host文件
	[root@srv /]# cat /etc/hosts
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	十：已经安装的软件包
	[root@srv /]# rpm -qa | wc -l
	197
	[root@srv /]# yum list installed | wc -l
	198

	十一：磁盘和分区
	[root@srv /]# df -h
	Filesystem          Size    Used          Avail Use    %    Mounted on

	/dev/simfs              10G     353M              9.7G       4%    /

	[root@srv /]# du -sh

	353M

	[root@srv /]# du /etc -sh

	4.6M     /etc

	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	九：查看键盘布局

	cat /etc/sysconfig/keyboard

	cat /etc/sysconfig/keyboard | grep KEYTABLE | cut -f2 -d=

	十二：查看默认语言

	echo $LANG $LANGUAGE

	cat /etc/sysconfig/i18n

	==================================

	http://hi.baidu.com/mypc007

	通过以下命令，可以查看RS/6000系统配备的物理内存的大小。

	　　lsdev -Cc memory

	　　查看RS/6000配置的物理内存设备，下面为其输出示例：

	　　mem0 Available 00-00 Memory

	　　L2cache0 Available 00-00 L2 Cache

	　　再使用命令

	　　lsattr -El mem0

	　　输出如下

	　　size 512 Total amount of physical memory in Mbytes False

	　　goodsize 512 Amount of usable physical memory in Mbytes False

	　　此例说明机器的物理内存为512MB。如果前面lsdev的输出中有设备名 mem1，则使用同样的命令查看其对应的大小并依此类推。L2cache0 为系统二级缓存(Level 2 Cache)的设备名。同样，使用命令：

	　　lsattr -El L2cache0

	　　可以查看其大小。

	查看LINUX系统位数

	1.编程实现：

	在程序中返回sizeof(int)的值，返回的结果是操作系统的字节数。若返回4则是32位操作系统，返回8即是64位。

	2.getconf命令：

	getconf命令可以获取系统的基本配置信息，比如操作系统位数，内存大小，磁盘大小等。

	例如：

	确定磁盘 hdisk0 大小，若是 root 用户，则输入：

	getconf DISK_SIZE /dev/hdisk0

	确定实际内存大小：getconf REAL_MEMORY

	确定是否机器硬件是 32 位或 64 位：getconf HARDWARE_BITMODE

	确定是否内核是 32 位或 64 位： getconf KERNEL_BITMODE

	若以上的getconf KERNEL_BITMODE方法不成功(在我的机器上就不成功)，可能是因为版本不一致，可以再尝试用：getconf WORD_BIT，这个命令返回int类型的长度，与sizeof(int)一致。
* diff和patch使用指南
　　diff和patch是一对工具，在数学上来说，diff是对两个集合的差运算，patch是对两个集合的和运算。
　　diff比较两个文件或文件集合的差异，并记录下来，生成一个diff文件，这也是我们常说的patch文件，即补丁文件。
　　patch能将diff文件运用于 原来的两个集合之一，从而得到另一个集合。举个例子来说文件A和文件B,经过diff之后生成了补丁文件C,那么着个过程相当于 A -B = C ,
	那么patch的过程就是B+C = A 或A-C =B。	
	
　　	因此我们只要能得到A, B, C三个文件中的任何两个，就能用diff和patch这对工具生成另外一个文件。
　　这就是diff和patch的妙处。下面分别介绍一下两个工具的用法:
　　1). diff的用法
　　diff后面可以接两个文件名或两个目录名。 如果是一个目录名加一个文件名，那么只作用在那么个目录下的同名文件。
　　如果是两个目录的话，作用于该目录下的所有文件，不递归。如果我们希望递归执行，需要使用-r参数。
　　命令diff A B >C ,一般A是原始文件，B是修改后的文件，C称为A的补丁文件。

　　	不加任何参数生成的diff文件格式是一种简单的格式，这种格式只标出了不一样的行数和内容。我们需要一种更详细的格式，可以标识出不同之处的上下文环境，
	这样更有利于提高patch命令的识别能力。这个时候可以用-c开关。	
　　2). patch的用法
　　patch用于根据原文件和补丁文件生成目标文件。还是拿上个例子来说
　　patch A C 就能得到B, 这一步叫做对A打上了B的名字为C的补丁。
　　之一步之后，你的文件A就变成了文件B。如果你打完补丁之后想恢复到A怎么办呢？
　　patch -R B C 就可以重新还原到A了。
　　所以不用担心会失去A的问题。
　　其实patch在具体使用的时候是不用指定原文件的，因为补丁文件中都已经记载了原文件的路径和名称。patch足够聪明可以认出来。但是有时候会有点小问题。比如一般对两个目录diff的时候可能已经包含了原目录的名字，但是我们打补丁的时候会进入到目录中再使用patch,着个时候就需要你告诉 patch命令怎么处理补丁文件中的路径。可以利用-pn开关，告诉patch命令忽略的路径分隔符的个数。举例如下：
　　A文件在 DIR_A下，修改后的B文件在DIR_B下，一般DIR_A和DIR_B在同一级目录。我们为了对整个目录下的所有文件一次性diff,我们一般会到DIR_A和DIR_B的父目录下执行以下命令
　　diff -rc DIR_A DIR_B >C
　　这个时候补丁文件C中会记录了原始文件的路径为 DIR_A/A
　　现在另一个用户得到了A文件和C文件，其中A文件所在的目录也是DIR_A。 一般，他会比较喜欢在DIR_A目录下面进行patch操作，它会执行	   
　　
	patch
　　但是这个时候patch分析C文件中的记录，认为原始文件是./DIR_A/A，但实际上是./A，此时patch会找不到原始文件。为了避免这种情况我们可以使用-p1参数如下
　　patch -p1	     
　　此时，patch会忽略掉第1个”/”之前的内容，认为原始文件是 ./A，这样就正确了。
　　最后有以下几点注意：
　　1). 一次打多个patch的话，一般这些patch有先后顺序，得按次序打才行。
　　2). 在patch之前不要对原文件进行任何修改
　　3). 如果patch中记录的原始文件和你得到的原始文件版本不匹配(很容易出现)，那么你可以尝试使用patch, 如果幸运的话，可以成功。大部分情况下，会有不匹配的情况，此时patch会生成rej文件，记录失败的地方，你可以手工修改。

	from: http://www.linuxsky.org/doc/admin/200712/213.html

* libvirt libvirt库 虚拟化库
	- 统一抽象虚拟化操作接口，避免不同hypervistor的学习成本
		比如，封装了xen API，这样通过统一的libvirt API即可管理xen hypervistor
	- 简介
		The virtualization API

		libvirt is:
		- A toolkit to interact with the virtualization capabilities of recent versions of Linux (and other OSes), see our project goals for details.
		- Free software available under the GNU Lesser General Public License.
		- A long term stable C API
		- A set of bindings for common languages
		- A CIM provider for the DMTF virtualization schema
		- A QMF agent for the AMQP/QPid messaging system
		
		libvirt supports:
		- The KVM/QEMU Linux hypervisor
		- The Xen hypervisor on Linux and Solaris hosts.
		- The LXC Linux container system
		- The OpenVZ Linux container system
		- The User Mode Linux paravirtualized kernel
		- The VirtualBox hypervisor
		- The VMware ESX and GSX hypervisors
		- The VMware Workstation and Player hypervisors
		- The Microsoft Hyper-V hypervisor
		- Virtual networks using bridging, NAT, VEPA and VN-LINK.
		- Storage on IDE/SCSI/USB disks, FibreChannel, LVM, iSCSI, NFS and filesystems
		
		libvirt provides:
		- Remote management using TLS encryption and x509 certificates
		- Remote management authenticating with Kerberos and SASL
		- Local access control using PolicyKit
		- Zero-conf discovery using Avahi multicast-DNS
		- Management of virtual machines, virtual networks and storage
		- Portable client API for Linux, Solaris and Windows

* xen 
	- vhd (virtual hard disk)
		Blktap2：Xen 4.0中所采用新的虚拟硬盘(VHD)提供了高性能虚拟机快照和克隆功能，此外还可以在不停止虚拟机处理的情况下做实时虚拟磁盘快照
	- 选择一种开源实现，以此为基础，利用其API或修改源码实现业务需求；需要对开源产品本身的深入研究，然后在此基础上开发相应工具，于自身业务系统对接，实现产品（包扩相关的方方面面的再封装和管理）。
	- tapdisk2
		tap_disk 结构抽象了 tapdisk2 所有支持的 disk 类型，如 vhd, qcow, img 等等

		ref: http://blog.csdn.net/majieyue
	- xen api
		通过xen开发的API，管理xen
		OR 通过修改源码，实现特殊业务
	- xen device 快照管理			    tapdisk2
		http://blog.csdn.net/majieyue/article/category/846491
	-  xen 快照 了解  虚拟机快照 【快照】
		虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
	由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
		chain 模式 比如 struts的intercepter ，插拔式
		
		http://server.it168.com/a2009/0723/611/000000611079.shtml
	- nc通过libvirt采集所属vm性能数据
	- 内存管理
		xm info 查看总内存和可使用的内存

		xm list
		也看查看dom0的内存数
			xm list -l 116
			查看domain的详细信息

		free -m 查看dom0的内存使用情况

		如果dom0占用过多内存，可以通过
		xm mem-set 0 xxx设置dom0的内存

		centos5 xen3
		创建domu时，报内存问题：

			网上搜索确定为xen的一个bug，可通过打patch解决。

	想到centos5上安装xen4，但Redhat 和Cent OS系统现在集成的是Xen3.x的版本，如果你不愿意折腾自行编译安装Xen4,下面教你用第三方Yum源快速安装xen4：
		$ cd /etc/yum.repos.d
		$ sudo wget http://www.gitco.de/repo/GITCO-XEN4.0.0_testing_x86_64.repo
		$ sudo yum update
		Dependencies Resolved
		==========================================================================================
		Package Arch Version Repository Size
		==========================================================================================
		Updating:
		xen x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 12 M
		xen-devel x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 408 k
		xen-libs x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 366 k
		Transaction Summary
		==========================================================================================
		Install 0 Package(s)
		Update 3 Package(s)
		Remove 0 Package(s)
		Total download size: 13 M
		Is this ok [y/N]: y
		grub.conf添加记录
		title CentOS (2.6.18-164.15.1.el5xen)
		root (hd0,0)
		kernel /xen.gz-4.0.0
		module /vmlinuz-2.6.18-164.15.1.el5xen ro root=/dev/VolGroup00/LogVol00 rhgb quiet
		module /initrd-2.6.18-164.15.1.el5xen.img
		重启即可
		$ sudo reboot
		from: http://bbs.linuxtone.org/thread-7259-1-1.html

		xen第三方源：http://www.gitco.de/repo/

* linux 安装方式
	系统集成了的软件安装
	源码编译安装
		如果需要打patch，则打好相应的patch后再编译安装
	第三方源安装
* linux c 开发			linux c/c++ c++ cpp
	- fork函数
			一个进程，包括代码、数据和分配给进程的资源。fork()函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，
		但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
　　		一个进程调用fork()函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来
		的进程的值不同。相当于克隆了一个自己。

			也就是说，在Linux下一个进程在内存里有三部分的数据，就是"代码段"、"堆栈段"和"数据段"。"代码段"，顾名思义，就是存放了程序代码的数据，假如机器中有数个进程运行相同的一个程序，那么它们就可以使用相同的代码段。"堆栈段"存放的就是子程序的返回地址、子程序的参数以及程序的局部变量。而数据段则存放程序的全局变量，常数以及动态数据分配的数据空间（比如用malloc之类的函数取得的空间）。系统如果同时运行数个相同的程序，它们之间就不能使用同一个堆栈段和数据段。
	　　仔细分析后，我们就可以知道：
	　　一个程序一旦调用fork函数，系统就为一个新的进程准备了前述三个段，首先，系统让新的进程与旧的进程使用同一个代码段，因为它们的程序还是相同的，对于数据段和堆栈段，系统则复制一份给新的进程，这样，父进程的所有数据都可以留给子进程，但是，子进程一旦开始运行，虽然它继承了父进程的一切数据，但实际上数据却已经分开，相互之间不再有影响了，也就是说，它们之间不再共享任何数据了。
	　　fork()不仅创建出与父进程代码相同的子进程，而且父进程在fork执行点的所有上下文场景也被自动复制到子进程中，包括：
	　　——全局和局部变量
	　　——打开的文件句柄
	　　——共享内存、消息等同步对象
	　　而如果两个进程要共享什么数据的话，就要使用另一套函数（shmget，shmat，shmdt等）来操作。现在，已经是两个进程了，对于父进程，fork函数返回了子程序的进程号，而对于子程序，fork函数则返回零，这样，对于程序，只要判断fork函数的返回值，就知道自己是处于父进程还是子进程中。
		from: http://www.dzsc.com/data/html/2009-9-10/78615.html

	- eclipse集成cpp开发环境，下载CDT版本的eclipse，或者安装CDT插件
		CDT插件：http://download.eclipse.org/tools/cdt/releases/helios
		eclipse for javaee版本，安装插件，再安装minGW

	- 以简单的c/c++例子学习
		http://www.oschina.net/code/list/2/cpp?show=month
		源码中国等技术网站，有用户上传的各类源码程序，是一个好的学习资源

	eg：keepalived目录结构
		bin		- 制作好的rpm包
		patch	- svn更新patch
		source	- 源码包
		spec - 用于制作rpm包
	* cpp
		 - 查看头文件的定义方法的具体实现时，可以从其new出来的实现类中查看对应方法的实现逻辑
		 - 内存分配方式
			内存的三种分配方式：
			1) 从静态存储区分配：此时的内存在程序编译的时候已经分配好，并且在程序的整个运行期间都存在。全局变量，static变量等在此存储。
			2) 在栈区分配：相关代码执行时创建，执行结束时被自动释放。局部变量在此存储。栈内存分配运算内置于处理器的指令集中，效率高，但容量有限。
			3) 在堆区分配：动态分配内存。用new/malloc时开辟，delete/free时释放。生存期由用户指定，灵活。但有内存泄露等问题。

			struts中属性的初始化，将引用的地址赋给结构体的成员

		 - vector
			vector容器类型
			vector容器是一个模板类，可以存放任何类型的对象（但必须是同一类对象）。vector对象可以在运行时高效地添加元素，并且vector中元素是连续存储的。
			vector的构造

			函数原型：
			template<typename T>
			explicit vector();                                 // 默认构造函数，vector对象为空
			explicit vector(size_type n, const T& v = T());    // 创建有n个元素的vector对象
			vector(const vector& x);
			vector(const_iterator first, const_iterator last);

			注：vector容器内存放的所有对象都是经过初始化的。如果没有指定存储对象的初始值，那么对于内置类型将用0初始化，对于类类型将调用其默认构造函数进行初始化
			（如果有其它构造函数而没有默认构造函数，那么此时必须提供元素初始值才能放入容器中）。

			举例：
			vector<string> v1;         // 创建空容器，其对象类型为string类
			vector<string> v2(10);     // 创建有10个具有初始值（即空串）的string类对象的容器
			vector<string> v3(5, "hello"); // 创建有5个值为“hello”的string类对象的容器
			vector<string> v4(v3.begin(), v3.end());  // v4是与v3相同的容器（完全复制）

			vector的操作（下面的函数都是成员函数）

			bool empty() const;                    // 如果为容器为空，返回true；否则返回false
			size_type max_size() const;            // 返回容器能容纳的最大元素个数
			size_type size() const;                // 返回容器中元素个数  
			size_type capacity() const;            // 容器能够存储的元素个数，有：capacity() >= size()  
			void reserve(size_type n);             // 确保capacity() >= n
			void resize(size_type n, T x = T());   // 确保返回后，有：size() == n；如果之前size()<n，那么用元素x的值补全。

			reference front();                     // 返回容器中第一个元素的引用（容器必须非空）
			const_reference front() const;                   
			reference back();                      // 返回容器中最后一个元素的引用（容器必须非空）
			const_reference back() const;

			reference operator[](size_type pos);   // 返回下标为pos的元素的引用（下标从0开始；如果下标不正确，则属于未定义行为。
			const_reference operator[](size_type pos) const; 
			reference at(size_type pos);           // 返回下标为pos的元素的引用；如果下标不正确，则抛出异常out_of_range
			const_reference at(size_type pos) const;
			    
			void push_back(const T& x);            // 向容器末尾添加一个元素          
			void pop_back();                       // 弹出容器中最后一个元素（容器必须非空）

			// 注：下面的插入和删除操作将发生元素的移动（为了保持连续存储的性质），所以之前的迭代器可能失效
			iterator insert(iterator it, const T& x = T());        // 在插入点元素之前插入元素（或者说在插入点插入元素）
			void insert(iterator it, size_type n, const T& x);     // 注意迭代器可能不再有效（可能重新分配空间）
			void insert(iterator it, const_iterator first, const_iterator last);

			iterator erase(iterator it);           // 删除指定元素，并返回删除元素后一个元素的位置（如果无元素，返回end()）
			iterator erase(iterator first, iterator last); // 注意：删除元素后，删除点之后的元素对应的迭代器不再有效。

			void clear() const;                    // 清空容器，相当于调用erase( begin(), end())

			void assign(size_type n, const T& x = T());   // 赋值，用指定元素序列替换容器内所有元素
			void assign(const_iterator first, const_iterator last);

			const_iterator begin() const;          // 迭代序列
			iterator begin();
			const_iterator end() const;
			iterator end();

			const_reverse_iterator rbegin() const;
			reverse_iterator rbegin();
			const_reverse_iterator rend() const; 
			reverse_iterator rend();

			vector对象的比较（非成员函数）

			针对vector对象的比较有六个比较运算符：operator==、operator!=、operator<、operator<=、operator>、operator>=。

			其中，对于operator==和operator!=，如果vector对象拥有相同的元素个数，并且对应位置的元素全部相等，则两个vector对象相等；否则不等。
			对于operator<、operator<=、operator>、operator>=，采用字典排序策略比较。

			注：其实只需要实现operator==和operator!=就可以了，其它可以根据这两个实现。因为，operator!= (lhs, rhs) 就是 !(lhs == rhs)，operator<=(lhs, rhs) 就是 !(rhs < lhs)，operator>(lhs, rhs) 
			就是 (rhs < lhs)，operator>=（lhs, rhs) 就是 !(lhs, rhs)。

			vector类的迭代器

			vector类的迭代器除了支持通用的前缀自增运算符外，还支持算术运算：it + n、it - n、it2 - it1。注意it2 - it1返回值为difference_type（signed类型）。

			注意，任何改变容器大小的操作都可能造成以前的迭代器失效。
		 - header file 头文件
				在C语言家族程序中，头文件被大量使用。一般而言，每个C++/C程序通常由头文件(header files)和定义文件(definition files)组成。头文件作为一种包含功能函数、
			数据接口声明的载体文件，用于保存程序的声明(declaration)，而定义文件用于保存程序的实现 (implementation)。而且 .c就是你写的程序文件。
				一般在一个应用开发体系中，功能的真正逻辑实现是以硬件层为基础，在驱动程序、功能层程序以及用户的应用程序中完成的。头文件的主要作用在于调用库功能，
			对各个被调用函数给出一个描述，其本身不包含程序的逻辑实现代码，它只起描述性作用，告诉应用程序通过相应途径寻找相应功能函数的真正逻辑实现代码。用户程序
			只需要按照头文件中的接口声明来调用库功能，编译器会从库中提取相应的代码。
				从以上结构图来看，头文件是用户应用程序和函数库之间的桥梁和纽带。在整个软件中，头文件不是最重要的部分，但它是C语言家族中不可缺少的组成部分。
			做一个不算很恰当的比喻，头文件就像是一本书中的目录，读者(用户程序)通过目录，可以很方便就查阅其需要的内容(函数库)。在一本书中，目录固然重要，但绝对
			不是一本书的核心的、最重要的部分。

		 - destructor 与构造器对应，用于过期时清理对应构造器未释放的对象
				When you use a constructor to create an object, the program undertakes the responsibility of
			tracking that object until it expires. At that time, the program automatically calls a special
			member function bearing the formidable title destructor. The destructor should clean up any
			debris, so it actually serves a useful purpose. For example, if your constructor uses new to allocate
			memory, the destructor should use delete to free that memory. The Stock constructor
			doesn’t do anything fancy like using new, so the Stock class destructor doesn’t really have any
			tasks to perform. In such a case, you can simply let the compiler generate an implicit, donothing
			destructor, which is exactly what the first version of the Stock class does.

			Unlike a constructor,
			a destructor must have no arguments. Thus, the prototype for a Stock destructor must be this:
			~Stock();
			Because a Stock destructor has no vital duties, you can code it as a do-nothing function:
			Stock::~Stock()
			{
			}
			However, just so that you can see when the destructor is called, you can code it this way:
			Stock::~Stock() // class destructor
			{
			cout << “Bye, “ << company << “!\n”;
			}

		 - 源码结合教程，快速看懂逻辑
			ClassName::~DestructorMethodName(){
			}
		 - 引用 参数值传递与址传递
			概念：
			引用引入了对象的一个同义词。定义引用的表示方法与定义指针相似，只是用&代替了*。引用（reference）是c++对c语言的重要扩充。
			引用就是某一变量（目标）的一个别名，对引用的操作与对变量直接操作完全一样。引用的声明方法：类型标识符 &引用名=目标变量名；　
			说明：
			（1）&在此不是求地址运算，而是起标识作用。
		　　（2）类型标识符是指目标变量的类型。
		　　（3）声明引用时，必须同时对其进行初始化。
		　　（4）引用声明完毕后，相当于目标变量名有两个名称，即该目标原名称和引用名，且不能再把该引用名作为其他变量名的别名。
			　　int a,&ra=a;
			　　a为目标原名称，ra为目标引用名。给ra赋值：ra=1; 等价于 a=1;
		　　（5）声明一个引用，不是新定义了一个变量，它只表示该引用名是目标变量名的一个别名，它本身不是一种数据类型，因此引用本身不占存储单元，系统也不给引用分配存储单元。故：对引用求地址，就是对目标变量求地址。&ra与&a相等。
		　　（6）不能建立数组的引用。因为数组是一个由若干个元素所组成的集合，所以无法建立一个数组的别名。
			
			引用参数：
				1) 传递可变参数
			　　传统的c中，函数在调用时参数是通过值来传递的，这就是说函数的参数不具备返回值的能力。
			　　所以在传统的c中，如果需要函数的参数具有返回值的能力，往往是通过指针来实现的
				2) 给函数传递大型对象
			　　当大型对象被传递给函数时，使用引用参数可使参数传递效率得到提高，因为引用并不产生对象的
			　　副本，也就是参数传递时，对象无须复制。

			引用返回值：只有类里面的方法可以返回引用，并且引用对象为类成员变量；对于一般的函数调用,返回引用将导致编译出错

			常引用：常引用声明方式：const 类型标识符&引用名=目标变量名；用这种方式声明的引用，不能通过引用对目标变量的值进行修改,从而使引用的目标成为const，
				达到了引用的安全性。

			引用和多态：引用是除指针外另一个可以产生多态效果的手段。这意味着，一个基类的引用可以指向它的派生类实例

		- 继承
			一个派生类可以从一个基类派生，也可以从多个基类派生。从一个基类派生的继承称为单继承；从多个基类派生的继承称为多继承。
			　　派生类的定义格式
			　　单继承的定义格式如下：
			　　class <派生类名>:<继承方式><基类名>
			　　{
			　　<派生类新定义成员>
			　　};
			　　其中，<派生类名>是新定义的一个类的名字，它是从<基类名>中派生的，并且按指定的<继承方式>派生的。<继承方式>常使用如下三种关键字给予表示：
			　　public 表示公有基类；
			　　private 表示私有基类；
			　　protected 表示保护基类；
			　　多继承的定义格式如下：
			　　class <派生类名>:<继承方式1><基类名1>,<继承方式2><基类名2>,…
			　　{
			　　<派生类新定义成员>
			　　};
			　　可见，多继承与单继承的区别从定义格式上看，主要是多继承的基类多于一个。
			　　如果省略继承方式，对'class'将采用私有继承，对'struct'将采用公有继承。

				from: http://baike.baidu.com/view/2129194.htm
		- 虚函数 virtual
			定义：在某基类中声明为 virtual 并在一个或多个派生类中被重新定 义的成员函数[1]
			语法：virtual 函数返回类型 函数名（参数表） { 函数体 }
			用途：实现多态性，通过指向派生类的基类指针，访问派生类中同名覆盖成员函数
			虚函数必须是基类的非静态成员函数，其访问权限可以是protected或public，在基类的类定义中定义虚函数的一般形式：
			　　class 基类名{
			　　.......
			　　virtual 返回值类型 将要在派生类中重载的函数名（参数列表）；
			　　}；
		
			动态联编规定，只能通过指向基类的指针或基类对象的引用来调用虚函数，其格式：
		　　1) 指向基类的指针变量名->虚函数名（实参表）
		　　2) 基类对象的引用名. 虚函数名（实参表）

		　　使用虚函数，我们可以灵活的进行动态绑定，当然是以一定的开销为代价。如果父类的函数（方法）根本没有必要或者无法实现，完全要依赖子类去实现的话，可以把此函数（方法）设为virtual 函数名=0 我们把这样的函数（方法）称为纯虚函数。
		　　如果一个类包含了纯虚函数，称此类为抽象类。
		- 简介
			美国AT&T贝尔实验室的本贾尼·斯特劳斯特卢普（Bjarne Stroustrup）博士在20世纪80年代初期发明并实现了C++（最初这种语言被称作“C with Classes”）。 
			一开始C++是作为C语言的增强版出现的，从给C语言增加类开始，不断的增加新特性。虚函数（virtual function）、运算符重载（operator overloading）、
			多重继承（multiple inheritance）、模板（template）、异常（exception）、RTTI、命名空间（name space）逐渐被加入标准。 
			
			1998年国际标准组织（ISO）颁布了C++程序设计语言的国际标准ISO/IEC 1988-1998。C++是具有国际标准的编程语言，通常称作ANSI/ISOC++
		- prototype define /function define /call function
		- 
			access names in a given namespace. The simplest way is to use
			::, the scope-resolution operator, to qualify a name with its namespace:
			Jack::pail = 12.34; // use a variable
			Jill::Hill mole; // create a type Hill structure
			Jack::fetch(); // use a function
		- prototype一般定义在头文件中，在cpp文件中具体实现；命名空间及其下面的类名字空间；
		- ->与::
			首先介绍一下C语言中的结构。对于一个结构来说， 
			struct MyStruct { 
			int member_a; 
			}; 
			如果有个变量MyStruct s，那么使用其中的成员元素时可以用 
			s.member_a = 1； 
			如果采用指针方法访问，比如MyStruct * ps，那么同样的访问必须用箭头号： 
			ps->member_a = 1; 

			::只用在类成员函数和类成员变量中。比如，声明一个类： 
			class CA { 
			public: 
			int ca_var; 
			int add(int a, int b); 
			int add(int a); 
			}; 
			那么在实现这个函数时，必须这样书写： 
			int CA::add(int a, int b) 
			{ 
			return a + b; 
			} 
			另外，双冒号也常常用于在类变量内部作为当前类实例的元素进行表示，比如: 
			int CA::add(int a) 
			{ 
			return a + ::ca_var; 
			} 
			表示当前类实例中的变量ca_var。

	* CEGUI

* 打开outlook的时候，错误提示“无法启动Microsoft Office Outlook。无法打开Outlook窗口”	* 修复 *系统修复　* 自修复		* outlook
	    重启机器仍无法解决问题。
	    解决办法：
	    Win7：开始> 搜索程序和文件夹里》输入“Outlook.exe /resetnavpane”回车
	    WinXP：开始>执行>输入“Outlook.exe /resetnavpane”回车
	    然后正常启动就可以了。
	怕你输错，直接把我引号里的复制过去。

	ps：
		这个自修复功能还是蛮不错的

	- outlook配置
		邮箱账户类型有 Exchange，POP3，IMAP或HTTP（M），对于exchange类型的邮箱账户配置方式与POP3等的不同，可见outlook配置时的提示操作。
		对于邮箱类型，可以看账户信息。
		如xxx@alibaba-inc.com账户为exchange类型。


* IP转发 * ip forward ,在Linux中使能IP转发
	
	应用：iptables中配置ip转发规则，需要开启ip转发功能。

	Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统，使用下面命令：
	cat /proc/sys/net/ipv4/ip_forward
 	如果上述文件中的值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。
	要想打开IP转发功能，可以直接修改上述文件：
	echo 1 > /proc/sys/net/ipv4/ip_forward
	把文件的内容由0修改为1。禁用IP转发则把1改为0。
	上面的命令并没有保存对IP转发配置的更改，下次系统启动时仍会使用原来的值，要想永久修改IP转发，需要修改/etc/sysctl.conf文件，修改下面一行的值：
	net.ipv4.ip_forward = 1
	修改后可以重启系统来使修改生效，也可以执行下面的命令来使修改生效：
	sysctl -p /etc/sysctl.conf
	进行了上面的配置后，IP转发功能就永久使能了
	from: http://easwy.com/blog/archives/enable-ip-forward-on-linux/

	How to enable IP Forwarding in Linux
		By default any modern Linux distributions will have IP Forwarding disabled. This is normally a good idea, as most peoples will not need IP Forwarding, but if we are setting up a Linux router/gateway or maybe a VPN server (pptp or ipsec) or just a plain dial-in server then we will need to enable forwarding. This can be done in several ways that I will present bellow.
		Check if IP Forwarding is enabled
		We have to query the sysctl kernel value net.ipv4.ip_forward to see if forwarding is enabled or not:
		Using sysctl:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 0
		or just checking out the value in the /proc system:
		cat /proc/sys/net/ipv4/ip_forward
		0
		As we can see in both the above examples this was disabled (as show by the value 0).
		Enable IP Forwarding on the fly
		As with any sysctl kernel parameters we can change the value of net.ipv4.ip_forward on the fly (without rebooting the system):
		sysctl -w net.ipv4.ip_forward=1
		or
		echo 1 > /proc/sys/net/ipv4/ip_forward
		the setting is changed instantly; the result will not be preserved after rebooting the system.
		Permanent setting using /etc/sysctl.conf
		If we want to make this configuration permanent the best way to do it is using the file /etc/sysctl.conf where we can add a line containing net.ipv4.ip_forward = 1
		/etc/sysctl.conf:
		net.ipv4.ip_forward = 1
		if you already have an entry net.ipv4.ip_forward with the value 0 you can change that 1.
		To enable the changes made in sysctl.conf you will need to run the command:
		sysctl -p /etc/sysctl.conf
		On RedHat based systems this is also enabled when restarting the network service:
		service network restart
		and on Debian/Ubuntu systems this can be also done restarting the procps service:
		/etc/init.d/procps.sh restart
		Using distribution specific init scripts
		Although the methods presented above should work just fine and you would not need any other method of doing this, I just wanted to note that there are also other methods to enable IP Forwarding specific to some Linux distributions.
		For example Debian based distributions might use the setting:
		/etc/network/options:
		ip_forward=no
		set it to yes and restart the network service.
		Also RedHat distributions might set this using:
		/etc/sysconfig/network:
		FORWARD_IPV4=true
		and again restart the network service.
		Regardless the method you have used once you have completed this you can check it out using the same method shown above:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 1
		cat /proc/sys/net/ipv4/ip_forward
		1
		If the result is 1 then the Linux system will start forwarding IP packets even if they are not destined to any of its own network interfaces.
		ps. I was setting up a VPN dial-in server when I wrote this post 

* ospf vrrp instance切换时, 通过ospf更新路由信息来切换, 而不是通过发送arp
	------
	开放式最短路径优先（英文：Open Shortest Path First，OSPF）是对链路状态路由协议的一种实现，隶属内部网关协议（IGP），故运作于自治系统内部。
	著名的迪克斯加算法被用来计算最短路径树。它使用“代价（Cost）”作为路由度量。链路状态数据库（LSDB）用来保存当前网络拓扑结构，它在同一区域
	中的所有路由器上是相同的。OSPF分为OSPFv2和OSPFv3两个版本,其中OSPFv2用在IPv4网络，OSPFv3用在IPv6网络。OSPFv2是由RFC 2328定义的，
	OSPFv3是由RFC 5340定义的。
	
	OSPF协议是大中型网络上使用最为广泛的IGP（Interior Gateway Protocol）协议。节点在建立邻接，接受链路状态通告（Link-state Advertisement，LSA）时，
	可以通过MD5或者明文进行安全验证。
	
	OSPF提出了“区域（Area）”的概念，一个网络可以由单一区域或者多个区域组成。其中，一个特别的区域被称为骨干区域（Backbone Area），该区域是整个
	OSPF网络的核心区域，并且所有其他的区域都与之直接连接。所有的内部路由都通过骨干区域传递到其他非骨干区域。所有的区域都必须直接连接到骨干区域，
	如果不能建立直接连接，那么可以通过虚拟链路（Virtual-link）和骨干区域建立虚拟连接。
	
	同一个广播域（Broadcast Domain）的路由器或者一个点对点（Point To Point）连接的两端的路由器，在发现彼此的时候，建立邻接（Adjacencies）[1]。多路访问网络
	以及非广播多路访问网络的路由器会选举指定路由器（Designated Router, DR）和备份指定路由器（Backup Designated Router, BDR），DR和BDR作为网络的中心负责
	路由器之间的信息交换从而降低了网络中的信息流量。OSPF协议同时使用单播（Unicast）和组播（Multicast）来发送Hello包和链路状态更新（Link State Updates），
	使用的组播地址为224.0.0.5和224.0.0.6。与RIP和BGP不同的是，OSPF协议不使用TCP或者UDP协议而是承载在IP协议之上，IP协议号为89，工作在OSI模型的传输层。
	------
	from: http://zh.wikipedia.org/wiki/OSPF


* keepalived是VRRP的完美实现，因此在介绍keepalived之前，先介绍一下VRRP的原理。	    * VRRP
	VRRP协议简介
	
	虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)

	在现实的网络环境中，两台需要通信的主机大多数情况下并没有直接的物理连接。对于这样的情况，它们之间路由怎样选择？主机如何选定到达目的主机的下一跳路由，
	这个问题通常的解决方法有二种：
	·        在主机上使用动态路由协议(RIP、OSPF等)
	·        在主机上配置静态路由
	很明显，在主机上配置路态路由是非常不切实际的，因为管理、维护成本以及是否支持等诸多问题。配置静态路由就变得十分流行，但路由器(或者说默认网关default gateway)却经常
	成为单点。
	VRRP的目的就是为了解决静态路由单点故障问题。

	VRRP通过一竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。

	工作机制

	在一个VRRP虚拟路由器中，有多台物理的VRRP路由器，但是这多台的物理的机器并不能同时工作，而是由一台称为MASTER的负责路由工作，其它的都是BACKUP，
	MASTER并非一成不变，VRRP让每个VRRP路由器参与竞选，最终获胜的就是MASTER。MASTER拥有一些特权，比如 拥有虚拟路由器的IP地址，我们的主机就是
	用这个IP地址作为静态路由的。拥有特权的MASTER要负责转发发送给网关地址的包和响应ARP请求。

	VRRP通过竞选协议来实现虚拟路由器的功能，所有的协议报文都是通过IP多播(multicast)包(多播地址 224.0.0.18)形式发送的。虚拟路由器由VRID(范围0-255)和一组IP地址组成，
	对外表现为一个周知的MAC地址。所以，在一个虚拟路由 器中，不管谁是MASTER，对外都是相同的MAC和IP(称之为VIP)。客户端主机并不需要因为MASTER的改变而
	修改自己的路由配置，对他们来 说，这种主从的切换是透明的。

	在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP广告包(VRRPAdvertisement message)，BACKUP不会抢占MASTER，除非它的优先级(priority)更高。
	当MASTER不可用时(BACKUP收不到广告包)， 多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性。

	由于安全性考虑，VRRP包使用了加密协议进行加密。

	==========================================

	vrrp简介
	随着Internet的迅猛发展，基于网络的应用逐渐增多。这就对网络的可靠性提出了越来越高的要求。斥资对所有网络设备进行更新当然是一种很好的可靠性解决方案；
	但本着保护现有投资的角度考虑，可以采用廉价冗余的思路，在可靠性和经济性方面找到平衡点。

	  虚拟路由冗余协议就是一种很好的解决方案。在该协议中，对共享多存取访问介质（如以太网）上终端IP设备的默认网关(Default Gateway)进行冗余备份，
	  从而在其中一台路由设备宕机时，备份路由设备及时接管转发工作，向用户提供透明的切换，提高了网络服务质量。 

	一、协议概述

	  在基于TCP/IP协议的网络中，为了保证不直接物理连接的设备之间的通信，必须指定路由。目前常用的指定路由的方法有两种：一种是通过路由协议（比如：内部路由协议RIP和OSPF）
	  动态学习；另一种是静态配置。在每一个终端都运行动态路由协议是不现实的，大多客户端操作系统平台都不支持动态路由协议，
	  即使支持也受到管理开销、收敛度、安全性等许多问题的限制。因此普遍采用对终端IP设备静态路由配置，一般是给终端设备指定一个或者多个默认网关(Default Gateway)。
	  静态路由的方法简化了网络管理的复杂度和减轻了终端设备的通信开销，但是它仍然有一个缺点：如果作为默认网关的路由器损坏，所有使用该网关为下一跳主机的通信必然要中断。
	  即便配置了多个默认网关，如不重新启动终端设备，也不能切换到新的网关。采用虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)可以很好的避免静态指定网关的缺陷。

	  在VRRP协议中，有两组重要的概念：VRRP路由器和虚拟路由器，主控路由器和备份路由器。VRRP路由器是指运行VRRP的路由器，是物理实体，虚拟路由器是指VRRP协议创建的，
	  是逻辑概念。一组VRRP路由器协同工作，共同构成一台虚拟路由器。该虚拟路由器对外表现为一个具有唯一固定IP地址和MAC地址的逻辑路由器。处于同一个VRRP组中的路由器
	  具有两种互斥的角色：主控路由器和备份路由器，一个VRRP组中有且只有一台处于主控角色的路由器，可以有一个或者多个处于备份角色的路由器。VRRP协议使用选择策略
	  从路由器组中选出一台作为主控，负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。当由于某种原因主控路由器发生故障时，
	  备份路由器能在几秒钟的时延后升级为主路由器。由于此切换非常迅速而且不用改变IP地址和MAC地址，故对终端使用者系统是透明的。 

	二、工作原理

	  一个VRRP路由器有唯一的标识：VRID，范围为0—255。该路由器对外表现为唯一的虚拟MAC地址，地址的格式为00-00-5E-00-01-[VRID]。主控路由器负责对ARP请求用该MAC地址做应答。这样，无论如何切换，保证给终端设备的是唯一一致的IP和MAC地址，减少了切换对终端设备的影响。

	  VRRP控制报文只有一种：VRRP通告(advertisement)。它使用IP多播数据包进行封装，组地址为224.0.0.18，发布范围只限于同一局域网内。这保证了VRID在不同网络中可以重复使用。为了减少网络带宽消耗只有主控路由器才可以周期性的发送VRRP通告报文。备份路由器在连续三个通告间隔内收不到VRRP或收到优先级为0的通告后启动新的一轮VRRP选举。

	  在VRRP路由器组中，按优先级选举主控路由器，VRRP协议中优先级范围是0—255。若VRRP路由器的IP地址和虚拟路由器的接口IP地址相同，则称该虚拟路由器作VRRP组中的IP地址所有者；IP地址所有者自动具有最高优先级：255。优先级0一般用在IP地址所有者主动放弃主控者角色时使用。可配置的优先级范围为1—254。优先级的配置原则可以依据链路的速度和成本、路由器性能和可靠性以及其它管理策略设定。主控路由器的选举中，高优先级的虚拟路由器获胜，因此，如果在VRRP组中有IP地址所有者，则它总是作为主控路由的角色出现。对于相同优先级的候选路由器，按照IP地址大小顺序选举。VRRP还提供了优先级抢占策略，如果配置了该策略，高优先级的备份路由器便会剥夺当前低优先级的主控路由器而成为新的主控路由器。

	  为了保证VRRP协议的安全性，提供了两种安全认证措施：明文认证和IP头认证。明文认证方式要求：在加入一个VRRP路由器组时，必须同时提供相同的VRID和明文密码。适合于避免在局域网内的配置错误，但不能防止通过网络监听方式获得密码。IP头认证的方式提供了更高的安全性，能够防止报文重放和修改等攻击。

	三、 应用实例

	  最典型的VRRP应用：RTA、RTB组成一个VRRP路由器组，假设RTB的处理能力高于RTA，则将RTB配置成IP地址所有者，H1、H2、H3的默认网关设定为RTB。则RTB成为主控路由器，负责ICMP重定向、ARP应答和IP报文的转发；一旦RTB失败，RTA立即启动切换，成为主控，从而保证了对客户透明的安全切换。

	  在VRRP应用中，RTA在线时RTB只是作为后备，不参与转发工作，闲置了路由器RTA和链路L1。通过合理的网络设计，可以到达备份和负载分担双重效果。让RTA、RTB同时属于互为备份的两个VRRP组：在组1中RTA为IP地址所有者；组2中RTB为IP地址所有者。将H1的默认网关设定为RTA；H2、H3的默认网关设定为RTB。这样，既分担了设备负载和网络流量，又提高了网络可靠性。

	  VRRP协议的工作机理与CISCO公司的HSRP（Hot Standby Routing Protocol）有许多相似之处。但二者主要的区别是在CISCO的HSRP中，需要单独配置一个IP地址作为虚拟路由器对外体现的地址，这个地址不能是组中任何一个成员的接口地址。

	  使用VRRP协议，不用改造目前的网络结构，最大限度保护了当前投资，只需最少的管理费用，却大大提升了网络性能，具有重大的应用价值。

* linux
	- /etc/sysctl.conf
		-----
		# Kernel sysctl configuration file for Red Hat Linux
		#
		# For binary values, 0 is disabled, 1 is enabled.  See sysctl(8) and
		# sysctl.conf(5) for more details.

		# Controls IP packet forwarding
		net.ipv4.ip_forward = 0

		# Controls source route verification
		net.ipv4.conf.default.rp_filter = 1

		# Do not accept source routing
		net.ipv4.conf.default.accept_source_route = 0

		# Controls the System Request debugging functionality of the kernel
		kernel.sysrq = 0

		# Controls whether core dumps will append the PID to the core filename
		# Useful for debugging multi-threaded applications
		kernel.core_uses_pid = 1

		# Controls the use of TCP syncookies
		net.ipv4.tcp_syncookies = 1

		# Controls the maximum size of a message, in bytes
		kernel.msgmnb = 65536

		# Controls the default maxmimum size of a mesage queue
		kernel.msgmax = 65536

		# Controls the maximum shared segment size, in bytes
		kernel.shmmax = 68719476736

		# Controls the maximum number of shared memory segments, in pages
		kernel.shmall = 4294967296

		# Determines how often to check for stale neighbor entries. 
		net.ipv4.neigh.default.gc_stale_time=120

		# Using arp_announce/arp_ignore to solve the ARP Problem
		net.ipv4.conf.default.arp_announce = 2
		net.ipv4.conf.all.arp_announce = 2

		# Disable reverse-path filter
		net.ipv4.conf.all.rp_filter = 0  
		net.ipv4.conf.default.rp_filter = 0
		net.ipv4.tcp_tw_reuse = 1
		net.ipv4.tcp_tw_recycle = 1
		-----
	- arping - send ARP REQUEST to a neighbour host
	- Linux调试工具strace和gdb常用命令小结
		---------
				strace（用来跟踪任何程序的系统调用）和 GDB 调试工具（用来在受控的环境中运行程序的功能齐全的调试工具）
				strace 专注于监控一个程序系统调用和它接受到的所有信号（与Unix系统上的truss是一样的），使用的是内核系统调用ptrace。另外，还有类似的ltrace（同样是
			基于ptrace的），它功能是能够跟踪进程的库函数调用。
				gdb比starce能做的事情更多，比如gdb可以获得堆栈跟踪信息，堆栈跟踪不仅会告诉你程序当前正在做什么，有底层的信息（如等待网络套接字），也有较高
			级别的信息（如正在执行什么类型的网络操作）。
			下面是使用过程中一些命令小结:
			
			strace调试工具
				strace工具用于跟踪进程执行时的系统调用和所接收的信号，包括参数、返回值、执行时间。在Linux中，用户程序要访问系统设备，必须由用户态切换到
			内核态，这是通过系统调用发起并完成的。
			strace常用参数：
			-c　　统计每种系统调用执行的时间、调用次数、出错次数，程序退出时给出报告
			-p pid　　跟踪指定的进程，可以使用多个-p同时跟踪多个进程
			-o filename　　strace默认输出到stdout，-o可以将输出写入到指定的文件
			-f　　跟踪由fork产生的子进程的系统调用
			-ff　　常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到各个filename.pid文件中
			-F　　尝试跟踪vfork子进程系统调用，注意：与-f同时使用时, vfork不被跟踪
			-e expr　　输出过滤表达式，可以过滤掉不想输出的strace结果
			-e trace=set　　指定跟踪set中的系统调用
			-e trace=network　　跟踪与网络有关的所有系统调用
			-e strace=signal　　跟踪所有与系统信号有关的系统调用
			-e trace=ipc　　跟踪所有与进程通讯有关的系统调用
			-e signal=set　　指定跟踪set中的信号
			-e read=set　　输出从指定文件中读出的数据，例如-e read=3,5
			-e write=set　　输出写入到指定文件中的数据，例如-e write=1
			-r　　打印每一个系统调用的相对时间
			-t　　在输出中的每一行前加上时间信息
			-tt　　在输出中的每一行前加上时间信息，时间精确到微秒级
			-ttt　　在输出中的每一行前加上时间信息，输出为相对时间
			-s　　指定每一行输出字符串的长度（默认为32）
			strace使用举例：
			strace -t whoami  #跟踪whoami可执行程序，每行输出结果前打印执行的时间
			strace -p 17151 -p 17152 -p 17153  #同时跟踪进程17151、17152、17153
			strace -f -e trace=read,write -p 17151 -o log  #跟踪进程17151及子进程中read和write系统调用，输出到log文件
			gdb调试工具
			GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具。gcc编译时加上-g参数，可以使可执行程序加上gdb调试信息。
			（1）info
			简写：i，列出gdb子命令的信息，如info break，info variables，info stack等。
			（2）list [file:]function
			简写：l，查看当前行的上下文，默认为10行，也可以设置在某个函数处列出源码。
			（3）edit [file:]function
			简写：e，编辑当前所在的行，也可以编辑某个函数的源码。
			（4）break [file:]function
			简写：b，设置断点，可以设置在某行或某个函数处。
			（5）run [arglist]
			简写：r，运行程序至断点处停住，run命令之后可以加上调试程序需要的参数。
			（6）next
			简写：n，单条语句执行。
			（7）continue
			简写：c，继续运行程序至下一个断点。
			（8）print
			简写：p，打印变量的值。
			（9）bt
			查看函数堆栈信息。
			（10）enter
			回车键，重复上一次调试命令。
			（11）help [name]
			显示指定的gdb命令的帮助信息。
			（12）quit
			简写：q，退出gdb。
			from: http://www.cnblogs.com/zhangzhang/archive/2013/01/07/2850355.html
		---------
	- strace命令
		---------
				strace 是一个非常简单的工具，用来跟踪可执行程序的系统调用(system call)。最简单的使用是，它追踪可行程序运行时的整个生命周期，
			输出每一个系统调用的名字，参数和返回值。  
			
			但是它还可以做更多的事情：
			 
			它可以基于系统调用或者系统调用组来过滤
			它可以通过计算制定系统调用的次数，花费的时间以及成功和失败的次数来描述系统调用的使用
			它可以追踪发送给进程的信号(signal)
			它可以通过进程id(pid)号加入到任意正在运行的进程上
			 
			如何使用
			 
			找出一个程序启动时读取了哪个配置文件
			 
			有的时候，你发发现，无论你如何修改配置文件，应用程序并没有按照你的思路去运行，这是什么原因？一个浅显但容易忽视的考虑是，
			应用程序启动时读取了你认为要读取的配置文件了吗？看下面的例子：
			 
			 $ strace php 2>&1 | grep php.ini          open("/usr/local/bin/php.ini", O_RDONLY) = -1 ENOENT (No such file or directory)          open("/usr/local/lib/php.ini", O_RDONLY) = 4          lstat64("/usr/local/lib/php.ini", {st_mode=S_IFLNK|0777, st_size=27,        ...}) = 0          readlink("/usr/local/lib/php.ini", "/usr/local/Zend/etc/php.ini",        4096) = 27          lstat64("/usr/local/Zend/etc/php.ini", {st_mode=S_IFREG|0664,st_size=40971, ...}) = 0    
			上述php程序程序会首先从/usr/local/bin/下读取php.ini文件，也许不是你想的首先从/usr/local/lib/下读取。
			上述的输出会很多，我们甚至可以通过参数来指定只追踪我们关心的系统调用，类似如下：
			 
			  $ strace -e open php 2>&1 | grep php.ini           open("/usr/local/bin/php.ini", O_RDONLY) = -1 ENOENT (No such file or         directory)           open("/usr/local/lib/php.ini", O_RDONLY) = 4  
			为什么程序没有打开我的文件？
			 
			每一个可执行程序读取文件时，如果权限不够，则会遭拒绝。而如果文件找不到，也并不会报错，除非你在程序里设置了错误处理，So，
			如果程序没有读取我的文件，我该如何跟踪呢？
			 
			 $ strace -e open,access 2>&1 |grep your-filename
			检查open()和access()系统调用的输出结果，看看是什么原因
			 
			进程此刻正在做什么？
			 
			你的程序突然消耗了大量的CPU，或者程序似乎被挂起了，那么我们通过进程的pid号看看此刻它正在做什么
			 
			 root@dev:~# strace -p 15427           Process 15427 attached - interrupt to quit           futex(0x402f4900, FUTEX_WAIT, 2, NULL           Process 15427 detached  
			通过跟踪，你知道程序挂起的原因是正在调用futex()。
			 
			程序的时间花在什么地方
			 
			你总是希望程序能够按照你的意愿去工作，也希望它能在正确的时间做正确的事情，甚至希望它是最优的，尽可能在程序运行的周期内，
			消耗的90%以上的资源都是在做需要做的事情，而不是简单的等待。也许，下面的这个指令可以帮上你的忙:
			 
			 root@dev:~# strace -c -p 11084
			 Process 11084 attached - interrupt to quit
			 Process 11084 detached
			 % time     seconds  usecs/call     calls    errors syscall
			 ------ ----------- ----------- --------- --------- ----------------
			  94.59    0.001014          48        21           select
			   2.89    0.000031           1        21           getppid
			   2.52    0.000027           1        21           time
			 ------ ----------- ----------- --------- --------- ----------------
			 100.00    0.001072                    63           total
			 root@dev:~# 
			如果你是跟踪的后台守护进程，可以通过上面的指令跟踪一段时间，然后按ctrl+c退出，strace会根据获得信息描述出上面的结果。
			上述的例子说明当前进程(postmaster)最要的时间花在等待select()函数上，在每调用一次select函数后，它分别调用getpid函数和time函数. 如果是非后台守护进程，
			那strace可以跟踪进程的开始至结束，类似下面这样：
			 
			 root@dev:~# strace -c >/dev/null ls
			 % time     seconds  usecs/call     calls    errors syscall
			 ------ ----------- ----------- --------- --------- ----------------
			  23.62    0.000205         103         2           getdents64
			  18.78    0.000163          15        11         1 open
			  15.09    0.000131          19         7           read
			  12.79    0.000111           7        16           old_mmap
			   7.03    0.000061           6        11           close
			   4.84    0.000042          11         4           munmap
			   4.84    0.000042          11         4           mmap2
			   4.03    0.000035           6         6         6 access
			   3.80    0.000033           3        11           fstat64
			   1.38    0.000012           3         4           brk
			   0.92    0.000008           3         3         3 ioctl
			   0.69    0.000006           6         1           uname
			   0.58    0.000005           5         1           set_thread_area
			   0.35    0.000003           3         1           write
			   0.35    0.000003           3         1           rt_sigaction
			   0.35    0.000003           3         1           fcntl64
			   0.23    0.000002           2         1           getrlimit
			   0.23    0.000002           2         1           set_tid_address
			   0.12    0.000001           1         1           rt_sigprocmask
			 ------ ----------- ----------- --------- --------- ----------------
			 100.00    0.000868                    87        10 total
			ls程序大部分时间花在读取目录条目上面。
			 
			为什么我不能连接到服务器？
			 
			调试进程不能连接到服务器是一个痛苦的事情，因为原因很多，比如DNS失效啦，连接被挂起啦，服务器返回异常数据啦，服务器本身异常啦，等等。
			一般网络调试方面，很多人会想到另外一个非常不错的工具-tcpdump。但它的参数太多了，而且你要从上百个连接进程中找出其中一个进程为什么不能连接
			恐怕是一件非常费力的工作。strace 其实也能在这种情景下帮上你的忙，它仅仅输出与系统调用相关的数据，从而可以让我们的注意力更集中。类似下面这样：
			 
			 $ strace -e poll,select,connect,recvfrom,sendto nc www.news.com 80
			 sendto(3, "\24\0\0\0\26\0\1\3\255\373NH\0\0\0\0\0\0\0\0", 20, 0, {sa_family=AF_NETLINK, pid=0, groups=00000000}, 12) = 20
			 connect(3, {sa_family=AF_FILE, path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
			 connect(3, {sa_family=AF_FILE, path="/var/run/nscd/socket"}, 110) = -1 ENOENT (No such file or directory)
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "\213\321\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\34\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "\213\321\201\200\0\1\0\1\0\1\0\0\3www\4news\3com\0\0\34\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 153
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "k\374\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\1\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "k\374\201\200\0\1\0\2\0\0\0\0\3www\4news\3com\0\0\1\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 106
			 connect(3, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, 28) = 0
			 poll([{fd=3, events=POLLOUT, revents=POLLOUT}], 1, 0) = 1
			 sendto(3, "\\\2\1\0\0\1\0\0\0\0\0\0\3www\4news\3com\0\0\1\0\1", 30, MSG_NOSIGNAL, NULL, 0) = 30
			 poll([{fd=3, events=POLLIN, revents=POLLIN}], 1, 5000) = 1
			 recvfrom(3, "\\\2\201\200\0\1\0\2\0\0\0\0\3www\4news\3com\0\0\1\0\1\300\f"..., 1024, 0, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr("62.30.112.39")}, [16]) = 106
			 connect(3, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("216.239.122.102")}, 16) = -1 EINPROGRESS (Operation now in progress)
			 select(4, NULL, [3], NULL, NULL)        = 1 (out [3])
			那么，上述的输出，说明进程发生了什么呢？
			注意到这个进程尝试连接/var/run/nscd/socket连接了吗？这意味着nc程序首先会去连接NSCD- Name Service Cache Daemon - 它通常用于设置和NIS，YP，
			LDAP或者类似目录协议相关的域名查询配置上。在上述例子中，连接失败了。
			 
			接下来进程开始连接到DNS，这点可以从sin_port=htons(53)输出可以看出。你可以看到，它接着做了一个sendto()的调用，发出了一个包含www.news.com信息
			的DNS包。然后读取返回的包数据，不知什么原因，它做了三次这样的尝试。一个可能的原因是www.news.com是一条CNAME记录。多次请求可能是nc程序处理的一种方式。
			 
			最后，它总算是发起了connect()操作，注意这个操作的返回结果是EINPROGRESS，这意味着这个连接是非阻塞式的，nc希望继续，于是它调用了select()。
			 
			增加read,write调用到strace跟踪的系统调用列表里，可以让我们看到下面的一些结果：
			 
			 read(0, "test\n", 1024)                 = 5
			 write(3, "test\n", 5)                   = 5
			 poll([{fd=3, events=POLLIN, revents=POLLIN}, {fd=0, events=POLLIN}], 2, -1) = 1
			 read(3, "
			上述表示它从读取”test” + 标准输入的一行信息，然后写入网络连接，接着调用poll来等待回应，然后读取网络反馈的信息并写到标准输出。
			from: http://5iwww.blog.51cto.com/856039/771031
		---------
	- linux挂载硬盘	    * linux挂载硬盘
		添加磁盘
		找到磁盘
			fdisk -l
		分区
			fidsk /dev/xxx
			n
			w
			...
		格式化
			mkfs -t ext3 /dev/xxx
		创建目录，并挂载上面的分区
			mkdir /disk
			mount /dev/xxx /disk
		验证挂载情况
			df -k
		设置开机自动挂载
			vi /etc/fstab
			/dev/xxx               /disk                 ext3    defaults        0 0
		from: http://blog.csdn.net/tianlesoftware/article/details/5642883

	- nslookup
		DNS信息
		Nslookup is a program to query Internet domain name servers.  Nslookup has two modes: interactive and non-interactive. Interactive
		       mode allows the user to query name servers for information about various hosts and domains or to print a list of hosts in a domain.
		       Non-interactive mode is used to print just the name and requested information for a host or domain
	- lsof (list open files)
		查看进程打开文件数
	- chown -hR admin /home/admin/
		修改文件/文件夹所属
		chown root /u        Change the owner of /u to "root".
		 chown root:staff /u  Likewise, but also change its group to "staff".
		 chown -hR root /u    Change the owner of /u and subfiles to "root".

	- 账户管理 用户管理
		centos用户&组权限&添加删除用户问题详解

		1) Linux操作系统是多用户多任务操作系统，包括用户账户和组账户两种
		细分用户账户（普通用户账户，超级用户账户）除了用户账户以为还有组账户所谓组账户就是用户账户的集合，centos组中有两种类型，私有组和标准组，当创建一个新用户时，若没有指定他所属的组，centos就建立以个和该用户相同的私有组，此私有组中只包括用户自己。标准组可以容纳多个用户，如果要使用标准组，那创建一个新的用户时就应该指定他所属于的组，从另外一方面讲，同一个用户可以属于多个组，例如某个单位的领导组和技术组，lik是该单位的技术主管，所以他就是属于领导组和技术组。当一个用户属于多个组时，其登录后所属的组是主组，其它组为附加组。

		 

		2) Linux环境下的账户系统文件主要在/etc/passwd, /etc/shadow,/etc/group,和/etc/gshadow四个文件。基本含义就不多说了重点说一下，root的uid是0，从1-499是系统的标准账户，普通用户从uid 500开始。

		 

		3) 使用命令管理账户
		useradd 选项  用户名//添加新用户

		usermod 选项  用户名//修改已经存在的用户

		userdel -r    用户名//删除用户表示自家目录一起删除。

		groupadd 选项  组名// 添加新组

		groupmod 选项  组名//修改已经存在的组

		groupdel 组名  //删除已经存在的特定组。

		 

		例子
		useradd zhh888 //添加一个用户zh888

		groupadd blog  //新建一个blog组

		useradd -G blog zh //表示创建一个新用户zh，同时加入blog附加组中。

		useradd -d /var/ftp/pub -M ftpadmin //创建一个新用户ftpadmin,指定目录是/var/ftp/pub,不创建自家目录（-M)

		usermod -G blog zh888 //表示将zh888添加到附加组blog中去。

		userdel ftpadmin //表示删除ftpadmin用户

		userdel -r zhh888 //表示删除zh888和/home中的目录一起删除。

		groupdel blog //表示删除blog组。

		 

		4) 口令管理及时效
		创建用户之后就要给用户添加密码，设置的口令的命令式passwd
		passwd 选项  用户名

		passwd -l 用户名账号名//禁止用户账户口令

		passwd -S 用户名//表示查看用户账户口令状态

		passwd -u 用户名//表示恢复用户账号

		passwd -d 用户名//表示删除用户账户口令

		 

		5) chage 命令是保护密码的时效这样可以防止其他人猜测密码的时间。

		chage 选项 用户名

		参数有 -m days, -M days ,-d days, -I days ,-E date, -W days,-l
		例子：#chage -m 2 -M 30 -W zhh//表示的意思是要求用户zhh两天内不能更改密码，并且口令最长存活期是30天，并且口令过期5天通知zhh

		 

		6) 用户和组的状态查询命令

		whoami //用于显示当前的用户名称。

		groups 用户名//表示显示指定的用户所属的组，如果没指定用户则是当前用户所属的组。

		id //表示显示当前用户的uid gid和用户所属的组列表。

		su - 用户//表示转换到其他用户，如果su表示切换到自己的当前用户。

		newgrp 组名//表示转换用户的当前组到指定的附加组，用户必须属于该组才能进行。

		 

		7) 更改属主和同组人

		有时候还需要更改文件的属主和所属的组。只有文件的属主有权更改其他属主和所属的组，用户可以把属于自己的文件转让给大家。改变文件属主用chown命令

		chown [-R] <用户名或组><文件或目录>

		chown zh888 files//把文件files属主改成zh888用户。

		chown zh888.zh888 files//将文件files的属主和组都改成zh888。

		chown -R zh888.zh888 files//将files所有目录和子目录下的所有文件或目录的主和组都改成zh888.


		8) 设置文件的目录和目录生成掩码

		用户可以使用umask命令设置文件默认的生成掩码。默认的生成掩码告诉系统创建一个文件或目录不应该赋予哪些权限。如果用户将umask命令放在环境文件.bash_profile中，就可以控制所有新建的文件和目录的访问权限。

		umask [a1a2a3]
		a1表示的是不允许属主的权限，a2表示的是不允许同组人的权限，a3代表不允许其他人的权限。

		umask 022//表示设置不允许同组用户和其他用户有写的权限。

		umask //显示当前的默认生成掩码。

		 

		9) 特殊权限的设置

		SUID SGID 和sticky-bit

		除了一般权限还有特殊的权限存在，一些特殊权限存在特殊的权限，如果用户不需要特殊权限一般不要打开特殊权限，避免安全方面的问题。具体的用法可以百度和google一下。

		希望自己整理出来的知识能帮助网友更好的理解centos用户&组权限&添加删除用户等问题。

		from: http://hi.baidu.com/phpmsn/item/9dc1831e40124d6c3f87ce08

	- ln创建软连接，即win系统的快捷方式，省去输入全路径去执行脚本的问题		  -tip-
		如对于/etc/init.d/httpd 这个脚本，可以创建ln到工作目录下，便于执行
		ln -s /etc/init.d/httpd ~/httpd

	- run level 运行级别
		 Linux下有7个运行级别：

		0 系统停机模式，系统默认运行级别不能设置为0，否则不能正常启动，机器关闭。
		1) 单用户模式，root权限，用于系统维护，禁止远程登陆，就像Windows下的安全模式登录。
		2) 多用户模式，没有NFS网络支持。
		3) 完整的多用户文本模式，有NFS，登陆后进入控制台命令行模式。
		4) 系统未使用，保留一般不用，在一些特殊情况下可以用它来做一些事情。例如在笔记本电脑的电池用尽时，可以切换到这个模式来做一些设置。
		5) 图形化模式，登陆后进入图形GUI模式，X Window系统。
		6) 重启模式，默认运行级别不能设为6，否则不能正常启动。运行init 6机器就会重启。

		运行级别原理：

		1).在目录/etc/rc.d/init.d下有许多服务器脚本程序，一般称为服务(service)
		2).在/etc/rc.d下有7个名为rcN.d的目录，对应系统的7个运行级别
		3).rcN.d目录下都是一些符号链接（即软链接）文件，这些链接文件都指向/etc/rc.d/init.d目录下的service脚本文件，命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位阿拉伯数字。
		4).系统启动时，会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件：对于以K开头的文件，系统将终止对应的服； 对于以S开头的文件，系统将启动对应的服务
		5).查看运行级别用：runlevel
		#表示当前系统运行在level 3模式下
		6).进入其它运行级别用：init N，如果init 3则进入终端模式，init 5则登录图形GUI模式
		#表示运行级别由3进入到5
		#再次输入init 3，则运行级别由5回到3
		7).另外init0为关机，init 6为重启系统
		 注意：输入init 0，系统会关机；输入init 6，系统会自动重启。这两个命令要非常小心！

		标准的Linux运行级别为3或5，如果是3的话，系统就在多用户状态；如果是5的话，则是运行着X Window系统。
		不同的运行级别有不同的用处，也应该根据自己的不同情形来设置。
		例如，如果丢失了root口令，那么可以让机器启动进入单用户状态来设置。
		1). 在启动后的GRUB界面输入e；
		2).光标选择kernel那一行，再次输入e；
		3).在最后添加“空格single”，回车；
		4).按b键进入单用户模式；
		5).通过passwd root命令，修改root的密码；
		6).重启系统。
	- 

* 分布式存储 * 云存储
	http://www.cnblogs.com/jason-one/archive/2008/12/17/1356461.html

* 单点问题，单点故障
	- 单点session问题，采用分布式session实现无单点故障的分布式session服务
		·memcache + 
* iptables * 防火墙 * linux防火墙设置
	--------
		 linux防火墙基础和管理设置iptables规则

		 一、linux防火墙基础
		防火墙分为硬件防火墙和软件防火墙。
		1.概述
		linux 防火墙体系主要工作在网络层，针对TCP/IP数据包实施过滤和限制，属于典型的包过滤防火墙。
		包过滤机制：netfilter
		管理防火墙规则命令工具：iptables
		netfilter 指linux内核中实现包过滤防火墙的内部结构，不依程序或文件的形式存在，属于“内核态”的防火墙功能体系
		iptables 指管理linux防火墙的命令工具，属于“用户态”的防火墙管理体系
		2.iptables的规则表、链结构
		iptables的作用在于为包过滤机制的实现提供规则，通过不同的规则作出不同的反应.
		iptables管理4个表、以及他们的规则链
		   filter,用于路由网络数据包。
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包从服务器流出
		FORWARD 网络数据包经服务器路由
		   nat,用于NAT表.NAT(Net Address Translation )是一种IP地址转换方法。
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		OUTPUT 网络数据包流出服务器
		   mangle,用于修改网络数据包的表，如TOS(Type Of Service),TTL(Time To Live),等
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包流出服务器
		FORWARD 网络数据包经由服务器转发
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		   raw, 用于决定数据包是否被跟踪机制处理
		OUTPUT 网络数据包流出服务器
		PREROUTING 网络数据包到达服务器时可以被修改
		3.数据包过滤匹配流程
		1>.规则表之间的优先顺序
		依次应用：raw、mangle、nat、filter表
		2>.规则链之间的优先顺序
		入站数据流向
		转发数据流向
		出站数据流向
		3>.规则链内部各条防火墙规则之间的优先顺序
		 
		二、管理和配置Iptables规则
		1.iptables的基本语法格式
		iptables [-t 表名] 命令选项 [链名] [条件匹配] [-] 目标动作或跳转
		表名链名用于指定iptables命令所做对象，未指定默认filter表，命令选项指于管理iptables规则的方式（插入、删除··）；条件匹配指定对条件的符合而处理；目标动作或跳转指定数据包的处理方式。
		2.管理iptables规则
		控制选项
		 -A 在链尾添加一条规则
		　-D 从链中删除一条规则
		 -I 在链中插入一条规则
		 -R 修改、替换某链的某规则
		 -L 列出某个链上的规则
		 -F 清空链，删除链上的所有规则
		 -N 创建一个新链
		 -X 删除某个规则链
		 -P 定义某个链的默认策略
		     -n 数字形式显示结果
		 -v 查看规则列表详细信息
		 -V 查看iptables命令工具版本
		 -h 查看命令帮助信息
		 -line-numbers 查看规则列表，显示顺序号
		增加、插入、删除和替换规则
		相关规则定义的格式为：
		iptables  [-t表名]  <-A | I | D | R> 链名 [规则编号] [-i | o 网卡名称] [-p 协议类型] [-s 源IP地址 | 源子网] [--sport 源端口号] [-d目标IP地址 | 目标子网] [--dport目标端口号] <-j动作>
		参数说明如下。
		[-t表名]：定义默认策略将应用于哪个表，可以使用filter、nat和mangle，如果没有指定使用哪个表，iptables就默认使用filter表。
		-A：新增加一条规则，该规则将会增加到规则列表的最后一行，该参数不能使用规则编号。
		-I：插入一条规则，原本该位置上的规则将会往后顺序移动，如果没有指定规则编号，则在第一条规则前插入。
		-D：从规则列表中删除一条规则，可以输入完整规则，或直接指定规则编号加以删除。
		-R：替换某条规则，规则被替换并不会改变顺序，必须要指定替换的规则编号。
		<链名>：指定查看指定表中哪个链的规则列表，可以使用INPUT、OUTPUT、FORWARD、PREROUTING、OUTPUT和POSTROUTING。
		[规则编号]：规则编号用于插入、删除和替换规则时用，编号是按照规则列表的顺序排列，规则列表中第一条规则的编号为1。
		[-i | o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出。网卡名称可以使用ppp0、eth0和eth1等。
		[-p 协议类型]：可以指定规则应用的协议，包含TCP、UDP和ICMP等。
		[-s 源IP地址 | 源子网]：源主机的IP地址或子网地址。
		[--sport 源端口号]：数据包的IP的源端口号。
		[-d目标IP地址 | 目标子网]：目标主机的IP地址或子网地址。
		[--dport目标端口号]：数据包的IP的目标端口号。 
		<-j动作>：处理数据包的动作，各个动作的详细说明可以参考表10-3。 
		1>.添加及插入规则
		   在Filter表的INPUT链的末尾添加一条防护墙规则
		[root@s2 ~]# iptables -t filter -A INPUT -p tcp -j ACCEPT
		   在Filter表的INPUT链中插入一条防护墙规则
		[root@s2 ~]# iptables -I INPUT -p udp -j ACCEPT
		   在在Filter表的INPUT链中插入一条防护墙规则（为链中第二条规则）
		[root@s2 ~]# iptables -I INPUT 2 -p icmp -j ACCEPT
		2>.查看规则表
		   查看Filter表的INPUT链中的所有规则，同时显示顺序号
		[root@s2 ~]# iptables -L INPUT --line-numbers
		Chain INPUT (policy ACCEPT)
		num  target     prot opt source               destination         
		1    ACCEPT     udp  --  anywhere             anywhere            
		2    ACCEPT     icmp --  anywhere             anywhere            
		3    REJECT     icmp --  anywhere             anywhere  
		   查看filter表各链中所有规则的详细信息，以数字形式显示地址和端口信息
		[root@s2 ~]# iptables -vnL
		Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
		pkts bytes target     prot opt in     out     source               destination         
		1189  154K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 ACCEPT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 REJECT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           reject-with icmp-port-unreachable 
		2449  221K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		3>.删除、清空规则
		   删除Filter表的INPUT链中的第2条规则
		[root@s2 ~]# iptables -D INPUT 2
		   清空filter表、nat表、mangle表各链中的所有规则	
		[root@s2 ~]# iptables -F
		[root@s2 ~]# iptables -t nat -F
		[root@s2 ~]# iptables -t mangle -F
		4>.设置规则链的默认策略
		最基本的两种策略为ACCEPT（允许）、DROP（丢弃）
		   将filter表中的FORWARD规则链的默认策略设为 DROP
		[root@s2 ~]# iptables -t filter -P FORWARD DROP
		   将filter表中的 OUTPUT规则链的默认策略设为 ACCEPT
		[root@s2 ~]# iptables -P OUTPUT ACCEPT
		5>.获得iptables相关选项用法的帮助信息
		   查看iptables命令中关于icmp协议的信息
		[root@s2 ~]# iptables -p icmp -h
		6>.新增、删除自定义规则链
		   清空raw表中自定义的所有规则链
		[root@s2 ~]# iptables -t raw -X
		3.条件匹配
		1>.通用条件匹配
		一般直接使用，而不依赖于其他的条件匹配及其扩展。常见匹配方式如下：
		协议匹配：用于检查数据包的网络协议
		拒绝进入防火墙的所有icmp协议数据包
		[root@s2 ~]# iptables -I INPUT -p icmp -j REJECT
		允许防火墙转发除icmp协议以外的所有数据包（“！”反取）	
		[root@s2 ~]# iptables -A FORWARD -p ! icmp -j ACCEPT
		[root@s2 ~]# iptables -L FORWARD
		Chain FORWARD (policy DROP)
		target     prot opt source               destination         
		ACCEPT    !icmp --  anywhere             anywhere    
		地址匹配：用于检查数据包的IP地址、网络地址。
		拒绝转发来自192.168.1.11主机的数据，允许来自192.168.0.0/24网段数据
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.11 -j REJECT
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT
		网络接口匹配：用于检查数据包从防火墙的哪个接口进入或离开
		丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP
		封堵IP地址段！并2小时后解锁
		[root@s2 ~]# iptables -I INPUT -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# iptables -I FORWARD -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# at now +2 hours
		at> iptables -D INPUT 1
		at> iptables -D FORWARD 1
		at> <EOT>
		job 1 at 2010-04-25 17:43
		2>.隐含条件匹配
		通常需要以指定的协议匹配为前提，对应功能由iptables自动装载内核。常见的隐含匹配方式如下：
		端口匹配：用于检查数据包的TCP或UDP端口号
		仅允许系统管理员从202.13.0.0/16网段使用SSH方式远程登录防火墙主机
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -j DROP
		允许本机开放TCP端口的 20 ~ 1024 提供的应用服务
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT
		[root@s2 ~]# iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT
		允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT
		[root@s2 ~]# iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT
		TCP标记匹配：用于检查数据包的TCP标记位
		拒绝从外网接口（eth1）直接访问防火墙本机的数据包，但允许响应防火墙TCP请求的数据包进入
		[root@s2 ~]# iptables -P INPUT DROP
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags SYN, RST, ACK SYN -j REJECT
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags ! --syn -j ACCEPT
		ICMP类型匹配：用于检查ICMP数据包
		禁止其他主机ping防火墙主机，但是允许防火墙能ping其他主机
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Request -j DROP
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Reply -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT
		显示条件匹配：需要额外的内核模块提供，因此需要手工指定匹配方式
		MAC地址匹配：主要检查数据包的源MAC地址
		[root@s2 ~]# iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP
		多端口匹配：检查数据包的源端口、目标端口时，用于匹配多个不连续的端口号。
		[root@s2 ~]# iptables -A INPUT -p tcp -m multiport --dport 20.21.24.11.1250:1280 -j ACCEPT
		多IP地址匹配：检查数据包的源地址、目标地址时，用于匹配一段范围内的IP地址
		[root@s2 ~]# iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP
		状态匹配：基于iptables的状态跟踪机制，检查数据包的连接状态
		禁止转发与正常TCP连接无关的非--syn请求数据包
		[root@s2 ~]# iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP
		4.数据包控制
		最常见处理方式;
		ACCEPT:允许数据包通过
		DROP：直接丢弃数据包，不给任何回应信息
		REJECT：拒绝数据包通过，必要时发个响应信息
		LOG: 记录日志信息，将数据包递给下一条规则
		对于尝试通过SSH方式登录防火墙主机的访问数据，记录日志信息并禁止访问
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j DROP
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j LOG
		用户自定义链：将数据传给用户自定义的链进行处理
		自定义一个链MYLAN 转发至192.168.1.0/24 网段数据包交给该链中的规则处理。
		[root@s2 ~]# iptables -t filter -N MYLAN
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A FORWARD -d 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A MYLAN -p icmp -j DROP
		SNAT:（源地址转换）修改数据包的源IP地址
		DNAT:（目标地址转换）修改数据包的目标IP地址
		 

		from: http://xiaozhuang.blog.51cto.com/4396589/874244

	--------
* redis
		redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。

* jboss
	- jboss启动失败一例
		jboss一个jmx相关的mbean注册时，由于identity不能识别，导致启动失败，需要本地回环(127.0.0.1)在/etc/hosts
		文件中有hostname执行本地回环的定义。
		如：
			127.0.0.1 identify-host-name
	- jboss简介
		1. Jboss Server 目录结构

		bin　　　　　　　　Start up scripts and start up configuration files available for Unix and Windows environments  
		bundles　　　　　　Location of OSGi bundles  
		docs/schema　　　　XML schema definition files  
		domain　　　　　　Configuration files, deployment content, and writable areas used by the domain mode processes run from this installation.  
		modules　　　　　　AS 7 is based on a modular classloading architecture. The various modules used in the server are stored here.  
		standalone　　　　Configuration files, deployment content, and writable areas used by the single standalone server run from this installation.  
		welcome-content　　Default Welcome Page content
		2. Standalone 目录结构

		1）configuration   
		　　Configuration files for the standalone server that runs off of this installation. All configuration information for the running server is located here and is the single place for configuration modifications for the standalone server.  
		2）data   
		　　Persistent information written by the server to survive a restart of the server  
		3）deployments   
		　　End user deployment content can be placed in this directory for automatic detection and deployment of that content into the server's runtime.   NOTE: The server's management API is recommended for installing deployment content. File system based deployment scanning capabilities remain for developer convenience.  
		4）lib/ext   
		　　Location for installed library jars referenced by applications using the Extension-List mechanism  
		5）log   
		　　standalone server log files  
		6）tmp   
		　　location for temporary files written by the server

		3. Jboss Rule

		JBoss Rules 的前身是Codehaus的一个开源项目叫Drools。最近被纳入JBoss门下，更名为JBoss Rules，成为了JBoss应用服务器的规则引擎。

		参考文档：
		https://docs.jboss.org/author/display/AS7/Getting+Started+Guide#GettingStartedGuide-GettingStartedwithJBossApplicationServer7
	- jboss 优化，服务器优化，系统优化

		   JBOSS访问缓慢，查看jboss的并发请求数及其TCP连接状态：
		netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
		LAST_ACK 5
		SYN_RECV 263
		CLOSE_WAIT 30
		ESTABLISHED 308
		FIN_WAIT1 499
		FIN_WAIT2 71
		CLOSING 20
		TIME_WAIT 19070
		检查发现TIME_WAIT 状态链接很高, 这样就需要对内核做些优化，
		Vi /etc/sysctl.conf
		net.ipv4.tcp_fin_timeout = 30
		net.ipv4.tcp_keepalive_time = 300
		net.ipv4.tcp_syncookies = 1
		net.ipv4.tcp_tw_reuse = 1
		net.ipv4.tcp_tw_recycle = 1
		net.core.netdev_max_backlog =8096
		net.ipv4.ip_local_port_range = 1024    65000
		net.ipv4.tcp_max_tw_buckets = 5000
		 
		修改完记的使用sysctl -p 让它生效

		以上参数的注解
		/proc/sys/net/ipv4/tcp_tw_reuse
		该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接。

		/proc/sys/net/ipv4/tcp_tw_recycle
		recyse是加速TIME-WAIT sockets回收

		对tcp_tw_reuse和tcp_tw_recycle的修改，可能会出现.warning, got duplicate tcp line warning, got BOGUS tcp line.上面这二个参数指的是存在这两个完全一样的TCP连接，
		这会发生在一个连接被迅速的断开并且重新连接的情况，而且使用的端口和地址相同。但基本上这样的事情不会发生，无论如何，使能上述设置会增加重现机会。
		这个提示不会有人和危害，而且也不会降低系统性能，目前正在进行工作

		/proc/sys/net/ipv4/tcp_keepalive_time
		表示当keepalive起用的时候,TCP发送keepalive消息的频度。缺省是2小时

		/proc/sys/net/ipv4/tcp_fin_timeout    最佳值和BSD一样为30
		fin_wait1状态是在发起端主动要求关闭tcp连接，并且主动发送fin以后，等待接收端回复ack时候的状态。对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。
		对方可能会断开连接或一直不结束连接或不可预料的进程死亡。

		/proc/sys/net/core/netdev_max_backlog
		该文件指定了，在接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
		net.ipv4.ip_local_port_range = 1024    65000
		表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
		 
		net.ipv4.tcp_max_tw_buckets = 5000
		表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，
		上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT
		套接字拖死。
		 
		 
		其它查看连接数据命令：
		1)统计80端口连接数
		netstat -nat|grep -i "80"|wc -l
		1
		2）统计httpd协议连接数
		ps -ef|grep httpd|wc -l
		1
		3）、统计已连接上的，状态为“established'
		netstat -na|grep ESTABLISHED|wc -l
		2
		4)、查出哪个IP地址连接最多,将其封了.
		netstat -na|grep ESTABLISHED|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
		 
		netstat -na|grep SYN|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
		iptables的设置:
		 
		防止同步包洪水（Sync Flood）
		# iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT
		也有人写作
		#iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT
		--limit 1/s 限制syn并发数每秒1次，可以根据自己的需要修改
		防止各种端口扫描
		# iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j
		ACCEPT
		Ping洪水攻击（Ping of Death）
		# iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT
		 
		 
		修改JBOSS连接池：
		Vi /usr/local/jboss/server/default/deploy/jbossweb-tomcat55.sar/server.xml
		<Connector port="80" address="${jboss.bind.address}"
			 maxThreads="500" strategy="ms" maxHttpHeaderSize="8192"
			 emptySessionPath="true" maxKeepAliveRequests="1"
			 enableLookups="false" redirectPort="8443" acceptCount="100"
			 connectionTimeout="10000" disableUploadTimeout="true"/>
		 
		 
		修改JBOSS内存：
		Vi /usr/local/jboss/bin/run.conf
		if [ "x$JAVA_OPTS" = "x" ]; then
		   JAVA_OPTS="-Xms1024m -Xmx2048m -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.rmi.dgc.server.gcInterval=3600000"
		fi
		 

		from:http://kerry.blog.51cto.com/172631/161179

* What Is a Socket	  * socket socket http socket与http
	
	-	A socket is one end-point of a two-way communication link between two programs running on the network. 
	Socket classes are used to represent the connection between a client program and a server program. The java.net package provides 
	two classes--Socket and ServerSocket--that implement the client side of the connection and the server side of the connection, respectively. 

	- socket与http关系
		http基于socket
			socket是点对点通讯的基础，一个抽象接口层；http是在socket层上面在封装，根据http协议定义的编码要求来收发；即也可自行根据socket实现自定义的通讯协议
			比如定义 nuwa://xxx协议，迅雷的thunder://，电驴ed2k://|file|
			·例子：http://www.cnblogs.com/sunwei2012/archive/2010/04/06/1705634.html 自定义应用层通信协议
				通信协议精确地定义了双方通信控制信息和解释信息：发送方能将特定信息（文本、图片、音频、视频）按协议封装成指定格式的数据包，最终以串行化比特流在网络上传输；接收方接收到数据包后，根据协议将比特流解析为本地化数据，从而获取对方发送过来的原始信息。
				通信协议包括三个要素：
				（1）语法：规定了信息的结构和格式；
				（2）语义：表明信息要表达的内容；
				（3）同步：规则涉及双方的交互关系和事件顺序。
				整个计算机网络的实现体现为协议的实现，TCP/IP协议是Internet互联网的核心协议。

* log * log4j
	- log4j热加载
	通过spring配置log4j的热加载：
		web.xml
		<context-param>
			<param-name>log4jConfigLocation</param-name>
			<param-value>file:${app.config.dir}/log4j.xml</param-value>
		</context-param>
		<context-param>
			<param-name>log4jRefreshInterval</param-name>
			<param-value>10000</param-value>
		</context-param>
		<listener>
			<listener-class>org.springframework.web.util.Log4jConfigListener</listener-class>
		</listener>
	- log4j通过配置，将log append到远程地址或日志存储服务中以便于查询和管理
		配置appender
	- log4j调优
		log4j输出log到文件时，使用缓冲输出
			log4j.appender.monitorAppender.BufferedIO=true
			log4j.appender.monitorAppender.BufferSize=8192
		组装输出内容之前可对logger的输出级别先进行判断而不要完全依赖log4j控制，因为组装输出日志内容也是要损耗效率的。
			//若log4j并未开启info级日志记录，直接返回
			if(!monitorLogger.isInfoEnabled()){
				return;
			}
			StringBuilder log = new StringBuilder();
			logSql.append(logPk+" ");
		ref: http://www.blogjava.net/conans/articles/345083.html


	- isDebugEnabled()的判断什么时候需要？
		if (replace && log.isDebugEnabled())
			log.debug("Expanded " + before + " to " + repository);
		这个时候，需要判断isDebugEnabled()，可以减少字符串拼接的操作；

		log.debug("Failed to operate")
		此时不需要，debug()方法中已判断了日志级别，不过还是会进入debug()方法处理一下再出来，若性能要求高，还是和上面一样，判断isDebugEnabled()再输出log。

	- log4j配置时
		定义appender，定义logger
		自定义的appender注意类全路径不要搞错（服务器启动时console会报提示）
		对于一些未定义的日志可统一在log4j.xml的root标签中记录，去掉报找不到appender的warn
		sql的日志，需要定义logger指向到java.sql
	- logger.error(e) vs logger.error("xxx",e)
	看log4j的error方法说明，直接传对象接收的是message消息对象，如何给的是非message对象，可能没有重写tostring方法，输出的日志内容为对象而不是异常的内容。

* concurrent包 ，java concurrent	       * 并发 * 同步 * java并发/同步
	- java.util.concurrent.Executors
		此为工厂类和工具类，提供静态方法操作Executor, ExecutorService, ScheduledExecutorService, ThreadFactory, and Callable classes defined in this package
		DOC
		-------
		Factory and utility methods for Executor, ExecutorService, ScheduledExecutorService, ThreadFactory, and Callable classes defined in this package. This class supports the following kinds 
		of methods: 

		Methods that create and return an ExecutorService set up with commonly useful configuration settings. 
		Methods that create and return a ScheduledExecutorService set up with commonly useful configuration settings. 
		Methods that create and return a "wrapped" ExecutorService, that disables reconfiguration by making implementation-specific methods inaccessible. 
		Methods that create and return a ThreadFactory that sets newly created threads to a known state. 
		Methods that create and return a Callable out of other closure-like forms, so they can be used in execution methods requiring Callable. 
		-------
		PS: 
			If none of the executors provided by the above factory methods meet your needs, constructing instances of java.util.concurrent.ThreadPoolExecutor or java.util.concurrent.ScheduledThreadPoolExecutor 
			will give you additional options.
			如果此工厂类提供创建的对象无法满足需求，可以自定义executor的实现类

	- ThreadPoolExecutor 

		 java.util.concurrent.ThreadPoolExecutor
		 DOC
		 -----------------------------------------
		An ExecutorService that executes each submitted task using one of possibly several pooled threads, normally configured using Executors factory methods. 

			Thread pools address two different problems: they usually provide improved performance when executing large numbers of asynchronous tasks, due to 
		reduced per-task invocation overhead, and they provide a means of bounding and managing the resources, including threads, consumed when executing a collection of tasks. 
		Each ThreadPoolExecutor also maintains some basic statistics, such as the number of completed tasks. 

		To be useful across a wide range of contexts, this class provides many adjustable parameters and extensibility hooks. However, programmers are urged to 
		use the more convenient Executors factory methods Executors.newCachedThreadPool (unbounded thread pool, with automatic thread reclamation), 
		Executors.newFixedThreadPool (fixed size thread pool) and Executors.newSingleThreadExecutor (single background thread), that preconfigure settings for 
		the most common usage scenarios. Otherwise, use the following guide when manually configuring and tuning this class: 

		Core and maximum pool sizes 
		A ThreadPoolExecutor will automatically adjust the pool size (see ThreadPoolExecutor.getPoolSize) according to the bounds set by corePoolSize (
		see ThreadPoolExecutor.getCorePoolSize) and maximumPoolSize (see ThreadPoolExecutor.getMaximumPoolSize). When a new task is submitted in method 
		ThreadPoolExecutor.execute, and fewer than corePoolSize threads are running, a new thread is created to handle the request, even if other worker threads are idle. 
		If there are more than corePoolSize but less than maximumPoolSize threads running, a new thread will be created only if the queue is full. By setting corePoolSize 
		and maximumPoolSize the same, you create a fixed-size thread pool. By setting maximumPoolSize to an essentially unbounded value such as Integer.MAX_VALUE, 
		you allow the pool to accommodate an arbitrary number of concurrent tasks. Most typically, core and maximum pool sizes are set only upon construction, but they may 
		also be changed dynamically using ThreadPoolExecutor.setCorePoolSize and ThreadPoolExecutor.setMaximumPoolSize. 

		On-demand construction 
		By default, even core threads are initially created and started only when new tasks arrive, but this can be overridden dynamically using method ThreadPoolExecutor.prestartCoreThread or ThreadPoolExecutor.prestartAllCoreThreads. You probably want to prestart threads if you construct the pool with a non-empty queue. 

		Creating new threads 
		New threads are created using a java.util.concurrent.ThreadFactory. If not otherwise specified, a Executors.defaultThreadFactory is used, that creates threads to all be in the same ThreadGroup and with the same NORM_PRIORITY priority and non-daemon status. By supplying a different ThreadFactory, you can alter the thread's name, thread group, priority, daemon status, etc. If a ThreadFactory fails to create a thread when asked by returning null from newThread, the executor will continue, but might not be able to execute any tasks. 
		Keep-alive times 
		If the pool currently has more than corePoolSize threads, excess threads will be terminated if they have been idle for more than the keepAliveTime (see ThreadPoolExecutor.getKeepAliveTime). This provides a means of reducing resource consumption when the pool is not being actively used. If the pool becomes more active later, new threads will be constructed. This parameter can also be changed dynamically using method ThreadPoolExecutor.setKeepAliveTime. Using a value of Long.MAX_VALUE TimeUnit.NANOSECONDS effectively disables idle threads from ever terminating prior to shut down. By default, the keep-alive policy applies only when there are more than corePoolSizeThreads. But method ThreadPoolExecutor.allowCoreThreadTimeOut(boolean) can be used to apply this time-out policy to core threads as well, so long as the keepAliveTime value is non-zero. 
		Queuing 
		Any BlockingQueue may be used to transfer and hold submitted tasks. The use of this queue interacts with pool sizing: 
		If fewer than corePoolSize threads are running, the Executor always prefers adding a new thread rather than queuing. 
		If corePoolSize or more threads are running, the Executor always prefers queuing a request rather than adding a new thread. 
		If a request cannot be queued, a new thread is created unless this would exceed maximumPoolSize, in which case, the task will be rejected. 
		There are three general strategies for queuing: 
		Direct handoffs. A good default choice for a work queue is a SynchronousQueue that hands off tasks to threads without otherwise holding them. Here, an attempt to queue a task will fail if no threads are immediately available to run it, so a new thread will be constructed. This policy avoids lockups when handling sets of requests that might have internal dependencies. Direct handoffs generally require unbounded maximumPoolSizes to avoid rejection of new submitted tasks. This in turn admits the possibility of unbounded thread growth when commands continue to arrive on average faster than they can be processed. 
		Unbounded queues. Using an unbounded queue (for example a LinkedBlockingQueue without a predefined capacity) will cause new tasks to wait in the queue when all corePoolSize threads are busy. Thus, no more than corePoolSize threads will ever be created. (And the value of the maximumPoolSize therefore doesn't have any effect.) This may be appropriate when each task is completely independent of others, so tasks cannot affect each others execution; for example, in a web page server. While this style of queuing can be useful in smoothing out transient bursts of requests, it admits the possibility of unbounded work queue growth when commands continue to arrive on average faster than they can be processed. 
		Bounded queues. A bounded queue (for example, an ArrayBlockingQueue) helps prevent resource exhaustion when used with finite maximumPoolSizes, but can be more difficult to tune and control. Queue sizes and maximum pool sizes may be traded off for each other: Using large queues and small pools minimizes CPU usage, OS resources, and context-switching overhead, but can lead to artificially low throughput. If tasks frequently block (for example if they are I/O bound), a system may be able to schedule time for more threads than you otherwise allow. Use of small queues generally requires larger pool sizes, which keeps CPUs busier but may encounter unacceptable scheduling overhead, which also decreases throughput. 
		Rejected tasks 
		New tasks submitted in method ThreadPoolExecutor.execute will be rejected when the Executor has been shut down, and also when the Executor uses finite bounds for both maximum threads and work queue capacity, and is saturated. In either case, the execute method invokes the RejectedExecutionHandler.rejectedExecution method of its RejectedExecutionHandler. Four predefined handler policies are provided: 
		In the default ThreadPoolExecutor.AbortPolicy, the handler throws a runtime RejectedExecutionException upon rejection. 
		In ThreadPoolExecutor.CallerRunsPolicy, the thread that invokes execute itself runs the task. This provides a simple feedback control mechanism that will slow down the rate that new tasks are submitted. 
		In ThreadPoolExecutor.DiscardPolicy, a task that cannot be executed is simply dropped. 
		In ThreadPoolExecutor.DiscardOldestPolicy, if the executor is not shut down, the task at the head of the work queue is dropped, and then execution is retried (which can fail again, causing this to be repeated.) 
		It is possible to define and use other kinds of RejectedExecutionHandler classes. Doing so requires some care especially when policies are designed to work only under particular capacity or queuing policies. 
		Hook methods 
		This class provides protected overridable ThreadPoolExecutor.beforeExecute and ThreadPoolExecutor.afterExecute methods that are called before and after execution of each task. These can be used to manipulate the execution environment; for example, reinitializing ThreadLocals, gathering statistics, or adding log entries. Additionally, method ThreadPoolExecutor.terminated can be overridden to perform any special processing that needs to be done once the Executor has fully terminated. 
		If hook or callback methods throw exceptions, internal worker threads may in turn fail and abruptly terminate. 

		Queue maintenance 
		Method ThreadPoolExecutor.getQueue allows access to the work queue for purposes of monitoring and debugging. Use of this method for any other purpose is strongly discouraged. Two supplied methods, ThreadPoolExecutor.remove and ThreadPoolExecutor.purge are available to assist in storage reclamation when large numbers of queued tasks become cancelled. 
		Finalization 
		A pool that is no longer referenced in a program AND has no remaining threads will be shutdown automatically. If you would like to ensure that unreferenced pools are reclaimed even if users forget to call ThreadPoolExecutor.shutdown, then you must arrange that unused threads eventually die, by setting appropriate keep-alive times, using a lower bound of zero core threads and/or setting ThreadPoolExecutor.allowCoreThreadTimeOut(boolean). 
		Extension example. Most extensions of this class override one or more of the protected hook methods. For example, here is a subclass that adds a simple pause/resume feature: 

		 class PausableThreadPoolExecutor extends ThreadPoolExecutor {
		   private boolean isPaused;
		   private ReentrantLock pauseLock = new ReentrantLock();
		   private Condition unpaused = pauseLock.newCondition();

		   public PausableThreadPoolExecutor(...) { super(...); }

		   protected void beforeExecute(Thread t, Runnable r) {
		     super.beforeExecute(t, r);
		     pauseLock.lock();
		     try {
		       while (isPaused) unpaused.await();
		     } catch (InterruptedException ie) {
		       t.interrupt();
		     } finally {
		       pauseLock.unlock();
		     }
		   }

		   public void pause() {
		     pauseLock.lock();
		     try {
		       isPaused = true;
		     } finally {
		       pauseLock.unlock();
		     }
		   }

		   public void resume() {
		     pauseLock.lock();
		     try {
		       isPaused = false;
		       unpaused.signalAll();
		     } finally {
		       pauseLock.unlock();
		     }
		   }
		 }
		 
		Since:
		1.5
		---------------
		PS: 
		1）上面对于线程池的队列实现选择，固定线程数的采用ArrayBlockingQueue，不固定线程数的queue采用LinkedBlockingQueue（链表实现），以发挥
		各自数据结构的优势
		2）queuing部分 必须为阻塞队列
			固定线程数和不固定线程数以及所使用的阻塞队列的长度选择，需要结合使用场景来设置，各有优缺点。
			阻塞队列JDK提供
			 java.util.concurrent.BlockingQueue<E>
			 DOC
			 --------------
			A java.util.Queue that additionally supports operations that wait for the queue to become non-empty when retrieving an element, and wait for space to become available in 
			the queue when storing an element. 





	- java.util.concurrent.CopyOnWriteArrayList

	- 原子对象，
		在concurrent包的atomic子包下，提供了几个原子操作对象：AtomicBoolean,AtomicIntegerArray,AtomicLong,AtomicLongArray
		-----
		public static final int STATUS_START = 0;

		private AtomicInteger _status = new AtomicInteger(STATUS_START);

		public int waitForDone() throws InterruptedException
		    {
			synchronized (this)
			{
			    while (!isDone())
				this.wait();
			    return _status.get();
			}
		    }
		-----
		PS: 在设置HTTP状态时，使用了Concurrent包中的AtomicInteger对象来实现状态修改的原子操作
	- CountDownLatch

		await()方法调用后，需要等到计数为0时线程才继续执行；await方法还能指定超时时间，避免一直等待；
		一般使用场景为，批量任务执行时，定义2个latch，一个标识是否都做完了，另一个标识是否都成功了，实现多线程间的同步。

		一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待
		DOC说明：
		-------
		A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. 

		A CountDownLatch is initialized with a given count. The await methods block until the current count reaches zero due to invocations of the countDown method, 
		after which all waiting threads are released and any subsequent invocations of await return immediately. This is a one-shot phenomenon -- the count cannot be reset. 
		If you need a version that resets the count, consider using a CyclicBarrier. 

		A CountDownLatch is a versatile synchronization tool and can be used for a number of purposes. A CountDownLatch initialized with a count of one serves as a simple on/off latch, 
		or gate: all threads invoking await wait at the gate until it is opened by a thread invoking countDown. A CountDownLatch initialized to N can be used to make one thread wait 
		until N threads have completed some action, or some action has been completed N times. 

		A useful property of a CountDownLatch is that it doesn't require that threads calling countDown wait for the count to reach zero before proceeding, it simply prevents any 
		thread from proceeding past an await until all threads could pass. 

		Sample usage: Here is a pair of classes in which a group of worker threads use two countdown latches: 

		The first is a start signal that prevents any worker from proceeding until the driver is ready for them to proceed; 
		The second is a completion signal that allows the driver to wait until all workers have completed. 
		 class Driver { // ...
		   void main() throws InterruptedException {
		     CountDownLatch startSignal = new CountDownLatch(1);
		     CountDownLatch doneSignal = new CountDownLatch(N);

		     for (int i = 0; i < N; ++i) // create and start threads
		       new Thread(new Worker(startSignal, doneSignal)).start();

		     doSomethingElse();            // don't let run yet
		     startSignal.countDown();      // let all threads proceed
		     doSomethingElse();
		     doneSignal.await();           // wait for all to finish
		   }
		 }

		 class Worker implements Runnable {
		   private final CountDownLatch startSignal;
		   private final CountDownLatch doneSignal;
		   Worker(CountDownLatch startSignal, CountDownLatch doneSignal) {
		      this.startSignal = startSignal;
		      this.doneSignal = doneSignal;
		   }
		   public void run() {
		      try {
			startSignal.await();
			doWork();
			doneSignal.countDown();
		      } catch (InterruptedException ex) {} // return;
		   }

		   void doWork() { ... }
		 }

		 
		Another typical usage would be to divide a problem into N parts, describe each part with a Runnable that executes that portion and counts down on the latch, and queue all the Runnables to an Executor. When all sub-parts are complete, the coordinating thread will be able to pass through await. (When threads must repeatedly count down in this way, instead use a CyclicBarrier.) 

		 class Driver2 { // ...
		   void main() throws InterruptedException {
		     CountDownLatch doneSignal = new CountDownLatch(N);
		     Executor e = ...

		     for (int i = 0; i < N; ++i) // create and start threads
		       e.execute(new WorkerRunnable(doneSignal, i));

		     doneSignal.await();           // wait for all to finish
		   }
		 }

		 class WorkerRunnable implements Runnable {
		   private final CountDownLatch doneSignal;
		   private final int i;
		   WorkerRunnable(CountDownLatch doneSignal, int i) {
		      this.doneSignal = doneSignal;
		      this.i = i;
		   }
		   public void run() {
		      try {
			doWork(i);
			doneSignal.countDown();
		      } catch (InterruptedException ex) {} // return;
		   }

		   void doWork() { ... }
		 }

		 
		Memory consistency effects: Actions in a thread prior to calling countDown() happen-before actions following a successful return from a corresponding await() in another thread.


		-------

	- continuration部分类用ReentrantLock实现同步
	countdown

	- 锁
		synchronized方法（锁定方法所在的实例化对象，若实例化对象不为同一个，则不能同步）
		synchronized块（以声明的锁对象进行锁定，若锁的实例不同则不能同步）
	- concurrenthashmap的实现
		将map划分到不同的segment中，通过hash到指定的segment（继承了ReentrantLock）从而只锁定部分数据。

		DOC
		-------
		A hash table supporting full concurrency of retrievals and adjustable expected concurrency for updates. This class obeys the same functional specification as 
		java.util.Hashtable, and includes versions of methods corresponding to each method of Hashtable. However, even though all operations are thread-safe, retrieval operations 
		do not entail locking, and there is not any support for locking the entire table in a way that prevents all access. This class is fully interoperable with Hashtable in programs that 
		rely on its thread safety but not on its synchronization details. 

		Retrieval operations (including get) generally do not block, so may overlap with update operations (including put and remove). Retrievals reflect the results of the most 
		recently completed update operations holding upon their onset. For aggregate operations such as putAll and clear, concurrent retrievals may reflect insertion or removal 
		of only some entries. Similarly, Iterators and Enumerations return elements reflecting the state of the hash table at some point at or since the creation of the iterator/enumeration. 
		They do not throw ConcurrentModificationException. However, iterators are designed to be used by only one thread at a time. 

		The allowed concurrency among update operations is guided by the optional concurrencyLevel constructor argument (default 16), which is used as a hint for internal sizing. 
		The table is internally partitioned to try to permit the indicated number of concurrent updates without contention. Because placement in hash tables is essentially random, the 
		actual concurrency will vary. Ideally, you should choose a value to accommodate as many threads as will ever concurrently modify the table. Using a significantly higher value 
		than you need can waste space and time, and a significantly lower value can lead to thread contention. But overestimates and underestimates within an order of magnitude do 
		not usually have much noticeable impact. A value of one is appropriate when it is known that only one thread will modify and all others will only read. Also, resizing this or any 
		other kind of hash table is a relatively slow operation, so, when possible, it is a good idea to provide estimates of expected table sizes in constructors. 

		This class and its views and iterators implement all of the optional methods of the Map and Iterator interfaces. 

		Like Hashtable but unlike HashMap, this class does not allow null to be used as a key or value. 
		-------
		PS: 

	- java concurrent 探秘
			我们都知道，在JDK1.5之前，Java中要进行业务并发时，通常需要有程序员独立完成代码实现，当然也有一些开源的框架提供了这些功能，
		但是这些依然没有JDK自带的功能使用起来方便。而当针对高质量Java多线程并发程序设计时,为防止死蹦等现象的出现，比如使用java之前的wait()、notify()和synchronized等，
		每每需要考虑性能、死锁、公平性、资源管理以及如何避免线程安全性方面带来的危害等诸多因素，往往会采用一些较为复杂的安全策略，加重了程序员的开发负担.万幸的是，
		在JDK1.5出现之后，Sun大神（Doug Lea）终于为我们这些可怜的小程序员推出了java.util.concurrent工具包以简化并发完成。开发者们借助于此，将有效的减少竞争条件（race conditions）
		和死锁线程。concurrent包很好的解决了这些问题，为我们提供了更实用的并发程序模型。

		Executor                  ：具体Runnable任务的执行者。
		ExecutorService           ：一个线程池管理者，其实现类有多种，我会介绍一部分。我们能把Runnable,Callable提交到池中让其调度。
		Semaphore                 ：一个计数信号量
		ReentrantLock             ：一个可重入的互斥锁定 Lock，功能类似synchronized，但要强大的多。
		Future                    ：是与Runnable,Callable进行交互的接口，比如一个线程执行结束后取返回的结果等等，还提供了cancel终止线程。
		BlockingQueue             ：阻塞队列。
		CompletionService         : ExecutorService的扩展，可以获得线程执行结果的
		CountDownLatch            ：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。
		CyclicBarrier             ：一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点
		Future                    ：Future 表示异步计算的结果。
		ScheduledExecutorService ：一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。

		接下来逐一介绍
		from：http://www.cnblogs.com/aurawing/articles/1887056.html
	- volatile transient / Java中的volatile关键字	 * volatile * transient

		A compile-time error occurs if a final variable is also declared volatile.
		volatile不能和final同时使用，否则编译时error

		transient和volatile两个关键字一个用于对象序列化，一个用于线程同步，都是Java中比较高阶的话题，简单总结一下。
		1) transient
		transient是类型修饰符，只能用来修饰字段。在对象序列化的过程中，标记为transient的变量不会被序列化。

		示例：
		class Test {
		transient int a; // 不会被持久化
		int b; // 持久化
		}
		当类Test的实例对象被序列化（比如将Test类的实例对象 t 写入硬盘的文本文件t.txt中），变量 a 的内容不会被保存，变量 b 的内容则会被保存。

		参考：
		把一个对象的表示转化为字节流的过程称为串行化（也称为序列化，serialization），从字节流中把对象重建出来称为反串行化（也称为为反序列化，deserialization）。
		transient 为不应被串行化的数据提供了一个语言级的标记数据方法。
		
		2) 关于volatile
		我们知道，在Java中设置变量值的操作，除了long和double类型的变量外都是原子操作，也就是说，对于变量值的简单读写操作没有必要进行同步。这在JVM 1.2之前，Java的内存模
		型实现总是从主存读取变量，是不需要进行特别的注意的。而随着JVM的成熟和优化，现在在多线程环境下volatile关键字的使用变得非常重要。在当前的Java内存模型下，线程可以把变
		量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值
		的拷贝，造成数据的不一致。要解决这个问题，只需要像在本程序中的这样，把该变量声明为volatile（不稳定的）即可，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中
		进行读取。
		一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。
		
		Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，
		两个不同的线程总是看到某个成员变量的同一个值。 

		Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才与共享成员变量的原始值对比。 
		这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。 
		而volatile关键字就是提示VM：对于这个成员变量不能保存它的私有拷贝，而应直接与共享成员变量交互。 
		使用建议：在两个或者更多的线程访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，不必使用。 
		由于使用volatile屏蔽掉了VM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。
		from: http://www.cnblogs.com/xwdreamer/archive/2012/05/13/2498615.html
		PS: "在Java中设置变量值的操作，除了long和double类型的变量外都是原子操作"对这句话的解释，摘自jls se 5.0
			-------
			17.7 Non-atomic Treatment of double and long

			Some implementations may find it convenient to divide a single write action on a 64-bit long or double value into two write actions on adjacent 32 bit values. For efficiency's sake, this behavior is implementation specific; Java virtual machines are free to perform writes to long and double values atomically or in two parts.

			For the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in 
			a situation where a thread sees the first 32 bits of a 64 bit value from one write, and the second 32 bits from another write. Writes and reads of volatile long and double values are always atomic. 
			Writes to and reads of references are always atomic, regardless of whether they are implemented as 32 or 64 bit values.

			VM implementors are encouraged to avoid splitting their 64-bit values where possible. Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs 
			correctly to avoid possible complications.
			-------
			PS: 就目前jvm的实现，如果long和double没有声明为volatile类型，则它们的赋值操作不是原子的，需要原子操作则要定义为volatile或者正确的同步。

		JDK官方对volatile,transient的说明：
		transient fileds:
			Variables may be marked transient to indicate that they are not part of the persistent state of an object.

			If an instance of the class Point:

			class Point {
				int x, y;
				transient float rho, theta;
			}
			were saved to persistent storage by a system service, then only the fields x and y would be saved. This specification does not specify details of such services; see the specification of java.io.Serializable 
			for an example of such a service.
		

		ref: http://docs.oracle.com/javase/specs/jls/se5.0/html/j3TOC.html or JSL3

		http://www.ibm.com/developerworks/cn/java/j-jtp06197.html  Java 理论与实践: 正确使用 Volatile 变量
	
	- java并发小节
		------
		Java多线程编程，是并发编程的一种（另一种重要的并发编程是多进程编程）。我们写java程序一般是运行在同一个进程中的，所以可以简单的认为：并发编程 = 多线程编程，让写操
		作系统的人去关注多进程编程吧。多线程编程是一个重要的软件基础，不管你的代码是不是多线程，java程序运行在jvm中一定是多线程运行的：运行你的main方法的线程，以及一些后
		台守护线程，如垃圾收集等。虽然在我们平时的程序中很少直接用到多线程，但是一些重要的框架都要用到多线程的。比如java应用服务器，Servlet，以及其他的任何一个知名的框架
		。所以，学好多线程编程，对我们理解框架的实现，提高软件设计水平，以及写出更好的可扩展，可伸缩的软件具有非常重要的作用。

		多线程编程是非常复杂的，主要体现在多线程程序非常容易引入bug，这些bug通常难以调试重现，同时是在程序在高并发高负载的时候偶然出现，而且很难重复出现，所以调试这些bug
		是一个很困难的事。既然难么困难，为什么要用多线程呢，单线程不也挺好的吗？明知山有虎，偏向虎山行？那是人家体现自己的勇气用的。采用多线程又有什么好处呢？总的来说，
		有以下两点好处：
		1). 速度。首先，现在多核CPU已经烂大街了，你的CPU如果还是单核的你都不好意思和人打招呼。采用多线程可以“充分”利用CPU的处理能力。其实，更重要的一点是，并发通常可以
		提高运行在单核处理器上的程序的性能。这听起来似乎违背直觉。导致这个现象产生的原因是 阻塞 。程序要很多的地方会产生阻塞，比如IO操作。此时单线程程序就会一直阻塞，直
		到线程的资源都就绪。这会大大浪费CPU的处理能力。
		2). 改进代码设计。面向对象就是要让程序以一种和自然世界相似的思维来设计程序，多线程编程可以以更加接近真实世界的方式来思维，使程序更加简单易懂。比如仿真，如果不采用
		多线程，基本上没法实现。
		并发编程是软件设计的基础，是可以离开任何程序语言来独立研究的。但是笔者认为那是计算机科学家干的事，比如Doug Lea，Brian Goetz 等，笔者窃认为自己还没有达到这种境界。
		所以笔者只有结合java来说说多线程编程。Java在语言层面就支持多线程，而且有大量的类库来用于多线程编程，所以可以轻松用java写出多线程程序，做到以前只有专家能做到的事（
		写出来的程序的质量当然有天渊之别，呵呵）。我觉得，java从以下三方面来支持多线程编程：
		1). 多线程的实现机制。Java采用命令模式来实现多线程，即 执行器+ 任务 的方式。
		2). 多线程的底层协调机制。从最基本的同步到各种用途的锁，让程序员精确控制线程之间的协作（合作和竞争）。
		3). 多线程的高层协调工具类。各种原子变量，非阻塞队列，同步容器，同步器，让线程和线程之间的协作更简单方便。
		下面分别从这三方面来阐述java的多线程编程。
		一． 多线程的实现机制
		Thread，Executor，ExecutorService，Runnable，Callable，Future……..当笔者看到这么多的类时，感到一阵头皮发麻。相信很多同仁也有一样的感觉。其实不止多线程，IO系统啊，Socket
		编程啊，都会让人有这种感觉，许多初学者望而怯步。但是我们只要以设计模式的思想去思考这些系统的实现，然后用某个设计模式慢慢梳理看似乱成一锅的类和接口时，就会发觉这
		些类库设计得很精妙和优雅。甚至对SUN的那帮人产生那什么XXX江水XXX连绵不绝的敬仰（不得不说，在技术上，过度的个人崇拜是不好的）。比如，用装饰者模式来分析IO系统
		，把那一大堆分成资源流和过滤器流之后，整个IO系统就简单明了的多了。把java的网络编程分成底层的Socket编程和高层的URL编程之后，又有豁然开朗的感觉。那么多线程的这一
		大堆类和接口又有什么玄机呢？答。案。就。是。。。。。。命令模式！首先分清楚执行器和任务这两个概念。执行器就是执行任务的器（？）。任务就是具体要实现的功能，依附在
		执行器上得以执行（以上两概念纯属瞎掰，不必较真，大概理解就行）。Thread，Executor，ExecutorService等属于执行器，而Runnable，Callable，FutureTask属于任务。程序运行时需要创
		建一个执行器，若干任务，任务依附在执行器上，由执行器启动执行并控制任务。至于ThreadFactory和UnCaughtExceptionHandler是指定执行的方式以及抛出异常时的处理，可以分别学
		习。值得一提的是一个重要的类是Future，它可以实现线程有返回值。返回的结果就放在Future里面，随时可以用get（）来检查执行结果。还可以用cancel（）来对线程执行
		interrupt（），功能十分强大。
		二． 多线程的底层协调机制
		编写多线程程序最重要的一个问题是对共享资源（或者叫共享，可变的状态）的访问，访问共享资源也是线程间相互通信的简单方法。而多个线程一起访问共享资源，就要注意线程安
		全。编写线程安全的代码，本质上是管理对状态的访问，而且通常是共享的，可变的状态.所谓共享，是指一个变量可以被多个线程访问；所谓可变，是指变量在生命周期内可以给便
		。我们讨论的线程安全好像是关于代码的，但真正要做的，是在不可控制的并发访问中保护数据。
		Java提供底层的协调机制，以控制对共享资源的访问。这里的协调，包括竞争，合作和通信。
		竞争是通过锁来实现的，在访问资源之前要先取得锁，如果锁正被其他线程占有，那么本线程就会阻塞，直到取得锁。具体的实现方式有两种：
		1. synchronized关键字。Synchronized的语义是 想要执行被包围的代码块或方法，必须先取得它声明的那个对象锁。如果不能取得，线程到这里就阻塞，直到取得对象锁。至于这样做是
		否能够真正保护了共享资源的访问，synchronized关键字是不管的。需要由程序员自己来保证：确保共享资源是私有的，所有访问共享资源的地方都加上了synchronized关键字，而且使用
		的是同一个对象锁。Synchronized不仅能保证操作的原子性，还可以保证变量的可见性。而volatile仅能保证变量的可见性。（有关原子性和可见性不知道要放哪里，这里先提一下）
		2. 使用concurrent.lock。使用concurrent.lock不仅能实现synchronized的全部功能，而且能提供更好的性能和更精确的语义。比如，synchronized用的是互斥锁，仅能实现对资源的互斥访问，
		为concurrent.lock不仅有互斥锁，还有读写锁。把读锁和写锁分开，写锁相当于互斥锁，而读锁是共享的，可以让多线程同时读，以提高性能。
		合作：线程之间的合作包括Object.wait/notify/notifyAll，Thread.interrupt， Condition.await/signal/signalAll。可以在资源未准备好时调用Object.wait()使当前线程进入阻塞，而其他线程在资源准备
		好时调用notify把所有在Object上阻塞的线程唤醒，进入可执行状态。Condition.await/signal/signalAll是jdk5提供的更加精细控制线程的类，可以组合不同的Condition来实现复杂的控制。
		通信:线程之间的通信通过PipedReader / PipedWriter组合成管道对。不同线程的线程可以在上面读写，从而实现通信。程序员可以方便地利用它们来实现“生产者-消费者”模型。
		三．多线程的高层协调工具类
		用底层的协调机制可以灵活实现各种各样的需求，但这样容易出错，对程序员的要求很高。JDK1.5推出了很多高层的协调工具类，这些类让我们可以不用再用synchronized或者Lock来控
		制并发，只要简单实用它提供的容器，同步器等，就可以实现并发访问。主要的类也可以用竞争，合作及通信来划分。主要包括：
		1). 各种特定用途的容器，方便线程之间的通信。如BlockingQueue，DelayQueue，ConcurrentHashMap，CopyOnWriteArrayList等。
		2). 线程安全的基本变量类，在包java.util.concurrent.atomic中提供。
		3). 各种用途的同步器synchronizer，如CountDownLatch，CyclicBarrier，Semaphore，Exchange。
		4). 计时。TimeUnit类为指定和控制基于超时的操作提供了多重粒度（包括纳秒级）。以代替简陋的Thread.sleep。
		以下将分别介绍：（暂略）
		附A：并发编程需要掌握的一些基本概念：
		1). 摩尔定律：集成电路芯片上所集成的晶体管数量，越每隔18个月便会翻一番。
		2). Amdahl定律：对计算机系统的某个部件采用优化措施后所获得的计算机性能的提高，依赖于这部分的执行时间在整个运行时间中所占的比率。
		3). 竞争条件：多个任务并发访问和操作同一数据且执行结果与访问的特定顺序有关，称为竞争条件。（多个任务竞争响应某个条件，因访问顺序不同产生冲突或不一致的情况）。比
		如
		“检查再运行”“惰性初始化”。
		4). 原子操作：任务在执行过程中不能被打断的一序列操作
		5). 复合操作：任务在执行过程中可以被打断的一序列操作
		6). 不变约束：不变式表达了对状态的约束，这些状态是应该符合这个约束的值的组合。不变式可以代表某种业务规则。
		7). 先验条件：针对方法，规定了在条用方法之前必须为真的条件
		8). 后验条件：针对方法，规定了在条用方法之后必须为真的条件
		9). 原子性：（见原子操作）
		10). 可见性：确保线程对变量的写入对其他线程是可见的。即刷新内存中的变量。
		附B：参考资料：
		1. Java编程思想 中文版 第四版 by Bruce Eckel
		2. Java并发编程实践 中文版 by Brian Goetz,Doug Lea 等
		------
		from: http://blog.sina.com.cn/s/blog_6271df6f01019wv8.html

* svn 代码
	版本控制，代码管理，使用
	整个SVN代码管理可以看做一棵倒置的树

		1、Branches做为分支，它就像树枝，最终还是合并到主干，用来控制新需求、需求变更、BUG修改等，每个分支都有一个专用的目的，分支编号将跟特定目标关系与需求管理文档内容关联。
		2、Tags做为里程碑，它就像树根，每一次Tag的生成都要根深蒂固，才能站稳，用来控制分支测试版本和生产正式版本，标志着一个时期。
		3、Trunk做为主干，它就是雄壮的树干，由它来生出树枝，扎下树根，他的作用是保存着最稳定，功能最全面的程序代码，用来管理整个项目。
	- svn 命令
		svn log -r486678 查看某个reversion log

* tddl	TDDL动态数据源	  取模，拆分，定位

	
	参考: http://rdc.taobao.com/team/jm/archives/1645

search in index find pdf 
* 平台，产品线，生态
	一个好的平台，衍生出多种产品线，构建良好的生态
* OSGi * osgi
	- bundle之间接口调用前，需要在MANIFEST.MF中导入要使用的bundle（根据发布bundle的MANIFEST.MF文件描述来确定）。
		Bundle-SymbolicName: example
		Export-Package: example.service

		Require-Bundle: example
	- OSGI练习
		通过eclipse的plug-in项目，实现采用Equinox来实验
		一个OSGI框架+N个bundle

		参考：
			http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-osgi/index.html		基于 OSGi 的面向服务的组件编程
			http://www.ibm.com/developerworks/cn/opensource/os-ecl-osgibdev/			利用 Eclipse 开发基于 OSGi 的 Bundle 应用
				bundle间的引用关系，需要在manifest,mf文件中定义
				将bundle打成jar包，便于osgi框架安装：osgi>install file:///c:\osgi\exampleclient.jar
				此例子中，client启动后需要接受console的输入，故不要自动启动，否则可能使用不了console；可以先启动example的nameservice服务后，再手动启动client，此时
				console即可接收输入。
								       
	- 	（OOSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。
	OSGi Alliance是一个由Sun Microsystems、IBM、爱立信等于1999年3月成立的开放的标准化组织，最初名为Connected Alliance。该组织及其标准原本主要目的在于使服务提供商通过住宅网关，
	为各种家庭智能设备提供各种服务。目前该平台逐渐成为一个为室内、交通工具、移动电话和其他环境下的所有类型的网络设备的应用程序和服务进行传递和远程管理的开放式服务平台。
	该规范和核心部分是一个框架 ，其中定义了应用程序的生命周期模式和服务注册。基于这个框架定义了大量的OSGi服务： 日志、配置管理、偏好，HTTP（运行servlet）、XML分析、
	设备访问、软件包管理、许可管理、星级、用户管理、IO连接、连线管理、Jini和 UPnP。
	这个框架实现了一个优雅、完整和动态的组件模型。应用程序（称为bundle）无需重新引导可以被远程安装、启动、升级和卸载（其中Java包／类的管理被详细定义）。
	API中还定义了运行远程下载管理政策的生命周期管理。服务注册允许bundles去检测新服务和取消的服务，然后相应配合。
	OSGi原先关注于服务网关，其实可用于多个方面。现在OSGi规范已经用于从移动电话到开源的Eclipse（其中包括了与IBM的OSGi框架SMF兼容的开源版本）。
	OSGi服务平台的应用包括：服务网关、 汽车、移动电话、 工业自动化、建筑物自动化、 PDA 网格计算、娱乐（如iPronto）、和 IDE。
	OSGi规范是由成员通过公开的程序开发，对公众免费而且没有许可证限制。但是OSGi Alliance的兼容性程序只对成员开放，目前有12个兼容的实现。
	2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。ProSyst是面向OSGi开发者的Eclipse插件。
	2003年10月， 诺基亚、摩托罗拉，ProSyst 和其他OSGi成员组建了Mobile Expert Group (MEG)为下一代智能手机规范业务平台，做为对 MIDP 和CDC的补充。
	
	eclipse 3.7.2提供了OSGI控制台
	- osgi初探 例子
		http://www.cnblogs.com/bjzhanghao/archive/2007/11/21/967320.html 利用OSGi DS实现可配置Web应用程序初探
* IaaS（Infrastructure as a Service），即基础设施即服务

* BVT (Build Verification Test)
	　　BVT是在所有开发工程师都已经检入自己的代码，项目组编译生成当天的版本之后进行，主要目的是验证最新生成的软件版本在功能上是否完整，主要的软件特性是否正确。
	如无大的问题，就可以进行相应的功能测试。BVT优点是时间短，验证了软件的基本功能。缺点是该种测试的覆盖率很低。因为运行时间短，不可能把所有的情况都测试到。

	自动化测试：通过脚本语言，比如python（丰富的库），建立各个测试用例，配置测试数据，编写测试逻辑，自动化测试，并输出结果。

* cgroups
	What are CGroups?
		You might be wondering at this point what CGroups actually are ? At a high level, it is a generic mechanism the kernel provides for grouping of processes and applying controls to those groups. 
	The grouping is done via a virtual filesystem called “cgroup”. Within this filesytem, each directory defines a new group. Thus groups can be arranged to form an arbitrarily nested hierarchy simply 
	by creating new sub-directories.

		Tunables within a cgroup are provided by what the kernel calls ‘controllers’, with each controller able to expose one or more tunable or control. When mounting the cgroups filesystem it is possible to
	indicate what controllers are to be activated. This makes it possible to mount the filesystem several times, with each mount point having a different set of (non-overlapping) controllers. Why might separate 
	mount points be useful ? The key idea is that this allows the administrator to construct differing group hierarchies for different sets of controllers/tunables.

	memory: Memory controller
	    Allows for setting limits on RAM and swap usage and querying cumulative usage of all processes in the group
	cpuset: CPU set controller
	    Binding of processes within a group to a set of CPUs and controlling migration between CPus
	cpuacct: CPU accounting controller
	    Information about CPU usage for a group of processes
	cpu: CPU schedular controller
	    Controlling the priorization of processes in the group. Think of it as a more advanced nice level
	devices: Devices controller
	    Access control lists on character and block devices
	freezer: Freezer controller
	    Pause and resume execution of processes in the group. Think of it as SIGSTOP for the whole group
	net_cls: Network class controller
	    Control network utilization by associating processes with a ‘tc’ network class

		This isn’t the blog post to go into fine details about each of these controllers & their capabilities, the high level overview will do. Suffice to say that at this time, the libvirt LXC driver (container based virtualization) 
	will use all of these controllers except for net_cls and cpuset, while the libvirt QEMU driver will only use the cpu and devices controllers. 

* SQL分页语句 分页
	- mysql通过limit语句实现分页；
				  
	- sql server分页
		摘自网络
		---------
			有关分页 SQL 的资料很多，有的使用存储过程，有的使用游标。本人不喜欢使用游标，我觉得它耗资、效率低；使用存储过程是个不错的选择，
			因为存储过程是经过预编译的，执行效率高，也更灵活。先看看单条 SQL 语句的分页 SQL 吧。

			方法1：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id NOT IN
				  (
				  SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
				  )
			ORDER BY id

			方法2：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id >
				  (
				  SELECT ISNULL(MAX(id),0) 
				  FROM 
					(
					SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
					) A
				  )
			ORDER BY id

			方法3：
			适用于 SQL Server 2005
			SELECT TOP 页大小 * 
			FROM 
				(
				SELECT ROW_NUMBER() OVER (ORDER BY id) AS RowNumber,* FROM table1
				) A
			WHERE RowNumber > 页大小*(页数-1)

			说明，页大小：每页的行数；页数：第几页。使用时，请把“页大小”和“页大小*(页数-1)”替换成数字。

			其它的方案：如果没有主键，可以用临时表，也可以用方案三做，但是效率会低。
			建议优化的时候，加上主键和索引，查询效率会提高。

			通过SQL 查询分析器，显示比较：我的结论是:
			分页方案二：(利用ID大于多少和SELECT TOP分页）效率最高，需要拼接SQL语句
			分页方案一：(利用Not In和SELECT TOP分页)   效率次之，需要拼接SQL语句
			分页方案三：(利用SQL的游标存储过程分页)    效率最差，但是最为通用
		    ---------

* LVM
		LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分
	区管理的灵活性。前面谈到，LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。
	物理卷（physical volume）物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备（如RAID），是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，
	却包含有与LVM相关的管理参数。
	　　Linux用户安装Linux操作系统时遇到的一个最常见的难以决定的问题就是如何正确地给评估各分区大小，以分配合适的硬盘空间。而遇到出现 某个分区空间耗尽时，
	解决的方法通常是使用符号链接，或者使用调整分区大小的工具（比如PatitionMagic等），但这都只是暂时解决办法，没有根本解决问题。随着Linux的逻辑盘卷管理功能的出现，
	这些问题都迎刃而解，用户在无需停机的情况下方便地调整各个分区大小。	

	lvm howto：http://blog.haohtml.com/archives/10298

* VNC
	
	- VNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC是一款优秀的远程控制工具软件，由著名的AT&T的欧洲研究实验室开发的。
	VNC是在基于UNIX和Linux操作系统的免费的开放源码软件，远程控制能力强大，高效实用，其性能可以和Windows和MAC中的任何远程控制软件媲美。 
	在Linux中，VNC包括以下四各命令：vncserver，vncviewer，vncpasswd，和vncconnect。大多数情况下我只需要其中的两个命令：vncserver和vncviewer。
	
	VNC Viewer
	TightVNC
	　　应用平台： Win9x/NT/2000/XP/2003 Linux/unix
	　　自由软件，遵循GPL条款，源代码开源，个人、企业使用均无任何限制。
		vnc的加强，短小精悍，功能强大。
	- 配置vnc访问xen的vm
		有时需要通过主机hvc0登录到虚拟机中，有时需要借助vnc登录虚拟机进行管理，这样就需要有相应的配置保证两者都能正常输出。具体的配置如下文。
		
		hvc是Xen虚拟化技术引入的对虚拟机进行控制的虚拟console，在虚拟机的配置中自动完成；VNC显示VGA硬件输出，可以完成对虚拟机的管理。
		在Xen虚拟化技术中hvc则是自带的，而VNC的输出需要借助qemu-dm来模拟VGA硬件。		
		
		hvc0的输出不需要调整，只需要在虚拟机中配置串口输出，就能够使得hvc0在串口输出；而tty1通过VGA输出，用VNC显示。具体配置如下，

		在虚拟机中完成：

		#vi  /boot/grub/menu.lst    视虚拟机的启动文件而变动

		serial --unit=0 --speed=38400 --word=8 --parity=no --stop=1

		在内核行添加如下的参数

		console=ttyS0,38400n8

		在/etc/securetty 中保证有ttyS0

		#echo ‘ttyS0’ >> /etc/securetty

		修改/etc/inittab保证有以下的内容

		#vi /etc/inittab

		1:2345:respawn:/sbin/getty 38400 hvc0

		2:2345:respawn:/sbin/getty 38400 tty1

		然后将虚拟机重启，就可以同时在VNC和host主机中访问虚拟机了。

* RPC
	 - 同步RPC call 异步RPCcall RPC调用
		同步RPC调用，可以在异步RPC调用基础上加锁来实现。比如java中用CountDownLatch同步锁实现异步RPC的同步调用


	 - 通过socket进行RPC调用
		 --------
		 ...
			OutputStream localOutputStream = paramSocket.getOutputStream();

			BufferedWriter localBufferedWriter = new BufferedWriter(new OutputStreamWriter(localOutputStream));
			localBufferedWriter.write("GET /?address=");
			localBufferedWriter.write(this.mRemoteAddress);
			localBufferedWriter.write("&method=");
			localBufferedWriter.write(MethodName);
			localBufferedWriter.write("&timeout=");
			localBufferedWriter.write(Integer.toString(this.mRpcTimeout));
			localBufferedWriter.write("&client=");
			localBufferedWriter.write(this.mRpcClientName);
			localBufferedWriter.write("&token=");
			localBufferedWriter.write(this.mRpcToken);
			localBufferedWriter.write(" HTTP/1.1\r\n");
			localBufferedWriter.write("HOST: *\r\n");
			localBufferedWriter.write("Content-Length: ");
			localBufferedWriter.write(Integer.toString(this.mRpcParameter.length));
			localBufferedWriter.write("\r\nConnection: Keep-Alive\r\n");
			localBufferedWriter.write("\r\n");
			localBufferedWriter.flush();

			localOutputStream.write(this.mRpcParameter);
			localOutputStream.flush();

			InputStream localInputStream = paramSocket.getInputStream();
			paramSocket.setSoTimeout(this.mRpcTimeout);
		...
		--------

	 - 介绍：
			RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，
		 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。
		 在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易
			RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程
		发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息的到达为止。
		当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程
		接收答复信息，获得进程结果，然后调用执行继续进行。
	　　	目前，有多种 RPC 模式和执行。最初由 Sun 公司提出。IETF ONC 宪章重新修订了 Sun 版本，使得 ONC RPC 协议成为
		IETF 标准协议。现在使用最普遍的模式和执行是开放式软件基础的分布式计算环境（DCE）。

* xml
	- <![CDATA[]]>

* 测试  Cucumber			 性能测试
	- tengine+tair性能测试
		
		ref: http://baike.corp.taobao.com/index.php/Cache_compare#.E6.80.A7.E8.83.BD.E6.AF.94.E8.BE.83	统一Web接入之静态化cache方案对比
	- 自动化测试
		Cucumber的目录结构和执行过程

	- 性能测试工具 ab	   (ApacheBench)  
		-----------
		简介
		ab的全称是ApacheBench，是 Apache 附带的一个小工具，专门用于 HTTP Server 的benchmark testing，可以同时模拟多个并发请求。前段时间看到公司的开发人员也在用它作一些测试，看起来也不错
		，很简单，也很容易使用，所以今天花一点时间看了一下。
		通过下面的一个简单的例子和注释，相信大家可以更容易理解这个工具的使用。
		一个简单的例子
		/*在这个例子的一开始，我执行了这样一个命令 ab -n 10 -c 10 http://www.google.com/。这个命令的意思是启动 ab ，向 www.google.com 发送10个请求(-n 10) ，并每次发送10个请求(-c 10)——也就是说
		一次都发过去了。跟着下面的是 ab 输出的测试报告，红色部分是我添加的注释。*/

		C:\Program Files\Apache Software Foundation\Apache2.2\bin>ab -n 10 -c 10 http://www.google.com/
		This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0
		Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
		Copyright 1997-2005 The Apache Software Foundation, http://www.apache.org/
		Benchmarking www.google.com (be patient).....done    
		Server Software:        GWS/2.1
		Server Hostname:        www.google.com
		Server Port:            80
		Document Path:          /
		Document Length:        230 bytes
		Concurrency Level:      10

		/*整个测试持续的时间*/

		Time taken for tests:   3.234651 seconds

		/*完成的请求数量*/

		Complete requests:      10

		/*失败的请求数量*/

		Failed requests:        0

		Write errors:           0

		Non-2xx responses:      10

		Keep-Alive requests:    10

		/*整个场景中的网络传输量*/

		Total transferred:      6020 bytes

		/*整个场景中的HTML内容传输量*/

		HTML transferred:       2300 bytes

		/*大家最关心的指标之一，相当于 LR 中的 每秒事务数 ，后面括号中的 mean 表示这是一个平均值*/

		Requests per second:    3.09 [#/sec] (mean)

		/*大家最关心的指标之二，相当于 LR 中的 平均事务响应时间 ，后面括号中的 mean 表示这是一个平均值*/

		Time per request:       3234.651 [ms] (mean)

		/*这个还不知道是什么意思，有知道的朋友请留言，谢谢 ^_^ */

		Time per request:       323.465 [ms] (mean, across all concurrent requests)

		/*平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题*/

		Transfer rate:          1.55 [Kbytes/sec] received

		/*网络上消耗的时间的分解，各项数据的具体算法还不是很清楚*/

		Connection Times (ms)

			      min  mean[+/-sd] median   max

		Connect:       20  318 926.1     30    2954

		Processing:    40 2160 1462.0   3034    3154

		Waiting:       40 2160 1462.0   3034    3154

		Total:         60 2479 1276.4   3064    3184

		/*下面的内容为整个场景中所有请求的响应情况。在场景中每个请求都有一个响应时间，其中 50％ 的用户响应时间小于 3064 毫秒，60 ％ 的用户响应时间小于 3094 毫秒，最大的响应时间小于 
		3184 毫秒*/

		Percentage of the requests served within a certain time (ms)

		  50%   3064

		  66%   3094

		  75%   3124

		  80%   3154

		  90%   3184

		  95%   3184

		  98%   3184

		  99%   3184

		 100%   3184 (longest request)

		更多信息

		ab 不像 LR 那么强大，但是它足够轻便，如果只是在开发过程中想检查一下某个模块的响应情况，或者做一些场景比较简单的测试，ab 还是一个不错的选择——至少不用花费很多时间去学习 LR 
		那些复杂的功能，就更别说那 License 的价格了。

		下面是 ab 的详细参数解释，大家有兴趣的可以研究一下，最近没有足够多的时间研究，如果哪位朋友有兴趣希望可以帮忙翻译一下每个参数的含义，有问题讨论也欢迎在这里回帖 ^_^

		ab [ -A auth-username:password ] [ -c concurrency ] [ -C cookie-name=value ] [ -d ] [ -e csv-file ] [ -g gnuplot-file ] [ -h ] [ -H custom-header ] [ -i ] [ -k ] [ -n requests ] [ -p POST-file ] [ -P proxy-auth-username:password ]
		[ -q ] [ -s ] [ -S ] [ -t timelimit ] [ -T content-type ] [ -v verbosity] [ -V ] [ -w ] [ -x <table>-attributes ] [ -X proxy[:port] ] [ -y <tr>-attributes ] [ -z <td>-attributes ] [http://]hostname[:port]/path

		-A auth-username:password

		Supply BASIC Authentication credentials to the server. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the server needs it (i.e., has sent an
		401 authentication needed).

		-c concurrency

		Number of multiple requests to perform at a time. Default is one request at a time.

		-C cookie-name=value

		Add a Cookie: line to the request. The argument is typically in the form of a name=value pair. This field is repeatable.

		-d

		Do not display the "percentage served within XX [ms] table". (legacy support).

		-e csv-file

		Write a Comma separated value (CSV) file which contains for each percentage (from 1% to 100%) the time (in milliseconds) it took to serve that percentage of the requests. This is usually more useful than the 'gnuplot' file; as the
		results are already 'binned'.

		-g gnuplot-file

		Write all measured values out as a 'gnuplot' or TSV (Tab separate values) file. This file can easily be imported into packages like Gnuplot, IDL, Mathematica, Igor or even Excel. The labels are on the first line of the file.

		-h

		Display usage information.

		-H custom-header

		Append extra headers to the request. The argument is typically in the form of a valid header line, containing a colon-separated field-value pair (i.e., "Accept-Encoding: zip/zop;8bit").

		-i

		Do HEAD requests instead of GET.

		-k

		Enable the HTTP KeepAlive feature, i.e., perform multiple requests within one HTTP session. Default is no KeepAlive.

		-n requests

		Number of requests to perform for the benchmarking session. The default is to just perform a single request which usually leads to non-representative benchmarking results.

		-p POST-file

		File containing data to POST.

		-P proxy-auth-username:password

		Supply BASIC Authentication credentials to a proxy en-route. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the proxy needs it (i.e., has
		sent an 407 proxy authentication needed).

		-q

		When processing more than 150 requests, ab outputs a progress count on stderr every 10% or 100 requests or so. The -q flag will suppress these messages.

		-s

		When compiled in (ab -h will show you) use the SSL protected https rather than the http protocol. This feature is experimental and very rudimentary. You probably do not want to use it.

		-S

		Do not display the median and standard deviation values, nor display the warning/error messages when the average and median are more than one or two times the standard deviation apart. And default to the min/avg/max values.
		(legacy support).

		-t timelimit

		Maximum number of seconds to spend for benchmarking. This implies a -n 50000 internally. Use this to benchmark the server within a fixed total amount of time. Per default there is no timelimit.

		-T content-type

		Content-type header to use for POST data.

		-v verbosity

		Set verbosity level - 4 and above prints information on headers, 3 and above prints response codes (404, 200, etc.), 2 and above prints warnings and info.

		-V

		Display version number and exit.

		-w

		Print out results in HTML tables. Default table is two columns wide, with a white background.

		-x <table>-attributes

		String to use as attributes for <table>. Attributes are inserted <table here >.

		-X proxy[:port]

		Use a proxy server for the requests.

		-y <tr>-attributes

		String to use as attributes for <tr>.

		-z <td>-attributes

		String to use as attributes for <td>.

		相关链接

		ab 是 Apache 的一个安装组件，所以需要下载 Apache 安装后才能使用，可以访问 Apache 的项目主页来下载 http://httpd.apache.org/download.cgi

		ab 的更多信息可以参加 Apache 主页上的描述

		http://httpd.apache.org/docs/2.0/programs/ab.html

		from: http://www.cnblogs.com/jackei/archive/2006/07/18/454144.html
		-----------
	- 部署打开debug
		远程shell(调用python封装好的各个接口调用，执行命令，传入参数即可)执行请求，ide debug处理过程
* yum 
	- yum 安装指定目录，指定安装目录
		--installroot=[path]  set install root
	- yum源设置
		比如使用163镜像站，可以参考其提供的使用帮助,下面为摘取部分：
			CentOS镜像使用帮助
			使用说明
				首先备份/etc/yum.repos.d/CentOS-Base.repo
				    mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
			下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份)
				•CentOS5
				•CentOS6
			运行yum makecache生成缓存
			from: http://mirrors.163.com/.help/centos.html
						
	- yum的使用:  
	    1)包的更新  
	    1.1)检查可更新包: yum check-update  
	    1.2)更新所有包: yum update  
	    1.3)更新指定包: yum update package_name  
	    1.4)版本升级: yum upgrade  
	    2)包安装与删除  
	    2.1)yum install package_name  
	    2.2)yum remove package_name  
	    3)包搜索  
	    3.1)搜索特定包: yum search package_name  
	    3.2)搜索包含特定文件名的包:yum provides name  
	    4)包列表  
	    4.1)列出所有安装或更新的包: yum list  
	    4.2)列出指定包:yum list name  
	    4.3)列出可更新包:yum list updates  
	    4.4)列出已安装包:yum list installed  
	    4.5)列出已安装但不包含在资源库中的包:yum list extras  

	CentOS yum源设定
	    2.1)加快yum下载速度: yum -y install yum-fastestmirror,在CentOs 4上名字叫做yum-plugin-fastestmirror  
	    2.2)yum源文件:/etc/yum.repos.d/CentOS-Base.repo  
	    2.3)CentOS 5的yum源设为上海交通大学网站 

* vim
	-自动缩进
		在文件末尾添加一行，输入  set autoindent
		在添加一行，输入         set cindent
		其中 autoindent 是自动缩进； cindent是特别针对 C语言语法自动缩进
	- 可以为操作的一行添加下划线
		set cursorline
   	- vimdiff
		vimdiff 命令比较文本，比较文件，文件比较 对比工具
	- 替换
		vi/vim 中可以使用 :s 命令来替换字符串
		:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
		:s/vivian/sky/g 替换当前行所有 vivian 为 sky
		:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
		:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
		n 为数字，若 n 为 .，表示从当前行开始到最后一行
		:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
		:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
		可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
		:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	
	- set paste 保持黏贴格式
	- 
		~/.vimrc - vim对当前用户的配置文件
		~/.vim/colors 目录下放自己的颜色方案文件  ，用户自己的设置

		颜色方案下载地址：http://www.vim.org/scripts/script.php?script_id=1651

	- 可以设置编辑的颜色方案
		通常, 如果工作在终端模式下, 你只有一个黑色的背景和白色的前景色. 这种配色太单调了, 看起也太暗淡了. 其实颜色方案是可以设计的.
		默认的, 你在终端下打开Vim时的的颜色和你打开的终端的颜色是一样的. 不过Vim给了用户一个权力来改变颜色的. 最常使用的就是配色方案文件. 这些文件通常放在Vim安装目录下的colors目录下.
		你可以简单地通过下面的命令在己安装的本色方案中切换
			:colorscheme mycolors
		mycolors要换成安装的配色方案的名称. 如可你不知道安装了哪些配色方案, 可以在写下下面的命令后:
			:colorscheme
		通过按tab键来在安装的配色方案的名字间切换. 当发现了想要的配色方案后 就可以按回车键来应用它.
		配色方案不仅只是应用在前景色和背景色, 也可以设置代码的高亮显示, 错误如何标识, 和其他的一些文本的可视化标识. 
		
		安装配色方案：
			root@ag # rpm -qa | grep -i vim	      - 找到vim的安装包
			vim-common-7.0.109-6.el5
			vim-enhanced-7.0.109-6.el5
			vim-minimal-7.0.109-6.el5
			root@ag # rpm -ql vim-common-7.0.109-6.el5 | grep colors		- 找到colors目录位置      - 
			/usr/share/vim/vim70/colors
			/usr/share/vim/vim70/colors/README.txt
			/usr/share/vim/vim70/colors/blue.vim
			/usr/share/vim/vim70/colors/darkblue.vim
			/usr/share/vim/vim70/colors/default.vim
			/usr/share/vim/vim70/colors/delek.vim
			/usr/share/vim/vim70/colors/desert.vim
			/usr/share/vim/vim70/colors/elflord.vim
			/usr/share/vim/vim70/colors/evening.vim
			/usr/share/vim/vim70/colors/koehler.vim
			/usr/share/vim/vim70/colors/morning.vim
			/usr/share/vim/vim70/colors/murphy.vim
			...

			将配色方案文件 *.vim，拷贝到colors目录下，
			切换颜色方案：
			:colorscheme SchemeFileName 
		
	-
		:reg 查看剪贴板内容
	- search
		type '/' > type words > key 'n' for next match
	- 在整个文件里面有效移动光标
		VIM 有很多命令，可以用来到达文件里面你想到达的地方。下面是一些在文件里面移动的命令：
	　　<C-F>：向下移动一屏。
	　　<C-D>：向下移动半屏。
	　　<C-B>：向上移动一屏。
	　　<C-U>：向上移动半屏。
	　　G：到文件尾
	　　numG：移动光标到指定的行（num）。（比如 10G 就是到第 10 行）
	　　gg：到文件首
	　　H：移动光标到屏幕上面
	　　M：移动光标到屏幕中间
	　　L：移动光标到屏幕下面
	　　*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。
	　　/text：从当前光标处开始搜索字符串 text，并且到达 text 出现的地方。必须使用回车来开始这个搜索命令。如果想重复上次的搜索的话，按 n移动到下个 text 处，N 移动到上一个 text 处 。
	　　？text：和上面类似，但是是反方向。
	　　m{a-z}：在当前光标的位置标记一个书签，名字为 a-z 的单个字母。书签名只能是小写字母。你看不见书签的存在，但它确实已经在那里了。
	　　`a：到书签 a 处。注意这个不是单引号，它一般位于大部分键盘的 1 的左边。
	　　`.：到你上次编辑文件的地方。这个命令很有用，而且你不用自己去标记它。
	　　%：在成对的括号等符号间移动，比如成对的 [ ] ， { }， ( ) 之间。将光标放到任意符号上，然后通过 % 来移动到和这个符号匹配的符号上，% 还可以正确的识别括号的嵌套层数，总是移动到真正匹配的位置上。因此这个命令在编辑程序代码的时候非常有用，可以让你方便的在一段代码的头尾间移动。
	　　6、它主要应用在--Linux系统
	- VIM 复制黏贴
		内容：
		用vim 这么久 了，始终也不知道怎么在vim 中使用系统粘贴板，通常要在网上复制 一段代码都是先gedit打开文件，中键粘贴后关闭，然后再用vim 打开编辑，真的不 爽；上次论坛上有人问到了怎么在vim 中使用系统粘贴板，印象里回复很多，有好几页的回复却没有解决问题，今天实在受不了了又在网上找办法，竟意外地找到 了，贴出来分享一下。

		如果只是想使用系统粘贴板的话直接在输入模式按Shift+Inset（粘贴）就可以了，下面讲一下vim 的粘贴板的基础知识，有兴趣的可以看看，应该会有所收获的。
		vim 帮助文档里与粘贴板有关的内容如下：

		    vim 有12个粘贴板，分别是0、1、2、...、9、a、“、＋；用:reg命令可以查看各个粘贴板里的内容。在vim 中简单用y只是复制 到“（双引号)粘贴板里，同样用p粘贴的也是这个粘贴板里的内容；

		    要将vim 的内容复制 到某个粘贴板，需要退出编辑模式，进入正常模式后，选择要复制 的内容，然后按"Ny（注意带引号）完成复制 ，其中N为粘贴板号(注意是按一下双引号然后按粘贴板号最后按y)，例如要把内容复制 到粘贴板a，选中内容后按"ay就可以了，有两点需要说明一下：
			“号粘贴板（临时粘贴板）比较特殊，直接按y就复制 到这个粘贴板中了，直接按p就粘贴这个粘贴板中的内容；
			+号粘贴板是系统粘贴板，用"+y将内容复制 到该粘贴板后可以使用Ctrl＋V将其粘贴到其他文档（如firefox、gedit）中，同理，要把在其他地方用Ctrl＋C或右键复制 的内容复制 到vim 中，需要在正常模式下按"+p；

		    要将vim 某个粘贴板里的内容粘贴进来，需要退出编辑模式，在正常模式按"Np，其中N为粘贴板号，如上所述，可以按"5p将5号粘贴板里的内容粘贴进来，也可以按"+p将系统全局粘贴板里的内容粘贴进来。

		注意：在我这里，只有vim.gtk或vim.gnome才能使用系统全局粘贴板，默认的vim.basic看不到+号寄存器。安装vim.gnome使用apt-get install vim-gnome，然后vim自动会链接到vim.gnome。
		（二）
		yy  複製游標所在行整行。或大寫一個 Y。
		2yy 或 y2y  複製兩行。ㄟ，請舉一反三好不好！:-)
		y^  複製至行首，或 y0。不含游標所在處字元。
		y$  複製至行尾。含游標所在處字元。
		yw  複製一個 word。
		y2w 複製兩個字。
		yG  複製至檔尾。
		y1G 複製至檔首。
		p   小寫 p 代表貼至游標後（下）。
		P   大寫 P 代表貼至游標前（上）。
		    整行的複製，按 p 或 P 時是插入式的貼在下（上）一行。非整行的複製則是貼在游標所在處之後（前）。
		"ayy  將本行文字複製到 a 緩衝區
		    a 可為 26 個英文字母中的一個，如果是小寫的話，原先的內容會被清掉，如果是大寫的話是 append 的作用，會把內容附加到原先內容之後。
		    " 是 Enter 鍵隔壁的那一個同上符號（ditto marks）。
		"ap  將 a 緩衝區的內容貼上。
		    緩衝區的術語在 vim 稱為 registers，vim 擴充了相當多的功能，有興趣深入的朋友請 :h registers。您用 d、c、s、x、y 等指令改變或刪除的內容都是放在 registers 中的。例如：您用 dd 刪除的一行，也是可以使用 p 來貼上的。只要是在緩衝區的內容都可以使用 p 來貼上，不是一定要 y 起來的內容才能用 p。因此您認為 p 是 paste 也可以，認為是 put 可能較正確。
		5"ayy  複製五行內容至 a 緩衝區。
		5"Ayy  再複製五行附在 a 內容之後，現在 a 中有十行內容了！
		    ㄟ！不要我一直用 a 您就認為只有 a 可以用喔。26 個英文字母都可以的，交叉運用下，您會發覺 vi(m) 肚量不小。
		    問題來了！忘記誰是誰的時候怎麼辦？ :reg（冒號命令）就會列出所有 registers 的代號及內容。您現在就試著按看看。咦！怎麼還有數目字、特殊符號的緩衝區，原來您剛剛刪除（複製）的內容就預設放在 " 這個緩衝區，然後依序是 0,1,2,...9。也就是說您按 p 不加什麼的話，是取出 " 緩衝區的內容的。% 指的是目前編輯的檔案，# 指的是前一次編輯的檔案。還有其它的呀！因為沒什麼重要，就請 :h registers 吧！registers 有個 "s" 結尾，不要搞錯了，而且 Tab 的補全鍵 vim 也支援的，也就是說您鍵入 :h regi 再按 Tab 鍵，vim 就會幫您補全，按了 Tab 後發現不是您要的，那就繼續按，總會出現您要的。:-)
		    Tab 補全的功能，elvis 也有，但叫出 registers 列表的命令則沒有，您得自行記憶在您的腦袋瓜子裡。而且 elvis 的補全能力並沒 vim 強。

		另外,按下v键,可以进入可视模式,这个时候可以更自由更灵活的选取要复制的段落,区块了.

* 一致性hash算法（consistent hashing） hash圆环 ，环形hash robin环 Round Robin round-robin    一致性哈希	 （这里以memcached客户端的应用为例子说明）
	- 自己的理解
		算法的好处：解决分布式系统中，比如缓存的重新发布以及缓存平衡性问题

		基础思想：
			1）对被存储Object和存储节点caches采用相同的hash算法
			2）hash算法的结果范围在，int型变量的范围内，即-2^31~2^31-1
		
		实现描述：
			1）声明一个长度为-2^31~2^31-1的有序map数据结构（eg: sortedmap-treemap）
			2）通过hash算法取到caches的hash值，在map中对应hash值的index上存入cache
				循环所有caches，加入上面map对应的index下标位置上(这里，如果要解决cache热点问题，需要定义cache虚拟节点以及虚拟节点的个数，
				循环虚拟节点数，并对cache加虚拟节点的下标字符串拼接取hash值，也存入map中对应的index下)。
			3）当需要存入某个object时，对object取hash值，c根据此hash值，从map中按自然顺序找到第一个出现的cache，若没找到则取map中的第一个cache
			4）将object存入上面找到的cache中
		
		各种情况分析：
			针对上面的一致性哈希算法，它提供了虚拟节点支持，下面分析加入新cache和删除某个已有cache的情形：
			增加一个cache：
				1）当增加一个cache时，根据hash算法取到对应的hash值，并以此hash值作为index存入map中
				2）此时在新cache的index和自然顺序位于其之前的cache的index之间的hash值所对应的object会受影响（对于原来存于之前cache的数据，可设置超时，
				或LRU算法来去除）
			去除一个cache：
				1）

	- 一篇一致性hash文章
		--------

		Consistent Hashing



		Posted by tomwhite on November 27, 2007 at 9:56 AM PST

		 I've bumped into consistent hashing a couple of times lately. The paper that introduced the idea (Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web by David Karger et al) appeared ten years ago, although recently it seems the idea has quietly been finding its way into more and more services, from Amazon's Dynamo to memcached (courtesy of Last.fm). So what is consistent hashing and why should you care?
		 
		The need for consistent hashing arose from limitations experienced while running collections of caching machines - web caches, for example. If you have a collection of n cache machines then a common way of load balancing across them is to put object o in cache machine number hash(o) mod n. This works well until you add or remove cache machines (for whatever reason), for then n changes and every object is hashed to a new location. This can be catastrophic since the originating content servers are swamped with requests from the cache machines. It's as if the cache suddenly disappeared. Which it has, in a sense. (This is why you should care - consistent hashing is needed to avoid swamping your servers!)
		 
		It would be nice if, when a cache machine was added, it took its fair share of objects from all the other cache machines. Equally, when a cache machine was removed, it would be nice if its objects were shared between the remaining machines. This is exactly what consistent hashing does - consistently maps objects to the same cache machine, as far as is possible, at least.
		 
		The basic idea behind the consistent hashing algorithm is to hash both objects and caches using the same hash function. The reason to do this is to map the cache to an interval, which will contain a number of object hashes. If the cache is removed then its interval is taken over by a cache with an adjacent interval. All the other caches remain unchanged.
		 
		Demonstration
		 
		Let's look at this in more detail. The hash function actually maps objects and caches to a number range. This should be familiar to every Java programmer - the hashCode method on Object returns an int, which lies in the range -231 to 231-1. Imagine mapping this range into a circle so the values wrap around. Here's a picture of the circle with a number of objects (1, 2, 3, 4) and caches (A, B, C) marked at the points that they hash to (based on a diagram from Web Caching with Consistent Hashing by David Karger et al):
		 


		To find which cache an object goes in, we move clockwise round the circle until we find a cache point. So in the diagram above, we see object 1 and 4 belong in cache A, object 2 belongs in cache B and object 3 belongs in cache C. Consider what happens if cache C is removed: object 3 now belongs in cache A, and all the other object mappings are unchanged. If then another cache D is added in the position marked it will take objects 3 and 4, leaving only object 1 belonging to A.
		 


		This works well, except the size of the intervals assigned to each cache is pretty hit and miss. Since it is essentially random it is possible to have a very non-uniform distribution of objects between caches. The solution to this problem is to introduce the idea of "virtual nodes", which are replicas of cache points in the circle. So whenever we add a cache we create a number of points in the circle for it.
		 
		You can see the effect of this in the following plot which I produced by simulating storing 10,000 objects in 10 caches using the code described below. On the x-axis is the number of replicas of cache points (with a logarithmic scale). When it is small, we see that the distribution of objects across caches is unbalanced, since the standard deviation as a percentage of the mean number of objects per cache (on the y-axis, also logarithmic) is high. As the number of replicas increases the distribution of objects becomes more balanced. This experiment shows that a figure of one or two hundred replicas achieves an acceptable balance (a standard deviation that is roughly between 5% and 10% of the mean).
		 


		Implementation
		 
		For completeness here is a simple implementation in Java. In order for consistent hashing to be effective it is important to have a hash function that mixes well. Most implementations of Object's hashCode do not mix well - for example, they typically produce a restricted number of small integer values - so we have a HashFunction interface to allow a custom hash function to be used. MD5 hashes are recommended here.
		 import java.util.Collection;import java.util.SortedMap;import java.util.TreeMap;public class ConsistentHash<T> { private final HashFunction hashFunction; private final int numberOfReplicas; private final SortedMap<Integer, T> circle = new TreeMap<Integer, T>(); public ConsistentHash(HashFunction hashFunction, int numberOfReplicas,     Collection<T> nodes) {   this.hashFunction = hashFunction;   this.numberOfReplicas = numberOfReplicas;   for (T node : nodes) {     add(node);   } } public void add(T node) {   for (int i = 0; i < numberOfReplicas; i++) {     circle.put(hashFunction.hash(node.toString() + i), node);   } } public void remove(T node) {   for (int i = 0; i < numberOfReplicas; i++) {     circle.remove(hashFunction.hash(node.toString() + i));   } } public T get(Object key) {   if (circle.isEmpty()) {     return null;   }   int hash = hashFunction.hash(key);   if (!circle.containsKey(hash)) {     SortedMap<Integer, T> tailMap = circle.tailMap(hash);     hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey();   }   return circle.get(hash); }} 
		The circle is represented as a sorted map of integers, which represent the hash values, to caches (of type T here).
		 When a ConsistentHash object is created each node is added to the circle map a number of times (controlled by numberOfReplicas). The location of each replica is chosen by hashing the node's name along with a numerical suffix, and the node is stored at each of these points in the map.
		 
		To find a node for an object (the get method), the hash value of the object is used to look in the map. Most of the time there will not be a node stored at this hash value (since the hash value space is typically much larger than the number of nodes, even with replicas), so the next node is found by looking for the first key in the tail map. If the tail map is empty then we wrap around the circle by getting the first key in the circle.
		 
		Usage
		 
		So how can you use consistent hashing? You are most likely to meet it in a library, rather than having to code it yourself. For example, as mentioned above, memcached, a distributed memory object caching system, now has clients that support consistent hashing. Last.fm's ketama by Richard Jones was the first, and there is now a Java implementation by Dustin Sallings (which inspired my simplified demonstration implementation above). It is interesting to note that it is only the client that needs to implement the consistent hashing algorithm - the memcached server is unchanged. Other systems that employ consistent hashing include Chord, which is a distributed hash table implementation, and Amazon's Dynamo, which is a key-value store (not available outside Amazon).
		 
		--------
		from: https://weblogs.java.net/blog/2007/11/27/consistent-hashing

		PS: 基本思想：The basic idea behind the consistent hashing algorithm is to hash both objects and caches using the same hash function.

	- 与加入/移除结点时缓存重新发布的关系
	- 一致性哈希算法最大程度的避免了key在服务节点列表上的重新分布，其他附带的改进就是有的一致性哈希算法还增加了虚拟服务节点的方法，也就是一个服务节点在环上有多个映射点，
	这样就能抑制分布不均匀，最大限度地减小服务节点增减时的缓存重新分布。
	- memcached客户端

	- http://www.cnblogs.com/liyulong1982/articles/2497731.html
	- 哈希分布与一致性哈希简介  		
			在我们的日常web应用开发当中memcached可以算作是当今的标准开发配置了。相信memcache的基本原理大家也都了解过了，memcache虽然是分布式的应用服务，
		但分布的原则是由client端的api来决定的，api根据存储用的key以及已知的服务器列表，根据key的hash计算将指定的key存储到对应的服务器列表上。
		基本的原理以及分布
			在这里我们通常使用的方法是根据 key的hash值%服务器数取余数 的方法来决定当前这个key的内容发往哪一个服务器的。这里会涉及到一个hash算法的分布问题，
		哈希的原理用一句话解释就是两个集合间的映射关系函数，在我们通常的应用中基本上可以理解为 在集合A（任意字母数字等组合，此处为存储用的key）里的一条记录
		去查找集合B（如0-2^32）中的对应记录。（题外话：md5的碰撞或者说冲突其实就是发生在这里，也就是说多个A的记录映射到了同一个B的记录）

		- 实际应用-
		显然在我们的应用中集合A的记录应该更均匀的分布在集合B的各个位置，这样才能尽量避免我们的数据被分布发送到单一的服务器上，
		在danga的memcached的原始版本（perl）中使用的是crc32的算法用java的实现写出来：
		    private static int origCompatHashingAlg( String key ) {
			int hash    = 0;
			char[] cArr = key.toCharArray();

			for ( int i = 0; i < cArr.length; ++i ) {
			    hash = (hash * 33) + cArr[i];
			}

			return hash;
		    }
		这里还有另一个改进版本的算法：
		    private static int newCompatHashingAlg( String key ) {
			CRC32 checksum = new CRC32();
			checksum.update( key.getBytes() );
			int crc = (int) checksum.getValue();

			return (crc >> 16) & 0x7fff;
		    }
		- 分布率测试 -
			有人做过测试，随机选择的key在服务器数量为5的时候所有key在服务器群组上的分布概率是：
			
			显然使用旧的crc32算法会导致第三个memcached服务的负载更高，但使用新算法会让服务之间的负载更加均衡。
			其他常用的hash算法还有FNV-1a Hash,RS Hash,JS Hash,PJW Hash,ELF Hash,AP Hash等等。有兴趣的童鞋可以查看这里：
				http://www.partow.net/programming/hashfunctions/
				http://hi.baidu.com/algorithms/blog/item/79caabee879ece2a2cf53440.html
		- 小结 -
			至此我们了解到了在我们的应用当中要做到尽量让我们的映射更加均匀分布，可以使服务的负载更加合理均衡。
		- 新问题 -
			但到目前为止我们依然面对了这样一个问题：就是服务实例本身发生变动的时候，导致服务列表变动从而会照成大量的cache数据请求会miss，
			几乎大部分数据会需要迁移到另外的服务实例上。这样在大型服务在线时，瞬时对后端数据库/硬盘照成的压力很可能导致整个服务的crash。
		- 一致性哈希（Consistent Hashing） -
			在此我们采用了一种新的方式来解决问题，处理服务器的选择不再仅仅依赖key的hash本身而是将服务实例（节点）的配置也进行hash运算。
				1) 首先求出每个服务节点的hash，并将其配置到一个0~2^32的圆环（continuum）区间上。
				2) 其次使用同样的方法求出你所需要存储的key的hash，也将其配置到这个圆环（continuum）上。
				3) 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务节点上。如果超过2^32仍然找不到服务节点，就会保存到第一个memcached服务节点上。

	from: http://www.cnblogs.com/liunx/archive/2010/03/24/1693925.html

* API 用户体验
	开发的api遵循一定的规范：（整齐划一，看着清爽）
		接口命名
		返回码规划（分段）
		错误提示格式 比如驼峰式书写
		语义描述统一
* error
	cannot find symbol —— maven test项目时报此错误，可能和eclipse编译的冲突，先清除eclipse的编译文件，再执行mvn test

* debug
	* 提奥斯
	从日志看，应用或者服务器日志；
	错误可能被应用屏蔽，没有输出，此时只能看应用的日志。

* virtual networking 虚拟网络
	
* 业务熟悉 熟悉业务
	文档
	从数据库表理解
	代码

* NIO 非阻塞操作/ 阻塞操作 消息驱动
	- SelectionKey
		DOC
		--------
		 java.nio.channels.SelectionKey


		A token representing the registration of a SelectableChannel with a Selector. 

		A selection key is created each time a channel is registered with a selector. A key remains valid until it is cancelled by invoking its cancel method, by closing its channel, or by 
		closing its selector. Cancelling a key does not immediately remove it from its selector; it is instead added to the selector's cancelled-key set for removal during the next selection operation. 
		The validity of a key may be tested by invoking its isValid method. 

		A selection key contains two operation sets represented as integer values. Each bit of an operation set denotes a category of selectable operations that are supported by the key's channel. 

		The interest set determines which operation categories will be tested for readiness the next time one of the selector's selection methods is invoked. The interest set is initialized with the value 
		given when the key is created; it may later be changed via the interestOps(int) method. 

		The ready set identifies the operation categories for which the key's channel has been detected to be ready by the key's selector. The ready set is initialized to zero when the key is created; it 
		may later be updated by the selector during a selection operation, but it cannot be updated directly. 

		That a selection key's ready set indicates that its channel is ready for some operation category is a hint, but not a guarantee, that an operation in such a category may be performed by a thread 
		without causing the thread to block. A ready set is most likely to be accurate immediately after the completion of a selection operation. It is likely to be made inaccurate by external events and 
		by I/O operations that are invoked upon the corresponding channel. 

		This class defines all known operation-set bits, but precisely which bits are supported by a given channel depends upon the type of the channel. Each subclass of SelectableChannel defines an 
		validOps() method which returns a set identifying just those operations that are supported by the channel. An attempt to set or test an operation-set bit that is not supported by a key's channel 
		will result in an appropriate run-time exception. 

		It is often necessary to associate some application-specific data with a selection key, for example an object that represents the state of a higher-level protocol and handles readiness notifications 
		in order to implement that protocol. Selection keys therefore support the attachment of a single arbitrary object to a key. An object can be attached via the attach method and then later retrieved 
		via the attachment method. 

		Selection keys are safe for use by multiple concurrent threads. The operations of reading and writing the interest set will, in general, be synchronized with certain operations of the selector. Exactly 
		how this synchronization is performed is implementation-dependent: In a naive implementation, reading or writing the interest set may block indefinitely if a selection operation is already in progress; 
		in a high-performance implementation, reading or writing the interest set may block briefly, if at all. In any case, a selection operation will always use the interest-set value that was current at the 
		moment that the operation began. 
		--------

		实现类的部分方法代码：
		sun.nio.ch.SelectorImpl
		--------
		private int lockAndDoSelect(long timeout) throws IOException {
			synchronized (this) {
				if (!isOpen())
					throw new ClosedSelectorException();
				synchronized (publicKeys) {
					synchronized (publicSelectedKeys) {
						return doSe-lect(timeout);
					}
				}
			}
		}
		--------
		同步相关的key集合对象及自身

	- SelectorProvider提供select的实现
		provider()方法说明
		DOC
		-----
		Returns the system-wide default selector provider for this invocation of the Java virtual machine. 

		The first invocation of this method locates the default provider object as follows: 

		If the system property java.nio.channels.spi.SelectorProvider is defined then it is taken to be the fully-qualified name of a concrete provider class. The class is loaded and instantiated; 
		if this process fails then an unspecified error is thrown. 

		If a provider class has been installed in a jar file that is visible to the system class loader, and that jar file contains a provider-configuration file named java.nio.channels.spi.SelectorProvider
		in the resource directory META-INF/services, then the first class name specified in that file is taken. The class is loaded and instantiated; if this process fails then an unspecified error is thrown. 

		Finally, if no provider has been specified by any of the above means then the system-default provider class is instantiated and the result is returned. 

		Subsequent invocations of this method return the provider that was returned by the first invocation. 
		-----
		PS: 若配置了provider则采用自定义的，否则采用默认
		ref: http://blog.csdn.net/pwlazy/article/details/7453429

	- Selector
		根据操作系统默认selector provider返回一个selector，或者从一个自定义的selector provider获得
		nio实现所基于操作系统底层的支持方式 ref: 	   http://blog.csdn.net/pwlazy/article/details/7453429 谈谈java selector的机制

		DOC
		-----
		A multiplexor of SelectableChannel objects. 

		A selector may be created by invoking the open method of this class, which will use the system's default selector provider to create a new selector. A selector may also be 
		created by invoking the openSelector method of a custom selector provider. A selector remains open until it is closed via its close method. 

		A selectable channel's registration with a selector is represented by a SelectionKey object. A selector maintains three sets of selection keys: 

		The key set contains the keys representing the current channel registrations of this selector. This set is returned by the keys method. 

		The selected-key set is the set of keys such that each key's channel was detected to be ready for at least one of the operations identified in the key's interest set during a prior 
		selection operation. This set is returned by the selectedKeys method. The selected-key set is always a subset of the key set. 

		The cancelled-key set is the set of keys that have been cancelled but whose channels have not yet been deregistered. This set is not directly accessible. The cancelled-key set 
		is always a subset of the key set. 

		All three sets are empty in a newly-created selector. 

		A key is added to a selector's key set as a side effect of registering a channel via the channel's register method. Cancelled keys are removed from the key set during selection operations. 
		The key set itself is not directly modifiable. 

		A key is added to its selector's cancelled-key set when it is cancelled, whether by closing its channel or by invoking its cancel method. Cancelling a key will cause its channel to be 
		deregistered during the next selection operation, at which time the key will removed from all of the selector's key sets. 

		Keys are added to the selected-key set by selection operations. A key may be removed directly from the selected-key set by invoking the set's remove method or by invoking the 
		remove method of an iterator obtained from the set. Keys are never removed from the selected-key set in any other way; they are not, in particular, removed as a side effect of selection 
		operations. Keys may not be added directly to the selected-key set. 

		Selection
		During each selection operation, keys may be added to and removed from a selector's selected-key set and may be removed from its key and cancelled-key sets. Selection is performed 
		by the select(), select(long), and selectNow() methods, and involves three steps: 

		Each key in the cancelled-key set is removed from each key set of which it is a member, and its channel is deregistered. This step leaves the cancelled-key set empty. 

		The underlying operating system is queried for an update as to the readiness of each remaining channel to perform any of the operations identified by its key's interest set as of the moment 
		that the selection operation began. For a channel that is ready for at least one such operation, one of the following two actions is performed: 

		If the channel's key is not already in the selected-key set then it is added to that set and its ready-operation set is modified to identify exactly those operations for which the channel is now 
		reported to be ready. Any readiness information previously recorded in the ready set is discarded. 

		Otherwise the channel's key is already in the selected-key set, so its ready-operation set is modified to identify any new operations for which the channel is reported to be ready. Any readiness 
		information previously recorded in the ready set is preserved; in other words, the ready set returned by the underlying system is bitwise-disjoined into the key's current ready set. 

		If all of the keys in the key set at the start of this step have empty interest sets then neither the selected-key set nor any of the keys' ready-operation sets will be updated. 
		If any keys were added to the cancelled-key set while step (2) was in progress then they are processed as in step (1). 

		Whether or not a selection operation blocks to wait for one or more channels to become ready, and if so for how long, is the only essential difference between the three selection methods. 

		Concurrency
		Selectors are themselves safe for use by multiple concurrent threads; their key sets, however, are not. 

		The selection operations synchronize on the selector itself, on the key set, and on the selected-key set, in that order. They also synchronize on the cancelled-key set during steps (1) and (3) above. 

		Changes made to the interest sets of a selector's keys while a selection operation is in progress have no effect upon that operation; they will be seen by the next selection operation. 

		Keys may be cancelled and channels may be closed at any time. Hence the presence of a key in one or more of a selector's key sets does not imply that the key is valid or that its channel is open. 
		Application code should be careful to synchronize and check these conditions as necessary if there is any possibility that another thread will cancel a key or close a channel. 

		A thread blocked in one of the select() or select(long) methods may be interrupted by some other thread in one of three ways: 

		By invoking the selector's wakeup method, 

		By invoking the selector's close method, or 

		By invoking the blocked thread's interrupt method, in which case its interrupt status will be set and the selector's wakeup method will be invoked. 

		The close method synchronizes on the selector and all three key sets in the same order as in a selection operation. 

		A selector's key and selected-key sets are not, in general, safe for use by multiple concurrent threads. If such a thread might modify one of these sets directly then access should be controlled by 
		synchronizing on the set itself. The iterators returned by these sets' iterator methods are fail-fast: If the set is modified after the iterator is created, in any way except by invoking the iterator's own 
		remove method, then a java.util.ConcurrentModificationException will be thrown. 
		-----

		Selector的select方法：
			DOC
			----
			Selects a set of keys whose corresponding channels are ready for I/O operations. 

			This method performs a blocking selection operation. It returns only after at least one channel is selected, this selector's wakeup method is invoked, or the current thread is interrupted, whichever comes first. 

			Returns:
			The number of keys, possibly zero, whose ready-operation sets were updated
			----
			select方法会blocking，直到有一个通道感兴趣的事件被触发

	- 缓冲区介绍 bytebuffer,intbuffer etc
		所有的缓冲区都具有四个属性来提供关于其所包含的数据元素的信息。它们是：
		容量（Capacity）
			缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。
		上界（Limit）
			缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。
		位置（Position）
			下一个要被读或写的元素的索引。位置会自动由相应的 get( )和 put( )方法更新。
		标记（Mark）
			一个备忘位置。调用 mark( )来设定 mark = postion。调用 reset( )设定 position = mark。标记在设定前是未定义的(undefined)。
		这四个属性之间总是遵循以下关系：
			0 <= mark <= position <= limit <= capacity

		ByteBuffer	Direct vs. non-direct buffers
			DOC
			------
			A byte buffer. 

			This class defines six categories of operations upon byte buffers: 
				Absolute and relative get and put methods that read and write single bytes; 
				Relative bulk get methods that transfer contiguous sequences of bytes from this buffer into an array; 						
				Relative bulk put methods that transfer contiguous sequences of bytes from a byte array or some other byte buffer into this buffer; 
				Absolute and relative get and put methods that read and write values of other primitive types, translating them to and from sequences of bytes in a particular byte order; 
				Methods for creating view buffers, which allow a byte buffer to be viewed as a buffer containing values of some other primitive type; and 
				Methods for compacting, duplicating, and slicing a byte buffer. 

			Byte buffers can be created either by allocation, which allocates space for the buffer's content, or by wrapping an existing byte array into a buffer. 

			Direct vs. non-direct buffers 
			A byte buffer is either direct or non-direct. Given a direct byte buffer, the Java virtual machine will make a best effort to perform native I/O operations directly upon it. 
			That is, it will attempt to avoid copying the buffer's content to (or from) an intermediate buffer before (or after) each invocation of one of the underlying operating system's native I/O operations. 

			A direct byte buffer may be created by invoking the allocateDirect factory method of this class. The buffers returned by this method typically have somewhat higher allocation 
			and deallocation costs than non-direct buffers. The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory 
			footprint of an application might not be obvious. It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying 
			system's native I/O operations. In general it is best to allocate direct buffers only when they yield a measureable gain in program performance. 

			A direct byte buffer may also be created by mapping a region of a file directly into memory. An implementation of the Java platform may optionally support the creation of direct 
			byte buffers from native code via JNI. If an instance of one of these kinds of buffers refers to an inaccessible region of memory then an attempt to access that region will not change
			the buffer's content and will cause an unspecified exception to be thrown either at the time of the access or at some later time. 

			Whether a byte buffer is direct or non-direct may be determined by invoking its isDirect method. This method is provided so that explicit buffer management can be done in 
			performance-critical code. 

			Access to binary data 
			This class defines methods for reading and writing values of all other primitive types, except boolean. Primitive values are translated to (or from) sequences of bytes according to the 
			buffer's current byte order, which may be retrieved and modified via the order methods. Specific byte orders are represented by instances of the ByteOrder class. The initial order of 
			a byte buffer is always BIG_ENDIAN. 

			For access to heterogeneous binary data, that is, sequences of values of different types, this class defines a family of absolute and relative get and put methods for each type. For 32-bit 
			floating-point values, for example, this class defines: 

			 float  getFloat()
			 float  getFloat(int index)
			  void  putFloat(float f)
			  void  putFloat(int index, float f)
			Corresponding methods are defined for the types char, short, int, long, and double. The index parameters of the absolute get and put methods are in terms of bytes rather than of the type
			being read or written. 

			For access to homogeneous binary data, that is, sequences of values of the same type, this class defines methods that can create views of a given byte buffer. A view buffer is simply another 
			buffer whose content is backed by the byte buffer. Changes to the byte buffer's content will be visible in the view buffer, and vice versa; the two buffers' position, limit, and mark values are 
			independent. The asFloatBuffer method, for example, creates an instance of the FloatBuffer class that is backed by the byte buffer upon which the method is invoked. Corresponding 
			view-creation methods are defined for the types char, short, int, long, and double. 

			View buffers have three important advantages over the families of type-specific get and put methods described above: 

			A view buffer is indexed not in terms of bytes but rather in terms of the type-specific size of its values; 

			A view buffer provides relative bulk get and put methods that can transfer contiguous sequences of values between a buffer and an array or some other buffer of the same type; and 

			A view buffer is potentially much more efficient because it will be direct if, and only if, its backing byte buffer is direct. 

			The byte order of a view buffer is fixed to be that of its byte buffer at the time that the view is created. 

			Invocation chaining 
			Methods in this class that do not otherwise have a value to return are specified to return the buffer upon which they are invoked. This allows method invocations to be chained. 
			The sequence of statements 

			 bb.putInt(0xCAFEBABE);
			 bb.putShort(3);
			 bb.putShort(45);
			can, for example, be replaced by the single statement 
			 bb.putInt(0xCAFEBABE).putShort(3).putShort(45);
			------

		flip
			DOC
			----
			Flips this buffer. The limit is set to the current position and then the position is set to zero. If the mark is defined then it is discarded. 

			After a sequence of channel-read or put operations, invoke this method to prepare for a sequence of channel-write or relative get operations. For example: 

			 buf.put(magic);    // Prepend header
			 in.read(buf);      // Read data into rest of buffer
			 buf.flip();        // Flip buffer
			 out.write(buf);    // Write header + data to channel
			This method is often used in conjunction with the compact method when transferring data from one place to another. 
			----

			翻转
				我们已经写满了缓冲区，现在我们必须准备将其清空。我们想把这个缓冲区传递给一个通
			道，以使内容能被全部写出。但如果通道现在在缓冲区上执行 get()，那么它将从我们刚刚
			插入的有用数据之外取出未定义数据。如果我们将位置值重新设为 0，通道就会从正确位置开
			始获取，但是它是怎样知道何时到达我们所插入数据末端的呢？这就是上界属性被引入的目
			的。上界属性指明了缓冲区有效内容的末端。我们需要将上界属性设置为当前位置，然后将位
			置重置为 0。我们可以人工用下面的代码实现：
				buffer.limit(buffer.position()).position(0);
				但这种从填充到释放状态的缓冲区翻转是 API 设计者预先设计好的，他们为我们提供了
			一个非常便利的方法：
				Buffer.flip();
				Flip()方法将一个能够继续添加数据元素的填充状态的缓冲区翻转成一个准备读出元素
			的释放状态

			一旦缓冲区对象完成填充并释放，它就可以被重新使用了。Clear()方法将缓冲区重置
			为空状态。它并不改变缓冲区中的任何数据元素，而是仅仅将上界设为容量的值，并把位置设
			回 0。这使得缓冲区可以被重新填入。

	- 流I/O，异步IO
		流的传输一般（也不必然如此）比块设备慢，经常用于间歇性输入。多数操作系统允许把流置于非阻塞模式，这样，
		进程可以查看流上是否有输入，即便当时没有也不影响它干别的。这样一种能力使得进程可以在有输入的时候进行处理，
		输入流闲置的时候执行其他功能。比非阻塞模式再进一步，就是就绪性选择。就绪性选择与非阻塞模式类似（常常就是建立在非阻塞模式之上），
		但是把查看流是否就绪的任务交给了操作系统。操作系统受命查看一系列流，并提醒进程哪些流已经就绪。这样，仅仅凭借操作系统返回的就绪信息，
		进程就可以使用相同代码和单一线程，实现多活动流的多路传输。这一技术广泛用于网络服务器领域，用来处理数量庞大的网络连接。就绪性选择
		在大容量缩放方面是必不可少的。
		from: java nio,Ron Hitchens     19&24
	- NIO包
		CLASS
		--------
		ServerSocketChannel
			DOC comment
			----------------
			A selectable channel for stream-oriented listening sockets. 

			Server-socket channels are not a complete abstraction of listening network sockets. Binding and the manipulation of socket options must be done through an associated java.net.ServerSocket 
			object obtained by invoking the socket method. It is not possible to create a channel for an arbitrary, pre-existing server socket, nor is it possible to specify the java.net.SocketImpl object to be 
			used by a server socket associated with a server-socket channel. 

			A server-socket channel is created by invoking the open method of this class. A newly-created server-socket channel is open but not yet bound. An attempt to invoke the accept method of an 
			unbound server-socket channel will cause a NotYetBoundException to be thrown. A server-socket channel can be bound by invoking one of the bind methods of an associated server socket. 

			Server-socket channels are safe for use by multiple concurrent threads. 
				
				METHOD
				-----------
					open
						DOC comment
						----------------
						Opens a server-socket channel. 

						The new channel is created by invoking the openServerSocketChannel method of the system-wide default java.nio.channels.spi.SelectorProvider object. 

						The new channel's socket is initially unbound; it must be bound to a specific address via one of its socket's bind methods before connections can be accepted. 

					socket (通过此方法获取一个ServerSocket对象，并与此channel绑定)
						DOC comment
						----------------
						Retrieves a server socket associated with this channel. 

						The returned object will not declare any public methods that are not declared in the java.net.ServerSocket class. 

						Returns:
						A server socket associated with this channel

					accept
						DOC comment
						----------------
						Accepts a connection made to this channel's socket. 

						If this channel is in non-blocking mode then this method will immediately return null if there are no pending connections. Otherwise it will block indefinitely until a new connection is 
						available or an I/O error occurs. 

						The socket channel returned by this method, if any, will be in blocking mode regardless of the blocking mode of this channel. 

						This method performs exactly the same security checks as the accept method of the java.net.ServerSocket class. That is, if a security manager has been installed then for each new 
						connection this method verifies that the address and port number of the connection's remote endpoint are permitted by the security manager's checkAccept method. 

						Returns:
						The socket channel for the new connection, or null if this channel is in non-blocking mode and no connection is available to be accepted




			
		SocketChannel
		DOC
		--------
		A selectable channel for stream-oriented connecting sockets. 

		Socket channels are not a complete abstraction of connecting network sockets. Binding, shutdown, and the manipulation of socket options must be done through an associated java.net.Socket object obtained by invoking the socket method. It is not possible to create a channel for an arbitrary, pre-existing socket, nor is it possible to specify the java.net.SocketImpl object to be used by a socket associated with a socket channel. 

		A socket channel is created by invoking one of the open methods of this class. A newly-created socket channel is open but not yet connected. An attempt to invoke an I/O operation upon an unconnected channel will cause a NotYetConnectedException to be thrown. A socket channel can be connected by invoking its connect method; once connected, a socket channel remains connected until it is closed. Whether or not a socket channel is connected may be determined by invoking its isConnected method. 

		Socket channels support non-blocking connection: A socket channel may be created and the process of establishing the link to the remote socket may be initiated via the connect method for later completion by the finishConnect method. Whether or not a connection operation is in progress may be determined by invoking the isConnectionPending method. 

		The input and output sides of a socket channel may independently be shut down without actually closing the channel. Shutting down the input side of a channel by invoking the shutdownInput method of an associated socket object will cause further reads on the channel to return -1, the end-of-stream indication. Shutting down the output side of the channel by invoking the shutdownOutput method of an associated socket object will cause further writes on the channel to throw a ClosedChannelException. 

		Socket channels support asynchronous shutdown, which is similar to the asynchronous close operation specified in the Channel class. If the input side of a socket is shut down by one thread while another thread is blocked in a read operation on the socket's channel, then the read operation in the blocked thread will complete without reading any bytes and will return -1. If the output side of a socket is shut down by one thread while another thread is blocked in a write operation on the socket's channel, then the blocked thread will receive an AsynchronousCloseException. 

		Socket channels are safe for use by multiple concurrent threads. They support concurrent reading and writing, though at most one thread may be reading and at most one thread may be writing at any given time. The connect and finishConnect methods are mutually synchronized against each other, and an attempt to initiate a read or write operation while an invocation of one of these methods is in progress will block until that invocation is complete. 

		Since:
		1.4

		--------
	
	To be contiue...

	- NIO深入
		NIO通常采用Reactor模式，AIO通常采用Proactor模式。AIO简化了程序的编写，stream的读取和写入都有OS来完成，不需 要像NIO那样子遍历Selector。
		Windows基于IOCP实现AIO，Linux只有eppoll模拟实现了AIO。
	
		Java7之前的JDK只支持NIO和BIO，从7开始支持AIO。
		你说的IO应该指BIO，这种模式需要阻塞线程，一个IO需要一个线程，NIO由一个thread来监听connect事件，另外多个thread来监听读写事件，带来性能上很大提高。
	- java1.4加入的NIO
	- 
		JAVA使用EPoll来进行NIO处理的方法
		JDK 6.0 以及JDK 5.0 update 9 的 nio支持epoll （仅限 Linux 系统 ），对并发idle connection会有大幅度的性能提升，这就是很多网络服务器应用程序需要的。

		启用的方法如下：
		-Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.EPollSelectorProvider

		例如在 Linux 下运行的 Tomcat 使用 NIO Connector ，那么启用 epoll 对性能的提升会有帮助。

		而 Tomcat 要启用这个选项的做法是在 catalina.sh 的开头加入下面这一行
		CATALINA_OPTS='-Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.EPollSelectorProvider' 
		PS: linux环境下默认select用epoll的实现，selector provider=sun.nio.ch.EPollSelectorProvider

	- 5种IO模式 epoll	* epoll	select/poll(多路复用IO接口) IO模型
		epoll 是Linux内核为处理大批量句柄而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著减少程序在大量并发连接中只有
		少量活跃的情况下的系统CPU利用率。

		简介

		使用epoll进行高性能网络编程
		epoll是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集合
		来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，
		只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。epoll除了提供select/poll那种IO事件的电平触发（Level Triggered）外，还提供了边沿触发
		（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。
	
		优点

		支持一个进程打开大数目的socket描述符
		select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是1024。对于那些需要支持的上万连接数目的IM服务器来说显然太少了。
		这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案（传统的Apache方案），不过
		虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。不过 epoll则没有这个限制，
		它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子，在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看，一般来说
		这个数目和系统内存关系很大。
		IO效率不随FD数目增加而线性下降
		传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是“活跃”的，但是select/poll每次调用都会线性扫描全部的集合，
		导致效率呈现线性下降。但是epoll不存在这个问题，它只会对“活跃”的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有“活跃”的
		socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个“伪”AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上
		都是活跃的---比如一个高速LAN环境，epoll并不比select/poll有什么效率，相反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境，epoll
		的效率就远在select/poll之上了。

		使用mmap加速内核与用户空间的消息传递

		这点实际上涉及到epoll的具体实现了。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，
		epoll是通过内核于用户空间mmap同一块内存实现的。而如果你像我一样从2.5内核就关注epoll的话，一定不会忘记手工 mmap这一步的。

		from: http://baike.baidu.com/view/1385104.htm

		epoll的实现：
			epoll的实现代码在 fs/EventPoll.c下，
			由于epoll涉及到几个系统调用，这里不逐个分析了，仅仅分析几个关键点，
			第一个关键点在
			static int ep_insert(struct eventpoll *ep, struct epoll_event *event,
				     struct file *tfile, int fd) 
			这是在我们调用sys_epoll_ctl 添加一个被管理socket的时候调用的函数，关键的几行如下：
			epq.epi = epi;
			    init_poll_funcptr(&epq.pt, ep_ptable_queue_proc);

			    /*
			     * Attach the item to the poll hooks and get current event bits.
			     * We can safely use the file* here because its usage count has
			     * been increased by the caller of this function. Note that after
			     * this operation completes, the poll callback can start hitting
			     * the new item.
			     */
			    revents = tfile->f_op->poll(tfile, &epq.pt); 
			这里也是调用文件系统的poll函数，不过这次初始化了一个结构，这个结构会带有一个poll函数的callback函数：ep_ptable_queue_proc，
			在调用poll函数的时候，会执行这个callback，这个callback的功能就是将当前进程添加到 socket的等待进程上。
			static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead,
					 poll_table *pt)
			{
			    struct epitem *epi = ep_item_from_epqueue(pt);
			    struct eppoll_entry *pwq;

			    if (epi->nwait >= 0 && (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) {
				init_waitqueue_func_entry(&pwq->wait, ep_poll_callback);
				pwq->whead = whead;
				pwq->base = epi;
				add_wait_queue(whead, &pwq->wait);
				list_add_tail(&pwq->llink, &epi->pwqlist);
				epi->nwait++;
			    } else {
				/* We have to signal that an error occurred */
				epi->nwait = -1;
			    }
			}  
			注意到参数 whead 实际上是 sk->sleep，其实就是将当前进程添加到sk的等待队列里，当该socket收到数据或者其他事件触发时，会调用
			sock_def_readable 或者sock_def_write_space 通知函数来唤醒等待进程，这2个函数都是在socket创建的时候填充在sk结构里的。
			从前面的分析来看，epoll确实是比select聪明的多、轻松的多，不用再苦哈哈的去轮询了。
			from: http://www.cnblogs.com/xuxm2007/archive/2011/08/15/2139809.html

	- 输入和输出都经过Buffer层，数据以块的方式处理（区别老IO以字节流的方式处理）利用操作系统的IO特性（如linux的epoll，mmap减少内存拷贝）

	-
	上图就是这个项目的总体结构图，从图中可以看出该程序分为这几大块：连接侦听线程、连接对象队列、发送线程池、接收线程池、分发线程、
	事件处理对象、监控处理对象。下面我将描述下整个连接处理过程：
	1、 连接侦听线程循环接收一个连接请求，如果有连接请求过来，则返回一个连接Socket对象，否则该线程就阻塞等待，直到有一个连接请求过来。
	2、 封装该返回的Socket对象（主要是封装获取完整包数据，发送方法，关闭方法等）成Connection对象，并把封装好的Connection对象放入连接对象队列。
	3、 分发线程不停的轮询连接对象队列，如果发现有可接收数据的连接对象，则扔给接收线程池去处理；如果发现有可发送数据的连接对象，则扔给发送线程池
	去处理。如果轮询一圈发现既没有可发送数据的连接对象也没有可接收数据的连接对象，则该线程会休眠一段时间，休眠过后又接着循环。
	4、 发送线程池内有一个连接对象队列，从队列中取出一个连接对象并发送数据，且记录连接状态信息。
	5、 接收线程池内也有一个连接对象队列，从队列中取出一个连接对象并接收一个数据包，且记录连接状态信息。如果接收的数据包是心跳检测包则更新连接状态，
	如果是数据包则通过事件处理对象发送给probe系统。
	    从上面的过程来看，我们可能看不出设计上面的漏洞，但有几个地方确实非常影响效率，在这里我想先提出来：
	1、 连接侦听线程一直在侦听，有连接请求过来则会返回，没有则会阻塞；这样这个线程就会一直挂着；如果时时刻刻都有很多的连接过来，这个线程还会充分发挥
	它的作用，但其实大部分时候，连接请求并没有这么频繁，所以这个线程大部分时间是阻塞的；这样为了这样一个功能单独利用一个线程就有点浪费了。
	2、 分发线程不停的轮询过程是导致整个系统效率低下最严重的一块，分发线程不停的轮询连接对象队列，其实分发线程并不知道哪个线程需要发送数据，哪些线程
	需要接收数据，而他只是盲目地从队列的头遍历到队列的尾部，如果发现没有可操作的连接对象则休眠一段时间；其实在大部分情况下，连接对象并不是时时刻刻
	都有数据发送和接收，所以这个分发线程大部分时间空循环，白忙了；并且这个休眠时间也不好控制，如果时间长了，则程序的即时性不够，如果太短了，程序似乎
	就是在空跑了。
	3、 在连接对象上发送和接收数据包的时候，这些方法都是阻塞操作的；所以当有大量的数据可接收和发送的时候，这种阻塞的操作时非常浪费资源的。
	    以上所提出的问题，如果是在并发规模比较小的情况下，是没有什么问题；但确实有很大的改进空间。上面的问题归结起来主要是两个：
	1、 当有连接请求过来或者有Socket连接有数据可读可写的时候，我们不会立即知道，我们必须要一个一个的轮询，我们能否有一种机制，即是，当有连接请求过来或者
	连接有数据可读或者可写的时候，直接通知我们来处理，而不需要我们主动轮询。
	2、 当读数据或者写数据的时候，所有的方法都阻塞了，能不能有一种办法当我们写数据或者接收数据的时候不用阻塞，而是直接返回，这样就明显提高了线程的使用率了。
	    值得我们庆幸的是，在Java的JDK1.4之后的版本，提供了NIO包，这里提出了事件驱动的I/O编程模式和非阻塞信道的概念，NIO里面的Selector对象解决了上面提出分发
	    和轮询的问题，Channel接口解决了阻塞读写的问题。我相信这些组件能够帮我们解决上面所提出的所有问题。所以下面有很大一部分篇幅来介绍NIO的使用和一些底层的机制。
	from: http://www.cnblogs.com/cpcpc/archive/2011/09/05/2167931.html

* visio
	- 输出图片格式
		
	- 提供多种图的绘制支持，比如uml，需要安装模板。
	- 序列图，可以用横版画图；宽度还不够的话，可以将名称换行(选中文本工具，即可编辑一些形状的名称)
	- 有些地方不可编辑，可能是保护原因，在形状上右键格式的保护力设置
	- 取消保护后，可以根据文本是文本或者文本块（选中某中文本按钮移上去后会以图表方式提示鼠标位置是文本还是文本块），
	  选中相应按钮，来调整形状的文字说明
	- 修改图层次序，在形状上右键的格式中设置
	- 对于名称，不能直接用文本按钮来设置，还是需要在名称属性里填上值，然后通过文本工具来设置文本格式，否则可能名称为空。
* redmine * 项目管理系统
	- redmine
		Redmine是用Ruby开发的基于web的项目管理软件，是用ROR框架开发的一套跨平台项目管理系统，据说是源于Basecamp的ror版而来，
		支持多种数据库，有不少自己独特的功能，例如提供wiki、新闻台等，还可以集成其他版本管理系统和BUG跟踪系统，例如SVN、CVS、TD等等。
		这种 Web 形式的项目管理系统通过“项目（Project）”的形式把成员、任务（问题）、文档、讨论以及各种形式的资源组织在一起，大家参与更新任务、
		文档等内容来推动项目的进度，同时系统利用时间线索和各种动态的报表形式来自动给成员汇报项目进度。

* 测试环境
	单台linux物理机 > xen虚拟多个vm (vm的lxc下多个app,eg:jetty)> 疏通vm网络 > 在vm上部署haproxy+keepalived以及web应用实现软负载均衡 > ...
	/etc/sysconfig/network-scripts/ifcfg-eth0
	/etc/sysconfig/network
	/etc/hosts
	域名服务器配置文件：/etc/resolv.conf
	
	 -------------------------
	 slbapi测试环境：
		mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
		http://10.230.204.24/slb/api?
 * JSR 303 Bean Validation
		“This JSR defines a metadata model and API for JavaBean validation. The default metadata source is annotations,
	with the ability to override and extend the meta-data through the use of XML validation descriptors.
	The validation API developed by this JSR is not intended for use in any one tier or programming model. It is specifically
	not tied to either the web tier or the persistence tier, and is available for both server-side application programming,
	as well as rich client Swing application developers.” – JSR-303 Specification
 * spring
	- spring文件上传处理
		从struts提供的ServletActionContext中获取request对象，从而获取上传的文件，然后用spring的文件类处理
		-----
		MultiPartRequestWrapper mpRequest = (MultiPartRequestWrapper) ServletActionContext.getRequest();
			File[] files = mpRequest.getFiles("ncInfo");
			if (files != null && files.length == 1) {
			    InputStream input = null;
			    try {
				input = new FileInputStream(files[0]);
			    } catch (FileNotFoundException e) {
				logger.error("read uploaded file error", e);
				throw new WebException(ExceptionConstants.FAILED_TO_OPEN_UPLOADED_FILE);
			    }
			    List<ApiIso> apiIsoList = ExcelUtil.readExcel(input, new IsoReadExcelHandler());
		-----
		PS: MultiPartRequestWrapper

		-----
		public static <T> List<T> readExcel(InputStream input,
					ReadExcelRowHandler<T> rowHandler) {
				// 参数检查
				if (input == null) {
					throw new RuntimeException("The InputStream is null");
				}
				if (rowHandler == null) {
					throw new RuntimeException("The ReadExcelRowHandler is null");
				}

				// 读取Excel
				Workbook workbook = null;
				try {
					try {
						workbook = Workbook.getWorkbook(input);
					} catch (Exception e) {
						throw new RuntimeException(
								"getWorkbook from inputStream error.", e);
					}
					Sheet sheet = workbook.getSheet(0);
					int rows = sheet.getRows();

					List<T> result = new ArrayList<T>(rows);
					// 第一行是标题
					if (rows <= 1) {
						return result;
					}
					// 标题列数
					int headingLength = sheet.getRow(0).length;

					// 循环解析每行数据,忽略第一行
					for (int i = 1; i < rows; i++) {
						Cell[] cells = sheet.getRow(i);
						if (cells.length > 0) {
							// 取出当前行每个单元格的值
							List<String> cellValueList = new ArrayList<String>(
									headingLength);
							boolean allBlank = true;
							// 循环获取当前行的每个单元格的值
							for (Cell cell : cells) {
								String value = cell.getContents();
								if (StringUtils.isNotBlank(value)) {
									value = value.trim();
									allBlank = false;
								}
								cellValueList.add(value.trim());
							}
							// 如果当前行的每个单元格都是空的，那么忽略当前行
							if (allBlank) {
								continue;
							}
							// 回调接口处理每行数据的转换
							T object = rowHandler.readRow(cellValueList, i,
									headingLength);
							if (object != null) {
								result.add(object);
							}
						}
					}
					return result;
				} finally {
					// 关闭资源
					if (workbook != null) {
						workbook.close();
					}
					try {
						input.close();
					} catch (IOException e) {
						throw new RuntimeException("close inputStream error.", e);
					}
				}
			}
		-----
		PS: 处理逻辑，通过回调函数来做具体转换，不同excel文件；实现行处理的回调函数即可

		-----
		public class IsoReadExcelHandler implements ReadExcelRowHandler<ApiIso> {
		    private final static Logger logger = Logger.getLogger(IsoReadExcelHandler.class);
		    private static final int CELLS_LENGTH = 8;

		    @Override
		    public ApiIso readRow(List<String> cellValueList, int row, int headingLength) {
			if (cellValueList == null || cellValueList.isEmpty()) {
			    return null;
			}

		-----
		PS: 回调接口，用以处理具体的转换逻辑


	- 代码中获取属性配置
	重写spring提供类的processProperties方法，spring处理属性文件的类设计
	-----
	<bean id="propertyConfigurer"
		class="com.tjsoft.base.util.CustomizedPropertyPlaceholderConfigurer">
		<property name="ignoreResourceNotFound" value="true" />
		<property name="locations">
			<list>
				<value>/WEB-INF/config/jdbc.properties</value>
				<value>/WEB-INF/config/mail.properties</value>
				<value>/WEB-INF/config/system.properties</value>
			</list>
		</property>
	</bean>
	-----
	-----
	import java.util.HashMap;
	import java.util.Map;
	import java.util.Properties;

	import org.springframework.beans.BeansException;
	import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;
	import org.springframework.beans.factory.config.PropertyPlaceholderConfigurer;

	/**
	 * 自定义PropertyPlaceholderConfigurer返回properties内容
	 * 
	 * @author LHY 2012-02-24
	 * 
	 */
	public class CustomizedPropertyPlaceholderConfigurer extends
			PropertyPlaceholderConfigurer {

		private static Map<String, Object> ctxPropertiesMap;

		@Override
		protected void processProperties(
				ConfigurableListableBeanFactory beanFactoryToProcess,
				Properties props) throws BeansException {
			super.processProperties(beanFactoryToProcess, props);
			ctxPropertiesMap = new HashMap<String, Object>();
			for (Object key : props.keySet()) {
				String keyStr = key.toString();
				String value = props.getProperty(keyStr);
				ctxPropertiesMap.put(keyStr, value);
			}
		}

		public static Object getContextProperty(String name) {
			return ctxPropertiesMap.get(name);
		}

	}
	-----
	from: http://blog.csdn.net/lhy030320999/article/details/7683243
	PS: 不仅从配置注入，编程时获取属性配置，获取属性文件
		重写spring的org.springframework.beans.factory.config.PropertyPlaceholderConfigurer，自


	- 自动注解注入配置
		 <context:component-scan base-package="com.aliyun.luorigong"/>
		 会扫描cllasspath下所有注解了component等注解的类，并自己注册到spring容器中

	- spring工厂方法配置
		-----
		<!--工厂类bean-->
		<bean id="carFactory" class="com.coder.bo.CarFactory" />
		<!--factory-bean指定工厂类Bean，factory-method指定工厂类Bean创建Bean的工厂方法-->
		<bean id="car" factory-bean="carFactory" factory-method="createQiRuiCar" />

		...

		<!--class直接指定工厂类Bean，factory-method指定工厂类Bean创建Bean的工厂方法-->
		<bean id="car" class="com.coder.bo.CarFactory" factory-method="createQiRuiCar" />
		-----
	- spring MVC		 * spring mvc JSR 303: Bean Validation
		1) 支持注解方式的参数处理，类似REST方式service的实现也提供了参数解析辅助注解
		2) 请求的uri带格式后缀时，比如/xxx/list.json，作用于视图解析部分，根据后缀返回对应的view
			org.springframework.web.servlet.view.ContentNegotiatingViewResolver
			DOC
			-----
			Implementation of ViewResolver that resolves a view based on the request file name or Accept 
			 header. 
			The ContentNegotiatingViewResolver does not resolve views itself, but delegates to other 
			 ViewResolvers. By default, these other view resolvers are picked up automatically from the application 
			 context, though they can also be set explicitly by using the viewResolvers property. <strong>Note</
			 strong> that in order for this view resolver to work properly, the order property needs to be set to a 
			 higher precedence than the others (the default is Ordered.HIGHEST_PRECEDENCE.) 
			This view resolver uses the requested media type to select a suitable View for a request. This media 
			 type is determined by using the following criteria: <ol> 
				- If the requested path has a file extension and if the setFavorPathExtension property is true, 
				 the mediaTypes property is inspected for a matching media type. 
				- If the request contains a parameter defining the extension and if the setFavorParameter 
				 property is true, the mediaTypes property is inspected for a matching media type. The default name 
				 of the parameter is format and it can be configured using the parameterName property. 
				- If there is no match in the mediaTypes property and if the Java Activation Framework (JAF) 
				 is both enabled and present on the classpath, FileTypeMap.getContentType(String) is used instead. 
				- If the previous steps did not result in a media type, and ignoreAcceptHeader is false, the 
				 request Accept header is used. </ol> 
			Once the requested media type has been determined, this resolver queries each delegate view 
			 resolver for a View and determines if the requested media type is compatible with the view's content 
			 type). The most compatible view is returned. 
			Additionally, this view resolver exposes the defaultViews property, allowing you to override the views 
			 provided by the view resolvers. Note that these default views are offered as candicates, and still need 
			 have the content type requested (via file extension, parameter, or Accept header, described above). 
			 You can also set the default content type directly, which will be returned when the other mechanisms 
			 (Accept header, file extension or parameter) do not result in a match. 
			For example, if the request path is /view.html, this view resolver will look for a view that has the text/
			 html content type (based on the html file extension). A request for /view with a text/html request 
			 Accept header has the same result. 
			-----

			spring配置
			-----
			<bean class="org.springframework.web.servlet.view.ContentNegotiatingViewResolver">
				<property name="mediaTypes">
					<map>
						<entry key="json" value="application/json" />
					</map>
				</property>
				<property name="defaultViews">
					<list>
						<bean
							class="org.springframework.web.servlet.view.json.MappingJacksonJsonView">
						</bean>
					</list>
				</property>
			</bean>			
			-----
			PS: 配置了请求扩展名为.json时，返回内容类型为application/json格式

			Spring MVC对响应的格式的封装，比如对于xml的返回，可以采用不同的xml转换组件，由org.springframework.oxm.Marshaller来抽象。
			DOC
			-----
			Defines the contract for Object XML Mapping Marshallers. Implementations of this interface can serialize a given Object to an XML Stream. 
			-----

	- 加入spring支持
		pom配置spring依赖包
		创建application
		若为web项目，在web.xml中配置spring 的listener用于启动时初始化spring容器
			<listener>
				<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
			</listener>

	- spring整合hibernate
		
	- spring对ibatis的整合，提供SqlMapClientCallback回调接口实现spring与ibatis结合，以回调的方式将操作封装给ibatis的SqlMapExecutor执行。
		org.springframework.orm.ibatis.SqlMapClientTemplate
		------

		private SqlMapClient sqlMapClient;

		public Object queryForObject(final String statementName, final Object parameterObject)
				throws DataAccessException {

			return execute(new SqlMapClientCallback() {
				public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
					return executor.queryForObject(statementName, parameterObject);
				}
			});
		}

		public Object execute(SqlMapClientCallback action) throws DataAccessException {
			Assert.notNull(action, "Callback object must not be null");
			Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

			// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
			// Connection (potentially transactional) in. This shouldn't be necessary if
			// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
			// we still need it to make iBATIS batch execution work properly: If iBATIS
			// doesn't recognize an existing transaction, it automatically executes the
			// batch for every single statement...

			SqlMapSession session = this.sqlMapClient.openSession();
			if (logger.isDebugEnabled()) {
				logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
			}
			Connection ibatisCon = null;

			try {
				Connection springCon = null;
				DataSource dataSource = getDataSource();
				boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

				// Obtain JDBC Connection to operate on...
				try {
					ibatisCon = session.getCurrentConnection();
					if (ibatisCon == null) {
						springCon = (transactionAware ?
								dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
						session.setUserConnection(springCon);
						if (logger.isDebugEnabled()) {
							logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
						}
					}
					else {
						if (logger.isDebugEnabled()) {
							logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
						}
					}
				}
				catch (SQLException ex) {
					throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
				}

				// Execute given callback...
				try {
					return action.doInSqlMapClient(session);
				}
				catch (SQLException ex) {
					throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
				}
				finally {
					try {
						if (springCon != null) {
							if (transactionAware) {
								springCon.close();
							}
							else {
								DataSourceUtils.doReleaseConnection(springCon, dataSource);
							}
						}
					}
					catch (Throwable ex) {
						logger.debug("Could not close JDBC Connection", ex);
					}
				}

				// Processing finished - potentially session still to be closed.
			}
			finally {
				// Only close SqlMapSession if we know we've actually opened it
				// at the present level.
				if (ibatisCon == null) {
					session.close();
				}
			}
		}
		------

		spring提供了一个工厂类，便于注入ibatis的SqlMapClient到spring context中
		spring-datasource.xml
		------
		<bean id="sqlMapTemplate" class="org.springframework.orm.ibatis.SqlMapClientTemplate">
			<property name="sqlMapClient">
				<bean class="org.springframework.orm.ibatis.SqlMapClientFactoryBean">
					<property name="dataSource">
						<ref bean="dataSource" />
					</property>
					<property name="configLocation" value="classpath:spring/slbapi-ibatis-config.xml" />
				</bean>
			</property>
		</bean>
		------
		public class SqlMapClientFactoryBean implements FactoryBean, InitializingBean {
		SqlMapClientFactoryBean实现了FactoryBean接口以返回spring能取到的对象，实现了InitializingBean来根据spring配置初始化成员变量sqlMapClient（ibatis的sqlMapClient）


	- spring对DAO层异常的封装与spring事务管理	Action,DAO,Service层， DataAccessException 异常应该在那一层捕获？
		
		spring事务配置在service层

		1）spring在进行声明时事务管理时，通过捕获Service层方法的DataAccessException来提交和回滚事务的，而Service层方法的DataAccessException
		又是来自调用DAO层方法所产生的异常． 
		2）我们一般在写DAO层代码时，如果继承JdbcDaoSupport 类，并使用此类所实现的JdbcTemplate来执行数据库操作，此类会自动把低层的SQLException转化成
		DataAccessException以及DataAccessException 
		的子类． 
		3）一般在Service层我们可以自己捕获DAO方法所产成的DataAccessException，然后再抛出一个业务方法有意义的异常(ps:此异常最好继承DataAccessException)，然后
		在Web层捕获，这样我们就可以手动编码的灵活实现通过业务方法执行的成功和失败来向用户转发不同的页面．

		spring事务配置属性说明：比如多个service在同一个事务中执行的的需求
		spring事务传递性、spring事务传播特性，参考下面文章：
			-----
			关于spring的事务传播特性

			摘要: 我们都知道事务的概念，那么事务的传播特性是什么呢？(此处着重介绍传播特性的概念，关于传播特性的相关配置就不介绍了，可以查看spring的官方文档) 在
			我们用SSH开发项目的时候，我们一般都是将事务设置在Service层 ...

			我们都知道事务的概念，那么事务的传播特性是什么呢？(此处着重介绍传播特性的概念，关于传播特性的相关配置就不介绍了，可以查看spring的官方文档) 
			在我们用SSH开发项目的时候，我们一般都是将事务设置在Service层 那么当我们调用Service层的一个方法的时候它能够保证我们的这个方法中执行的所有的对数据库
			的更新操作保持在一个事务中，在事务层里面调用的这些方法要么全部成功，要么全部失败。那么事务的传播特性也是从这里说起的。 

			如果你在你的Service层的这个方法中，除了调用了Dao层的方法之外，还调用了本类的其他的Service方法，那么在调用其他的 Service方法的时候，这个事务是怎么规定的呢，
			我必须保证我在我方法里掉用的这个方法与我本身的方法处在同一个事务中，否则如果保证事物的一致性。事务的传播特性就是解决这个问题的，“事务是会传播的”在Spring
			中有针对传播特性的多种配置我们大多数情况下只用其中的一种:PROPGATION_REQUIRED：这个配置项的意思是说当我调用service层的方法的时候开启一个事务(具体调用
			那一层的方法开始创建事务，要看你的aop的配置),那么在调用这个service层里面的其他的方法的时候,如果当前方法产生了事务就用当前方法产生的事务，否则就创建一个
			新的事务。这个工作使由Spring来帮助我们完成的。 
			
			以前没有Spring帮助我们完成事务的时候我们必须自己手动的控制事务，例如当我们项目中仅仅使用hibernate，而没有集成进 spring的时候，我们在一个service层中调用
			其他的业务逻辑方法，为了保证事物必须也要把当前的hibernate session传递到下一个方法中，或者采用ThreadLocal的方法，将session传递给下一个方法，其实都是一个
			目的。现在这个工作由 spring来帮助我们完成，就可以让我们更加的专注于我们的业务逻辑。而不用去关心事务的问题。 

			默认情况下当发生RuntimeException的情况下，事务才会回滚，所以要注意一下 如果你在程序发生错误的情况下，有自己的异常处理机制定义自己的Exception，
			必须从RuntimeException类继承 这样事务才会回滚！
			 
			Spring事务传播特性总结：
			1)只要定义为spring的bean就可以对里面的方法使用@Transactional注解。 
			2)Spring的事务传播是Spring特有的。不是对底层jdbc的代理。
			3)使用spring声明式事务，spring使用AOP来支持声明式事务，会根据事务属性，自动在[方法调用之前决定是否开启一个事务]，并在[方法执行之后]决定事务提交或回滚事务。
			
			4)Spring支持的PROPAGATION_NESTED 与PROPAGATION_REQUIRES_NEW的区别:
			PROPAGATION_REQUIRES_NEW：二个事务没有信赖关系，不会存在A事务的成功取决于B事务的情况。有可能存在A提交B失败。A失败（比如执行到
			doSomeThingB的时候抛出异常）B提交，AB都提交，AB都失败的可能。
			PROPAGATION_NESTED：与PROPAGATION_REQUIRES_NEW不同的是，内嵌事务B会信赖A。即存在A失败B失败。A成功，B失败。A成功，B成功。而不存在A失败，
			B成功。

			5) 特别注意PROPAGATION_NESTED的使用条件:使用JDBC 3.0驱动时,仅仅支持DataSourceTransactionManager作为事务管理器。需要JDBC 驱动的java.sql.Savepoint类。
			有一些JTA的事务管理器实现可能也提供了同样的功能。使用PROPAGATION_NESTED，还需要把PlatformTransactionManager的nestedTransactionAllowed属性设为true;而
			nestedTransactionAllowed属性值默认为false;
			6)特别注意PROPAGATION_REQUIRES_NEW的使用条件：JtaTransactionManager作为事务管理器			 
			的AOP简介与事务传播特性总结2009-10-26 16:56srping用到的另外一项技术就是AOP(Aspect-Oriented Programming, 面向切面编程)，它是一种新的方**, 是对传统 
			OOP(Object-Oriented Programming, 面向对象编程)的补充。AOP 的主要编程对象是切面(aspect), 而切面模块化横切关注点。在应用 AOP 编程时, 仍然需要在定义公共功能,
			但可以明确的定义这个功能在哪里, 以什么方式应用, 并且不必修改受影响的类. 这样一来横切关注点就被模块化到特殊的对象(切面)里。每个事物逻辑位于一个位置, 
			代码不分散，便于维护和升级，业务模块更简洁, 只包含核心业务代码。 

			现实中使用spring最多的就是声明式事务配置功能。下面就来了解其aop在事务上应用。首先要了解的就是AOP中的一些概念： 
			Aspect(切面):指横切性关注点的抽象即为切面，它与类相似，只是两者的关注点不一样，类是对物体特征的抽象，而切面是横切性关注点的抽象。 
			joinpoint(连接点):所谓连接点是指那些被拦截到的点。在spring中，这些点指的是方法，因为spring只支持方法类型的连接点，实际上joinpoint还可以是field或类构造器)。 
			Pointcut(切入点):所谓切入点是指我们要对那些joinpoint进行拦截的定义。 
			Advice(通知):所谓通知是指拦截到joinpoint之后所要做的事情就是通知.通知分为前置通知，后置通知，异常通知，最终通知，环绕通知。 
			Target(目标对象):代理的目标对象。 
			Weave(织入):指将aspects应用到target对象并导致proxy对象创建的过程称为织入。 
			Introduction(引入):在不修改类代码的前提下，Introduction可以在运行期为类动态地添加一些方法或Field。 

			所谓AOP，我的理解就是应该是这样一个过程，首先需要定义一个切面，这个切面是一个类，里面的方法就是关注点(也是通知)，或者说里面的方法就是
			用来在执行目标对象方法时需要执行的前置通知，后置通知，异常通知，最终通知，环绕通知等等。有了切面和通知，要应用到目标对象，就需要定义这些通知
			的切入点，换句话说就是需要对哪些方法进行拦截，而这些被拦截的方法就是连接点，所谓连接点也就是在动态执行过程，被织入切面的方法(至少在spring中只能
			对方法进行拦截)。因此，在动态过程中通知的执行就属于织入过程，而被织入这些通知的对象就是目标对象了。 

			通常应用中，被织入的都是事务处理，对事务的织入不是普通简单的织入，它有着事务特有的特性—— 
			事务的传播特性： 
			1) PROPAGATION_REQUIRED: 如果存在一个事务，则支持当前事务。如果没有事务则开启新的事物。 
			2) PROPAGATION_SUPPORTS: 如果存在一个事务，支持当前事务。如果没有事务，则非事务的执行。 
			3) PROPAGATION_MANDATORY: 如果已经存在一个事务，支持当前事务。如果没有一个活动的事务，则抛出异常。 
			4) PROPAGATION_REQUIRES_NEW: 总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。 
			5) PROPAGATION_NOT_SUPPORTED: 总是非事务地执行，并挂起任何存在的事务。 
			6) PROPAGATION_NEVER: 总是非事务地执行，如果存在一个活动事务，则抛出异常 
			7) (spring)PROPAGATION_NESTED：如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按TransactionDefinition.PROPAGATION_REQUIRED 属性执行。 
			这些都是事务特有的特性，比如前面分析的，如果两个在代码上不相关的操作，需要放在同一个事务中，这就需要利用到传播特性了，这时后调用的方法的传播特性
			的值就应该是PROPAGATION_REQUIRED。在spring中只需要进行这样的配置，就实现了生命式的事物处理。

				- REQUIRED
				- SUPPORTS
				- MANDATORY
				- REQUIRES_NEW
				- NOT_SUPPORTED
				- NEVER
				- NESTED

			化成表格的事务的传播特性
			----------------------------------
			事务属性	事务1	事务2
			----------------------------------
			Required		无		事务2
						事务1	事务1
			RequiredNew	无		事务2
						事务1	事务2
			Support		无		无
						事务1	事务1				
			Mandatory	无		抛异常
						事务1	事务1			
			NOSupport	无		无
						事务1	无			
			Never		无		无
						事务1	抛异常
			
			最后一点需要提及的就是Spring事务的隔离级别： 
			1) ISOLATION_DEFAULT：这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别。 
			2) ISOLATION_READ_UNCOMMITTED：这是事务最低的隔离级别，它充许令外一个事务可以看到这个事务未提交的数据。 
			3) ISOLATION_READ_COMMITTED：保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。 
			4) ISOLATION_REPEATABLE_READ：这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，
			还保证了避免下面的情况产生(不可重复读)。 
			5) ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。 
			除了第一个是spring特有的，另外四个与
			-----
			from: http://blog.sina.com.cn/s/blog_84feb25101010yoe.html


	- Log4jConfigListener 
		log4j配置动态加载，Spring默认刷新Log4j配置文件的间隔,单位为millisecond
	- spring抽象类注入，spring接口注入有区别
		抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	- spring通过aop拦截器，拦截自定义注解所注解的方法 参考day52
		参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/
	- ioc时注意，有些ioc是直接通过注解注入的，故在配置文件中找不到，这个细节要注意
		作用：1）管理对象关系，避免了直接new实现，更符合接口编程 2）对象生命周期管理

		@Autowired(required = true)
		public void setXX(@Qualifier("xx") xx xx) {
			//
		}
	- 编程式事务一例：
		spring 编程式事务管理
		1）bean配置
		<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
		   <property name="dataSource" ref="dataSource" />
		</bean>

		<bean id="transactionTemplate" class="org.springframework.transaction.support.TransactionTemplate" >
		   <property name="transactionManager" ref="transactionManager"/>
		</bean>

		<bean id="servie" class="SimpleService">
		  <property name="transactionTemplate" ref="transactionTemplate"/>
		</bean>

		TransactionTemplate是线程安全的，不同的service可以共用一个bean实例，其配置状态也是一致的。
		如果要用到不同的配置状态，则需要配置不同的TransactionTemplate Bean

		2）在Service中，定义TransactionTemplate全局变量

		public class SimpleService implements Service {
		  
		  private final TransactionTemplate transactionTemplate;

		  public void setTransactionTemplate(TransactionTemplate transactionTemplate) {
		    this.transactionTemplate = transactionTemplate;
		  }

		  public Object someServiceMethod() {
		    return transactionTemplate.execute(new TransactionCallback() {

		      // the code in this method executes in a transactional context
		      public Object doInTransaction(TransactionStatus status) {
			updateOperation1();
			return resultOfUpdateOperation2();
		      }
		    });
		  }
		}

		3）使用status.setRollbackOnly()方法回滚事务

		transactionTemplate.execute(new TransactionCallbackWithoutResult() {

		  protected void doInTransactionWithoutResult(TransactionStatus status) {
		    try {
		      updateOperation1();
		      updateOperation2();
		    } catch (SomeBusinessExeption ex) {
		      status.setRollbackOnly();
		    }
		  }
		});

		doInTransaction方法一旦执行完毕，事务自动提交；如果在catch块中设置了回滚setRollbackOnly，方法执行完毕将“提交”回滚。

		4、有返回值，使用TransactionCallback；如果没有返回值，使用TransactionCallbackWithoutResult
 * word * office word
	- word的列表问题，多级列表调整缩进样式，选中列表项，右键选“调整列表缩进”，具体看哪个对话框。

* 消息系统 消息中间件 MQ	 * rabbitmq
	- rabbitmq
		-----
		RabbitMQ 
		1). introduction:
		      RabbitMQ is a message broker. In essence, it accepts messages from producers, and delivers them to consumers. In-between, it can route, buffer, and persist the messages according to rules you give it.

		    A queue is the name for a mailbox. It lives inside RabbitMQ. Although messages flow through RabbitMQ and your applications, they can be stored only inside a queue. A queue is not bound 
		    by any limits, it can store as many messages as you like - it's essentially an infinite buffer. Many producers can send messages that go to one queue - many consumers can try to receive data from one queue.

		    To send, we must declare a queue for us to send to; then we can publish a message to the queue:
		     channel.queueDeclare(QUEUE_NAME, false, false, false, null);
		    String message = "Hello World!";
		    channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
		    System.out.println(" [x] Sent '" + message + "'");
		     Declaring a queue is idempotent - it will only be created if it doesn't exist already. The message content is a byte array, so you can encode whatever you like there.
		2). Work Queues:
		     The main idea behind Work Queues (aka: Task Queues) is to avoid doing a resource-intensive task immediately and having to wait for it to complete. Instead we schedule the task to be done later. 
		     We encapsulate a task as a message and send it to a queue. A worker process running in the background will pop the tasks and eventually execute the job. When you run many workers the tasks 
		     will be shared between them.
		     
		     One of the advantages of using Task Queue is the ability to easily parallelise work. If we are building up a backlog of work, we can just add more workers and that way, scale easily.
		Message acknowledgment：
		    Doing a task can take a few seconds. You may wonder what happens if one of the consumers starts a long task and dies with it only partly done. With our current code, once RabbitMQ delivers 
		a message to the customer it immediately removes it from memory. In this case, if you kill a worker we will lose the message it was just processing. We'll also lose all the messages that were dispatched 
		to this particular worker but were not yet handled.
		
		But we don't want to lose any tasks. If a worker dies, we'd like the task to be delivered to another worker.

		In order to make sure a message is never lost, RabbitMQ supports message acknowledgments. An ack(nowledgement) is sent back from the consumer to tell RabbitMQ that a particular message 
		has been received, processed and that RabbitMQ is free to delete it.

		If a consumer dies without sending an ack, RabbitMQ will understand that a message wasn't processed fully and will redeliver it to another consumer. That way you can be sure that no message is lost, 
		even if the workers occasionally die.
		There aren't any message timeouts; RabbitMQ will redeliver the message only when the worker connection dies. It's fine even if processing a message takes a very, very long time.

		Message durability：
		    We have learned how to make sure that even if the consumer dies, the task isn't lost. But our tasks will still be lost if RabbitMQ server stops.
		When RabbitMQ quits or crashes it will forget the queues and messages unless you tell it not to. Two things are required to make sure that messages aren't lost: we need to mark both the queue and 
		messages as durable.
		    First, we need to make sure that RabbitMQ will never lose our queue. In order to do so, we need to declare it as durable:
		boolean durable = true;
		channel.queueDeclare("hello", durable, false, false, null);
		     RabbitMQ doesn't allow you to redefine an existing queue with different parameters and will return an error to any program that tries to do that. 
		     At this point we're sure that the task_queue queue won't be lost even if RabbitMQ restarts. Now we need to mark our messages as persistent - by setting MessageProperties (which implements 
		BasicProperties) to the value PERSISTENT_TEXT_PLAIN.
		import com.rabbitmq.client.MessageProperties;
		channel.basicPublish("", "task_queue", 
			    MessageProperties.PERSISTENT_TEXT_PLAIN,
			    message.getBytes());
		Note on message persistence：
		     Marking messages as persistent doesn't fully guarantee that a message won't be lost. Although it tells RabbitMQ to save the message to disk, there is still a short time window when RabbitMQ has 
		accepted a message and hasn't saved it yet. Also, RabbitMQ doesn't do fsync(2) for every message -- it may be just saved to cache and not really written to the disk. The persistence guarantees aren't 
		strong, but it's more than enough for our simple task queue. If you need a stronger guarantee you can wrap the publishing code in a transaction.

		Fair dispatch：
		    You might have noticed that the dispatching still doesn't work exactly as we want. For example in a situation with two workers, when all odd messages are heavy and even messages are light, one worker 
		will be constantly busy and the other one will do hardly any work. Well, RabbitMQ doesn't know anything about that and will still dispatch messages evenly.   This happens because RabbitMQ just dispatches 
		 message when the message enters the queue. It doesn't look at the number of unacknowledged messages for a consumer. It just blindly dispatches every n-th message to the n-th consumer.
		     In order to defeat that we can use the basicQos method with the prefetchCount = 1 setting. This tells RabbitMQ not to give more than one message to a worker at a time. Or, in other words, don't 
		dispatch a new message to a worker until it has processed and acknowledged the previous one. Instead, it will dispatch it to the next worker that is not still busy.
		int prefetchCount = 1;
		channel.basicQos(prefetchCount);

		3). Publish/Subscribe: 
		     Essentially, published messages are going to be broadcast to all the receivers.
		Exchanges:
		     The core idea in the messaging model in RabbitMQ is that the producer never sends any messages directly to a queue.

		     Instead, the producer can only send messages to an exchange. An exchange is a very simple thing. On one side it receives messages from producers and the other side it pushes them to queues. 
		     The exchange must know exactly what to do with a message it receives. Should it be appended to a particular queue? Should it be appended to many queues? Or should it get discarded. The rules
		     for that are defined by the exchange type.

		     There are a few exchange types available: direct, topic, headers and fanout.
		     channel.exchangeDeclare("logs", "fanout");

		Nameless exchange：
		     In previous parts of the tutorial we knew nothing about exchanges, but still were able to send messages to queues. That was possible because we were using a default exchange, which we identify 
		     by the empty string ("").

		     Recall how we published a message before:
		      channel.basicPublish("", "hello", null, message.getBytes());
		     The first parameter is the the name of the exchange. The empty string denotes the default or nameless exchange: messages are routed to the queue with the name specified by routingKey, if it exists.

		Temporary queues：
		     Giving a queue a name is important when you want to share the queue between producers and consumers.
		     We want to hear about all log messages, not just a subset of them. We're also interested only in currently flowing messages not in the old ones. To solve that we need two things.
		     Firstly, whenever we connect to Rabbit we need a fresh, empty queue. To do this we could create a queue with a random name, or, even better - let the server choose a random queue name for us.
		     Secondly, once we disconnect the consumer the queue should be automatically deleted.
		     In the Java client, when we supply no parameters to queueDeclare() we create a non-durable, exclusive, autodelete queue with a generated name:
		      String queueName = channel.queueDeclare().getQueue();
		     At that point queueName contains a random queue name. For example it may look like amq.gen-U0srCoW8TsaXjNh73pnVAw==.
		Bindings：
		     We've already created a fanout exchange and a queue. Now we need to tell the exchange to send messages to our queue. That relationship between exchange and a queue is called a binding.
		      channel.queueBind(queueName, "logs", "");
		4). Routing：
		Bindings：
		     In previous examples we were already creating bindings. You may recall code like:
		      channel.queueBind(queueName, EXCHANGE_NAME, "");
		     A binding is a relationship between an exchange and a queue. This can be simply read as: the queue is interested in messages from this exchange.
		     Bindings can take an extra routingKey parameter.
		      channel.queueBind(queueName, EXCHANGE_NAME, "black");
		     The meaning of a binding key depends on the exchange type. The fanout exchanges, which we used previously, simply ignored its value.
		Direct exchange:
		     We will use a direct exchange instead. The routing algorithm behind a direct exchange is simple - a message goes to the queues whose binding key exactly matches the routing key of the message.
		     The routing algorithm behind a direct exchange is simple - a message goes to the queues whose binding key exactly matches the routing key of the message.
		5). Topics
		     Messages sent to a topic exchange can't have an arbitrary routing_key - it must be a list of words, delimited by dots. The words can be anything, but usually they specify some features connected t
		     o the message.

		     There can be as many words in the routing key as you like, up to the limit of 255 bytes.
		     The binding key must also be in the same form. The logic behind the topic exchange is similar to a direct one - a message sent with a particular routing key will be delivered to all the queues that 
		     are bound with a matching binding key. However there are two important special cases for binding keys:
		     * (star) can substitute for exactly one word.
		     # (hash) can substitute for zero or more words.
		6). Remote procedure call (RPC)
		     But what if we need to run a function on a remote computer and wait for the result? Well, that's a different story. This pattern is commonly known as Remote Procedure Call or RPC.
		-----
		from: http://sishuok.com/forum/blogPost/list/5782.html
	- rabbitmq
		常用命令
		Mirrored Queue Behaviour

		In normal operation, for each mirrored-queue, there is one master and several slaves, each on a different node. The slaves apply the operations that occur to the master in exactly the same order as the master and thus maintain the same state. All actions other than publishes go only to the master, and the master then broadcasts the effect of the actions to the slaves. Thus clients consuming from a mirrored queue are in fact consuming from the master.

		Should a slave fail, there is little to be done other than some bookkeeping: the master remains the master and no client need take any action or be informed of the failure.

		If the master fails, then one of the slaves must be promoted. At this point, the following happens:

		A slave is promoted to become the new master. The slave chosen for promotion is the eldest slave. As such, it has the best chance of being synchronised with the master. However, note that should there be no slave that is synchronised with the master, messages that only the master held will be lost.
		The slave considers all previous consumers to have been abruptly disconnected. As such, it requeues all messages that have been delivered to clients but are pending acknowledgement. This can include messages for which a client has issued acknowledgements: either the acknowledgement was lost on the wire before reaching the master, or it was lost during broadcast from the master to the slaves. In either case, the new master has no choice but to requeue all messages it thinks have not been acknowledged.
		Clients that were consuming from the mirrored-queue and support our Consumer Cancellation Notifications extension will receive a notification that their subscription to the mirrored-queue has been abruptly cancelled. At this point they should re-consume from the queue, which will pick up the new master. The reason for sending this notification is that informing clients of the loss of the master is essential: otherwise the client may continue to issue acknowledgements for messages they were sent by the old, failed master, and not expect that they might be about to see the same messages again, this time sent by the new master. Of course, clients that were connected to the failed node will find their connections failed, and will need to reconnect to a surviving node of the cluster.
		As a result of the requeuing, clients that re-consume from the queue must be aware that they are likely to subsequently receive messages that they have seen previously.
		As the chosen slave becomes the master, no messages that are published to the mirrored-queue during this time will be lost: messages published to a mirrored-queue are always published directly to the master and all slaves. Thus should the master fail, the messages continue to be sent to the slaves and will be added to the queue once the promotion of a slave to the master completes.

		Similarly, messages published by clients using publisher confirms will still be confirmed correctly even if the master (or any slaves) fail between the message being published and the message being able to be confirmed to the publisher. Thus from the point of view of the publisher, publishing to a mirrored-queue is no different from publishing to any other sort of queue. It is only consumers that need to be aware of the possibility of needing to re-consume from a mirrored-queue upon receipt of a Consumer Cancellation Notification.

		If you are consuming from a mirrored-queue with noAck=true (i.e. the client is not sending message acknowledgements) then messages can be lost. This is no different from the norm of course: the broker considers a message acknowledged as soon as it has been sent to a noAck=true consumer, and should the client disconnect abruptly, the message may never be received. In the case of a mirrored-queue, should the master die, messages that are in-flight on their way to noAck=true consumers may never be received by those clients, and will not be requeued by the new master. Because of the possibility that the consuming client is connected to a node that survives, the Consumer Cancellation Notification is useful in identifying when such events may have occurred. Of course, in practise, if you care about not losing messages then you are advised to consume with noAck=false.

		Publisher Confirms and Transactions
		Mirrored queues support both Publisher Confirms and Transactions. The semantics chosen are that in the case of both confirms and transactions, the action spans all mirrors of the queue. So in the case of a transaction, a tx.commit-ok will only be returned to a client when the transaction has been applied across all mirrors of the queue. Equally, in the case of publisher confirms, a message will only be confirmed to the publisher when it has been accepted by all of the mirrors. It is correct to think of the semantics as being the same as a message being routed to multiple normal queues, and of a transaction with publications within that similarly are routed to multiple queues.

		Unsynchronised Slaves

		A node may join a cluster at any time. Depending on the configuration of a queue, when a node joins a cluster, queues may add a slave on the new node. At this point, the new slave will be empty: it will not contain any existing contents of the queue. Such a slave will receive new messages published to the queue, and thus over time will accurately represent the tail of the mirrored-queue. As messages are drained from the mirrored-queue, the size of the head of the queue for which the new slave is missing messages, will shrink until eventually the slave's contents precisely match the master's contents. At this point, the slave can be considered fully synchronised, but it is important to note that this has occured because of actions of clients in terms of draining the pre-existing head of the queue.

		Thus a newly added slave provides no additional form of redundancy or availability of the queue's contents until the contents of the queue that existed before the slave was added have been removed or the queue has been explicitly synchronised (see below). Since the queue becomes unresponsive while synchronisation is occurring, it is preferable to allow active queues from which messages are being drained to synchronise naturally, and only explicitly synchronise inactive queues.

		Explicit synchronisation can be triggered in two ways: manually or automatically. If a queue is set to automatically synchronise it will synchronise whenever a new slave joins - becoming unresponsive until it has done so.

		Starting and Stopping Nodes

		If you stop a RabbitMQ node which contains the master of a mirrored-queue, some slave on some other node will be promoted to the master (assuming there is one). If you continue to stop nodes then you will reach a point where a mirrored-queue has no more slaves: it exists only on one node, which is now its master. If the mirrored-queue was declared durable then, if its last remaining node is shutdown, durable messages in the queue will survive the restart of that node. In general, as you restart other nodes, if they were previously part of a mirrored-queue then they will rejoin the mirrored queue.

		However, there is currently no way for a slave to know whether or not its queue contents have diverged from the master to which it is rejoining (this could happen during a network partition, for example). As such, when a slave rejoins a mirrored-queue, it throws away any durable local contents it already has and starts empty. Its behaviour is at this point the same as if it were a new node joining the cluster.

		Configuring Mirroring

		Queues have mirroring enabled via policy. Policies can change at any time; it is valid to create a non-mirrored queue, and then make it mirrored at some later point (and vice versa). There is a difference between a non-mirrored queue and a mirrored queue which does not have any slaves - the former lacks the extra mirroring infrastructure and will run faster.

		You should be aware of the behaviour of adding mirrors to a queue.

		To cause queues to become mirrored, you should create a policy which matches them and sets policy keys ha-mode and (optionally) ha-params. The following table explains the options for these keys:

		ha-mode	ha-params	Result
		all	(absent)	 Queue is mirrored across all nodes in the cluster. When a new node is added to the cluster, the queue will be mirrored to that node.
		exactly	count	 Queue is mirrored to count nodes in the cluster. If there are less than count nodes in the cluster, the queue is mirrored to all nodes. If there are more than count nodes in the cluster, and a node containing a mirror goes down, then a new mirror will not be created on another node. (This is to prevent queues migrating across a cluster as it is brought down.)
		nodes	node names	 Queue is mirrored to the nodes listed in node names. If any of those node names are not a part of the cluster, this does not constitute an error. If none of the nodes in the list are online at the time when the queue is declared then the queue will be created on the node that the declaring client is connected to.
		Whenever the HA policy for a queue changes it will endeavour to keep its existing mirrors as far as this fits with the new policy.

		"nodes" policy and migrating masters
		Note that setting or modifying a "nodes" policy can cause the existing master to go away if it is not listed in the new policy. In order to prevent message loss, RabbitMQ will keep the existing master around until at least one other slave has synchronised (even if this is a long time). However, once synchronisation has occured things will proceed just as if the node had failed: consumers will be disconnected from the master and will need to reconnect.

		For example, if a queue is on [A B] (with A the master), and you give it a nodes policy telling it to be on [C D], it will initially end up on [A C D]. As soon as the queue synchronises on its new mirrors [C D], the master on A will shut down.

		Synchronising Queues
		Queues can be set to automatically synchronise by setting the ha-sync-mode policy key to automatic. ha-sync-mode can also be set to manual. If it is not set then manual is assumed.

		You can determine which slaves are synchronised with the following rabbitmqctl invocation:

		rabbitmqctl list_queues name slave_pids synchronised_slave_pids
		You can manually synchronise a queue with:

		rabbitmqctl sync_queue name
		And you can cancel synchronisation with:

		rabbitmqctl cancel_sync_queue name
		These features are also available through the management plugin.

		Some examples
		Policy where queues whose names begin with "ha." are mirrored to all nodes in the cluster:

		rabbitmqctl	
		rabbitmqctl set_policy ha-all "^ha\." '{"ha-mode":"all"}'
		rabbitmqctl (Windows)	
		rabbitmqctl set_policy ha-all "^ha\." "{""ha-mode"":""all""}"
		HTTP API	
		PUT /api/policies/%2f/ha-all {"pattern":"^ha\.", "definition":{"ha-mode":"all"}}
		Web UI	
		Navigate to Admin > Policies > Add / update a policy.
		Enter "ha-all" next to Name, "^ha\." next to Pattern, and "ha-mode" = "all" in the first line next to Policy.
		Click Add policy.
		Policy where queues whose names begin with "two." are mirrored to any two nodes in the cluster, with automatic synchronisation:

		rabbitmqctl	
		rabbitmqctl set_policy ha-two "^two\." \
		   '{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}'
		rabbitmqctl (Windows)	
		rabbitmqctl set_policy ha-two "^two\." ^
		   "{""ha-mode"":""exactly"",""ha-params"":2,"ha-sync-mode":"automatic"}"
		HTTP API	
		PUT /api/policies/%2f/ha-two
		{"pattern":"^two\.", "definition":{"ha-mode":"exactly", "ha-params":2,"ha-sync-mode":"automatic"}}
		Web UI	
		Navigate to Admin > Policies > Add / update a policy.
		Enter "ha-two" next to Name and "^two\." next to Pattern.
		Enter "ha-mode" = "exactly" in the first line next to Policy, then "ha-params" = 2 in the second line, then "ha-sync-mode" = "automatic" in the third, and set the type on the second line to "Number".
		Click Add policy.
		In This Section
		Features
		Server Documentation
		Configuration
		SSL Support
		Distributed RabbitMQ
		Reliable Delivery
		Clustering
		High Availability
		High Availability (pacemaker)
		Access Control
		SASL Authentication
		Flow Control
		Memory Use
		Firehose / Tracing
		Manual Pages
		Windows Quirks
		Client Documentation
		Plugins
		News
		Protocol
		Our Extensions
		Building
		Previous Releases
		License
		In This Page
		Mirrored Queue Behaviour
		Unsynchronised Slaves
		Starting and Stopping Nodes
		Configuring Mirroring
		Sitemap | Contact

		HA
		ref: http://www.rabbitmq.com/ha.html

		AMQP(Advanced Message Queuing Protocol) 规范说明：http://www.amqp.org/

		rabbit-mq命令：
			1) rabbitmq-multi - start/stop local cluster RabbitMQ nodes
				SYNOPSIS
				       rabbitmq-multi {command} [command options...]
				DESCRIPTION
				       RabbitMQ is an implementation of AMQP, the emerging standard for high performance enterprise messaging. The RabbitMQ server is a robust and scalable
				       implementation of an AMQP broker.

				       rabbitmq-multi scripts allows for easy set-up of a cluster on a single machine.
			2) rabbitmqctl
				Commands:
				    stop
				    stop_app
				    start_app
				    status
				    reset
				    force_reset
				    rotate_logs <suffix>

				    cluster <clusternode> ...
				    force_cluster <clusternode> ...

				    close_connection <connectionpid> <explanation>

				    add_user <username> <password>
				    delete_user <username>
				    change_password <username> <newpassword>
				    set_admin <username>
				    clear_admin <username>
				    list_users

				    add_vhost <vhostpath>
				    delete_vhost <vhostpath>
				    list_vhosts
				    set_permissions [-p <vhostpath>] <user> <conf> <write> <read>
				    clear_permissions [-p <vhostpath>] <username>
				    list_permissions [-p <vhostpath>]
				    list_user_permissions [-p <vhostpath>] <username>

				    list_queues [-p <vhostpath>] [<queueinfoitem> ...]
				    list_exchanges [-p <vhostpath>] [<exchangeinfoitem> ...]
				    list_bindings [-p <vhostpath>] [<bindinginfoitem> ...]
				    list_connections [<connectioninfoitem> ...]
				    list_channels [<channelinfoitem> ...]
				    list_consumers
			3）rabbitmq-server - start RabbitMQ AMQP server
			NOTES
			1). clustering on a single machine guide
			   http://www.rabbitmq.com/clustering.html#single-machine


	- AMQP(Advanced Message Queuing Protocol )协议
		rabbitMQ基于此协议实现
			tutorial：http://www.rabbitmq.com/tutorials/tutorial-one-python.html

	- 消息队列 消息队列框架 message queue ，MQ
	发布/订阅
	MQ的特点：
			MQ的消费-生产者模型的一个典型的代表，一端往消息队列中不断的写入消息，而另一端则可以读取或者订阅队列中的消息。MQ和JMS类似，
		但不同的是JMS是SUN JAVA消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品。
	使用场景(异步处理需求):
		　　最近在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从
		而提高了系统的吞吐量。

	- Jafka - 一个高性能的消息系统 : http://www.blogjava.net/xylz/archive/2012/05/10/377759.html
		淘宝内部使用的Kafka克隆版metaq,内部做了大量的改进和附加组件。如果你需要一个全功能的“复杂”系统，可以试试metaq: 
			https://github.com/killme2008/Metamorphosis
	
	- Rabbitmq erlang实现的消息中间件
		http://www.rabbitmq.com/
		根据tutorial说明，provider或者consumer都可以建立queue

	- JMS		       * JMS
		JMS是一种与厂商无关的 API，用来访问消息收发系统。它类似于 JDBC(Java Database Connectivity)：这里，JDBC 是可以用来访问许多不同关系数据库的 API，
	而 JMS 则提供同样与厂商无关的访问方法，以访问消息收发服务。许多厂商目前都支持 JMS，包括 IBM 的 MQSeries、BEA的 Weblogic JMS service和 Progress 的 
	SonicMQ，这只是几个例子。 JMS 使您能够通过消息收发服务（有时称为消息中介程序或路由器）从一个 JMS 客户机向另一个 JMS客户机发送消息。消息是 JMS 
	中的一种类型对象，由两部分组成：报头和消息主体。报头由路由信息以及有关该消息的元数据组成。消息主体则携带着应用程序的数据或有效负载。根据有效
	负载的类型来划分，可以将消息分为几种类型，它们分别携带：简单文本 (TextMessage)、可序列化的对象 (ObjectMessage)、属性集合 (MapMessage)、字节流
	(BytesMessage)、原始值流 (StreamMessage)，还有无有效负载的消息 (Message)。
	
	消息通信是软件组件或应用程序用来通信的一种方法。JMS就是一种允许应用程序创建、发送、接收、和读取消息的JAVA技术。				

	JMS提供者实现
	　　要使用Java消息服务，你必须要有一个JMS提供者，管理会话和队列。现在既有开源的提供者也有专有的提供者。 　　
		开源的提供者包括： 　　
			Apache ActiveMQ —— is the most popular and powerful open source messaging and Integration Patterns server
			http://activemq.apache.org/
* haproxy
		HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代 理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。
	HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。
	并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。
		HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，
	很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，
	这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。

	haproxy与lvs的关系：
		软件负载均衡一般通过两种方式来实现：基于操作系统的软负载实现和基于第三方应用的软负载实现。LVS就是基于Linux操作系统实现的一种软负载，
		HAProxy就是开源的并且基于第三应用实现的软负载。
	
	HAProxy相比LVS的使用要简单很多，功能方面也很丰富。当 前，HAProxy支持两种主要的代理模式:"tcp"也即4层（大多用于邮件服务器、内部协议通信服务器等），
	和7层（HTTP）。在4层模式 下，HAProxy仅在客户端和服务器之间转发双向流量。7层模式下，HAProxy会分析协议，并且能通过允许、拒绝、交换、增加、修改
	或者删除请求 (request)或者回应(response)里指定内容来控制协议，这种操作要基于特定规则。
	
	---------
	我现在用HAProxy主要在于它有以下优点，这里我总结下：
		一、免费开源，稳定性也是非常好，这个可通过我做的一些小项目可以看出来，单Haproxy也跑得不错，稳定性可以与LVS相媲美；
		二、根据官方文档，HAProxy可以跑满10Gbps-New benchmark of HAProxy at 10 Gbps using Myricom's 10GbE NICs (Myri-10G PCI-Express)，这个作为软件级负载均衡，
		也是比较惊人的；
		三、HAProxy可以作为MySQL、邮件或其它的非web的负载均衡，我们常用于它作为MySQL(读)负载均衡；
		四、自带强大的监控服务器状态的页面，实际环境中我们结合Nagios进行邮件或短信报警，这个也是我非常喜欢它的原因之一；
		五、HAProxy支持虚拟主机。
	---------
	from: http://www.cnblogs.com/dkblog/archive/2011/07/06/2098949.html

	数据库(读)负载均衡：
		应用维持一个数据库连接池的情况
* 系统部署架构
	请求 > web负载均衡 > squid web cache > web server > squid db cache > 数据库负载均衡> db

* loadbalance 负载均衡	      * slb software load balance * lb 
	haproxy + keepalived 方式实现软负载均衡
		http://www.cnblogs.com/dkblog/archive/2011/07/06/2098949.html

	slb的优点（相对于dns实现的lb）：
	SLB has several benefits, which is why it is such a highly successful and widely
	employed technology. Three main benefits directly address the concerns and
	needs of highly trafficked, mission-critical web sites:
	Flexibility
		SLB allows the addition and removal of servers to a site at any time, and the
		effect is immediate. Among other advantages, this allows for the maintenance
		of any machine, even during peak hours with little or no impact to the site. A
		load balancer can also intelligently direct traffic using cookies, URL parsing,
		static and dynamic algorithms, and much more.
	High availability
		SLB can check the status of the available servers, take any nonresponding
		servers out of the rotation, and put them in rotation when they are functioning
		again. This is automatic, requiring no intervention by an administrator.
		Also, the load balancers themselves usually come in a redundant configuration,
		employing more than one unit in case any one unit fails.
	Scalability
		Since SLB distributes load among many servers, all that is needed to increase
		the serving power of a site is to add more servers. This can be very economical,
		since many small- to medium-sized servers can be much less expensive
		than a few high-end servers. Also, when site load increases, servers can be
		brought up immediately to handle the increase in traffic.
	
* html/css模板 ，有此类网站搜集页面模板
	http://www.html-themes.com/free/
				
* 正则表达式 例子	  RegEx
	通过一些小正则工具来验证表达式
	
	整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
	只能输入数字："^[0-9]*$"。 
	只能输入n位的数字："^\d{n}$"。 
	只能输入至少n位的数字："^\d{n,}$"。 
	只能输入m~n位的数字：。"^\d{m,n}$" 
	只能输入零和非零开头的数字："^(0|[1-9][0-9]*)$"。 
	只能输入有两位小数的正实数："^[0-9]+(.[0-9]{2})?$"。 
	只能输入有1~3位小数的正实数："^[0-9]+(.[0-9]{1,3})?$"。 
	只能输入非零的正整数："^\+?[1-9][0-9]*$"。 
	只能输入非零的负整数："^\-[1-9][]0-9"*$。 
	只能输入长度为3的字符："^.{3}$"。 
	只能输入由26个英文字母组成的字符串："^[A-Za-z]+$"。 
	只能输入由26个大写英文字母组成的字符串："^[A-Z]+$"。 
	只能输入由26个小写英文字母组成的字符串："^[a-z]+$"。 
	只能输入由数字和26个英文字母组成的字符串："^[A-Za-z0-9]+$"。 
	只能输入由数字、26个英文字母或者下划线组成的字符串："^\w+$"。 
	验证用户密码："^[a-zA-Z]\w{5,17}$"正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。 
	验证是否含有^%&',;=?$\"等字符："[^%&',;=?$\x22]+"。 
	只能输入汉字："^[\u4e00-\u9fa5]{0,}$" 
	验证Email地址："^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$"。 
	验证InternetURL："^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$"。 
	验证电话号码："^(\(\d{3,4}-)|\d{3.4}-)?\d{7,8}$"正确格式为："XXX-XXXXXXX"、"XXXX-XXXXXXXX"、"XXX-XXXXXXX"、"XXX-XXXXXXXX"、"XXXXXXX"和"XXXXXXXX"。 
	验证身份证号（15位或18位数字）："^\d{15}|\d{18}$"。 
	验证一年的12个月："^(0?[1-9]|1[0-2])$"正确格式为："01"～"09"和"1"～"12"。 
	验证一个月的31天："^((0?[1-9])|((1|2)[0-9])|30|31)$"正确格式为；"01"～"09"和"1"～"31"。 
	匹配中文字符的正则表达式： [\u4e00-\u9fa5] 

	匹配双字节字符(包括汉字在内)：[^\x00-\xff] 
	-  more -
			正则表达式语法 
		在典型的搜索和替换操作中，必须提供要查找的确切文字。这种技术对于静态文本中的简单搜索和替换任务可能足够了，但是由于它缺乏灵活性，
		因此在搜索动态文本时就有困难了，甚至是不可能的。 

		使用正则表达式，就可以： 

		•测试字符串的某个模式。例如，可以对一个输入字符串进行测试，看在该字符串是否存在一个电话号码模式或一个信用卡号码模式。这称为数据有效性验证。
		•替换文本。可以在文档中使用一个正则表达式来标识特定文字，然后可以全部将其删除，或者替换为别的文字。
		•根据模式匹配从字符串中提取一个子字符串。可以用来在文本或输入字段中查找特定文字。 
		例如，如果需要搜索整个 web 站点来删除某些过时的材料并替换某些HTML 格式化标记，则可以使用正则表达式对每个文件进行测试，看在该文件中是否存在所
		要查找的材料或 HTML 格式化标记。用这个方法，就可以将受影响的文件范围缩小到包含要删除或更改的材料的那些文件。然后可以使用正则表达式来删除过时的材料，
		最后，可以再次使用正则表达式来查找并替换那些需要替换的标记。

		另一个说明正则表达式非常有用的示例是一种其字符串处理能力还不为人所知的语言。VBScript 是 Visual Basic 的一个子集，具有丰富的字符串处理功能。与 C 类似的
		Jscript 则没有这一能力。正则表达式给 JScript 的字符串处理能力带来了明显改善。不过，可能还是在 VBScript 中使用正则表达式的效率更高，它允许在单个表达式中
		执行多个字符串操作。

		一个正则表达式就是由普通字符（例如字符 a 到 z）以及特殊字符（称为元字符）组成的文字模式。该模式描述在查找文字主体时待匹配的一个或多个字符串。正则表达式
		作为一个模板，将某个字符模式与所搜索的字符串进行匹配。

		这里有一些可能会遇到的正则表达式示例：


		JScript VBScript 匹配 
		/^\[ \t]*$/ "^\[ \t]*$" 匹配一个空白行。 
		/\d{2}-\d{5}/ "\d{2}-\d{5}" 验证一个ID 号码是否由一个2位数字，一个连字符以及一个5位数字组成。 
		/<(.*)>.*<\/\1>/ "<(.*)>.*<\/\1>" 匹配一个 HTML 标记。 



		下表是元字符及其在正则表达式上下文中的行为的一个完整列表：


		字符 描述 
		\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 后向引用、或一个八进制转义符。例如，'n' 匹配字符 "n"。'\n' 匹配一个换行符。序列 '\\' 匹配 "\" 而 "\(" 则匹配 "("。 
		^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 '\n' 或 '\r' 之后的位置。 
		$ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 '\n' 或 '\r' 之前的位置。 
		* 匹配前面的子表达式零次或多次。例如，zo* 能匹配 "z" 以及 "zoo"。 * 等价于{0,}。 
		+ 匹配前面的子表达式一次或多次。例如，'zo+' 能匹配 "zo" 以及 "zoo"，但不能匹配 "z"。+ 等价于 {1,}。 
		? 匹配前面的子表达式零次或一次。例如，"do(es)?" 可以匹配 "do" 或 "does" 中的"do" 。? 等价于 {0,1}。 
		{n} n 是一个非负整数。匹配确定的 n 次。例如，'o{2}' 不能匹配 "Bob" 中的 'o'，但是能匹配 "food" 中的两个 o。 
		{n,} n 是一个非负整数。至少匹配n 次。例如，'o{2,}' 不能匹配 "Bob" 中的 'o'，但能匹配 "foooood" 中的所有 o。'o{1,}' 等价于 'o+'。'o{0,}' 则等价于 'o*'。 
		{n,m} m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。刘， "o{1,3}" 将匹配 "fooooood" 中的前三个 o。'o{0,1}' 等价于 'o?'。请注意在逗号和两个数之间不能有空格。 
		? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 "oooo"，'o+?' 将匹配单个 "o"，而 'o+' 将匹配所有 'o'。 
		. 匹配除 "\n" 之外的任何单个字符。要匹配包括 '\n' 在内的任何字符，请使用象 '[.\n]' 的模式。 
		(pattern) 匹配pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 '\(' 或 '\)'。 
		(?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 "或" 字符 (|) 来组合一个模式的各个部分是很有用。例如， 'industr(?:y|ies) 就是一个比 'industry|industries' 更简略的表达式。 
		(?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如， 'Windows (?=95|98|NT|2000)' 能匹配 "Windows 2000" 中的 "Windows" ，但不能匹配 "Windows 3.1" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 
		(?!pattern) 负向预查，在任何不匹配Negative lookahead matches the search string at any point where a string not matching pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如'Windows (?!95|98|NT|2000)' 能匹配 "Windows 3.1" 中的 "Windows"，但不能匹配 "Windows 2000" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始  
		x|y 匹配 x 或 y。例如，'z|food' 能匹配 "z" 或 "food"。'(z|f)ood' 则匹配 "zood" 或 "food"。  
		[xyz] 字符集合。匹配所包含的任意一个字符。例如， '[abc]' 可以匹配 "plain" 中的 'a'。  
		[^xyz] 负值字符集合。匹配未包含的任意字符。例如， '[^abc]' 可以匹配 "plain" 中的'p'。  
		[a-z] 字符范围。匹配指定范围内的任意字符。例如，'[a-z]' 可以匹配 'a' 到 'z' 范围内的任意小写字母字符。  
		[^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，'[^a-z]' 可以匹配任何不在 'a' 到 'z' 范围内的任意字符。  
		\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\b' 可以匹配"never" 中的 'er'，但不能匹配 "verb" 中的 'er'。  
		\B 匹配非单词边界。'er\B' 能匹配 "verb" 中的 'er'，但不能匹配 "never" 中的 'er'。 
		\cx 匹配由x指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。 x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 'c' 字符。  
		\d 匹配一个数字字符。等价于 [0-9]。  
		\D 匹配一个非数字字符。等价于 [^0-9]。  
		\f 匹配一个换页符。等价于 \x0c 和 \cL。 
		\n 匹配一个换行符。等价于 \x0a 和 \cJ。 
		\r 匹配一个回车符。等价于 \x0d 和 \cM。 
		\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 
		\S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 
		\t 匹配一个制表符。等价于 \x09 和 \cI。 
		\v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 
		\w 匹配包括下划线的任何单词字符。等价于'[A-Za-z0-9_]'。  
		\W 匹配任何非单词字符。等价于 '[^A-Za-z0-9_]'。  
		\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如， '\x41' 匹配 "A"。'\x041' 则等价于 '\x04' & "1"。正则表达式中可以使用 ASCII 编码。. 
		\num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，'(.)\1' 匹配两个连续的相同字符。  
		\n 标识一个八进制转义值或一个后向引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为后向引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 
		\nm 标识一个八进制转义值或一个后向引用。如果 \nm 之前至少有is preceded by at least nm 个获取得子表达式，则 nm 为后向引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的后向引用。如果前面的条件都不满足，若  n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。 
		\nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 
		\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。 

		常用正则：
		1.验证用户名和密码：（ "^[a-zA-Z]\w{5,15}$ "）正确格式： "[A-Z][a-z]_[0-9] "组成,并且第一个字必须为字母6~16位； 
		2.验证电话号码：（ "^(\d{3.4}-)\d{7,8}$ "）正确格式：xxx/xxxx-xxxxxxx/xxxxxxxx； 
		3.验证身份证号（15位或18位数字）：（ "^\d{15} ¦\d{18}$ "）； 
		4.验证Email地址：( "^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ ")； 
		5.只能输入由数字和26个英文字母组成的字符串：( "^[A-Za-z0-9]+$ ") ; 
		6.整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
		7.只能输入数字： "^[0-9]*$ "。 
		8.只能输入n位的数字： "^\d{n}$ "。 
		9.只能输入至少n位的数字： "^\d{n,}$ "。 
		10.只能输入m~n位的数字：。 "^\d{m,n}$ " 
		11.只能输入零和非零开头的数字： "^(0 ¦[1-9][0-9]*)$ "。 
		12.只能输入有两位小数的正实数： "^[0-9]+(.[0-9]{2})?$ "。 
		13.只能输入有1~3位小数的正实数： "^[0-9]+(.[0-9]{1,3})?$ "。 
		14.只能输入非零的正整数： "^\+?[1-9][0-9]*$ "。 
		15.只能输入非零的负整数： "^\-[1-9][]0-9 "*$。 
		16.只能输入长度为3的字符： "^.{3}$ "。 
		17.只能输入由26个英文字母组成的字符串： "^[A-Za-z]+$ "。 
		18.只能输入由26个大写英文字母组成的字符串： "^[A-Z]+$ "。 
		19.只能输入由26个小写英文字母组成的字符串： "^[a-z]+$ "。 
		20.验证是否含有^%& &apos;,;=?$\ "等字符： "[^%& &apos;,;=?$\x22]+ "。 
		21.只能输入汉字： "^[\u4e00-\u9fa5]{0,}$ " 
		22.验证URL： "^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$ "。 
		23.验证一年的12个月： "^(0?[1-9] ¦1[0-2])$ "正确格式为： "01 "～ "09 "和 "1 "～ "12 "。 
		24.验证一个月的31天： "^((0?[1-9]) ¦((1 ¦2)[0-9]) ¦30 ¦31)$ "正确格式为； "01 "～ "09 "和 "1 "～ "31 "。
		25."^\d+$ "　　//非负整数（正整数 + 0） 
		26."^[0-9]*[1-9][0-9]*$ "　　//正整数 
		27."^((-\d+) ¦(0+))$ "　　//非正整数（负整数 + 0） 
		28."^-[0-9]*[1-9][0-9]*$ "　　//负整数 
		29."^-?\d+$ "　　　　//整数 
		30."^\d+(\.\d+)?$ "　　//非负浮点数（正浮点数 + 0）
		31."^(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*))$ "　　//正浮点数 
		32."^((-\d+(\.\d+)?) ¦(0+(\.0+)?))$ "　　//非正浮点数（负浮点数 + 0） 
		33."^(-(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*)))$ "　　//负浮点数
		34."^(-?\d+)(\.\d+)?$ "　　//浮点数 
		35."^[A-Za-z]+$ "　　//由26个英文字母组成的字符串
		36."^[A-Z]+$ "　　//由26个英文字母的大写组成的字符串 
		37."^[a-z]+$ "　　//由26个英文字母的小写组成的字符串 
		38."^[A-Za-z0-9]+$ "　　//由数字和26个英文字母组成的字符串 
		39."^\w+$ "　　//由数字、26个英文字母或者下划线组成的字符串
		40."^[\w-]+(\.[\w-]+)*@[\w-]+(\.[\w-]+)+$ "　　　　//email地址
		41."^[a-zA-z]+://(\w+(-\w+)*)(\.(\w+(-\w+)*))*(\?\S*)?$ "　　//url 
		42.提取信息中的网络链接: (h ¦H)(r ¦R)(e ¦E)(f ¦F) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		43.提取信息中的邮件地址: \w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)* 
		44.提取信息中的图片链接: (s ¦S)(r ¦R)(c ¦C) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		45.提取信息中的ip地址: (\d+)\.(\d+)\.(\d+)\.(\d+) 
		46.提取信息中的中国手机号码: (86)*0*13\d{9} 
		47.提取信息中的中国固定电话号码: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{8} 
		48.提取信息中的中国电话号码（包括移动和固定电话）: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{7,14} 
		49.提取信息中的中国邮政编码: [1-9]{1}(\d+){5} 
		50.提取信息中的中国身份证号码: \d{18} ¦\d{15} 
		51.提取信息中的整数： \d+ 
		52.提取信息中的浮点数（即小数）：(-?\d*)\.?\d+ 
		53.提取信息中的任何数字 ： (-?\d*)(\.\d+)? 
		54.提取信息中的中文字符串： [\u4e00-\u9fa5]* 
		55.提取信息中的双字节字符串 (汉字)：[^\x00-\xff]* 
		56.提取信息中的英文字符串：\w*
		57.提取任意HTML标记之间的内容：<script[\s\S]+</script *>
		58.高强度日期验证
		     ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-))$

		59.高强度日期+时间验证
		    ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-)) (20|21|22|23|[0-1]?\d):[0-5]?\d:[0-5]?\d$

		从上面我们可以看到: "^ "表示后面紧跟着的字符为开头;与之相对应的式 "$ "以紧跟前面的字符为结尾.但是要注意的式当 "^ "位于 "[] "里时,表示 "非 "的意思,例如:[^AZ]表示不能为 "AZ "中的任一个字符. "[] "表示当中的一个字符. "{} "可以取得一个范围,例如 "{9} "表示9个,而 "{1,9} "表示1到9个字符. 

		正则调试工具：
		/Files/yasin/RegexTester.zip 
		来自：http://www.cnblogs.com/yasin/archive/2009/07/20/1527013.html

* Squid cache 
	- squid搭设CDN
		------
		主服务器群,然后在利用Squid逆向缓存web80端口来加速自己的网站.各大门户网站象163,sina,chinaitlab之类基本都是使用的这种技术,好处是大大的有.比如加速了网络和可以防黑客（因为他们见到的都是CDN的主机）
		这是利用Squid逆向集群模式做的一种应用

		网络环境：

		主服务器群：源Web服务器群 位于公网ip:220.XXX.XXX.X port:80(后台才是WEB的服务器)

		注: 要保证TCP80,UDP3130在防火墙上是开的(供icp_port通讯使用,多台Squid集群才会用到)

		全国各地分服务器：A服务器公网IP111.xxx.xxx.x

		B服务器公网ip112.xxx.xxx.x

		注: 要保证TCP80,UDP3130在防火墙上是开的(供icp_port通讯使用,多台Squid集群才会用到)

		……………………
		需要解决的问题：

		全国的所有用户,无论是电信,还是网通,都能速度很好的打开网站

		实施

		1）分别在主服务器群和全国各地分服务器的三台服务器安装Squid,不会安装的请直接关闭本网页.

		2）分别配置Squid,这里只重点叙述Squid集群配置要点.

		主服务器群Squid的配置：

		http_port 220.XXX.XXX.X:80 vhost vport #让Squid监听本机ip的80端口

		icp_port 3130 #多台squid通信使用

		cache_peer “内网web服务器的地址” parent 80 0 no-query originserver no-digest name=cache0 #设置源Web服务器群的ip和端口

		cache_peer 220.XXX.XXX.X sibling 80 3130 name=cache1 #让远程的squid连接本地Squid工作在sibling模式并指定其端口

		cache_peer 111.xxx.xxx.x sibling 80 3130 name=cache2 #A服务器

		cache_peer 112.xxx.xxx.x sibling 80 3130 name=cache3 #B服务器

		cache_peer_domain cache0 www.php-oa.com #配置本机squid允许接受访问的域名

		acl Safe_ports port 80

		acl Safe_ports port 3130 #允许以上端口的代理

		全国各地分服务器Squid的配置：

		A服务器：

		http_port 111.xxx.xxx.x:80 vhost vport

		icp_port 3130

		cache_peer 220.xxx.xxx.x parent 81 0 no-query originserver no-digest name=cache0 #设置主服务器群Web服务器为源服务器

		cache_peer 111.xxx.xxx.x sibling 80 3130 name=cache1

		cache_peer 220.xxx.xxx.x sibling 80 3130 name=cache2

		cache_peer 112.xxx.xxx.x sibling 80 3130 name=cache3

		cache_peer_domain cache0 www.php-oa.com

		acl Safe_ports port 80

		acl Safe_ports port 3130

		B服务器：

		http_port 112.xxx.xxx.x:80 vhost vport

		icp_port 3130

		cache_peer 220.xxx.xxx.x parent 80 0 no-query originserver no-digest name=cache0

		cache_peer 112.xxx.xxx.x sibling 80 3130 name=cache1

		cache_peer 220.xxx.xxx.x sibling 80 3130 name=cache2

		cache_peer 111.xxx.xxx.x sibling 80 3130 name=cache3

		cache_peer_domain cache0 www.php-oa.com

		acl Safe_ports port 80

		acl Safe_ports port 3130
		虽然配置好了但是如何让电信和网通的用户能有选择的访问两个不同镜像呢？这个请各位自己查相关的资料,要不到https://www.dnspod.com申请双线,电信网通的转发服务

		注:下面看看cache_peer的参数

		通过squid.conf配置文件中的cache_peer选项来配置代理服务器阵
		列,通过其他的选项来控制选择代理伙伴的方法.Cache_peer的使用格式如下：
		cache_peer  hostname type http_port icp_port
		共有5个选项可以配置：
		1） hostname:指被请求的同级子代理服务器或父代理服务器.可以用主机名或ip地址表示；
		2）type：指明hostname的类型,是同级子代理服务器还是父代理服务器,也即parent（父） 还是 sibling（子）；
		3）http_port：hostname的监听端口；
		4）icp_port：hostname上的ICP监听端口,对于不支持ICP协议的可指定7；
		5） options：可以包含一个或多个关键字.
		Options可能的关键字有：
		1） proxy-only：指明从peer得到的数据在本地不进行缓存,缺省地,squid是要缓存这部分数据的；
		2） weight=n：用于你有多个peer的情况,这时如果多于一个以上的peer拥有你请求的数据时,squid通过计算每个peer的ICP响应时间来 决定其weight的值,然后squid向其中拥有最大weight的peer发出ICP请求.也即weight值越大,其优先级越高.当然你也可以手工 指定其weight值；
		3） no-query：不向该peer发送ICP请求.如果该peer不可用时,可以使用该选项；
		4） Default：有点象路由表中的缺省路由,该peer将被用作最后的尝试手段.当你只有一个父代理服务器并且其不支持ICP协议时,可以使用default和
		no-query选项让所有请求都发送到该父代理服务器；
		5）login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证.

		curl -I http://www.xxx.com
		------
		ref: http://www.php-oa.com/2007/12/27/squid-dnspod.html
	- Why should I deploy Squid?
		(Or.. "Why should I bother with web caching? Can't I just buy more bandwidth?")
		The developers of the HTTP protocol identified early on that there was going to be exponential growth in content and, concerned with distribution mechanisms, added powerful caching primitives.
		These primitives allow content developers and distributors to hint to servers and end-user applications how content should be validated, revalidated and cached. This had the effect of dramatically reducing the amount of bandwidth required to serve content and improved user response times.
		Squid is one of the projects which grew out of the initial content distribution and caching work in the mid-90s. It has grown to include extra features such as powerful access control, authorization, logging, content distribution/replication, traffic management and shaping and more. It has many, many work-arounds, new and old, to deal with incomplete and incorrect HTTP implementations.
		
		For ISPs: Save on bandwidth, improve user experience
		Squid allows Internet Providers to save on their bandwidth through content caching. Cached content means data is served locally and users will see this through faster download speeds with frequently-used content.
		A well-tuned proxy server (even without caching!) can improve user speeds purely by optimising TCP flows. Its easy to tune servers to deal with the wide variety of latencies found on the internet - something that desktop environments just aren't tuned for.
		Squid allows ISPs to avoid needing to spend large amounts of money on upgrading core equipment and transit links to cope with ever-demanding content growth. It also allows ISPs to prioritise and control certain web content types where dictacted by technical or economic reasons.
		
		For Websites: Scale your application without massive investment in hardware and development time
		Squid is one of the oldest content accelerators, used by thousands of websites around the world to ease the load on their servers. Frequently-seen content is cached by Squid and served to the end-client with only a fraction of the application server load needed normally. Setting up an accelerator in front of an existing website is almost always a quick and simple task with immediate benefits.
		
		For Content Delivery Providers: distribute your content worldwide
		Squid makes it easy for content distributors and streaming media developers to distribute content worldwide. CDN providers can buy cheap PC hardware running Squid and deploy in strategic locations around the internet to serve enormous amounts of data cheaply and efficiently.
		A large number of companies have deployed servers running Squid in the past in exactly this manner.

	- Squid cache（简称为Squid）是一个流行的自由软件（GNU通用公共许可证）的代理服务器和Web缓存服务器。
		Squid有广泛的用途，从作为网页服务器的前置cache服务器缓存相关请求来提高Web服务器的速度，到为一组人共享网络资源而缓存万维网，域名系统和其他网络搜索，
		到通过过滤流量帮助网络安全，到局域网通过代理上网。Squid主要设计用于在Unix一类系统运行。
	- 代理服务器和Web缓存服务器
	- Lighttpd->Squid->Apache :架构：
			上述处理链，Lighttpd在最前面，专门处理静态内容的请求，把动态内容请求通过 Proxy模块转发给Squid，如果Squid中有该请求的内容且没有过期，
		则直接返回给Lighttpd。新请求或者过期的页面请求交由Apache 中的脚本程序来处理。经过Lighttpd和Squid的两级过滤，Apache需要处理的请求大大减少，
		减少了Web应用程序的压力。同时这样的构架，便于把不同的处理分散到多台计算机上进行，由Lighttpd在前面统一分发。 
			在这种架构下，每一级都是可以进行单独优化的，比如Lighttpd可以采用异步IO方式，Squid可以启用内存来缓存，Apache可以启用 MPM（Multi -Processing Modules，
		多道处理模块）等，并且每一级都可以使用多台机器来均衡负载，伸缩性好。
	- summary
			Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. 
		Squid has extensive access controls and makes a great server accelerator. It runs on most available operating systems, including Windows and is licensed under the GNU GPL.
			Making the most of your Internet Connection
			Squid is used by hundreds of Internet Providers world-wide to provide their users with the best possible web access. Squid optimises the data flow between client and server to improve 
		performance and caches frequently-used content to save bandwidth. Squid can also route content requests to servers in a wide variety of ways to build cache server hierarchies which 
		optimise network throughput.
			Website Content Acceleration and Distribution
			Thousands of web-sites around the Internet use Squid to drastically increase their content delivery. Squid can reduce your server load and improve delivery speeds to clients. Squid can also be used 
		to deliver content from around the world - copying only the content being used, rather than inefficiently copying everything. Finally, Squid's advanced content routing configuration allows you to build 
		content clusters to route and load balance requests via a variety of web servers.
		
		[The Squid systems] are currently running at a hit-rate of approximately 75%, effectively quadrupling the capacity of the Apache servers behind them. This is particularly noticeable when a large surge 
		of traffic arrives directed to a particular page via a web link from another site, as the caching efficiency for that page will be nearly 100%. " - Wikimedia Deployment Information. 
	ref: http://www.squid-cache.org/Intro/
* hadoop
	- HDFS HA部署相关	  VIP部署 NFS部署
	1) HDFS HA部署之VIP(Virtual IP Address)部署
		在HA中会有2个NameNode：Active NameNode 和Standby NameNode，刚启动时2个NN都处于Standby状态，然后手动（或自动：ZooKeeper自动选举）将一个NN变成Active状态。
		Client端有几种方法进行Failover：

		向ZooKeeper询问：
		Client每次访问NN时，先向ZooKeeper询问当前的Active NameNode，这样就能得到正确地址，如果期间发生Failover，则Client可以再向ZooKeeper询问一次，并和新的
		Active NameNode进行通信。貌似fb就是采用这种方式。

		使用Smart Client：
		Client端配置2个NameNode的地址信息，Client每次连接时先选择一个NN的地址信息，并和其建立联系，如果该NN是Standby NameNode，则Client会收到一个StandbyException，
		然后Client换一个NN进行尝试。这样最后经过2次尝试，Client就可以建立和Active NameNode的通信。社区版的代码使用这种方式。

		使用VIP：
		虽然在HA中，有2个NN，但是对于Client，只需要Active NameNode的信息。因此可以使用VIP（Virtual IP Address）方式来进行Failover。
		•	方法：
		(1).	给Active NameNode指定一个VIP;
		(2).	Client端只配置一个VIP地址信息，即Active NameNode的地址;
		(3).	当一个NameNode变成Active 状态时，同时在该节点上配置VIP;
		(4).	当发生Failover时，不光进行NN的状态切换，还停用Standby上的VIP，启用Active上的VIP;
		(5).	当Client和Active NameNode通信出现异常时会进行尝试，一直等到Failover完成。
		这种方法和Smart Client相似，不同之处在于现在只在一个VIP上进行尝试，不用切换。这样升级时，Client不用修改配置文件，当集群规模大，Client很多时，这种方式代价小。
		VIP部署
		接着介绍如何部署VIP
		假设VIP为10.220.99.120,部署在网卡0上，网关为10.220.99.254：
		(1).	将VIP：10.220.99.120绑定到网卡0上;
		(2).	通知网关，这一步是必须的，这样Client可以立即感知该VIP;
		(3).	挂载fstab下所有选项;
		(4).	执行命令如下所示，需要root权限：
		sudo ifconfig bond0:0 10.220.99.120 netmask 255.255.255.0 up

		sudo arping -c 1 -s 10.220.99.120 10.220.99.254
			man arping说明
			-----
			SYNOPSIS
				 arping [ -AbDfhqUV]  [ -c count]  [ -w deadline]  [ -s source]  -I interface destination
			DESCRIPTION
				Ping destination on device interface by ARP packets, using source address source.
			OPTIONS
				-c count
					stop after sending count ARP REQUEST packets. With deadline option, arping  waits  for  count  ARP REPLY packets, until the timeout expires.
				-s source
					IP source address to use in ARP packets.  If this option is absent, source address is:
					In DAD mode (with option -D) set to 0.0.0.0.
					In Unsolicited ARP mode (with options -U or -A) set to destination.
					Otherwise, it is calculated from routing tables.
			-----

		sudo mount -a
		如果要停用VIP，则需要执行：
		sudo /sbin/ifconfig bond0:0 down
		如何自动输入密码：
		由于执行VIP相关命令需要root权限，如果当前用户不是root则需要输入密码，此时可以使用，来自动输入密码。
		•	假设用户root密码为：123456;
		•	并且节点上已经安装expect，如果没有安装，则可以下载软件包安装，或使用yum install来安装，这里不详述;
		启用VIP的shell脚本：
		#!/usr/bin/expect

		spawn sudo /sbin/ifconfig bond0:0 10.220.99.120 netmask 255.255.255.0 up
		expect {
			"Password:"   {send -- "123456\r"}
			}
		expect "#"
		spawn sudo /sbin/arping -c 1 -s 10.220.99.120 10.220.99.254
		expect {
			"Password:"   {send -- "123456\r"}
			}

		expect "#"
		spawn sudo /bin/mount -a
		expect {
			"Password:"   {send -- "123456\r"}
			}

		expect "#"
		停用VIP的shell脚本：
		#!/usr/bin/expect
		spawn sudo /sbin/ifconfig bond0:0 down

		expect {
			"Password:"   {send -- "123456\r"}
			}
		expect "#"
		from: http://zhangjie.me/ha_vip/

	- 提供暴露rest方式的service
		rest实现应该用了jersey(jersey jar)
	- sbin/hadoop-setup-hdfs.sh
		用户问题
		Optional parameters:
		     --format                                                        Force namenode format
		     --group=hadoop                                                  Set Hadoop group
		     -h                                                              Display this message
		     --hdfs-user=hdfs                                                Set HDFS user
		     --kerberos-realm=KERBEROS.EXAMPLE.COM                           Set Kerberos realm
		     --hdfs-user-keytab=/home/hdfs/hdfs.keytab                       Set HDFS user key tab
		     --mapreduce-user=mr                                             Set mapreduce user			
	- install		     参考：http://blog.csdn.net/starxu85/article/details/2120412
		svn: https://svn.apache.org/repos/asf/hadoop/common/tags/release-1.0.3/
			编译安装，要考虑jdk版本，ant版本，hadoop版本
		
		或者直接下rpm包安装，目录prefix不支持不推荐

		下载tar包，解压即可: 
			http://mirror.bjtu.edu.cn/apache/hadoop/common/stable/hadoop-1.0.3.tar.gz
			tar -xvf  hadoop-1.0.3.tar.gz	     （避免rpm包安装，文件散落在各个目录中）
			设置hadoop-env.sh配置java环境

		user
			groupadd hadoop
			useradd -d /hadoop/home -g hadoop hadoop
			chown -R hadoop:hadoop /hadoop 修改目录所有者
			passwd hadoop hadooppassword
		
		ssh无密码登陆（user hadoop）
		
		rpm安装，不指定prefix，默认安装
			/etc/hadoop/hadoop-env.sh
				设置环境参数，java配置等等
			hadoop-site.xml
				配置
		/etc/init.d/hadoop/hadoop-namenode statt
		tail -f /var/log/hadoop/xxx.log

		hadoop账户启动服务，执行目录，日志目录，通过chown让hadoop具有权限。

	-  这里先大致介绍一下Hadoop.
			本文大部分内容都是从官网Hadoop上来的。其中有一篇介绍HDFS的pdf文档，里面对Hadoop介绍的比较全面了。我的这一个系列的Hadoop学习笔记
		    也是从这里一步一步进行下来的，同时又参考了网上的很多文章，对学习Hadoop中遇到的问题进行了归纳总结。
			言归正传，先说一下Hadoop的来龙去脉。谈到Hadoop就不得不提到Lucene和Nutch。首先，Lucene并不是一个应用程序，而是提供了一个纯Java的高性能
		全文索引引擎工具包，它可以方便的嵌入到各种实际应用中实现全文搜索/索引功能。Nutch是一个应用程序，是一个以Lucene为基础实现的搜索引擎应用，
		Lucene为Nutch提供了文本搜索和索引的API，Nutch不光有搜索的功能，还有数据抓取的功能。在nutch0.8.0版本之前，Hadoop还属于Nutch的一部分，而从nutch0.8.0开始，
		将其中实现的NDFS和MapReduce剥离出来成立一个新的开源项目，这就是Hadoop，而nutch0.8.0版本较之以前的Nutch在架构上有了根本性的变化，那就是完全构建在
		Hadoop的基础之上了。在Hadoop中实现了Google的GFS和MapReduce算法，使Hadoop成为了一个分布式的计算平台。
		   其实，Hadoop并不仅仅是一个用于存储的分布式文件系统，而是设计用来在由通用计算设备组成的大型集群上执行分布式应用的框架。
		   Hadoop包含两个部分：

		   1)HDFS

		      即Hadoop Distributed File System (Hadoop分布式文件系统)
				HDFS具有高容错性，并且可以被部署在低价的硬件设备之上。HDFS很适合那些有大数据集的应用，并且提供了对数据读写的高吞吐率。HDFS是一个master/slave的结构，
		      就通常的部署来说，在master上只运行一个Namenode，而在每一个slave上运行一个Datanode。
		      HDFS支持传统的层次文件组织结构，同现有的一些文件系统在操作上很类似，比如你可以创建和删除一个文件，把一个文件从一个目录移到另一个目录，
		      重命名等等操作。Namenode管理着整个分布式文件系统，对文件系统的操作（如建立、删除文件和文件夹）都是通过Namenode来控制。 
		     下面是HDFS的结构：

				从上面的图中可以看出，Namenode，Datanode，Client之间的通信都是建立在TCP/IP的基础之上的。当Client要执行一个写入的操作的时候，命令不是马上就发送
		      到Namenode，Client首先在本机上临时文件夹中缓存这些数据，当临时文件夹中的数据块达到了设定的Block的值（默认是64M）时，Client便会通知Namenode，
		      Namenode便响应Client的RPC请求，将文件名插入文件系统层次中并且在Datanode中找到一块存放该数据的block，同时将该Datanode及对应的数据块信息告诉Client，
		      Client便这些本地临时文件夹中的数据块写入指定的数据节点。
				HDFS采取了副本策略，其目的是为了提高系统的可靠性，可用性。HDFS的副本放置策略是三个副本，一个放在本节点上，一个放在同一机架中的另一个节点上，
		      还有一个副本放在另一个不同的机架中的一个节点上。当前版本的hadoop0.12.0中还没有实现，但是正在进行中，相信不久就可以出来了。

		   2) MapReduce的实现

			      MapReduce是Google 的一项重要技术，它是一个编程模型，用以进行大数据量的计算。对于大数据量的计算，通常采用的处理手法就是并行计算。至少现阶段而言，
		      对许多开发人员来说，并行计算还是一个比较遥远的东西。MapReduce就是一种简化并行计算的编程模型，它让那些没有多少并行计算经验的开发人员也可以开发并行应用。
				MapReduce的名字源于这个模型中的两项核心操作：Map和 Reduce。也许熟悉Functional Programming（函数式编程）的人见到这两个词会倍感亲切。简单的说来，
		      Map是把一组数据一对一的映射为另外的一组数据，其映射的规则由一个函数来指定，比如对[1, 2, 3, 4]进行乘2的映射就变成了[2, 4, 6, 8]。Reduce是对一组数据进行归约，
		      这个归约的规则由一个函数指定，比如对[1, 2, 3, 4]进行求和的归约得到结果是10，而对它进行求积的归约结果是24。
		      关于MapReduce的内容，建议看看孟岩的这篇MapReduce:The Free Lunch Is Not Over!

		   好了，作为这个系列的第一篇就写这么多了，我也是刚开始接触Hadoop，下一篇就是讲Hadoop的部署，谈谈我在部署Hadoop时遇到的问题，也给大家一个参考，少走点弯路。

		- 公钥认证过程 数字签名 非对称加密
			简单的说，在dbrg-1上需要生成一个密钥对，即一个私钥，一个公钥。将公钥拷贝到dbrg-2，dbrg-3上，这样，比如当dbrg-1向dbrg-2发起ssh连接的时候，
		dbrg-2上就会生成一个随机数并用dbrg-1的公钥对这个随机数进行加密，并发送给dbrg-1；dbrg-1收到这个加密的数以后用私钥进行解密，并将解密后的数发送回dbrg-2，
		dbrg-2确认解密的数无误后就允许dbrg-1进行连接了。这就完成了一次公钥认证过程。

* MapReduce 
	MapReduce is a programming model for processing large data sets with a parallel, distributed algorithm on a cluster.

* gfs
	一曰google file system	   (google)
	一曰global file system  (redhat)

* mina 以及基于mina的应用，如apache的纯java ftp server
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
	It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.

	 Apache FtpServer
		The Apache FtpServer is a 100% pure Java FTP server. It's designed to be a complete and portable FTP server engine solution based on currently available open protocols. 
		FtpServer can be run standalone as a Windows service or Unix/Linux daemon, or embedded into a Java application. We also provide support for integration within Spring 
		applications and provide our releases as OSGi bundles.
		from：http://mina.apache.org/ftpserver/index.html
	mina：http://mina.apache.org/downloads.html

The default network support is based on Apache MINA, a high performance asynchronous IO library. Using MINA, FtpServer can scale to a large number of concurrent users.

It is also an FTP application platform. We have developed a Java API to let you write Java code to process FTP event notifications that we call the Ftplet API. Apache FtpServer provides an implementation of an FTP server to support this API.

* Confluence 2.9.
	- 企业级 wiki ，便于交流互动 ，文档修改并记录历史类似版本控制，可以回滚，很是方便
* junit
	- 参考开源框架使用junit的方式 eg: metaq
	- junit fixture工作
		方法执行前准备工作，可以通过注解来配置，比如 @Before表示在每个用例执行前都行执行这个before注解的方法。

	-	请牢记！请牢记这一条 JUnit 最佳实践：测试任何可能的错误。单元测试不是用来证明您是对的，而是为了证明您没有错。
		JUnit 深入
		当然，JUnit 提供的功能决不仅仅如此简单，在接下来的内容中，我们会看到 JUnit 中很多有用的特性，掌握它们对您灵活的编写单元测试代码非常有帮助。
		Fixture
			何谓 Fixture ？它是指在执行一个或者多个测试方法时需要的一系列公共资源或者数据，例如测试环境，测试数据等等。在编写单元测试的过程中，
		您会发现在大部分的测试方法 在进行真正的测试之前都需要做大量的铺垫——为设计准备 Fixture 而忙碌。这些铺垫过程占据的代码往往比真正测试的代码多得多，
		而且这个比率随着测试的复杂程度的增加而递增。当多个测试方法都需要做同样的铺垫时，重复代 码的“坏味道”便在测试代码中弥漫开来。这股“坏味道”会弄脏您的代码，
		还会因为疏忽造成错误，应该使用一些手段来根除它。
			JUnit 专门提供了设置公共 Fixture 的方法，同一测试类中的所有测试方法都可以共用它来初始化 Fixture 和注销 Fixture。和编写 JUnit 测试方法一样，
		公共 Fixture 的设置也很简单，您只需要：
		1).使用注解 org,junit.Before 修饰用于初始化 Fixture 的方法。
		2).使用注解 org.junit.After 修饰用于注销 Fixture 的方法。
		3).保证这两种方法都使用 public void 修饰，而且不能带有任何参数。

* test * mock  * jmock		       * 单元测试 * 集成测试		 * jtester

	- 测试File文件
		动态生成，测试结束后删除
		-----
		    @Test
		    public void testReadAllContentFromFile() throws Exception{
			
			File f = new File("temp");
			FileOutputStream fos = new FileOutputStream(f);
			fos.write("hello".getBytes());
			
			String actual = ReadFromFile.readAllContentFromFile(f.getAbsolutePath());
			
			Assert.assertEquals(actual, "hello");
			
			fos.close();
			
			f.delete();
		    }
		-----
	- jtester mock静态私有方法
		-----
		 //mock slb master
		@Test
		public void testCreateLb2(){

		new MockUp<SlbOperatonUtils>(){
		    @SuppressWarnings("unused")
		    @Mock
		    public String executePost(String url){
			return "{\"code\":200,\"msg\":\"successful\",\"data\":{\"lb_id\":\"12345678-region_id\",\"eip\":\"10.250.6.36\"}}";
		    }
		};

		String[] actual = SlbOperatonUtils.createLb(regionNo, userId, masterUrl);

		System.out.println(actual);
		Assert.assertNotNull(actual);
		}
		...
		...
		private static String executePost(String url){
			String resultStr = null;
			try {
			    resultStr = Request.Post(url).execute().returnContent().asString();
			} catch (ClientProtocolException e) {
			    e.printStackTrace();
			} catch (IOException e) {
			    e.printStackTrace();
			}
			
			return resultStr;
		};
		-----
		PS: 这里createLb方法，将http调用部分独立出方法，便于解耦和单元测试 -tip-
		mock静态方法

	    @Test
	    public void testReloadCache(){
		
		new MockUp<ApiProxyOperationUtils>(){
		    @SuppressWarnings("unused")
		    @Mock
		    public String executeGet(String url){//此为静态私有方法，可去掉static声明，并改为public
			return "{\"code\": 200, \"msg\": \"reset all regions success.\"}";
		    }
		};
		
		ResultDomain actual = ApiProxyOperationUtils.reloadCache("testIp");
		
		Assert.assertTrue(actual.getCode() == 200);
		
	    }

	- jtester
		框架在测试方法前，准备数据时，开启了事务，插入了几条记录
		方法中的操作需要再次开启事务，对插入的记录修改时，由于与原事务不一致，导致事务等待，产生死锁，测试方法执行失败？
		解决方案：

		jtester的运行过程，事务的管理机制？
			测试框架通过替换spring上下文中的datasource实例为一个proxy来达到框架和被测试到的datasource为同一个并管理事务的目的，正确情况下datasource对应的
			实例应该被替换，但此案例下没有被替换，导致事务不一致，原因？




	- jtester抽象类方法的测试, mock一个抽象类实现
		写一个mock类继承抽象类，并在spring测试配置中注入
		<bean id="abstractService" class="com.aliyun.slb.api.service.impl.AbstractServiceMockImpl">
			<property name="rsService" ref="rsService" />
		</bean>

		测试类
			---------
			@SpringBeanByName
			AbstractService abstractService;

			@Test
			public void testName2ipInLocal() throws Exception{
				/* json格式1 */
				final String jsonStr = "[\"vm1\",\"vm2\"]";
				final String expected = "10.1.1.1";
				final String expected2 = "10.1.1.2";
				
				RequestContextHolder.getContext().setRegion(new Region());
				RequestContextHolder.getContext().setUser(new User());
				
				new MockUp<AbstractService>(){
					@Mock
					public Map<String, Object> getParamsMap() {
						Map<String,Object> map = new HashMap<String, Object>();
						map.put("rs_list", new String[]{jsonStr});
						return map;
					}
				};
				
				new Expectations(){
					@Mocked(methods={"queryInstanceIp"})
					RsServiceImpl rsService;
					{
						when(rsService.queryInstanceIp(anyString, anyString, anyString)).thenReturn(expected);
						when(rsService.queryInstanceIp(anyString, anyString, anyString)).thenReturn(expected2);
					}
				};
				
				Result<Object> actual = abstractService.name2ipInLocal("rs_list");
				List<Rs> rsList = (List<Rs>)actual.getResultInfo();
				
				Assert.assertEquals(rsList.get(0).getIp(),expected);
				Assert.assertEquals(rsList.get(1).getIp(),expected2);
				
				/* json格式2 */
				final String jsonStr2 = "[{\"vm_name\":\"vm1\",\"weight\":100},{\"vm_name\":\"vm2\",\"weight\":100}]";
				final String expected3 = "10.1.1.1";
				final String expected4 = "10.1.1.2";
				
				RequestContextHolder.getContext().setRegion(new Region());
				RequestContextHolder.getContext().setUser(new User());
				
				new MockUp<AbstractService>(){
					@Mock
					public Map<String, Object> getParamsMap() {
						Map<String,Object> map = new HashMap<String, Object>();
						map.put("rs_list", new String[]{jsonStr2});
						return map;
					}
				};
				
				new Expectations(){
					@Mocked(methods={"queryInstanceIp"})
					RsServiceImpl rsService;
					{
						when(rsService.queryInstanceIp(anyString, anyString, anyString)).thenReturn(expected3);
						when(rsService.queryInstanceIp(anyString, anyString, anyString)).thenReturn(expected4);
					}
				};
				
				Result<Object> actual2 = abstractService.name2ipInLocal("rs_list");
				List<Rs> rsList2 = (List<Rs>)actual.getResultInfo();
				
				Assert.assertEquals(rsList2.get(0).getIp(),expected);
				Assert.assertEquals(rsList2.get(1).getIp(),expected2);
			}
			---------
	- jtest用unitils的@SpringBeanByName注解时注意，注解的属性可以不在spring里配置，需要通过其他类注入了此属性来测试
	- 定义期望执行expectation时，如果步骤多，不易于定位那里不对			  -tip-
		可以通过化整为零方式，去掉所有的期望，从第一个执行开始，结合debug逐步补充上执行过程中需要的expectation。
		需要什么就mock或expect什么
				
	- jtester mock 自身方法，私有方法等
		------
			new MockUp<AbstractExecuteAction>() {
						@SuppressWarnings("unused")
						@Mock
						public ResultDomain getResourceOwner(){
							ResultDomain result = ResultDomainVisitor.createSuccessResult();
							Map<String,Object> map = new HashMap<String, Object>();
							map.put(GroupParameter.RESOURCE_OWNER.getName(), "1");
							result.setData(map);
							return result;
						}
					};
		------

		私有方法，可在mock块中声明为public类型，例如：
		----
		...
			new MockUp<xxxServiceImpl>(){
				@SuppressWarnings("unused")
				@Mock
				public void removeXXX(List<xxx> xxx) {//原方法为private，此处定义为public以免执行时报无access权限
					//do nothing
				}
			};
		...
		----
	- jtester
		mock时，可通过比较未mock对象和mocked对象的运行状态值（cglib or jdk proxy）来判断是否正确mock了。
	- 单元测试ok后，可以进行集成测试，以测试集成逻辑调用是否ok，比如各个环节的集成调用。
		
	- 查找框架已提供的mock类
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。
	- jtester ,用jmock框架
		写期望 Expectations 时，要注意按照调用次序写 -tip-
				a. 
					when(resourceQueryFacade.query(Instance.class, (String[])any)).thenReturn(new Instance[]{new Instance(),new Instance()}); //java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Lcom.aliyun.houyi.entity.Instance;
				b. 
					//resourceQueryFacade.query(Instance.class, (String[])any);
					//returnValue(new Instance[]{new Instance(),new Instance()});
				上面2中写法结果不一样。
		报 unexpected invocation 错误时，一般为expectation顺序不对，或者个数不对，比如某个方法有2个拦截器判断，就需要写2个expectation
			可以通过一步步 debug 找到那里写的不对（笨了点，但实用，终极解决 ~~）
				主要是通过反射执行代码，debug时要注意。debug也帮助理解mock测试的过程。比如：方法执行前会先执行方法拦截器。 -tip-
				“ ----------- 一步步的debug，验证执行逻辑是否符合预期，也能知道是什么原因导致用例执行失败。----------"
					是expectation顺序不对，还是数目不对或是其他，都可找到。
		如果一个对象被mock了，那么每次调用的expectation需要编写，否则返回null（在一些场合就会报错）
	- void mock 无返回值方法mock mock void
		直接mock那个对象或相应的方法，不做处理即可。
	- new Expectations(){
		理解Expectations的含义：
			Expectations即期望，录制期望发生的动作（设置期望返回值），执行时，按照期望的顺序执行（如不是期望定义的顺序会报错）。
		期望Expectations与mock的关系？
			expectations里 要按照执行顺序写期望逻辑。
				否则报调用错误 unexpected invocation xxx
		参考下面jmock的说明：
			JMockit Expectations

			TheJMockit Expectationsmocking API provides arecord-replaymodel for writingbehavior-basedtests. In this model, a test
			begins by setting one or moreexpectationson the invocations made from code under test to its collaborators (dependencies). 
				The classes and instances for such dependencies are established through the declaration of one or
			moremocked typesinside the test class/method. Such mocked types can be declared through instance fields of the test
			class or of an Expectations anonymous subclass inside a test method, and also through parameters of test methods
			(even though JUnit and TestNG don't allow regular test methods to have parameters). After expectations are defined in
			thisrecording phase, the test transitions to thereplay phase, when the code under test is exercised. The invocations that
			actually occur on the mocked collaborators are handled according to the mocked type declarations and the corresponding
			expectations recorded on them (if any). At the end of the replay phase, those expectations for which one or more
			invocations were expected are automatically verified so that missing invocations can be detected.
	- mock私有方法时，参数的设置方式如下，否则报类似错误：Invalid null value passed as argument 0 (instead of null, provide the Class object for the parameter type)
		
	- 单元测试
		做的好处多，特别对于合作开发，对可变情况的检测，功能完整性，逻辑错误等等。
	- junit mock
		执行顺序
			是否可以手动顺序调用用例？
		数据库测试支持 ，类似jtester?
	- easymock与junit结合 
		EasyMock:
			http://www.easymock.org/
			EasyMock provides Mock Objects for interfaces (and objects through the class extension) by generating them on the fly using Java's proxy mechanism. Due to EasyMock's unique style of recording expectations, most refactorings will not affect the Mock Objects. So EasyMock is a perfect fit for Test-Driven Development.
		例子：
			-----
			...
				public void testRegisterUser() {   
					User user = new User();   
					user.type = "vip";   
					userDao = createMock(UserDao.class);   
					expect(userDao.insertUser(user)).andReturn(true);   
					replay(userDao);   
					userService.setUserDao(userDao);   
					assertEquals(true, userService.registerUser(user));   
					verify(userDao);  
				} 
			...
			-----
* struts
	- struts.xml的package定义namespace，action的name属性定义uri，通过下面在action uri和所请求的action方法名之间加上叹号的方式定位到方法，称为动态方法调用。
	struts2请求方式：http://localhost:8080/luorigong/resourceManagerAction!listBigRegion.action?_dc=1372

	一个action包含多个请求处理的配置方式有下面几种： (对于共享数据，可以放到ThreadLocal中，类似struts的action可以从context中取一样)
	1）为Action配置method属性
		-----
		将Action类中的每一个处理方法都定义成一个逻辑Action方法。
		
		如上，把LoginAction中的login和regist方法都配置成逻辑Action。要调用login方法，则相应的把index.jsp中表单元素的action设置为"manage/userLogin.action"；
		要调用regist方法，把regist.jsp中表单元素的action设置为"manage/userRegist.action"。
		-----
	2）使用通配符映射(wildcard mappings)方式
		-----
		在struts.xml文件中配置<action…>元素时，它的name、class、method属性都可支持通配符，这种通配符的方式是另一种形式的动态方法调用。
		当我们使用通配符定义Action的name属性时，相当于用一个元素action定义了多个逻辑Action：
		<action name="user_*"
		class="org.qiujy.web.struts2.action.UserAction" method="{1}">
			    <result name="success">/success.jsp</result>
			    <result name="error">/error.jsp</result>
			</action>
		如上，<action name=”user_*”>定义一系列请求URL是user_*.action模式的逻辑Action。同时method属性值为一个表达式{1}，表示它的值是name属性值中第一个*的值。
		例如：用户请求URL为user_login.action时，将调用到UserAction类的login方法；用户请求URL为user_regist.action时，将调用到UserAction类的regist方法。
		-----
	3）动态方法调用
		-----
		DMI：Dynamic Method Invocation 动态方法调用。
		动态方法调用是指：表单元素的action不直接等于某个Action的名字，而是以如下形式来指定对应的动作名：
		<form method="post" action="userOpt!login.action">
		则用户的请求将提交到名为”userOpt”的Action实例，Action实例将调用名为”login”方法来处理请求。同时login方法的签名也是跟execute()一样，即为public String login() throws Exception。
		注意：要使用动态方法调用，必须设置Struts2允许动态方法调用，通过设置struts.enable.DynamicMethodInvocation常量来完成，该常量属性的默认值是true。
		-----
	ref: http://blog.csdn.net/zz_mm/article/details/5460397Struts2 XML配置详解

	- struts.xml
		配置package标签的namespace，路由请求
		配置action标签，name定义请求的uri

	- Struts2插件机制
		比如，struts与spring集成时，可以用spring来获取注入的对象，就是通过struts的配置struts.objectFactory=spring来完成
		下面为一篇介绍struts2插件机制的文章：
		-----
		方便为Struts2扩展功能。

		主要作用：

		简化开发，提高开发效率，有人写插件，封装技术细节，其他人使用；
		代码复用，封装的插件，可以重复利用；
		提高软件开发的质量，插件被反复使用，bug应该较少。

		Struts2 插件的文档：http://struts.apache.org/2.0.11/docs/plugins.html

		Struts2的插件机制，类似eclipse或者firefox的插件机制，和Struts1.x有很大区别。

		Struts2插件由单一的jar文件组成，包括：类文件和配置文件（扩展、替代或者添加到已有的框架功能中）。

		安装插件：通过复制（并且复制依赖jar文件）到classpath。

		配置插件：插件的jar文件中包含struts-plugin.xml，和struts.xml文件格式相同。

		该配置文件可以：

		定义新的package、result、interceptor、action
		覆盖框架的常量
		引入新的扩展点实现类
		框架中一些受欢迎，但是可选的属性通过插件方式发布。应用程序发布时可以留下所有插件，也可以只包含其中使用到的。插件可以包含在原始代码中，也可以是第三方发布的。

		注意：插件的加载没有特定次序。插件不能互相依赖。插件可以依赖struts2核心部分的类，但是不能依赖其他插件的类。

		框架加载配置文件的次序：

		struts-default.xml (bundled in the Core JAR)
		struts-plugin.xml (as many as can be found in other JARs)
		struts.xml (provided by your application)
		配置文件都加载完毕后，各个插件才可以使用这些配置。

		扩展点：

		com.opensymphony.xwork2.ObjectFactory：单例的，用于创建action、result和interceptor，属性是struts.objectFactory
		com.opensymphony.xwork2.ActionProxyFactory：创建Action的代理
		com.opensymphony.xwork2.util.ObjectTypeDeterminer：确定数据类型
		org.apache.struts2.dispatcher.mapper.ActionMapper：确定请求对应的action
		org.apache.struts2.dispatcher.multipart.MultiPartRequest：处理文件上传的请求
		org.apache.struts2.views.freemarker.FreemarkerManager：加载和处理freemarker的模板
		org.apache.struts2.views.velocity.VelocityManager：加载和处理velocity的模板
		-----
		ref: http://marshal.easymorse.com/archives/177
		struts2插件机制官网说明：http://struts.apache.org/release/2.0.x/docs/plugins.html

	- struts2一些线程对象的访问是通过ThreadLocal来实现线程共享的，如
		 org.apache.struts2.ServletActionContext
		 DOC
		 ---------
		Web-specific context information for actions. This class subclasses ActionContext which provides access to things like the action name, value stack, etc. 
		This class adds access to web objects like servlet parameters, request attributes and things like the HTTP session.

	- struts2请求处理流程
		一个请求在Struts2框架中的处理大概分为以下几个步骤：
		1 客户端初始化一个指向Servlet容器（例如Tomcat）的请求；
		2 这个请求经过一系列的过滤器（Filter）（这些过滤器中有一个叫做ActionContextCleanUp的可选过滤器，这个过滤器对于Struts2和其他框架的集成很有帮助，例如：SiteMesh Plugin）
		3 接着FilterDispatcher被调用，FilterDispatcher询问ActionMapper来决定这个请是否需要调用某个Action
		4 如果ActionMapper决定需要调用某个Action，FilterDispatcher把请求的处理交给ActionProxy
		5 ActionProxy通过Configuration Manager询问框架的配置文件，找到需要调用的Action类
		6 ActionProxy创建一个ActionInvocation的实例。
		7 ActionInvocation实例使用命名模式来调用，在调用Action的过程前后，涉及到相关拦截器（Intercepter）的调用。
		8 一旦Action执行完毕，ActionInvocation负责根据struts.xml中的配置找到对应的返回结果。返回结果通常是（但不总是，也可 能是另外的一个Action链）一个需要被表示的JSP或者FreeMarker的模版。在表示的过程中可以使用Struts2 框架中继承的标签。在这个过程中需要涉及到ActionMapper

		在上述过程中所有的对象（Action，Results，Interceptors，等）都是通过ObjectFactory来创建的。

		Struts2的目标很简单--使Web开发变得更加容易。为了达成这一目标，Struts2中提供了很多新特性，比如智能的默认设置、annotation的使用以及"惯例重于配置"原则的应用，
		而这一切都大大减少了XML配置。Struts2中的Action都是POJO，这一方面增强了Action本身的可测试性，另一方面也减小了框架内部的耦合度，而HTML表单中的输入项
		都被转换成了恰当的类型以供action使用。开发人员还可以通过拦截器（可以自定义拦截器或者使用Struts2提供的拦截器）来对请求进行预处理和后处理，这样一来，
		处理请求就变得更加模块化，从而进一步减小耦合度。模块化是一个通用的主题--可以通过插件机制来对框架进行扩展；开发人员可以使用自定义的实现来替换掉框架的关键类，
		从而获得框架本身所不具备的功能；可以用标签来渲染多种主题（包括自定义的主题）；Action执行完毕以后，可以有多种结果类型--包括渲染JSP页面，Velocity和Freemarker模板，
		但并不仅限于这些。最后，依赖注入也成了Struts2王国中的一等公民，这项功能是通过Spring框架的插件和Plexus共同提供的，与PicoContainer的结合工作还正在进行中
		from: http://blog.csdn.net/zhangxu3739/article/details/4028656

	- 拦截器直接返回
		设置结果到valueStack中，返回view
	- struts2的返回
		根据action的result的配置，定义返回值，可自定义一个result继承框架的result接口接口，在返回给client前进行特殊处理。

	- ValueStack valueStack = con.getValueStack();
			ResultDomain result = (ResultDomain)valueStack.findValue(ResultDomainVisitor.RESULT_KEY, ResultDomain.class);
	- ActionContext
		内部实现为 ThreadLocal
	- struts拦截器测试 ，interceptor 测试
		struts2框架提供了相应的mock类，便于测试 ，比如：
			com.opensymphony.xwork2.mock.MockActionInvocation
		spring框架页提供了struts框架等框架类的mock实现，方便测试 比如：org.springframework.mock.web.MockHttpServletRequest
		
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。

* bat 批处理 不继续执行  (搜素 bat 调用mvn - 对于bat执行好mvn后就不继续执行其他操作的问题解决搜索关键词) 脚本
	- 用pause命令实现 按任意键继续
		确认是否继续执行
	- bat自动化脚本
	停止多个RS，编译新包，替换新包，并启动所有RS
		-----
			echo deploy...

			echo ---------shutdown rs...
			cd D:\apache-tomcat-6.0.35\bin
			call shutdown.bat
			cd D:\apache-tomcat-6.0.35-2\bin
			call shutdown.bat
			
			pause

			echo ---------rmove old file...
			if exist D:\apache-tomcat-6.0.35\webapps\javaweb rd /s /q "D:\apache-tomcat-6.0.35\webapps\javaweb"

			if exist D:\apache-tomcat-6.0.35\webapps\javaweb.war rm -rf "D:\apache-tomcat-6.0.35\webapps\javaweb.war"

			if exist D:\apache-tomcat-6.0.35-2\webapps\javaweb rd /s /q "D:\apache-tomcat-6.0.35-2\webapps\javaweb"

			if exist D:\apache-tomcat-6.0.35-2\webapps\javaweb.war rm -rf "D:\apache-tomcat-6.0.35-2\webapps\javaweb.war"

			echo ---------build new package...
			cd D:\workspace2\javaweb-maven
			call mvn clean package

			echo ---------copy...
			cd target
			if exist javaweb.war cp javaweb.war D:\apache-tomcat-6.0.35\webapps

			if exist javaweb.war cp javaweb.war D:\apache-tomcat-6.0.35-2\webapps

			echo ---------starting rs
			cd D:\apache-tomcat-6.0.35\bin
			call startup.bat
			cd D:\apache-tomcat-6.0.35-2\bin
			call startup.bat

			exit 0
		-----
		在一些命令前加判断，避免因为异常导致脚本退出
	- start命令
		下面是一个小脚本，批量启动开机后需要打开的程序。
		pre.bat
		-----
		...
			echo day pre...
			echo chrome
			start C:\Users\wb_shen.chengs\AppData\Local\Google\Chrome\Application\chrome.exe
			echo eclipse
			start D:\eclipse\eclipse.exe
			echo outlook
			start outlook.exe /resetnavpane
			echo wangwang
			call "D:\PROGRA~1\AliWangWang\AliIM.exe" /run:desktop
		...
		------
	- mavn web project 自动部署启动容器脚本(bat脚本)
		-------
			rem Eclipse 开发 maven web project部署脚本，便于部署调试

			set "CATALINA_HOME=D:\apache-tomcat-6.0.35"
			set "PROJECT_DIR=D:\workspace\javaweb-branch-base"

			echo stop tomcat...
			cd %CATALINA_HOME%\bin
			call shutdown.bat

			echo build...
			cd %PROJECT_DIR%
			call mvn clean
			call mvn package

			echo delpoy...
			cd target
			cp -r javaweb.war %CATALINA_HOME%\webapps
			rm -r %CATALINA_HOME%\webapps\javaweb

			#cd ..
			#echo clean...
			#call mvn clean

			echo start tomcat...
			cd %CATALINA_HOME%\bin
			call startup.bat

			:end
		-------
	-
		在于不熟悉bat。联想到shell脚本，shell脚本会继续执行
		-------
			bat中mvn命令执行完后不继续执行的解决方法
			2012-04-24 17:29codeif.com 比如有下面一段批处理程序
			mvn clean
			echo “hello world”

			输出如下
			…..
			[INFO] BUILD SUCCESSFUL
			[INFO] ————————————————————————
			[INFO] Total time: 25 seconds
			[INFO] Finished at: Tue Apr 24 17:21:55 CST 2012
			[INFO] Final Memory: 43M/123M
			[INFO] ————————————————————————
			D:\test>

			hello world并没有输出,没有达到我们的预期
			在mvn前加上call,改为如下后
			call mvn clean
			echo “hello world”

			hello word就会输出了

			cmd命令行中Call的使用如下:
			Call 从一个批处理程序调用另一个批处理程序，并且不终止父批处理程序。
		------

* rest
	rest方式的请求，根据uri定位资源 ，各种http方法发送的请求 可以用matrix url请求rest服务

* Redis
	　　redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。
	http://redis.io/

* Memcached  
	- memcached解决单点实现HA方法
		1）通过集群实现HA
		repcached（memched主从复制），结合LVS的NAT模式不同端口转发实现memched双机HA。(区别于主备方式)
		ref: http://www.linuxidc.com/Linux/2013-04/82684.htm
		PS: 对于机器利用率问题，可以合理利用已有的机器资源，将memcached部署到内存消耗少的已有机器上。
		lvs主备互为HA，
		repcached是日本人开发的实现memcached复制功能，它是一个单 master单 slave的方案，但它的 master/slave都是可读写的，而且可以相互同步，如果 master坏掉， 
		slave侦测到连接断了，它会自动 listen而成为 master；而如果 slave坏掉， master也会侦测到连接断，它就会重新 listen等待新的 slave加入 ；master没有抢占功能，
		如果master挂掉再起来只能是从了，并且永远只能是从。ref: http://blog.csdn.net/sanshiqiduer/article/details/6336902	

	- 缓存系统MemCached的Java客户端优化历程 http://www.infoq.com/cn/articles/memcached-java
		参考
			用concurrent包替换原先synchronize关键字
		比较原client与优化后的client
			原whain客户端：https://github.com/gwhalin/Memcached-Java-Client.git
			优化后的客户端：http://memcache-client-forjava.googlecode.com/svn/trunk/memcache-client-forjava

			

	- HA的实现
		Memcached 是什么？
			Memcached是一种集中式Cache，支持分布式横向扩展。这里需要解释说明一下，很多开发者觉得Memcached是一种分布式缓存系统，
			但是其实Memcached服务端本身是单实例的，只是在客户端实现过程中可以根据存储的主键做分区存储，而这个区就是Memcached服务端的一个或者多个实例，
			如果将客户端也囊括到Memcached中，那么可以部分概念上说是集中式的。其实回顾一下集中式的构架，无非两种情况：一是节点均衡的网状（JBoss Tree Cache），
			利用JGroup的多播通信机制来同步数据；二是Master-Slaves模式（分布式文件系统），由Master来管理Slave，比如如何选择Slave，如何迁移数据等都是由Master来完成，
			但是Master本身也存在单点问题。下面再总结几个它的特点来理解一下其优点和限制。
		内存存储：
			不言而喻，速度快，但对于内存的要求高。这种情况对CPU要求很低，所以常常采用将Memcached服务端和一些CPU高消耗、内存低消耗应用部署在一起。
			（我们的某个产品正好有这样的环境，我们的接口服务器有多台，它们对CPU要求很高——原因在于WS-Security的使用，但是对于内存要求很低，因此可以
			用作Memcached的服务端部署机器）。
		集中式缓存（Cache）：
			避开了分布式缓存的传播问题，但是需要非单点来保证其可靠性，这个就是后面集成中所作的集群（Cluster）工作，可以将多个Memcached作为一个虚拟的集群，
			同时对于集群的读写和普通的Memcached的读写性能没有差别。
		分布式扩展：
			Memcached很突出的一个优点就是采用了可分布式扩展的模式。可以将部署在一台机器上的多个Memcached服务端或者部署在多个机器上的Memcached服务端组成
			一个虚拟的服务端，对于调用者来说则是完全屏蔽和透明的。这样做既提高了单机的内存利用率，也提供了向上扩容（Scale Out）的方式。
		Socket通信：
			这儿需要注意传输内容的大小和序列化的问题，虽然Memcached通常会被放置到内网作为缓存，Socket传输速率应该比较高（当前支持TCP和UDP两种模式，同时
			根据客户端的不同可以选择使用NIO的同步或者异步调用方式），但是序列化成本和带宽成本还是需要注意。这里也提一下序列化，对于对象序列化的性能往往
			让大家头痛，但是如果对于同一类的Class对象序列化传输，第一次序列化时间比较长，后续就会优化，也就是说序列化最大的消耗不是对象序列化，而是类的序列化。
			如果穿过去的只是字符串，这种情况是最理想的，省去了序列化的操作，因此在Memcached中保存的往往是较小的内容。
		特殊的内存分配机制：
			首先要说明的是Memcached支持最大的存储对象为1M。它的内存分配比较特殊，但是这样的分配方式其实也是基于性能考虑的，简单的分配机制可以更容易回收再分配，
			节省对CPU的使用。这里用一个酒窖做比来说明这种内存分配机制，首先在Memcached启动的时候可以通过参数来设置使用的所有内存——酒窖，然后在有酒进入的时候，
			首先申请（通常是1M）的空间，用来建酒架，而酒架根据这个酒瓶的大小将自己分割为多个小格子来安放酒瓶，并将同样大小范围内的酒瓶都放置在一类酒架上面。
			例如20厘米半径的酒瓶放置在可以容纳20-25厘米的酒架A上，30厘米半径的酒瓶就放置在容纳25-30厘米的酒架B上。回收机制也很简单，首先新酒入库，看看酒架是否有
			可以回收的地方，如果有就直接使用，如果没有则申请新的地方，如果申请不到，就采用配置的过期策略。从这个特点来看，如果要放的内容大小十分离散，同时大小比例
			相差梯度很明显的话，那么可能对于空间使用来说效果不好，因为很可能在酒架A上就放了一瓶酒，但却占用掉了一个酒架的位置。
		缓存机制简单：
			有时候很多开源项目做的面面俱到，但到最后因为过于注重一些非必要的功能而拖累了性能，这里提到的就是Memcached的简单性。首先它没有什么同步，消息分发，
			两阶段提交等等，它就是一个很简单的缓存，把东西放进去，然后可以取出来，如果发现所提供的Key没有命中，那么就很直白地告诉你，你这个Key没有任何对应的
			东西在缓存里，去数据库或者其他地方取；当你在外部数据源取到的时候，可以直接将内容置入到缓存中，这样下次就可以命中了。这里介绍一下同步这些数据的两种方式：
			一种是在你修改了以后立刻更新缓存内容，这样就会即时生效；另一种是说容许有失效时间，到了失效时间，自然就会将内容删除，此时再去取的时候就不会命中，然后
			再次将内容置入缓存，用来更新内容。后者用在一些实时性要求不高，写入不频繁的情况。
		客户端的重要性：
			Memcached是用C写的一个服务端，客户端没有规定，反正是Socket传输，只要语言支持Socket通信，通过Command的简单协议就可以通信。但是客户端设计的合理十分重要，
			同时也给使用者提供了很大的空间去扩展和设计客户端来满足各种场景的需要，包括容错、权重、效率、特殊的功能性需求和嵌入框架等等。
		几个应用点：
			小对象的缓存（用户的Token、权限信息、资源信息）；小的静态资源缓存；SQL结果的缓存（这部分如果用的好，性能提高会相当大，同时由于Memcached自身提供向上扩容，
			那么对于数据库向上扩容的老大难问题无疑是一剂好药）；ESB消息缓存。
		from: http://www.cnblogs.com/chenying99/archive/2012/06/29/2568958.html

	- 使用外部缓存框架，对应程序，通过统一接口调用，
	- memcached的交互接口
			memcached的客户端通过TCP连接与服务器通信（UDP协议的接口也可以使用，详细说明请参考”UDP 协议”部分）。一个给定的运行中的memcached服务器在某个（可配置的）端
		口上监听连接；客户端连接该端口，发送命令给服务器，读取反馈，最后关闭连接。
	       没有必要发送一个专门的命令去结束会话。客户端可以在不需要该连接的时候就关闭它。注意：我们鼓励客户端缓存它们与服务器的连接，而不是每次要存储或读取数据的时候再次重
	       新建立与服务器的连接。memcache同时打开很多连接不会对性能造成到大的影响，这是因为memcache在设计之处，就被设计成即使打开了很多连接（数百或者需要时上千个连接）也可
	       以高效的运行。缓存连接可以节省与服务器建立TCP连接的时间开销（于此相比，在服务器段为建立一个新的连接所做准备的开销可以忽略不计）。
	       memcache通信协议有两种类型的数据：文本行和非结构化数据。文本行用来发送从客户端到服务器的命令以及从服务器回送的反馈信息。非结构化的数据用在客户端希望存储或者读取
	       数据时。服务器会以字符流的形式严格准确的返回相应数据在存储时存储的数据。服务器不关注字节序，它也不知道字节序的存在。memcahce对非结构化数据中的字符没有任何限制，
	       可以是任意的字符，读取数据时，客户端可以在前次返回的文本行中确切的知道接下来的数据块的长度。
	       文本行通常以“"r"n”结束。非结构化数据通常也是以“"r"n”结束，尽管"r、"n或者其他任何8位字符可以出现在数据块中。所以当客户端从服务器读取数据时，必须使用前面提供的数据块的
	       长度，来确定数据流的结束，二不是依据跟随在字符流尾部的“"r"n”来确定数据流的结束，尽管实际上数据流格式如此。

	c 实现
	项目主页: http://code.google.com/p/memcached/wiki/Clients	
	说明：
		memcached is a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. 
	Danga Interactive developed memcached to enhance the speed of LiveJournal.com, a site which was already doing 20 million+ dynamic page views per day for 1 million users with a bunch of webservers and a bunch of database servers. memcached dropped the database load to almost nothing, yielding faster page load times for users, better resource utilization, and faster access to the databases on a memcache miss. 
	If you're a developer, or interested in helping us along, please help test the latest beta release on the download page. We work hard to ensure the beta releases are of high quality, but as with all beta software, be warned. 
	
	 开源的东西，潜力与生俱来
	
	启动：
		memcached -d -m 10 -u root -l 192.168.232.162  -p 12000 -c 256 -P /tmp/memcached.pid
		
		client: 官网说明：
			http://code.google.com/p/memcached/wiki/Clients
	安装：
		
		- 需要libevent库 需要制定prefix
			wget http://github.com/downloads/libevent/libevent/libevent-2.0.18-stable.tar.gz --no-check-certificate
			tar -zxvf libevent-2.0.18-stable.tar.gz
			./configure --prefix=/usr
			make
			make install
			再继续memcache安装
			例子：
					Linux下Memcache服务器端的安装
					服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
					下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
					另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
					官网：http://www.monkey.org/~provos/libevent/
					下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

					用wget指令直接下载这两个东西.下载回源文件后。
					1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
					2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
					这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

					    1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
					    # cd /tmp
					    # wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
					    # wget http://www.monkey.org/~provos/libevent-1.2.tar.gz

					    2.先安装libevent：
					    # tar zxvf libevent-1.2.tar.gz
					    # cd libevent-1.2
					    # ./configure –prefix=/usr
					    # make
					    # make install

					    3.测试libevent是否安装成功：
					    # ls -al /usr/lib | grep libevent
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
					    -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
					    -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
					    -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
					    还不错，都安装上了。

					    4.安装memcached，同时需要安装中指定libevent的安装位置：
					    # cd /tmp
					    # tar zxvf memcached-1.2.0.tar.gz
					    # cd memcached-1.2.0
					    # ./configure –with-libevent=/usr
					    # make
					    # make install
					    如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
					    安装完成后会把memcached放到 /usr/local/bin/memcached ，

					    5.测试是否成功安装memcached：
					    # ls -al /usr/local/bin/mem*
					    -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
					    -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug 

					安装Memcache的PHP扩展
					1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
					2.安装PHP的memcache扩展

					    tar vxzf memcache-2.2.1.tgz
					    cd memcache-2.2.1
					    /usr/local/php/bin/phpize
					    ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
					    make
					    make install

					3.上述安装完后会有类似这样的提示：

					    Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

					4.把php.ini中的extension_dir = “./”修改为

					    extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

					5.添加一行来载入memcache扩展：extension=memcache.so

					memcached的基本设置：
					1.启动Memcache的服务器端：
					# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

					    -d选项是启动一个守护进程，
					    -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
					    -u是运行Memcache的用户，我这里是root，
					    -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
					    -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
					    -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
					    -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

					2.如果要结束Memcache进程，执行：

					    # kill `cat /tmp/memcached.pid`

					也可以启动多个守护进程，不过端口不能重复。

					3.重启apache，service httpd restart

					Memcache环境测试：
					运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
					< ?php
					$mem = new Memcache;
					$mem->connect(”127.0.0.1″, 11211);
					$mem->set(’key’, ‘This is a test!’, 0, 60);
					$val = $mem->get(’key’);
					echo $val;
					?>
					来自：http://blog.csdn.net/21aspnet/article/details/6827316
					
				服务端启动ok
				设置client调用？

	- 访问linux虚拟机中的memcache,需要设置linux防火墙规则，否则不能访问服务 key=centos memcache 访问
		-------
			在虚拟机里安装了centos，在centos里安装memcached服务器,可是在本机里使用memcached的php扩展来访问虚拟机里centos的memcached服务时，没有响应，发现PHP的日志里有以下信息：
			[html] view plaincopyprint?
			01.[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。  
			[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。


			后来在网上找了一些资料，才找到解决办法。即是在centos的iptable增加两条规则，让用户可以访问虚拟机的memcached的服务。
			命令如下：
			#/sbin/iptables -I INPUT -p tcp --dport 11211 -j ACCEPT
			#/sbin/iptables -I INPUT -p udp --dport 11211 -j ACCEPT
			/etc/ini.d/iptabls save/status
			如果启动memcached服务时用了其他端口，在将你的端口号代替11211. 
		-------
	- 用了gwhalin 的Memcached-Java-Client  api，基本操作ok

	这个java版本的memcached客户端，实现了多memcached集群实例的存取支持(需要避免热点cache)。
		参看：SockIOPool类
			提供3种hash方式，不同的方法对缓存分布是否均匀有影响以及是否支持多client。说明如下：
				- SockIOPool.NATIVE_HASH (0)     - native String.hashCode() - fast (cached) but not compatible with other clients
				- SockIOPool.OLD_COMPAT_HASH (1)	- original compatibility hashing alg (works with other clients)
				- SockIOPool.NEW_COMPAT_HASH (2)	- new CRC32 based compatibility hashing algorithm (fast and works with other clients)
				- SockIOPool.CONSISTENT_HASH(3)	- MD5 Based -- Stops thrashing when a server added or removed
				以及consistent hash的实现，避免了key在服务节点列表上的重新分布，有的还实现了虚拟节点让缓存发布更加均匀。

	------
		public class test {

			public static void main(String[] args) {
				
				MemcachedClient mc = new MemcachedClient();
				
				mc.add("a", 1);
				
				System.out.println(mc.get("a"));
				
			}
			
			
			//inital iopool
			static {
				String[] serverlist = { "192.168.232.162:12000" };

				SockIOPool pool = SockIOPool.getInstance();
				pool.setServers(serverlist);
				pool.initialize();	
			}

			
		}
	------
* mongodb

* Elastic IP 弹性IP
	Elastic IP Addresses – Elastic IP addresses are static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account not a 
	particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to 
	mask instance or Availability Zone failures by programmatically remapping your public IP addresses to any instance in your account. Rather than waiting on a data technician 
	to reconfigure or replace your host, or waiting for DNS to propagate to all of your customers, Amazon EC2 enables you to engineer around problems with your instance or
	software by quickly remapping your Elastic IP address to a replacement instance. In addition, you can optionally configure the reverse DNS record of any of your Elastic IP
	addresses by filling out this form.

* json
	- json串转Bean时，如果Bean定义为内部类，则会报错
		说属性的set方法找不到；同样，从内部类的Bean转为json对象也会报get方法找不到。    即使是静态内部类
		环境：net.sf.json.JSONObject json-lib-2.2.3.jar

		Property 'code' has no getter method in class 'class test.json.pojo2$pojo3'
		Property 'code' has no setter method in class 'class test.json.pojo2$pojo3'

	- 测试 json转换为map对象
		String str3 = "{\"code\":200,\"msg\":\"successful\",\"data\":{ \"lb_id\":\"123\",\" eip\":\"10.250.6.36\"}}";
		Map map3 = (Map)JSONObject.toBean(JSONObject.fromObject(str3),HashMap.class);
		System.out.println(map3.get("msg"));//successful
* ibatis
	- mapping文件写法一例
		-----
		<select id="selectClusterByIdcId" parameterClass="Long" resultClass="cluster">
			<include refid="select-region" />  
			<dynamic prepend="WHERE">
			  <isNotEmpty prepend="and" property="bigRegionId"> 
			      big_region_id =  #bigRegionId# 
			 </isNotEmpty>
		    </dynamic>
		</select>
		-----
	- DAO测试时，创建记录语句需要结合ibatis的key select配置来返回id，若未配置返回的是null，即插入操作无返回值
		-----
		<selectKey resultClass="long" keyProperty="id">  
		<![CDATA[
		SELECT LAST_INSERT_ID() AS ID 
		]]>    
		</selectKey>
		-----
	- houyi api使用ibatis没有使用cacheModel的原因
		由于houyi api的部署有多个，且各自相互独立，如果启用缓存，可能会出现一台API机器RS1缓存了某些数据，但另一台RS2却修改了db数据，RS2的缓存
		根据配置会随即更新，但RS1的缓存却无法触发更新。

		解决方法之一：使用同一缓存，比如使用memcached统一缓存；统一缓存部分设计为可替换方式，比如后面如果需要替换缓存实现服务。

		OSCache支持分布式缓存，了解下它是如何保证分布式环境下的一致性的？
	- ibatis+oscache
		

	- sqlmap配置文件中的CacheModel
	cacheModel
		A cacheModel is used to describe a cache for use with a  query mapped statement. Each query mapped statement can use a different cacheModel, or the same 
		one. The following example will demonstrate how it looks related to a statement: 

		<cacheModel id="product-cache" type="LRU">
			<flushInterval hours="24"/>
			<flushOnExecute statement="insertProduct"/>
			<flushOnExecute statement="updateProduct"/>
			<flushOnExecute statement="deleteProduct"/>
			<property name=”size” value=”1000” />
		</cacheModel>

		<select id=”getProductList” parameterClass=”int” cacheModel=”product-cache”>
			select * from PRODUCT where PRD_CAT_ID = #value#
		</select>
		
		In the above example, a cache is defined for products that uses a WEAK reference type and flushes every 24 hours or whenever associated update statements are executed.

		PS:  cacheModel用于查询缓存
			
			标签说明：
			Element : flushInterval
				Defines the interval of when the cache will be flushed. There can be only one flush interval element 
				 and it can be set using hours, minutes, seconds or milliseconds.
			Element : flushOnExecute
				Defines that the cache will be flushed when the specified statement is executed. There can be any 
				 number of "flush on execute" elements specified for a cache.
			Element : property
				Defines a standard Java property. Is used by various elements to define settings.

	- spring对ibatis的支持
		提供模板类 SqlMapClientTemplate ，对于批量操作需要使用其SqlMapClientCallback回调类来实现。
		下面是模板类的部分doc说明：
		It is generally recommended to use the convenience methods on this template for plain query/insert/update/delete operations. However, for more complex operations 
		like batch updates, a custom SqlMapClientCallback must be implemented, usually as anonymous inner class. For example: 

		 getSqlMapClientTemplate().execute(new SqlMapClientCallback() {
			 public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
				 executor.startBatch();
				 executor.update("insertSomething", "myParamValue");
				 executor.update("insertSomethingElse", "myOtherParamValue");
				 executor.executeBatch();
				 return null;
			 }
		 });

	- 缓存及其扩展
		比如结合memcached使用(oscache为默认配置)
		iBatis提供CacheController接口，用于实现第三方缓存架构的扩展
		http://blog.csdn.net/ecsoftcn/article/details/1777904
		
		memcached整合ibatis
		ibatis自带的本地缓存有FIFO，LRU(Least Recently Used)等，对于分布式缓存也有osCache支持，而最常用的memcached也可以整合到ibatis里滴，这样通过map关系配置，就省了很多硬编码。
		http://www.cnblogs.com/langke93/archive/2011/03/30/2217387.html

		iBatis整理——EhCache支持扩展
		http://snowolf.iteye.com/blog/1481969

		目的：
			ibatis结合memcached实现分布式缓存(比如查询缓存)

		基于上面小节下，ibatis默认没有内置memcached的缓存支持，但是设计上已考虑到缓存实现的不同，提供了CacheController接口用于自定义缓存实现，基于这个接口ibatis内置实现了
		FIFO,LRU,OSCACHE,MEMERY，现在可以自己实现用于memcached的CacheController实现，再进行相应的配置即可。这里可以学习下ibatis的接口设计，易于扩展，也体现了对于涉及具体
		实现的地方需要考虑是否需要扩展，从而设计为接口。-tip- * 架构 * 设计 * 扩展
	- ibatis也支持简单的内置对象返回
		比如用queryList方法返回resultClass="hashmap"的List<Map>数据结构

	- mapping文件语句定义
		插入数据时，返回其主键（自定义查询的主键）
		<insert id="insertImage" parameterMap="imageParameter">
		insert into xxx(id,new_id,name)
		values(?,?,?)
		<selectKey resultClass="long" keyProperty="newId">
			select last_insert_id() as new_id from xxx limit 1
		</selectKey>
		</insert>

	- mapping文件，标签属性的意义整理：     there is a trick if u ignore this^^ 
		比如<select></select>标签中：
			resultMap	  自定义返回结果bean的map映射定义，通过map定义将结果集映射为bean	 ,将查询结果集映射到不同的对象
				返回对象为自定义的class
			resultClass 基本类
				返回对象为标准class
			parameterMap 自定义参数bean到参数map的映射，可以定义参数对象的属性如何映射到SQL查询语句的动态参数上
			paremeterClass 基本参数类


	- ibatis属性转换，自定义转换 TypeHandlerCallback
		通过在mapping文件中直接定义或者统一定义
		（1）各自的mapping文件中	（sqlMap）
			<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
			<typeAlias alias="snapshotStorageTypeHandler" type="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>	
			<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER" typeHandler="snapshotStorageTypeHandler"/>
		（2）在config文件中统一配置（sqlMapConfig）
			<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
			<typeHandler javaType="snapshotStorageType" callback="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>
		eg：
			<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER"/>
	- where calse的共用需要设计好，否则反而增加维护
		<isNotEqual>语句需要注意，类似if..else，可能会意外带入条件，最好还是用匹配上的条件去判断<isNotEmpty>,<isEqual>
	- in查询，条件sql
		select 
			xx
		 from xx
		 where  
		 <iterate property="userIds" prepend=" xx " open="(" close=")" conjunction=",">
			#ids[]#
		 </iterate> 
	- ibatis mapping文件检查       ，ibatis启动
		会验证每个语句的传入参数/对象是否和定义的名称一致，不一致报出来相应的语句错误。	单元测试加载ibatis框架以验证mapping文件格式正确。
	- * SQL预编译
		下面我们就来详细看一下有关预编译的一些知识。
		   1、什么是预编译语句
		   预编译语句PreparedStatement 是java.sql中的一个接口，它是Statement的子接口。通过Statement对象执行SQL语句时，需要将SQL语句发送给DBMS，由DBMS首先进行编译后再执行。预编译语句和Statement不同，在创建PreparedStatement 对象时就指定了SQL语句，该语句立即发送给DBMS进行编译。当该编译语句被执行时，DBMS直接运行编译后的SQL语句，而不需要像其他SQL语句那样首先将其编译。
		   2、什么时候使用预编译语句
		   一般是在需要反复使用一个SQL语句时才使用预编译语句，预编译语句常常放在一个fo r或者while循环里面使用，通过反复设置参数从而多次使用该SQL语句。为了防止SQL注入漏洞，在某些数据操作中也使用预编译语句。
		   3、为什么使用预编译语句
		   预编译机制除了在开篇提到的可以防止SQL注入外，还有一下两方面的优点：
		   (1)提高效率
		   数据库处理一个SQL语句，需要完成解析SQL语句、检查语法和语义以及生成代码，一般说来，处理时间要比执行语句所需要的时间长。预编译语句在创建的时候已经是将指定的SQL语句发送给了DBMS，完成了解析、检查、编译等工作。因此，当一个SQL语句需要执行多次时，使用预编译语句可以减少处理时间，提高执行效率。
		   (3)提高代码的可读性和可维护性
		   将参数与SQL语句分离出来，这样就可以方便对程序的更改和扩展，同样，也可以减少不必要的错误。
		   4、预编译语句的使用
		   代码段二中创建了包含带两个 IN 参数占位符的 PreparedStatement 对象，在执行之前，必须设置每个 ? 参数的值。这可通过调用 setXXX 方法来完成，该方法的第一个参数是要设置的参数的序数位置，第二个参数是设置给该参数的值，其中 XXX 是与该参数相应的类型。例如，以下代码将第一个参数设为 “tom”，第二个参数设为 “123456a”：
		   pstmt.setString(1, “tom”);
		   pstmt.setString(2, “123456a”);
		   一旦设置了给定语句的参数值，其值将一直保留，直到被设置为新值或者调用clearParameters()方法清除它为止。
		   问题延伸：请大家看一下以下的代码：
		    String sqlSt = “sel ect* from table1 where name=”+tb_name+” and passwo rd=”+tb_pwo rd;
		   PrepareStatement pst = con.createPreparementStatement();
		   ResultSet rsPst = pst.exe cuteQuery(sqlSt);
		 
		    那么在安全性和执行效率方面会不会有问题呢？请感兴趣的同事可以自己尝试一下吧。
		    from：http://www.52testing.com/showart.asp?id=67

	- ibatis 与sql注入
		假设用户执行
		    select * from product where id = 5 
		    这条语句。其中5是有用户输入的。
		    SQL注入的含义就是，一些捣蛋用户输入的不是5，而是
		    5;  delete  from  orders
		    那么原来的SQL语句将会变为，
		    select * from product where id=5;  delete  from  orders 
		    在执行完select后，还将删除orders表里的所有记录。（如果他只删了这些记录，已经谢天谢地了，他可能会做更可怕地事情）。
		    不过庆幸的是，Ibatis使用的是预编译语句（PreparedStatement
		    s ）。

		    上述语句会被编译为，
		    select * from product where id=? 
		    从而有效防止SQL注入。
		    不过当你使用$占位符时就要注意了。
		     
		    例如：动态的选择列和表
		    SELECT * FROM $TABLE_NAME$ WHERE $COLUMN_NAME$ = #value# 
		     
		    这时你一定要仔细过滤那些值以避免SQL注入。当然这种情况不只存在Ibatis中。		
			参考资料：
			【iBATIS in Action】3.5.2 SQL injection 
		    from: http://www.2cto.com/Article/201203/124648.html
		
		总结：
			正如上文所说，动态选择列或表或构造排序等操作时，需要手工过滤那些值以避免sql注入。
			当需要编程来避免sql注入时，可以通过工具类处理错位参数的字符，转义特殊字符。

	- ibatis配置文件的 typeHandler 标签配置类型转换处理方式
		·实现 com.aliyun.slb.api.dao.support.TypeHandlerCallback 接口
	- 动态where条件
		<dynamic prepend="WHERE">
			<isNotEmpty property="ip">
				ip=#ip#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="lbId">
				lb_id=#lbId#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="rsPoolName">
				rs_pool_name=#rsPoolName#
			</isNotEmpty>
		</dynamic>	
	- ibatis debug sql 执行语句位置
		com.ibatis.sqlmap.engine.execution.SqlExecutor
			public void executeQuery(StatementScope statementScope, Connection conn, String sql, Object[] parameters, int skipResults, int maxResults, RowHandlerCallback callback) throws SQLException {
	- Ibatis中#与$的区别？
		1) #是把传入的数据当作字符串，如#field#传入的是id,则生成sql语句:order by "id";
		2) $传入的数据直接生成在sql里，如#field#传入的是id,则sql语句生成是这样，order by id ;
		3) #方式能够很大程度防止sql注入, 但$方式无法防止sql注入;
		4) $方式一般用于传入数据库对象．例如传入表名;
		5) 一般能用#的就别用$ ;
	- iBatis与Hibernate区别
		1) iBatis 需要手写sql语句，也可以生成一部分，Hibernate则基本上可以自动生成，偶尔会写一些Hql。同样的需求,iBATIS的工作量比 Hibernate要大很多。
		类似的，如果涉及到数据库字段的修改，Hibernate修改的地方很少，而iBATIS要把那些sql mapping的地方一一修改。
		2) iBatis 可以进行细粒度的优化
		比如说我有一个表，这个表有几个或者几十个字段，我需要更新其中的一个字段，iBatis 很简单，执行一个sql UPDATE TABLE_A SET column_1=#column_1# 
		WHERE id=#id# 但是用 Hibernate 的话就比较麻烦了,缺省的情况下 hibernate 会更新所有字段。 当然我记得 hibernate 有一个选项可以控制只保存修改过的字段，
		但是我不太确定这个功能的负面效果。
		例如：我需要列出一个表的部分内容，用 iBatis 的时候，这里面的好处是可以少从数据库读很多数据，节省流量SELECT ID, NAME FROM TABLE_WITH_A_LOT_OF_COLUMN 
		WHERE ...一般情况下Hibernate 会把所有的字段都选出来。比如说有一个上面表有8个字段，其中有一两个比较大的字段，varchar(255)/text。上面的场景中我
		为什么要把他们也选出来呢？用hibernate 的话，你又不能把这两个不需要的字段设置为lazy load，因为还有很多地方需要一次把整个 domain object 加载出来。
		这个时候就能显现出ibatis 的好处了。如果我需要更新一条记录（一个对象），如果使用 hibernate，需要现把对象 select 出来，然后再做 update。这对数据库来说
		就是两条sql。而iBatis只需要一条update的sql就可以了。减少一次与数据库的交互，对于性能的提升是非常重要。
		3)开发方面：
		开发效率上，我觉得两者应该差不多。可维护性方面，我觉得 iBatis 更好一些。因为 iBatis 的 sql 都保存到单独的文件中。而 Hibernate 在有些情况下可能会在
		java 代码中保sql/hql。相对Hibernate“O/R”而言，iBATIS 是一种“Sql Mapping”的ORM实现。 而iBATIS 的着力点，则在于POJO 与SQL之间的映射关系。也就是说
		，iBATIS并不会为程序员在运行期自动生成SQL 执行。具体的SQL 需要程序员编写，然后通过映射配置文件，将SQL所需的参数，以及返回的结果字段映射到
		指定POJO。使用iBATIS 提供的ORM机制，对业务逻辑实现人员而言，面对的是纯粹的Java对象，这一层与通过Hibernate 实现ORM 而言基本一致，而对于具体
		的数据操作，Hibernate会自动生成SQL 语句，而iBATIS 则要求开发者编写具体的SQL 语句。相对Hibernate而言，iBATIS 以SQL开发的工作量和数据库移植性上的
		让步，为系统设计提供了更大的自由空间。
		4) 运行效率
		在不考虑 cache 的情况下，iBatis 应该会比hibernate 快一些或者很多。
		5）hibernate提供一级，二级缓存的支持；ibatis只有二级缓存的支持

* aqua 
	ctrl + d -- desc table
* 遍历 map.entrySet()
		Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		
		Assert.assertEquals(map.size(), 2);
		Set<Entry<String,IMetaData>> set = map.entrySet();
		for(Entry<String, IMetaData> data:set){
 * Amoeba
		Amoeba for MySQL致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的时候充当query 路由功能，
	专注 分布式数据库 proxy 开发。座落与Client、DB Server(s)之间。对客户端透明。具有负载均衡、高可用性、Query过滤、读写分离、
	可路由相关的query到目标数据库、可并发请求多台数据库合并结果。 在Amoeba上面你能够完成多数据源的高可用、负载均衡、数据切片的功能。
		目前在很多企业的生产线上面使用。
	from: http://xfshean.blog.163.com/blog/static/60206566201272224458578/
* mysql
	- Mysql 查看连接数,状态    kill连接
		命令： show processlist; 
		如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。 
		show processlist;只列出前100条，如果想全列出请使用show full processlist; 
		mysql> show processlist;
		from: http://blog.csdn.net/starnight_cbj/article/details/4492555

	KILL [CONNECTION | QUERY] thread_id

	- mysql超时设置，设置超时
		配置mysql服务器超时时间，以满足测试场景

		show global variables like "%timeout%";

		interactive_timeout=28800
		The number of seconds the server waits for activity on an interactive connection before closing it. An interactive client is defined as a client that uses the CLIENT_INTERACTIVE 
		option to mysql_real_connect(). See also wait_timeout.

	- mysql终端，汉字显示，乱码问题
		mysql --default-character-set=utf8
		指定编码的数据库连接方式来解决

		or
		进入mysql终端后，再设置编码格式

	- 字符串拼接
		MySQL的concat函数可以连接一个或者多个字符串,如....
		from: http://richelace.blog.sohu.com/101765008.html
	- mysql case when then语句 sql逻辑语句
	-----
			case 
        	when odbs.db_type='ecs_region' then region.cluster_name
        	else null 
		end clusterName,
		case 
        	when odbs.db_type='ecs_bigregion' then bregion.name
        	else null 
		end bigRegionName,
		case 
        	when odbs.db_type='ecs_houyiapi' then hapi.vip
        	else null 
		end houyiApiVip
	 from odbs odbs
	 left join room room on room.id=odbs.room_id
	 left join region region on region.id=odbs.id_type
	 left join big_region bregion on bregion.id=odbs.id_type
	 left join houyiapi hapi on hapi.id=odbs.id_type 
	-----
	此场景为某个id_type列存的是不同引用表的主键id，以db_type表示类型以指向特定的表；
	此查询动态根据条件从关联表中取对应的数据。

	参考：http://www.cnblogs.com/john2000/archive/2010/09/21/1832729.html mysql 语句case when
		-----
		表的创建
		CREATE TABLE `lee` (
		`id` int(10) NOT NULL AUTO_INCREMENT,  
		`name` char(20) DEFAULT NULL,  
		`birthday` datetime DEFAULT NULL,  
		PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8

		数据插入：

		insert into lee(name,birthday) values ('sam','1990-01-01');

		insert into lee(name,birthday) values ('lee','1980-01-01');

		insert into lee(name,birthday) values ('john','1985-01-01');

		 

		使用case when语句

		1)

		select name,
		 case 
			when birthday<'1981' then 'old'
			when birthday>'1988' then 'yong'
			else 'ok' END YORN
		from lee;

		 

		 

		2)

		select NAME,
		 case name
		     when 'sam' then 'yong'
			when 'lee' then 'handsome'
			else 'good' end
		from lee;

		 

		当然了case when语句还可以复合

		3)

		select name,birthday,
		 case 
		     when birthday>'1983' then 'yong'
			when name='lee' then 'handsome'
			else 'just so so ' end
		from lee;

		  

		在这里用sql语句进行日期比较的话，需要对年加引号。要不然可能结果可能和预期的结果会不同。我的mysql版本5.1

		当然也可以用year函数来实现，以第一个sql为例

		select NAME,
		 CASE
		     when year(birthday)>1988 then 'yong'
			when year(birthday)<1980 then 'old'
			else 'ok' END
		from lee;
					 
		create table penalties
		(
		 paymentno INTEGER not NULL,
		    payment_date DATE not null,
		    amount DECIMAL(7,2) not null,
		    primary key(paymentno)
		)

		insert into penalties values(1,'2008-01-01',3.45);
		insert into penalties values(2,'2009-01-01',50.45);
		insert into penalties values(3,'2008-07-01',80.45);


		(1)#对罚款登记分为三类，第一类low，包括大于0小于等于40的罚款，第二类moderate大于40
		#到80之间的罚款，第三类high包含所有大于80的罚款。

		(2)#统计出属于low的罚款编号。

		 

		第一道题的解法与上面的相同
		select paymentno,amount,
		 case 
		     when amount>0 and amount<=40 then 'low'
			when amount>40 and amount<=80 then 'moderate'
			when amount>80 then 'high'
			else 'incorrect' end lvl
		from `penalties`

		(3)#统计出属于low的罚款编号。重点看这里的解决方法
		方法1.
		select paymentno,amount
		from `penalties`
		where case 
		 when amount>0 and  amount<=40 then 'low'
		    when amount>40 and amount<=80 then 'moderate'
		    when amount>80 then 'high'
		    else 'incorrect' end ='low';

		方法2
		select * 
		from (select paymentno,amount,
		 case 
		     when amount>0 and amount<=40 then 'low'
			when amount>40 and amount<=80 then 'moderate'
			when amount>80 then 'high'
			else 'incorrect' end lvl
		from `penalties`) as p
		where p.lvl='low';
		-----

	- mysql报错分析
		sql语句错误，mysql会从错误开始时做提示，比如下面的提示：
		You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'room.name idcName,    hapi.vip houyiApiVip   from realserver rs    left join roo' at line 1
		错误就发生在其引用sql片段的开始位置。

	- mysql锁查询，行锁查询

	- 设置编码类型，字符编码 ；cmd默认连接到mysql汉字显示为乱码
		mysql> show variables like 'character%';
		+--------------------------+----------------------------+
		| Variable_name            | Value                      |
		+--------------------------+----------------------------+
		| character_set_client     | latin1                     |
		| character_set_connection | utf8                       |
		| character_set_database   | latin1                     |
		| character_set_filesystem | binary                     |
		| character_set_results    | latin1                     |
		| character_set_server     | latin1                     |
		| character_set_system     | utf8                       |
		| character_sets_dir       | /usr/share/mysql/charsets/ |
		+--------------------------+----------------------------+
		8 rows in set (0.00 sec)	

		set character_set_client=utf8
		...
		设置为下面的结果即可：
		mysql> show variables like 'charac%';
		+--------------------------+----------------------------+
		| Variable_name            | Value                      |
		+--------------------------+----------------------------+
		| character_set_client     | utf8                       |
		| character_set_connection | utf8                       |
		| character_set_database   | utf8                       |
		| character_set_filesystem | binary                     |
		| character_set_results    | utf8                       |
		| character_set_server     | utf8                       |
		| character_set_system     | utf8                       |
		| character_sets_dir       | /usr/share/mysql/charsets/ |
		+--------------------------+----------------------------+

		最好是在连接时指定编码，如下：
		mysql -uroot -pxxxx --default-character-set=utf8

	- 查看表空间信息
		如果想知道MySQL数据库中每个表占用的空间、表记录的行数的话，可以打开MySQL的 information_schema 数据库。在该库中有一个 TABLES 表，这个表主要字段分别是：
		TABLE_SCHEMA : 数据库名
		TABLE_NAME：表名
		ENGINE：所使用的存储引擎
		TABLES_ROWS：记录数
		DATA_LENGTH：数据大小 单位为字节
		INDEX_LENGTH：索引大小
		其他字段请参考MySQL的手册，我们只需要了解这几个就足够了。
		所以要知道一个表占用空间的大小，那就相当于是 数据大小 + 索引大小 即可。
		SQL:
		SELECT TABLE_NAME,DATA_LENGTH+INDEX_LENGTH,TABLE_ROWS FROM TABLES WHERE TABLE_SCHEMA='数据库名' AND TABLE_NAME='表名'

	- 导数据
		select into from	 (mysql不支持)
		insert into from
			eg:
				insert into Table1(field1,field2) select field1,1 from Table2;
		------
			如何在mysql从多个表中组合字段然后插入到一个新表中，通过一条sql语句实现。具体情形是：有三张表a、b、c，现在需要从表b和表c中
			分别查几个字段的值插入到表a中对应的字段。对于这种情况，我们可以使用如下的语句来实现：

			1) INSERT INTO db1_name(field1,field2) SELECT field1,field2 FROM db2_name
			      当然，上面的语句比较适合两个表的数据互插，如果多个表就不适应了。对于多个表，我们可以先将需要查询的字段join起来，然后组成一个视图后再select from就可以了：

			2) INSERT INTO a(field1,field2) SELECT * FROM(SELECT f1,f2 FROM b JOIN c) AS tb
			      其中f1是表b的字段，f2是表c的字段，通过join查询就将分别来自表b和表c的字段进行了组合，然后再通过select嵌套查询插入到表a中，这样就满足了我们这个场景了，如果需要不止2个表，那么可以多个join的形式来组合字段。需要注意的是嵌套查询部分最后一定要有设置表别名，如下：

			3) SELECT * FROM(SELECT f1,f2 FROM b JOIN c) AS tb
			      即最后的as tb是必须的（当然tb这个名称可以随意取），即指定一个别名，否则在mysql中会报如下错误：

			ERROR 1248 (42000): Every derived TABLE must have its own alias
			      即每个派生出来的新表都必须指定别名才可以的。
		------
		注：不同数据库支持的语法不同，可参考对应的使用说明

	- 主备切换 自动切换
		通过VIP（需要主备库IP在同一网段）
		通过DNS
		其他
	- master HA
		通过ZK竞选master
		MHA
			A primary objective of MHA is automating master failover and slave promotion within short (usually 10-30 seconds) downtime, without suffering from replication consistency problems, 
			without spending money for lots of new servers, without performance penalty, without complexity (easy-to-install), and without changing existing deployments.
			
			ref: http://code.google.com/p/mysql-master-ha

	- 用户被拒绝
		Access denied for user 'test'@'10.1.171.195'
		注意此处，'test'@'10.1.171.195整个对mysql来说是一个用户标识，不要纠结那个IP而误认为mysql连接到错误的IP上去了(配置都是对的啊???!!!)'



	- mysql注释
		create table xxx (
			xxx varchar(32) NOT NULL COMMENT '@desc xxx',
			xxx tinyint(1) unsigned DEFAULT '1' NOT NULL COMMENT '@descxxx',
			PRIMARY KEY(xxx,xxx)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='xxx';
		字段注释
		表注释

	- 事务隔离级别
		mysql默认事务隔离级别：
			mysql>help ISOLATION
			Query global and session transaction isolation levels:
				mysql>SELECT @@GLOBAL.tx_isolation, @@tx_isolation
					REPEATABLE-READ

		mysql 事务级别说明：
		--------
			The following list describes how MySQL supports the different
			transaction levels:

			o READ UNCOMMITTED

			  SELECT statements are performed in a nonlocking fashion, but a
			  possible earlier version of a row might be used. Thus, using this
			  isolation level, such reads are not consistent. This is also called a
			  "dirty read." Otherwise, this isolation level works like READ
			  COMMITTED.

			o READ COMMITTED

			  A somewhat Oracle-like isolation level with respect to consistent
			  (nonlocking) reads: Each consistent read, even within the same
			  transaction, sets and reads its own fresh snapshot. See
			  http://dev.mysql.com/doc/refman/5.1/en/innodb-consistent-read.html.

			  For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE),
			  InnoDB locks only index records, not the gaps before them, and thus
			  allows the free insertion of new records next to locked records. For
			  UPDATE and DELETE statements, locking depends on whether the
			  statement uses a unique index with a unique search condition (such as
			  WHERE id = 100), or a range-type search condition (such as WHERE id >
			  100). For a unique index with a unique search condition, InnoDB locks
			  only the index record found, not the gap before it. For range-type
			  searches, InnoDB locks the index range scanned, using gap locks or
			  next-key (gap plus index-record) locks to block insertions by other
			  sessions into the gaps covered by the range. This is necessary
			  because "phantom rows" must be blocked for MySQL replication and
			  recovery to work.

			  *Note*: In MySQL 5.1, if the READ COMMITTED isolation level is used
			  or the innodb_locks_unsafe_for_binlog system variable is enabled,
			  there is no InnoDB gap locking except for foreign-key constraint
			  checking and duplicate-key checking. Also, record locks for
			  nonmatching rows are released after MySQL has evaluated the WHERE
			  condition. As of MySQL 5.1, if you use READ COMMITTED or enable
			  innodb_locks_unsafe_for_binlog, you must use row-based binary
			  logging.

			o REPEATABLE READ

			  This is the default isolation level for InnoDB. For consistent reads,
			  there is an important difference from the READ COMMITTED isolation
			  level: All consistent reads within the same transaction read the
			  snapshot established by the first read. This convention means that if
			  you issue several plain (nonlocking) SELECT statements within the
			  same transaction, these SELECT statements are consistent also with
			  respect to each other. See
			  http://dev.mysql.com/doc/refman/5.1/en/innodb-consistent-read.html.

			  For locking reads (SELECT with FOR UPDATE or LOCK IN SHARE MODE),
			  UPDATE, and DELETE statements, locking depends on whether the
			  statement uses a unique index with a unique search condition, or a
			  range-type search condition. For a unique index with a unique search
			  condition, InnoDB locks only the index record found, not the gap
			  before it. For other search conditions, InnoDB locks the index range
			  scanned, using gap locks or next-key (gap plus index-record) locks to
			  block insertions by other sessions into the gaps covered by the
			  range.

			o SERIALIZABLE

			  This level is like REPEATABLE READ, but InnoDB implicitly converts
			  all plain SELECT statements to SELECT ... LOCK IN SHARE MODE if
			  autocommit is disabled. If autocommit is enabled, the SELECT is its
			  own transaction. It therefore is known to be read only and can be
			  serialized if performed as a consistent (nonlocking) read and need
			  not block for other transactions. (This means that to force a plain
			  SELECT to block if other transactions have modified the selected
			  rows, you should disable autocommit.)
		  --------
	- MySQL查询结果导出到文件
		选择某些行作为需要的数据
			SELECT id,dbname FROM `index` into outfile "d://aaa.txt";
		一般大家都会用 “SELECT INTO OUTFIL”将查询结果导出到文件，但是这种方法不能覆盖或者添加到已经创建的文件，下文为您介绍的这种方法则很好地解决了此问题。
		一般大家都会用 “SELECT INTO OUTFIL”将查询结果导出到文件，但是这种MySQL查询结果导出到文件方法不能覆盖或者添加到已经创建的文件。例如：
		mysql> select 1 into outfile '/tmp/t1.txt';  
			需要有写文件的权限
			chmod a+rw $DIR_NAME
			drwxrwxrwx
			owner group everyone

			Unix permissions concern who can read a file or directory, write to it, and execute it. Permissions are granted or withheld with a magic 3-digit number. 
			The three digits correspond to the owner (you); the group (?); and the world (everyone else).
			
	- 读写分离
		实现方式有2种：
			1）对应用透明，通过proxy方式（如mysql proxy等代理工具实现）
				    mysql proxy
					get mysql-proxy: http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.3-linux-rhel5-x86-64bit.tar.gz
					lua/lua-devel
					mysql-devel
					glib2-devel.x86_64
					libevent

					make
					make install

					/usr/local/bin/mysql-proxy 

					lua脚本

				    amoeba
					座落与Client、DB Server(s)之间。对客户端透明。具有负载均衡、高可用性、Query过滤、读写分离、可路由相关的query到目标数据库、可并发请求多台数据库合并结果
			2）在应用层实现读写分离（如可以配置多个数据源，按需要注入对应的数据源）
	- mysqlbinlog
		二进制日志
			主从复制，数据恢复。。。通过mysql的binlog
	- mysql主从复制 mysql用户管理

		环境：linux 2.6.32-220.el6.x86_64
			mysql  Ver 14.14 Distrib 5.1.61, for redhat-linux-gnu (x86_64) using readline 5.1

		下面以InnoDB引擎为例，说明配置主从复制的方法。
		 
		1) 配置/etc/my.cnf
			修改主服务器my.cnf，在[mysqld]中增加如下内容：
			##打开binlog
			log-bin=mysql-bin
			##服务器ID。服务器之间不能有重复ID，一般主是1
			server-id=1

			修改从服务器my.cnf，设置server-id=2。
			另外，主从服务器的ip和端口信息配置不在my.cnf里配置，整合到后面的change master命令里。
			修改了my.cnf，重启主从服务器：
			mysqladmin -uroot shutdown


		2) 主服务器上添加数据库复制用户
			在主服务器上，必须为从服务器创建主从复制的用户，并设置replication slave权限。所用具体命令如下：
			create user rep;
			grant replication slave on *.* to rep@'10.250.8.33' identified by '';
			flush privileges;
			10.250.8.33是从服务器，就通过rep用户密码为空来同步复制。通过查询user表查看Repl_slave_priv的值为Y：
			select * from mysql.user where user='rep'\G;

		3) 获取主服务器的快照：
			show master status\G;
				+------------------+----------+--------------+------------------+
				| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |
				+------------------+----------+--------------+------------------+
				| mysql-bin.000003 |      106 |              |                  |
				+------------------+----------+--------------+------------------+
			记录File 及Position 项的值，以便之后对从服务器进行配置。File是当前处理的binlog，
			Position是处理的binlog位置，这是从服务器的同步起点。

		4) 在从服务器上操作，连接主服务器开始同步数据：
			Change master to
			Master_host = '10.250.8.11',
			Master_port = 3306,
			Master_user = 'rep',
			Master_password = '',
			Master_log_file = 'mysql-bin.000003',
			Master_log_pos = 106;
			这里包含的信息有主机的地址和端口、主机提供的复制帐号、主机的binlog位置信息。Master_log_file和Master_log_pos是主服务器的快照信息，从服务器从该binlog的相应位置开始从主服务器同步数据。
			启动从服务器线程就可以开始同步了：
			start slave;
			一旦从服务器开始同步了，就能在数据文件目录下找到2个文件master.info和relay-log.info。从服务器利用这2个文件来跟踪处理了多少master的binlog。
			分别在主从服务器show processlist查看连接，就可以看到rep用户的连接，可证明复制已经生效。

		初步验证：
			
			a. 分别在主从服务器show processlist查看连接，就可以看到rep用户的连接，可证明复制已经生效。
				mysql> show processlist;
				+----+------+-------------------------+------+-------------+------+----------------------------------------------------------------+------------------+
				| Id | User | Host                    | db   | Command     | Time | State                                                          | Info             |
				+----+------+-------------------------+------+-------------+------+----------------------------------------------------------------+------------------+
				|  3 | rep  | vm3.mytest.com.cn:39581 | NULL | Binlog Dump |  920 | Has sent all binlog to slave; waiting for binlog to be updated | NULL            
			b. 或者查看mysql的日志，查看复制情况
				tail -f -n100 /var/log/mysqld.log

				从mysql的log：
					120917 14:45:36 [ERROR] Slave I/O: error reconnecting to master 'rep@10.250.8.11:3306' - retry-time: 60  retries: 86400, Error_code: 2013
					120917 14:46:36 [Note] Slave: connected to master 'rep@10.250.8.11:3306',replication resumed in log 'mysql-bin.000002' at position 432
			

		参考：http://www.cnblogs.com/luoine/archive/2011/05/25/2056493.html

	- mysql执行计划，sql执行计划
		mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

		mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		更多见mysql计划ppt说明

	- mysql数据dump
		mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
		source /home/xx.sql
	- 从文件导大量数据到数据库时，可以用
		source path/file eg: source d:\xx.sql
		如果拷贝出来去执行速度很慢。
		linux下：
			mysql -uxx -pxx -Ddbname < xx.sql
		需要相应权限
	-  mysql账户管理，账户授权	增加用户 删除用户
		GRANT ALL PRIVILEGES ON *.* TO 'monty'@'localhost' IDENTIFIED BY 'some_pass' WITH GRANT OPTION;

		在库qatest_normal_0中创建tddl用户,授予读写数据库权限

		CREATE USER ’tddl’@'%’ IDENTIFIED BY ’tddl’;

		GRANT Insert,Update,Select,Delete ON qatest_normal_0.* TO ’tddl’@'%’;

		PS:
			create user 'tddl'@'10.250.8.214' identified by 'tddl';
			Check： select * from mysql.user where user='tddl'\G;

			grant insert,update,select,delete on slbapi.* to 'tddl'@'10.250.8.214';
			
			由于已定义了host，用其他host登陆时会报错：
			C:\Users\xxx>mysql -utddl -ptddl
			ERROR 1045 (28000): Access denied for user 'tddl'@'localhost' (using password: YES)

			drop user tddl;

	- 一些命令使用，可以参考gui工具执行命令的sql参考 比如：Aqua Data Studio ，在alter table 时可以查看preview sql
	insert into vip (host,port,gmt_create,gmt_modify)values('host3',80,'2012-12-12 00:00:00','2012-12-12 00:00:00'); //id为自增列
	 select last_insert_id() as id from vip limit 1 
	 - select * from `group`
		group是mysql的关键词，需要引起来查询
		（mysql  Ver 14.14 Distrib 5.1.40, for unknown-linux-gnu (x86_64) using readline 5.1）
	- mysql>system ls
		mysql下执行shell，命令行命令方式
	- mysql where条件字符串不区分大小写
		？是否哪里可以设置要区分大小写
	- mysql 区分大小写
		参考day66
	- mysql用户管理
		create user houyi@10.250.8.214;
		set password for houyi = password('houyi');
		GRANT ALL PRIVILEGES ON *.* TO 'houyi'@'10.250.8.214' IDENTIFIED BY 'houyi' WITH GRANT OPTION;
	- InnoDB和MyISAM是在使用MySQL最常用的两个表类型，各有优缺点，视具体应用而定。基本的差别为：MyISAM类型不支持事务处理等高级处理，
		而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持已经外部键等高级数据库功能。
	- DML语句，比如insert ,update, delete，如果关闭自动提交需要执行commit才会持久化；而DDL，比如alter table，是系统自动提交无法回滚
		
Apply address:http://www.taobao.ali.com/chanpin/wb/Lists/List4/view.aspx
* php 从小例子入手
	- shell中执行php
		chengs@houyi-vm19.dev.sd.aliyun.com $ vi foo.php

		#!/usr/local/bin/php -q
		<?
			$var = 'foo';
			echo $var."\n";
		?>

		"foo.php" [New] 5L, 62C written                                                                                  
		chengs@houyi-vm19.dev.sd.aliyun.com $ php foo.php 
		foo
		chengs@houyi-vm19.dev.sd.aliyun.com $ 

* eclipse 插件开发 eclipse plugin
	http://code.google.com/p/eclipse-fonts/ 这是简单设置编辑器字体大小的插件，可以学习eclipse的plugin编程 ?
	
* ide * eclipse
	- eclipse项目红叉
		到Error log下查看
	- 配置eclipse项目的源码目录和文件夹，以及导入项目的目录顺序，项目属性-Order and Export
	- 项目依赖的Validate,如果关闭了自动Validate功能，项目导入后不会自动检查问题；可以手动执行validate以发现问题，比如可能某个库没导入
		导入错误，感叹号 
	- quick fix	       ctrl+1
		修改属性名，类名等，需要IDE自动修改依赖的地方，可通过此功能去做，无需各处都手动修改		
	- eclipse设置文件默认编辑器时，在edit配置中，比如wiki类型，可以新建类型，设置编辑器时，需要设置默认编辑器（有default按钮），否则ide可能出错，导致设置失败。
	- debug时，保证被debug的程序和当前源码一致，否则可能debug异常（比如debug不进来）
		debug查看源码有问题时，比如不能定位到源码，可以在配置debug时就将源码目录或项目文件夹等配置上去，然后再进行debug。
	- eclipse debug时，可以激活 break points窗口中的skip all break points按钮，这样会跳过所有debug点。
		debug点图标上会多个右斜线
	- 设置文件默认打开编辑器：general - appearance - editors - file associations 比如设置文本方式打开xml文件
	- 对于同时要打开重名项目的需求，可以通过放到不同的workspace中，单独打开操作，避开重名冲突。
	- 字体大小
		当设置字体的按钮不能用时，我就碰到了点的没反应，我们可以下载eclipse设置字体相关的插件，
		通过插件间接设置我们想要的字体，大小等。（官方文档都是基于IDE的设置窗口，但按钮是失效的，也是是bug）
		http://code.google.com/p/eclipse-fonts/ 这是其中一个插件
			
	- Eclipse取消Show in Breadcrumb
		随手右键启用这个功能，半天么找到如何取消，囧。。。
		百度了下，方且搞定，位置在：
			window > customize perspective > tool bar visibility > editor presentation > toggle greadcrumb
		工具栏上有个按钮，也可直接取消选中。
		后记：不过，对eclipse的使用及设置又学了一招。
	ctrl + shift + L 列出所有快捷键列表
	- 字母大小写
		ctrl + shift + x (大写)/ ctrl + shift + y (小写)
	- eclipse 文件夹上下关系 project property - build path -move
		source folder ，设置源码包 build path - change to source folder
		xml 标签自动提示，schema ，dtd定义正确即可
		类似aqua data studio 通过快捷键查看表结构；通过 CTRL+T 快捷键查看类型的结构(实现，继承等)
	- eclipse 快捷键 
		ctrl + t;
		ctrl + 1 quick fix ，如改包名等
		ctrl + shift + r 查找资源类
			在open按钮处选择打开方式，后面会以此方式为默认
		ctrl + shift + t 查找类型(比如某个jar包中的某个类)
	- debug插件，远程debug时，有时报错，
		一般是已打开了其debug模式，可以关闭debug（有多个debug在进行时，需要在debug面板选择需要操作的debug实例），重新打开remote debug，
		再不行，可以尝试重启eclipse再debug
	- eclipse 的 type hierarchy 面板应用
		在测试时，比如jtester测试，如果只想执行某一个方法的测试，可以在这个视图的方法上右击执行（通过反射执行，不用执行每个用例）
	- eclipse插件
		1）IvyIDE的eclipse插件在线安装：http://www.apache.org/dist/ant/ivyde/updatesite

* Source Insight
	- 
		Source Insight是一个面向项目开发的程序编辑器和代码浏览器，它拥有内置的对C/C++, C#和Java等程序的分析。Source Insight能分析你的源代码并在你工作的同时动态维护
	它自己的符号数据库，并自动为你显示有用的上下文信息。 Source Insight不仅仅是一个强大的程序编辑器，它还能显示reference trees，class inheritance diagrams和call trees。
	Source Insight提供了最快速的对源代码的导航和任何程序编辑器的源信  息。 Source Insight提供了快速和革新的访问源代码和源信息的能力。与众多其它编辑器产品不同，
	Source Insight能在你编辑的同时分析你的源代码，为你提供实用的信息并立即进行分析。
	- 快捷键
		alt+,/. 回退/前进
		ctrl+= 进入方法定义
		shift+F8 高亮显示选中内容
	- 导入工程方法
		project->new project>选泽源码所在目录>...


* php 
	 Discuz
	 开源bug管理系统bugfree：
		 http://www.bugfree.org.cn/blog/?page_id=9
* 测试，测试框架，测试插件
	* testng
		BeforeTest
		AfterTest
		使用这些注解配合自动执行测试用例
	* jtester
		- 不便于全局mock，需要细粒度到方法mock时，注意被mock属性的定义，需要定义到实现类，而不能是接口类型（否则不会被mock），正确例子如下：
			new Expectations(){
				@Mocked(methods={"selectXXX"})
				ImageDaoImpl imageDao; //这里声明的是实现类
				{
					when(imageDao.selectXXX(anyLong, (Image)any, anyInt, -1)).thenReturn(expectImageList);
				}
				@Mocked(methods={"detailXXX"})
				SnapshotServiceImpl snapshotService;    
				{
					when(snapshotService.detaildetailXXX("testSnapshotId", "testRegionNO")).thenReturn(expectResult);
				}
			};
		- jtester顺序执行，按次序执行，类似集成测试的方式
			观察jtester执行用例的方式，是以方法名排序的，通过加入字符人工干预其排序达到顺序执行用例，解决依赖测试问题（比如要先创建LB，才能查询LB,删除LB等等）。
		- jtest 事务回滚测试，事务测试，unitils测试事务
			@Transactional(TransactionMode.DISABLED)
				测试事务时，需要关闭测试框架的事务，否则会出现在测试框架开启的事务中，又开启新的事务，导致交叉，不能准确的测试事务一致性。
		- 
			jtester框架测试，用dbfit测试数据库，默认以jtester.properties的数据库操作，若要动态跨数据库操作可以在wiki文件里配置，格式如下：

			指定需要连接的库
				|connect|jdbc:mysql://10.10.10.10/databaseName?useUnicode=true&amp;characterEncoding=utf-8|userName|password|com.mysql.jdbc.Driver|
				|clean table|`tableName`|
				|insert|`table|`tableName`|`|
				|id|name|
				|1|jack|
				|2|tom|
			采用默认库
				|connect|
				|clean table|`tableName`|
		- 测试异常抛出
			-----
			...
				new Expectations(){
					{	when(xx).thenReturn(xx);
						throwException(new RuntimeException(xxx));
					}
				};
				try{
					xxx.execute();
				}catch (Exception e) {
					Assert.assertEquals(e.getClass(), RuntimeException.class);
					Assert.assertEquals(e.getMessage(), xxx);
				}
			...
			-----
		- 一个测试方法，含多个测试点的时候
			可以按照顺序依次测试（在同一个方法中），不过expectation需要新建（从之前的拷贝过来即可），改动点需要设置的地方，再assert即可。
		- 测试框架，提供了各种测试方式及支持，比如mock，通过反射测试私有类等的工具JTesterReflector ，完整的去用一个测试框架。阅读其说明文档
		- 提供集成测试支持(如数据库等)
		- jtester是结合其他框架基础上的，比如@Test 注解用的就是testing框架，此时eclipse插件就下载testing(TestNG )的插件，即可在ide执行测试。ide比如eclipse执行单元
		测试框架的测试用例是根据框架的注解来解析执行的，找到框架的ide插件即可。
		下载地址：http://testng.org/doc/index.html 从其jar里找到网站信息
			http://beust.com/eclipse-old/eclipse-5.14.0.1 新版本有问题，用这个旧版本
		- TestNG is designed to cover all categories of tests:  unit, functional, end-to-end, integration, etc...
			TestNG is a testing framework inspired from JUnit and NUnit but introducing some new functionalities that make it more powerful and easier to use
		- 新项目加入jtester步骤：整合Jtester测试框架
			1）加入依赖
				<repositories>
					<repository>
					<id>jtester-maven</id>
					<name>JTester</name>
					<url>http://java-tester.googlecode.com/svn/maven2/</url>
					</repository>
				</repositories>		
				<dependencies>
					<dependency>
					<groupId>org.jtester</groupId>
					<artifactId>jtester</artifactId>
					<version>1.0.1</version>
					<scope>test</scope>
				</dependency>				
			2）添加jtester.properties配置文件到classpath
				-----
				database.type=mysql
				database.url=jdbc:mysql://localhost:3306/slbapi
				database.userName=root
				database.password=abc123

				database.driverClassName=com.mysql.jdbc.Driver
				DatabaseModule.Transactional.value.default=rollback
				#rollback, commit
				database.only.testdb.allowing=true

				tracer.database=false
				tracer.springbean=false
				#unitils.modules=database,dbunit,dbfit,inject,spring,tracer
				unitils.modules=dbunit,inject,tracer	
				-----
				PS: 注意这里的unitils.modules属性的配置，如果要用到spring，值中应该包含，否则不会初始化spring容器！！！，其他组件也是一样的
					
			3）创建抽象父类，进行测试前的资源初始化操作
				@SpringApplicationContext({
					"classpath:houyi-spring-test.xml",
					"classpath:houyi-spring-dao.xml",
				    "classpath:houyi-spring-db.xml",
				    "classpath:houyi-openapi.xml",
					})
				@AutoBeanInject(maps = { @BeanMap(intf = "**.*", impl = "**.impl.*Impl") })
				public abstract class BaseJtester extends JTester {
				}
				这里 classpath:houyi-spring-test.xml 是配置了jdbc等配置文件信息的参数信息，要配置正确
			4）测试类继承上面的抽象类（db，mock，etc）
				public class ZoneDaoImplTest extends BaseJtester {
					
					@SpringBeanByName
					ZoneDao zoneDao;
					
					@DbFit(when={"ZoneDaoImplTest.testQueryClusterIdByZoneId.when.wiki"})
					@Test
					public void testQueryClusterIdByZoneId(){
						String clusterId = zoneDao.queryClusterIdByZoneId("testZoneId");
						Assert.assertEquals("testClusterId", clusterId);
					}
		- 配置jtester时，报属性文件找不到
			Caused by: java.io.FileNotFoundException: C:\Users\wb_shen.chengs\.houyi\jdbc.properties (系统找不到指定的路径。)
				查找jtester抽象父类，导入的配置文件中，是否那个配置文件引用了错误的路径；如果原配置文件不能动，可以再test包下的resource中对其
			做个拷贝，修改相应值，替代原配置文件导入。
		- jtester配置数据库时，要配置应用的jdbc和jtester自身的jtester.properties文件中的数据库配置 
			以免报数据库连接被拒绝等连接问题
			

* 简称
	 业务运营支撑系统(BOSS) 
	 弹性计算(Elastic Computing - EC) 
	 云引擎(Cloud Engine - CE) 
	 开放存储服务(Open Storage Service - OSS) 
	 云数据库服务(Cloud Database Service - CDS) 
	 阿里邮箱(Ali Mail - AM) 
	 开放表服务（Open Table Service - OTS）
* 精度转换
	Long.valueOf(String.valueOf(compensationFailureJobHour * HOUR_SEC))
* maven
	- maven项目编码问题
		报：spring Invalid byte 2 of 3-byte UTF-8 sequence
		xml文件中的汉字有编码问题，需要显式的设置pom中的属性：
		eg:
		<properties>
			<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>	  <!-- 显式指定编码 -->
			<maven.test.skip>true</maven.test.skip>
			<struts.version>2.2.1</struts.version>
			<org.springframework.version>3.1.1.RELEASE</org.springframework.version>
			<junit.version>4.4</junit.version>
		</properties>

	- maven-tomcat-plugin的用法
		-----
		maven-tomcat-plugin的用法
		maven-tomcat-plugin让maven与tomcat配合得很好。它可以把应用部署到Tomcat服务器，也可以把 tomcat作为内嵌服务器启动，就像jetty一样。
		使用JPDA启动tomcat的远程调试功能。这样就能与eclipse配合起来，轻松地实现调试。而且具有tomcat的热部署功能。
		 
		具体做法如下：
		1) 在pom.xml文件中配置maven-tomcat-plugin插件。
		Xml代码
		  <build>
		    <finalName>demo</finalName>
		    <plugins>
		     <plugin>
		      <groupId>org.codehaus.mojo</groupId>
		      <artifactId>tomcat-maven-plugin</artifactId>
		      <version>1.1</version>
		     </plugin>
		    </plugins>
		  </build>
		 
		2) 配置环境变量MAVEN_OPTS，启动调试功能。
		写道
		MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,address=1044,server=y,suspend=n
		 
		3) 在eclipse中配置远程调试

		MAVEN命令：mvn tomcat:run

		参考：
		http://mojo.codehaus.org/tomcat-maven-plugin/introduction.html


		上面的配置是把tomcat作为内嵌服务器使用。

		如果把tomcat作为外部服务器，还需要做如下配置。
		1) 修改startup.bat
		  修改call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%
		2) 修改catalina.bat
		  修改set JPDA_TRANSPORT=dt_socket
		  修改set JPDA_ADDRESS=1045
		3) 修改tomcat-users.xml
		  如果没有，则加入<role rolename="manager"/>
		  加入，<user username="admin" password="" roles="manager"/>
		  maven默认使用admin密码为空登录tomcat管理控制台。
		******************************************************************
		maven-tomcat-plugin能够方便的部署war应用到本地或远程的tomcat上,废话少说,看代码,下面是带有maven- tomcat-plugin配置的pom.xml
		<properties>
		　　　　<!--　Cargo　settings　-->
		　　　　 <cargo.container.manager.url>http://192.168.1.107/manager</cargo.container.manager.url>
		　　　　 <cargo.container.username>admin</cargo.container.username>
		　　　　 <cargo.container.password>123456</cargo.container.password>
		　　　　<cargo.wait>false</cargo.wait>
		</properties>
		<build>
		　　　　<plugins>
		　　　　　　　　<plugin>
		　　　　　　　　　　　　 <groupId>org.codehaus.mojo</groupId>
		　　　　　　　　　　　　 <artifactId>tomcat-maven-plugin</artifactId>
		　　　　　　　　　　　　 <version>1.0-beta-1</version>
		　　　　　　　　　　　　 <configuration>
		　　　　　　　　　　　　　　　　<path>/runes</path>
		　　　　　　　　　　　　　　　　<url>${cargo.container.manager.url}</url>
		　　　　　　　　　　　　　　　　 <username>${cargo.container.username}</username>
		　　　　　　　　　　　　　　　　<password>${cargo.container.password}</password>
		　　　　　　　　　　　　　　　　 <warDirectory>${basedir}/src/main/webapp</warDirectory>
		　　　　　　　　　　　　</configuration>
		　　　　　　　　　　　　<executions>
		　　　　　　　　　　　　　　　　<execution>
		　　　　　　　　　　　　　　　　　　　　 <id>tomcat-deploy</id>
		　　　　　　　　　　　　　　　　　　　　 <phase>deploy</phase>
		　　　　　　　　　　　　　　　　　　　　<goals>
		　　　　　　　　　　　　　　　　　　　　　　　　<goal>deploy</goal>
		　　　　　　　　　　　　　　　　　　　　</goals>
		　　　　　　　　　　　　　　　　</execution>
		　　　　　　　　　　　　　　　　<!--execution>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 <id>undeploy</id>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 <phase>deploy</phase>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 <goals>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 <goal>start</goal>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 </goals>
		　　　　　　　　　　　　　　　　　　　　　　　　　　　　</execution-->
		　　　　　　　　　　　　</executions>
		　　　　　　　　</plugin>
		　　　　 </plugins>
		-----
		ref: http://blog.sina.com.cn/s/blog_7fa2bcf50100yy68.html
	- maven库下载错误，比如配置正确但无法自动下载到本地目录下，可以尝试删除原目录再调用maven命令以触发下载。
		也可能是某个jar没下载，比如maven库没有配置正确，导致其他的jar也下载失败
		test成功，jar都下载下来后，eclipse里update下依赖即可
	- maven web项目 maven项目 部署 测试 ，可通过bat或shell的方式来自动化编译打包部署，方便web项目的调试
		搜索本文件内容：mavn web project 自动部署启动容器脚本(bat脚本)

		打包速度太慢，直接用maven插件进行热部署并启动：
		mvn tomcat:run
		mvn jetty:run	mvn jetty:stop 

		maven插件及其使用

		maven plugin 说明：http://maven.apache.org/plugins/index.html

	- maven jvm参数配置 配置jvm    maven运行参数配置
		maven默认的jvm配置，比如内存不能满足需要，可能导致错误，如：java.lang.OutOfMemoryError: PermGen space问题
		下面摘自网络，可参考：
		-------
		　有时候我们需要设定maven环境下的JVM参数，以便通过maven执行的命令或启动的系统能得到它们需要的参数设定。比如：当我们使用jetty:run启动jetty服务器时，在进行热部署时会经常发生:java.lang.OutOfMemoryError: PermGen space问题,这时我们需要增大JVM参数MaxPermSize的值。再者，当我们需要进行远程调试时，也需要设置监听端口。maven配置jvm参数的地方是%M2_HOME%/bin/mvn.bat文件，这是启动Maven的脚本文件，在该文件中你能看到有一行注释为：@REM set MAVEN_OPTS=-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000．通过添加set MAVEN_OPTS可以为maven设定jvm参数了。比如：
		　　1.建立远程调试，端口为:4000的设定为：
		　　set MAVEN_OPTS=-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=4000
		注意：suspend最好设定为n.设定上述参数后，在eclipse中新建远程调试，设置端口为4000，这样通过jetty:run启动系统时就可以进行远程调试了。
		　　2.解决自动热部署时java.lang.OutOfMemoryError: PermGen space问题解决这一问题只需要增大PermGen区，默认为 64m，设置方法为：
		　　set MAVEN_OPTS=-XX:MaxPermSize=128M
		-------
		from：http://blog.csdn.net/bluishglc/article/details/6310071

	- maven clean时，linux中若文件被ln连接引用，需要删除引用（如target中的war包被引用）
		可重新svn co
	- 发布jar到nexus
		发布到中央库需要具有一定权限
			mvn deploy:deploy-file -DgroupId=com.google.inject.extensions -DartifactId=guice-servlet -Dversion=3.0 -Dpackaging=jar -Dfile=guice-servlet-3.0.jar -Durl=http://www.some-domain.com/some-path -DrepositoryId=nexus
	- maven依赖jar的下载问题
		maven下载pom中定义的jar依次从本项目的pom中配置的repository.url>指向的地址下载，若没有则去本地maven的repository列表逐个去下载。
		由于子pom中没有定义jar的本地repository地址，本地maven配置也没有其地址，从而报jar找不到。

		项目pom中的repository配置方式例子(若项目中没有配置，则本地maven库需要配置)：
			<repositories>
				<repository>
				<id>jtester-maven</id>
				<name>JTester</name>
				<url>http://java-tester.googlecode.com/svn/maven2/</url>
				</repository>
			</repositories>

	- nexus
		maven本地库搭建
		http://blog.csdn.net/westkingwy/article/details/7671371
			nexus-webapp-1.4.1/conf/plexus.properties 此属性文件配置nexus信息

	- mvn clean package -Dmaven.test.skip=true -Dconfig.file=/home/admin/houyi-ace4j/service/config/auto-config.properties
	- maven 循环依赖问题，依赖交叉
		可通过将接口抽取到一个模块中，被其他实现模块引用；接口模块自身不依赖或只依赖类似model的中立模块

	- 忽略测试失败
		mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	- 测试覆盖率插件 surefire-report
		mvn surefire-report:report-only
	- maven项目分为多个子项目debug时，如果debug到的类不在当前子项目中，会找不到源码，可把关联的子项目源码包位置指定给ide，指定class的目录，比如com.xxx.xx
	- mavne 插件使用说明，查阅其官方说明：
		eclipse插件：maven-eclipse-plugin http://maven.apache.org/plugins/maven-eclipse-plugin/
		mvn某些goal执行错误时，可以尝试eclipse中clean项目再执行。
			如果eclipse使用的jdk和maven使用的jdk不是同一个的话，会报编译错误；保证2者使用同一个jdk。

	- maven可以通过参数执行特定的goal，或测试某个用例，不需要全部执行，灵活 (-Dxxx=)
		mvn test -Dtest=AppDaoImplTest
	- maven 打包后，将jar包install到本地库中
		mvn package install

	- maven版本编译问题，若maven版本低，默认会采用jdk1.3编译，需要在pom中指定java版本：
			-------
			<plugin>
			    <groupId>org.apache.maven.plugins</groupId>
			    <artifactId>maven-compiler-plugin</artifactId>
			    <configuration>
			      <source>1.6</source>
			      <target>1.6</target>
			    </configuration>
			 </plugin>
			-------
		版本不对报：annotations are not supported in -source 1.3


	- maven web project ,maven通过选择不同的 Archetype 快速建立对应的项目目录骨架。 maven构建
	web项目(eg:webx3.0项目)
		- 比如 group id 为 org.apache.maven.archetypes 下有多种Archetype。如何自定义Archetype？
		- 还有pom文件中必须引入servlet，jsp的相关jar包，scope设置为provided，表示它们最终不会打包到war项目中
	- mvn执行测试时进行debug
		mvn -Dmaven.surefire.debug=true -Dtest=OpenApplicatonControllerTest test
	- maven test 
		test 时需要debug，可以利用测试插件提供的方法，结合ide(eclipse)进行debug
			比如： Surefire Plugin 测试环节的插件，支持test时，进行debug ，下面为maven的官网说明摘取：
				Forked Tests
					By default, Maven runs your tests in a separate ("forked") process. You can use the maven.surefire.debug property to debug your forked tests remotely, like this:
						mvn -Dmaven.surefire.debug test	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
				launch configuration via the menu command "Run" > "Open Debug Dialog..."
					If you need to configure a different port, you may pass a more detailed value. For example, the command below will use port 8000 instead of port 5005.
						mvn -Dmaven.surefire.debug="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000 -Xnoagent -Djava.compiler=NONE"  test
				Non-forked Tests
					You can force Maven not to fork tests by configuring the forkMode configuration parameter.
						mvn -DforkMode=never test
					Then all you need to do is debug Maven itself. Since Maven 2.0.8, Maven has shipped with a "mvnDebug" shell script that you can use to launch Maven with convenient debugging options:
					mvnDebug -DforkMode=never testThen you can attach Eclipse to Maven itself, which may be easier/more convenient than debugging the forked executable.
				上面这段：	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
					launch configuration via the menu command "Run" > "Open Debug Dialog..."
				说明如何通过eclipse来进行maven的debug调试。-tip-
				mvn -Dmaven.surefire.debug test  //maven debug
	- maven添加jar到本地库
		mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
		添加源码到本地库 添加source
		 mvn install:install-file -DgroupId=org.apache.velocity -DartifactId=velocity -Dversion=1.6.2 -Dpackaging=jar -Dfile=velocity-1.6.2-sources.jar -DgeneratePom=true -Dclassifier=sources 

		从jar导入到maven库与从maven项目源码编译导入到库的区别：若从源码编译导入则jar自身依赖的jar会自动下载（依赖jar的pom文件已定义其自身的依赖）。		


	- maven jar包重复问题，可通过
		mvn dependency:tree 查看依赖关系。
		配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
		对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
		只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。
		上面如果没效果：
			通过定义 <dependencyManagement> 来自己管理依赖版本，然后再引用来解决 .work well.
	- maven source:jar 打源码包
	- maven test时一种错误
	需要强制转换。
	- maven构建时报内存溢出解决
		 Windows环境中 
			找到文件%M2_HOME%\bin\mvn.bat	
			set MAVEN_OPTS= -Xms128m -Xmx512m
			E:\test>mvn -version
			E:\test>set MAVEN_OPTS= -Xms128m -Xmx512m
		Linux环境中 
			也可以通过设置环境变量解决该问题， 如，编辑文件 /etc/profile 如下
			MAVEN_OPTS=-Xmx512m
			export JAVA_HOME MAVEN_HOME MAVEN_OPTS JAVA_BIN PATH CLASSPATH
	- maven web project debug ，maven debug tomcat
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS% 启动tomcat调试模式 ，通过socket方式
	- maven 编译错误 
		原因之一：ide的一些操作导致冲突，清楚ide的附加内容(配置，临时文件等等)，mvn clean下，再重新import到ide中即可。
		原因之二：命令行下mvn操作与ide的操作，在缓存文件上导致错误，命令行clean了，但ide上没刷新 。解决就是ide上 maven clean 然后 project clean ，
			命令行就不会报错了。
	- maven 注解不支持 annotations are not supported in  ，显式定义插件，配置参数，设置jdk版本
		Maven default is using JDK1.3 for the project compilation, building or packaging (mvn compile, install). Since JDK1.3 is not support annotation, if your project has annotation, you need to configure your Maven to use the latest JDK version. The solution is very simple, just include the Maven compiler plugin and specify the JDK version. For example,
		<project ....>
		 <build>
		  <plugins>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>2.3.2</version>
				<configuration>
					<source>1.6</source>
					<target>1.6</target>
				</configuration>
			</plugin>
		   </plugins>
		  </build>
		</project>
		Above declaration tell Maven to use JDK 1.6.
	- maven 编码相关 - maven命令行执行能看到采用的编码
		a. maven插件在处理任务时，如果没有定义编码会自动匹配编码，如果与需要的不符，则运行时报错。解决：定义各插件执行的编码格式，如下：
			可以通过 mvn -version 查看maven默认采用的编码是什么？
			<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-resources-plugin</artifactId>
					<configuration>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
				<plugin>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>2.3.2</version>
					<configuration>
						<source>1.6</source>
						<target>1.6</target>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
	- 执行时，设置maven参数
			mvn -Dmaven.test.skip=false test 不跳过测试的test操作
	- No goals needed for project - skipping 跳过测试问题
		大项目下有多个子项目，某些子项目mvn test 不执行里面的test，报：No goals needed for project - skipping
		内部程序配置冲突是原因之一
	- maven pom.xml文件build标签配置例子
		-------
		<build>
			<finalName>javaweb</finalName>

			<resources>
				<resource>
					<directory>src/main/resources</directory>
					<filtering>true</filtering>
					<includes>
						<include>*.xml</include>
						<include>**/*.xml</include>
						<include>*.properties</include>
					</includes>
				</resource>
				<resource>
					<directory>src/test/resources</directory>
					<filtering>true</filtering>
					<includes>
						<include>**/*.wiki</include>
						<include>**/*.xml</include>
						<include>*.properties</include>
					</includes>
				</resource>
			</resources>

			<pluginManagement>
				<plugins>
					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-resources-plugin</artifactId>
						<configuration>
							<encoding>${file.encoding}</encoding>
						</configuration>
					</plugin>
					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-compiler-plugin</artifactId>
						<configuration>
							<source>1.6</source>
							<target>1.6</target>
							<encoding>${file.encoding}</encoding>
						</configuration>
					</plugin>
					<plugin>
						<groupId>org.apache.maven.plugins</groupId>
						<artifactId>maven-war-plugin</artifactId>
						<version>2.0.2</version>
						<configuration>
							<excludes>
								<exclude>**/.svn</exclude>
							</excludes>
							<webResources>
								<resource>
									<directory>${basedir}/src/main/webapp/WEB-INF</directory>
									<targetPath>WEB-INF</targetPath>
									<filtering>true</filtering>
									<includes>
										<include>*.xml</include>
									</includes>
								</resource>
							</webResources>
						</configuration>
					</plugin>
				</plugins>
			</pluginManagement>
			
		</build>
		-------

* 工具类
	 apache commond 
		StringUtils 
		...
* 协作
	”系统间协作的部分，找到相关人员沟通效率就快了，都是人定义的，谁定义谁最清楚 “

* python
	- rstrip函数
		Python中的strip用于去除字符串的首尾字符，同理，lstrip用于去除左边的字符，rstrip用于去除右边的字符。这三个函数都可传入一个参数，指定要去除的首尾字符。
	- 终端输入，命令行输入，用户输入 用raw_input([prompt])
		var = raw_input("Enter something: ")
		print "you entered ", var
	- pythobn脚本
		使用库时，尽量使用内置的库，避免依赖问题，比如:
			from _pyio import open
			直接使用内置的:open即可
		
	- 异常捕获
		抛出异常：
			raise errorclass, errorvalue

		捕获异常
		try:
			xxx
		except xxxException:
			xxx

	-----
		Python的异常处理能力是很强大的，可向用户准确反馈出错信息。在Python中，异常也是对象，可对它进行操作。所有异常都是基类Exception的成员。
		所有异常都从基类Exception继承，而且都在exceptions模块中定义。Python自动将所有异常名称放在内建命名空间中，所以程序不必导入exceptions模块即可使用异常。
		一旦引发而且没有捕捉SystemExit异常，程序执行就会终止。如果交互式会话遇到一个未被捕捉的SystemExit异常，会话就会终止。

		方式一:try语句:

		1使用try和except语句来捕获异常

		try:
		   block
		except [exception,[data…]]:
		   block

		try:
		block
		except [exception,[data...]]:
		   block
		else:
		   block

		该种异常处理语法的规则是：

		·   执行try下的语句，如果引发异常，则执行过程会跳到第一个except语句。

		·   如果第一个except中定义的异常与引发的异常匹配，则执行该except中的语句。

		·   如果引发的异常不匹配第一个except，则会搜索第二个except，允许编写的except数量没有限制。

		·   如果所有的except都不匹配，则异常会传递到下一个调用本代码的最高层try代码中。

		·   如果没有发生异常，则执行else块代码。

		例:

		try:

		   f = open(“file.txt”,”r”)
		except IOError, e:
		   print e

		捕获到的IOError错误的详细原因会被放置在对象e中,然后运行该异常的except代码块

		捕获所有的异常

		try:
		   a=b
		   b=c
		except Exception,ex:
		   print Exception,":",ex

		使用except子句需要注意的事情，就是多个except子句截获异常时，如果各个异常类之间具有继承关系，则子类应该写在前面，否则父类将会直接截获子类异常。放在后面的子类异常也就不会执行到了。

		2 使用try跟finally:

		语法如下:

		try:
		   block
		finally:
		   block

		该语句的执行规则是：

		·   执行try下的代码。

		·   如果发生异常，在该异常传递到下一级try时，执行finally中的代码。

		·   如果没有发生异常，则执行finally中的代码。

		第二种try语法在无论有没有发生异常都要执行代码的情况下是很有用的。例如我们在python中打开一个文件进行读写操作，我在操作过程中不管是否出现异常，最终都是要把该文件关闭的。

		这两种形式相互冲突，使用了一种就不允许使用另一种，而功能又各异

		2. 用raise语句手工引发一个异常:

		raise [exception[,data]]

		在Python中，要想引发异常，最简单的形式就是输入关键字raise，后跟要引发的异常的名称。异常名称标识出具体的类：Python异常是那些类的对象。执行raise语句时，Python会创建指定的异常类的一个对象。raise语句还可指定对异常对象进行初始化的参数。为此，请在异常类的名称后添加一个逗号以及指定的参数（或者由参数构成的一个元组）。

		例:

		try:
		    raise MyError #自己抛出一个异常
		except MyError:
		    print 'a error'

		raise ValueError,’invalid argument’
		捕捉到的内容为:

		type = VauleError
		message = invalid argument
	-----
	from: http://blog.csdn.net/JINXINXIN_BEAR_OS/archive/2011/02/23/6202784.aspx

	- 定义编码格式 Defining Python Source Code Encodings
		支持中文，需要在源文件中定义字符编码格式，比如：
			#coding=utf-8
		ref: http://www.python.org/dev/peps/pep-0263/


	- pytest
		python测试工具
		scales from simple unit to complex functional testing
	- edit plue开发python
		
		运行python文件，需要参数时，可以配置对应tool的argument选项，如：配置为 $(FileName) $(Prompt) ，这样在运行时允许指定参数

		语法高亮，换行等
		运行python
		-----
			EditPlus开发python 编辑器环境的配置

			Python也可以使用编辑器进行开发。例如，文本编辑软件EditPlus也能成为Python的编辑、执行环境，甚至可以用于调试程序。EditPlus具备语法加亮、
			代码自动缩进等功能。本节介绍一下如何配置EditPlus编辑器的开发环境。

			1)添加Python群组

			首先启动EditPlus，然后单击【工具】|【配置用户工具】命令，打开【参数】对话框。在【参数】对话框中单击【添加工具】按钮，在弹出的菜单中选择【程序】命令。
			新建的群组名称命名为“Python”，分别在【菜单文本】文本框中输入“python”，在【命令】文本框中输入Python的安装路径，在【参数】文本框中输入“$(FileName)”，
			在【起始目录】文本框中输入“$(FileDir) ”。勾选【捕获输出】选项，Python程序运行后的输出结果将显示在Edit Plus的输出栏中，否则，运行Python程序后将弹出命令行窗口，
			并把结果输出到命令行中。

			设置完成后的对话框如图1-10所示。单击【确定】按钮，新建一个Python文件，【工具】菜单下将会出现【python】选项。单击【python】选项或按快捷键Ctrl＋1，
			就可以运行Python程序。

			2)设置Python高亮和自动完成

			EditPlus不仅可以作为Python的开发环境，还支持Java、C#、PHP、HTML等其他类型的语言。不同语言的语法高亮显示和自动完成的特征各不相同。为了实现语法加亮
			和自动完成功能，需要下载python.acp和python.stx这两个特征文件。下载地址为http://www.editplus.com/files/pythonfiles.zip。下载后把文件python.acp和python.stx解压到EditPlus
			的安装目录下。acp后缀的文件表示自动完成的特征文件，stx后缀的文件表示语法加亮的特征文件。在编写Python代码之前，需要先在EditPlus中设置这些特征文件。

			（1）选择【文件】|【设置与语法】选项，在【文件类型】列表中选择【python】选项，【描述】文本框中输入“python”，【扩展名】文本框中输入“py”，如图1-11所示。

			图1-10  在EditPlus中添加对Python的支持图1-11  设置Python的特征文件

			（2）在【设置与语法】选项卡中，在【语法文件】文本框中输入python.stx的路径，在【自动完成】文本框中输入python.acp的路径。

			 

			（3）Python的语法中没有使用begin、end或{}区分代码块，而是使用冒号和代码缩进的方式区分代码之间的层次关系。单击【制表符/缩进】按钮，打开【制表符与缩进】
			对话框。设置Python代码的缩进方式，如图1-12所示。在使用IDE工具时，输入冒号代码会自动缩进，EditPlus也可以设置该功能。在【制表符】和【缩进】文本框中分别
			输入空格的个数，一般设置为“4”。把【启用自动缩进】选项选中，在【自动缩进开始】文本框中输入“:”。单击【确定】按钮保存设置。

			（4）单击【函数模型】按钮，打开【函数模型】对话框，如图1-13所示。在【函数模型正则表达式】文本框中输入“/[ //t/]*def/[ //t/].+:”。单击【确定】按钮保存设置。

			图1-12  Python代码的缩进方式

			图1-13  设置函数模型

			至此，EditPlus的Python开发环境就设置完成了。EditPlus还可以建立Python文件的模板，以后每次新建Python文件都可以在模板的基础上编写代码。编写Python代码经常要
			使用中文，同时也要考虑跨平台的功能，因此可以建立名为“template.py”的模板文件。template.py的内容如下所示。

			 

			#!/usr/bin/python

			# -*- coding: UTF-8 -*-

			  第1行代码使Python程序可以在UNIX平台上运行。

			  第2行代码设置编码集为UTF-8，使Python代码可以支持中文。

			注意在EditPlus中通过快捷键Ctrl＋F11可以查看当前python文件中的函数列表。

			 

			    运行Python程序前，需要先保存Python程序。下面使用EditPlus编写一段Python程序并输出结果，如图1-14所示。
		-----
		参考：http://blog.csdn.net/hendyyou/article/details/4694973

	- python命令行参数处理
		测试命令行参数问题时，可通过run as命令来配置运行参数，从而测试参数

	- python异常分析，异常日志由上到下，为异常的入口点，直到报错的地方；java是由下而上，日志前面是具体出错的地方
		------
			[root@AT-HOUYIDEV_AG]$ python houyiapi_bigregion2new_update_regionstatus.py 
			Before update houyi.region_status, houyi.region_status has 0 records
			Traceback (most recent call last):
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 46, in <module>
			    main()
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 42, in main
			    import_region_status_into_houyi()
			  File "houyiapi_bigregion2new_update_regionstatus.py", line 31, in import_region_status_into_houyi
			    houyidb.execute(sql)
			  File "/usr/local/lib/python2.5/site-packages/pypet/common/database.py", line 103, in execute
			    return self.cursor.execute(_format(sql), args)
			  File "build/bdist.linux-x86_64/egg/MySQLdb/cursors.py", line 174, in execute
			  File "build/bdist.linux-x86_64/egg/MySQLdb/connections.py", line 36, in defaulterrorhandler
			_mysql_exceptions.OperationalError: (1054, "Unknown column 'AT' in 'field list'")
		------
	- eclipse开发python
		在pyconsole中导入module时，需要设置项目的pydev-PYTHONPATH（设置PATH）

	- 文件头部的预处理语句说明
		#!/usr/bin/python是告诉操作系统执行这个脚本的时候，调用/usr/bin下的python解释器；
		#!/usr/bin/env python这种用法是为了防止操作系统用户没有将python装在默认的/usr/bin路径里。当系统看到这一行的时候，首先会到env设置里查找python的安装路径，再调用对应路径下的解释器程序完成操作。
		#!/usr/bin/python相当于写死了python路径;
		#!/usr/bin/env python会去环境设置寻找python目录,推荐这种写法
	- GC
		mark-and-sweep
			The mark-and-sweep algorithm is called a tracing garbage collector because is traces out the entire collection of objects that are directly or indirectly accessible by the program.  The objects 
		that a program can access directly are those objects which are referenced by local variables on the processor stack as well as by any global variables that refer to objects. In the context of garbage 
		collection, these variables are called the roots .

			The mark-and-sweep algorithm consists of two phases: 
			1) In the first phase, it finds and marks all accessible objects. The first phase is called the mark phase. 
			2) In the second phase, the garbage collection algorithm scans through the heap and reclaims all the unmarked objects. The second phase is called the sweep phase.	At the same time, 
			the marked field on every live object is set back to False in preparation for the next invocation of the mark-and-sweep garbage collection algorithm

			In order to distinguish the live objects from garbage, we record the state of an object in each object. That is, we add a special bool field to each object called, say, marked. By default, 
		all objects are unmarked when they are created. Thus, the marked field is initially False.
			The main disadvantage of the mark-and-sweep approach is the fact that that normal program execution is suspended while the garbage collection algorithm runs. In particular, this can be 
		a problem in a program that interacts with a human user or that must satisfy real-time execution constraints. For example, an interactive application that uses mark-and-sweep garbage collection 
		becomes unresponsive periodically.

		see for detail: http://www.brpreiss.com/books/opus7/html/page425.html#figgarbage5
			新建的object状态为默认的false即不会被本次回收 ；从根处开始查找引用树；
			The Fragmentation Problem 内存碎片问题


	- List comprehension
		python最强大的的特性之一
			A list comprehension is a syntactic construct available in some programming languages for creating a list based on existing lists. It follows the form of the mathematical 
		set-builder notation (set comprehension) as distinct from the use of map and filter functions.
		eg of list comprehension:
			["%s=%s" % (k, v) for k, v in params.items()]

			>>> li = [1, 9, 8, 4]
			>>> [elem*2 for elem in li]
			[2, 18, 16, 8]

	- python类型转换、数值操作
		类型转换
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		函数                      描述
		 int(x [,base ])         将x转换为一个整数
		 long(x [,base ])        将x转换为一个长整数
		 float(x )               将x转换到一个浮点数
		 complex(real [,imag ])  创建一个复数
		 str(x )                 将对象 x 转换为字符串
		 repr(x )                将对象 x 转换为表达式字符串
		 eval(str )              用来计算在字符串中的有效Python表达式,并返回一个对象
		 tuple(s )               将序列 s 转换为一个元组
		 list(s )                将序列 s 转换为一个列表
		 chr(x )                 将一个整数转换为一个字符
		 unichr(x )              将一个整数转换为Unicode字符
		 ord(x )                 将一个字符转换为它的整数值
		 hex(x )                 将一个整数转换为一个十六进制字符串
		 oct(x )                 将一个整数转换为一个八进制字符串

		序列操作
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		操作                      描述
		 s + r                   序列连接
		 s * n , n * s           s的 n 次拷贝,n为整数
		 s % d                   字符串格式化(仅字符串)
		 s[i]                    索引
		 s[i :j ]                切片
		 x in s , x not in s     从属关系
		 for x in s :            迭代
		 len(s)                  长度
		 min(s)                  最小元素
		 max(s)                  最大元素
		 s[i ] = x               为s[i]重新赋值
		 s[i :j ] = r            将列表片段重新赋值
		 del s[i ]               删除列表中一个元素
		 del s[i :j ]            删除列表中一个片段

		数值操作
		Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--> 1 
		x << y                  左移
		 x >> y                  右移
		 x & y                   按位与
		 x | y                   按位或
		 x ^ y                   按位异或 (exclusive or)
		 ~x                      按位翻转
		 x + y                   加
		 x - y                   减
		 x * y                   乘
		 x / y                   常规除
		 x // y                  地板除
		 x ** y                  乘方 (xy )
		 x % y                   取模 (x mod y )
		 -x                      改变操作数的符号位
		 +x                      什么也不做
		 ~x                      ~x=-(x+1)
		 abs(x )                 绝对值
		 divmod(x ,y )           返回 (int(x / y ), x % y )
		 pow(x ,y [,modulo ])    返回 (x ** y ) x % modulo
		 round(x ,[n])           四舍五入，n为小数点位数
		 x < y                   小于
		 x > y                   大于
		 x == y                  等于
		 x != y                  不等于(与<>相同)
		 x >= y                  大于等于
		 x <= y                  小于等于

	- 教程 快速入门 
		http://www.diveintopython.net/	Dive Into Python

		深入的话，看python源码剖析（C实现的动态语言）

		这里有不少书籍，比较详细：
		http://www.brpreiss.com/

	- 
		Zope - opensource appserver written by python
		PyDev eclipse python插件 http://www.fabioz.com/pydev/updates
		PyDev for Eclipse 简介 http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-pydev/index.html
	- python小工具（根据配置文件订正对应的表）
		数据库操作
		文件操作
		读取执行参数
	- 命令行执行py文件
		配置python命令到环境变量中
		cmd or shell中执行：python xxx.py即可；参数传递 --key=xxx,--name=xxx
	
	- __init__.py在目录下，代表module包；一般为空，也可初始化值

* Google App Engine 
		虽然GAE有很多限制和缺陷，但是我对GAE还是喜爱有加的。GAE是免费的，任何人都可以很轻松的通过GAE实现自己的Web应用。比如，做一些实用的小工具，
	实现一个博客程序来练手。通过GAE，我们可以轻松的搭建属于自己的Blog(micolog)，搭建属于自己的Wiki系统(NancyWiki)。
	没有GAE，就不会有大家都懂的gappproxy，gtap，twiter-feed。是的，你懂的。	
	from: http://www.cnblogs.com/coderzh/archive/2010/11/30/goodby-google-app-engine.html
* powerdesigner  生成er图
	pd12 连接mysql，database菜单-configure data connection - 选择 connection profiles 设置即可

* shell
	- 例子
		-----
		maven,tomcat, jetty 自动部署脚本

		#tomcat:

		cd /home/deploy/javaside.org/javaside/

		log=../.mvn-pkg.log

		webPath=/var/www/javaside.org/

		mvn clean package -Pproduct | tee $log
		t=$(grep "BUILD SUCCESS" $log)

		if [ $? -eq 0 ]
		then
		    #mvn package success deploy project
		    t=$(ps aux |grep "catalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start" | grep -v grep)

		    if [ $? -eq 0 ]
		    then
			#stop tomcat server
			echo ""
			echo "stop tomcat ......"
			echo ""
			/usr/local/tomcat/bin/shutdown.sh

			while true
			do
			    t=$(ps aux |grep "catalina.home=/usr/local/tomcat -Djava.io.tmpdir=/usr/local/tomcat/temp org.apache.catalina.startup.Bootstrap start" | grep -v grep)

			    if [ $? -ne 0 ]
			    then
				#now stoping, wait
				sleep 1
			    else
				break
			    fi
			done
		    fi

		    rm -rf ${webPath}/*
		    cp -r /home/deploy/javaside.org/javaside/target/javaside/* ${webPath}
		    cp ../config/*.properties ${webPath}/WEB-INF/classes/

		    #start tomcat server
		    echo ""
		    echo "start tomcat ......"
		    echo ""
		    /usr/local/tomcat/bin/startup.sh
		else
		    echo ""
		    echo "===================== Project Build Fail ========================="
		    echo ""
		fi

		rm -rf $log

		tail -f /usr/local/tomcat/logs/catalina.out


		#jetty:

		cd /home/deploy/javaside.org/javaside/

		log=../.mvn-pkg.log

		webPath=/var/www/jetty/javaside.org/

		mvn clean package -Pproduct | tee $log
		t=$(grep "BUILD SUCCESS" $log)

		if [ $? -eq 0 ]
		then
		    #mvn package success deploy project
		    t=$(ps aux |grep "/usr/local/jetty/start.jar" | grep -v grep)

		    if [ $? -eq 0 ]
		    then
			#stop jetty server
			echo ""
			echo "stop jetty ......"
			echo ""
			/usr/local/jetty/bin/jetty.sh stop

		    fi

		    rm -rf ${webPath}/*
		    cp -r /home/deploy/javaside.org/javaside/target/javaside/* ${webPath}
		    cp ../config/*.properties ${webPath}WEB-INF/classes/

		    #start jetty server
		    echo ""
		    echo "start jetty ......"
		    echo ""
		    /usr/local/jetty/bin/jetty.sh start
		else
		    echo ""
		    echo "===================== Project Build Fail ========================="
		    echo ""
		fi

		rm -rf $log

		tail -f /usr/local/jetty/logs/$(date "+%Y_%m_%d").stderrout.log

		自启动脚本

		export JAVA_HOME=/usr/local/java
		export PATH=$JAVA_HOME/bin/:$PATH
		export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATH
		       
		/usr/local/jetty/bin/jetty.sh start
		-----
	- shell带颜色输出，比如区分检查结果的成功（绿色）和失败（红色）
		echo -e "\033[32m [something here] \033[0m"
		
		shell脚本中echo显示内容带颜色[zz]
		-----		
		shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数-e 
	　　格式如下： 
	　　echo -e "\033[字背景颜色；文字颜色m字符串\033[0m" 
	　　例如： 
	　　echo -e "\033[41;36m something here \033[0m" 
	　　其中41的位置代表底色， 36的位置是代表字的颜色 
	　　注： 
	　　1、字背景颜色和文字颜色之间是英文的"" 
	　　2、文字颜色后面有个m 
	　　3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 
	　　下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配 
	　　例 
	　　echo -e “\033[31m 红色字 \033[0m” 
	　　echo -e “\033[34m 黄色字 \033[0m” 
	　　echo -e “\033[41;33m 红底黄字 \033[0m” 
	　　echo -e “\033[41;37m 红底白字 \033[0m” 
	　　字颜色：30—–37 
	　　echo -e “\033[30m 黑色字 \033[0m” 
	　　echo -e “\033[31m 红色字 \033[0m” 
	　　echo -e “\033[32m 绿色字 \033[0m” 
	　　echo -e “\033[33m 黄色字 \033[0m” 
	　　echo -e “\033[34m 蓝色字 \033[0m” 
	　　echo -e “\033[35m 紫色字 \033[0m” 
	　　echo -e “\033[36m 天蓝字 \033[0m” 
	　　echo -e “\033[37m 白色字 \033[0m” 
	　　字背景颜色范围：40—–47 
	　　echo -e “\033[40;37m 黑底白字 \033[0m” 
	　　echo -e “\033[41;37m 红底白字 \033[0m” 
	　　echo -e “\033[42;37m 绿底白字 \033[0m” 
	　　echo -e “\033[43;37m 黄底白字 \033[0m” 
	　　echo -e “\033[44;37m 蓝底白字 \033[0m” 
	　　echo -e “\033[45;37m 紫底白字 \033[0m” 
	　　echo -e “\033[46;37m 天蓝底白字 \033[0m” 
	　　echo -e “\033[47;30m 白底黑字 \033[0m” 
	　　最后面控制选项说明 
	　　\33[0m 关闭所有属性 
	　　\33[1m 设置高亮度 
	　　\33[4m 下划线 
	　　\33[5m 闪烁 
	　　\33[7m 反显 
	　　\33[8m 消隐 
	　　\33[30m — \33[37m 设置前景色 
	　　\33[40m — \33[47m 设置背景色 
	　　\33[nA 光标上移n行 
	　　\33[nB 光标下移n行 
	　　\33[nC 光标右移n行 
	　　\33[nD 光标左移n行 
	　　\33[y;xH设置光标位置 
	　　\33[2J 清屏 
	　　\33[K 清除从光标到行尾的内容 
	　　\33[s 保存光标位置 
	　　\33[u 恢复光标位置 
	　　\33[?25l 隐藏光标 
	　　\33[?25h 显示光标 
		-----
	- shell将执行结果赋值给一个变量
		shell赋值语句，等号两边不能有空格
		
		var1=`ls -al |head -n1`
		echo $var1

	- 暂停 按任意键继续
		使用 read 命令暂停，等待用户输入，不作任何后续判断即可，这样任意键都可以继续
		read -p "Press any key to continue." var

	- 遍历指定目录下所有文件
		for i in $(find .)
		do
		    echo $i
		done
	- 根据shell命令行参数执行对应的方法
		
	- 判断当前执行shell的用户	用户判断
		if [ $USER != "admin" ]		      或者  $(whoami) != "admin" Or `whoami` != "admin"
		then
			echo "****** ERROR: only user admin can execute this script!"
			exit 2
		fi		
	-  字符串分组
		cat tempoutfile20121119.txt | grep "cn-hangzhou-dg-a01" |awk -F"|" '{print $3}' >temmmp3
	- 
		#!/bin/bash
		str=$1
		echo $str
		service keepalived $str
	- if [ $# -lt 2 ]; then 命令行参数个数小于2判断
		if [ $# -eq 3 ]; then 参数个数等于3
		shell运算符：
			
	- 判断输入参数个数
		#!/bin/sh
		num=$#
		echo $num
		
	- shell执行时，确保有执行权限
	- shell中调用其他shell ,用点运算符或source命令
		./shell.sh stop
	- 根据参数执行任务shell
		-----
			#!/bin/bash
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    insert) echo "device inserted.";;
			    remove) echo "device removed.";;
			    *) echo "invalid option.";;
			esac
		-----
	- 常用shell ，执行sh后，用tail显示执行log
		-----
			#!/bin/bash

			if [ $# -lt 2 ];
			then
				echo "USAGE: $0 -f server.properties"
				exit 1
			fi
			LOGFILE=$(dirname $0)/../logs/metaServer.log

			nohup sh $(dirname $0)/meta-run-class.sh com.taobao.metamorphosis.server.MetamorphosisStartup $@ 2>&1 >>$LOGFILE &
			tail $LOGFILE -f
		-----
* linux
	- 命令行下html浏览工具
		htmlview

	- sysctl命令 * 内核配置 * kernel配置 * kernel设置
		vi /etc/sysctl.conf
		sysctl -p 使内核配置生效
		sysctl - configure kernel parameters at runtime

	- 目录树显示，树状目录显示
		tree /home/admin/ -L 2 
	-  linux在关机或重启时自动执行某个任务
	　　先写一个脚本放在/etc/rc.d/init.d下，chmod -f 777 ， 再ln -s 到 /etc/rc.d/rc0.d/K01脚本名 与 /etc/rc.d/rc6.d/K01脚本名,同时也要 ln -s 到 /etc/rc.d/rc3.d/S99脚本名 与/etc/rc.d/rc5.d/S99脚本名。
	　　K开头的代表系统关闭的时候执行，S开头的代表开机的时候执行。注意服务器脚本编写的规范，因为有K开通的软链接并不一定会在关机的时候自动去执行，这是为什么呢？
	刚开始一直没搞明白，后来从网上看到，执行K脚本的时候会查询/var/lock/subsys/下是否有与K开头脚本同名的空文件名，如果没有就不去执行，所以要按照服务器脚本编写的规范，
	启动的时候要在/var/lock/subsys/先touch一个与K01后面同名的空文件.同时也要调用/etc/rc.d/init.d/functions能够接受star与stop命令信号，具体可以参考/etc/rc.d/rc文件，
	本人是在/etc/rc.d/rc0.d/K01yum基础上改写实现的。

	补充：
	--------
		linux /etc/rc.d/目录的详解
		分类： Linux 2008-04-09 16:16 1516人阅读 评论(0) 收藏 举报

		rc.d的内容如下：
		init.d/ :各种服务器和程序的二进制文件存放目录。
		rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
		还有三个脚本:rc.sysinit, rc, rc.local

		redhat的启动方式和执行次序是：
		加载内核
		执行init程序
		/etc/rc.d/rc.sysinit # 由init执行的第一个脚本
		/etc/rc.d/rc $RUNLEVEL # $RUNLEVEL为缺省的运行模式
		/etc/rc.d/rc.local
		/sbin/mingetty # 等待用户登录

		在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
		调入keymap以及系统字体
		启动swapping
		设置主机名
		设置NIS域名
		检查（fsck）并mount文件系统
		打开quota
		装载声卡模块
		设置系统时钟
		等等。

		/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
		，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
		从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
		/etc/rc.d/rc3.d/下的脚本。
		值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
		的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

		init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
		action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
		至此，LINUX的启动结束。 

		 

		最后自己补充一些:

		1. 许多网络服务都由超级服务/etc/rc.d/init.d/xinetd启动,这些服务的配置文件在/etc/xinetd.d/目录下,

		如telnet就是由xinetd启动的,其配置文件如下(fc7)

		  1 # default: on
		  2 # description: The telnet server serves telnet sessions; it uses /
		  3 #   unencrypted username/password pairs for authentication.
		  4 service telnet
		  5 {
		  6     flags       = REUSE
		  7     socket_type = stream
		  8     wait        = no
		  9     user        = root
		 10     server      = /usr/sbin/in.telnetd
		 11     log_on_failure  += USERID
		 12     disable     = no
		 13 }
		修改配置文件以后,重启xinetd服务即可.
	from: http://blog.csdn.net/cradmin/article/details/2270497
	--------
		2. 除了直接调用脚本外(如/etc/rc.d/init.d/xinetd),还可以用service命令来控制init.d目录下的服务,

		     如 service xinetd restart,


	ps：上面摘自网络，个人总结：
		要在linux开关机时执行自定义任务，可在 /etc/rc.d/init.d 目录下放脚本；ln到/etc/rc.d/目录下对应启动级别目录下；然后在/var/lock/subsys/目录下建同名文件。
	 
	- text 分辨率修改
		vim /boot/grub/menu.lst 
		kernel行末尾加上 vga=791
	- curl 
		测

	- beep关闭
		1）编辑 /etc/inputrc，找到
		＃set bell style none
		这一行，去掉前面的注释符号。
		2）或者编辑 /etc/profile，添加这一句，	setterm -blength 0即可。
	- md5sum
		计算md5值，验证文件完整性。
	- 设置开机启动
		在 /etc/rc.d/rc.local 	    目录：
			/etc/rc.d目录详解：
			--------
				rc.d的内容如下：
				init.d/ :各种服务器和程序的二进制文件存放目录。
				rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
				还有三个脚本:rc.sysinit, rc,  rc.local

				redhat的启动方式和执行次序是：
				加载内核
				执行init程序
				/etc/rc.d/rc.sysinit            # 由init执行的第一个脚本
				/etc/rc.d/rc $RUNLEVEL          # $RUNLEVEL为缺省的运行模式
				/etc/rc.d/rc.local
				/sbin/mingetty                  # 等待用户登录

				在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
				  调入keymap以及系统字体
				  启动swapping
				  设置主机名
				  设置NIS域名
				  检查（fsck）并mount文件系统
				  打开quota
				  装载声卡模块
				  设置系统时钟
				等等。


				/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
				，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
				从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
				/etc/rc.d/rc3.d/下的脚本。
				值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
				的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

				init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
				action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
				至此，LINUX的启动结束。
				from: http://zhidao.baidu.com/question/10963481.html
			--------
	- /etc/init.d/ 目录，存放程序的启动文件，比如mysql，httpd，iptables等等，这里都是程序安装好后，统一把控制脚本放到这里
	- 看程序启动参数
		ps 命令看程序启动命令
	- 系统配置，语言，网络等等
		/etc/sysconfig 目录下
	- 字符编码，语言设置，编码设置	      
		vim的i进入insert模式错误：
		/etc/sysconfig/i18n
		内容修改为：
			LANG="en_US.UTF-8"
			SYSFONT="latarcyrheb-sun16"
		重新加载下：
			source /etc/sysconfig/i18n
		vim按i键，正常进入insert模式

		支持中文 ，解决中文乱码

	- 修改所有者，修改拥有者
		例：要将当前目录下名 title 的文件夹及其子文件的所有者改为geust组的su用户，方法如下：
		#chown -R su.geust title
		-R 递归式地改变指定目录及其下的所有子目录和文件的拥有者。

		chown -R admin src ——修改当前目录中的src目录及其所有内容的所有者为admin

	- 端口占用查询 ，端口查询 linux端口查询
		查询端口被谁占用（linux命令）
		分类： linux 资料或经验 2012-03-26 16:59 118人阅读 评论(0) 收藏 举报
		lsof -i:3306
		查看3306端口被谁占用
		lsof简介
		lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，
		还可以访问网络连接和硬件。所以如传输控制协议 (tcp) 和用户数据报协议 (udp) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，
		无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量
		关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。
		lsof使用
		lsof输出信息含义
		在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。
		from: http://blog.csdn.net/shuhuai007/article/details/7395690
	- ls --color=never 或 --color=aways
		命令行 ，终端 ，颜色
	- ssh远程命令行 ，通过 rz ,sz 传递/接受文件
		远程拷贝目录结构：
			scp -r $LIB_DIR/* admin@$1:$LIB_DIR/   #这里需要ssh可以自动登入，比如通过公钥认证
				scp -r xx.zip admin@xx.xx.xx.xx:/home/youDir
			------
				Linux下rz/sz安装及使用方法
				-
				-
				1)    工具说明
				在SecureCRT这样的ssh登录软件里, 通过在Linux界面里输入rz/sz命令来上传/下载文件. 对于RHEL5, rz/sz默认没有安装所以需要手工安装.
				sz: 将选定的文件发送(send)到本地机器;
				rz：运行该命令会弹出一个文件选择窗口, 从本地选择文件上传到服务器(receive).
				下载安装包lrzsz-0.12.20.tar.gz: http://www.ohse.de/uwe/software/lrzsz.html

				2)    软件安装
				首先通过sftp工具把安装文件上传到/tmp目录下.

				# cd /tmp
				# tar zxvf lrzsz-0.12.20.tar.gz && cd lrzsz-0.12.20
				# ./configure && make && make install
				 

				上面安装过程默认把lsz和lrz安装到了/usr/local/bin/目录下, 下面创建软链接, 并命名为rz/sz:

				# cd /usr/bin
				# ln -s /usr/local/bin/lrz rz
				# ln -s /usr/local/bin/lsz sz
				 

				3)    使用说明
				打开SecureCRT软件 -> Options -> session options -> X/Y/Zmodem 下可以设置上传和下载的目录; 然后在用SecureCRT登陆linux终端的时候:
				# sz filename (发送文件到客户端,zmodem接收可以自行启动)
				# rz (从客户端上传文件到linux服务端)

				:)

				来自：http://www.ej38.com/showinfo/linux-183843.htm
			------
	
		* SecureCRT
			- 快捷键 alt + 1,2,3....切换子标签窗口

	-   $# 是传给脚本(或者函数)的参数个数, $0 是脚本本身的名字, $@ 是传给脚本(或者函数)的所有参数的列表. 举例:

                  QUOTE:
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; cat foo.sh
                  #!/bin/bash

                  echo "script name   : $0"
                  echo "# of arguments: $#"
                  echo "all arguments : $@"
                  echo "arguments in order:"
                  for sArg in "$@"; do
                      echo "  $sArg"
                  done
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa bb cc
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc
                  arguments in order:
                    aa
                    bb
                    cc
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa "bb cc" dd
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc dd
                  arguments in order:
                    aa
                    bb cc
                    dd
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; bye


                  付：
                    $0   这个程式的执行名字       
                    $n   这个程式的第n个参数值，n=1..9       
                    $*   这个程式的所有参数       
                    $#   这个程式的参数个数       
                    $$   这个程式的PID       
                    $!   执行上一个背景指令的PID       
                    $?   执行上一个指令的返回值
	- linux shell命令中Esac是什么意思？
		一些刚刚接触bash编程的人，总是很奇怪bash里的一些关键字，知道它的功能，但不知道为什么要这样写。比如：
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac
		fi是if语句的结束，esac是case语句的结束。Fi和esac这样的关键字是不是很怪异呢？呵，仔细想一想，一点也不怪，考虑一下{} [] 等等，{和}是垂直轴对称的，[和]是垂直轴对称的。现在来看， if和fi及case和esac不也是这样吗？它们刚好反过，分别表示开始和结束。
	- 内核升级 linux 内核 升级 
		下面是centos例子：
			----
				具体的过程如下:
				[root@localhost ~]# uname -r
				2.6.18-194.el5
				1.下载linux-2.6.30内核包到/usr/src目录
				cd /usr/src
				wget ftp://ftp.kernel.org/pub/linux/kernel/v2.6/linux-2.6.30.tar.gz
				tar -xzvf linux-2.6.30.tar.bz2 -C /usr/src
				cd linux-2.6.30
				make mrproper  清除环境变量，即清除配置文件
				make menuconfig 在菜单模式下选择需要编译的内核模块:
				networking support—>networking options—>network packet filtering framework(netfilter)
				(1).core netfilter configuration
				A 勾中”Netfilter connection tracking support”  -m state相关模块是依赖它的，不选则没有。
				B 将netbios name service protocal support(new)   编译成模块,不然后面升级iptables后启动时会出错
				C 勾中“Netfilter Xtables support (required for ip_tables)”
				(2).IP: Netfilter Configuration
				A 将 “IPv4 connection tracking support (require for NAT)” 编译成模块。
				B 勾中IP tables support (required for filtering/masq/NAT) 。
				C 将 “Full NAT” 下的 “MASQUERADE target support” 和 “REDIRECT target support” 编译成模块
				(3).其它模块可以根据自己的需要进行选择,若不懂可以参考内核配置手册.
				make clean  确保所有东西均保持最新状态.
				make bzImage  生成内核文件
				make modules 编译模块
				make modules_install 安装模块
				make install  安装
				mkinitrd  /boot/initrd_2.6.30.img  2.6.30  根据内核版本和指定参数生成映像文件
				cp arch/x86/boot/bzImage /boot/vmlinuz-2.6.30
				cp /usr/src/linux-2.6.30/System.map /boot/System.map-2.6.30
				2.在/etc/grub.conf添加如下2.6.30的信息,并把default=1改为default=0
				[root@localhost ~]# cat /etc/grub.conf
				# grub.conf generated by anaconda
				#
				# Note that you do not have to rerun grub after making changes to this file
				# NOTICE:  You have a /boot partition.  This means that
				#          all kernel and initrd paths are relative to /boot/, eg.
				#          root (hd0,0)
				#          kernel /vmlinuz-version ro root=/dev/VolGroup00/LogVol00
				#          initrd /initrd-version.img
				#boot=/dev/sda
				default=0
				timeout=5
				splashimage=(hd0,0)/grub/splash.xpm.gz
				hiddenmenu
				title CentOS (2.6.18-194.el5)
					root (hd0,0)
					kernel /vmlinuz-2.6.18-194.el5 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.18-194.el5.img
				title CentOS (2.6.30)
					root (hd0,0)
					kernel /vmlinuz-2.6.30 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.30.img
				3.此步若没有操作,重启会报错”insmod: error inserting ‘/lib/dm-region-hash.ko’: –1 File exits”,原因是重复了，根据网上查到的资料，2.6.x自编译内核会有这个小bug,我测试过不修改直接重启，虽然有报错，但仍然可以进入系统的.

				[root@localhost]cp /boot/initrd-2.6.30.img /tmp
				[root@localhost]cd /tmp/
				[root@localhost tmp]mkdir newinitrd
				[root@localhost tmp]cd newinitrd/
				[root@localhost newinitrd]zcat ../initrd-2.6.30.img |cpio -i
				[root@localhost newinitrd]vi init             删掉重复的如下两行:
				echo “Loading dm-region-hash.ko module”
				insmod /lib/dm-region-hash.ko
				[root@localhost newinitrd]# find .|cpio -c -o > ../initrd
				14765 blocks
				[root@localhost newinitrd]# cd ..
				[root@localhost tmp]# gzip -9 < initrd > initrd-2.6.30.img
				[root@localhost tmp]# ls
				gconfd-root  initrd  initrd-2.6.30.img  mapping-root  newinitrd  scim-panel-socket:0-root
				[root@localhost tmp]# mv /boot/initrd-2.6.30.img /home/
				[root@localhost tmp]# cp initrd-2.6.30.img /boot/
				[root@localhost tmp]#reboot
				4.重启成功后,再看看内核，是2.6.30，ok了。
				[root@localhost ~]# uname -r
				2.6.30 
			----
			from: http://bbs.51cto.com/thread-788212-1.html
		实际：
			make menuconfig 报需要ncurses包(及其devel包)
				yum install ncurses-devel //通过yum安装


	linux command eg 命令
	字符转换 unix字符 window字符
	unix2dos dos2unix

	SERVER=/home/user - 定义=号两边不能有空格

	将shell执行的pid保存到文件，读取文件中的pid关闭程序
	#! /bin/sh
	SERVER=/home/chengs
	java test > $SERVER/server.log & echo $! > $SERVER/server.pid
	
	- 关于Linux网络配置
		一：什么是网络接口卡以及如何查看网络接口的网络信息：
		 在Linux系统中，主机的网络接口卡通常称为“网络接口”，我们可以使用ifconfig命令来查看网络
		 
		接口的信息（普通用户使用/sbin/ifconfig）:
		 [root@lht ~]# ifconfig
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:6712 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1219 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:590780 (576.9 KiB)  TX bytes:156407 (152.7 KiB)
			   Interrupt:177 Base address:0x1080
		 
		lo        Link encap:Local Loopback
			   inet addr:127.0.0.1  Mask:255.0.0.0
			   inet6 addr: ::1/128 Scope:Host
			   UP LOOPBACK RUNNING  MTU:16436  Metric:1
			   RX packets:1654 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1654 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:0
			   RX bytes:3893045 (3.7 MiB)  TX bytes:3893045 (3.7 MiB)
		 “eth0”是Linux系统中第一块以太网卡的名称，在大多数主机中只有一块物理网卡，因此“eth0”
		 
		代表系统中唯一的网络接口。
		 “lo”是Linux系统中的“环回”网络接口，“lo”并不代表真正的网络接口，而是一个虚拟的网络
		 
		接口，其IP地址永远是“127.0.0.1”；“lo”网络接口通常用于对本机的网络测试，这样在主机没
		 
		有物理网络接口或物理网络接口没有激活时Linux系统仍然可以完成网络相关的操作；
		 查看指定接口网络信息：ifconfig 网络接口名称：
		 [root@lht ~]# ifconfig eth0
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:832 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:139 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:73325 (71.6 KiB)  TX bytes:22844 (22.3 KiB)
			   Interrupt:177 Base address:0x1080
		 
		[root@lht ~]#
		 其中“HWaddr”表示网络接口物理地址（MAC地址），“inet addr”表示网络接口IP地址，“Bcast
		 
		”表示网各接口所在网络的广播地址，“Mask”表示网络接口的子网掩码；另外我们还可以用
		 
		ifconfig -a查看所有网络接口的网络信息。
		 二：查看网关地址和路由信息：
		 1：route:route命令不使用任何命令选项和参数时可以显示当前Linux主机中的路由表信息：
		 [root@lht ~]# route
		 Kernel IP routing table
		 Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
		 192.168.5.0     *               255.255.255.0   U     0      0        0 eth0
		 169.254.0.0     *               255.255.0.0     U     0      0        0 eth0
		 default         192.168.5.1     0.0.0.0         UG    0      0        0 eth0
		 2：使用ping命令测试与其他主机的网络连接：
		 ping 目标主机地址
		 [root@lht ~]# ping 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.123 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.176 ms
		 64 bytes from 192.168.5.104: icmp_seq=3 ttl=64 time=0.163 ms
		 64 bytes from 192.168.5.104: icmp_seq=4 ttl=64 time=0.818 ms
		 
		--- 192.168.5.104 ping statistics ---
		 4 packets transmitted, 4 received, 0% packet loss, time 3004ms
		 rtt min/avg/max/mdev = 0.123/0.320/0.818/0.288 ms
		 注意：ping命令会持续发送测试包，因此会一直在屏幕上显示每个包的测试结果，使用Ctrl+C组合键
		 
		将结束ping命令发送测试数据包；
		 使用ping命令发送指定数量的数据包进行网络测试连接：
		 ping -c 测试数据包的数量 目标的主机地址：
		 [root@lht ~]# ping -c 2 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.146 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.170 ms
		 
		--- 192.168.5.104 ping statistics ---
		 2 packets transmitted, 2 received, 0% packet loss, time 1002ms
		 rtt min/avg/max/mdev = 0.146/0.158/0.170/0.012 ms
		 3:使用traceroute命令测试当前主机到目的主机之间经过了哪些网络节点：
		 traceroute 目的主机地址
		 [root@lht ~]# traceroute 192.168.5.104
		 traceroute to 192.168.5.104 (192.168.5.104), 30 hops max, 40 byte packets
		  1   (192.168.5.104)  0.859 ms  0.255 ms  0.625 ms
		 三：查看主机名称信息：
		 1：使用hostname命令查看当前主机名称：
		 [root@lht ~]# hostname
		 lht
		 2：更改主机名称：
		 [root@lht ~]# hostname lihantuan
		 [root@lht ~]# hostname
		 lihantuan
		 3：使用nslookup查询liuux主机中的域名：
		 nslookup->输入需要查询的域名->回车
		 nslookup 待解析的域名
		 四：网络设置方法：
		 1：DHCP网络配置：
		 使用dhclient命令可以从DHCP服务器中申请新的网络配置应用于当前的Linux主机；
		 2：手工网络配置：
		 ip地址配置命令：
		 ifconfig eth0 ip地址 netmask 子网掩码
		 [root@lht ~]# ifconfig eth0 192.168.5.247 netmask 255.255.255.0
		 [root@lht ~]#
		 注意ifconfig命令设置的网络接口属性只在当前系统运行时起效，重启后将按照网络接口配置文件
		 
		ifcfg-xxx重新设置网络接口属性；
		 3：路由配置命令：
		 添加默认网关路由：
		 route add default gw 网关地址
		 [root@lht ~]# route add default gw 192.168.5.104
		 [root@lht ~]#
		 删除默认网关：
		 route del default gw 网关地址：
		 [root@lht ~]# route del default gw 192.168.5.104
		 [root@lht ~]#
		 4：通过修改配置文件进行网络设置：
		 修改网络接口配置文件ifcfg-xxx,其中\"xxx\"是网络接口名称：
		 vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 [root@lht ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 # Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]
		 DEVICE=eth0//用于设置网络接口的名称
		 BOOTPROTO=static//用于设置网络接口是配置为静态地址（static）还是配置为dhcp；
		 BROADCAST=192.168.5.255
		 HWADDR=00:0C:29:D1:42:3F
		 IPADDR=192.168.5.247 //设置网络接口地址
		 GATEWAY=192.168.5.1 //设置网络接口的默网关
		 IPV6ADDR=
		 IPV6PREFIX=
		 NETMASK=255.255.255.0 //设置网络接口的子网掩码
		 NETWORK=192.168.5.0
		 ONBOOT=yes
		 保存好配置文件后还得重启网络服务：
		 [root@lht ~]# /etc/init.d/network restart
		 Shutting down interface eth0:                              [  OK  ]
		 Shutting down loopback interface:                          [  OK  ]
		 Bringing up loopback interface:                            [  OK  ]
		 Bringing up interface eth0:                                [  OK  ]
		 5：修改主机配置文件：
		 /etc/sysconfig/network
		 [root@lht ~]# cat /etc/sysconfig/network
		 NETWORKING=yes
		 NETWORKING_IPV6=yes
		 HOSTNAME=lht
		 GATEWAY=192.168.5.1
		 如果改了/etc/sysconfig/network里的主机名，则还需更改/etc/hosts里的主机名
		 [root@lht ~]# cat /etc/host
		 cat: /etc/host: No such file or directory
		 [root@lht ~]# cat /etc/hosts
		 # Do not remove the following line, or various programs
		 # that require network functionality will fail.
		 127.0.0.1               lht localhost.localdomain localhost
		 ::1             localhost6.localdomain6 localhost6
		 再重启系统就生效；
		 系统管理员还可以通过修改hosts文件添加更多的IP地址与主机的对应记录，hosts文件保存后就会立
		刻生效。
		 6：域名服务器配置文件：/etc/resolv.conf
		 [root@lihantuan ~]# cat /etc/resolv.conf
		 nameserver 192.168.6.100
		 nameserver 192.168.6.90
		 nameserver配置选项设置DNS服务器的IP地址，文件中最多可以有3个nameserver记录，linux系统会
		 
		优先使用文件最上面的nameserver记录，当前面的DNS服务器无效时系统会自动使用后面的DNS服务器
		 进行域名解析。

		来自：http://my.oschina.net/adamboy/blog/35109

	kill `cat server.pid` -- 这里注意是波浪号 ，不是单引号
	--------
		############################################################################
		mount -l -t

		sh startup.sh

		############################################################################
		该如何才能知道系统都有什么硬件设备，有如下几种方式：
		方式一：
		使用lsdev命令，可以显示系统中的设备及其特征。
		例如：lsdev -C
		但是一般的系统上可能没有这个命令，比如我装的fedora上面就没有这个命令。
		方法二：
		显示/proc/dev文件，这个文件记录了系统的一些硬件信息，
		例如：cat /proc/dev
		方法三：
		如果要查找特定的usb设备，则可以使用lsusb命令，列出所有的usb设备。
		如果要查找特定的pcmcia设备，则可以使用lspcmcia命令，列出所有的pcmcia设备。
		如果要查找特定的pci设备，则可以使用lspci命令，列出所有的pcm设备。
		来自：达内BBS
		############################################################################

		有些在freebsd下也能用…
		# uname -a               # 查看内核/操作系统/CPU信息
		# head -n 1 /etc/issue   # 查看操作系统版本
		# cat /proc/cpuinfo      # 查看CPU信息
		# hostname               # 查看计算机名
		# lspci -tv              # 列出所有PCI设备
		# lsusb -tv              # 列出所有USB设备
		# lsmod                  # 列出加载的内核模块
		# env                    # 查看环境变量资源
		# free -m                # 查看内存使用量和交换区使用量
		# df -h                  # 查看各分区使用情况
			-h human can read
		# du -sh         # 查看指定目录的大小
		# grep MemTotal /proc/meminfo   # 查看内存总量
		# grep MemFree /proc/meminfo    # 查看空闲内存量
		# uptime                 # 查看系统运行时间、用户数、负载
		# cat /proc/loadavg      # 查看系统负载磁盘和分区
		# mount | column -t      # 查看挂接的分区状态
		# fdisk -l               # 查看所有分区
			/dev/hda4            2946        3916     7799557+   5  Extended
				未分配的空间
				fdisk /dev/hda
				m查看帮助
				n为新建分区
				输入起始和结束cylinders ，可以通过fdisk -l 查看可分配空间，工具也会提示可分配空间

		# swapon -s              # 查看所有交换分区
		# hdparm -i /dev/hda     # 查看磁盘参数(仅适用于IDE设备)
		# dmesg | grep IDE       # 查看启动时IDE设备检测状况网络
		# ifconfig               # 查看所有网络接口的属性
		# iptables -L            # 查看防火墙设置
		# route -n               # 查看路由表
		# netstat -lntp          # 查看所有监听端口
		# netstat -antp          # 查看所有已经建立的连接
		# netstat -s             # 查看网络统计信息进程
		# ps -ef                 # 查看所有进程
		# top                    # 实时显示进程状态用户
		# w                      # 查看活动用户
		# id             # 查看指定用户信息
		# last                   # 查看用户登录日志
		# cut -d: -f1 /etc/passwd   # 查看系统所有用户
		# cut -d: -f1 /etc/group    # 查看系统所有组
		# crontab -l             # 查看当前用户的计划任务服务
		# chkconfig –list       # 列出所有系统服务
			chkconfig  provides  a  simple  command-line  tool  for  maintaining the /etc/rc[0-6].d directory hierarchy by relieving system administrators of 
			the task of directly manipulating the  numerous  symbolic  links  in  those directories.
		# chkconfig –list | grep on    # 列出所有启动的系统服务程序
		# rpm -qa                # 查看所有安装的软件包
		cat /proc/cpuinfo ：查看CPU相关参数
		cat /proc/partitions ：查看硬盘和分区
		cat /proc/meminfo ：查看内存信息
		cat /proc/version ：查看版本，类似uname -r
		cat /proc/ioports ：查看设备io端口
		cat /proc/interrupts ：查看中断
		cat /proc/pci ：查看pci设备的信息
		cat /proc/swaps ：查看所有swap分区的信息
		来自：达内BBS
		############################################################################
		linux目录架构
		/   根目录
		/bin    常用的命令 binary file 的目錄
		/boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内
		     /boot/grub/menu.lst   GRUB设置
		     /boot/vmlinuz   内核
		     /boot/initrd     核心解壓縮所需 RAM Disk
		/dev    系统周边设备     
		/etc    系统相关设定文件
		     /etc/DIR_COLORS   设定颜色
		     /etc/HOSTNAME   设定用户的节点名
		     /etc/NETWORKING   只有YES标明网络存在
		     /etc/host.conf 文件说明用户的系统如何查询节点名
		     /etc/hosts 设定用户自已的IP与名字的对应表
		     /etc/hosts.allow 设置允许使用inetd的机器使用 
		     /etc/hosts.deny 设置不允许使用inetd的机器使用
		     /etc/hosts.equiv 设置远端机不用密码
		     /etc/inetd.conf 设定系统网络守护进程inetd的配置
		     /etc/gateways 设定路由器
		     /etc/protocols 设定系统支持的协议
		     /etc/named.boot 设定本机为名字服务器的配置文件
		     /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP
		     /etc/resolv.conf    设置DNS  
		     /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這兩個 X Server 的設定檔
		     /etc/fstab    记录开机要mount的文件系统
		     /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel
		     /etc/issue 记录用户登录前显示的信息
		     /etc/group 设定用户的组名与相关信息
		     /etc/passwd 帐号信息
		     /etc/shadow 密码信息
		     /etc/sudoers 可以sudo命令的配置文件
		     /etc/securetty 设定哪些终端可以让root登录
		     /etc/login.defs 所有用户登录时的缺省配置
		     /etc/exports 设定NFS系统用的
		     /etc/init.d/   所有服務的預設啟動 script 都是放在這裡的，例如要啟動或者關閉
		     /etc/xinetd.d/  這就是所謂的 super daemon 管理的各項服務的設定檔目錄
		     /etc/modprobe.conf   内核模块额外参数设定
		     /etc/syslog.conf   日志设置文件
		/home   使用者家目录
		/lib    系统会使用到的函数库
		     /lib/modules   kernel 的相关模块
		     /var/lib/rpm   rpm套件安装处 
		/lost+found    系統不正常產生錯誤時，會將一些遺失的片段放置於此目錄下
		/mnt     外设的挂载点
		/media   与/mnt类似
		/opt     主机额外安装的软件
		/proc    虚拟目录，是内存的映射
		      /proc/version   内核版本
		       /proc/sys/kernel   系统内核功能
		/root    系统管理员的家目录
		/sbin    系统管理员才能执行的指令
		/srv     一些服務啟動之後，這些服務所需要取用的資料目錄
		/tmp     一般使用者或者是正在執行的程序暫時放置檔案的地方
		/usr     最大的目录，存许应用程序和文件
		    /usr/X11R6：   X-Window目录 
		    /usr/src：    Linux源代码
		    /usr/include：系统头文件
		    /usr/openwin 存放SUN的OpenWin 
		    /usr/man 在线使用手册
		    /usr/bin           使用者可執行的 binary file 的目錄
		    /usr/local/bin     使用者可執行的 binary file 的目錄
		    /usr/lib           系统会使用到的函数库
		    /usr/local/lib     系统会使用到的函数库
		    /usr/sbin          系统管理员才能执行的指令
		    /usr/local/sbin    系统管理员才能执行的指令
		/var   日志文件
		    /var/log/secure    記錄登入系統存取資料的檔案，例如 pop3, ssh, telnet, ftp 等都會記錄在此檔案中
		    /var/log/wtmp      記錄登入者的訊息資料, last
		    /var/log/messages  幾乎系統發生的錯誤訊息
		    /var/log/boot.log  記錄開機或者是一些服務啟動的時候，所顯示的啟動或關閉訊息
		    /var/log/maillog   紀錄郵件存取或往來( sendmail 與 pop3 )的使用者記錄
		    /var/log/cron      記錄 crontab 這個例行性服務的內容
		    /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log/procmail.log：
		    分別是幾個不同的網路服務的記錄檔
		 
		一些常用的基本命令:
		uname -a    查看内核版本       
		ls -al    显示所有文件的属性
			-R, --recursive            list subdirectories recursively
			ls -a -R 显示子目录文件
			ls -h 显示文件大写，以可读方式显示结果
			-c 根据创建时间排序
		pwd         显示当前路径        
		cd -    返回上一次目录     cd ~    返回主目录
		date s      设置时间、日期          
		cal      显示日历     cal 2006
		bc          计算器具               
		man  & info     帮助手册
		locale     显示当前字体     locale -a    所有可用字体     /etc/sysconfig/i18n设置文件
		LANG=en    使用英文字体            
		sync       将数据同步写入硬盘        
		shutdonw -h now & half & poweroff  关机
		reboot     重启                   
		startx  &  init 5   进入图形介面
		/work  & ?work    向上、下查找文档内容
		chgrp      改变档案群组  chgrp testing install.log    
		chown     改变所属人   chown root:root install.log
		chmod      改变属性     chmod 777 install.log     read=4  write=2  execute=1
		cp   复制   cp filename
		rm   删除文件  rm -rf filename   强制删除文件 
			rm -rf directory or file   -r或-R或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
		rmdir   删除文件夹
		mv  移动    mv 123.txt 222.txt  重命名
		mkdir     创建文件夹  
			mkdir -p /usr/dat.txt  # -p 参数表示如果上级目录不存在则创建
		touch     创建文件  更新当前时间
		cat       由第一行开始显示     cat |more  分页
		nl        在内容前加行号
		more  &  less   一面一面翻动
		head -n filename   显示第N行内容
		tail -n filename  显示后N行内容
			tail -f  显示追加内容
			-f
			 如果输入文件是常规文件或如果 File 参数指定 FIFO（先进先出），那么 tail 命令不会在复制了输入文件的最后的指定单元后终止，而是继续从输入文件读取和复制额外的单元（当这些单元可用时）。如果没有指定 File 参数，并且标准输入是管道，则会忽略 -f 标志。tail -f 命令可用于监视另一个进程正在写入的文件的增长。

			 同时显示多个文件追加的内容，比如用于同时查看多个日志文件场景
			 tail -f -n20 logs/info.log logs/error.log
			
			显示文件前几行内容：
				 If the first character of N (the number of bytes or lines) is a `+',	       print beginning with the Nth item from the start of each file, otherwise,print the last N items in the file.
				 tail -f -n+10

		od        显示非纯文档
		df -h 显示分区空间      (磁盘)
		du  显示目录或文件的大小
		fdisk   分区设置    fdisk -l /dev/hda  显示硬盘分区状态
		mkfs    建立各种文件系统  mkfs -t ext3  /dev/ram15   
		fsck    检查和修复LINUX档案
		ln      硬链接   ln -s  软件链接
			rm -rf open.war
			ln -s /home/admin/houyi/service/src/houyi.console.openapi/target/open.war
		whereis   查找命令
		locate    查找
		find      查找   find / -name "***.***"
			在当前目录下查找包含 hello 字符串的 后缀名为 .c 的文件:
				find . -name "*.c" | xargs grep -H "hello"
		which     查看工具
		whoami    显示当前用户
		gcc -v    查看GCC版本
		chattr +i filename  禁止删除   chattr -i filename  取消禁止
		lsattr    显示隐藏档属性
		updatedb  更新资料库
		mke2fs    格式化   mkfs -t ext3 
		dd if=/etc/passwd of=/tmp/passwd.bak    备份
			用法：dd [操作符]...
			  或：dd 选项
			Copy a file, converting and formatting according to the operands.

			  bs=BYTES        force ibs=BYTES and obs=BYTES
			  cbs=BYTES       convert BYTES bytes at a time
			  conv=CONVS      convert the file as per the comma separated symbol list
			  count=BLOCKS    copy only BLOCKS input blocks
			  ibs=BYTES       read BYTES bytes at a time
			  if=FILE         read from FILE instead of stdin
			  iflag=FLAGS     read as per the comma separated symbol list
			  obs=BYTES       write BYTES bytes at a time
			  of=FILE         write to FILE instead of stdout
			  oflag=FLAGS     write as per the comma separated symbol list
			  seek=BLOCKS     skip BLOCKS obs-sized blocks at start of output
			  skip=BLOCKS     skip BLOCKS ibs-sized blocks at start of input
			  status=noxfer   suppress transfer statistics			

			从dvd制作iso文件：
			  dd if=/dev/cdrom of=/var/lib/libvirt/images/CentOS-6.2-x86_64-bin-DVD1.iso 
		mount     列出系统所有的分区
		mount -t iso9660 /dev/cdrom /mnt/cdrom   挂载光盘
		mount -t vfat /dev/fd0 /mnt/floppy       挂载软盘
		mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
		mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
		Linux-NTFS Project: http://linux-ntfs.sourceforge.net/
		umount /mnt/hda3  缷载
		ifconfig   显示或设置网络设备
			设置ip: ifconfig eth0 192.168.232.162 netmask 255.255.255.0
			ifconfig eth0 hw ether 00:11:33:44:55:66 - set mac
		service network restart   重启网卡  
		ifdown eth0  关闭网卡
		ifup eth0    开启网卡
		clear    清屏
		history    历史记录       !55  执行第55个指令
		stty   设置终端    stty -a
		fdisk /mbr   删除GRUB
		at     僅進行一次的工作排程
		crontab   循環執行的例行性命令    [e]编辑,[l]显示,[r]删除任务
			Crontab  is  the  program  used  to  install,  deinstall  or list the tables used to drive the cron(8) daemon in ISC Cron
		&       后台运行程序    tar -zxvf 123.tar.gz & --------->后台运行
		jobs    观看后台暂停的程序   jobs -l
		fg      将后台程序调到前台   fg n ------>n是数字,可以指定进行那个程序
		bg      让工作在后台运行
		kill    结束进程    kill -9 PID     [9]强制结束,[15]正常结束,[l]列出可用的kill信号
			kill -9 强制停止进程，kill不了
			kill -3 PID
				sudo kill -3 PID获取thread dump log
		ps aux  查看后台程序   
		top     查看后台程序   top -d 2    每两秒更新一次        top -d 2 -p10604   观看某个PID
			top -b -n 2 > /tmp/top.txt ----->將 top 的資訊進行 2 次，然後將結果輸出到 /tmp/top.txt    
		pstree   以树状图显示程序    [A]以 ASCII 來連接, [u]列出PID, [p]列出帐号
		killall   要刪除某個服務    killall -9 httpd
		free      显示内存状态     free -m  -------->以M为单位显示
		uptime    显示目前系统开机时间
		netstat   显示网络状态    netstat -tulnp------>找出目前系統上已在監聽的網路連線及其 PID
		dmesg     显示开机信息    demsg | more
		nice      设置优先权      nice -n -5 vi & ----->用 root 給一個 nice 植為 -5 ，用於執行 vi 
		renice    调整已存在优先权
		runlevel  显示目前的runlevel

		depmod    分析可载入模块的相依性
		lsmod     显示已载入系统的模块
		modinfo   显示kernel模块的信息
		insmod    载入模块
		modprobe   自动处理可载入模块
		rmmod     删除模块
		chkconfig   检查，设置系统的各种服务     chkconfig --list ----->列出各项服务状态
		ntsysv     设置系统的各种服务
		cpio      备份文件
		 

		压缩命令：
		 *.Z      compress 程式壓縮的檔案； 
		 *.bz2    bzip2 程式壓縮的檔案； 
		 *.gz     gzip 程式壓縮的檔案； 
		 *.tar    tar 程式打包的資料，並沒有壓縮過； 
		 *.tar.gz tar 程式打包的檔案，其中並且經過 gzip 的壓縮
		compress filename  压缩文件  加[-d]解压  uncompress
		gzip filename   压缩  加[-d]解压  zcat 123.gz 查看压缩文件内容
		bzip2 -z filename  压缩  加[-d]解压   bzcat filename.bz2  查看压缩文件内容
		tar -cvf /home/123.tar /etc  打包，不压缩
		tar -xvf 123.tar   解开包
		tar -zxvf /home/123.tar.gz  以gzip解压
		tar -jxvf /home/123.tar.bz2  以bzip2解压
		tar -ztvf /tmp/etc.tar.gz   查看tar内容
		cpio -covB  > [file|device]   份份
		cpio -icduv < [file|device]   还原
		 zip -r fileName ./*.txt - 打包当前目录下所有txt文件 -r 表示递归所有子目录
			zip -r foo . -i *.sql 打包当前目录下匹配文件名的文件到foo
		vi一般用法
		一般模式              编辑模式                  指令模式
		h 左               a,i,r,o,A,I,R,O             :w 保存
		j 下                进入编辑模式                :w! 强制保存
		k 上                dd 删除光标当前行           :q! 不保存离开
		l 右                ndd 删除n行                 :wq! 保存后离开
		0 移动到行首        yy 复制当前行                :e! 还原原始档
		$ 移动到行尾        nyy 复制n行                  :w filename 另存为
		H 屏幕最上          p,P 粘贴                     :set nu 设置行号
		M 屏幕中央          u  撤消                      :set nonu 取消行号
		L 屏幕最下          [Ctrl]+r 重做上一个动作       ZZ 保存离开
		G 档案最后一行      [ctrl]+z 暂停退出            :set nohlsearch   永久地关闭高亮显示
		/work 向下搜索                                   :sp 同时打开两个文档 
		?work 向上搜索                                   [Ctrl]+w 两个文档设换
		gg 移动到档案第一行                              :nohlsearch    暂时关闭高亮显示
		 
		认识SHELL
		alias    显示当前所有的命令别名      alias lm="ls -al"   命令别名    unalias lm 取消命令别名
		type      类似which
		exprot    设置或显示环境变量
		exprot PATH="$PATH":/sbin  添加/sbin入PATH路径
		echo $PATH    显示PATH路径
		bash      进入子程序
		name=yang     设定变量
		unset name    取消变量
		echo $name    显示变量的内容
		myname="$name its me"   &   myname='$name its me'     单引号时$name失去变量内容
		ciw=/etc/sysconfig/network-scripts/     设置路径
		env      列出所有环境变量
		echo $RANDOM    显示随意产生的数
		set      设置SHELL
		PS1='[\u@\h \w \A #\#]\$ '     提示字元的設定
		   [root@linux ~]# read [-pt] variable     -----------读取键盘输入的变量
		   參數：
		   -p  ：後面可以接提示字元！
		   -t  ：後面可以接等待的『秒數！』
		declare    声明 shell 变量
		ulimit -a   显示所有限制资料
		 ls /tmp/yang && echo "exist" || echo "not exist"
		 意思是說，當 ls /tmp/yang 執行後，若正確，就執行echo "exist" ,若有問題，就執行echo "not exist" 
		 echo $PATH | cut -d ':' -f 5       以:为分隔符,读取第5段内容
		 export | cut -c 10-20      读取第10到20个字节的内容
		 last | grep 'root'    搜索有root的一行,加[-v]反向搜索
		 cat /etc/passwd | sort    排序显示
		 cat /etc/passwd | wc      显示『行、字数、字节数』
		正规表示法
		[root@test root]# grep [-acinv] '搜尋字串' filename
		       參數說明：
		       -a ：將 binary 檔案以 text 檔案的方式搜尋資料
		       -c ：計算找到 '搜尋字串' 的次數
		       -i ：忽略大小寫的不同，所以大小寫視為相同
		       -n ：順便輸出行號
		       -v ：反向選擇，亦即顯示出沒有 '搜尋字串' 內容的那一行！

		文件内容查找：

		 grep -n 'the' 123.txt     搜索the字符 -----------搜尋特定字串       
		 grep -n 't[ea]st' 123.txt    搜索test或taste两个字符---------利用 [] 來搜尋集合字元
		 grep -n '[^g]oo' 123.txt     搜索前面不为g的oo-----------向選擇 [^] 
		 grep -n '[0-9]' 123.txt  搜索有0-9的数字
		 grep -n '^the' 123.txt 搜索以the为行首-----------行首搜索^
		 grep -n '^[^a-zA-Z]' 123.txt  搜索不以英文字母开头
		 grep -n '[a-z]$' 123.txt    搜索以a-z结尾的行---------- 行尾搜索$
		 grep -n 'g..d' 123.txt     搜索开头g结尾d字符----------任意一個字元 . 
		 grep -n 'ooo*' 123.txt     搜索至少有两个oo的字符---------重複字元 *
			tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'
				grep -v 查看不匹配的行（select non-matching lines）
					如果有多个字符串匹配，先去掉匹配率高的，否则可能导致响应慢
				grep -i 去区分大小写


		sed    文本流编辑器    利用脚本命令来处理文本文件
		awd    模式扫描和处理语言
		 nl 123.txt | sed '2,5d'   删除第二到第五行的内容
		diff     比较文件的差异
		cmp      比较两个文件是否有差异
		patch    修补文件
		pr       要打印的文件格式化
		 

		帐号管理
		/etc/passwd    系统帐号信息
		/etc/shadow    帐号密码信息    经MD5 32位加密
		     在密码栏前面加『 * 』『 ! 』禁止使用某帐号
		/etc/group     系统群组信息
		/etc/gshadow
		newgrp    改变登陆组
		useradd  &  adduser    建立新用户  ---------> useradd -m test  自动建立用户的登入目录
			  useradd -m -g pgroup test --------->指定所属级
		/etc/default/useradd   相关设定
		/etc/login.defs       UID/GID 有關的設定
		passwd    更改密码 -----------> passwd test
		usermod   修改用户帐号
		userdel   删除帐号 ----------->userdel -r test
		chsh      更换登陆系统时使用的SHELL   [-l]显示可用的SHELL;[-s]修改自己的SHELL
		chfn      改变finger指令显示的信息
		finger    查找并显示用户信息
		id        显示用户的ID ----------->  id test
		groupadd   添加组
		groupmod   与usermod类似
		groupdel   删除组
		su test    更改用户   su -    进入root,且使用root的环境变量
		sudo       以其他身份来执行指令
		visudo     编辑/etc/sudoers      加入一行『 test ALL=(ALL) ALL 』
			   %wheel ALL = (ALL) ALL               系统里所有wheel群组的用户都可用sudo
			   %wheel ALL = (ALL) NOPASSWD: ALL     wheel群组所有用户都不用密码NOPASSWD
		       User_Alias ADMPW = vbird, dmtsai, vbird1, vbird3         加入ADMPW组
		       ADMPW ALL = NOPASSWD: !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, \
		       !/usr/bin/passwd root      可以更改使用者密码,但不能更改root密码 (在指令前面加入 ! 代表不可)
		PAM (Pluggable Authentication Modules, 嵌入式模組)
		who & w     看谁在线                     
		last        最近登陆主机的信息
		lastlog     最近登入的時間    读取 /var/log/lastlog 
		talk        与其他用户交谈
		write       发送信息    write test   [ctrl]+d 发送
		mesg        设置终端机的写入权限    mesg n 禁止接收     mesg y 
		wall        向所有用户发送信息    wall this is q test
		mail        写mail   
		/etc/default/useradd    家目录默认设置
		quota      显示磁盘已使用的空间与限制     quota -guvs ----->秀出目前 root 自己的 quota 限制值
			   quota -vu   查询
		quotacheck   检查磁盘的使用空间与限制     quotacheck -avug  ----->將所有的在 /etc/mtab 內，含有 quota 支援的 partition 進行掃瞄
			     [-m] 强制扫描  
		     quota一定要是独立的分区,要有quota.user和quota.group两件文件,在/etc/fstab添加一句:
		     /dev/hda3 /home ext3 defaults,usrquota,grpquota 1 2
		     chmod 600 quota*         设置完成,重启生效
		edquota    编辑用户或群组的quota  [u]用户,[g]群组,[p]复制,[t]设置宽限期限 
			   edquota -a yang       edquota -p yang -u young ----->复制    
		quotaon    开启磁盘空间限制     quotaon -auvg -------->啟動所有的具有 quota 的 filesystem
		quotaoff   关闭磁盘空间限制     quotaoff -a  -------->關閉了 quota 的限制
		repquota -av     查閱系統內所有的具有 quota 的 filesystem 的限值狀態
		Quota 從開始準備 filesystem 的支援到整個設定結束的主要的步驟大概是：
		1、設定 partition 的 filesystem 支援 quota 參數：
		由於 quota 必須要讓 partition 上面的 filesystem 支援才行，一般來說， 支援度最好的是 ext2/ext3 ，
		其他的 filesystem 類型鳥哥我是沒有試過啦！ 啟動 filesystem 支援 quota 最簡單就是編輯 /etc/fstab ，
		使得準備要開放的 quota 磁碟可以支援 quota 囉；
		2、建立 quota 記錄檔：
		剛剛前面講過，整個 quota 進行磁碟限制值記錄的檔案是 aquota.user/aquota.group， 
		要建立這兩個檔案就必須要先利用 quotacheck 掃瞄才行喔！
		3、編輯 quota 限制值資料：
		再來就是使用 edquota 來編輯每個使用者或群組的可使用空間囉；
		4、重新掃瞄與啟動 quota ：
		設定好 quota 之後，建議可以再進行一次 quotacheck ，然後再以 quotaon 來啟動吧！

		开机流程简介
		1、載入 BIOS 的硬體資訊，並取得第一個開機裝置的代號； 
		2、讀取第一個開機裝置的 MBR 的 boot Loader (亦即是 lilo, grub, spfdisk 等等) 的開機資訊； 
		3、載入 Kernel 作業系統核心資訊， Kernel 開始解壓縮，並且嘗試驅動所有硬體裝置； 
		4、Kernel 執行 init 程式並取得 run-level 資訊； 
		5、init 執行 /etc/rc.d/rc.sysinit 檔案； 
		6、啟動核心的外掛模組 (/etc/modprobe.conf)； 
		7、init 執行 run-level 的各個批次檔( Scripts )； 
		8、init 執行 /etc/rc.d/rc.local 檔案； 
		9、執行 /bin/login 程式，並等待使用者登入； 
		10、登入之後開始以 Shell 控管主機。 
		在/etc/rc.d/rc3.d內,以S开头的为开机启动,以K开头的为关闭,接着的数字代表执行顺序
		GRUB vga设定
		彩度\解析度  640x480  800x600  1024x768  1280x1024   bit 
		    256        769      771      773       775      8 bit 
		   32768       784      787      790       793     15 bit 
		   65536       785      788      791       794     16 bit 
		   16.8M       786      789      792       795     32 bit 

		./configure    检查系统信息       ./configure --help | more  帮助信息
		make clean     清除之前留下的文件
		make           编译
		make install   安装
		rpm -q  ----->查询是否安装             rpm -ql ------>查询该套件所有的目录
		rpm -qi ----->查询套件的说明资料       rpm -qc[d] ----->设定档与说明档
		rpm -ivh  ---->安装                    rpm -V  -------->查看套件有否更动过
		rpm -e  ------>删除                    rpm -Uvh ------->升级安装  
			rpm -e --nodeps python-2.3.4-14.7.el4 卸载安装包，检查依赖包
		--nodeps ----->强行安装                --test ----->测试安装

		来自：http://blogold.chinaunix.net/u/30619/showart.php?id=249558

		1、alternatives --install /usr/bin/java java /usr/java/jdk1.6.0_24/bin/java 300
		这一句的意思是给java这个LINK多加一个Path。至于什么是Link，请man alternatives，看alternatives命令的帮助，就大概能明白了。
		2、alternatives --config java 会出现一下信息：
		----------------------------------------------------------------------
		*  1           /usr/lib/jvm/jre-1.4.2-gcj/bin/java
		+ 2           /usr/java/jdk1.6.0_24/bin/java
		按 Enter 来保存当前选择[+]，或键入选择号码：2

		shutdown -h now
		halt
	
	############################################################################

		linux下Java环境的配置
		linux下Java环境的配置
			　　现在用linux的朋友越来越多了，前几天就有两个朋友问我linux下怎么配置java环境，我想还有很多朋友想了解学习这方面的东西，就写一个完全一点的linux java环境配置吧，希望对大家有帮助。
		一. 下载jdk5.0 for linux
		　　到sun的主页 http://java.sun.com/j2se/1.5.0/download.jsp 下载jdk安装文件jdk-1_5_0_05-linux-i586.bin
		二. 解压安装jdk
		　　在shell终端下进入jdk-1_5_0_05-linux-i586.bin文件所在目录，执行命令./jdk-1_5_0_05-linux-i586.bin这时会出现一段协议，连继敲回车，当询问是否同意的时候，输入yes，回车。之后会在当前目录下生成一个jdk-1.5.0_05目录，你可以将它复制到任何一个目录下。
		三. 需要配置的环境变量
		　　1.PATH环境变量。作用是指定命令搜索路径，在shell下面执行命令时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。
		　　2.CLASSPATH环境变量。作用是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。
		　　3. JAVA_HOME环境变量。它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。
		四. 三种配置环境变量的方法
		　　1. 修改/etc/profile文件
		　　　　如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
		　　　　·用文本编辑器打开/etc/profile
		　　　　·在profile文件末尾加入：
		　　　　　　JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　PATH=$JAVA_HOME/binPATH
		　　　　　　CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		　　　　　　export JAVA_HOME
		　　　　　　export PATH
		　　　　　　export CLASSPATH
		　　　　·重新登录
		　　　　·注解
		　　　　　　a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
		　　　　　　b. linux下用冒号“:”来分隔路径
		　　　　　　c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值
		　　　　　　　 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种
		　　　　　　　 常见的错误。
		　　　　　　d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
		　　　　　　e. export是把这三个变量导出为全局变量。
		　　　　　　f. 大小写必须严格区分。
		　　2. 修改.bashrc文件
		　　　　
		　　　　这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
		　　　　·用文本编辑器打开用户目录下的.bashrc文件
		　　　　·在.bashrc文件末尾加入：
		　　　　　　
		　　　　　　set JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　export JAVA_HOME
		　　　　　　set PATH=$JAVA_HOME/binPATH
			    　　　export PATH
			    　　　set CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
			    　　　export CLASSPATH
		　　　　·重新登录
		　　3. 直接在shell下设置变量
		　　　　不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
		　　　　只需在shell终端执行下列命令：
		　　　　export JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　export PATH=$JAVA_HOME/binPATH
		　　　　export CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		五. 测试jdk
		　　1. 用文本编辑器新建一个Test.java文件，在其中输入以下代码并保存：
		　　　　public class test {
		　　　　　　public static void main(String args[]) {
		　　　　　　　　System.out.println("A new jdk test !");
		　　　　　　}
		　　　　}
		　　2. 编译：在shell终端执行命令 javac Test.java
		　　3. 运行：在shell终端执行命令 java Test
		　　　　当shell下出现“A new jdk test !”字样则jdk运行正常。
		六. 卸载jdk
		　　·找到jdk安装目录的_uninst子目录
		　　·在shell终端执行命令./uninstall.sh即可卸载jdk。 



		############################################################################


		vi 

		保存退出
		* shift + ： 进入命令行状态
		* 输入wq ，并回车，即保存退出

		:w   保存文件但不退出vi 
		:w file 将修改另外保存到file中，不退出vi 
		:w!  强制保存，不推出vi
		:wq  保存文件并退出vi 
		:wq! 强制保存文件，并退出vi
		q：不保存文件，退出vi
		:q!不保存文件，强制退出vi 
		:e! 放弃所有修改，从上次保存文件开始再编辑



		############################################################################


		命令 结果定向到文件 

		rpm -qa >> /home/show

		查找到安装软件包名 ： java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5

		rpm -ql  java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5 —— 查询该套件所有的目录
		
		查找是否已安装mysql，有则卸载掉
		# rpm -qa | grep -i  mysql			   -i : ignore case
		...
		# rpm -e xxxx

		############################################################################

		安装 bin格式的jdk软件包 
		进到软件包的目录下 ，运行 ./jdk1.6***.bin 即可安装
	--------

* base64 编码
		Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。
	Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符
	（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为
	适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所
	直接看到。

*	vmware7安装centos5 - 自定义方式 -  OS Installlation步骤选择install later(否则后面可能直接进入live CD 模式，不是正常安装模式)	      ，
	新建好VM后，再设置CD/DVD的地方指向ISO镜像，启动后，即可正常选择安装模式，进行安装
		确保ssh模块已安装 ，通过ssh客户端连接vmware中的centos
		vmware 修改磁盘容量 ，分区工具，重新分区
		http://www.cnblogs.com/ZhengGuoQing/archive/2008/04/03/1135803.html

*	虚拟集群,及其相关应用测试【测试】

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day1 2012年3月14日

1. 环境
	..
	eclipse 
		常用插件
			svn 
			mavn 
			spring插件 - 主要编译配置文件定位到java文件,自动提示等便捷功能
			Eclipse Web Tools Platform
			python 插件 pydev http://pydev.org/updates
			uml
			er - http://www.eclipse.org/gef/updates/index.php
			...
		eclipse jre配置设置为jdk
		-vm
		D:\Java\jdk1.6.0_10\bin\javaw.exe —— 这里路径注意下 空格之类处理为 progra~1
		-vmargs
		-Dosgi.requiredJavaVersion=1.5
		-Xms128m
		-Xmx256m	

		ide eclipse 依赖 ，依赖从上到下配置，上面不对会导致下面的类编译报错。

2. svn 
	wiki http://wiki.houyi.alibaba-inc.com/dashboard.action
	申请权限
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/
	和
	http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine

	department
	阿里云-云计算业务发展-基础产品-平台技术

wiki：
	http://wiki.houyi.alibaba-inc.com/dashboard.action

bbs:
	http://bbs.aliyun.com/

feitian SLB ACE（JCE...） (ACE - Ali Cloud Engine云引擎) OSS(kv storage)
	
	ACE php container, nodejs container,jsp container

test evn:
	Latest SLB Build: http://10.1.152.71/release/houyi/slb/trunk/2.0.476963.0/
	Latest Keepalived Build: http://10.1.152.71/release/houyi/slb/system/keepalived/1.1.20-476658.0/
	Latest HAProxy Build: http://10.1.152.71/release/houyi/slb/system/haproxy/1.4.15.1-476658.0/

	Bugfree: http://bugfree.aliyun-inc.com/index.php/bug/list/2

3. Cloud Engine - Cloud Engine是一个基于ACE的web应用托管运行环境，能够提供应用的自动伸缩以及多种核心服务。
	
	Google App Engine
	


4. linux about
	* gdb:
		What is GDB?

		GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another 
		program was doing at the moment it crashed.

		GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act:

		    Start your program, specifying anything that might affect its behavior.
		    Make your program stop on specified conditions.
		    Examine what has happened, when your program has stopped.
		    Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. 

		The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might 
		be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft 
		Windows variants.
		
		DBP实战：
			问题：

			ndb进程cpu达到99%，怀疑存在死循环，需要排查

			1.   ps -eLf | grep nbd-server

			找出那个nbd-server线程占用cpu最高，记住他的ppid（线程id）

			2.   gdb nbd-server <pid>

			启动gdb ， attach到运行的nbd-server进程

			3.  info thread

			查看所有线程

			4. thread 10

			切换到这个线程

			5. bt

			查看线程堆栈

			6. 分析代码

			from:wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=3932212

5. ssh client
	PuTTY
6. 路由  消息订阅

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day2 2012年3月15日

1. 后羿系统
	
	参考资料 Sina App Engine数据存储服务架构
	
2.  svn 账户授权 即 svn 注册用户 
	wb_shen.chengs + pwd

	url
		...houyi/cloudengine
		...houyi/console
			branches-api...-requirement 

3. houyi 异步通知 * houyi api open api
	
	异步通知是后羿系统提供的一套基于HTTP协议主动向客户系统发送VM操作结果状态的基础服务。其基本流程如下：
	 
	通知系统交互流程说明：
	1. 后羿向外部系统发出通知，即访问外部系统提供的通知接收URL。// 外部系统提供的通知接收URL
	2. 客户系统接到通知请求，根据签名信息验证通知真实性。
	3. 客户系统处理通知。
	摘自：houyi api 说明doc
	
	该说明书主要提供给后羿系统的终端用户，用户可以开发自己的系统访问后羿API完成有关虚拟机等其他后羿资源的管理和查询。

4. 通过svn checkout 部分houyi项目 熟悉 【配置 svn】
	svn插件拉下项目代码 (svn 项目绑定到对应的svn库上，(对于eclipse，如果绑定错误，先删除原有svn库，从team里重新绑定即可))
	maven插件构建
		部分依赖找不到的情况：(把所在目录下已有的文件删除)通过到依赖库手动下载pom文件和相应jar.swf等文件，放到maven的.m2文件夹中解决。
		nexus http://10.250.6.11:8081/nexus/index.html#welcome 

	maven版本问题，比如编译，打包等用到plugin时，选择合适的版本，配置正确的repo，目前用maven2.2.1
		配置文件配置:
			   <!-- profile
			     | Specifies a set of introductions to the build process, to be activated using one or more of the
			     | mechanisms described above. For inheritance purposes, and to activate profiles via <activatedProfiles/>
			     | or the command line, profiles have to have an ID that is unique.
			     |
			     | An encouraged best practice for profile identification is to use a consistent naming convention
			     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.
			     | This will make it more intuitive to understand what the set of introduced profiles is attempting
			     | to accomplish, particularly when you only have a list of profile id's for debug.
			     |
			     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.
			    -->			
			 <profile>
			      <id>dev</id>

			      <repositories>
				
				<repository>
				  <id>ay32-releases</id>
				  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>

				<repository>
				  <id>nexus-releases</id>
				  <name>nexusre</name>
				  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>
			     
			 </repositories>
				  <pluginRepositories>
				<pluginRepository>
					  <id>ay32-releases</id>
					  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				<pluginRepository>
					  <id>nexus-releases</id>
					  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				  </pluginRepositories>
			    </profile>
	

	通过maven脚本构建测试部署 ？

	ide里编辑，构建工具统一编译测试部署。
	mvn clean install -rf :houyi-console-web-staff 
	参数参考：
		usage: mvn [options] [<goal(s)>] [<phase(s)>]

		Options:
		 -am,--also-make                        If project list is specified, al
							build projects required by the
							list
		 -amd,--also-make-dependents            If project list is specified, al
							build projects that depend on
							projects on the list
		 -B,--batch-mode                        Run in non-interactive (batch)
							mode
		 -C,--strict-checksums                  Fail the build if checksums don'
							match
		 -c,--lax-checksums                     Warn if checksums don't match
		 -cpu,--check-plugin-updates            Ineffective, only kept for
							backward compatibility
		 -D,--define <arg>                      Define a system property
		 -e,--errors                            Produce execution error messages
		 -emp,--encrypt-master-password <arg>   Encrypt master security password
		 -ep,--encrypt-password <arg>           Encrypt server password
		 -f,--file <arg>                        Force the use of an alternate PO
							file.
		 -fae,--fail-at-end                     Only fail the build afterwards;
							allow all non-impacted builds to
							continue
		 -ff,--fail-fast                        Stop at first failure in
							reactorized builds
		 -fn,--fail-never                       NEVER fail the build, regardless
							of project result
		 -gs,--global-settings <arg>            Alternate path for the global
							settings file
		 -h,--help                              Display help information
		 -l,--log-file <arg>                    Log file to where all build outp
							will go.
		 -N,--non-recursive                     Do not recurse into sub-projects
		 -npr,--no-plugin-registry              Ineffective, only kept for
							backward compatibility
		 -npu,--no-plugin-updates               Ineffective, only kept for
							backward compatibility
		 -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates
		 -o,--offline                           Work offline
		 -P,--activate-profiles <arg>           Comma-delimited list of profiles
							to activate
		 -pl,--projects <arg>                   Comma-delimited list of specifie
							reactor projects to build instea
							of all projects. A project can b
							specified by [groupId]:artifactI
							or by its relative path.
		 -q,--quiet                             Quiet output - only show errors
		 -rf,--resume-from <arg>                Resume reactor from specified
							project
		 -s,--settings <arg>                    Alternate path for the user
							settings file
		 -T,--threads <arg>                     Thread count, for instance 2.0C
							where C is core multiplied
		 -t,--toolchains <arg>                  Alternate path for the user
							toolchains file
		 -U,--update-snapshots                  Forces a check for updated
							releases and snapshots on remote
							repositories
		 -up,--update-plugins                   Ineffective, only kept for
							backward compatibility
		 -V,--show-version                      Display version information
							WITHOUT stopping build
		 -v,--version                           Display version information
		 -X,--debug                             Produce execution debug output

		tip:
			parent pom declare most properties ,plugins etc,models under parent,only needs to config special requiments ,if needs to make war package for example and it can references definetions
			from parent pom ,just lile inheritance(eg struts2's configuration file struts.xml).

		maven 插件 ，源码自动下载

5. 熟悉houyi代码，结构
	
	
	
6. xStream javabean 与 xml ，json映射工具
	参考：http://www.cnblogs.com/hoojo/archive/2011/04/22/2025197.html
	部分如下：
		xStream框架

			xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换；

			前面有介绍过json-lib这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/21/2023805.html

			以及Jackson这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/22/2024628.html

			它们都完美支持JSON，但是对xml的支持还不是很好。一定程度上限制了对Java对象的描述，不能让xml完全体现到对Java对象的描述。
			这里将会介绍xStream对JSON、XML的完美支持。xStream不仅对XML的转换非常友好，而且提供annotation注解，可以在JavaBean中完成
			对xml节点、属性的描述。以及对JSON也支持，只需要提供相关的JSONDriver就可以完成转换。 

7. Quartz 调度

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day3 2012年3月16日

1. 项目目录结构 maven
	
	

2. 结合 openapi 接口文档 ，熟悉代码，规范

	以hoyi-console-openapi  为例，熟悉大体框架，配置方式，处理流程
	
	根据应用上下文配置文件(web.xml)，熟悉请求处理流程 （web应用 ,java应用根据程序入口）

		* struts2 ,spring ,ibatis
			spring
				bean管理 - pojo,dao bean ,action
				事务管理
			struts2
				interceptor - default and user defined interceptors / pluggable
				objectfactory = spring
				action继承/接口关系(部分)
					public class RackQueryAction extends PagingInfovalidator implements ExecuteAction {
					-> public abstract class PagingInfovalidator extends AbstractExecuteAction implements ActionValidator{
					-> public abstract class AbstractExecuteAction implements ExecuteAction {

				部分struts源码截取：【struts】
					multi-thread safe
					--------
						package com.opensymphony.xwork2;
						...
						public class ActionContext implements Serializable {
						    static ThreadLocal actionContext = new ThreadLocal();
						...
						    Map<String, Object> context;

						    public ActionContext(Map<String, Object> context) {
							this.context = context;
						    }
						...
						    public static void setContext(ActionContext context) {
							actionContext.set(context);
						    }
						    public static ActionContext getContext() {
							return (ActionContext) actionContext.get();
					--------
					
					--------
					...
					package com.opensymphony.xwork2;
					public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable {
					...
					    public Locale getLocale() {
						ActionContext ctx = ActionContext.getContext();
						if (ctx != null) {
						    return ctx.getLocale();
						} else {
						    LOG.debug("Action context not initialized");
						    return null;
						}
					    }
					...
					--------
					Interface :
						Action - All actions may implement this interface, which exposes the execute() method. 
						Validateable - Provides an interface in which a call for a validation check can be done.
						ValidationAware - ValidationAware classes can accept Action (class level) or field level error messages. Action level messages are kept in a Collection. 
									Field level error messages are kept in a Map from String field name to a List of field error msgs.
						TextProvider - Provides access to ResourceBundles and their underlying text messages.
						LocalProvider - Indicates that the implementing class can provide its own Locale. 
					
					ActionInvocation
							An ActionInvocation represents the execution state of an Action. It holds the Interceptors and the Action instance. By repeated re-entrant execution 
						of the invoke() method, initially by the ActionProxy, then by the Interceptors, the Interceptors are all executed, and then the Action and the Result.
						代理类，维护interceptors集合并依次序传递和执行ActionInvocation的实现类。？




			ibatis openAPI通过spring提供ibatis的template进行dao操作
				部分代码，spring集成ibatis部分
					--------
					package org.springframework.orm.ibatis;
					...
					public class SqlMapClientTemplate extends JdbcAccessor implements SqlMapClientOperations {
						public Object queryForObject(final String statementName, final Object parameterObject)
								throws DataAccessException {

							return execute(new SqlMapClientCallback() {
								public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
									return executor.queryForObject(statementName, parameterObject);
								}
							});
						...
						public Object execute(SqlMapClientCallback action) throws DataAccessException {
							Assert.notNull(action, "Callback object must not be null");
							Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

							// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
							// Connection (potentially transactional) in. This shouldn't be necessary if
							// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
							// we still need it to make iBATIS batch execution work properly: If iBATIS
							// doesn't recognize an existing transaction, it automatically executes the
							// batch for every single statement...

							SqlMapSession session = this.sqlMapClient.openSession();
							if (logger.isDebugEnabled()) {
								logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
							}
							Connection ibatisCon = null;

							try {
								Connection springCon = null;
								DataSource dataSource = getDataSource();
								boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

								// Obtain JDBC Connection to operate on...
								try {
									ibatisCon = session.getCurrentConnection();
									if (ibatisCon == null) {
										springCon = (transactionAware ?
												dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
										session.setUserConnection(springCon);
										if (logger.isDebugEnabled()) {
											logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
										}
									}
									else {
										if (logger.isDebugEnabled()) {
											logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
										}
									}
								}
								catch (SQLException ex) {
									throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
								}

								// Execute given callback...
								try {
									return action.doInSqlMapClient(session);
								}
								catch (SQLException ex) {
									throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
								}
								finally {
									try {
										if (springCon != null) {
											if (transactionAware) {
												springCon.close();
											}
											else {
												DataSourceUtils.doReleaseConnection(springCon, dataSource);
											}
										}
									}
									catch (Throwable ex) {
										logger.debug("Could not close JDBC Connection", ex);
									}
								}

								// Processing finished - potentially session still to be closed.
							}
							finally {
								// Only close SqlMapSession if we know we've actually opened it
								// at the present level.
								if (ibatisCon == null) {
									session.close();
								}
							}
						}	}
					...
					--------
			dbcp - DB connection pool


		* 枚举 enum 
			定义常量(可扩展的)，优于普通常量定义
			 AgreementParameter
			 GlobalErrorMessage
			...
				eg:
				return CloudEngineEvent.NGINX.getEvent();

				public enum CloudEngineEvent {
					REGISTER(10001),
					NGINX(30001),
					FASTCGI(30002),
					SLB(30003),
					MEMCACHED(30004),
					RDS(30005),
					NODEJS(30006)
					;
					
					private CloudEngineEvent(Integer event) {
						this.event = event;
					}
					
					private Integer event;
					public Integer getEvent() {
						return event;
					}
				}

		* 

	openAPI mode 要引用到得其他各层分别在不同的model中: (openapi为houyi项目其中一个model)
		<modules>
		  <module>houyi.console.model</module> 域模型(历史原因有部分分散在其他model中)
		  <module>houyi.console.util</module> 工具
		  <module>houyi.console.acl</module> 访问控制
		  <module>houyi.console.dao</module> DAO
		  <module>houyi.console.clc</module> 对内master交互模块(操作vm等)
		  <module>houyi.console.service</module> 逻辑层
		  <module>houyi.console.message</module> 消息
		  <module>houyi.console.statistics</module>  
		  <module>houyi.console.web/houyi.console.web.support</module>  web这块原先以portal调
		  <module>houyi.console.web/houyi.console.web.staff</module>
		  <module>houyi.console.web/houyi.console.web.admin</module>
		  <module>houyi.console.web/houyi.console.web.isv</module>
		  <module>houyi.console.openapi</module> 对外openapi模块
		</modules>		
	
	openAPI 放开的请求action配置：- 统一出入口 ？
		<package name="instance" extends="houyi-open" namespace="/">
			<action name="services" class="openAPIProxyAction" method="proxy"><!-- action交给spring管理，此action为：open api 的访问代理 -->
			   <result type="userActionResult"></result> <!-- 自定义result -->
			</action>
		</package>
		代理action利用req请求消息，通过工厂方式(目标action都实现相同接口)调用对应的目标acton，目标action通过spring context获得：
			// Return the bean instances that match the given object type (including subclasses), judging from either bean definitions or the value of getObjectType in the case of FactoryBeans. 
			Map map = context.getBeansOfType(ExecuteAction.class);


3. xen 快照 了解  虚拟机快照 【快照】
	虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
	chain 模式 比如 struts的intercepter ，插拔式
	
	http://server.it168.com/a2009/0723/611/000000611079.shtml
4. StringEscapeUtils 
	Escapes and unescapes Strings for Java, Java Script, HTML, XML, and SQL
	commons-lang包

5. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day4 2012年3月19日

1. RESTful REST 请求

http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v2/master/src/main/java/com/aliyun/cloudengine/
JCE的master以REST架构，处理openAPI(为get/post请求规范)请求需要提供一个适配层(将REST请求转换为http方式的get/post请求) ？ - Java Cloud Engine

jce的rest实现基于

rest http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/
	介绍jdk1.6提供的rest接口，master的rest基于jdk的rest接口 javax.ws.rs

基于 REST 的 Web 服务遵循一些基本的设计原则：
    系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的 URI。
    以遵循 RFC-2616 所定义的协议的方式显式地使用 HTTP 方法，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与 HTTP 方法之间的一对一映射：
        若要在服务器上创建资源，应该使用 POST 方法；
        若要检索某个资源，应该使用 GET 方法；
        若要更改资源状态或对其进行更新，应该使用 PUT 方法；
        若要删除某个资源，应该使用 DELETE 方法。
    URI 所访问的每个资源都可以使用不同的形式加以表示（比如 XML 或者 JSON），具体的表现形式取决于访问资源的客户端，客户端与服务提供者使用一种内容协商的机制（请求头与 MIME 类型）来选择合适的数据格式，最小化彼此之间的数据耦合。

【Task】
	以 /houyi-cloudengine-master/src/main/java/com/aliyun/cloudengine/RestAdminApplication.java 为例，熟悉rest方式，并分析rest方式与openapi标准的get/post方式如何转换 ？
	houyi-cloudengine-master 提供几个rest接口供外界调用。
	由于rest方式的请求url不同于普通http请求的url，需要提供一个模块处理标准http请求的处理(接受请求-调用接口-返回结果)
		rest方式URI: persion/123		http方式: persion?id=123
	
	cloudengine 运行是基于xuanyuan的一个组件，xuanyuan负责请求分配。
	
	参考实现的文档，搭建测试环境测试，判断是否支持预想的解决方案。 - tip -

2.  test 测试
JTester
	   http://java-tester.googlecode.com/svn/maven2/

	   http://www.blogjava.net/kiral/archive/2011/02/04/344072.html usage
	

3. 搭建 restful 环境，测试
	jersey + tomcat 的restful测试环境搭建：
		wiki https://wikis.oracle.com/display/Jersey/Main
		参考 http://www.ibm.com/developerworks/cn/web/wa-aj-tomcat/

	@POST 
	@Path("/test")
	@Produces(MediaType.APPLICATION_JSON)
	public String showTime(@FormParam("username") String userName,@Context HttpServletRequest httpRequest) {
	:
	:
	:
	}
	// jersey - 通过context注解获得httprequest对象
	
	对于openAPI调用(待测试)：
		可以给定URI请求，匹配到一个service上，然后取得request对象，做后续处理。
		(要做的步骤：
			配置一个service匹配opanapi的所有请求

		)

Using Entity Providers toMapHTTP Response and
Request Entity Bodies
Entity providers supply mapping services between representations and their associated Java
types. There are two types of entity providers: MessageBodyReader and MessageBodyWriter.
For HTTP requests, the MessageBodyReader is used to map an HTTP request entity body to
method parameters. On the response side, a return value is mapped to an HTTP response entity
body using a MessageBodyWriter. If the application needs to supply additional metadata, such
Responding to HTTP Resources
Chapter 3 • Creating a RESTful Resource Class 19
as HTTP headers or a different status code, a method can return a Response that wraps the
entity, and which can be built using Response.ResponseBuilder.

——jersey文档

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day5 Tuesday, March 20, 2012

1. day4第3条 go on
	* 下载jersey包
	* 新建web项目，导入jersey必要包
	* 配置jersey的请求处理servlet，并正确配置package属性：com.sun.jersey.config.property.packages - 指向你的resource包
	* 部署到tomcat中
	* 测试

	部分代码：
	-----
		<servlet>
			<servlet-name>Jersey REST Service</servlet-name>
			<servlet-class>
			  com.sun.jersey.spi.container.servlet.ServletContainer
			</servlet-class>
			<init-param>
			  <param-name>com.sun.jersey.config.property.packages</param-name>
			  <param-value>test.jersey.service</param-value>
			</init-param>
			<load-on-startup>1</load-on-startup>
		</servlet>
		<servlet-mapping>
		  <servlet-name>Jersey REST Service</servlet-name>
		  <url-pattern>/rest/*</url-pattern>
		</servlet-mapping>

		package test.jersey.service;
		@Path("hello")
		public class HelloResponse {

			@GET
			@Produces(MediaType.TEXT_PLAIN)
			public String sayHello(){
				return "Hello jersey";
			}
	
		}
	------
	[ Test ]
		req: http://localhost:8080/jersey/rest/hello
		resp: Hello jersey

	[ Test ]
		@GET
		@Produces(MediaType.TEXT_PLAIN)
		public String sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
			return "id:"+id+" name:"+name;
		}	
		request: http://localhost:8080/jersey/rest/hello?id=1&name=jack   - 
		response: id:1 name:jack

	[ Test ]
		@Path("/hello")
		public class HelloResponse {

			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			public MyResponse sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
		//		return "NORMAL id:"+id+" name:"+name+"\n";
				return new MyResponse(id,name);
			}
			
			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			@Path("/sayhello/{id}/{name}")
			public Object sayHelloRest(@DefaultValue("1") @PathParam("id") String id,@DefaultValue("1NaN") @PathParam("name") String name){
				return new MyResponse("1","jack");
			}
		}
		web.xml: 
			<servlet-mapping>
				  <servlet-name>Jersey REST Service</servlet-name>
				  <url-pattern>/open/*</url-pattern>
			</servlet-mapping>
		request: http://localhost:8080/jersey/open/hello/sayhello/1/1
		response: 
				<data>
					<id>1</id><
					name>jack</name>
				</data>

	要返回json或xml，需要将返回的对象配置上对象到xml的映射注解，比如利用jaxb等 ，需要提供一个对象到json或者xml的映射机制，如果直接返回
	jdk的list对象会报错，无法转换：
		A message body writer for Java class java.util.ArrayList, and Java type interface java.util.List, and MIME media type application/xml was not found
		eg:http://blog.coderunnr.com/2011/02/clienthandlerexception-a-message-body-writer-for-java-type-class-and-mime-media-type-applicationoctet-stream-was-not-found/
	将返回的pojo通过注解映射到xml即可：
		@XmlRootElement(name="data")
		public class MyResponse {
			
			private String id;
			
			private String name;
			
			public MyResponse(){}
			
			public MyResponse(String id,String name){
				this.id = id;
				this.name = name;
			}
			
			@XmlElement(name="id")
			public String getId() {
				return id;
			}
			public void setId(String id) {
				this.id = id;
			}
			
			@XmlElement(name="name")
			public String getName() {
				return name;
			}
			public void setName(String name) {
				this.name = name;
			}
		}
		

		问题：
			// 这个标签标示注解的方法支持下面定义的 2 种返回数据格式，具体确定？
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			
			如上，可以返回多个MIME，如何选择，确定返回的类型？
				比如，需要返回xml，或者需要返回json 
				看openAPI是根据什么返回指定格式的数据的？
					openAPI通过请求参数 format 来判断client请求的数据格式，故这里需要用到 @queryparam 来取得 format ，从而返回对应的
				格式。
			jersey guide：
					If a resource class is capable of producing more that one MIME media type then the resource method chosen will correspond to the most acceptable media type 
				as declared by the client. More specifically the Accept header of the HTTP request declared what is most acceptable. For example if the Accept header is:
					Accept: text/plain
				then the doGetAsPlainText method will be invoked. Alternatively if the Accept header is:
					Accept: text/plain;q=0.9, text/html
				which declares that the client can accept media types of "text/plain" and "text/html" but prefers the latter, then the doGetAsHtml method will be invoked.
				More than one media type may be declared in the same @Produces declaration, for example:
			方案1：从jersey guide看，可以根据http请求头的 accept定义值返回相应格式。
				但openapi规范提供的是根据get方式的 format参数来确定返回格式的
			方案2:：根据 format 字段，找到rest框架提供的动态自定义返回格式的设置 ？ 在哪里设置？
				在response里设置header，rest框架根据header定义的格式渲染结果。
				通过response根据需要的返回状态(status)取得responsebuilder对象(处理返回内容)，取得请求参数，通过builder设置返回的Cotent-Type类型(MediaType定义的类型)
				builder的entry方法处理需要返回的对象，build()，返回即可。

			【tip】误区，试图设置request的accept值来影响response的返回数据格式，要返回什么样的数据及其格式都可以通过response来设置。
				拥有者或者自身或其相关工具一般会提供操作其自身的值的入口。

				

2. jax-rs 注解(from jax-rs api)
	Consumer - Defines the media types that the methods of a resource class or MessageBodyReader can accept 定义资源可以接受处理的请求类型
	Produces - Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce
	MediaType - An abstraction for a media type. Instances are immutable(不变的). 


3. 对于第1条的REST框架也支持非REST请求uri的转发，这其中，只是转发的作用，不带有业务逻辑，是否可以用nginx的rewrite来实现？
	后续SLB也需要对openapi提供处理层，其中含业务逻辑，选择REST方式。

4. nginx rewrite 重写
	目标：将openapi的标准请求重写为符合REST接口的rest请求。
	nginx的rewrite规则(rewrite模块)：
	http://xx.host/action?id=xx&name=xx rewrite为 http://xx.host/action/xx/xx

	
	URL rewriting is a key element to Search Engine Optimization (SEO). ——　摘自：Nginx HTTP Server p141

		参考 http://chenxiaoyu.org/2011/10/30/nginx-modules.html
	正则表达式 规则 regex	* 正则表达式
	regular expression(Perl Compatible Regular Expression (PCRE) library):
		Metacharacter
			Description
		^
		Beginning
			The entity after this character must be found at the beginning.
			Example pattern: ^h
			Matching strings: hello, h, hh
			Non-matching strings: character, ssh
		$
		End
			The entity before this character must be found at the end.
			Example pattern: e$
			Matching strings: sample, e, file
			Non-matching strings: extra, shell
		.
		Any
			Matches any character.
			Example pattern: hell.
			Matching strings: hello, hellx, hell5, hell!
			Non-matching strings: hell, helo
		[ ]
		Set
			Matches any character within the specified set.
			Syntax: [a-z] for a range, [abcd] for a set, and [a-z0-9] for
			two ranges
			Example pattern: hell[a-y123]
			Matching strings: hello, hell1, hell2, hell3
			Non-matching strings: hellz, hell4, heloo
		[^ ]
		Negate set
			Matches any character that is not within the specified set.
			Example pattern: hell[^a-np-z0-9]
			Matching strings: hello, hell;
			Non-matching strings: hella, hell5
		|
		Alternation
			Matches the entity placed either before or after the |.
			Example pattern: hello|welcome
			Matching strings: hello, welcome, helloes, awelcome
			Non-matching strings: hell, ellow, owelcom
		( )
		Grouping
			Groups a set of entities, often to be used in conjunction with |.
			Example pattern: ^(hello|hi) there$
			Matching strings: hello there, hi there.
			Non-matching strings: hey there, ahoy there
		\
		Escape
			Allows you to escape special characters.
			Example pattern: Hello\.
			Matching strings: Hello., Hello. How are you?, Hi! Hello...
			Non-matching strings: Hello, Hello, how are you?

		Quantifiers
		So far, you are able to express simple patterns with a limited number of characters. Quantifiers allow you to extend the amount of accepted entities:
		Quantifier
			Description
		*
		0 or more times
			The entity preceding * must be found 0 or more times.
			Example pattern: he*llo
			Matching strings: hllo, hello, heeeello
			Non-matching strings: hallo, ello
		+
		1 or more times
			The entity preceding + must be found 1 or more times.
			Example pattern: he+llo
			Matching strings: hello, heeeello
			Non-matching strings: hllo, helo
		?
		0 or 1 time
			The entity preceding ? must be found 0 or 1 time.
			Example pattern: he?llo
			Matching strings: hello, hllo
			Non-matching strings: heello, heeeello
		{x}
		x times
			The entity preceding {x} must be found x times.
			Example pattern: he{3}llo
			Matching strings: heeello, oh heeello there!
			Non-matching strings: hello, heello, heeeello
		{x,}
		At least x times
			The entity preceding {x,} must be found at least x times.
			Example pattern: he{3}llo
			Matching strings: heeello, heeeeeeello
			Non-matching strings: hllo, hello, heello
		{x,y}
		x to y times
			The entity preceding {x,y} must be found between x and y times.
			Example pattern: he{2,4}llo
			Matching strings: heello, heeello, heeeello
			Non-matching strings: hello, heeeeello
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day6 Wednesday, March 21, 2012

1. openapi 
	OpenAPI - 消息推送/订阅(Message push/subscrible)  -Master 
	
	根据登记在消息服务器上的订阅节点信息，进行push

2. python nodejs 
	python yaml模块 - YAML是一种直观的能够被电脑识别的的数据序列化格式，容易被人类阅读，并且容易和脚本语言交互。YAML类似于XML，但是语法比XML简单得多，
	对于转化成数组或可以hash的数据时是很简单有效的。

3.  wget 从vmware中的centso访问本机的rest服务
	取得返回内容，cat查看
	sshl连接到centos命令行操作。
	
	环境：
		apache ,
		tomcat,
		nginx,
		mysql,
		eclipse,
		python,(test)
		nodejs,(test)
		linux container(test)

4. CIDR Classless Inter-Domain Routing 了解
	无类别域间路由选择
	ref:
		CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给
	服务提供商（ISP），	再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，
	从而减轻Internet路由器的负担。		

	CIDR	Classless Inter-Domain Routing	无类别域间路由选择	是互联网中一种新的址方式，与传统的 A 类、B 类和 C 类寻址模式相比，CIDR 在 IP 地址分配方面更为高效。
	IP号段是125.203.96.0 - 125.203.127.255， 怎样转换成CIDR格式呢？化cidr格式其实就是找相同:
	125.203.0110 0000.0000 0000
	125.203.0111 1111.1111 1111
	前十九位相同,所以可以写成125.203.96.0/19

5. ce里shell脚本熟悉
	"#!/bin/sh" - 对shell的声明，说明你所用的是那种类型的shell及其路径所在。
	自定义shell function封装常用功能，提高shell编写效率。
		eg: 


6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day7 Thursday, March 22, 2012

1. ace mast agent(python shell) 
	master 职责


2.  ace 计量单位讨论会议，
	字段需要取出推送到消息系统，供后续计量，计费
	主要关于 计量字段需求，及可行性确认
	详见记录
	tip: 由于涉及多个系统的交互，如何处理规则，处理变化的问题，如果适应变化减少依赖耦合。

3. cloudengine 熟悉
	master ,agent 部分
	master调用agent
	agent根据不同的应用类型(目前:php，nodejs，jsp)调用相应的build脚本(配置环境运行环境，部署应用，启动应用，启动agent)

	nodejs http://nodejs.org/
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day8 Friday, March 23, 2012

1. cloudengine 
	trunk
		agent - agent模块(python)
			fastcgi
			memcached
			monitor
			nginx
			nodejs
			test
			yaml
		carrier - Erlang (rebar ...)
		ftpserver - ftp服务(java)
		master - master(java)
		memcahched_pach - memchche部署
		nginx_pach - nginx部署
		nodejs -  nodejs部署(build_agent -> install_agent -> install_nodejs -> upgrade_nodejs)
		php - php部署

2. ACE计量 
	计量单位，字段说明
	oss接口
	ms接口

	目标：将ACE各计量单位取到并以ms要求的格式推送给ms(Metering Service)计量系统系统 ，有一个python的
	的实现可以参考:
		python 
			程序基本结构
			变量，运算 etc
			模块
				MySQLdb
					eg 通过此模块与mysql数据库交互：(下载这个库有linux和win版本)
						conn=MySQLdb.connect(host="localhost",user="root",passwd="sa",db="mytable")
	
			执行
			应用
	* 

	参考 houyi-console/static (java)实现，上述任务 【Task】
	= = URL请求的要求(格式，构造)等可以参考这个实现 = =
		定义数据格式
		定义任务
		spring配置调用执行

		步骤：(公用动作比如推送等已有实现，调用其逻辑处理即可) 细化
			>> 取
				* MS取SLB流量(appid对应的流量，appid指每个具体的应用)	单位 byte
					- 从ACE DB中取得appid对应的slb_id，及应用的id与SLB的id对应关系 1对1
						- 从DB得到app_id对应的slb_id(cloudengine库)

							-- 从DB得到app_id对应的slb_id
							select 
								app.id app_id,
								slb.id slb_id
							from app app,slb_alloc_record slb
							where app.id = slb.id
							
					- 请求Meteriing Service，根据slb_id取数据
						MS接口文档(比如如何查询SLB数据？)
						

					-  MS返回vip对应的流量数据的数据格式
						Flow_detail的格式如下：
						[tcp(VIP:80|2|3|)(VIP:8080|2|3|)][http(www.a.com:80|2|3|)(www.b.com:90|2|3|)]
					
					- 

				* MS取OSS
					- 从app表(cloudengine)取得kv_bucket
						select 
							id app_id,
							kv_bucket
						from app
					- URL格式
						columns: storage;
						where: openid=ace;pid=oss;bid=26842;inst_id=$bucketname;begin_time=13123121400;end_time =132123241500;inst_id,migrate-win2003-vifs
						http://10.1.157.163:8080/aliyun/QS/OSS/RAW
						bid - 用户ID，app所属的用户
						$bucketname对应kv_bucket
					- 
						
				* DB取cpu时间等
					‘cloudengine`.`fastcgi_app_running_info` cpu_acc_usage App的cpu持续使用时间，单位：秒

			>> 处理

			>> 推送 写往MS
				推送数据格式
					* 在 DataFormat里定义枚举 
					*  pojo (实现接口)
					* 请求
						http request header:
						PUT /aliyun.com/QS/SLB/RAW HTTP/1.1（待定，需姜一提供）
						HOST: ms.aliyun.com
						CONTENT‐LENGTH: 12345
						META: uid,string;inst_id,string; time, integer; usetime,integer; total_in,integer;total_out,integer;tcp_flow_in,integer;tcp_flow_out,integer;http_flow_in,integer;http_flow_out,integer;vip_type,string;rs,integer;flow_detail,string;region_id,string;end_time,integer;
						“META为用户发送的数据的格式信息，这部分必须添加在http的header部分，为计量服务(MS)特有字段”
						http://metering.aliyun-inc.com:8080/aliyun/QS/OSS/RAW  —— 线上系统的地址
						http://10.1.157.163:8080/aliyun/QS/SLB/RAW —— 测试时用测试系统地址
					* 整理推送的字段对照 doc ？
						Cpu(ms)、流量(byte)、存储空间(byte)、请求次数、memory-cache(byte)

						属性名			类型			单位			描述
						uid				string							包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务
						time				integer							开始时间(记录当前记录的时刻，为一点态时间，如果用户的计量数据采集并非实时，则time表示抽样开始时间即begin_time，采用可显示的unix时间表示法)
						end_time			integer							结束时间(表示抽样结束时间，同样采用可显示的unix时间表示法)
						inst_id			string							应用id即appid
						cpu				integer			ms				cpu使用时间
						flow				integer			byte				总流量(http流量)
						flow_in			integer			byte				流入流量
						flow_out			integer			byte				流出流量
						app_size			integer			byte				存储空间(oss)
						req_count			integer			个				请求次数(包括pv内的多个异步请求)
						version			integer							版本号，目前为1



						






		uid：包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day9 Monday, March 26, 2012

1. 计量的接口说明 最新的 ？
	

2. 把ace计量初步需求写入文档，
	类似于slb接口文档等
	
	目的：设计ace计量项，并取到后处理然后提交到ms系统
	计量项列表：
	实现：
		计量项获取：
		处理
		推送
	xuanyuan cloudengine数据库表间关系由程序控制，注释说明关系。

3. job的具体实现，失败补偿逻辑，参看console中的static模块
	？


4. 通过powerdesigner的reverse engine ，从database的sql文件将ddl转换为er图，了解db表关系

5. velocity 方便对象格式化到文件
	...
	velocityEngine.init();//spring配置好resourceLoaderPath
	template = velocityEngine.getTemplate(templateFile);
	VelocityContext context = new VelocityContext();
	context.put("datasMap", map);
	writer = new FileWriter(outfile);
	template.merge(context, writer);
	...
6. spring + quartz 执行定时任务
	<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
		<property name="targetObject" ref="task" />
		<property name="targetMethod" value="execute" />
		<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
	</bean>	
	<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
		<property name="jobDetail" ref="collectDataDetail" />
		<property name="cronExpression" value="0 0 */1 * * ?" />
	</bean>  
	<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="triggers">
			<list>
				<ref bean="collectDataTrigger" />
			</list>
		</property>
	</bean>
7. 操作记录及时保存为数据库的日志，后续补偿机制根据数据库补偿并更新 ？
	细节

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day10 Tuesday, March 27, 2012

1. 根据上面ace计量文档，编码
	对于时间如何处理，补偿机制

2. ACE计量先不提供需要访问MS的SLB和OSS数据，暂先考虑DB数据 【task】
	先实现ace监控数据的抽取推送。
		一些dao需要自己定义以取监控数据
		时间校准，以抽取逻辑定义的时间为准，根据定义的时间去取监控数据并汇总，处理，推送
	处理的整体流程：
		关键是发生错误的补偿处理逻辑：
		tasklog表记录task日志。		

3. 表说明
	region - 代表一个集群
测试环境 mysql
mysql -h10.249.153.1 -ucloudengine -pcloudengine2011 -Dcloudengine



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day11 Wednesday, March 28, 2012

1. 设计好补偿处理逻辑
	结合day10第二条的表记录job及其result实现补偿处理。

2. 任务处理已有设计，在已有的任务设计下实现功能
	* job代表每一次执行的任务
		job推送前都记录到数据库，job下的内容保存为临时文件。
	* spring+squza定时任务
	* 日期处理
		DateUtils.java —— 将date日期格式化为需要的格式；date到秒；string+patten到date  (SimpleDateFormat实现)
	* pojo
		TaskLog 任务日志pojo
			private Long id;
			private int status; // 1:success,0:failed
			private String filename;
			private Long taskTime;
			private int jobType; //[0:vm job,1:device job; default 0]
			private Date beginTime;
			private Date endTime;
			OR文件：/houyi-console-dao/src/main/resources/ibatis/TaskLog.xm
				houyi库 statistics_log
	* service
		JobService ：job相关操作
			public boolean addOrModify(TaskLog job);
			public boolean checkStatus(TaskLog job);
			public List<TaskLog> listFailedJobs(long startTime);
			public List<TaskLog> listJobs(long startTime,long endTime);
			public TaskLog getLastJob();
	* dao
		TaskLogDao ：任务日志DAO操作
			void insertTaskLog(TaskLog log) ;
			void updateTaskLog(TaskLog log) ;
			TaskLog getTaskLog(TaskLog log) ;
			TaskLog getLastTaskLog();
			List<TaskLog> getFailedTaskLogs(Long bTime);
			List<TaskLog> getTaskLogs(Long bTaskTime,Long eTaskTime);

	* task 由于时间等内容不好共用，可再设计一个task，并通过spring配置执行。
		或对task进行业务无关的再抽象，只留下共用的逻辑，其他都内聚到job自身中。-tip-

	处理流程：(包括 Task ，JobProducer，需要的service,dao,pojo) - 由程序入口分析
		--> task - execute()定时执行这个方法 - 调用dojob()  —— dojob是单线程的，如果job多或者某个前面的job占用时间长会影响后面的job的执行开始时间 ？ tip 如果是独立的task则不用考虑影响问题
			遍历执行注入的jobproducer实现 (获取方式：beans = (Map<String, JobProducer>) applicationContext.getBeansOfType(JobProducer.class))
		--> jobproducer(具体job逻辑在jobproducer的实现类里编写)\
		--> service
		--> dao
		逻辑就在task，jobproducer,abstract jobproducer中，定义自己的逻辑即可。
			原有任务以task作为主流程控制，jobproducer抽象类及其实现定义了所有逻辑。抽象类提供公用逻辑或抽象方法统一逻辑。-tip-
				取数据 - 存入数据库/文件(通过velocity映射对象集合(以appid为标识)存为文本) - push - 更新状态
3. 模拟实现
	根据原有static模块任务设计
		* 定义数据结构 pojo ,velocity模板(用于对象格式化持久化)
			是否需要将此pojo作为对象查询？即某个查询直接返回此pojo，需要ibatis映射配置，这样只要查询一次关联几张表得到数据；或者分别查询在程序中处理。
			暂定位分别查询。分别查询，减少关联
		* 实现一个job producer
		* 定时task类，可能需要再实现一个并在spring里配置(原task再抽象以下，可配置)，
		参考配置：
			<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
				<property name="targetObject" ref="task" />
				<property name="targetMethod" value="execute" />
				<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
			</bean>	
			<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
				<property name="jobDetail" ref="collectDataDetail" />
				<property name="cronExpression" value="0 0 */1 * * ?" />
			</bean>  
			<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
				<property name="triggers">
					<list> <!-- 此处配置定时要执行的task列表 -->
						<ref bean="collectDataTrigger" /> 
					</list>
				</property>
			</bean>
		* 判断tasklog是否已执行过，通过jobtype类型和jobtime-job开始时间，如果是依据查询的最新执行时间作为job开始时间
			if (jobService.checkStatus(job))
			{
				logger.info("exist job:" + jobTime);
				return true;
			}
		* abstract producer的一些公用成员变量是否可以提供get方法供子类调用，子类不用重复定义 ？
		* task的recoverJob逻辑处理丢失的任务（比如关机等造成的任务丢失），目前任务是能处理丢失10次的任务，是否可以根据做新一次的任务的开始时间
		结合当前时间计算共丢失多少次任务，然后执行所有丢失的任务？
			Task
			------
			...
				/** Get the last record of success in the log table **/
				TaskLog log = jobService.getLastJob();

				/** compensate for missing the task **/
				if (log != null)
				{
					int i = 1;
					while (log.getTaskTime() + i * HOUR_SEC < jobTime)
					{
						/** Compensate for 10 times **/
						if (i == 10)
						{
							break;
						}

						TaskLog job = new TaskLog();
						job.setBeginTime(new Date());
						job.setTaskTime(log.getTaskTime() + i * HOUR_SEC);
						job.setStatus(0);
						jobService.addOrModify(job);
						i++;
					}
				}
			...
			------
		* 一些任务参数是否可以配置到配置文件中，类似abstract job producer的parentpath路径配置 比如：采集间隔，一些补偿机制参数 ？
		* statistics_log表？
		* app的类别区分是哪个字段(php,nodejs,jsp) ?
			templetid?
		* 用到的一些接口需要修改 ，通过的方式过少，是否可修改，其他地方是否有调用？
			比如提供id数组查询。
		* 应用运行时状态表
			fastcgi_app_running_info
			nginx_app_running_info
			memcache_app_running_info
			nodejs_app_running_info
		* console与cloudengine不是同一项目，maven管理依赖，引入cloudengine的包？
			自己重新写maping文件pojo及dao接口和实现。不依赖不相关系统。
			在dao，model等模块加入对应代码。
		* ibatis查询，可以根据外键设置关联查询，减少查询次数
		* 由于是另外一个数据库，需要再配置数据源
		* 在houyi-console-dao里写dao层用到pojo是static中的，是否把pojo，dao，service都按照模块放置，负责dao就要依赖到static中的pojo ？
			static的model不直接提供dao，而是从其他数据组合而成。比如从appdao的查询记录里组合而成。
		* 统计一个时间段的缓存使用量，如何取？暂定为求和
		* 参考master的constant 包定义的常量，帮助了解一些业务知识
			AppType 定义了应用的类型。php.nodejs...
			app 的 language 属性定义apptype类型。
		* 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day12 Thursday, March 29, 2012

1. go on 
	新建maven project开发，独立功能
	参考console的static模块，做成一个任务模块(业务，逻辑分离，易配置)
	wiki地址：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8259199
	svn ：http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk
	web项目 or java进程(jar包main函数启动) or 作为一个组件部署（作为组件部署，有哪些要求，比如 cloudengine 在 xuanyuan 上运行）？
	
	* 导入需要的包
	* 拷贝公用代码 工具类 等
	* dao设计依据master，提供抽象dao实现namespace的spring配置
	* 参考master用jtester测试
		加入jtester依赖包 地址http://java-tester.googlecode.com
		jtester 配置文件中 unitils.modules=database,dbunit,dbfit,inject,spring,tracer ，这里列出了需要的模块
		编译测试，提示编译版本问题时，可以切换下jdk版本，并clean下project。
		测试用例数据，参考master的：eg
			@DbFit(when = {"AgentCheckResultDaoTest.testReadByAgentId.when.wiki"})
		集成spring测试时，可能由于spring配置等问题导致maven test失败；可通过基本的main函数先保证spring的注入式正确的 -tip-
		maven test + main method test
		maven clean + eclipse project clean solve cmplile problems 
	
		如何自动生成测试用例 ？ ，对每个方法都手工去编写基础测试代码过于繁琐
		
		wiki方式数据库测试时，jtester测试时可以根据wiki配置临时清除表数据，做测试，结束后回滚。

	*  wiki project描述

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day13 Friday, March 30, 2012

1. ameasure-data project
	job基础代码与业务代码分离，实现可配置。
	* 配置maven插件,jar (以及插件的参数配置，jar执行main函数配置 etc - 参考maven jar插件说明：http://maven.apache.org/shared/maven-archiver/index.html)
	* 测试报 Could not find Velocity resource: class path resource [VM_global_library.vm
	* 配置maven插件 maven-assembly-plugin ,packaged with-dependencies 打包并加上依赖 ,配置assembly参数，比如jar分别打包，
		打包时可能jar包文件重复，test目录下的测试文件也打包进来，配置一些参数即可，例如：
			-----
			...
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.Test</mainClass>
							</manifest>
						</archive>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				(2)
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<descriptors>
							<descriptor>src/main/assembly/src.xml</descriptor>
						</descriptors>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.StartTask</mainClass>
							</manifest>
						</archive>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0" 
				  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				  xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd">
				  <!-- TODO: a jarjar format would be better -->
				  <id>with-dependencies</id>
				  <formats>
				    <format>zip</format>
				  </formats>
				  <includeBaseDirectory>false</includeBaseDirectory>
				  
				  <dependencySets>
				    <dependencySet>
				      <outputDirectory>/</outputDirectory>
				      <useProjectArtifact>true</useProjectArtifact>
				      <unpack>false</unpack>
				      <scope>runtime</scope>
				    </dependencySet>
				  </dependencySets>
				</assembly>
			...
			-----
			打成上面这种jar包集合方式，在同一文件夹下运行即可，省去classpath配置的麻烦。

		maven clean after close resource opened -tip-
	* 加上shell执行脚本，调用此jar并执行
	* 原有推送逻辑，一次job比如推50条，一条失败就退出，暂处理为本次任务再尝试推送(设定尝试次数)
	*  ibatis 在命令行下运行找不到mapping文件，在eclipse下测试ok 原因？ 待  —— ibatis没问题，spring也ok，字体用的不好(大小写居然相似，
		最后还是仔细看了错误输出，错误点才发现大小写)大小写错误，配置文件配置和实际文件大小写不一致！！！-tip-
		如何避免：提示文件找不到，名称不匹配等等，首要看是否书写错误，能拷贝一定拷贝，不要手工输入，特变是在配置文件场合。 -tip-




2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day14 Saturday, March 31, 2012

1. measure-data
	* 逻辑细化 command
	* quartz ? cluster
		利用quartz实现调度执行，将操作记入日志，失败处理另外实现并
	* 任务测试
		测试表 tasklog `statistics_log`
			CREATE TABLE  `cloudengine`.`statistics_log` (
			  `id` int unsigned NOT NULL AUTO_INCREMENT  COMMENT '@desc 主键ID' ,
			  `status` tinyint NOT NULL COMMENT '@desc 1', 
			  `filename` varchar(128)  COMMENT '@desc filename',
			  `task_time` datetime NOT NULL  COMMENT '@desc tasktime',
			  `begin_time` datetime NOT NULL  COMMENT '@desc begin_time',
			  `end_time` datetime NOT NULL  COMMENT '@desc end_time',
			  `job_type` tinyint NOT NULL COMMENT '@desc 1', 
			  PRIMARY KEY (`id`)
			) ENGINE=InnoDB DEFAULT CHARSET=utf8;
			ALTER TABLE `statistics_log` MODIFY COLUMN `task_time` bigint(20) NOT NULL GO
			测试数据：
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(1,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',3);
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(2,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',1);
	* 提供开启程序，退出程序脚本 ，通过命令操作即可 。可参考tomcatd的脚本
		手工停止任务执行。（或强制停止并处理强制停止任务的恢复逻辑），假如某次job有200条记录在推送了150条时，程序关闭了
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day15 Thursday, April 05, 2012

1. 逻辑实现
计量会议
linux环境：
	10.250.8.214 chengs 123456
shell 下java程序控制：
	  -----
	  ...
		#! /bin/sh

		#启动方法
		start(){

			java -Xms128m -Xmx2048m -jar test1.jar 5 > log.log &
			java -Xms128m -Xmx2048m -jar test2.jar 5 > log.log &
			tail -f result.log
		}
		#停止方法
		stop(){
			ps -ef|grep test|awk '{print $2}'|while read pid
			do
			   kill -9 $pid
			done
		}

		case "$1" in
		start)
		  start
		  ;;
		stop)
		  stop
		  ;;
		restart)
		  stop
		  start
		  ;;
		*)
		  printf 'Usage: %s {start|stop|restart}\n' "$prog"
		  exit 1
		  ;;
		esac

		...
		CLASS_PATH=dayemail.jar
		CLASS_PATH=$CLASS_PATH:lib/activation.jar
		CLASS_PATH=$CLASS_PATH:lib/classes12.jar
		CLASS_PATH=$CLASS_PATH:lib/c3p0-0.9.1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/commons-email-1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/dom4j-1.6.jar
		CLASS_PATH=$CLASS_PATH:lib/jaxen-1.1.1.jar
		CLASS_PATH=$CLASS_PATH:lib/jxl.jar
		CLASS_PATH=$CLASS_PATH:lib/log4j-1.2.16.jar
		CLASS_PATH=$CLASS_PATH:lib/mail.jar

		SERVER=/qzpt/mydayemail
		cd $SERVER   
		  
		case "$1" in   
		  
		  start)   
		    nohup java -Dfile.encoding=UTF8 -Xms64M -Xmx256M -cp $CLASS_PATH com.trendsnet.myemail.EmailShell > $SERVER/server.log 2>&1 &   
		    echo $! > $SERVER/server.pid   
		    ;;   
		  
		  stop)   
		    kill `cat $SERVER/server.pid`   
		    rm -rf $SERVER/server.pid   
		    ;;   
		  
		  restart)   
		    $0 stop   
		    sleep 1   
		    $0 start   
		    ;;   
		  
		  *)   
		    echo "Usage: myshell.sh {start|stop|restart}"  
		    ;;   
		  
		esac   
		  
		exit 0  
	...
	-----
	来自：http://www.iteye.com/topic/1122093
	* 在程序中中增加一个hook,jvm退出时会执行hook中的代码 
	Runtime.getRuntime().addShutdownHook(Thread); 
	kill -15 （SIGTERM）能够执行hook中代码 
	kill -9   (SIGKILL) 不能够执行hook中代码 
	在程序关闭前做处理工作，然后关闭。
	* 启动的时候将shell脚本的PID记录到文件里面，然后关闭的时候就可以直接读文件获取PID，避免用ps查询了，有可能不准确的 
	echo $! > $SERVER/server.pid

2. mvn test package etc 配置好资源文件 如 -tip-
	<resource>
	<directory>src/main/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>

	<resource>
	<directory>src/test/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.wiki</include>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>
	上面，加载包括main和test下的所有配置文件(部分子目录下的文件)。
mvn test生成的报告会说明失败原因，依据错误解决问题。
maven test failure —— 错误报告会告知哪里导致错误，一步步检查 cause 即可。另，test等都是依据pom的配置执行的，pom的配置要细心。
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day16 Friday, April 06, 2012

1. test 抽象类(实现方法，测视类中静态内部类继承) ，私有方法（反射）
	通过反射测试
	

2. Cron expressions  ,quartz		 cron表达式
	- expressions format
		Format
		A cron expression is a string comprised of 6 or 7 fields separated by white space. Fields can contain any of 
		the allowed values, along with various combinations of the allowed special characters for that 
		field. The fields are as follows:

		Field Name	Mandatory	Allowed Values	Allowed Special Characters 
		Seconds		YES			0-59				, - * / 
		Minutes		YES			0-59				, - * / 
		Hours		YES			0-23				, - * / 
		Day of month	YES			1-31				, - * ? / L W
		Month		YES			1-12 or JAN-DEC	, - * / 
		Day of week	YES			1-7 or SUN-SAT	, - * ? / L # 
		Year			NO			empty, 1970-2099	, - * / 
	- 
		-----
		...
			Method method = aceCalcJob.getClass().getDeclaredMethod("buildAceCalcStruct", Date.class,Date.class);
				method.setAccessible(true);
				Object result = method.invoke(aceCalcJob,startDate,endDate );
				@SuppressWarnings("unchecked")
				Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		...
		-----
3. acecalc
	* 任务第一次执行时，采集时间点的确定，根据app的创建日期为起点开始采集？
		自动查询数据库得出 or 配置文件配置初始抽取时间点 or 两者都支持
	* 

4. MS 改为 OMS 参看其文档 * OMS open metering service
	 OMS简介
		阿里云 计量 服务（ Open Metering Service ，简称 OMS），是阿里云对外提供 ），是阿里云对外提供 用户在阿里云平台上使各个服务（如 用户在阿里云平台上
		使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个
		服务（如 用户在阿里云平台上使各个服务（如 用户在阿里云平台上使各个服务（如 OSS OSS，OTS ，ODPS ，RDS ，VM ，ACE ）产生 的计量数据存储和查询
		服务。用户可以通过简单的 REST 接口 ，获取格式化的 ，获取格式化的 自 己
	
	开放计量服务(OMS)的数据模型包括以下几个概念:
		 Object
		 Domain
		 Accessid
		 Accesskey
	上面观念划分，体现了OMS的REST服务方式。
	
	推送数据格式：
		* Date 目前Date只支持GMT格式，具体的GMT格式可参考如下示例:
			Wed, 30 Aug 1991 09:13:05 GMT
			更多关于GMT时间格式的信息，请参考RFC|1123
		* 
		
5. 
cpu

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day17 Monday, April 09, 2012

1. 新OMS提交修改

2. 访问次数 pv 所在表
	nginx_app_abstract_running_info 
	nginx_app_running_info
3. 推送测试环境 ？ OMS测试环境提供推送测试
	测试推送逻辑
demo http://svn.simba.taobao.com/svn/Apsara/openapi/trunk/java/src/com/aliyun/openservices/oms/

	uri：http://10.230.201.85:8080/ACE_RAW
	accessid: rot1d0cc9bxp97vpcwjyo98o
	accesskey: 0GC/ahEtRiNReKA1NhuNimJ2b3A

	* 推送格式改为xml
	* 请求头变化
	
	加好各种header后，进行签名，带上content 发送请求。

	
	临时文件名，取名时需要考虑2个或2个以上操作发生在同一秒内的情况。

	403 签名错误 ，
	400 非法参数 InvalidParameterValue <Message>unsuported content-type</Message>
	* put内容的字段变化了 原来的uid，改为3个分开：
		eg:
			#foreach ($data.value in $datasMap.entrySet())
			   <Object><uid>default</uid><pid>ace</pid><bid>aliyun</bid><inst_id>$data.value.appId</inst_id><time>$data.value.startTime</time><cpu_acc_usage>$data.value.cpuAccUsage</cpu_acc_usage><memcache_size>$data.value.memcacheSize</memcache_size><req_count>$data.value.reqCount</req_count><lb_id>$!data.value.lbId</lb_id><version>$data.value.version</version><end_time>$data.value.endTime</end_time></Object>
			#end
	 * OMS client的get方法，查询测试用。
		查询OMS
	main test 输出：
		{response=<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authenticate user</Message>
		<RequestID>41e3d2b9-31d0-2c4f-493b-e4635bff819b</RequestID>
		</Error>
		, status=403}

4. mem_size 暂取为某个计量时间段内的平均值 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day18 Tuesday, April 10, 2012

1. 
	* oms get测试 - pass
	* 一次put多个object测试
	* 启动，关闭脚本修改 
	* 计量值多数据测试，统计的sql是否存在问题，大数据计算精度问题
	* 某些job中app并没有产生任何数据是否应该抛弃，不推送到OMS上，导致的问题是，在某个时间点或者区间查询时导致没有数据。？
	* quartz 挂起api ，正常停止任务，不建议job执行时强制关闭进程（程序逻辑需要处理这种例外）
	* 运行jar的配置文件独立到jar外面便于配置 
		通过spring配置加载外部配置文件。
			spring配置文件也配置在外部(不在classpath上)，spring提供了org.springframework.context.support.ClassPathXmlApplicationContext 以加载classpath之外的配置文件。外部配置文件 -tip-
		log4j提供的配置文件设置类 org.apache.log4j.xml.DOMConfigurator ，可以设置定时检查配置文件修改并重新加载配置。在main函数里初始化如下：
			String log4jfile = System.getProperty("user.dir") +File.separator +"config"+ File.separator +"log4j.xml";
			DOMConfigurator.configure(log4jfile);
		配置文件改为：
			spring和properties文件都移到jar外面，ibatis配置文件还是在jar包中。
			问题是，maven如何打包时，把config文件夹拷贝一份和包在同目录下？ assembly ？
			改为：
				配置文件只把关键的 log4j,job,jdbc 等放在jar外面加载，其他进jar包。
			shell 脚本需要在bin目录下运行，否则有配置文件找不到等错误 -tip- ，如何优化shell脚本
	* 拿到真实环境的相关数据库表机构，是否与本机一致？比如statistics_log表
	

2.  oms get测试

	已push成功的待查询测试数据：
		<?xml version="1.0" encoding="UTF-8"?>
		<Objects>   
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id></lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>
	get查询请求参数：
		"GET /ACE_RAW HTTP/1.1[\r][\n]"
		"Authorization: OMS rot1d0cc9bxp97vpcwjyo98o:yqb7kFIP3prg8z0x4gw5T4lnXEw=[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:30 GMT[\r][\n]"
		"x-oms-filter: time=1334019600[\r][\n]"
		"x-oms-select: uid;pid;bid;inst_id;time;cpu_acc_usage;memcache_size;req_count;lb_id;version;end_time[\r][\n]"
		"User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]"
		"Host: 10.230.201.85:8080[\r][\n]"
		"[\r][\n]"

	返回成功信息：
		"HTTP/1.1 200 OK[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:31 GMT[\r][\n]"
		"Server: Apache/2.2.17 (Unix)[\r][\n]"
		"Content-Length: 322[\r][\n]"
		"Content-Type: text/xml;charset=UTF-8[\r][\n]"
		"[\r][\n]"
		"<?xml version="1.0" encoding="UTF-8" ?>
		<Objects>
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id>0</lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>"

	注：上面put的数据与get返回的数据 lb_id由空变为了0，这是OMS对某些字段如果空会置默认值的逻辑。

	uid+time
	uid+pid+bid+inst_id+time
	目前就这两个你有权限查
	
	domain没有操作权限：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authorize user</Message>
		<RequestID>7a44a74b-211a-fda1-68b6-7f5907108b41</RequestID>
		</Error>	
	查询条件错误：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>InvalidQueryExpressison</Code>
		<Message>query condition not match any dimension</Message>
		<RequestID>66a00276-6ad9-d94f-1bf7-db7f0c4830ba</RequestID>
		</Error>	
3. 部署  程序运行目录定义说明（配置简单操作为好）
		bin - 放运行脚本
		build - 放编译脚本(svn下载，maven构建，部署到设定的目录(到bin,lib,config))
		config - 存放配置文件(log4j,job等的配置文件)
		lib - jar文件
		logs - 日志

		操作从调用build下的脚本开始执行。
		build下放置build好的文件，如何deploy脚本将build好的文件分别部署到相应的目录中去。
		bin下的启动脚本需要在bin当前目录下运行，否则报配置文件找不到？

4. sh -x xx.sh 查看
	脚本可能因为隐藏字符导致错误，执行时 -x 查看即可。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day19 Wednesday, April 11, 2012

1. 
	执行过程中断处理
	那些数据时不用推送的，比如某个时间段都没有产生数据（这压缩数据交给oms？）


2. shell 执行路径问题  shell 必须在当前路径执行，否则路径错误 ，解决？【 spring加载资源文件路径 ，类路径，外部路径 配置路径 路径设置 改变工作目录 当前路径】
	关键：cd 命令，设置当前路径 
	#!/root/bash
	echo `pwd`
	current_dir=$(cd "$(dirname "${0}")";pwd)
	echo $current_dir
	
	pwd会因为执行路径不同而变化，current_dir可以取到shell所在路径。 

	但对于没有动态调用 user.dir 找到classpath之外资源路径的情况，可以在非shell所在目录执行时，在shell里cd到所在base目录，这样
	后续java加载取值时，取得就是cd后的路径。-tip-

	shell执行时，指定java系统参数 user.dir 即可 ，即指定java执行时用户当前目录为程序所在主目录（base目录，其子目录有lib，bin等等）。-tip-
	通过java命令的 -D 参数指定 user.dir ,结合程序逻辑，指定资源文件等的路径path。
		String log4jFile = System.getProperty("user.dir") + File.separator + "config"+ File.separator +"log4j.xml";
		-----
		...
			#!/bin/bash
			BIN_DIR=$(cd "$(dirname "${0}")";pwd)
			BASE_DIR=`dirname $BIN_DIR`
			LIB_DIR=$BASE_DIR/lib
			LOG_DIR=$BASE_DIR/logs
			#set for java to load resource
			USER_DIR=$BASE_DIR
			JAR_NAME=houyi-measuredata-all-0.0.1.jar
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    start)
				cd $BASE_DIR # 转到程序需要的工作路径，比如需要此路径来加载资源文件，spring里从外部文件加载的资源文件相对此$BASE_DIR取路径即可。
				java -Xms64M -Xmx256M -Duser.dir=$USER_DIR -jar $LIB_DIR/$JAR_NAME > $BIN_DIR/server.log 2>&1 &
				echo $! > $BIN_DIR/server.pid
				;;
			    stop)
				kill `cat $BIN_DIR/server.pid`
				rm -rf $BIN_DIR/server.pid
				;;
			    *)
				echo  "invalid option ,usage: $0 [insert|remove]";
				;;
			esac

			exit 0
		...
		-----
		通过 -Duser.dir=xxx 设置user.dir参数好

		执行路径，相对路径 ，程序默认读当前路径，执行路径时，在shell可以 cd 到所需要的当前路径(工作路径)，再执行即可。
		
3. svn 提交 eclipse ，还是用svn客户端 
		eg: TortoiseSVN   
			check for modification - revert  
		可以用客户端管理版本，eclipse只负责项目开发。 不同svn客户端交叉用可能出错误。
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk 
		username
		password
	* svn
		- install (its package named subversion ,not svn)
			yum install subversion
		- 各种svn工具操作命令不相同，但svn基本功能都是提供的，只是不熟悉的话要去找找
			比如：TortoiseSVN 查看某个文件的提交记录 ，是调用 show log 菜单 ；eclipse的svn插件用的可能就是 xx history ；熟练度的关系

4. 从svn下载到maven编译到部署运行 ，整个的脚本
	svn取到项目源码
	mvn 构建
		不同机子上构建时依赖可能出现的问题：
			Error transferring file: Connection refused
			Specified destination directory cannot be created: /usr/ali/maven/repository/org/slf4j/slf4j-api/1.5.6 - maven库没有添加jar权限，改为已有的版本绕过
				eg: ls /usr/ali/maven/repository/org/slf4j/slf4j-api


5. 部署说明文档 (测试，部署人员依据此文档操作)
	* 从10.250.8.214机子上拷贝目录measure(/home/admin/measure)到目标机/home/admin目录下，进入该目录 (编译机和运行机都采用上面的目录结构)
	* 执行bulid 目录中的build.sh构建
	* 然后执行build目录下的deploy.sh部署
	* 再执行bin目录下的execute.sh启动和关闭程序，用法如下：
		execute.sh start - 启动程序
		execute.sh stop - 关闭程序
	目录结构说明：
		measure
			- bin 包含执行程序的脚本 execute.sh ，shell执行日志文件server.log,程序的的pid备份server.pid
			- build 包含构建和部署脚本build.sh,deploy.sh
			- config 包含程序配置文件log4j，job，jdbc的属性配置
			- logs 程序执行日志
			- src 存放源码
				- target 打包后的文件(zip)

6. maven换其他环境编译时，依赖找不到解决，看错误日志找到依赖找不到的原因，一般即可解决

7.  shell 脚本  ,字符不认识问题 ，在windows下的文本，通过ssh工具拷贝到linux中后，不能正常执行命令。可能是字符编码或者异常特殊符号(;/r)等问题，可在linux下
新建shell解决，拷贝的一般都有问题。

或者，是因为使用的ssh客户端没设置好，传输时编码问题？从svn下载下来的shell(原在windows下创建)都不能正常执行。 -tip-

原因：unix，dos 字符间需要转换 
	xxx@xxx$ uni
		unicode_start  unicode_stop   uniq           unix2dos       unix_chkpwd
	dos2unix

8. 
unix2dos dos2unix

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
day20 Thursday, April 12, 2012

1.  
	sql独立，将各自的查询sql独立查询，程序里再组合，编写涉及到表的pojo和映射文件
	dao db wiki 测试
		'file://D:\workspace\measure/target/dbfit/com\aliyun\houyi\measuredata\dao\impl\MemacheAppRunningInfoDaoImplTest.testReadAceCalInfocByTimePeriod.when.html'

2. 
	ls -R 
	shell判断文件是否存在，再做后续操作
		if [ -f urfile ]  then
			./a.sh   
		fi

3. sql独立
	对于数据量可预知且不大的情况下，可以进行关联查询，减少访问数据库次数。对于数据量非常大的表最好单独查询，计量减少关联查询。 -tip-

4. 单元测试，补上db部分的测试，验证sql逻辑等 -tip-
	mvn test -Dtest=AppDaoImplTest 只测试某个用例
5. 
duplicate entry key 
	确认那些字段是唯一的，一条若有多个唯一的，保证都唯一，否则数据库报错可能误报，比如有key3和key8都是unique，此时即使key3是唯一的，但key8
	是重复的，执行后可能会误报key3重复，实际上是key8重复。-tip-

6. vip 表字段修改，测试时注意
	 alter table vip add lb_id varchar(20) default NULL;
	 alter table vip MODIFY COLUMN lb_id varchar(20) default NULL;

7. mysql ,ibatis
	mysql的各种数字统计函数对应的类型不同
		需要定义好。在sql语句里转换好类型。
8. maven test 时报错误，找不到某个类，是因为测试环境和开发环境冲突了，比如在开发环境用了测试的jar，会导致错误，部署时，除去测试的依赖。 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day21 Friday, April 13, 2012

1. 
	*  job 的丢失处理时间和临时文件保留时间改为配
	* ace计量中agent的角色
		计量数据由agent上报，同app同类型数据可能有多个agent上报，统计时，需要注意这点。比如求平均时需要先求时间段内每个agent各自
		数据的平均值，再对平均值求和。
	* JCE OpenAPI
		svn改了新分支，下载新的cloudengine分支
			http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v5/master

2. job 的丢失处理时间
	和临时文件保留时间改为配
	丢失文件查找费时间

3. jce openapi  
	目标：
		标准openapi请求转接到rest服务处理。
	具体：
		根据一个请求路径，比如 /open，将所有对openapi的请求转到openapi调用service来处理，在这个service里，得到openapi的请求参数
	，根据参数调用master提供的service进行处理并返回。其中对参数的验证等可参考rest路径请求进来的处理过程。
			
	RestOpenService.java  供 openapi 调用的service
	目前文档里稳定的接口是 3.1->3.9

4. sql ，app_id,agent_id 一个app_id对应每个agent_id平均值的和,一次分组求平均，一次分组求和，多次分组统计即可 -tip-
	-------
	...
		select
		    app_id,
		    sum(tempmem.memcache_size) as memcache_size
		from (
		    SELECT  
			memcache_agent_id,
			app_id,
			ifnull(avg(mem_bytes),0) as memcache_size 
		    FROM memcache_app_running_info
		    group by memcache_agent_id
		    ) tempmem
		group by tempmem.app_id
	...
	-------
	前提 memcache_agent_id 与 app_id 为一对一或多对一的关系。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day22 Monday, April 16, 2012

1. 
	* 根据mast提供的service和jce openapi ,设计一个供openapi调用，处理普通get,put方式的rest服务。
		目标：此服务通过master提供的接口，实现jce openapi提供的接口服务(比如创建app,删除app等等)
			请求的验证，master在提供的service调用里已有处理，故此服务只根据请求的action定位到service，传递参数。
		
	* wiki 添加ace计量sql语句供review
		- app_id查询时应该不带状态，如果只取已部署的app，可能导致部分app运行数据丢失
		- memcache 计算sql语句错误，app_id和memcache上报agentId是多对多关系。
			
	* ace的部署方式，加上先从svn下载默认目录结构(包含build部署，执行脚本)，然后执行build进行build,然后deploy，最后execute
		这样，部署ace计量程序步骤如下：
			a. 在有写权限的临时路径下执行
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/deploy-env			
			b. 进入上面checkout下来的目录(deploy-env)，找到measure目录，将其拷贝到/home/admin/measure目录下(若没有此目录则新建，若重名就另外取目录名亦可)
				cd deploy-env
				cp -r measure /home/admin/measure
			c. 进入 /home/admin/measure 目录
				cd /home/admin/measure
			d 执行构建脚本
				sh build/build.sh
			e 执行部署脚本
				sh build/deploy.sh
			f 执行启动服务脚本
				sh bin/execute.sh

2. master的rest对openapi，
提供一个rest service接受所有openapi请求，内部通过一个方法接受所有请求并解析后调用对应action，service处理。

jce的openapi调用文档 —— 据此文档解析请求，调用jce master提供的service


3. ots
	http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000

4.maven debug
	mvn -Dmaven.surefire.debug test
	在ide，比如eclipse上配置远程debug(remote java application)，通过socket来debug。
	通过所使用的maven测试插件自带说明来配置debug，文档最清楚 -tip-

	运行上面maven命令后，再到eclipse配置debug run 为remote java application等配置，执行debug即可进入远程debug模式。
5. jce openapi
	根据请求的action的不同，分发到各自的function去处理，如何去分发？
		通过反射？
			定义acton与方法的的对应关系,比如以属性文件方式配置
			根据action通过反射调用service的方法
		还是自定义注解解析请求uri的方式？
			参考Spring MVC ，提供了完全基于注解的配置
				参考：http://www.cnblogs.com/sunwei2012/archive/2010/05/11/1732518.htm
					http://www.infoq.com/cn/articles/cf-java-annotationl
	* jce日志接口调用
		query_app_log这个接口的type类型，应用的日志是在ols(open log service)服务 里获取的
		
6. 自定义 annotation 实现元数据配置 ，自定义注解
	* 定义action注解
		actionName - 请求的action名称
		parms - 对应action所需要的参数(这里每个action参数不一致，引出下面的问题)
			需要rest提供一种方式，可以取到比较原始的请求消息，可以进行自定义再处理，而不是在rest方法里定义好
		需要取那个参数。？
	* 通过注解，由于每个jec open api的请求参数不同，所有需要根据rest规范，得到请求的所有参数，
	参考了sum的RESTfulWeb Services Developer'sGuide(p26)，可以通过context注解来注入请求上下文内容，
	从而获得所有请求参数。再匹配到对应的action取到各自的参数，调用service执行逻辑。-tip-
		----
		...
			Form parameters (indicated by decorating the parameter with javax.ws.rs.FormParam)
			extract information from a request representation that is of the MIME media type
			application/x-www-form-urlencoded and conforms to the encoding specified by HTML
			forms, as described here. This parameter is very useful for extracting information that is
			POSTed by HTML forms. The following example extracts the form parameter named "name"
			from the POSTed form data.
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(@FormParam("name") String name) {
			// Store the message
			}
			If it is necessary to obtain a general map of parameter names to values, use code such as that
			shown in the following example , for query and path parameters.
			@GET
			public String get(@Context UriInfo ui) {
			MultivaluedMap<String, String> queryParams = ui.getQueryParameters();
			MultivaluedMap<String, String> pathParams = ui.getPathParameters();
			}
			Or code such as the following for header and cookie parameters:
			@GET
			public String get(@Context HttpHeaders hh) {
			MultivaluedMap<String, String> headerParams = hh.getRequestHeaders();
			Map<String, Cookie> pathParams = hh.getCookies();
			}
			In general @Context can be used to obtain contextual Java types related to the request or
			response.
			For form parameters it is possible to do the following:
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(MultivaluedMap<String, String> formParams) {
			// Store the message
			}
		...
		-----
		先看了注解源码说明，再依据文档。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day23 Tuesday, April 17, 2012

1. 
	* 通过 rest  的规范中的 @context 注解来取得请求参数，传递给其他函数处理
		action映射在启动时初始化好。
	* jce openapi
	接口文档里面提到的一些param 字符串需要你这边把输入参数转换为json。
		转换的内容在 com.aliyun.cloudengine.model.opeanapi 下，里面以Param结尾的类定义
		siteId是之前跟王永生约定好的，调用方的标识ID
	- com.aliyun.cloudengine.service.openapi.OpenApiFacadeService(定义在spring-base-service.xml中) 处理openapi请求
		需要将请求参数转换为json格式传递
	- 日志查询需要用到ols ？待		 * OLS
		集合jce openapi文档参考ols文档
		关于ACE OpenAPI的日志查询接口说明
			1、操作接口是query_app_log，日志类型是manipulateLog和appRunningLog 
			2、以上两种类型的日志需要通过OTS获取，其他类型的通过调用master接口获取
			3、测试环境调用地址：curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'
			4、具体的调用可参见《开放日志服务接口文档.docx》

2. maven添加jar到本地库
	mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
	from:http://blog.sina.com.cn/s/blog_4b81125f0100ifnm.html
3. maven jar包重复问题，可通过
	mvn dependency:tree 查看依赖关系。
	配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
	对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
	只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。

	若还是冲突，修改scope为provided，或者通过exclusions来处理。
4. 关于ace计量pv
	nginx_app_abstract_running_info 中的pv包含静态和动态之和； nginx_app_running_info 中的pv只为静态请求次数

5. http状态表示 ，状态常量定义 
	import org.apache.commons.httpclient.HttpStatus;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day24 Wednesday, April 18, 2012

1. 
	* jce open api
		- jce接口中的site_id就是jce请求的site_user_id ?site_id不是用户调用jce open apisite_user_id这个site_id表示阿里云，万网或是其他的id标识，可以
		   到app表取到(注意：目前取app表的user_id作为site_id,后续会废弃user_id改为app表的site_id的值)这个site_id在到openapi处理时已经附加在用户请求中了
		   参考 产品线接入Open API规范说明_v0.2
		- 由于线上cloudengine的库表结构和最新开发的库表结构可能不一致，从trunk上拿线上版本的表，再测试下 ？
			包括相关的mapping文件pojo等
		- ace计量bid定为26842，测试时用的aliyun
		- 测试oms时，可以到ace_calc_struct.xml把生成数据替换为测试数据测试
		- jce sevice接口调用参数改为传递对象方式，原为json
	* ace计量
		- 对于没有任何app的情况，跳过不处理。

2. firefox 能正确显示json格式，ie8却不能处理 ？
	即content-type = application/json时ie8不认识，不会处理。
	查看ie8支持的媒体类型：

3. 通过注解anotation配置映射信息 ,取代配置文件实现元数据配置。
	------
	...
		@Retention(RetentionPolicy.RUNTIME)
		@Target(ElementType.METHOD)
		public @interface OpenAction {
			
			String actinName();
			String[] paramNames();
			
		}	
	...
	------
4. mysql 
	不同版本统计函数返回的数据类型也是不一致的，

5. jce openapi 日志
	日志类型,manipulateLog、accessLog、jettyRunningLog、appRunningLog
		其中，manipulateLog和appRunningLog类型日志从OLS服务获取，accessLog、jettyRunningLog调用master接口获取。

	OLS测试地址：
		curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'	
		服务位置：http://ols.aliyun-inc.com
6. 测试时从类相同路径加载资源文件
	this.getClass().getResourceAsStream("JobServiceImplTest.testPushRequest.xml");
	加载资源的方法有多种，下面摘自网络小节：
			------
				Java中getResourceAsStream的用法
				首先，Java中的getResourceAsStream有以下几种： 
				1). Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从
				ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。 
				2). Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由
				ClassLoader获取资源。 
				3). ServletContext. getResourceAsStream(String path)：默认从WebAPP根目录下取资源，Tomcat下path是否以’/'开头无所谓，
				当然这和具体的容器实现有关。 
				4). Jsp下的application内置对象就是上面的ServletContext的一种实现。 
				其次，getResourceAsStream 用法大致有以下几种： 
				第一： 要加载的文件和.class文件在同一目录下，例如：com.x.y 下有类me.class ,同时有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("myfile.xml"); 
				第二：在me.class目录的子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.y.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("file/myfile.xml"); 
				第三：不在me.class目录下，也不在子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				总结一下，可能只是两种写法 
				第一：前面有 “   / ” 
				“ / ”代表了工程的根目录，例如工程名叫做myproject，“ / ”代表了myproject 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				第二：前面没有 “   / ” 
				代表当前类的目录 
				me.class.getResourceAsStream("myfile.xml"); 
				me.class.getResourceAsStream("file/myfile.xml"); 
			------

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day25 Thursday, April 19, 2012

1. 
	* jce open api
		- ols日志部分
			a. 根据jce openapi文档日志查询部分需求，设计接口及实现
			b. 使用master内处理http发送接收请求的代码与日志服务交互
				http交互公用代码
		其余action实现
2. 关于rest的response问题 -tip-
	* 在简单的测试项目中一个pojo service在暴露rest服务并做处理返回时，这个返回对象需要是rest规范定义的response的
	子类，这样rest框架处理时就能正确响应给请求者。
	* 还有一种方式，就是这个rest service继承某个类，或实现接口，其暴露的rest服务方法只返回pojo对象，处理响应交给依赖的
	类去处理
	fire: REST方法的返回对象必须是REST接口定义的Response类的子类。上面的说明还是和所使用的rest框架相关的，下面的 RESTEasy 框架
	rest服务返回的就是直接的pojo对象，框架自身回去处理把pojo构造为标准的http response返回。
3. RESTEasy  框架实现REST服务
	RESTEasy
		RESTEasy is a JBoss project that provides various frameworks to help you build RESTful Web Services and RESTful Java applications. 
	It is a fully certified and portable implementation of the JAX-RS specification. JAX-RS is a new JCP specification that provides a Java API for RESTful Web Services over the HTTP protocol.
		RESTEasy can run in any Servlet container, but tighter integration with the JBoss Application Server is also available to make the user experience nicer in that environment. 
	While JAX-RS is only a server-side specification, RESTEasy has innovated to bring JAX-RS to the client through the RESTEasy JAX-RS Client Framework. This client-side framework allows you to map outgoing HTTP requests to remote servers using JAX-RS annotations and interface proxies.

	from:http://www.jboss.org/resteasy/

	搭建 RESTEasy 测试project。
4. String.valueOf() 注意null值

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day26 Friday, April 20, 2012

1. 
	* 测试jce openapi
		- 由于运行环境不易构建，通过 mock 方式测试用例，mock出需要的条件。
			mock测试目的：测试目标类的功能时，模拟其依赖对象，关键在于测试目标类。
		- openapi把用户请求转发给jce open api前会去校验action是否存在
		- 停止APP的参数不统一？jce open api文档有的参数pojo中没有
	* 参照jce open api对比所有参数正确性 ？ 

2. jtester 可以利用其提供的反射工具类进行特殊方法(如私有方法)的测试
	JTesterReflector 通过反射执行调用测试
	提供集成测试支持(如数据库等)
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day27 Monday, April 23, 2012

1. 
	*jce openapi 
		- post请求 rest 取得post参数集合	
			结合openapi的post请求规范提供服务
		- 日志部分接口定义说明 ，返回码，格式
		- 功能增加，实现
			update OpenApiFacadeService ，svn diff with previous version ，得到新增接口方法，实现对应逻辑及单元测试。


2. rest post请求参数 , get post parameters restful -tip-
	jersey文档说明如下：
		In general @Context can be used to obtain contextual Java types related to the request or response. For form parameters it is possible to do the following:

		Example 2.19. Obtaining general map of form parameters

		@POST
		@Consumes("application/x-www-form-urlencoded")
		 public void post(MultivaluedMap<String, String> formParams) {
		     // Store the message
		 }
	参数集合，自动封装Injection 自动注入 。
		get请求通过uriinfo封装
		post请求直接通过MultivaluedMap封装

3.for test
#for test case 
slb.api.server=1
slb.api.serviceSecretKey=2
slb.api.session=3
slb.api.regionNo=4
ftp.url=1
ftp.address=2
ftp.port=3
dns.server=4

4.  调用过程
	请求处理
	资源分配
	rpc(mina)
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
		It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
	结果处理
5. quartz 属性配置文件配置跳过更新检查
	或者通过java命令的 -D参数设置
		-Dorg.terracotta.quartz.skipUpdateCheck=true
6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day28 Tuesday, April 24, 2012

1. 
	* jce openapi 内部联调
		- 测试环境openapi接入前准备
			mysql -utest -ptest
			openapi 
				配置接入参数到 服务表 和 action表
			测试地址：http://10.230.129.182:8088/open?
			jce 测试环境wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8651094
		- master的属性配置到 /src/main/conf/cemaster_env.properties 中，test下的属性只供测试调用
		- rest暴露的服务uri定位 /open 
		- wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=6094915
		- site_id master的接口实现已经做了参数验证，桥接层不需要处理，提供统一的异常提示。
			转接层不做业务相关的处理,让了解业务的逻辑去处理验证是否符合要求。模块责任清晰
			参考 struts2的自动参数注入逻辑，不匹配的置为null
	* 着手 SLB API V2 时间点 4.30
2. 测试环境 mysql
	10.250.8.214
	mysql -utest -ptest
	open api服务接入配置：
	use openapi
		service_provider
			insert into service_provider values(7,'ace','http://10.230.129.182:8088/open?','1.0','ace',now(),now());
		api
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('create_app',60,'create_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_name',60,'check_app_name',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_domain',60,'check_app_domain',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_web_container_quota',60,'set_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values(set_reverse_proxy_quota',60,'set_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_memcache_quota',60,'set_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_start_args',60,'set_app_start_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_stop_args',60,'set_app_stop_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('start_app',60,'start_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('stop_app',60,'stop_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('build_app',60,'build_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_build_job',60,'query_build_job',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app',60,'query_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_app',60,'delete_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app_topolgy',60,'query_app_topolgy',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_os_monitor',60,'query_os_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_reverse_proxy_quota',60,'query_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_web_container_quota',60,'query_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_quota',60,'query_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_info',60,'query_memcache_info',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_jvm_monitor',60,'query_jvm_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_reverse_proxy_configuration',60,'set_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('test_reverse_proxy_configuration',60,'test_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('get_reverse_proxy_configuration',60,'get_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_reverse_proxy_configuration',60,'delete_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_net_io',60,'query_net_io',1,1,7,now(),now());

			| api_id | api_name                           | timeout | description                        | status | level_id | sp_id | gmt_create          | gmt_modify          |
			+--------+------------------------------------+---------+------------------------------------+--------+----------+-------+---------------------+---------------------+
			|    289 | create_app                         |      60 | create_app                         |      1 |        1 |     7 | 2012-04-24 10:30:45 | 2012-04-24 10:30:45 |
			|    291 | check_app_name                     |      60 | check_app_name                     |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    292 | check_app_domain                   |      60 | check_app_domain                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    293 | set_web_container_quota            |      60 | set_web_container_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    294 | set_reverse_proxy_quota            |      60 | set_reverse_proxy_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    295 | set_memcache_quota                 |      60 | set_memcache_quota                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    296 | set_app_start_args                 |      60 | set_app_start_args                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    297 | set_app_stop_args                  |      60 | set_app_stop_args                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    298 | start_app                          |     600 | start_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    299 | stop_app                           |      60 | stop_app                           |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    300 | build_app                          |      60 | build_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    301 | query_build_job                    |      60 | query_build_job                    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    302 | query_app                          |      60 | query_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    303 | delete_app                         |      60 | delete_app                         |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    304 | query_app_topology                 |      60 | query_app_topolgy                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    305 | query_os_monitor                   |      60 | query_os_monitor                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    306 | query_reverse_proxy_quota          |      60 | query_reverse_proxy_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    307 | query_web_container_quota          |      60 | query_web_container_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    308 | query_memcache_quota               |      60 | query_memcache_quota               |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    309 | query_memcache_info                |      60 | query_memcache_info                |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    310 | query_jvm_monitor                  |      60 | query_jvm_monitor                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    311 | set_reverse_proxy_configuration    |      60 | set_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    312 | test_reverse_proxy_configuration   |      60 | test_reverse_proxy_configuration   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    313 | get_reverse_proxy_configuration    |      60 | get_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    314 | delete_reverse_proxy_configuration |      60 | delete_reverse_proxy_configuration |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    315 | query_net_io                       |      60 | query_net_io                       |      1 |        1 |     7 | 2012-04-24 10:31:46 | 2012-04-24 10:31:46 |
	
	文档action名称定义：
		create_app
		check_app_name
		check_app_domain
		set_web_container_quota
		set_reverse_proxy_quota
		set_memcache_quota
		set_app_start_args
		set_app_stop_args
		start_app
		stop_app
		build_app
		query_build_job
		query_app
		delete_app
		query_app_topology
		query_os_monitor
		query_reverse_proxy_quota
		query_web_container_quota
		query_memcache_quota
		query_memcache_info
		query_jvm_monitor
		set_reverse_proxy_configuration
		test_reverse_proxy_configuration
		get_reverse_proxy_configuration
		delete_reverse_proxy_configuration
		query_net_io


3. 产品线接入openapi ，诸如验证，访问控制，负载，api是否开放等等由openapi负责 ，产品线关心业务。 -tip-

4. jce openapi 测试
	测试每一个action ，测试结果以与rest接口暴露的action的返回结果一致为准。
		create_app
			domain_name 格式要求 xxxxxx.aliapp.com ，xx位置格式要求为4-18个字符
		url=http://10.230.129.78:8088/open?oauth_nonce=28587223711112&start_args=test_start_args&oauth_version=1.0&oauth_consumer_key=TestVMFhd506uBsO&app_name=testAppName1088&site_user_id=1088&oauth_signature=sZUqPtyuaPXlsRx1NVnboV0tIaw%3D%0D%0A&oauth_signature_method=HMAC-SHA1&action=create_app&app_language=2&stop_args=test_stop_args&user_id=1&domain_name=ace2012.aliapp.com&git_url=test.git.url&oauth_timestamp=1335258526
		{"data":{"appId":3},"code":200,"msg":"success"}			
	* yaml 格式配置消息 -tip-
		准备此格式配置内容
	* 

5.  SLB API V2
	* 目标
		- 接收用户请求
		- 根据请求消息，构造请求体，调用后端slb，得到结果
			需要根据request信息，查询db得到调用slb后端接口的必要参数
				region_id所属的HOUYI region id
		- 将结果状态处理下 比如 -100 转换为-2100，返回给用户
		- 实现slb后端提供的接口调用(定义的action操作)
	* check out 代码
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 阅读相关文档
	* 查看源码
		框架构成：struts2 + spring + ibatis 
			- bean交给spring管理，struts配置文件引用其名称；action定义于spring配置中 ，通过ApplicationContext的getBeansOfType(Class type)获得所有action的名称实例map
			- 请求映射通过统一的proxyaction接受，并根据请求的action，通过反射执行对应action的接口方法，得到返回结果。
			   其中的action名到对应action实例的映射关系实现通过ExecuteActionFactory初始化，这里的设计，每个action名对应一个
			    action处理类，启动时以bean names as keys and the corresponding bean instances as values初始化到map中。
			- 需要用的参数，拦截器处理好放到threadlocal实现的RequestContextHolder对象中，提供了静态方法，供service调用slb后端
			   时调用
	* SLB API
		业务


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day29 Wednesday, April 25, 2012

1. 
	* slb api v2
		- 根据上面分析，现在的任务是：
			a. 实现slb后端文档提供的操作Action类，并配置到spring配置中
			b. LoadBalancerService 加入新的功能定义，并实现
				
		- 涉及到vm的信息(比如向lb_id中加vm时) ，需要到后羿vm处去查询  ，数据库 houyi
			配置文件：slbapi.properties 
				ec.api.url=http://10.230.204.65/open/services?
		- 一些交互细节，demo等可参考v1版本的代码(houyi-console下)
			svn 地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/trunk
			如 /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/LBControlServiceImpl.java 参考其与slb后端交互逻辑。
		- slb后端的请求url从region表中获得。
		- post请求：
			注意请求内容以multipart的方式构造请求体，这样服务端接收时才能正确解析。
		- 返回码搞清楚
			对于slb后端返回的状态码，如果为负数则减去2000作为返回状态码
			如果slb api前端报错，则根据前端文档返回对应状态及msg

		- 任何异常(Exception)都指定到错误的result上去。
	* slb 测试
		测试地址：10.150.8.214
		部署
			部署结构：nginx+tomcat
			启动tomcat 
				/home/admin/slbapi/bin/tomcatctl start
			启动nginx（/home/admin/openapi/bin/nginxctl start）——若已启动，则不需要操作，只需启动tomcat即可
			
			http://10.250.8.214/slb/api?action=list_rs_pool&timestamp=2012-05-31+19%3A45%3A37&region_no=AT03-HOUYI1&session=lei.chang%40alibaba-inc.com&sign=kmEdDhkMXlIqGXxpsfwG3A%3D%3D

			查看tomcat日志，在..slbapi/.default/...tomcat-localhost-6.1xx.log
				
2. 
openapi接入的服务
mysql> select * from service_provider;
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
| sp_id | sp_name  | url                                 | version | description | gmt_create          | gmt_modify          |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
|     1 | ecs      | http://10.230.204.65/open/services? | 1.0     | ecs         | 2011-12-31 17:13:55 | 2011-12-31 17:13:55 |
|     2 | slb      | http://10.230.204.65/open/services? | 1.0     | slb         | 2012-01-10 10:21:07 | 2012-01-10 10:21:07 |
|     3 | ecs_test | http://127.0.0.1:8888/?             | 1.0     | ecs test    | 2012-01-18 17:31:33 | 2012-01-18 17:31:33 |
|     4 | boss     | http://10.230.128.5:8080/           | 1.0     | boss        | 2012-04-20 15:20:26 | 2012-04-20 15:20:26 |
|     5 | rds      | http://127.0.0.1:8888/?             | 1.0     | rds         | 2012-04-20 15:20:39 | 2012-04-20 15:20:39 |
|     6 | git      | http://ceqa-gitserver1:4567/api     | 1.0     | git         | 2012-04-23 16:42:49 | 2012-04-23 16:42:49 |
|     7 | ace      | http://10.230.129.182:8088/open?    | 1.0     | ace         | 2012-04-24 10:20:47 | 2012-04-24 10:20:47 |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
ecs - vm openapi

3. slb v2 
	测试url：http://localhost:8080/slb/api.do?action=create_loadbalancer
		 <?xml version="1.0" encoding="utf-8" ?> 
		 <rsp>
		  <code>-50</code> 
		  <msg>illegal user</msg> 
		  </rsp>


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day30 Thursday, April 26, 2012

1. 
	* slb api v2 
		* 走通一个action
			http://localhost:8080/slb/api?action=create_loadbalancer&user_id=1&session=xxx

2. maven web 项目debug ，maven tomcat debug
	修改tomcat启动脚本,远程调试：
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%  
3. 请求slb后端方式的修改
	slb后端服务是REST方式，在请求时需要满足其格式要求。
		比如除了get方式外，其他请求方式post，put，delete请求方式，都需要把请求体也放到URI中，目前采用的是 Matrix URIs  方式：
			Matrix URIs 
			Matrix spaces and Semicolons 
			It is maybe obvious to note that there are many, many hierarchical systems. An interesting analogy with a hierarchical power is, in a programming language, a sequence of parameters supplied to a command or a procedure. For example, in some languages a procedure may take positional parameters which may be optional so that any parameters from a certain point on may be omitted. This syntax can be compared with a hierarchical slash separated URL path. This is an interesting analogy because looking at the alternative representation for procedure parameters which consists of a list of procedure name and value pairs. This leads us naturally to a discussion of the use of the semi-colon in URLs and the matrix syntax. Just as the slash separated set of elements is useful for representing a tree, so a set of names and equally significant parameter can represent a space more like a (possible sparse) matrix. In this case navigation to "close" locations is done by varying one or more parameters which form the dimensions of the matrix. This is the purpose of the a=b; parts of URL syntax which was added later in the URL's history. The initial need was to put qualifiers onto URLs which were themselves hierarchical. 

			The analogy with procedure call holds still when looking at combined forms: The hierarchical part of the URL is paused first, and then the semi-colon separated qualifiers are paused as indicating positions in some matrix. As an example let's imagine the URL of an automatically generated map in which the parameters for latitude, longitude and scale are given separately. Each may be named, and each if omitted may take a default. So, for example,

				 //moremaps.com/map/color;lat=50;long=20;scale=32000

			might be the URL of an automatically generated map. 
			摘自：http://www.w3.org/DesignIssues/MatrixURIs.html
	根据上面：
			请求SLB后端时，get请求直接根据uri格式要求请求；对于有content内容(注意区别与普通post请求是放到请求体重)的请求，
		需要以Matrix URIs的方式，把请求内容放到uri中，再去请求。-tip-
	
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day31 Friday, April 27, 2012

1. 
	* SLB API v2
		- 根据slb对外api文档，将请求结果处理后依据slb后端调用文档调用，并返回结果
2. 测试
	* 创建LoadBalancer：		
		客户端请求：http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
		slb后端请求：http://10.230.130.129:8088/lbs/lbname1;lb_type=compact;region_id=region-test;eip_type=internet;user_id=1
			结果：{response={"data":{"lb_id":"25-region-test","eip":"42.120.64.227"},"code":200,"msg":"successful"}, status=200}
			struts的自定义result处理结果时报错。
				处理结果返回类型的 UserActionResult 在 response.getWriter().write(resultFormat.value(result)); 处转换对象为json或者xml时报错？
	* 查询LoadBalancer信息：
		http://10.230.130.129:8088/lbs/123/
		user_id如何传递？
	* 查询loadbalancer列表 http://10.230.130.129:8088/lbs;user_id=1
		结果：{"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","26-region-test","27-region-test","28-region-test","29-region-test","30-region-test","31-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test"]},"code":200,"msg":"successful"}



3. 
SLB API 错误码：
		2000 - 2100 -平台错误
		>2100 业务错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day32 Saturday, April 28, 2012

1. 
	* 根据slb后端文档，实现调用接口，对比前端用户api文档，修改接口实现中需要参数转换的逻辑。
	* 拿到rest服务的源码校对url请求 ？
		- 看rest服务代码，测试请求来的精确
			eg：查询lb:http://10.230.130.129:8088/lbs/43-region-test;user_id=1 这里需要将user_id传递过去，因为slb后端是根据lb_id和user_id都匹配来查询lb的
	* slb api v2 平台错误提示需要细化，比如：
		http://localhost:8080/slb/api?action=query_loadbalancer&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":-2003,"msg":"system exception"}
		http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":200,"data":{"lb_id":"43-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.215","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		第一个请求的错误，具体原因是action的名称不对，可以细化错误提示，便于调试和理解。

		错误，异常提醒细化 

2. 
	测试记录：
		创建LB: 
			compact http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"53-region-test","eip":"42.120.64.204"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
				{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
			hybrid http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=hybrid&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"60-region-test","eip":"42.120.64.238"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname2&lb_type=hybrid&eip_type=internet&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","eip":"42.120.64.226"},"msg":"successful"}
		查询LB: http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.227","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		删除LB: http://localhost:8080/slb/api?action=delete_loadbalancer&region_no=region-test&lb_id=31-region-test&&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置LB: http://localhost:8080/slb/api?action=config_loadbalancer&region_no=region-test&lb_id=25-region-test&status=active&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询LB列表：http://localhost:8080/slb/api?action=list_loadbalancers&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test","40-region-test","41-region-test","42-region-test","43-region-test","44-region-test"]},"msg":"successful"}
		
		创建VIP: 
			compact: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A80%2C%22backend_port%22%3A82%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22persistence_timeout%22%3A1000%2C%22check%22%3A{%22type%22%3A%22vtcp%22}}}%2C{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A83%2C%22status%22%3A%22inactive%22%2C%22backend_port%22%3A81%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22forwardfor%22%3A%22on%22%2C%22keepalive%22%3A%22on%22}}]&lb_id=59-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}
			http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=401-AT03-HOUYI1&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
			hy: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=62-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}		
				http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=23-region-test&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
		删除VIP: http://localhost:8080/slb/api?action=delete_vip&region_no=region-test&lb_id=25-region-test&frontend_port_list=[80,90]&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置VIP: http://localhost:8080/slb/api?action=config_vip&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询VIP: http://localhost:8080/slb/api?action=query_vip_info&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"protocol":"tcp","port":80,"status":"stopped","config":{"scheduler":"rr","check":{"type":"vtcp"},"persistence_timeout":1000}},"msg":"successful"}
		查询VIP的健康状态: http://localhost:8080/slb/api?action=query_vip_healthcheck&frontend_port=80&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"rs_list":[]},"msg":"successful"}

		添加VM: http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22vm1%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=22-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"22-region-test","vm_list":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		查询VM信息: http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"weight":100,"vm_name":"vm1"}]},"msg":"successful"}
			注：ip与vm名称是一对一，如果为一对多则会出错。依据业务为准
			http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"53-region-test","vm_list":[]},"msg":"successful"}
		删除VM: http://localhost:8080/slb/api?action=delete_vm&vm_list=[%22vm1%22]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		切换VM: http://localhost:8080/slb/api?action=switch_vm&old_vm=[%22vm1%22]&new_vm=[{%22vm_name%22:%22vm2%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
			注：与文档说明返回不一致？			
		
		// hybrid
		添加Rule: http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=59-region-test&session=accessid1&sign=xx
			{"code":-2402,"msg":"RuleNotSupport"} //compact lb 不能添加rule
			http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=60-region-test&session=accessid1&sign=xx
			hybrid:http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool2%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","rule_id":"1-region-test"},{"name":"rule2","rule_id":"2-region-test"}]},"msg":"successful"}
		配置Rule: http://localhost:8080/slb/api?action=config_rule&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}
		查询Rule: http://localhost:8080/slb/api?action=query_rule_info&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","domain":"www.xxx.com","rs_pool_name":"rspool2","rule_id":"1-region-test","scheduler":"wrr","private_header":{"key2":"value2","key1":"value1"}},{"name":"rule2","domain":"www.abc.com","rs_pool_name":"rspool2","rule_id":"2-region-test","scheduler":"wrr"}]},"msg":"successful"}
		删除Rule: http://localhost:8080/slb/api?action=delete_rule&rule_name_list=[%22rule1%22]&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}

		// compact
		添加rs pool: http://localhost:8080/slb/api?action=create_rs_pool&name=rspool1&protocol=http&port=80&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"name":"rspool1","protocol":"http","port":80},"msg":"successful"}
			http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool2&protocol=http&port=80&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"name":"rspool2","protocol":"http","port":80},"msg":"successful"}
		查询RS POOL列表: http://localhost:8080/slb/api?action=list_rs_pool&vm_name=vm2&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":-2502,"msg":"RealServerParseError"}
			http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=60-region-test&region_no=region-test&session=cao.yin&sign=xx
			{"code":-2502,"msg":"RealServerParseError"} //SLB 后端bug，待修改
		添加rs 到 rs pool: http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool1&rs_list=[{%22vm_name%22:%22vm2%22}]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool2&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		从rs pool 删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool1&rs_list=[%22vm-tes1%22,%22vm-test2%22]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
		删除rs pool:http://localhost:8080/slb/api?action=delete_rs_pool&rs_pool_name=rspool2&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":-2505,"msg":"RspoolRuleExist"} //前提 删除rs pool配置的rule
		删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool2&rs_list=[%22ceqa-ag-0419160429%22]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		切换rs: http://localhost:8080/slb/api?action=switch_rs&rs_pool_name=rspool2&old_rs=[%22ceqa-ag-0419160429%22]&new_rs=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day33 Wednesday, May 02, 2012

1. 
	* SLB API action测试
		- vm 与 ip的转换，slbapi库的rs表ip与vm是一对一还是一对多？ select * from rs; ，一对一
	* 


2.系统错误提醒设计细化
	错误码提示易定位，人性化
	从总体设计异常提示。

3. 懂业务测试效率更高，特别对于具有依赖关系逻辑的测试。
	slb api测试中，不少用例的测试都是具有依赖关系的，需要前提条件满足才能继续下一个用例的测试
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day34 Thursday, May 03, 2012

1. 
	* slb api需要和vm api交互的地方，参看 云服务器api说明4.0版本
		比如用户调用slb api传递的是vm的名称，slb api层需要将name转换为ip传给slb后端，slb后端返回的数据中将vm的ip消息转换为vm的名称。
			vm api的测试账户？key ，id
			vm_name = DotProject-4661  / ceqa-ag-0419160429
				cao.yin
				cao.yin
				ec.api.url=http://10.230.204.65/open/services?
	* 上面替换的需求，需要定义查找的key名称，可以统一到常量中，避免硬编码 ？
	* jce open api 修改action时也同时需要到open api表去修改action的名称，哪里会先处理action的正确性。
	* 在 add rs vm,delete rs vm,switch rs vm 时本地rs表的数据是否正确变化也需要测试通过？
	* 一些依赖导致的错误，比如add_rs时需要先add_vm这样在rs表里会有ip与name的对应数据，否则报错，此时应该细化这个错误提示，不都是 sysytemerror ，客户端或者
	开发者自己也不便于debug
	* rs ,vm 删除时都要去删除rs表的记录，也要查询是否有冲突？
2. slb api需要做vm ip和vm name转换的地方，对比slb后端api与slb api
	add_vm //done
	delete_vm //done
	switch_vm //done
	query_vm_info //done
	query_vip_healthcheck //done
	add_rs //done
	delete_rs //done
	switch_rs //done
	query_rs_pool_info  (list_rs_pool) //done
	delete_rs_pool //done

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day35 Friday, May 04, 2012

1. 
	* 配置slb api日志，调用日志，业务日志分开
		api调用日志记录调用前后时间，按照设计的日志格式输出。可以在拦截器中记录调用日志
	* slb api配上签名验证
		测试例子：http://localhost:8080/slb/api?sign=kxUxw8Op%2B8TsTemi6qrknQ%3D%3D&timestamp=2012-05-04%2014%3A53%3A51&session=cao.yin&action=query_loadbalancer_info&lb_id=25-region-test&region_no=region-test&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-region-test","frontend_port":[],"eip":"42.120.64.225","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day36 Monday, May 07, 2012

1. 
	* slb api日志记录在log拦截器执行 
	* 在 10.230.204.24机子上部署测试
		目录为 /home/admin/slbapi
		编译: build/build.sh
		关闭/启动tomcat: bin/tomcatctl stop/start
		eg:
			http://10.230.204.24/slb/api?sign=7kes%2FcmCqF5ofzJkpsI7rg%3D%3D&timestamp=2012-05-07%2015%3A21%3A13&session=cao.yin&lb_id=8-region-test&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":-2610,"msg":"LbIdNotExist"}
			http://10.230.204.24/slb/api?sign=pp9LAo7fjImc9ge4NoIbmg%3D%3D&timestamp=2012-05-08%2009%3A43%3A35&session=cao.yin&lb_id=25-AT03-HOUYI1&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-AT03-HOUYI1","frontend_port":[],"eip":"42.120.64.197","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
	* 日志实现改为 将各处log项存入localthread中，最后记录log时，把log对象tostring即可。
		参考 http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLogHolder.java 实现
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLog.java
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.framework/src/main/java/com/aliyun/openapi/interceptor/LogInterceptor.java
	* slb api的region_no 问题
		AT03-HOUYI1,region-test 此值从slbapi库的region_mapping表中查询得到；将客户传递来的vm region转换为slb的region，对外统一用vm的region
	* rs表操作的测试，事务一致性测试
	* slb api上线需要做的工作：

2. slb api上线需要做的工作：部署
	(1)建库，建表，表订正
		slbapi库，表有：
			region(region_no ,region_name ,url ,status) slb api的region表，表示slb 的region(区别于vm的region)
			region_mapping(region_no ,vm_region_no) slb的region与vm region的映射关系表，根据vm的region找到slb的region
			rs(vm_name ,ip) 用来做负载均衡的vm服务器的名称对应的ip映射表(用户请求的vm名称通过调用vm的api得转换为其ip调用slb后端，slb后端返回时根据此表将ip转换回vm名称，即对外只提供vm名称的操作隐藏vm的ip)
			user( user_id ,user_name ,service_secret_key ,service_access_id  ,status ,is_admin) slb用户
			lb流量接口表：（这个表会存在多个实例吗？）
				monitor_datasource slb后端提供
		配置数据源：
			- slb api库数据源配置(库slbapi)
			- slb后端业务数据数据库源配置(xuanyuan)
			- 上面的 monitor_datasource 表中配置slb后端计量数据数据库源
	(2) svn下载默认目录结构，地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api/deploy-env
	(3) 将上面目录中的 slbapi 目录cp到 /home/admin 下
	(4) 进入 slbapi 目录
		cd /home/admin/slbapi
	(5) 执行build并部署: sh build/build.sh
	(6) 启动容器: sh bin/tomcattrl start/stop

3. rs的一些操作事务一致性测试
	参看文档，那些地方需要事务保证？
	* 涉及到rs表操作的地方 ，文档中有vm_name, vm_list 相关的地方，据此查到action
		query_vip_healthcheck
		add_vm
		delete_vm
		query_vm_info
		switch_vm
		add_rs
		delete_rs
		switch_rs
		query_rs_pool_info
	* 注意： -tip- sprint事务配置 ，配置方式 + 触发回滚方式: 异常抛出，异常回滚
			spring的事务回滚下面的配置是依据异常抛出来触发回滚的，如果catch了异常，没有抛出，则事务不会回滚，这点在
		程序逻辑上要控制好，适当的抛出需要回滚的异常。
	* spring事务配置例子：
	
		<?xml version="1.0" encoding="UTF-8"?>
		<beans xmlns="http://www.springframework.org/schema/beans"
			xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
			xmlns:aop="http://www.springframework.org/schema/aop"
			xmlns:jee="http://www.springframework.org/schema/jee" 
			xmlns:tx="http://www.springframework.org/schema/tx"
			xsi:schemaLocation="http://www.springframework.org/schema/beans 
			http://www.springframework.org/schema/beans/spring-beans.xsd
			http://www.springframework.org/schema/aop 
			http://www.springframework.org/schema/aop/spring-aop.xsd
			http://www.springframework.org/schema/jee
			http://www.springframework.org/schema/jee/spring-jee-2.5.xsd
		    http://www.springframework.org/schema/tx 
		    http://www.springframework.org/schema/tx/spring-tx-2.5.xsd">
		<tx:advice id="txAdvice4Ip" transaction-manager="transactionManager">
			<tx:attributes>
				<tx:method name="get*" read-only="true" />
				<tx:method name="assign*" rollback-for="Throwable" />
				<tx:method name="release*" rollback-for="Throwable" />
				<tx:method name="modify*" rollback-for="Throwable" />
				<tx:method name="bind*" rollback-for="Throwable" />
				<tx:method name="unBind*" rollback-for="Throwable" />
			</tx:attributes>
		</tx:advice>
		<aop:config>
			<aop:pointcut
				expression="execution(* com.aliyun.houyi.service.impl.IpAddressServiceImpl.*(..))"
				id="ipAddressPointCut" />
			<aop:advisor advice-ref="txAdvice4Ip" pointcut-ref="ipAddressPointCut" />
		</aop:config>
		<aop:config>
			<aop:pointcut id="instanceStatusPointcut"
				expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
			<aop:advisor advice-ref="instanceStatusInterceptor"
				pointcut-ref="instanceStatusPointcut" order="10" />
		</aop:config>
		...
		
		spring 编程式事务：
			-------
			...
				DefaultTransactionDefinition def = new DefaultTransactionDefinition(
						TransactionDefinition.PROPAGATION_REQUIRED);// 事务定义类

				String[] results = null;
				TransactionStatus status = transactionManager.getTransaction(def);
				try
				{
					results = InstanceServiceHelper.createInstances(this.instanceDao,
							noGenerator, this.instancePassworder, instance, count);
					transactionManager.commit(status);
				} catch (DuplicateNameException e)
				{
					transactionManager.rollback(status);
					throw e;
				} catch (Throwable e)
				{
					transactionManager.rollback(status);
					throw new BizException("创建VM发生错误！", e);
				}
			...
			-------
	* 

4. rs 增加删除混乱？	
	目前是有问题的：
		比如，进行更新rs的操作
	是否每次将每个action自己的vm name 与ip关系保存到当前线程中，用好即抛弃？
	可行性：
		是否每次action查询的vm name 与ip映射都满足当前操作。根据文档分析
		会存在返回其他ip的情况

	第二种方式：
		维护vm name 与ip的表，从houyi库里取得，只做查询，更新，不修改？

	
	有个业务前提：
			rs表删除某个记录(vm name - ip address mapping)时，在slb后端已经事先删除了，即在后续查询中，除了再插入这个映射记录，
		否则后端不会返回此ip。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day37 Tuesday, May 08, 2012

1. 
	* rs 重复add操作时，会无判断插入rs表记录，需要判断下，已有的话就跳过记录插入操作。
	* delete_rs_pool 操作如果poo不存在，返回什么？文档需要定义此返回值，现根据slb后端返回来处理 ，先后端也没定义，只是返回 systembusy 
	* slb backend文档修改 ，查看
	* 目前对action的参数合法性没有进行验证，直接调用了slb后端？
		需要实现 ActionValidator 接口，对每个action的参数验证，
		slb api 具有自己的错误码和msg ，还是依赖slb后端的错误码，只是桥接？
		slb后端也会进行验证，可参考


2. rs重复操作测试例子：
	删除没有执行成功，slb后端不是按照json格式解析rslist字段，只返回当前的rs配置。slb后端修改

	http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
	{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool3&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool3","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"} // 返回值为更新后的rs列表。如果传入列表中有已经添加的rs，直接忽略，不会报错
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}

	一个vm对应在多个rs pool中，此时在某个pool中删除这个vm，另一个pool的vm返回正确吗？
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool4&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool4","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool4&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool4","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	再执行一次：
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2100,"msg":"SystemError"} //后端对不存在的rs直接忽略，返回最新的rs列表

	http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2003,"msg":"system exception"}
3. action validator


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day38 Wednesday, May 09, 2012

1. 
	* action 的业务参数验证，由于slb后端会做业务参数验证，slb api不做验证
		如果要对每个action做各自的验证，可以在设计action时，提供公用方法通过spring IOC注入自己的validator，此时验证在执行action前操作；
		或者在拦截器层处理，可以在拦截器的上配置action名称对应的validator类。
	* slb api 文档与slb 后端文档在返回码参数定义上一致修正；compact，hybird文档独立
	* rs表在多个rs pool上都有同一个vm时，执行某个pool上删除此vm，导致其他pool再删除此vm时，ip映射不到name，
		解决：细化rs表，加入rs_pool_name ,lb_id分别用于rs操作和vm操作的ip映射,一标识各自的映射数据
			alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
			alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	* 单元测试 ,slb 后端调用加上单元测试
		在有改动时，便于发现问题 ，对于易变部分的逻辑更能体现其作用 ~
	* bug id #41
		由于cacheManage为null导致错误，系统用到cacheManage的地方暂不用。
		搜素整个project，处理
2. alter table
	修改表字段定义：
		sql server:
			alter table table_name alter column column_name varchar(200)
		mysql:
			alter table table_name modify column column_name varchar(100) 

	-- alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
	-- alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	-- alter table rs add id int(10) unsigned NOT NULL COMMENT '@desc id'
	-- alter table rs add vm_name varchar(32) NOT NULL COMMENT '@desc vm name'

	-- delete from rs;

	-- alter table rs modify column rs_pool_name varchar(100) COMMENT '@desc rs pool name'
	-- alter table rs modify column lb_id varchar(32) COMMENT '@desc lb_id'

	修改主键
	-- alter table rs drop column vm_name
	-- alter table rs add id int(10) unsigned NOT NULL AUTO_INCREMENT primary key COMMENT '@desc id'
	
3. remote debug跳不过去，地址不是同一地址 ~~~


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day39 Thursday, May 10, 2012

1.
	* 单元测试补充
		junit
			mock
			数据库测试
			执行顺序
	* 文档修改查看
2. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day40 Friday, May 11, 2012

1. 
	* create_vip
		delete_vip 后端参数名称修改：frontend_port 改为 frontend_port_list
	delete_vm文档定义需要修改 ，address参数不需要，weight不需要？

2. linux系统不同权限账户操作同一目录时注意，可以对导致其他用户不能访问，权限高账户创建的内容，导致任务失败。
比如root创建了某个文件，其他没权限的账户就不能删除，导致文件没有更新。-tip-
	例子：
		root账户编译部署了web应用，换个admin账户去做同样操作时，root创建的文件不能被更新。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day41 Monday, May 14, 2012

1. 
	* 大region了解
		数据中心随着业务增长，当前region不能放入更多vm，需要跨region，但逻辑上他们还是属于同一region，这样上层下发规则时，能对应到同region的vm。
		当前解决方式，把region规则上提到api层，在这层统一region。
	* houyi api 在vm迁移时需要刷新cache中的region信息以映射到新的region，在region定位接口，提供清楚指定资源的cache接口。 clear_cache

		缓存：AbstractResourceLocator 类的 resourceRegionCache 方法 (定位用)

		com.aliyun.houyi.service.ResourceLocator
			DefaultResourceLocator 和 AbstractResourceLocator中实现(/houyi-console-service)
			然后添加一个action(包位置：com.aliyun.houyi.openapi.control.vm)，并配置(/houyi-console-openapi):在spring里配置action这个bean，至于action请求映射配置由于用了
			代理方式依据配置bean的name来执行，故不用再到struts.xml中配置(只配置一个代理的访问入口)。
		action bean名为clear_cache
		需要定义接口说明，传递参数，返回值，状态码说明等。
			参考houyi api文档
			cache_key: vm名称
			cache_type:instance,ip,.. 要删除的cache实例类型，目前有instance,ip_segment,group,ip_address四种类型，默认为instance类型

			ClearCacheErrorMessage
			状态码可复用已有的比如vm中的vm_name验证状态码：VmErrorMessage
				-200	vm name must set	没有指定VM的名称
				-205	vm not exists	待操作的VM 不存在
			对于cache type需要另外定义：
				-283 cache类型不存在
				-284 清除cache失败
			resourceNO根据不同的cache类型对应不同的值，需要处理。
2. open jce bug fix 
	pojo属性拷贝错位。
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (RestOpenApiService.java:76) - JCE OpenAPI called , paramsMap={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]} siteId=wwg
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (OpenApplicatonControllerImpl.java:95) - set App Start Args is called. params={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]}
	2012-05-11 22:55:13,937   INFO [1700182798@qtp-980075617-11] (OpenApiFacadeServiceImpl.java:225) - openapi called. action: setAppStartArgs, siteId: wwg, params: com.aliyun.cloudengine.openapi.model.SetAppStartArgsParamExt@28e2b1e1[appId=66,startArgs=66]

3. vm api 测试地址
	http://10.230.204.65/open/services
	签名 ，vm name和slb一致

	例子：http://10.230.204.65/open/services?sign=gMnnRDw0%2FIu05Yr9NpM0SA%3D%3D&timestamp=2012-05-14%2020%3A41%3A56&cache_type=instance&session=cao.yin&cache_key=AT03-HOUYI1&action=clear_cache&format=json
		{"code":-284,"data":null,"msg":"cache of this key not exist"}
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day42 Tuesday, May 15, 2012

1. 
	* slb api 加入流量查询接口2个，参考v1的文档：
		指定时间段查询负载均衡流量 query_loadbalancer_flow
		指定时间段批量获取负载均衡流量 list_loadbalancer_flows
		从数据库获取，参考v1版本，不需要调用slb后端

	* jce open api api表修改配置错误，并检查其他配置是否有误
	* slb 后端文档修改：
		- 查询vm接口删除，把其原先返回内容放到查询loadbalance信息接口的返回结果中
		- 查询rs信息接口删除，同时修改了查询rs pool信息的uri

2. lb流量查询的数据源
	是否和slb open api的库一致，还是需要再配个数据源？需要配置到数据库中，每个slb都有一个库；和操作slb后端api地址一样，每个slb是不同的地址。
	先根据基本datasource配置（维护monitor_datasource表(需要订正维护)，和rs表同在一个库中），取得所有region的datasource配置，然后动态返回对应region_no的数据源(slb后端的数据源)。

	* 验证上面到slb后端取数据的sql字段是否与slb后端的表结构一致，参考slb后端数据库表。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day43 Wednesday, May 16, 2012

1. 
	* slb api
		- 流量接口sql与后端表核对
		- 从slb后端得到region的数据源地址配置，并配置到monitor_datasource表中
			10.230.130.1 root/654123 xuanyuan_monitor
			insert  into monitor_datasource 
				(url,username,passwd,region_no) 
			values('jdbc:mysql://10.230.130.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8','root','654123','AT03-HOUYI1')
		- api文档修改
		- regionno从vm转为lb的region
	* slb api部署 day36

2. lb region ，slb api这层的region概念
	lb region在slbapi库region表里管理

3. 测试新加入的lb流量接口
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+10%3a10%3a10&end_time=2012-05-06+12%3a10%3a10&lb_id=31-region-test&&session=cao.yin&sign=xx

4. sql 对照
	LBMonitor.queryL4Flow —— vip_stats_xxx
	LBMonitor.queryL7Flow —— haproxy_rule_stats_xxx
	LBMonitor.loadBalancerCount —— loadbalancer
	
	lb_id 改为 lb_global_id
	
	loadbalancer 表在哪里?
	
5. tomcat报错一例，uri参数格式错误
	invalid chunk starting at byte
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&=4
6. jdbc url 过个空格 ，报错 
	Cannot create JDBC driver of class 'com.mysql.jdbc.Driver' for connect URL ' jdbc:mysql://10.230.130
	.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8'
	java.sql.SQLException: No suitable driver

	一个简单问题，复杂了太多，源于告知 No suitable driver == 驱动没找对 ，忽略了 url错误也是报这个错 ，汗
	+无语

6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day44 Thursday, May 17, 2012

1. 
	* 测试
	* slb后端分计量数据的库 和 业务数据的库
		即在LB流量接口的查询中，用到这两个库
			业务库配置：
				mysql -uroot -p654123 -h10.230.130.129 xuanyuan

		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；

	* lb后端创建lb时，去掉name参数，api需要做相应修改，api文档修改
	* 了解大region需求

	* vm api 之前实现了清除cache的action，现在需要确认是否也能把预加载的region去掉？
		houyi-console-openapi
		
2. 
	select sum(in_bytes) as tcp_internet_rx,lb_global_id      
	from  `vip_stats_20120506`      
	where lb_global_id='57-tr' 
	and user_id=235 
	and (gmt_create between '2012-05-06 05:10:10' and '2012-05-06 12:10:10')        
	group by lb_global_id

	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"tcp_internet_bandwidth":0,"http_internet_rx":0,"end_time":"2012-05-06 23:10:10","http_internet_bandwidth":0,"tcp_internet_tx":0,"lb_id":"83-tr","start_time":"2012-05-06 05:10:10","http_internet_tx":0,"tcp_internet_rx":477},"msg":"successful"}

	http://localhost:8080/slb/api?action=list_loadbalancer_flows&page_no=1&page_size=10&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"total":32,"page_size":10,"end_time":"2012-05-06 23:10:10","start_time":"2012-05-06 05:10:10","page_no":1,"loadbalancers":[{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"1","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"2","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"3","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"4","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"5","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"6","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"7","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"8","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"9","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"10","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0}]},"msg":"successful"}

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day45 Friday, May 18, 2012

1. 
	* slb api cache region启用修改
		bug 41 继续报错

	* houyi防火墙规则了解，大region相关业务点熟悉
	* slb后端api user_id必选，rs_type参数名改为mode ，对api这层做相应调整(代码+文档)

2. 虚拟化
	防火墙规则



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day46 Monday, May 21, 2012
1. 
	* vm 内部接口文档整理
	* 大region设计预查看
		对比加入大region前后 vm api流程操作的区别，比如 create_img，原来逻辑哪里需要修改？预分析
		首先要了解原来的流程

	* vm region cache 清除接口是否需要做操作控制？
		属于某个用户的vm的缓存自己能清除，否则某个用户可以把别的缓存清除。再或者只留给内部调用，不需要控制。
	* slb后端文档修改，slb api文档也做相应修改：健康检查查询接口frontend_port必选之后，url也应相应变化
	* 

2. 新浪云计算(关于配额系统，系统稳定摘取)：sina app engine
		日志和统计中心：负责对用户所使用的所有服务进行统计和资源计费，并设定的分钟配额，来判定是否有非正常的使用。
	分钟配额描述了资源消耗的速度，当资源消耗的速度到达一个预警阈值时，SAE通知系统会提前向用户发出一个警告，提醒用
	户应用在某个服务上的使用可能存在问题，需要介入关注或处理，配额系统是SAE用来保证整个平台稳定的措施之一；日志中心
	负责将用户所有服务的日志汇总并备份，并提供检索查询服务。

	配额细化到每个调用者(用户)，以保证稳定持久的服务。

3. 消息中间件 MQ
	云服务器api
	/houyi-console-message

	<dependency>
		<groupId>com.rabbitmq</groupId>
		<artifactId>amqp-client</artifactId>
	</dependency>

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day47 Tuesday, May 22, 2012

1. 
	* big region 分3此迭代开发(测试尽早介入)  —— 具体见邮件
		对开发部分，做设计文档说明(程序流程，控制)，便于测试
		对于设计文档：
			- 参考已有文档说明及程序实现
		数据库：
			xuanyuan
	* big region 需求评审会议
		处理开发迭代1/3涉及的接口修改。
	* big region
		项目管理页面：http://redmine.aliyun-inc.com/projects/vm wb_shen.chengs 域密码
	* slb v2换build，此次改动较大，请前端注意查看最新的文档
		1) rs_type->mode; 2) 去掉rule_name(待修改文档？)
		
2. 业务
	云服务器 产品 - 通过api操作操作云服务器
	ACE云引擎产品 - 目前包含php,node.js,java(JCE)应用环境，基于云服务器产品之上

3.迭代一修改的地方列表如下：
	背景信息
	
	* cluster_id
			之前用户传入小region，以给api查找region；现在用户传入大region，api需要定位到小region，通过用户传入的cluster_id
		在zone表里找到对应的region_no。
			api操作需要定位到region，然后执行操作。

	* API 数据库在zone表增加cluster_id的初始化，记录每个zone_no对应的cluster_id。
		device_no改成：cluster_id-device_no；
		snapshot_id改成：cluster_id-device_no-snapshot_id；
		nc_id改成：cluster_id-nc_id
	* action的执行从AbstractExecuteAction的doExecute()方法开始，具体实现由子类action的execute方法处理。
		
	- snapshotid等格式设计(API)
	- add_disk时解析并拆分用户传入的snapshot_id
		处理请求的snapshot_id和响应结果中的device_no
		cluster_id由用户传递过来，那个地方需要用到？
		AddDiskExecuteAction

	- 查询VM设备接口，返回的device_no格式变成cluster_id-device_no
		query_vm_device
		QueryVmDeviceExecuteAction

	- 创建snapshot接口，解析并拆分传递的device_no参数
		CreateSnapshotExecuteAction
	- 取消创建snapshot接口，解析并拆分传递的snapshot_id参数
		CancelCreateSnapshotExecuteAction

	- 查询设备已有的快照接口(list_snapshot)，解析并拆分传递的device_no参数，并修改返回值中snapshot_id的格式
		ListSnapshotExecuteAction
	- 查询快照详情接口，解析并拆分传递的snapshot_id参数，并修改返回值中snapshot_id格式
		DetailSnapshotExecuteAction
	- 删除快照接口，解析并拆分传递的snapshot_id,device_no参数
		RemoveSnapshotExecuteAction
	- 回滚快照接口，解析并拆分传递的snapshot_id,device_no参数
		RollbackSnapshotExecuteAction
	- 保留快照接口，解析并拆分传递的snapshot_id,device_no参数
		RetainSnapshotExecuteAction
	- 查看已挂载的快照接口(list_mounted_snapshot),修改返回值中device_no格式
		ListMountedSnapshotExecuteAction
	- 挂载快照接口(mount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		MountSnapshotExecuteAction
	- 卸载快照接口(unmount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		UnmountSnapshotExecuteAction
	- 在线迁移接口( live_migrate_vm),解析并拆分传递的nc_id参数
		VmLiveMigrateExecuteAction
	- 故障迁移接口，解析并拆分参数destination_nc,destination_rack，并修改返回值中nc_id格式
		recover_vm
		VmRecoverExecuteAction
		
	- 查询可切换的nc接口，修改返回值中nc_id格式
		QueryAvaliableNcsExecuteAction
	- 查询nc详情(detail_nc)接口，解析并拆分传递的nc_id参数，并修改返回值中nc_id格式
		到houyi-openapi.xml找对应关系
		SingleNcResourceAction
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day48 Wednesday, May 23, 2012

1. 
	* big region需求分解，要做哪些工作？
		- 拦截器处理region时，根据： cluster_id-device_no； cluster_id-device_no-snapshot_id； cluster_id-nc_id
		   得到cluster_id，再到zone表查询得到region_no,再到region表得到小region信息(对外大region，内部暂还是小region)。
		- 设计文档

	* slb后端文档修改：
		create_rule: rule_list中去掉rule_name字段
			相关的delete_rule的修改：
				去掉原来的rule_name_list 改为 domain_list
			query_rule_info文档说明修改
		config_rule: domain由可选改为必选

		open api文档需要做相应修改
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day49 Thursday, May 24, 2012

1. 
	* 继续迭代1文档及action流程整理


2. select * from `group`
group是mysql的关键词

3. visio描述简单流程图


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day50 Friday, May 25, 2012

1. 
	* 文档整理，今天整理结束
		文档根据项目模板文档要求修改
	* uml seq图流程基本类似，修改相应地方即可
	* slb后端 待？
	昨天跟aliyun.com的同事讨论之后，对query_healthcheck这个接口做了比较大的调整。已经提交了。你们注意相应的修改。
	另外 之前讨论所提到的“将一个rs从slb中删除”的接口(release_rs)，一直漏了，今天也添加到文档中了。
2. 业务关键点 理解 大region
	add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过snapshot_id得到其所属的region，然后进行相应操作

	这也是大region需要参数修改，参数如是修改的目的。-tip-

	大region需求分析：
		小region时,open api根据用户传入的资源（region_no）来定位region信息，后续的操作都是在此小region内执行的，即不跨region调用。
		随着业务增长，小region已不能满足业务上需要容纳更多的vm的需求，现需要在open api层实现跨region调用，这样对外就是一个大region，
	open api下一层还是小region结构。
		由上面跨region调用的需求结合内部是小region实现，现通过修改接口参数（在参数上携带cluster_id）以便open api通过请求参数定位资源
	所在的region，从而完成跨region操作。（比如：add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过
	snapshot_id得到其所属的region，然后进行相应操作），同时对应返回结果也做相应调整。


3. houyi open api部分在内部文档，或者过期文档中
	比如：list_mounted_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Monday, May 28, 2012

1. 
	* big region 参数修改文档再修订，加入4个接口修改说明
		修改文档
	* slb release_rs接口实现包含测试用例，并修改相应文档
	* meeting，修改文档
	
2. 添加4个接口
	解析并拆分创建VM（create_vm）接口用户传入的nc_id和rack_id参数
		
	解析并组装list_vm_status接口返回的nc_id
		
	解析并组装detail_vm接口返回的rack_id，nc_id
		
	解析并拆分调用remove_disk接口用户传入的device_no参数
		
		
3. spring 编程式事务

4. 业务 概念 清晰
	VM	Virtual Machine	虚拟机	通过物理服务器，采用虚拟化技术虚拟出来的计算机
	RS	Real server	后端服务器	用来做负载均衡的VM服务器

	2个对比，理解rs即用于slb的vm，实际就是vm。
	
	add_rs即添加一个vm作为slb负载均衡用~ 
	release_rs即在负载均衡集群中去掉一台vm（这里的去掉应该就是删除vm自身，具体看下面说明）

	delete_rs是从rspool删除rs，release rs是前端删掉一台vm后，清掉所有与他相关的slb配置，
	包括rspool里的rs，也包括loadbalancer里的vm
	
	zone属于某个region，是多对一的关系，cluster_id和region_no是一对一

	houyi api部分涉及权限的操作是在zone内进行的，即不跨zone，比如：迁移，

5. NIO
	解决同步IO资源耗尽问题 ，open api 等场景部分优化
	消息
	并发处理
	阻塞操作
	http://www.cnblogs.com/phoebus0501/archive/2010/12/05/1897245.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Tuesday, May 29, 2012

1. 
	* 在处理参数时，注意新老存储的调用兼容性 ，比如老存储的api调用是没有snapshot_id参数的，如果解析抽象出来要
	考虑到这个情况。
	
2. 
	几个概念
		cluster	一个集群
		rack		机架
		region	数据中心	代表一个数据中心或者Houyi集群，不同数据中心的VM不能相互访问
		zone		安全域		代表一个安全域，不同安全域的VM不能进行数据迁移
		group	安全组		VM相关的安全组，一个VM一定属于某个安全控制组

	之间的关系理清楚？
		* 一个cluster对应一个region(小region)，多个region对外统一为一个大region
		* region和zone是一对多的关系？zone是网络用的概念，一个region下有多个zone，zone和cluster_id是一对一关系
		* region与group是一对多关系 ( group表中有region_no,user_id字段)
		* 从user层面看，user_id与group是一对多关系，某个user_id的group可以跨region
			目前，权限是对group授权(后面再加上到vm的授权)，
			授权源group的某个端口可以在公网(或者私网)网口通过某种协议访问目标group的某个端口的规则(accept，drop，reject)。
		* 
	tip：
		可以从库表中反应它们间一定的关系 :)
	
	api层只有region的概念，houyi后端有cluster_id概念？
	
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day52 Wednesday, May 30, 2012

1. 
	* 基于参数修改设计文档，设计逻辑实现：
		- 对于组合参数的解析，提供静态一个工具类方法，传入参数值和预知的组合个数，返回参数值依据“-”分割
			 后的结果数组
		- 封装一个service用于查询从cluster_id得到region_no
		- 返回值的处理封装：在action层统一处理，实现方式：
			在action的父类里实现，提供一个公用的方法处理。
		- 尽量避免不必要的网络交互（eg：访问数据库，访问网络上的其他service服务）
		- 
	* 整理houyi open api定位到region的规则
			现有2个api，北京那边api（不升级），杭州这边api（要升级），准备在2个api之上，用一个类似路由程序来统一接受访问api的请求，
		并根据预定规则，将请求转发给老api或者新api，故需要整理这个路由的规则，让其能判断某个请求是到老api还是新api的？
			新老版本如何共享一个DB？
				有没有表操作冲突，看数据库的改动。
			规则分析如下：
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				可供识别的条件有：（类似RegionAwareIntercept定位region的逻辑）
					- 首先根据所查询的资源(open api库)
						1) vm_name - 根据vm_name查询instance表
							select
								d.instance_id,d.instance_no,d.image_id,d.status,d.status_comment,d.ip_address,d.group_id,d.node_id,d.mount_type,d.type_id,d.usage_type,
								d.user_id,d.kernel_id,d.ramdisk_id,d.platform,d.passwd,d.start_to_passwd,d.gmt_modified,d.gmt_create,d.remark,d.zone_id,d.vlan_no,d.region_no,
								d.group_no,d.bps,d.rx,d.tx,d.rx_pub,d.tx_pub,d.cores,d.mem,d.disk,d.image_device_no,d.recoverable,d.ballon_enable,d.recover_policy,d.rack_id,d.safety_quota,d.intensive_io,
								d.hostname,d.intensive_cpu,d.intensive_net,a.image_no,a.image_name,a.location as image_location,a.version as image_version,a.services_sign as image_servicesSign,
								a.image_size,a.base_image_id,a.snapshot_id,a.sys_driver,a.region_no as image_region_no,a.iso_id as iso_id,b.image_no as kernel_no,b.image_name as kernel_name,b.location as kernel_location,c.image_no as ramdisk_no,c.image_name as ramdisk_name,
								c.location as ramdisk_location,k.key_pair_id,k.key_pair_name,k.public_key,d.nc_id,d.machine_no,d.machine_no,d.is_balloon,d.is_migrate,d.is_upgrade,d.startup_mode
							from instance d
							left outer join image a on d.image_id=a.image_id
							left outer join image b on d.kernel_id=b.image_id
							left outer join image c on d.ramdisk_id=c.image_id 
							left outer join key_pair k on d.key_pair_id=k.key_pair_id 
							where d.instance_no=#value#
							?instance_no不是region_no

						2)  ip - 根据ip查询zone_ip表得出ip所在的段的记录，从而得到其所属region
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #value# and ip_end >= #value#
							limit 1

						3)  group_no  根据group_no,user_id,region_no查询group表（由于需要region_no，故此资源的操作可被region_no代替）
							select 
								group_id,
								group_no,
								user_id,
								description,
								region_no 
							from `group` 
							where user_id=#userId# and group_no=#groupNo# and region_no=#regionNo#
							order by region_no,group_no desc

						4)  ip_segment 根据CIDR地址ip地址查询zone_ip表
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #ipBegin# and ip_end >= #ipEnd#
							limit 1
							结果例子：
								| zone_id       | region_no   | zone_ip_segment | ip_begin  | ip_end    |
								+---------------+-------------+-----------------+-----------+-----------+
								| region-test-a | region-test | 10.249.130.0/24 | 184123904 | 184124159 
					- 根据用户请求参数region_no
						region_no - 根据region_no查询
					- 根据调用者（user）
						比如query_region接口只能通过user信息定位region，user信息可以根据session参数查询houyi open api数据库得到
						但是，用户会在北京region和杭州region都有vm吗？

					上面，只是得到了用户所要请求的是那个region，还需要判断这个region是老api的，还是新api的？
						背景：
							原来api只有一个入口一个版本，现在api会有2个入口且版本不一致但DB公用；路由层需要一个映射——根据region转发请求到相应的api。

						是不是需要维护一张region和api地址的映射表，路由根据region_no从此表找到转发地址？

						
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				还要考虑到用户传错参数的情况
				
				结果：
					优先根据region_no定位老api（北京）还是新api（杭州）
					再根据vm_name
					最后根据user所在的region

					要维护region和其对应的是老api，还是新api类型的映射关系表，不然只能到各自数据中心的region表查询是否存在，目前只部署一个点，
					故可以从唯一的库中查询。

2. 对于修改设计的实现设计部分细节分析
	* 返回值修改
			现有逻辑，已有一个从后端调用结果到api结果pojo对象转换的逻辑(在action层中，有的是map方式转，格局返回类型不同转换方式各异)，
		可以考虑在后端数据类型转换为api pojo时，进行我们需要的参数修改需求。eg: SnapshotApi
			现在，在那个位置统一处理好？影响小，透明化，易理解，好维护
				- 现定义在返回执行统一转换
				- 被转换的源类型包含多种(map,list,其他)
					通过方法多态，提供通用几种类型的方法，对于参数个数不一致，通过可变长参数实现
					xxx(String... args)
				- 被转换参数一个或者多个

			
3. houyi open api常量类设计分析
		对于一些常量，状态值的设计定义，减少硬编码：通过枚举定义一些常量，或者一组状态；通过一个接口定义枚举
	基本机构。
		* 枚举定义一些基本常量 eg: InstanceStatus定义vm的状态（待启动，启动中，运行中等）
		* 如果在上面基础上需要组合一组常量，为一个状态，通过往枚举的构造总放入数组即可
			eg: InstanceStatusSet定义vm可启动状态集合（包含：待启动，启动失败，已停止3个状态）

4. api操作权限控制 acl	
	通过注解设置service操作权限，再通过在spring里配置此注解到pointcut，拦截操作，判断权限
	
	spring + annotation + aop 实现权限与业务分离，注解配置权限点，通过aop拦截包含这些注解的方法的执行，校验权限，继续执行。
	被操作的对象（比如instance）有属性InstanceStatus（instance状态常量定义枚举）标记其状态，拦截器判断被操作的instance是否在允许的
	状态中，以判断操作是否可进行（比如mount_disk操作，instance只能在特定的状态下）。

	key words: expression="@annotation(
	
	<bean id="resourceQueryFacade" class="com.aliyun.houyi.acl.ResourceQueryFacade"/>
	
	<bean id="resourceSurveyor" class="com.aliyun.houyi.acl.ResourceSurveyor">
    		<property name="resourceQueryFacade" ref="resourceQueryFacade"></property>
	</bean>

	<bean id="instanceStatusInterceptor" class="com.aliyun.houyi.service.rule.InstanceStatusInterceptor">
		<property name="resourceSurveyor" ref="resourceSurveyor"/>
	</bean>

	<aop:config>
		<aop:pointcut id="instanceStatusPointcut"
			expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
		<aop:advisor advice-ref="instanceStatusInterceptor"
			pointcut-ref="instanceStatusPointcut" order="10" />
	</aop:config>	
	
	参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day53 Thursday, May 31, 2012

1. 
	* region定位规则，并细化步骤，便于路由部分参考
		实现可以不一样，逻辑基本一致。
	* 除了db公用冲突分析外，是否还有其他地方需要考虑？
		考虑大region关于open api的需求还有那些地方可能会影响？
			迭代2,3需要评估
	* 后端mock：
		调用houyi后端的mock实现。
		对 ApsaraCommandExecutor 进行mock
			保证传递进去的参数是正确的，mock出预期的返回，便于测试。
	* 迭代2

	* slb release_rs接口url及参数名称修改 done
	
2. 
	分析迭代2部分需求：
			原来的概念，上了大region都会改变，比如原来查询某个region下某个zone中的vlan信息，大region后
		要查询的就是这个用户在大数据中心所有的zone下的vlan信息。
	

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day54 Friday, June 01, 2012

1. 
	* 迭代1新增需求分析
		1）不停机升级云服务器配置，重启生效	API对modify_vm接口操作的VM前置状态增加running条件 1
		2）SLB的L4 VIP不能配置健康检查的问题 1
		3）因为machine_no（随机字段）这个值存在重复性，启用新的算法(类似于UUID类的算法)，保证生成的machine_no是不会重复的 2
		4）支持动态添加新region信息，不需要重启 1  动态添加新region信息
			是否有添加region这个接口？
				houyi.region表是手动插入记录
				没有这个接口，需要设计方案；RegionValuesFactory里的region缓存，如何在region表手动插入记录时，更新RegionValuesFactory里region
				缓存？
					a. 定时刷新
					b. 缓存找不到就去数据库找，若找到则加入缓存，找不到则返回相应的结果。




	* 迭代2需求，各接口流程梳理
	* 查询slb后端业务表的数据源，可能有多个的情况，配置在数据库中，根据不同的slb region调用不同的数据源。？待
2. 
	slb 测试环境：
		
		mysql
			mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi

	http://workflow.it.alibaba-inc.com/StartWorkflow.ashx?wfid=dfdd6d75-e539-4cb6-a289-a01eaaa5b426
	服务类型，新开令牌；需求权限，内网默认权限

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day55 Monday, June 04, 2012

1. 
	* 迭代1新增需求分析 见day54第1条
		详见迭代一新增需求文档（doc）
	* 将分支：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_btc_migrate/中clear_cache接口代码加到分支	
	   http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_update_struts上。
		拉api_update_struts的代码，并更新上clear_cache接口
	* slb后端会部署多个slb，每个slb对应一个计量库，一个业务库； 参考day42 slb 流量
		一个slb对应多个vm，每个vm可能位于不同的region。
		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；
		？
		monitor_datasource表，就是保存了每个slb，其region_no对应的取流量数据库的地址映射。
			monitor_datasource的region_no指的是slb的region，不能和vm的混淆；region表里都是slb的信息，唯一vm和slb region有关系的就是region_mapping表，表示了vm region和slb
			region的映射。

		参考解决方案：
			1）在monitor_datasource表加个type字段，用以标识slb后端数据库类型（0-业务库；1-计量库）；在LBMonitorSqlMapTemplateFactory里，
			     初始化slb region对应的2个库的sqlmapclient实例。
			2）slb后端提供查询接口，这样传入user_id，分页参数即可（region表定义了到那个url上去取数据）
	* slb open api bugfix
		delete_loadbalance 接口，同时清除LoadBalancer相关的配置——对应open api层也要清理rs表。

2. redmine 任务列表
	拉分支 ：
	【代码SVN路径】
		houyi-api: http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_big_region
		控制系统：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/houyi/branches/ec_big_region
	
	list_vlan 第三周期？

3. cache不便于查找 缓存方案 cache方案
	RegionValuesFactory - CachedRegionValuesFactory 
	region 缓存

	如果系统有多处需要使用cache，可以考虑使用一种cache框架，统一cache使用方案。-tip-
		参考：http://www.cnblogs.com/ieage/archive/2012/05/20/2509454.html

4. maven 跳过test ？
	No goals needed for project - skipping


5. LB,RS,RS_POOL,VIP之间什么关系？待
	从delete_loadbalance接口需要删除那些相关东西入手
	
	看下面query_rs_ pool_info的结果截取：
		{
		"name":"testpool1",
		"protocol":"http",
		"port":80,
		"vips":[{"lb_id":"1377236b076-region1","frontend_port":80,"rules":["www.wqwqwq2.com","www.wqwqwq1.com","www.wqwqwq3.com"]}],
		"realservers":[{"address":"192.168.1.28","weight":100}]
		}
	一个rs pool对应多个vip，多个rs
	删除LB,是否也删除rs_pool？不用，rs pool为用户自己管理
	删除rs pool时，需要删除rs。
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day56 Tuesday, June 05, 2012

1. 
	* 迭代一开发 开始
	* slb open api bugfix
		表修改：
			alter table rs modify column vm_name varchar(50);
			alter table rs modify column ip varchar(15);
			alter table rs modify column lb_id varchar(110);
	
2. 迭代一开发记录
	结果处理：
		操作成功才需要修改返回内容，操作失败时，只返回错误码和状态，没有结果。
	返回码修改：
		由于参数格式修改，需要修改部分返回码的错误提示。
	结合jtester框架测试
		service层mock后端执行的返回值：mock后端返回值
			后端返回格式，参考每个command里的代码，比如：CreateSnapshotCommand ，这些命令都继承自 AbstractCommand
	service层的测试，对于内部私有类，可以通过替sprintg配置来实现mock。
		如果mock返回的类型不是预期，可以考虑让mock类实现相应的接口。
	测试环境
		测试依赖的配置文件，有一部分在用户目录下，需要在spring配置文件中配置正确。

	- 4.2	查询VM的设备接口（query_vm_device）
		* /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/InstanceServiceImpl.java
			queryDevice方法修改
		* zonedaoimpl
		* ZoneDaoImplTest
			jtester测试通过
		* zoneservice / zoneserviceimpl
		* /houyi-console-model/src/main/java/com/aliyun/houyi/entity/Zone.java 加上clusterId属性
		* zone表加cluster_id字段【sql 修改】
			alter table zone add cluster_id varchar(32) NOT NULL;
		* /houyi-console-util/src/main/java/com/aliyun/houyi/util/ResultParseUtil.java 工具类 ，处理返回值装配
		* QueryVmDeviceExecuteAction
			取得cluster_id，修改返回值
			待测
				dao
				service
				action
				util工具类
					单元测试通过
	- 4.3	磁盘创建snapshot接口（create_snapshot）
		* 修改错误码：
			SnapshotErrorMessage
			DEVICE_IS_NULL(-900, "device No. is null"), ——》 改为：DEVICE_IS_NOT_ILLEGAL(-900, "device No. is not illegal"),
		* CreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"), DOC
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		* 修改错误码：
			SNAPSHOT_IS_NULL(-920, "snapshot is null"), ——》改为： SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"),
		* CancelCreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
	- 4.1	add_disk接口
		* AddDiskExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
		

3. maven 跨项目test
	独自测试依赖问题？

4. jtester测试 参考： * jtester

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day57 Wednesday, June 06, 2012

1. 
	* 迭代一开发
	* slb bugfix
		slb后端对于错误的url就直接返回原始错误，比如404之类；这样，open api这里需要保证url的准确性。

2. 迭代一开发记录
	- 4.5	查询设备已有的快照接口(list_snapshot)
		ListSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),  DOC
	- 4.6	查询快照详情接口（detail_snapshot）
		SnapshotService
			mock测试
			主要是mock每个action相应的command执行结果，这个结果参考相应action的command中处理返回值的代码。比如：此接口参考 QuerySnapshotCommand （由于缺少后端接口说明）结果处理，处理结果
			？

		DetailSnapshotExecuteAction 
			待测
		状态码修改：
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法			
	- 4.7	删除快照接口（remove_snapshot）
		AbstractSnapshotExecuteAction 涉及deviceNo，需要修改
		RemoveSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法	
	- 4.8	回滚快照接口（rollback_snapshot）
		RollbackSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法		
	- 4.9	保留快照接口（retain_snapshot）
		SnapshotService
		RetainSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法

3. spring，资源文件加载 问题
	如果导入资源文件的配置文件没有初始化，提前处理调用资源文件会报错：
		eg: jtester抽象父类，初始化spring context时。

	mock复杂的私有内部类时，通过新建一个类（继承原来的类）来mock，配置时初始化由于早于属性文件导入，报了错。放到属性文件加载之后即可。

4. 设计中测试的考虑


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day58 Thursday, June 07, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		SnapshotService
		ListMountedSnapshotExecuteAction
			待测
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotService
		MountSnapshotExecuteAction
		？snapshot 和 snapshot_id混用？
			String snapshot = ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT);
			if(StringUtils.isEmpty(snapshot)){
				 snapshot=ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT_ID);
			}
			—— 查看过期API，是因为兼容老api，snapshot已废弃被snapshot_id替代
				按照当前逻辑，如果新旧参数都传了，还是以旧参数为准 ，其他接口一样，这点要注意。（以最新参数为准较好？）
		状态码修改：
			ILLEGAL_DEVICE_NO(-901,"illegal device no") DOC
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id ") DOC
	- 4.13	在线迁移接口( live_migrate_vm)
		InstanceService
		VmLiveMigrateExecuteAction
		状态码修改：
			增加错误码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), 表示迁移时需要在同一个region中 ？ DOC
					迁移目标NC和当前instance不在同一个region中
					注：这个与对外是一个大region矛盾，是否处理可迁移的nc列表，不包含不可迁移的nc？还是只供内部用？
				ILLEGAL_NC(-731,"illegal nc"),
			待测
	- 4.15	查询可切换的nc接口（query_available_nc）
		QueryAvaliableNcsExecuteAction
			待测
	- 4.16	查询nc详情(detail_nc)接口 (houyi-openapi.xml)
		NodeControlService
		SingleNcResourceAction
		状态码修改：NcErrorMessage 
				NC_NO_IS_NULL(-730, "nc_no is null"), —— 》NC_NO_IS_NOT_ILLEGAL(-730, "nc_no is not illegal"), DOC
			待测
	- 4.17	创建VM（create_vm）接口 
		VmCreateExecuteAction
			逻辑在getInstanceInfo方法里
		RackServiceImpl
		状态码修改：
			增加状态提示：
				GlobalErrorMessage NO_IN_THE_SAME_REGION (-142, "not in the same region"), DOC
				当rack的region和nc的region不一致时报错。
			待测
	- 4.14	故障切换接口（recover_vm）
		状态码修改：
			增加状态码：
				NcErrorMessage RACK_ID_NOT_ILLEGAL(-719,"rack is not illegal"), DOC
					rack_id格式不合法（destination_rack）
			增加状态码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), DOC
					nc region 和intance region不一致。
		InstanceServiceImpl
		VmRecoverExecuteAction
			待测
	- query_racks action也要改动？ 多态一个，此接口暂不变。

3. 对于service层的 public CommandExecutor commandExecutor; mock费了不少时间，由于此属性的注入方式是通过一个工厂（CommandExecutorFactory）获得（spring的beanfactory接口的实现）
mock这个工厂取得commandExecutor对应的实例对象时，返回的却是这个工厂的类型，不是CommandExecutor的实现类。
		工厂内部通过一个私有内部类来得到真正的CommandExecutor实现类（不便mock），最后通过把这个工厂类的配置单独提出来，写一个mock类继承CommandExecutorFactory，并测试时
	配置为工厂的mock类，这样测试能通过。
		但是这个工厂需要根据场景返回不同的CommandExecutor实现类，不便于每次测试去修改mock类。
		debug发现在测试类中再去mock一下这个mock类时，返回的是其自身，转型时不能转为CommandExecutor类型，于是让这个工厂mock类实现CommandExecutor接口。
4. 
	拦截器mock
		如果不便于mock，则找到其内部关键点进行mock。
	mock里面嵌套mock 是否可行？不必要，正确mock了某个类，可以忽略其内部逻辑。

5. mock 与 expections 结合 jmockit ,jtester
	mock对象，编写期望 expections 。
		-------
		...
			@SpringBeanByName
			QueryVmDeviceExecuteAction query_vm_device;
			
		//	@Mocked
		//	@SpringBeanFor
		//	InstanceService instanceService;
			
			@Mocked
			@SpringBeanFor
			ZoneService zoneService;
			
			@SuppressWarnings("unchecked")
			@Test
			public void testExecute() throws Throwable{

				final Result<PagingInfo<DeviceEx,DeviceEx>> expectedDeviceResult = new Result<PagingInfo<DeviceEx,DeviceEx>>();
				expectedDeviceResult.setSuccessful(true);
				expectedDeviceResult.setResultInfo(new PagingInfo<DeviceEx, DeviceEx>(){
					@Override
					public List<DeviceEx> getItems() {
						List<DeviceEx> list = new ArrayList<DeviceEx>();
						list.add(new DeviceEx(10,1024,"System"));
						list.add(new DeviceEx(11,512,"System"));
						list.add(new DeviceEx(12,256,"System"));
						return list;
					}
				});
				
				final String expectedClusterId = "testClusterId";
				final ResultMessage expected = ResultMessage.SUCCESSFUL;
				
				final Instance instance = new Instance();
				instance.setInstanceNo("testNo");
				instance.setStatus(InstanceStatus.Running);
				
				final ResultDomain resultDomain = new ResultDomain(200, "successful");
				
				UserHolder.setCurrentUser(new User());
				RegionHolder.setCurrentRegion(new Region());
				
			new Expectations(){
				{
		//        		when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
					when(zoneService.queryClusterIdByZoneId(anyString)).thenReturn(expectedClusterId);
				}
				@Mocked(methods="queryDevice")
				InstanceService instanceService;
				{
					when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
				}

			};
				
				ResultMessage result = query_vm_device.execute(instance, null, resultDomain);
				
				Assert.assertEquals(result, expected);
				Assert.assertEquals(((List<DeviceApi>)resultDomain.getData().get("devices")).get(0).getDevice_no(), expectedClusterId+"-10");
			}
		...
		-------
	分析上面的测试用例代码的 instanceService 部分：
		如果要mock instanceService的某个方法，可以在属性里定义mock；如果只是想测试一个调用期望，可以写在expections里（录制-重现），以验证是否被调用。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day59 Friday, June 08, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 继续 create_vm接口
		
	- 继续nc详情
	- 

3. mock 测试 
	代码里计量显式的传递变量，尽量少与第三方的代码耦合，否则耦合度高，同时也不利于单元测试。
		比如struts框架的 ServletActionContext 便于读取action的上下文，尽量只在入口处调用，不是每个地方都去调用这个类。逻辑尽量紧凑。

		即尽量减少与容器耦合。否则那些个特殊类都需要去mock（eg:session.rquest,respone....）

	测试一个action时，可通过mock其父类的方法来便于测试。
		利用mock框架的只对特定方法mock能力。

	mock某个类，那么spring 的注入就失效了（=null）

	* 对于静态方法，全局变量，可以再运行时设置进去。
		比如struts2的actoncontext，可以自己注入一个用于测试：
			ActionContext.setContext(new ActionContext(params));
	
			ActionContext.getContext().setParameters(params);

			mock代码：
				Map<String,Object> params = new HashMap<String, Object>();
				ActionContext.setContext(new ActionContext(params));
	
	* 下面2个方法的声明，就关于params参数的设置，看哪个好测试？
	（1）
		@Override
		public ResultMessage execute(Instance instance, Map<String, Object> params,
				ResultDomain resultHolder)
		{
	（2）
		@Override
		public ResultMessage execute()
		{
			Map<String, Object> params = ActionContext.getContext().getParamters();
		很明显，第一个测试时传入即可，第二个却要去自己访问第三方类，设置值，如果不方便设置就囧了~~~
		对于确实依赖第三方的地方，可以统一包装使用（通过参数传递进来），不零散调用。比如抽取到工具类中去。朝着低耦合，高内聚的目标走
4. 问题
	VmCreateExecuteAction.
		try{
			 image = super.getResources(Image.class, imageNo);
		}catch(ResourceUnfoundedException e){
			 image = imageService.queryCustomImageByImageNo(imageNo);
		} 
		？异常做逻辑处理？
	或者抛出，结束执行，或者捕获，日志，继续执行。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day60 Monday, June 11, 2012

1. 
	* 迭代一开发
	* 补偿迭代一单元测试
	* SLB open api原查询后端业务表的逻辑修改：
		不查询SLB后端业务表，改为从查询LoadBalancer列表(list_lb)接口获取需要的信息：
			a. 
			b. 

2. 开发记录
	- 4.18	查询用户所有VM状态（list_vm_status）接口  ？ 当前还只是返回指定region下的所有vm状态，待到后面迭代实现返回大region下信息
		QueryVmListInfoExecuteAction

	- 4.20	删除云硬盘(remove_disk)接口
		RemoveDiskExecuteAction
		InstanceService
		状态码修改：
			增加：SnapshotErrorMessage DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), 错误码  DOC
	4.19	查询VM详情（detail_vm）接口
		VmQueryExecuteAction
		InstanceService修改queryInstanceAtNc方法
		InstanceService修改queryInstancePublicIp方法
		

3. 单元测试补充记录
	- CancelCreateSnapshotExecuteAction
		SnapshotService 的cancelCreateSnapshot方法 done
	- CreateSnapshotExecuteAction
		snapshotService.createSnapshot
	..具体见redmine

4.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day61 Tuesday, June 12, 2012

1. 
	* 迭代一开发 +　单元测试补偿
	* 迭代一接口的状态码修改，更新到设计文档中 ？待
	
	* SLB OPEN API bug修改
		检查请求后端的URL的正确性，比如某些关键参数为空的话，则URL请求返回404等错误，后端没有处理，open api需要处理。
		monitorInfoService 已处理一个方法，还有个得到分页的user lbs方法 待？
			listLoadBalancerFlows 接口：
				- slb流量接口，当前逻辑是查询统计所有流量数据，如何根据lb_id分页匹配数据，响应client。
					后面可以优化根据需要查询的lb_id的流量进行真分页查询。？
						先得到分页的lb_id列表，然后到后端流量表一次性查询对应的流量数据。
				- 此接口获取lb_ids的逻辑改为从list_loadbalances接口间接获取，排序后分页，返回。


2.  开发记录
	新增接口修改：没有列入参数修改设计文档，根据redmine开发：
	vlan_no 改为 cluster_id-vlan_no 涉及到 create_vm 也要修改
	- 查询虚拟网络信息（list_vlans），修改返回值(vlan_no改成cluster_id-vlan_no)
		VlanQueryAction

3. mock 测试			   * mock
	测试框架提供了部分，常用J2EE框架的mock类 比如 ：HttpServletRequestSimulator ，用于测试struts时模拟request对象。 mock request对象
		-------
			HttpServletRequestSimulator requestMock =new HttpServletRequestSimulator(new ServletContextSimulator());
			requestMock.addParameter(IpAddressParameter.IP.getName(), "10.1.1.1");
			ServletActionContext.setRequest(requestMock);
		-------

4. 设计 ，id，name ，。。。命名统一，或者叫id或者统一name。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day62 Wednesday, June 13, 2012

1. 
	* slb bug fix
	* 迭代一接口的状态码修改，更新到设计文档中 doing
	* 迭代一  补充接口处理	redmine没录入？
		- 4.12	卸载快照接口(unmount_snapshot)
	* SLB后端数据格式修改？
		查询用户lb列表：
			{\"code\":200,\"msg\":\"successful\",\"lbs\":[\"lb1\",\"lb2\"]}"); 由统一的data字段表示数据，改为lbs 。？

	* houyi open api 参数修改部分，某些参数不是必选的？逻辑需要考略 
		参考原有逻辑，处理可选参数。
	* 状态码修改补充
		原状态码不变（尽量减小对客户端的影响），新增需要的状态码：
			device_no is illegal	device_no参数格式不合法
			nc_no is illegal	nc_no格式不合法（cluster_id-nc_no）
			not in the same region	xxx的region和xxx的region不一致
			rack is illegal	xxx rack格式不合法（cluster_id-xxxrack）
			snapshot id is illegal	snapshot_id格式不合法

			device_no is illegal  device_no参数格式不合法
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),

			 nc_no is illegal nc_no格式不合法（cluster_id-nc_no）
			ILLEGAL_NC(-731,"illegal nc"),

			 rack is illegal    xxx rack格式不合法（cluster_id-xxxrack）
			ILLEGAL_RACK_ID(-721, "illegal rack id") ;

			 snapshot id is illegal         snapshot_id格式不合法
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "),

			vlan_no
			ILLEGAL_VLAN_NO(-191, "illegal vlan_no"),;

	之前的状态码修改 ，修改为上面的格式。
	
2. 文档管理

3. 数组操作
	Arrays 工具类 collections 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day63 Thursday, June 14, 2012

1. 
	* 迭代一单元测试补充
	* umount_snapshot接口实现
	* slb  api bugfix
		及文档修改
			错误提示都修改为驼峰式。eg: NameIsEmpty 
	* 迭代一
		可选参数，逻辑处理检查 done

2. 补充
	- umount_snapshot 卸载快照接口
		UnmountSnapshotExecuteAction
		SnapshotServiceImpl
		状态码增加：
			-901	illegal device no	device_no格式不合法 DOC
			-921	illegal snapshot id	snapshot_id格式不合法 DOC
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day64 Friday, June 15, 2012

1. 
	* 动态添加region，不重启 ,
		具体需求为：添加region表的信息，添加region对应的monitor_datasource信息
		day54 no.1		
		RegionValuesFactory
			单元测试（region缓存初始化后，往数据库插一条新region记录，验证缓存中不存在就去数据库查找并存入缓存的逻辑）
		下半部分需求分析：
			- DefaultClcEndpointLoader （通过regionDao得到region_no与nuwa地址的map）
			- CommandExecutorFactory 根据上面的map，初始化 executors：
				this.executors = new HashMap<String, CommandExecutor>();
			- 上面的 executors 每次调用时根据regionNO返回对应的操作后端的 ApsaraCommandExecutor
				CommandExecutor executor = executors.get(regionNo);
			
			所以，更新 executors 即可将新region的monitor_datasource添加到缓存中。
				由于对外没有提供修改 executors 变量的入口，考虑通过反射来动态设置 executors 。
				这个逻辑的触发放到哪里？
					谁最先知道有了新region？
					分析代码知道，RegionAwareInterceptor 最先执行（需要通过 RegionValuesFactory 来查询用户请求中的region信息），所以，上面的逻辑触发
					放到 RegionValuesFactory 动态加region信息的逻辑中。
			方案：
				在 RegionValuesFactory 处理新增region的缓存逻辑中，同时增加更新CommandExecutorFactory的executors属性，加上新region的调用对象的逻辑。
			例外情况：
				手动加region表记录和加monitor_datasource记录是不同步的，或者可以理解2者没关系。
				所以上面的触发逻辑，分别处理各自在查找cache的逻辑中实现动态更新。

				此需求，在RegionAwareInterceptor中更新CommandExecutorFactory的executors属性逻辑部分，由于采用新的缓存类cacheservice，于是无法触发原更新缓存逻辑(大region项目reversion:487318)，导致加入新region后，
				调master报region找不到错误。
					解决方法：
						在同一cacehservice服务类处理新增region的逻辑中，加上更新endpoint的逻辑即可。
		
		monitor_datasource和 region，至少2者有各自的作用：
			MonitorSqlMapTemplateFactory 的 monitorDatasources 变量
				ConsistentCircle

	* houyi open api 测试环境
		http://10.250.6.33/open/services?
		key:lisw,secret:lisw

	* houyi open api 
		涉及snapsho的接口，原部分接口逻辑在操作快照时没有对用户是否有权限操作快照做约束，现需要判断：
			- 快照的owner和当前用户是否一致。
			（image是有visibility使用权限设置的，可以设置为私有或公有或者其他定义的类型，快照为私有）

			- 增加判断权限的单元测试
			- 参考 InstanceServiceImpl 的 mountDisk 方法
			- 修改范围：
				迭代一中涉及用户对snapshot操作的接口
			- 验证错误报：
				CLCErrorCode.SnapshotNoPrivilege

2. snapshot权限验证 （对snap操作时都应该验证owner，或是查询或取消创建或删除或挂载。。。）
	然后，上面的验证逻辑是在open api层还是控制层？
		是api自己去一次次查询再验证，还是把需要的参数给后端(user_id,snapshot_id etc..)，让后端来校验并返回给api？
	
	查询快照时，返回前判断快照是否属于这个user：

		DetailSnapshotExecuteAction
			if (!snapshotExt.getOwnerId().equals(
					String.valueOf(UserHolder.getCurrentUserId())))
			{
				ResultMessage message = SnapshotErrorMessage.SNAPSHOT_NO_PRIVILEGE;
				ResultDomain resultDomain = new ResultDomain(message);
				return resultDomain;
			}
	
	？ 需要确认，后端那些做了验证，那些没做验证？

	- 4.1	add_disk接口 done
		InstanceServiceImpl 的mountDisk方法
			done
			判断逻辑：
				snapshotExt = (SnapshotExt) result.getResultInfo();

				/** check permission **/
				if(snapshotExt.getOwnerId().equals(String.valuseOf(UserHolder.getCurrentUserId()))){
					return new Result<Object>(CLCErrorCode.SnapshotNoPrivilege);
				}			
		unit test
			done
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		？此接口没有查询快照，直接传递snapshot_id给后端，执行取消快照创建 ，是否需要先查询，判断owner正确，再取消创建？ 待
			或者是后端会根据snapshot_id结合instance信息，判断是否有操作权限？后端确认，“无文档”，验证较好，权限体系
		若api层做验证，参考4.1实现。
	- 4.5	查询设备已有的快照接口(list_snapshot)
		？同4.4，返回的快照列表是否可能是其他用户的快照
			如果后端没验证，open api需要验证
		ListSnapshotExecuteAction
	- 4.6	查询快照详情接口（detail_snapshot）
		DetailSnapshotExecuteAction
		原逻辑已验证，跳过
	- 4.7	删除快照接口（remove_snapshot）
		？同4.4 ，原逻辑也是传递snapshotId给后端，是否需要先查询，再执行
		部分代码：
			RemoveSnapshotCommand command = new RemoveSnapshotCommand(instance, deviceNo, snapshotId);
			return commandExecutor.execute(command,snapshotRegionNo);
	- 4.8	回滚快照接口（rollback_snapshot）
		？同4.4
	- 4.9	保留快照接口（retain_snapshot）
		？同4.4
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		？同4.4
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotServiceImpl > mountSnapshot
			done
		unit test
			done
	- 4.12	卸载快照接口(unmount_snapshot)
		SnapshotServiceImpl
			done
		unit test 
			done
			


3. api调控制系统的设计
	采用command模式，每个接口都定义为一个command对象，封装了endpoint，参数，处理返回值等逻辑。

	统一由一个执行对象执行。

	action中处理返回值的逻辑，是否可以移到command的处理防护值方法中 职责划分

4. houyi open api 系统
	InstanceServiceImpl > mountDisk
		this.instanceDao.updateInstanceConfig(instance); //没返回值，没log，非理想情况如何处理
	mock？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day65 Monday, June 18, 2012

1. 
	* slb bug fix
		严格按照文档说明来开发，编写单元测试（基于文档）
		- 流量接口 pageNO,pageSize可选，空的话采用默认值。依据文档说明
		- 目前OPENAPI的RS表没有user_id字段，虽然lb_id是全局唯一的，但是rs_pool_name却是用户唯一的，所以光凭rs_pool_name无法唯一确定一个rs_pool，可能会有重复的情况出现。
			rs表加user_id字段，增加删除时都带上这个筛选字段。lb_id ，rs_pool_name都带上对应的user_id
			sql修改
				alter table rs add user_id int(10) unsigned;
	* big region
		svn提交格式：
			fix bug #3243 修复某问题的comments
2. 设计
action的参数验证，可以抽象出来，不用在acton的方法里详细验证

3. 基于文档 ，每个条件/参数都提供测试用例，测试用例覆盖每个错误状态
	理想状态用例
	参数不合法用例
	。。。
4. 实现 ApplicationContextAware 接口的类，在spring初始化时初始化应用的一些缓存等操作时，bean需要配置，以便spring来实例化
	

5. linux部署时，会由于权限问题导致，部署失败，或者部署时，有部分文件没被更新。
需要注意。

6. 整理 slbapi 操作rs表的接口及其操作rs的逻辑（增加逻辑/删除逻辑）
	- add_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
	- delete_rs
		根据vm_name,rs_pool_name和user_id删除rs表记录
	- switch_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
		根据vm_name,rs_pool_name和user_id删除rs表记录
	-add_vm
		根据vm_name,lb_id和user_id增加rs表记录
	-delete_vm
		根据vm_name,lb_id和user_id删除rs表记录
	- switch_vm
		根据vm_name,lb_id和user_id增加rs表记录
		根据vm_name,lb_id和user_id删除rs表记录
	- delete_lb
		根据lb_id和user_id删除记录
	- release_backend
		根据vm_name 和user_id删除rs表记录
	- delete_rs_pool
		根据rs_pool_name和user_id删除rs表记录


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day66 Tuesday, June 19, 2012

1. 
	* big region 动态添加regin，更新monitor datasource信息
		？更新缓存接口
		逻辑实现 + 测试
		触发条件：
				需要用到各自region的SqlMapClientOperations操作的dao层，都是通过MonitorSqlMapTemplateFactory的 getMonitorDatasource 方法取到 SqlMapClientOperations 进行后续操作，
			故，以 getMonitorDatasource 方法作为触发加载新region monitor datasource的点。
		修改点：
			MonitorSqlMapTemplateFactory 
				public SqlMapClientOperations getMonitorDatasource(String regionNo, String instanceNo){
	* slb rs表测试
	* big region ,根据cluster_id查询region_no时，如果region_no不存在应该报错 ？ 添加验证逻辑
		返回码设计：
			根据不同参数的cluster_id查询region，设计相应的返回码
			- cluster_id-device_no-snapshot_id
				报snapshot_id不存在
			- cluster_id-device_no
				报device_no不存在
			- cluster_id-nc_id
				报nc_di不存在
			- cluster_id-rack_id
				报rack_id不存在
			- cluster_id-vlan_no
				报vlan_no不存在

	* mysql case sensitive
		mysql 区分大小写
		参看下面：
				The default character set and collation are latin1 and latin1_swedish_ci, so nonbinary string comparisons are case insensitive by default. This means that if you search with col_name LIKE 'a%', 
			you get all column values that start with A or a. To make this search case sensitive, make sure that one of the operands has a case sensitive or binary collation. For example, if you are comparing a 
			column and a string that both have the latin1 character set, you can use the COLLATE operator to cause either operand to have the latin1_general_cs or latin1_bin collation:
				col_name COLLATE latin1_general_cs LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_general_cs
				col_name COLLATE latin1_bin LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_bin
				If you want a column always to be treated in case-sensitive fashion, declare it with a case sensitive or binary collation.
			from:http://stackoverflow.com/questions/5629111/mysql-case-sensitive-string-comparison
		2种方式实现mysql支持大小写区分
			1) 查询时通过操作符 COLLATE
			2) 建表时声明
		此处选择建表时声明列区别大小写：
			-- 此为更新语句 sql修改
			alter table region_mapping modify column vm_region_no varchar(32) binary NOT NULL COMMENT '@desc vm region_no';  
			alter table region_mapping modify column region_no varchar(32) binary NOT NULL COMMENT '@desc slb region_no';  
			alter table region modify column region_no varchar(32) binary NOT NULL;  
			alter table rs modify column vm_name varchar(50) binary NOT NULL COMMENT '@desc vm name';
			alter table rs modify column rs_pool_name varchar(100) binary COMMENT '@desc rs pool name';
			alter table rs modify column lb_id varchar(110) binary COMMENT '@desc lb_id';
			alter table monitor_datasource modify column region_no varchar(32) binary NOT NULL;

			建表语句类似上面。
				  `region_no` varchar(32) binary NOT NULL COMMENT '@desc slb region_no',

2. monitor datasource相关修改点，测试点
	- monitorDatasource.xml 增加根据region_no查询记录的select语句定义
		MonitorSqlMapTemplateFactory 直接用了这个映射文件（充当dao层）
			测试时测试这个类即可
				测试新增的select
	- MonitorSqlMapTemplateFactory修改 getMonitorDatasource 方法
	
3. bug提交格式 
	fix bug #3243 修复某问题的comments

4. 单元测试覆盖程序的逻辑，覆盖关键点越细，工作量越大，但代码健壮性越强。
	slb这边测试用例只测试几个正常的场景，对一些例外没有写用例，导致qa测试bug。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day67 Wednesday, June 20, 2012

1. 
	*  slb bug fix #122
		先新建lb，然后重现问题
		原因：
			hybird类型 query_loadbalance_info时，返回值中没有vm_list字段
	* slbapi rs表加region_no字段（slb的region），目的在操作rs_pool_name记录时，处理多个slb region_no的rs_pool_name重名情况
		每个rs记录都记录region_no
		sql修改
			alter table rs add region_no varchar(32) DEFAULT NULL  COMMENT '@DESC slb region no';
	* 迭代一 参数修改部分 ，新增2个接口需要修改
		
2. slbapi 测试环境
	mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
3. slb测试
	测试的条件能重现，就可以在本地debug

4. SystemError 2100
	slbapi在处理 ip2name时会报这个异常
5. rs表加region_no字段 —— 只在操作rs_pool_name时考虑这个字段
	rs.xml
6. 部署没更新问题
	删除部署的内容后，重新build再部署。
7. 接口测试，单元测试中，可能没有细致到返回结果处理的测试用例，隐藏了
	a. 调用成功
	b. 返回值正确
	c. 处理返回的相应正确

	一套单元测试用例很重要，打好基础，再变更时，处理就很方便；否则，未知数太多，需要QA或运行时才能暴露问题。

8. 迭代一 参数修改 新增接口 文档说明整理
	- 4.22	query_nc_resources接口
		ClusterNcResourceListAction

	- 4.23	query_racks接口
		RackQueryAction

		哪怕是那寥寥几个字节的注释，也能鼓起我看完这漫长代码的勇气~，如果连这点也剥夺，那也就只好苦逼的被一行行、一遍遍的摧残了

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day68 Thursday, June 21, 2012

1.
	* big region 迭代一bug处理
	* big region 迭代一新增2个接口开发
	* big region 测试环境
		请求api的client 位置：
			/houyi-console-openapi/src/test/java/com/aliyun/houyi/openapi/util
		10.242.209.4  api地址
		10.242.209.1 api db
		日志 /home/admin/houyi/service/logs/openapi
		10.250.8.214环境 admin操作
			cd /home/admin/houyi/service
			sh build/build.sh 
			sh bin/reloadws_alone 
			tail -f logs/openapi/jboss_stdout.log 
		配置文件：
			/home/admin/.houyi/

		dev开发测试环境：
			AT-HOUYIDEV-AG 10.250.6.27
			HOUYI-MASTER:10.250.8.212
			HOUYI-NETC:/10.250.6.32
			API:10.250.6.33
			DB:10.250.6.27

			

2. big region 迭代一bug处理
	- detail_vm 返回的vlan_no格式错误 http://bugfree.corp.taobao.com/bug/175626
		原因：设计时丢了vlan_no的格式转换（vlan_no为后续增加待修改参数）
		修改：
			VmQueryExecuteAction
			VmQueryExecuteActionTest
	- 

3.  big region 迭代一新增2个接口开发
	- 4.22	query_nc_resources 接口
		修改：
			ClusterNcResourceListAction
				zone_id的获取？
					AbstractExecuteAction 提供2个重载的 getCurrentZone 方法供action调用，采用哪个无参的方法。（即请求中无zone_no，则取用户默认的zone）
			ClusterNcResourceListActionTest
	- 4.23	query_racks接口
		修改：
			RackQueryAction
			RackQueryActionTest

4. 问题排查
	请求内容 + 错误返回内容 + 日志内容


5. 迭代一 cluster_id 修改整理：	 from mail
	3）cluster_id是否存在需要判断（nc_id,rack_id,vlan_no,device_no,snapshot_id）
	DEVICE_NOT_EXISTS(-905, "device not exists at vm"),
	SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
	NC_NOT_EXISTS(-700, "nc not exists"),
	RACK_NOT_EXISTS(-160, "rack not exits"),
	NC_NOT_EXISTS(-161, "nc not exits"),
	VLAN_NOT_EXISTS(-190, "Virtual Lan not exits")
	4）涉及新device_no，新snapshot_id中都需要判断格式中的device_no是否一致，若不存在，错误码是SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
		 这个问题建议使用以前的错误码。
		如recover_vm接口，在vm_name和destination_rack 或destination_nc的cluster_id的region不匹配时，复用以前的错误码  -283（not in same zone of vm）
		如list_snapshot接口，在vm_name和device_no的cluster_id的region不匹配时，复用以前的错误码 -905（device not exists at vm ）

	5）需要判断涉及cluster_id与vm_name对应的region是否一致，这个错误码待考虑？
	以下4、5是在不跨region使用snapshot,disk情况下，API层作的权限验证。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day69 Monday, June 25, 2012

1. 
	* 迭代一cluster_id，device_no 验证bug修复
	* slbapi回归bug
		ip转name时，传入了lbId去查询，数据库中lb_id为null，导致ip转name错误；ip转name可以减少限定条件 只根据 vm_name,ip,region_no确定，如果多条记录报错，记录log，对外报SystemError
			select distinct vm_name region_no=xxx and ip=xxx
	* 职责
		谁操作，谁知道，谁负责校验。

2. bug 修复
	1）修改设计文档
	2）基于文档，修改程序
	3）test
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
		-283, not in same zone of vm
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),
		-917,snapshot not at the device
	修改记录：
		- add_disk
			AddDiskExecuteAction
			AddDiskExecuteActionTest
			InstanceServiceImpl
		- create_snapshot
			CreateSnapshotExecuteAction
			CreateSnapshotExecuteActionTest
		- cancel_create_snapshot
			CancelCreateSnapshotExecuteAction
			CancelCreateSnapshotExecuteActionTest
		- list_snapshot
			ListSnapshotExecuteAction
			ListSnapshotExecuteActionTest
		- detail_snapshot
			DetailSnapshotExecuteAction
			DetailSnapshotExecuteActionTest
		- remove_snapshot
			RemoveSnapshotExecuteAction
			RemoveSnapshotExecuteActionTest
		- rollback_snapshot
			RollbackSnapshotExecuteAction
			RollbackSnapshotExecuteActionTest
			RollbackSnapshotExecuteActionTestTest
		- retain_snapshot
			RetainSnapshotExecuteAction
		- mount_snapshot
			MountSnapshotExecuteAction
		- unmount_snapshot
			UnmountSnapshotExecuteAction
		- live_migrate_vm
			VmLiveMigrateExecuteAction
			
			
		if(!vmClusterId.equals(deviceClusterId)){//check same region
			logger.error("vmCluster and deviceClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		if(!vmClusterId.equals(snapshotClusterId)){//check same region
			logger.error("vmCluster and snapshotClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		String snapshotRegionNo = instance.getRegionNo();
		if(deviceNo!=null&&!deviceNo.equals(snapshotDeviceNo)){//check same device
			logger.error("deviceNo and snapshotDeviceNo is not equal");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(SnapshotErrorMessage.SNAPSHOT_NOT_AT_THE_DEVICE);
			return result;
		}

3. 测试环境 部署时
	打开远程debug，便于分析bug。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day70 Tuesday, June 26, 2012

1. 
	* 文档review，
		修改部分内容，修改相应程序逻辑
	* 迭代一bug fix
		@Entry(action = Action.VM, resource = @Resource(argNo = 5)) }) 由于加了参数资源位置发生改变，需要更新
	* slb v2 测试环境 monitor库地址修改：
		10.230.204.24 slbapi monitor_datasource表 
	* big region
		状态码重复：							clear_cache接口状态码与现有重复
			CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
			NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

			CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
			NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
			-288
			-292
			ClearCacheErrorMessage
	* cluster_id ,device_no,vm的校验方案修改：
		方案改为：
			1）cluster_id校验是否存在，报相应id不存在
			2）nc_id,rack_id,vlan_no，vm校验cluster_id一致
			3）nc_id,rack_id,vlan_no同时传时，取最小的
			4）这5个参数的校验顺序：便于case
				snapshot_id
				device_no
				nc_id
				rack_id
				vlan_no
2. 资源位置改变更新bug修改点
	SnapshotServiceImpl
		unmountSnapshot
3. big region api&houyi avalible
	API:10.250.6.33
	DB:10.250.6.27
4. 错误码 ，调试时，错误码+log
	-283 ,not in same zone of vm
	-917,snapshot not existed at the device
5. 根据修改的文档，继续day69第2条任务
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),

6. 
	# web console staff
	cd `dirname $0`/..
	BASE_HOME=`pwd`

	#rm -rf $BASE_HOME/src/*
	svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api $BASE_HOME/src
	cd $BASE_HOME/src
	mvn clean package -Dmaven.test.skip=true 


	# HOUYI API
	cd $BASE_HOME
	./bin/tomcatctl stop
	cd $BASE_HOME/.default/webapps
	rm -rf slb
	rm -rf slb.war
	ln -s $BASE_HOME/src/target/slb.war

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day71 Wednesday, June 27, 2012

1. 
	* 迭代一，cluster_id等校验规则重新设计，见文档
		开发+测试用例
	* 迭代一 sql调整整理
	* action的validator方法
		会提前验证 参数的格式，需要修改为匹配新格式
			nc_id		NcParameter.NC_NO("nc_no",new RegularValidator("^[0-9]{0,75}$"),null),
			snapshot_id	SnapshotParameter.NAPSHOT_ID("snapshot_id",null), 
			device_no		SnapshotParameter.DEVICE_NO("device_no", null), 
			InstanceParameter
				RACK_ID("rack_id", null),
				NC_ID("nc_id", null),
				VLAN_NO("vlan_no", null),
	* list_snapshot 接口文档返回以删除部分字符串，以实际返回为准
				<rsp>
		  <code>200</code>
		  <msg>successful</msg>
		  <data>
		    <snapshotExts list="true">
		      <snapshotExt>
			<snapshot_id>27-703-520318</snapshot_id>
			<snapshot_name></snapshot_name>
			<progress>37%</progress>
			<create_time>2012-06-27 20:24:54</create_time>
			<image_no>windows2008_64_alibase_v02.vhd</image_no>
			<owner>149</owner>
		      </snapshotExt>
		    </snapshotExts>
		    <device_no>27-703</device_no>
		    <vm_name>wysh-627-a</vm_name>
		    <snapshots>
		      <snapshot>520318</snapshot>
		    </snapshots>
		    <vm_status>Running</vm_status>
		  </data>
		</rsp>
	* aghell05a10.250.6.27 hy create_vm_f vm_conf/windows_vm  wysh-627-a shell脚本执行操作，命名操作名称  ，参数

2. 修改记录
	- add_disk 
		AddDiskExecuteAction @ -
		AddDiskExecuteActionTest @
		InstanceServiceImpl
	- create_snapshot 
		CreateSnapshotExecuteAction @ -
		CreateSnapshotExecuteActionTest @
	- cancel_create_snapshot 
		CancelCreateSnapshotExecuteAction @ -
		CancelCreateSnapshotExecuteActionTest @
	- list_snapshot 
		ListSnapshotExecuteAction @ -
		ListSnapshotExecuteActionTest @
	- detail_snapshot 
		DetailSnapshotExecuteAction @ -
		DetailSnapshotExecuteActionTest @
	- remove_snapshot 
		RemoveSnapshotExecuteAction @ - result返回设置
		RemoveSnapshotExecuteActionTest @
	- rollback_snapshot
		RollbackSnapshotExecuteAction @ -
		RollbackSnapshotExecuteActionTest @
	- retain_snapshot
		RetainSnapshotExecuteAction @ -
		RetainSnapshotExecuteActionTest @
	- mount_snapshot
		MountSnapshotExecuteAction @ -
		MountSnapshotExecuteActionTest @
	- unmount_snapshot
		UnmountSnapshotExecuteAction @ -
		UnmountSnapshotExecuteActionTest @
	- live_migrate_vm
		VmLiveMigrateExecuteAction	@ -
		VmLiveMigrateExecuteActionTest @
	- recover_vm
		VmRecoverExecuteAction @ -
		VmRecoverExecuteActionTest @
		NodeControlServiceImpl @
	- detail_nc
		SingleNcResourceAction @ -
		SingleNcResourceActionTest @
	- create_vm 
		VmCreateExecuteAction @ -
	- remove_disk
		RemoveDiskExecuteAction @ -
		RemoveDiskExecuteActionTest @

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day72 Thursday, June 28, 2012

1. 
	* bugfix 
	* 项目单元测试报错问题
		- 如果是junit，它会去执行带Test开头或结尾的类去执行测试，类不用耦合junit的类，junit会根据自己的规则去找测试类，
		找到了，但类中没有测试方法会报：No runnable methods
		- mvn skip的原因
			原因为：testng框架在初始化时报错，对于依赖的测试用例都将skip
			解决：解决初始化问题，比如spring容器初始化错误等
				暂时先注释houyicontext重复加载抛错
				设置 houyi.openapi.test=true 标识
	* -90 system error 错误
		原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
			com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
				instance找到了，


2. sql整理
	houyi,zone表
	alter table zone add cluster_id varchar(32) NOT NULL;
	SELECT	region_no	FROM zone WHERE cluster_id=#clusterId#
	SELECT	cluster_id	FROM zone WHERE zone_id=#zoneId#	
	select 
		url,
		username,
		passwd,
		region_no,
		index_at_region,
		driver_class,
		min_idle,
		max_active,
		max_idle,
		validation_query
	from monitor_datasource
	where region_no=#regionNO#
3. bugfix
	- bug #177163 live_migrate_vm接口：nc_id为‘-’或者‘--’时，统一返回-90
		
4. mvn test
	mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	big region ，重复设置houyi上下文，导致spring初始化失败

5. -90 system error 错误
	原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
		instance.xml
		instance.selectInstanceDetailByNo
		com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
			instance找到了，left outer join 去找image时，image的记录是不存在的，但这种join方式，还是返回了vm存在的记录，只是image的字段都是空的。
			可以在 join 时，如果image找不到则不匹配，返回空。
			OR
			image对象字段都有默认值，但能判断是否存在。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day73 Friday, June 29, 2012

1. 
	* create_vm接口测试用例补充
		
	* web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
	* big region 状态码重复 修改

2. 

3. jtester 解析wiki文件时，会判断文件的编码格式 参考 jtester部分源码 [源码]
	org.jtester.utility.ResourceUtil	
		String encoding = ResourceUtil.getFileEncodingCharset(file);

	/* inputstream to string */
	public static String convertStreamToString(InputStream is, String encoding) {
		BufferedReader reader = null;
		String line = null;
		try {
			StringBuilder buffer = new StringBuilder();
			reader = new BufferedReader(new InputStreamReader(is, encoding));
			while ((line = reader.readLine()) != null) {
				buffer.append(line + "\n");
			}
			return buffer.toString();
		} catch (IOException e) {
			throw new RuntimeException(e);
		} finally {
			close(reader);
			close(is);
		}
	}
	/* 异常统一捕获，减少遍布try/catch的情况 */
	public static void close(Reader reader) {
		if (reader == null) {
			return;
		}
		try {
			reader.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	public static void close(InputStream is) {
		if (is == null) {
			return;
		}
		try {
			is.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	ResourceUtil中的其他工具方法，开源框架的工具类代码风格

4. web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
		对于不同的web服务器，或web框架都提供错误url处理方式。
			java web项目可以再web.xml里针对异常或错误码配置error page
				<error-page>
					<error-code>404</error-code>
					<location>index.jsp</location>
				</error-page>
		或者通过配置代理服务器，将非法url指向到错误页面。

	生产环境的系统，要处理应用层的非法请求，还要处理服务器层的非法请求（比如，tomcat，apache处理非法请求的指向）；
		比如服务器层的非法请求处理，下面以tomcat为例，在$TOMCAT_HOM/conf/web.xml中配置：
			<error-page>
				<error-code>404</error-code>
				<location>/index.html</location>
			</error-page>			
		其他web服务器，可以参照其文档说明，找到配置点，配置即可。

	实验了下，baidu，等网站对于域名下非法url指向到首页。

5.  big region
	状态码重复：
		CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

		CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
		NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
		-288
		-292
		ClearCacheErrorMessage

	暂不改


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day74 Monday, July 02, 2012

1. 
	* big region参数修改bug fix
		创建    unmount_snapshot API超时返回-95
		创建    API参数调整设计文档中未提及create_image接口
		query_available_ncs: vm用户非法情况，API报-90
		query_available_ncs: vm状态为destroyed的情况下，API报-90
	* 关键性log，记录并打印关键内容 ，便于后续查找log排查问题。个人感觉，log需要记录关键性的原生请求内容，比如请求参数，返回内容等
		进入拦截器打个日志，这样在某些关键点打日志就可以从日志中大致判断那个地方报错了。
	* live_migrate_vm接口nc_id是否为必须？
		待确定，代码里验证为必须。
		
2. big region参数修改bug fix
	qa环境不在6.33上，看日志需要到qa测试机查看 10.242.209.4 （改为 10.230.204.19）
	
	创建    unmount_snapshot API超时返回-95
	创建    API参数调整设计文档中未提及create_image接口			  done
		修改设计文档
		CreateImgExecuteAction
		ImageServiceImpl
	query_available_ncs: vm用户非法情况，API报-90
	query_available_ncs: vm状态为destroyed的情况下，API报-90	   （控制系统destory，api这层为release状态）
		在根据vm_name查找instance时（为了查询资源的regionNo），dao层sql语句报错，和之前一样，let join的表没数据，但result这个字段又是必须，故报ibatis设置result map错误，程序没有捕捉这个错误。
			应该报这个错，日志没记录：
				com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
		解决：
			捕捉这个错误，打出log。
		注：
			错误日志找了半天找不到（根据请求内容，返回结果），原因在于 log里没有打印请求相关的内容，不好根据请求内容匹配，建议可以适当打印请求的一些关键内容，便于排查错误。 【日志内容设计，建议】
				2012-07-02 14:12:13,249 ERROR [com.aliyun.houyi.openapi.interceptor.ParameterInterceptor] - [业务参数校验有问题，请检查原因：com.aliyun.houyi.openapi.exception.ParameterException: 协议参数校验不通过，参数名称：timestamp！]

				2012-07-02 14:35:38,204 ERROR [com.aliyun.houyi.openapi.interceptor.RegionAwareInterceptor] - [查询资源信息时发生错误!]
				就这条日志，导致error错误发生，log里没有明确的内容标识本此请求，故通过即时重现来得到log输出。这里可以适当打印一些请求内容，便于后续排查错误。

3. 日志打个唯一tag，再结合用户标识等唯一标识以及时间，可以从日志中统计出每个用户每次调用的所有有序日志输出。think it


4. debug 代码不一致，不是部署错了，就是自己的代码没更新，排查呀排查 。。。 呵呵

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day75 Tuesday, July 03, 2012

1. 
	* region转换需求分析 redmine
	*迭代三 开发需求分析
	* slb v1,v2的vm的小region转为大region	 需求分析


2. 迭代三任务
	- [ID:175057]兼容用户使用小region调用
		a. 兼容用户使用小Region的调用(用户传入的小region统一转成大region，用户输入小region,API返回小region)
			需求理解为：（需要review）
				1. 兼容用户使用小Region的调用(用户传入的小region统一转成大region)
				2. 用户传入小region，步骤1中转换为大region，即使用户传入小region，api实际返回的还是大region下的内容
				3. api只返回大region的region_no

				原则：
				所谓兼容，指的是用户可以传入小region_no，但api都转换为大region_no处理，包括返回的也统一为大region_no			
		b. 查询用户所有VM状态接口(list_vm_status)，根据用户输入的大Region返回大Region信息
			需求理解为：（需要review正确与否）
				1. 根据用户输入的大Region返回大Region下用户所有VM状态，返回大region_no
				2. 若传入小region,查询小region下用户所有VM状态,返回小region_no
				QA:
				1. 大小region_no如何区分？
					表region_alias记录小region与大region的关系
						region_no
						real_region_no
					参考：弹性计算大Region项目_调度设计_API部分__20120628.docx

			QueryVmListInfoExecuteAction
			InstanceDaoImpl

3. SLB V1版本，V2版本所使用region_no全部换成大region_no
	前提：现在vm的大region和slb的region是一对一的，即vm的大region都对应slb的一个region。
	有了上面的前提，v2版本的slb api项目要修改的地方：
		1）配置vm的大region对应slb的region的映射关系，保证大region传递过来能正确调用到slb的region。
		2）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day76 Wednesday, July 04, 2012

1. 
	* 迭代三
		region_alias表big_region_no字段增加
	* 小region改为大region，涉及到的command中region属性判断需要设置为目标region。doing
		参考：CreateInstanceCommand
	* 迭代一的根据zoneId取clusterId逻辑，改为从cache中取，参考    QueryVmListInfoExecuteAction	       getRegionValuesFactory().getClusterIdByZoneId(xx)		  待
			

2. 迭代三
	- list_vm_status
		QueryVmListInfoExecuteAction
			转换nc_id时，要考虑到不同region取出的nc的cluster_id是不一致的。
			设计时，如果每个转换都查db，性能很低sql很简单当连接耗时，考虑缓存zone_id,cluster_id映射数据。
				在RegionValuesFactory存放此缓存 缓存设计（总体设计，类设计，更新策略，。。。）
					系统有多处小cache，是否设计一种通用方式，不用每个cache都自己去写个类，去clean等共性操作。
						抽象出缓存操作接口层，不论底层是什么缓存工具，接口的实现来实现细节。上层应用只调用接口，在配置中配置具体实现。应用系统缓存设计
			在处理每个nc不同的cluster_id前缀时，处理方式改为在原有逻辑循环中，从clusterId缓存中取得后设置。
		InstanceDaoImpl
		instance.xml 增加新查询，已有查询不动（避免影响已有调用）
		RegionValuesFactory
			getClusterIdByZoneId
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		QueryUnassignedIpsExecuteAction

		此接口需要根据 zone_id取到对应的小region_no，查询houyi时，指定在这个小region上操作。
		
3. dbfit 测试用的wiki文件，直接从sql检索结果贴过来，会有很多空格，可以用空来替换空格，再补上必要的空格，省去删空格的繁琐。
	替换功能帮助不小
4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day77 Thursday, July 05, 2012

1. 
	* 迭代三开发


2. 迭代三
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		由于zone_id是必选，原有逻辑不变，不跨小region。
		QueryUnassignedIpsExecuteAction
		QueryUnassignedIpsExecuteActionTest
	- [ID:175055]查询可用的ISO接口(query_available_isos)，根据大Region参数该大Region下的所有资源
		QueryAvaliableIsosExecuteAction 
			region_no参数没用到 ，iso_resource表加入region_no字段待确定？ 这样iso就属于某个小region
				iso_resource 加region_no（小region_no）字段
				sql修改
					alter table iso_resource add region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的小region_no';
				相应要修改的点：
					iso.xml
						对region_no字段加入，需要修改的sql
					IsoDaoImpl 修改 selectUserAvailableIsos方法

3. 对于兼容的地方，文档应尽量说明，便于理解。
	比如一个必选的参数，但没传也ok，容易误解。文档描述与程序逻辑的一致。

4. 
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction

4. big region ,houyi api 代码中多处用到java对象的址传递方式来，从一个方法中取得多个结果
	比如：声明一个变量，传入到方法参数中，执行好后，方法返回一个结果，参数中对象也保存了结果

	这样的现象出现的原因？有何优缺点？
		原因还是对方法的结果没有更好的封装对象，需要
		弱封装，一个方法包含多个功能 

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day78 Friday, July 06, 2012

1. 
	* 迭代三开发
		- 根据写的开发修改文档
		- region表增加big_region_no字段，和region_alias表（real_region_no字段由于存储2个region_no对应同一个存储，
			在imge接口里，为了区分用）的big_region_no一致
			sql修改：
				alter table region add big_region_no varchar(32)  NOT NULL COMMENT '@desc 小region_no对应的大region_no';
			相应点的修改
			测试用例，wiki文件修改 待？

			注：7月9号，取消上面的修改，region表不增加big_region_no字段。
				通过svn版本还原各个修改点。

	* 缓存使用
		- 系统多处地方，频繁调用数据库，结合简单缓存service，将某些查询缓存起来。在查询缓存命中时，免去数据库操作，提高性能。
		- 提高公共缓存服务，可以根据类型操作各自缓存；便于扩展，加入新缓存类型
		- 缓存的更新，若缓存没命中，则继续到数据库中找，找到就放到缓存中，并返回
		- 缓存的过期清除，不用的缓存，命中率低的缓存，能自动清除或调整
		- 缓存总大小限制，控制无限增大缓存(个数控制，。。。)
		

2. 迭代三记录
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction
		  VmTopNMonitorExecuteActionTest
		  MonitorServiceImplTest

		  norm值，判断指标在指定的region是否支持，大region_no如何处理？
			内部判断region是否为大二层网络，因为现在到以后都会是大二层网络，故这个判断可以忽略。

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day 79 Monday, July 09, 2012

1. 
	* region表取消big_region_no字段，相应修改
	* 迭代三开发

2. 迭代三
	- 查询可用的ISO接口(query_available_isos
		修改补充
	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		VmPageMonitorExecuteAction
		InstanceMonitorInfoDaoImpl
		InstanceMonitorInfoDaoImplTest
	- list_vm_status		
		
	- query_rack
		RackQueryAction
		RackQueryActionTest
		AbstractExecuteAction
	- ID:175051]大region下list_vlans接口
		VlanQueryAction
		VlanQueryActionTest
	- [ID:175052]大region下 query_zones 接口
		返回的region_no改为大region_no
		ZoneQueryAction
		ZoneQueryActionTest
	- ID:175053]大region下 query_regions 接口
		文档返回结果说明需要修改，现在返回的是大region_no
			返回值格式不修改，用大region_no字符串构造region对象，返回；向前兼容
		RegionQueryAction
	- 大region下 add_ip_segment 接口，同时增加zone_no参数
		AddIpSegmentExecuteAction
		IpSegmentService


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day80 Tuesday, July 10, 2012

1. 
	* monitor_vm_topn 接口修改
		VmTopNMonitorExecuteAction
		排序
			Collections
			Arrays
	* 用户体系修改review
		关联到的slb v2用户改造
	* region缓存修改问题
		RegionValuesFactory
	* slb v2 slb region那些地方用到？
	* ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		需求分析

	* ibatis的sql注入问题：在使用##时，采用预编译可以避免sql注入，但用$$时要程序避免sql注入
		order by b.$orderBy$ $order$ 
	* cache修改，涉及到丢失修改的测试用例修改
		openapi模块


2. slb v2 slb region那些地方用到
	- 请求slb后端，需要slb region_no,定位后端请求信息（url之类）
	- 查询流量接口，需要根据slb region_no，调用其对应的monitor库
	- 操作api的rs表时用到slb region_no

3. ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	需求分析 
	slb v2 api ，在region_mapping表通过vm的region_no得到slb的region_no
	，然后，在调用slb后端和查询流量数据时用到这个slb region_no。

	slb v1 版本代码在houyi api的一个包中，属于houyi api project：
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day81 Wednesday, July 11, 2012

1. 
	* 迭代三开发
	* -1007,"desc":  "ip segment is used
		控制系统这个错误码，api层没有定义相应的错误映射，以默认-95，system error返回。暂不改

	* 接口兼容


2. 迭代三
	- ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		前提:
			一个vm大region_no对应slb的一个region_no，他们是一对一关系
		需求分析
		请求参数中region_no为大region_no时	   ，只要在region_mapping表找到对应的slb region_no即可：
			SLB V1用到slb region_no的地方有(houyi库)：
				a. slb流量查询接口，
					slb_monitor_datasource（此表region_no为vm的region_no）
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。

				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					slb_region
			SLB V2 用到slb region_no的地方有（slbapi库）：
				a. slb流量查询接口，
					monitor_datasource
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。
				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					region
	数据订正：
		SLB V1（houyi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
			2）slb_monitor_datasource 表
				订正region_no为大region_no（原来此列值为小region_no）
		SLB V2（slbapi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
	代码修改：
		SLB V1 : 部分代码需要修改，涉及到从vm的region_no得到slb region_no的地方


3. 全局变量设计 ，控制使用范围
	系统全局变量设计时要考虑好，尽量不用或少用，用的不好导致系统各个地方充斥着全局变量调用或设置，
	维护，调试比较麻烦，可通过在上层用，下层通过传参传递，这样也知道一个方法用到哪些参数，不是上层不知道的情况下，
	调用了一个全局变量。个人见解

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day82 Thursday, July 12, 2012

1. 
	* 迭代三修改点 与QA review
	* SLB V2中根据vm的region_no查询slb region_no部分逻辑代码修改
	* SLB V1,V2用户体系分析，新项目准备工作
	* 提测前准备工作：
		HOUYI API , SLB V1 API ,SLB V2 API
		- 表订正

	* iso_resource表增加的小region_no，修改为增加大region_no
		sql修改
			alter table iso_resource add big_region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的大region_no';
		相应要修改的点：
			iso.xml
				对region_no字段加入，需要修改的sql
			IsoDaoImpl 修改 selectUserAvailableIsos方法		
		
	      待改数据库并svn提交 ？
2. 

										     

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day83 Friday, July 13, 2012

1. 
	* 用户体系改造项目设计review
	* houyi api 接口调用用例编写，便于测试
	* 
		
2. vm状态 vm status
	Pending(1, "待启动") 
	Starting(2, "启动中") 
	Running(3, "运行中"), 
	StartFailure(4, "启动失败") 
	Shutting(5, "停止中") 
	ShutFailure(6, "停止失败"), 
	Shutted(7, "已停止"), 
	Released(8, "已释放"), 	     释放后instance表记录保留
	Resetting(9, "重置中") 
	ResetFailure(10, "重置失败"),
	Transferring(11, "迁移中");

3. houyi api 接口调用用例编写，便于测试
	- create_vm接口返回值region_no为小region_no？   是否还有其他的也需要检查
	- 创建的vm，调start_vm状态为pengding，数据库为startfail
	- start_vm start fail 原因？控制系统
		看api调用此接口传递给控制系统的参数，isoName参数为空，因为iso_resource表增加了big_region_no，开发环境没有更新此表。
	- houyi api对取消创建快照接口，控制系统报 cancel failed错误时，api没有映射对应的错误，统一以-95报错	 ，或者是控制系统状态码错误？	
		注：确认为控制系统没有对错误码归类，比如不同错误可能都报-1码 ，有待控制系统返回特定码。
		result: {"code":  -1,"desc":  "cancel failed","isSuccess":  "FALSE"}。
		-95，invoke houyi system error
	- 同上，卸载快照接口，
		code":  -1,"desc":  "umount device from vm failed
		-95，invoke houyi system error
	- query_available_imgs 查询可用的镜像接口，返回值snapshot_id格式没更改	?
		   文档注明返回值中snapshot_id部分废弃，本次代码不动，后续将去掉这个值
	- list_vlans
		-95，invoke houyi system error
		Caused by: com.alibaba.apsara.kuafu.KuafuException: Exception: Message is dropped by KFC, server does not exist
		控制系统服务不正常，在重启

	qa测试：
		cd /home/admin/lix/lix-src/tools  or /home/admin/lix/lix-src/tools/houyiTestFrame/houyiTestFrame
		python2.7 houyiframe.py cases/release_test/bvt_ci.xml test vm_test		or python2.7 houyiframe.py cases/release_test/bvt_ci.xml 22:22
		[root@AT-HOUYIDEV-AG]$me
		Local_Address: 10.250.6.27

		涉及到参数值修改在: bvt_ci.xml test vm_test 中
			cluster_id=27


ZoneServiceImpl


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day84 Monday, July 16, 2012

1. 
	   *  qa bvt测试 ，开发自测
	   * big region项目中，缓存reload接口
		目前有，region，zone，clusterId三块缓存，根据指定的key，reload对应的缓存（用于源数据被修改后，需要同时更新缓存值的目的）
	   
2. bvt测试
	具体执行环境参考day83第3条

3. reload缓存接口，根据缓存类型，调用接口实现对应类型的缓存reload	    ，内部调用接口
	region，zone，clusterId三块缓存
	命名：
		action名： reload_cache
		ReloadCacheAction
		ReloadCacheService
		ReloadCacheServiceImpl
		ClearCacheParameter
			CACHE_MODULE("cache_module",NotEmptyValidator.instance)
		CacheModuleType
			REGION(1),
			ZONE(2),
			CLUSTER_ID(3);
		ServerErrorMessage			  新的错误码，到这里定义
			CACHE_MODULE_IS_EMPTY(-7100,"cache module is empty"),
			CACHE_MODULE_IS_ILLEGAL(-7101,"cache module is illegal"),
			RELOAD_CACHE_MODULE_FAILED(-7102,"reload cache module failed or cache module not found");			
		houyi-spring-action.xml
		houyi-spring-service.xml
			

4. 从StringUtils工具类的选用，看代码耦合 系统设计 工具类设计
	这个工具类在好多第三方包中都有，是直接用还是通过自己项目的工具类再包装下使用？
		为了减少耦合，建议自己做层简单封装，这样对第三方库通过一个入口来管理，即使以后换了实现，也只需要改一个地方即可，不用面临侵入代码
		各个地方的情况。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day85 Tuesday, July 17, 2012

1. 	
	* detail_vm接口 region_no返回为大region_no ？
		修改为大region_no
	* slb v2 用户体系改造
	* slb v1接口测试
		query_available_vips
		QueryAvailableVipsExecuteAction
		IpAddressServiceImpl
			slbRegionService没有注入
		vm region_no找不到slb region_no,报：-95，invoke houyi system error ？
	* list_vm_status
		QueryVmListInfoExecuteAction
		此接口，由于instance对应的image不存在报-90错误
		？是否修改sql，对于image数据错误的记录不返回
		instance.xml 中设置image属性默认值

2. slb v2 用户体系改造 需求分析
	1）代码修改
		支持原有用户验证；并支持新的AliyunIDKP用户方式。
		AliyunIDKP方式：
			请求中有此参数且不为空，表示已鉴权；
			到数据库user表查询此AliyunIDKP，若找不到则新增
		用户信息缓存起来，减少数据库io次数。
	2）数据订正
		涉及的表：user, rs：
			user表的user_id订正为AliyunIDKP的值，订正依据由portal提供，提供原user_id，key,id组合和AliyunIDKP的对应关系；
			rs表，portal提供原user_id，新AliyunIDKP，和rs_pool_name的关系
		订正方式：
			提供执行工具，根据上面的映射关系来更新表
		订正过程：
			（1）依据portal提供的映射关系表（文本方式,格式类似下面，具体格式见实际文本）
				user_id	aliyunIDKP	rs_pool_name
				144		1366		pool1
				144		1366		pool3
				144		1367		pool2
				144		1368		pool4
			（2）通过脚本（python，shell,...）解析上面文本
			（3）执行
				a. 读取第一行，
				b. 取到aliyunIDKP值，
				c. 到user表查询user_id字段是有此 aliyunIDKP
				d. 有则跳过，没有则插入此记录（user_id | user_name | service_secret_key        | service_access_id         | status | is_admin | billing），除了user_id为此	 aliyunIDKP的值外，其他字段和原user_id对应的值一致
				e. 取到 rs_pool_name 值
				f. 到rs表查询此rs_pool_name对应的记录
				g. 无则跳过，有记录，则更新此记录中的user_id值为步骤b得到的aliyunIDKP值，有多条则更新多条（循环执行）
				h. 读取下一行
				i. 继续从步骤b执行 
				j. 循环至末行处理结束

3. python表订正工具
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day86 Wednesday, July 18, 2012

1. 
	*   query_available_vips 接口
		查询时，没有将小region_no转换为大region_no
		QueryAvailableVipsExecuteAction										 s
		IpAddressServiceImpl
	* 用户体系改造项目
		 - 分支见redmine
		 - 订正工具（python脚本实现）
		 - 设计文档
	* 用户体系项目分支
		slb v2 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		houyi api http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_user_reform

2. 

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day87 Thursday, July 19, 2012

1. 
	* 账户体系改造SLB V2相关设计文档编写
	* big region bug fix
	* jteser事务测试
		注意测试框架的事务会影响测试代码事务

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day88 Friday, July 20, 2012

1. 
	* 会议
		防火墙，调度
	* SLB V2用户体系改造设计
	
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day89 Monday, July 23, 2012

1. 
	* SLB V2用户体系改造，根据邮件给出的prd文档，分析
	* big region后续bug提交方式，通过下面的地址建立子任务，并建立对应的bug进行提交：
		http://redmine.aliyun-inc.com/issues/2648
	* 单元测试严格划分职能，对于数据库测试，wiki文件只应出现在dao层中，service层不应该出现（信任dao层），层层完成自己的验证，层间依赖信任
		集成测试情况会跨多个层
	* big region
		- 迭代一周期 ，由于后续变动，需要更新redmine文档
		- device，snapshot，vmAPI这边的权限验证，代码实现  ，具体见redmine新任务 待？

		
2. houyi api白名单
	在配置文件定义白名单ip，spring注入到拦截器等需要校验的地方。
	配置时，多个ip间以“,”逗号隔开，spring注入时，调用set方法注入，在set方法里编写逻辑将ip字符串处理为Map。（通过重写set方法实现指定注入转换）

	也可通过直接在spring配置中配置Map数据。

3.  SLB V2用户体系改造，根据邮件给出的prd文档		  本周完成下面子任务
	- 白名单参考houyi api的实现
		slbapi.properties 配置白名单ip
		AgreementParameter 平台参数验证，session验证改为aliyun_idkp验证
		CheckUserSignInterceptor 白名单验证，注掉以前user_id验证
		GlobalErrorMessage
			新增错误码：ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),


		ServerErrorMessage 错误码定义
			------

				/** server error code **/
				/** -3000 ~ -3099 **/
				
				/** vm FAIL **/
				/** -3100 ~ -3999 **/

				/** snapshot error code **/
				/** -4000 ~ -4999 **/
				
				/** ip error code **/
				/** -5000 ~ -5999 **/

				/**group error code **/
				/** -6000 ~ -6999 **/

				/** admin error code **/
				/** -7000 ~ -7999 **/
			------

		原来用到user的地方需要修改：
			LogInterceptor
				SlbApiLog
			AbstractService
				Rs
				slbapi.sql rs表的user_id字段值为aliyunIDKP，原来是long类型的user_id，故重新定义字段，依据houyi api的user表user_id字段定义：
					aliyun_idkp` varchar(32) DEFAULT NULL, 待确认？
				RsService
				RsServiceImpl
				RsDao
				RsDaoImpl
			LoadBalancerServiceImpl
			查询SLB流量接口
				MonitorInfoDaoImpl
			调用houyi api改动
				ECServiceImpl


	- 原校验机制注释，只采用AliyunIDKP验证机制，是否涉及错误码改动？待检查
	- user表废弃
	- 数据订正：rs表的user_id和rs_pool_name
	- 调用houyi api部分，去掉原有签名（user表已废弃），通过aliyunIDKP方式调用houyi api（houyi api需要将slb api v2加入白名单中）
	- 对于关键点，类编写测试用例
		CheckUserSignInterceptorTest 


4. 设计中，对于id这类的字段，虽然目前是long，后面可能会改为string，设计pojo时最好设计为string类型，
否则后续类型改动，需要改相应接口及实现 设计
	对于某些可预知，后续字段数据类型可能发生变化的场景，设计pojo时考虑好类型，方便后续变动。

5. big region
	校验逻辑梳理：
		
 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day90 Tuesday, July 24, 2012

 1. 
	* 用户体系改造-SLB V2 API
	*  device，snapshot，vmAPI这边的权限验证
		API有user和vm的所属关系（houyi instance表）
		控制系统有VM，device，snapshot之间的所属关系
	* houyi API 与控制系统状态保持
		控制系统状态变化会通知rabbit MQ，API从MQ中得到消息，进行同步 ？	    Message模块中
		通过rabbitMQ java开发包实现
		eg：start_vm控制系统接到后返回200，过一段时间vm启动后，控制系统发消息到MQ,API读取消息，更新vm状态
	* 控制系统重启，导致部分操作成功，部分失败：
		结果之一：一个vm已经stop，但vm表的状态为starting，导致状态不一致。
	* start_vm 控制系统对于vm不存在的情况，不返回结果，API超时返回
	* VmCreateExecuteAction ，在createVM返回空时，instance = (Instance) result.getResultInfo(); 返回了快照对象，导致类型转换错误？
		待修改提交 

 2. 用户体系改造
	- 什么时候可以测试环境连调测试？
		SLB后端
		houyi API
		SLB V2 API
			流量接口
			调用SLB后端
			调用houyi API
	- 数据订正谁来做，portal数据什么时候提供？	     由其他同学负责
	- 测试类
	- 后面的问题在于测试
	- 修改点
		UserDaoImpl.		      废弃
		User			废弃
		UserStatus		废弃
		slbapi-ibatis-config.xml 修改
		UserServiceImpl 废弃
		RequestContext 修改
		UserService  废弃
		LoadBalancerServiceImplTest  修改
		AbstractServiceTest 修改
		User.xml 废弃
		spring-dao.xml 修改
		spring-service.xml 修改

 3.  device，snapshot，vmAPI这边的权限验证
	下面3个接口，暂定由API将必要消息传给控制系统，控制系做资源所属验证：
		a. API层验证user和vm的所属关系。
		b. 由控制系统来判断资源间的所属关系（vm，device，snapshot）

	- [ID:182636 ]retain_snapshot 安全风险 用户可retain其他用户的snapshot
		RetainSnapshotExecuteAction

		需求：用户进行retain快照操作时，检查快照是属于当前用户的
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		此接口，只传递了device_id和snapshot_id
			修改，将vm_name也传递到控制系统，由控制系统来验证vm，device，snapshot之间的所属关系

	- [ID:182495]remove_snapshot 安全风险 可以删除其他用户的snapshot
		RemoveSnapshotExecuteAction
		需求：用户只能删除自己的snapshot
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		[call houyi system. method:RemoveSnapshot,parameter:{"snapshot":"520322test","vmName":"mytestvm2012-2","deviceId":"817"}]
			给控制系统有VM名称,快照ID和设备ID
	- [ID:182101]cancel_create_snapshot时传入的vm_name和snapshot_id不匹配时没有报错
		CancelCreateSnapshotExecuteAction
		[call houyi system. method:CancelSnapshot,parameter:{"snapshotId":"520322","vmName":"mytestvm2012-2"}]
			传给控制系统 快照ID和VM名称，是否应该控制系统验证所属关系？API去验证的话就需要多一步查询控制系统步骤，最后验证还是由控制系统决定。
	- detail_snapshot需要判断snapshot是否属于该用户
		经查看代码，已有验证，跳过
	- umount_snapshot需要判断vm与device判断，device与snapshot判断
		UnmountSnapshotExecuteAction
		经查代码（region.isUpgrade() ==1），已有验证（跳过detail_snapshot接口去控制系统查询了下，这个接口vmName也是传递给控制系统的，对于这种有vmName的情况，
		vm对应的资源所属验证统一交由控制系统处理，API只保证
		user和vm的所属关系？）
		region的isUpgrade判断目的是什么？
			确定的是没有升级的region，快照没有userId字段，不需要验证快照与user的关系

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day91 Wednesday, July 25, 2012

1. 
	* big region
		list_mounted_snapshot接口，返回值中，snapshot_name内容是snapshot_id，如何转换为3元组？
		
	* 用户体系改造
		加入jtester测试框架，便于单元测试
			

	
			
2. list_mounted_snapshot 接口处理snapshot_name为cluster_id-device_no-snapshot_id三元组方式
	确认为API返回的snapshot_name值为snapshot_id，三元组构成，可以通过从控制系统返回结果中得到snapshot的deviceNo，
			从vm得到其clusterId，构造成：cluster_id-device_no-snapshot_id三元组整体返回。
			问题：
				返回结果中的deviceNo是快照挂载上去后，生成的新device的deviceNo,不是快照原来的deviceNo，这样对于用户来说，snapshot_id发生了变化，故不能从返回值的deviceNo拼接三元组
			解决：
				根据控制系统返回的快照id去查询其deviceNo,以拼接三元组返回？
					去detail_snapshot,
						具体见邮件：增加一个snapshot_id的属性，为了兼容性考虑目前保持snapshot_name与snapshot_id一致
	ListMountedSnapshotExecuteAction
		？待测

3. 可用的image ，测试
	select 
		image.image_no,
		image.region_no as imageRegionNo,
		inst.region_no as instanceRegionNo 
	from image image,instance inst 
	where image.image_id=inst.image_id limit 1,2;
	加上user，大region条件，筛选可用image。

4. 高亮显示光标所在字符或字符串
	命令行模式下：
		*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。

	和 /text 方式查询类似，但可根据文本内多次直接搜索，不需输入检索字符串。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day92 Thursday, July 26, 2012

1. 
	* big region 测试用例验证，修改
		http://10.250.8.214:81/surefire-report-dao.html		   fixed
		http://10.250.8.214:81/surefire-report-service.html	   
		提交ID:
			[ID:183748]完善测试用例
	* list_mounted_snapshot接口测试用例修改，提交代码
	* houyi api
		控制系统返回的对象类型定义在各自的command实现类中，可以查看API与控制系统交互的数据格式
		确认rpc返回的pojo类类型。
	* SLB API V2用户体系改造，调用SLB后端的user_id名称不变，只是值为aliyun_idkp
	* SLB API V2流量查询接口，查询的时间早于计量库保存记录的时间点，导致计量库找不到对应的表，API报：
		code":-2001,"msg":"backend service exception
		是否要修改？要知道计量库的表设计逻辑，比如保存几天的记录表？这里跨系统访问数据库，不是接口，导致此类依赖问题
			接口说明是7天，那么需要判断从当前时间往前6天供7天的表是有的，超出这个范围的是没有记录的，API需要做判断，并加入对应的状态码？
				或者超出时间的直接返回空？
				计量库 原lb_global_id改回为lb_id?
					这是旧的库，新库地址：
						mysql -uhouyi_odbs -phouyi_odbs -hmy3306.mysql.aliyun.com xuanyuan

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day93 Friday, July 27, 2012

1. 
	* 用户体系改造	
		涉及到list_vm_status接口改动
	* 	业务熟悉
		技术：多线程，并发，性能，服务器编程，重构
		
	* houyi api 数据推送模块后续重构
		考虑使用独立的缓存系统（比如，memcached），可以在API上抽象出操作缓存的接口，
		可以针对不同的缓存框架使用对应的实现，比如通过操作memcached的接口，操作memcached缓存
	* detail_vm接口问题
		当vm release过后，调detail_vm接口报：-90 system error
		文档没有说明不能查询released的vm
		原因为代码处理问题导致空指针。fixed
		
2.  用户体系改造
	- portal查询vm状态接口，由于此次用户改造，原有的根据144大用户取得其卖出的所有vm状态信息的功能已经不能用（已拆分为子用户，然后没有用户组等关系来
		判断子用户属于哪个大用户；目前，vm主要包含portal和万网的vm，还有少量的其他用户的vm，暂定为在查询用户所有vm状态的接口逻辑里，以硬编码aliyunIDKP方式判断是portal的请求还是
		万网的请求，portal的请求就返回除了万网的所有vm信息，万网的请求只返回万网的vm信息）
	
		问题：
			如何区分IDKP是不是portal来的IDKP？
				设置专门对原144的IDKP值，API根据此值可以知道是否为portal的请求。

		需求变动，验证方式为key方式+白名单方式，即先需要经过key验证（通过在user表继续保留144账户），
		然后判断是否有AliyunIDKP值，如果有继续处理，如果没有处理逻辑待定（判断为管理调用，返回所有接口的所有内容？）
			上面的返回所有内容问题缘于之前是144用户的所有数据，现在切分为一个个独立的IDKP对应的数据，现在要返回这个大用户下所有IDKP账户对应的数据。这样portal需要遍历每个
			IDKP去Houyi API取数据，原来一次即可，如何解决？
				提供一个接口，能根据portal传递过来的IDKP列表批量返回对应的数据。							

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day94 Saturday, July 28, 2012

1. 
	* big region
		排查涉及 RegionHolder.getCurrentRegion() 语句的代码，此代码得到的小region_no可能为用户默认region_no。
			eg：用户为HZ用户，需要到BZ的大region中create_vm，传入的是BZ的大region_no，而小region_no却默认到HZ了？
				可以根据大region_no得到其默认操作的小region_no（）
				检查用到用户小region_no的点
	* 用户体系改造，user表加入代理商ID字段，标识子用户属于哪个代理商
		- 所有请求都需要先经过签名认证
		- 白名单配置代理商ID（IP会存在改变的问题）
		- 没有传AliyunIDKP值，则用户类型为代理商用户，返回结果时需要处理，返回代理商下所有子用户的数据（涉及到的接口由PD整理）
		- 传递了AliyunIDKP的	 ，判断user表是否已有记录，没有则增加记录（代理商ID根据白名单配置），有则继续操作。
2. 
													      


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day95 Monday, July 30, 2012

1. 
	* 用户体系改造，流程图ok
	* big region 
		- RegionAwareInterceptor 的region缓存替换为RegionCacheManage的统一方式
		- RegionAwareInterceptor中，用户传入大region_no时，设置小region不能用user的默认小region,改为从大region的小region列表中取第一个。
			排查代码用用到regionHolder中默认小region的点。
				RegionHolder.getCurrentRegion().isUpgrade()
				boolean isBigEtherNetwork = RegionHolder.getCurrentRegion().isBigEtherNetwork()
				list_vlans接口
					有region_no和zone_no
					ZoneServiceImpl
			提交修改后，在开发环境验证功能
				
	* SLB V2 用户体系改造，构建目录，deploy目录设置好，便于部署
		http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/build.sh

		svn checkout 部署目录：			nginx+tomcat
			在/home/admin/slbapi目录下：
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi
				sh build/build.sh
				sh bin/tomcatctl start
		
		部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
			
			小结：
					当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
				启动失败了，即服务器是起来了，但应用确没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
				ok的情况下极可能就是应用启动失败）。
					这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。
			
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day96 Tuesday, July 31, 2012

1. 
	* big region bug fix
		- 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。

	* 用户体系改造，SLB API build脚本
		当前的方式，需要在部署机去build，可能会因为网络不通等问题导致依赖找不到，编译失败，通过先build再分发的方式解决此问题，也是build机的用意。
		参考已有build过程
	* 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	* big region
		create_vm等接口流程（在原有基础上加上了调度，防火墙的逻辑）
	* SLB V2 在大region项目中的变动
		兼容用户小region_no请求？待
		维护小region_no到大region_no的映射，在请求传入时，将小region_no转换为大region_no。
	* big region
		计量推送，region_no改为大region_no？待
	* 10.230.204.24 部署slb v2 user_reform环境
		在slbapi-user-reform目录
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi .
			删除src目录下的所有内容
		修改build/build.sh的svn地址为 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		sh build/build.sh
		修改spring配置文件中的属性文件路径：默认为 ${user.home}/slbapi/conf目录下
			在src下修改spring配置，然后mvn build
		配置白名单
			slbapi.properties
		通过各自项目的nginx.conf,mime.type文件，启动自己的应用监听。	    （不推荐，这样会导致端口修改，2个独立的nginx进程不能共享同一个端口）
		下面，通过配置转发规则，让多个应用公用80端口：
		 ---------
			  ...
				   server {
					listen       80;
					server_name  openapi.aliyun.com;

					charset UTF-8;

					proxy_connect_timeout 600;
					proxy_read_timeout 600;
					proxy_send_timeout 600;

					#access_log  logs/host.access.log  main;

					if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
					{ 
					  set $domain $1; 
					  set $new_uri /openapi/$domain$request_uri;
					} 

					location /{
					    proxy_set_header        X-Real-IP $remote_addr;
					    proxy_set_header        Host $host;
					    proxy_pass http://127.0.0.1:8080$new_uri;
					
					}

				       location /slb/api{
						   proxy_set_header        X-Real-IP $remote_addr;
						   proxy_set_header        Host $host;
			...
			---------
			此方式，先验证后端服务启动正常，再验证nginx转发正常，因为后端的错误可能不能从nginx的相应内容中直接看到，比如后端tomcat返回404，nginx给你的可能就是
			空白。

2. 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。
	AbstractExecuteAction
	SingleNcResourceAction
	SingleNcResourceActionTest
	CancelCreateSnapshotExecuteAction
	CancelCreateSnapshotExecuteActionTest
	CreateSnapshotExecuteAction
	CreateSnapshotExecuteActionTest
	DetailSnapshotExecuteAction
	DetailSnapshotExecuteActionTest
	ListSnapshotExecuteAction
	ListSnapshotExecuteActionTest
	MountSnapshotExecuteAction
	MountSnapshotExecuteActionTest
	RemoveSnapshotExecuteAction
	RemoveSnapshotExecuteActionTest
	RetainSnapshotExecuteAction
	RetainSnapshotExecuteActionTest
	RollbackSnapshotExecuteAction
	RollbackSnapshotExecuteActionTest
	UnmountSnapshotExecuteAction
	UnmountSnapshotExecuteActionTest
	VmCreateExecuteAction
	VmCreateExecuteActionTest

3. 用户体系改造 houyi api
	user表修改，sql修改：
	alter table user add is_agent tinyint default 0 COMMENT '@desc 0 不是代理商，默认为0;1 是代理商';
	alter table user add agent_id int(10) unsigned DEFAULT null COMMENT '@desc 代理商ID，表示子用户属于哪个代理商';
	alter table user add image_using_mode int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted;1 : only private image permitted';
	alter table  user  add  image_using_mode  int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted ; 1 : only private image permitted';

4. userholder 加标识isGent，标识用户身份。
	user插入逻辑确定：

5. 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	- user表增加字段，参看第3条
	- 修改user表改动涉及的类改动，mapping文件改动
		user.xml
		User
	- UserHolder不变，存入的是代理商用户还是最终用户需要根据user的isgent属性判断
	- 老userId方式调用时，订正表时，isagent要标记为0，即非agent用户（比如万网）
	- 兼容老userId方式调用（isgent=0，但agent_id为空），新aliyunIDKP调用，管理接口调用（取得对应的子aliyunIDKP账号）
	- 新aliyunIDKP插入user记录，字段定义：
		aliyun_idkp
		key
			沿用其代理商的key，自己的key字段为空
				由于原user表字段约束，某些字段必须设置值（或者修改表约束，暂定位不动约束）
				user默认值：insertSql = " insert into  user ( default_region , default_zone , aliyun_idkp ,  user_name ,  md5_password ,  service_secret_key , email ,  service_access_id ,  status ,  gmt_last_login, agent_id ) 
											values('cn-hangzhou-1','cn-hangzhou-1-a', $idkp, $idkp, $idkp, $idkp, 'developer@aliyun.com', $idkp, 0, now(), 144) ; "
		region_no
		zone_no

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day97 Wednesday, August 01, 2012

1. 
	* 用户体系改造，houyi api
	* 用户体系改造，SLB V2 api
	* 大region，slb v2兼容小region

2. 用户体系改造，houyi api
	- 是否为管理接口调用的判定？在白名单且aliyunidkp值为空
	- 在判断IDKP是否为空前，增加判断，请求的接口是否必须IDKP参数值
		在哪里判断？通过配置文件还是其他方式标识
	- 搭建 houyi api user_reform版本开发环境， doing
		10.250.8.214
	- 	- 万网等非白名单用户，数据表订正时，标识为非agent用户，即isagent=0（万网等非白名单用户，和以前一样没有切分子用户）


		
3.  用户体系改造，SLB V2 api
		需求待确定，SLB v2都需要做签名验证？
			user表存基本的验证必须字段，aliyunIDKP透传和调用。
			slb v2 api请求vm api和原来一样，走签名

4. 大region，slb v2兼容小region
	兼容用户大小region_no请求，小region_no转换为大region_no；
	传递给SLB后端为大region_no；
	后端接受的是大regionNo,对其数据推送影响？待确定
	- sql修改
		alter table region_mapping add vm_big_region_no varchar(32) NOT NULL COMMENT '@desc vm big region no',
		一个vm小region_no对应一个vm大region_no，一个vm大region_no对应一个slb region_no。
		修改约束，slb region_no与 vm_big_region_no联合主键：
			alter table region_mapping drop primary key
			alter table region_mapping add constraint primary key (region_no,vm_big_region_no);
		region_mapping表维护：
			vm小region_no和vm 大region_no关系，
			加上vm大region_no和slb region_no关系，2种关系。
			
	- region拦截器中中处理大小vm region_no请求兼容问题：
		将小vm region_no转换为大vm region_no后放入threadlocal中，
	- SLB API调用需要lb所属的vm region_no，SLB API调用SLB后端只在create_loadbalance接口传入了vm的region_no。8/1/20128/1/20128/1/2012
	- 兼容大小vm regionNo调用程序要处理的有两个地方：
		a. 由vm regionNo取到对应的slb reigon，从而知道slb region调用信息
		b. create_loadbalance接口需要将vm大region_no传递给SLB后端
	- bug id：[ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	- 修改结束后，用 AbstractServiceTest 类测试几个接口，验证修改逻辑。	
	- 大region中SLB V2 API没有分支，提交的代码需要回滚，重新拉分支提交，待处理？


sudo bash root

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day98 Thursday, August 02, 2012

1. 
	* 用户体系改造 houyi api
		提供管理者调用功能，
		修改的点：
			- 签名验证逻辑实现完善
			- 白名单userid配置，以区别是idkp调用还是老接口调用及是
				配置到spring文件中（List便于判断是否存在）
			- 配置必需待IDKP参数的接口，即不提供管理功能的接口
				配置到spring文件中（List便于判断是否存在）
				必须带IDKP参数的接口，在拦截器中就判断后，如果没带返回错误；对于业务接口调用不用修改、
				业务接口不需修改的接口列表：
					1) 创建VM 
					2) 创建自定义image  ： A, 用户自定义image， idkp为用户id；B,对外售卖的自定义镜像， idkp指定为：26842
					3) 新增硬盘 
					4) 创建Group
					5) 创建快照 
					6) 创建Key Pair
			- 对于其他接口，都需要处理管理接口调用
				业务接口需要修改
			- 资源check类中（instance,ip,...ResourceChecker ），增加代理商调用处理逻辑，如果是代理商调用，且资源所属用户的代理商
				check列表：
					InstanceChecker
					GroupChecker
					ImageUseChecker
					IpAddressChecker

			- 对于有管理功能接口的修改，支持返回代理商下面所有用户对应原接口的数据
				以list_vm_status接口为例。
				查询数据时，原来根据user_id筛选；现在对于代理商调用，需要返回代理商下所有用户的数据。
			- 对于接口返回值，代理商调用和最终用户调用（老user_id方式比如万网，待IDKP值的用户）的区别
				类似detail_vm(指定了vm)，list_snapshot（指定了device）接口，指定了资源操作的接口，返回的是资源所属的信息（不存在跨代理商的子用户）
				类似list_vm_status（指定用户），指定用户去操作用户的数据的接口，代理商去调用时，返回或操作的是代理商下所有用户的数据
			- 对于代理商，也分配有IDKP，如果传入的是代理商自身的IDKP，视为最终用户处理
				在返回代理商所有用户的数据时，还需加上代理商自身的数据（能否通过将代理商的agent_id设置为其自身一个sql解决？）
			- 对于万网这些没有进行用户改造的用户，数据订正时，标识为非代理商用户。
			- session拦截器取到用户后，需要判断其is_agent值为1（是代理商），这层check是因为最终用户的session_id列也是有值的（现在订正为用户的idkp），如果其传session_id为自身
			的idkp时，会误认为其实代理商。
				上面方式兼容万网等老用户调用有问题（万网is_agent=0）,判断代理商条件修改为：能根据session_id找到用户且其service_secret_key值不为空
				
			- houyi api数据库的user表，service_secret_key字段去掉不为空约束，对于代理商的子用户，此字段为空
			- 配置白名单和action必须带IDKP的配置文件为：/houyi-console-openapi/src/main/resources/houyi-openapi.xml


	* 用户体系改造 SLB V2 API需求列表：
		- 所有请求都需签名验证（和用户体系改造前的验证一样）
		- 只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的key）
		- 原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
		- rs表数据订正

2. 用户体系改造 houyi api  —— 参考第一条说明
	管理接口修改：
		- detail_vm
			VmQueryExecuteAction
			getInstanceService().viewInstanceAtNc(instance); 做权限验证（注解方式），需要修改：
				修改check包下对应的 InstanceChecker 
				
			ResourceChecker抽象类中加入user cache，便于子checker调用。

			InstanceChecker 修改，后面vm验证所属用户操作都会用这个checker，不再做说明
			
		- list_vm_status
			先
	
	acl模块与service模块相互引用，导致依赖循环，如何解决？
			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day99 Friday, August 03, 2012

1. 
	* 用户体系改造，houyi api
		- 解决maven循环依赖问题，将依赖的接口独立到一个接口模块中，接口的实现在其他模块中
			mvn a
		- cache方式，
	* 大region项目
		涉及SLB V2 API改动点，需要另开分支提交，不在下面分支提交，对已提交的兼容大小region_no调用修改进行回滚：
			http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 用户体系改造 SLB V2 api 代码回滚，提交后，将需要修改的地方再reversion回来
		

2. 用户体系改造 houyi api 
	    管理接口修改
		check修改
			ipAddressChecker
				isBinary 判断ip是否为网段
		- list_vm_status			列表接口
			限定条件：
				region_no	必选	string		云服务器所属于的Region
				zone_no	必选	string		云服务器所属的可用域
					zone如果没传，取代理商的默认zone，保持原接口一致
			QueryVmListInfoExecuteAction
				是代理商时，去掉一些限定参数（如zone_id）	      ,不去掉，代理商也需要传
			instance.xml
				where条件里加上代理商查询条件，关联user表，查询出代理商所有子用户的数据
					传参时需要处理
			InstanceServiceImpl. 的 queryOwnInstances方法
				涉及传入user筛选条件的地方需要修改（处理代理商调用条件）。			
					数据订正逻辑？万网关联user_id字段，得到其instance列表；传入IDKP值的用户，也是关联user_id字段？
						数据订正案例：业务方提供aliyun_idkp和vm_name的映射表，订正工具到user表加入此idkp对应的用户（user_id为自增值）记录（如果没有的话），然后
						把user_id这个自增值更新到instance表对应vm_name的记录。
			修改的sql是否会被多个dao层调用，加入了agent_id筛选条件是否会影响其他调用此sql的逻辑？
				控制传入agetn_id的入口，即agent_id是显式的传入的，调用者知道传入agent_id会返回什么样的结果。
					当前设计，只好在dao层还去取user信息，后续需要重构，参数从service传过来，dao层不做过多依赖 -tip-
						在原有的statement上在加上分支查询逻辑，不利于维护，后续需要修改。
			InstanceDaoImpl
		- start_vm
			VmStartExecuteAction
			InstanceServiceImpl
				addUrlCallback方法中，当是代理商调用时，不能取UserHolder.getCurrentUserId()用户，暂定用instance对象的user_id属性，待确认？
					后面需要搜索整个项目用到：UserHolder.getCurrentUserId() 和 UserHolder.getCurrentUser() 的地方，确认调用是否ok？
				每个操作过后，把回调信息存入houyidb的url_callback表。
		- stop_vm
			VmStopExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法
		- restart_vm
			VmRestartExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法


3. 用户体系改造bugfree
	http://bugfree.corp.taobao.com/bug/list/156?productmodule_id=12215


4. 系统设计tip
	- maven开发时，模块划分，在依赖方便需要设计好，可以剥离接口和实现到不同模块，避免交叉依赖问题
	 - 方法的参数设计，需要利于扩展，比如增加或减少参数，或不同类型的参数等需求。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day100 Saturday, August 04, 2012

1. 
	* 
2. 用户体系改造 houyi api 
	重要：
		- 原用到UserHolder.getCurrentUser() 或 UserHolder.getCurrentUserId()的地方，都需要考虑user不是最终用户的情况了。	     （幽灵般的userholder~~~）
		- 代理商调用时，regionNo需要模拟最终用户的调用，否则会取代理商自身的默认region去操作。
		- describe_vip接口属于slb v1接口，不需要处理
	管理接口修改
	- release_vm
		VmReleaseExecuteAction
		InstanceServiceImpl
			releaseInstances方法，释放的VIP时需要传入user_id
				暂改为instance的user_id，即销毁vm时，vm的vip和vm的user_id一致。
			修改的点：
				GetVIPInfoCommand
				IpAddressServiceImpl
				IpAddressService
	- reset_vm
		VmResetExecuteAction
		ImageDaoImpl
			selectImageByNos方法在dao层，调用了threadlocal中的user，建议从调用层传参过来，避免各层充斥这全局变量。
			修改多个点：
				实现查询资源带user信息
		InstanceServiceImpl
			getInstanceService().addUrlCallback(instance, url,Message.statusSync);
	- reset_passwd
		VmResetPasswdExecuteAction	       
	- modify_vm
		VmModifyExecuteAction
	- modify_flow_limit
		VmModifyFlowLimitExecuteAction
	- modify_hostname
		ModifyVmHostNameAction
	- create_image
		CreateImgExecuteAction
		因为必带IDKP值，故userholder中的user为end user，业务逻辑代码不需修改
	- remove_image  ？
		先查询image和user关系，然后删除，代理商去查询image是否存在时，是否会存在返回多个image的情况，
		即：imageNo+end userId是唯一的，imageNo+agent userId不唯一，可能会删除过个子用户同名的image，待确认？
			加个参数标识代理商所操作的用户ID？targetAliyunIdkp
				加个resource_owner参数（值为IDKP），以便代理商告知api其操作资源的目标用户是谁
					错误提示：resource_owner不能为空
						RESOURCE_OWNER_IS_EMPTY(-8000,"resource_owner must set")	resource_owner参数值为空或没传
						RESOURCE_OWNER_NOT_EXISTS(-8005,"resource_owner not exists") resource_owner对应的用户找不到
		RemoveImgExecuteAction
			if(image.getUserId() != UserHolder.getCurrentUser().getUserId()){ 修改增加处理代理商调用逻辑
		ImageServiceImpl
			增加方法：queryImageDetailByImageNo(String image_no,Long userId)
	- recover_vm
		VmRecoverExecuteAction
	- query_available_ncs
		QueryAvaliableNcsExecuteAction
	- query_available_isos	 列表接口
		QueryAvaliableIsosExecuteAction
		IsoServiceImpl 
			加入代理商查询逻辑
				新增代理商查询业务接口
			修改点：
				IsoDao
				IsoDaoImpl
	- mount_iso
		VmMountIsoExecuteAction
			
		


3. 通过方法拦截器结合注解来实现权限验证，设计的好，是个好的方式。	   设计 -tip-
		将日志记录，性能统计，安全控制，事务处理，异常处理等代码从业务逻辑代码中划分出来，通过对这些行为的分离，
	我们希望可以将它们独立到非指导业务逻辑的方法中，进而改变这些行为的时候不影响业务逻辑的代码。

4. 业务逻辑堆在action层，导致依赖变动复杂
	

5. 读取Houyi配置信息发生错误，装载Endpoint信息不能为空
	houyi api启动时会初始化到控制系统的endpoint对象，需要提前在数据库配置好。
	at java.lang.Thread.run(Thread.java:619)
Caused by: com.aliyun.houyi.clc.CLCConfigException: 读取Houyi配置信息发生错误，装载Endpoint信息不能为空！
        at com.aliyun.houyi.service.support.CommandExecutorFactory.afterPropertiesSet(CommandExecutorFactory.java:88)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1369)

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day101 Monday, August 06, 2012

1. 
	* big region bug fix
		调用cancel_create_snapshot时传入的vm和snapshot不匹配时，报-95
	* 用户体系改造-houyi api修改
	* 用户体系改造，slb api 需求列表，最后修改整理说明，便于调用方知晓 待？

2. 用户体系改造-houyi api修改
	- mount_iso
		VmMountIsoExecuteAction
			增加处理代理商操作逻辑，此类验证逻辑代码后续可以移到service层，或者再抽取，提到切面中去。-tip-
	- unmount_iso
		VmUnMountIsoExecuteAction
	- add_disk
		AddDiskExecuteAction
	- remove_disk
		RemoveDiskExecuteAction
	- shift_disk
		ShiftDiskExecuteAction
		------
		...
		@Authority(
			{ @Entry(action = Action.VM),
					@Entry(action = Action.VM, resource = @Resource(argNo = 1)) })
			@InstanceStatusConstraint(statusSet = InstanceStatusSet.canRecover)
			public Result<?> shiftDisk(Instance instance, Instance srcInstance,	  权限验证，多个entry，后续指定位置
		...
		-------
	- detail_vm
		VmQueryExecuteAction
	- query_vm_security
		QueryVMSecurityExecuteAction
	- query_available_imgs			     列表接口
		是否需要带目标用户去查？
		查询代理商可用的image，这个结果是否为业务方需要的结果？
			暂定返回代理商下所有的
		ImgQueryExecuteAction
		ImageServiceImpl 增加代理商查询可用image逻辑
		imageUsingMode对结果的筛选逻辑？	代理商查询时，设置默认
			0 : default 可以使用公有image和自建image   1 : 只使用自己的image
	- query_unassigned_ips			 列表接口
		QueryUnassignedIpsExecuteAction
		user_id需要传给控制系统，结果如何返回？分页返回	，代理商调用返回public的ips
		注意：ip相关接口，user_id都传递给了控制系统，api层不能通过代理商调用
	- assign_ip  ？
		确认houyi db的subnet表，原user_id=144的记录，是否都订正为public？如果是这样，那么传递代理商ID给控制系统即可。
			这样接口就不需要修改，代理商传递代理商的userId给控制系统
		AssignIpExecuteAction
		IpAddressServiceImpl
			assignIpAddressCommand 需要带user_id	   ？？
			ipStatusCanOperate方法代理商调用逻辑添加
	- release_ip	？
		ReleaseIpExecuteAction
		ReleaseIpAddressCommand 需要带user_id操作，必须传IDKP？
	- bind_ip	    ？
		BindIpExecuteAction
		BindIpAddressCommand 需要user_id到控制系统		？
	- unbind_ip     ？
		UnBindIpExecuteAction
		UnbindIpAddressCommand 需要user_id传递给控制系统 ？
	- open_ftp_pasv
		OpenFtpPasvExecuteAction
		IpAddressServiceImpl
			非大二层网络下，需要判断用户是否可用ip
				ipStatusCanOperate方法，增加代理商调用处理逻辑
	- add_ip_segment			 ？
		AddIpSegmentExecuteAction
		大二层，AddIpSegmentCommand需要传user_id到控制系统，代理商如何调用	      ？
		非大二层，IpSegmentServiceImpl 的addIpSegment方法执行添加操作时，需要user_id ？
		解决：
			类似create_vm接口，必须传IDKP？
	- add_dns_alias
		AddDnsAliasExecuteAction
	- del_dns_alias
		RemoveDnsAliasExecuteAction
	- monitor_vm
		VmMonitorDataQueryExecuteAction
	- monitor_vm_topn	       doing
		VmTopNMonitorExecuteAction
		需要到monitor库去查询，哪里的表没有agent_id字段，只能在api层遍历agent对应的所有user，然后去查询
		monitorInfo.xml

	- create_group
		必须传IDKP
	- authorize_group		  
		AuthorizeGroupExecuteAction
		AbstractGroupAuthExecuteAction
		需要知道用户所拥有的group，代理商调用没有目标用户标识？
			根据之前查询出来的group，找到userId，保证源group都是属于这个userId的（原逻辑是直接传userHOlder.getCurrentUser().getUserId()）
	- revoke_group 撤销group规则	     
		RevokeGroupExecuteAction
	- adjust_group_auth
		AdjustGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 方法增加代理商查询子用户数据逻辑
	- remove_group
		RemoveGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 
	- detail_group
		DetailGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupWithAuthes方法增加代理商调用处理逻辑
	- query_groups			   列表接口
		QueryGroupsExecuteAction
		GroupServiceImpl
			viewOwnGroups方法增加代理商调用逻辑
	- guard_ddos
		GuardDDoSExecuteAction
		对ip进行操作
		IpAddressQuerier 查询出ip资源（需要user_id）	     结合ipaddresschecker
			public Map<String, IpAddress> query(String[] businessCodes) {
	- unguard_ddos
		UnguardDDosExecuteAction
	- query_vm_device
		QueryVmDeviceExecuteAction
	-  create_snapshot
		必须带IDKP
	- cancel_create_snapshot
		CancelCreateSnapshotExecuteAction
	- retain_snapshot
		RetainSnapshotExecuteAction
	- list_snapshot device的所有snapshot列表
		ListSnapshotExecuteAction
	- detail_snapshot
		DetailSnapshotExecuteAction
	- list_mounted_snapshot
		ListMountedSnapshotExecuteAction
	- remove_snapshot		imageService没注入？	     spring在配置文件中声明自动注入
		RemoveSnapshotExecuteAction
	- rollback_snapshot
		RollbackSnapshotExecuteAction
	- mount_snapshot
		MountSnapshotExecuteAction
	- unmount_snapshot
		UnmountSnapshotExecuteAction
	- query_nc_resources	 查询集群的nc资源信息（regionNo中的zone_id范围）
		ClusterNcResourceListAction
	- detail_nc
		SingleNcResourceAction
	- query_regions		？
		 RegionQueryAction
		 RegionSQL.xml 的 Region_listRegion 块带了分页参数，接口中无分页参数说明？
	- query_zones	  查询指定集群下的Zone信息
		ZoneQueryAction
	- query_racks 查询指定region,，指定zone下rack列表
		RackQueryAction
	- list_vlans	  查询指定集群的Zone下的VLan信息 ？
		VlanQueryAction
		GetVlanListCommand 需要传递user_id？
	- query_instance_type	  查询云服务器类型
		QueryInstanceTypeAction
	- create_key_pair
		必须传IDKP
	- remove_key_pair
		KeyPairRemoveExecuteAction
		KeyPairServiceImpl
			public ErrorCode removeOwnKeyPair(String keyPairName) { 增加代理商处理逻辑。
	- describe_key_pair
		KeyPairDescribeExecuteAction
		KeyPairServiceImpl
			修改describeOwnKeyPair方法，增加代理商调用逻辑
	
3. image ,iso,snapshot三者关系
	image为用户自定义image，系统盘
	iso镜像为数据镜像，可以被挂载。

		image为系统盘，iso可以是数据盘，也可以是系统盘，可以挂在到vm上

		vm基于image创建,imagej基于系统盘快照创建，iso就是系统光盘具有配置脚本，image没有配置脚本；vm通过iso修复。

		业务：iso类似系统光盘，挂在在光驱上，只读

4. 权限	，权限体系结构之一
	级联权限关系
		有了vm的操作权限，默认就有对vm已有资源的操作权限，比如卸载快照，查询其ip信息等

5. pojo
       BaseDomain中的动态字段，维护一个map，动态添加字段，这种方式用pojo传递动态新增的属性值到其他层。
	dynamicFileds

6. 用户体系改造，houyi api测试环境
	http://10.250.8.214/open/service?action=detail_vm
	部署的tomcat报内部错误：
		500 
		The server encountered an internal error () that prevented it from fulfilling this request.
		java.lang.NullPointerException
	org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
	com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
	org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
	org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
	com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
	org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
	org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
	org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
	org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
	是不是服务器文件不完整？
	请求路径错误，应用的struts拦截器抛错，没有log，定位struts没找到执行的action，
	nginx + tomcat
		nginx负责把符合要求的uri请求转发给tomcat，tomcat自己配置接受处理的uri。

	MQ配置
		message.properties
	EC配置（控制系统）

	配置文件目录
		/home/admin/.houyi/
	EC日志查看
		root@houyi-vm17.dev.sd.aliyun.com # vim /var/log/houyi/master/HouyiMaster.LOG
		10.250.8.212
7. nginx + tomcat
	请求uri设置，在nginx的conf配置文件里，告诉那些uri需要proxy_pass到目标应用服务器地址即可，nginx直接把请求转发给应用服务器。

8. ip,vlan 资源的userId在控制系统维护，依赖性增加

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day102 Tuesday, August 07, 2012

1. 
	* 用户体系改造 hoiuyi api
		remove_image最终定为加上 resource_owner标识最终用户
	
2. 处理day101第2条带问号的接口
	
3. linux + tomcat7 + houyi api		  ，500 internal error 1990 
	http://10.250.8.214/open/services
		正确URI
	http://10.250.8.214/open/service
		这个路径由于struts没有配置此action（请求的uri找不到映射的action，即找不到servlet），导致在struts的自带拦截器：
			 <interceptor name="prepare" class="com.opensymphony.xwork2.interceptor.PrepareInterceptor"/>
			执行时，浏览器报：500 java.lang.NullPointerException 空指针错误，
			错误如下：
				----------
					HTTP Status 500 -
					type Exception report
					message
					description The server encountered an internal error () that prevented it from fulfilling this request.
					exception
					java.lang.NullPointerException
						org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
						com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
						org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
						org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
						com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
						org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
						org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
						org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
						org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
				----------
			debug进入源码分析：
				----------
				    protected void prepare() {
					String profileKey = "create DefaultActionProxy: ";
					try {
					    UtilTimerStack.push(profileKey);
					    config = configuration.getRuntimeConfiguration().getActionConfig(namespace, actionName);

					    if (config == null && unknownHandlerManager.hasUnknownHandlers()) {
						config = unknownHandlerManager.handleUnknownAction(namespace, actionName);
					    }
					    if (config == null) {
						throw new ConfigurationException(getErrorMessage());
					    }		
				----------		
				在找不到  config 时抛出了ConfigurationException。

		从上面错误结果看，程序已经执行到houyi api应用中，在struts框架中报了错，找不到action的config信息。

		然后看houyi api的action配置，地址为services ，struts找不到action，prepare拦截器执行时就抛出了异常，可能是设置原因，应用和服务器都没有对应log，囧。

		实际struts.xml配置的action路径为services。

		小结：-tip-
			先判断问题出在哪个层次/部分，有log依据log，实在没log，debug源码，查找是什么原因导致抛出问题

4. vim 查找替换
	vi/vim 中可以使用 :s 命令来替换字符串
	:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
	:s/vivian/sky/g 替换当前行所有 vivian 为 sky
	:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
	:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
	n 为数字，若 n 为 .，表示从当前行开始到最后一行
	:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
	:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
	可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
	:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	


5. 用户体系改造-houyi api白名单暂放到 houyi.properties中

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
typhoon

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day103 Thursday, August 09, 2012

1. 
	*  用户体系改造-houyi api
		集成测试
			
	* 用户体系改造-slb api
		rs表订正
			portal提供 lb_id ,IDKP映射表，订正lb_id不为null的记录中的user_id为IDKP值
			另外订正lb_id为null的记录的user_id为指定的测试用IDKP值
	* big region
		流量接口bigregion查询检查

2. 本机ip地址是通过dhcp获取的，测试环境调用本地mysql，需要调整ip。 houyi apidev测试环境（8.214）

3. 用户体系改造-houyi api
	不支持管理员是个最终用户
		比如不能创建vm
	集成测试
		白名单userId,
			管理接口
				299代理商操作其子用户数据
					比如detail_vm （属于275用户）
				调用必传IDKP接口时，报错
			最终用户
				299的一个子用户调用
			万网老用户调用	       （没进行用户体系改造，is_agent=0,agent_id=null）
				is_agent=0
	接口修改
		  monitor_vm_topn
		VmTopNMonitorExecuteAction

4. spring抽象类注入，spring接口注入有区别 * spring
	抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	还是尽量面向接口编程
5. 测试 create_vm保证image对应的快照是存在的
	表查看，找快照id
	detail_snapshot 查询快照详情（有快照id值）	
	15-147019-137.vhd                           |          1 |      21 | 428         | AT03-HOUYI1
6. monitor计量数据	  业务
	根据是否大二层网络，对应的数据在不同的库中，表结构不一致。
		rx - rx_intra
7. slb 8.214测试
	http://10.250.8.214/slb/api?
	houyi api
	http://10.250.8.214/open/services?


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day104 Friday, August 10, 2012

1. 
	* 用户体系改造 slb api处理
		query_monitor_vms 
			VmPageMonitorExecuteAction

	* 用户体系改造　houyi api bug fix
		
2. 用户体系改造 slb api处理						  slb v2 api
	用户体系改造 SLB V2 API需求和关键点列表：
	1）所有请求都需签名验证（和用户体系改造前的验证一样）
	2）只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的签名信息）
	3）原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
	4）rs表数据订正
	5）slb api透传aliyun_id值给slb后端，参数名和原来一致（即user_id）

	对照上面需求点，处理SLB api代码

	修改点：
		新增错误码：
			ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),
3. mysql数据dump
	mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
	source /home/xx.sql

4. 
	8.214开发测试环境的slb环境，新建slb后端的计量库便于测试，地址在本机
	houyi api 的db改用big region的db（6.27的db）


	http://www.cnblogs.com/lovecindywang/archive/2012/08/06/2624678.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day105

1. bug fix


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day106 Monday, August 13, 2012

1. 
	* 用户体系改造 houyi api bug fix
		- live_migrate_vm 接口修改（需求时文档未列出此接口）
		- create_vm接口
			处理user_image_mode的逻辑，  只用自己的image还是可用自己的和公有的	   （0可用自己和公有的image；1只能用属于自己的image）
		- reset_vm
			处理user_image_mode的逻辑，只用自己的image还是可用自己的和公有的
		- release_ip
			控制系统新增接口，根据ips得到vm_names，api根据vm_name验证是否有release_ip权限。
			
	* 
2. 

3.  Linux查看程序端口占用情况，占用的程序
	Tomcat 8080端口起不来，老提示端口已经被占用。
	使用命令：
	ps -aux | grep tomcat
	发现并没有8080端口的Tomcat进程。
	使用命令：netstat –apn
	查看所有的进程和端口使用情况。发现下面的进程列表，其中最后一栏是PID/Program name 
	clip_image002
	发现8080端口被PID为9658的Java进程占用。
	进一步使用命令：ps -aux | grep java，或者直接：ps -aux | grep pid 查看
	clip_image004
	就可以明确知道8080端口是被哪个程序占用了！然后判断是否使用KILL命令干掉！
	方法二：直接使用 netstat   -anp   |   grep  portno
	即：netstat –apn | grep 8080

4. houyi api db业务
	iso表
		user_iso - 标识iso是用户上传还是管理员上传的，用户查询iso时，不会返回user_iso=0的iso，
		visibility标识iso可见性，0为公有（此时忽略user_id），1为私有
	image表
		visibility 0为公有（忽略user_id），1为私有
	
	资源所属校验时，处理这些逻辑。不仅筛选user_id条件，还需处理公有私有情况等。

	remove_image
		删除image，用户必须为image所属的user_id，或其代理商
	
	user表
		image_user_mode 0可用自己和公有的image；1只能用属于自己的image
5. 根据ips返回names
	http://10.250.6.111/wiki/index.php/QueryVmByIp

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day107 Tuesday, August 14, 2012

1. 
	* 用户体系改造 - houyi api
		release_ip
		ReleaseIpExecuteAction
		需求：
			修复用户可以release状态为public的ip，控制系统提供根据ip列表找到vmName列表接口，api判断vm与用户的所属关系后执行release操作。

		IpAddressServiceImpl的 public Result<Object> releaseIpAddress(String ipAddress) 方法，注解判断权限
		@Authority(
		{ @Entry(action = Action.IpUse, actAtNetwork = HouyiNetworkSetting.nonBigEther, resource = @Resource(identify = Resource.Identify.QByCode, argNo = 0)) })
		对于以“，”隔开的ip，根据注解配置找到其资源查询类，验证每个ip的权限
		
		增加错误码：
			IP_ADDRESS_UNAUTHORIZED(-5008,"has no privilege to release ip"),
		release_ip
			ip为多个ip用“,”隔开时，根据资源定位region时报错-90。
			那个版本修复？
	* x
2. 签名时api去掉了某些字段，然后进行服务端签名，再与用户签名比对
	去掉 app_key,sign,sign_type，
		app_key

3. houyi api bug fix
	- bug id：187183
		UNIQUE KEY `key_pair` (`key_pair_name`,`user_id`) ，key_pair表key_pair_name不唯一

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day108 Wednesday, August 15, 2012

1. 
	*　用户体系改造 houyi api
		remove_key_pair
			KeyPairRemoveExecuteAction
			增加错误码：
				ILLEGAL_RESOURCE_OWNER(-8007,"illegal resource_owner")		   
					resource_owner表示的IDKP不是最终用户或不是当前代理商的子用户
		describe_key_pair
			KeyPairDescribeExecuteAction
			2个接口都增加 resource_owner 参数，标识代理商操作资源所属的用户标识，和remove_image类似。
		release_ip
			控制系统对于没分配的ip，vm_name值为0，此为控制系统的业务，返回给api应该为空。
			api判断ip没找到vm。
2. 

3. 业务
	资源No定位region，zone_ip表通过ip的long格式映射其对应的zone。

4. 
	 * @deprecated
	 * @param keyPairName
	 */
	public

5. 日志级别定义
	info
	debug
	error
	fatal
	对各种异常的日志级别设置
		系统级错误打error
		业务级别，用户级别打info
		调试用的打debug

6. rpc同步，异步调用 （封装rpc调用包，内部提供调用接口，对外屏蔽调用细节） aos
	线程池调用
	ThreadPoolExecutor
		java concurrent包
	
	每个请求封装为一个个工作任务（task，workitem），交给工作线程池去处理。
	
	接口开发，面向接口开发、
	
	合适的工具
7. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Wednesday, August 16, 2012 - Wednesday, August 26, 2012
missing by svn revert operation
补加：

* svn 代码合并(tortoiseSVN)
	- 打patch，合并patch
		通过svn工具将原来此bugId的修改保存为patch/diff，然后apply patch到新项目中 apply patch
			打patch时注意，若patch生成时所基于的版本与将要apply到的版本不同，即中间不一致则apply时会有冲突，需要手工解决。
	- 
	eg：branch合并到trunk
		将trunk代码check out到本地，在其目录中调用merger命令，选择相应的选项，可先预览合并结果，进行合并；
		合并好后，通过diff工具(kdiff)对比branch目录，验证合并是否正确。
		kdiff 
			对比时可设置参数，比如忽略的文件或目录等，然后比较。
		合并好后，svn commit
		QA测试(提测)
	对于2个并行的分支都做了大量交叉的修改的情况，要尽量避免；如果已发生（big region&user reform)通过工具理解2个支的逻辑人肉合并并加全量回归测试。

* 发布步骤整理及演练，发布失败回滚方案设计
	保证正式发布顺利和优化发布流程

	发布步骤细化到每个命令，具体到能直接执行。

		服务停止
		数据订正
			大数据量，关联复杂时，订正方式，订正语句的优化
		代码发布
		回归测试

	多系统联合发布，需要全盘考虑。
* 系统全局变量使用设计
	在mvc架构中，全局变量控制在c层即控制层，比如action层，保证其他层的逻辑不会意外的从全局变量中去取值，导致控制层对逻辑的不可控，不利于后续的
	扩展和维护。
	userholder控制范围，就不会出现不走到dao的执行层（参数交给ibatis）都不敢保证最终传入的参数的担心，它可能在dao层从userholder取了userId传入的~
		不利于统一验证user的逻辑，而需要

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day118 Monday, August 27, 2012
1. 
	* big region+user_reform check go on
		对user_reform改动到的接口，big region和进来后，再进行review，是否满足user_reform需求？
		根据之前列出的修改接口列表查看：
			

	* 权限验证优化重构，aop，切面编程，方法拦截器
		可通过注解，将必要的参数放到方法的参数中，通过拦截器来处理这些注解，来验证用户操作资源的权限，这种设计，需要将待验证的资源显式的定义出来，比如
		通过放在方法的参数中（一般在service层），通过方法拦截，进行权限验证；从而，避免验证逻辑充斥业务代码，也利于维护和扩展。-tip-
			eg：
				现有的vm和user的验证就是通过方法拦截器，解析service层操作资源的方法中的参数（由注解定义check类型和check的arg）来验证用户操作vm的权限。

		验证能不能操作（比如现有的vm和user所属）和根据用户类型不同调用不同逻辑需要区分开，将功能分类；比如start_vm只需验证能否操作，后续操作管理接口和end user是一样的。

		小节下权限分类：
			不同系统有不同的权限体系，用户权限体系中，有角色权限（不同的角色对应的可访问功能不一样），资源权限/数据权限(对资源或数据用户是否有权限查看或操作)。
		
		user_reform项目由于接口设计，不便于

2. big region+user_reform check go on
	- 合并好的代码与big region比较，分析user_reform的修改点 ，是否正确
		无
	- 合并好的代码与user_reform比较，分析big_region的修改点，并分析是否需要再修改
	查看big region的代码是否有需要对应user_reform进行修改？
		- SnapshotServiceImpl
		     mountSnapshot方法，快照校验所属用户需要修改？
		- SnapshotServiceImpl.
		     unmountSnapshot方法
		- AdjustGroupExecuteAction
		     executeAdjust方法查找group传入的userId
			       Group group1 = groupControlService.viewOwnGroupBaseInfo(resourceOwnerUserId, source, bigRregionNo);
			
		- AuthorizeGroupExecuteAction
		     原groupService替换为big region的groupcontrulservice，user部分需要修改        ？如果userId只用来生成lock，不进行比较所属，是否不需要修改？
		     建议，从group取userId不从userHolder取。
		- ReviseVmToolsAction
		     可忽略
		- QueryGroupVmInfoExecuteAction
		     user_reform没修改，遗漏？
		- GlobalErrorMessage
		     -191错误码重复
		- JoinGroupAction        还有其他big region加入涉及取userHolder取user操作的新接口
		     此为新增接口，不修改，根据代理商找不到group。
		  
3.  big region+user_reform check go on

	- release_vm
		GroupControlServiceImpl
			private boolean leaveAllGroups(Instance instance, List<Group> groups) {
			long ownerId = instance.getUserId();//此处替换从userholder取user
		测试验证释放VIP是否正确
	- remove_image
		imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId()))
		userholder中取user改为显式传参
	- bind_ip
		houyi-spring-action.xml
		action配置修改：
			<property name="limit" value="780"/> 改为：<property name="limit" value="5000"/>
	- authorize_group		  
		AuthorizeGroupExecuteAction
		groupControlService.addGroupAuth(currentUserId, group, groupAuth)
			此处user只用来取锁，代理商也ok，或者直接改为用group对象中的userId来做锁？谭总确认：已确认锁的逻辑不受影响
	- adjust_group_auth
		AdjustGroupExecuteAction
		private ResultDomain executeAdjust(String bigRregionNo, String groupNo, String adjust) {
		查询group时，显式的带userId过去查，替换原来从userholder中取的方式
	- remove_group
		RemoveGroupExecuteAction
			groupControlService.deleteGroup(resourceOwnerUserId, bigRegionNo, groupNo);	      //此为新方法，用了userholder.getUser()
			修改：
				GroupControlServiceImpl
					public OperationResult deleteGroup(long ownerId, String bigRegionNo, String groupNo) {
	- mount_snapshot
		MountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),	      -913状态码废弃
	- unmount_snapshot
		UnmountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day119 Tuesday, August 28, 2012

1. 
	* 
2. 

3. 服务器性能检查
	netstat

4. lb

5. tcp状态
	eg：在6.33上打开一个访问8.214的mysql命令行终端
	在8.214上查看网络连接情况：
	netstat -n | grep 3306
	tcp        0      0 10.250.8.214:3306           10.250.6.33:45378           ESTABLISHED
	表示一个打开的连接

* TCP/IP(Transmission Control Protocol/Internet Protocol) * UDP(User Datagram Protocol)
	- TCP建立连接三次握手
		Client								Server
				SYN=j
		SYN_SENT
							SYN=k,ACK=j+1
											SYN_RECV
				ACK=k+1
		ESTABLISHED						
											ESTABLISHED
	- TCP关闭连接四次握手
		Client								Server
				FIN=m
		FIN_WAIT_1
							ACK=m+1
											CLOSE_WAIT
							FIN=n
											LAST_ACK
		TIME_WAIT
				ACK=n+1
											CLOSED	

		异常场景：
			

	- UDP	* UDP
		
		UDP处于IP层之上

		UDP 是User Datagram Protocol的简称， 中文名是用户数据报协议，是 OSI 参考模型中一种无连接的传输层协议，提供面向事务的
		简单不可靠信息传送服务，IETF RFC 768是UDP的正式规范。
		
		在选择使用协议的时候，选择UDP必须要谨慎。在网络质量令人不十分满意的环境下，UDP协议数据包丢失会比较严重。但是由于UDP的特性：
		它不属于连接型协议，因而具有资源消耗小，处理速度快的优点，所以通常音频、视频和普通数据在传送时使用UDP较多，因为它们即使偶尔
		丢失一两个数据包，也不会对接收结果产生太大影响。比如我们聊天用的ICQ和QQ就是使用的UDP协议。

		虽然UDP是一个不可靠的协议，但它是分发信息的一个理想协议。例如，在屏幕上报告股票市场、在屏幕上显示航空信息等等。
		UDP也用在路由信息协议RIP（Routing Information Protocol）中修改路由表。在这些应用场合下，如果有一个消息丢失，在几秒之后
		另一个新的消息就会替换它。UDP广泛用在多媒体应用中，例如，Progressive Networks公司开发的RealAudio软件，它是在因特网上
		把预先录制的或者现场音乐实时传送给客户机的一种软件，该软件使用的RealAudio audio-on-demand protocol协议就是运行在UDP之上
		的协议，大多数因特网电话软件产品也都运行在UDP之上。

			既然UDP是一种不可靠的网络协议，那么还有什么使用价值或必要呢？其实不然，在有些情况下UDP协议可能会变得非常有用。
		因为UDP具有TCP所望尘莫及的速度优势。虽然TCP协议中植入了各种安全保障功能，但是在实际执行的过程中会占用大量的系统开销，
		无疑使速度受到严重的影响。反观UDP由于排除了信息可靠传递机制，将安全和排序等功能移交给上层应用来完成，极大降低了执行时间，
		使速度得到了保证。
			关于UDP协议的最早规范是RFC768，1980年发布。尽管时间已经很长，但是UDP协议仍然继续在主流应用中发挥着作用。包括视频
		电话会议系统在内的许多应用都证明了UDP协议的存在价值。因为相对于可靠性来说，这些应用更加注重实际性能，所以为了获得
		更好的使用效果（例如，更高的画面帧刷新速率）往往可以牺牲一定的可靠性（例如，画面质量）。这就是UDP和TCP两种协议的
		权衡之处。根据不同的环境和特点，两种传输协议都将在今后的网络世界中发挥更加重要的作用。

		PS:
			类型heartbeat这些心跳服务，也是通过UDP协议来通讯的，即使丢失少量包，新的数据包会马上收到，可以容忍。

		-------
		Datagram sockets also use IP for routing, but they don't use TCP; they use the "User Datagram Protocol", or "UDP" 

		Why are they connectionless? Well, basically, it's because you don't have to maintain an open connection as you do with stream sockets. 
		You just build a packet, slap an IP header on it with destination information, and send it out. No connection needed. They are generally used 
		either when a TCP stack is unavailable or when a few dropped packets here and there don't mean the end of the Universe. Sample applications: 
		tftp (trivial file transfer protocol, a little brother to FTP), dhcpcd (a DHCP client), multiplayer games, streaming audio, video conferencing, etc.

		"Wait a minute! tftp and dhcpcd are used to transfer binary applications from one host to another! Data can't be lost if you expect the application 
		to work when it arrives! What kind of dark magic is this?"

		Well, my human friend, tftp and similar programs have their own protocol on top of UDP. For example, the tftp protocol says that for each packet that 
		gets sent, the recipient has to send back a packet that says, "I got it!" (an "ACK" packet.) If the sender of the original packet gets no reply in, say, five seconds, 
		he'll re-transmit the packet until he finally gets an ACK. This acknowledgment procedure is very important when implementing reliable SOCK_DGRAM applications.

		For unreliable applications like games, audio, or video, you just ignore the dropped packets, or perhaps try to cleverly compensate for them. (Quake players 
		will know the manifestation this effect by the technical term: accursed lag. The word "accursed", in this case, represents any extremely profane utterance.)
		-------
		from: http://www.beej.us/guide/bgnet/output/html/multipage/theory.html
		PS: UDP虽不可靠，但处理效率高，对应某些确实需要可靠传输的场景，可以在应用层面保证可靠；对于类似视频，game的场景由于后续消息会马上补偿
		故也没什么影响。

	- TCP/IP详解
		书籍

	- They use a protocol called "The Transmission Control Protocol", otherwise known as "TCP" (see RFC 793 for extremely detailed info on TCP.) TCP makes sure your 
		data arrives sequentially and error-free. You may have heard "TCP" before as the better half of "TCP/IP" where "IP" stands for "Internet Protocol" (see RFC 791.) IP 
		deals primarily with Internet routing and is not generally responsible for data integrity.
	- tcp状态：
		LISTEN：侦听来自远方的TCP端口的连接请求
		SYN-SENT：再发送连接请求后等待匹配的连接请求
		SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认
		ESTABLISHED：代表一个打开的连接
		FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认
		FIN-WAIT-2：从远程TCP等待连接中断请求
		CLOSE-WAIT：等待从本地用户发来的连接中断请求
		CLOSING：等待远程TCP对连接中断的确认
		LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认
		TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认
		CLOSED：没有任何连接状态

6. 网络性能监控
	netperf
		is  a  benchmark that can be used to measure various aspects of networking performance.
	netserver
		a network performance benchmark server, listens  for  connections  from a benchmark, and responds accordingly.
	http://www.netperf.org/netperf/

7. grep -v 查看不匹配的行
	eg：
		tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'

8. pangu 存储
	k-v
	rds

	写入速度快，保证写入成功，除非

9. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day120 Wednesday, August 29, 2012

1. 
	* 通过工具模拟大量并发请求，重现socket red 问题（服务访问缓慢甚至返回500错误）
		然后分析原因
	* big region合到trunk后，数据库表的改动对mapping文件中sql的影响排查
		执行dao单元测试
	* 大region对sql的修改，用户体系改造需检查是否有对应的修改
		eg ：image.xml查询用户可用image sql

		svn对比big region对mapping文件做了哪些修改点

		*inBigRegion(xxx的方法都需要考虑从新加入user_reform逻辑。
		byagentid 是否已换成新方法？
			inbigregion的方法，还是用此方法，加入user_reform逻辑
				没有对应的byagentid方法，就是从原有的方法中取需要的逻辑
			byagentid还是用byagentid方法，加入bigregion逻辑
		
		daoimpl类中搜索 inbigregion ， byagentid

		所有byagentid的sql加上big region逻辑。
			
		- remove_image
			RemoveImgExecuteAction
			用imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId())查询是否正确？
	
			

2. 通过工具模拟大量并发请求，重现socket red 问题
	- 并发请求，重现socketread问题
		ab -n10000 -c300 http://xxxx

	- jstack dump堆栈信息 （以时间段dump多份便于对比）
		jstack 1345 > dump1
		----------
		java的线程状态值有：定义在 java.lang.State中
			A thread state. A thread can be in one of the following states: 

			NEW
				A thread that has not yet started is in this state. 
			RUNNABLE
				A thread executing in the Java virtual machine is in this state. 
			BLOCKED
				A thread that is blocked waiting for a monitor lock is in this state. 
				线程在等待一个对象锁，会处于这种状态
			WAITING
				A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 
			TIMED_WAITING
				A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. 
			TERMINATED
				A thread that has exited is in this state. 
			
			A thread can be in only one state at a given point in time. These states are virtual machine states which do not reflect any operating system thread states.
		----------


		分析运行的细节
3. linux help
	svn --help
	svn co --help
4. jboss ,tomcat
	tomcat报 NoClassDefFoundError: org/slf4j/impl/StaticLoggerBinder ，表示缺少对应的jar或找不到
	但，jboss却正常，是不是在不同的jar中有了这个实现？

5. ibatis映射
	返回值中无此参数和表中无此字段的报错的区别？
		select中无此字段：
		org.springframework.jdbc.BadSqlGrammarException: SqlMapClient operation; bad SQL grammar []; nested exception is com.ibatis.common.jdbc.exception.NestedSQLException:   
		--- The error occurred in ibatis/iso.xml.  
		--- The error occurred while applying a result map.  
		--- Check the iso.isoMap.  
		--- Check the result mapping for the 'bigRegionNo' property.  
		--- Cause: java.sql.SQLException: Column 'big_region_no' not found.
		
		select有此字段，表中无此字段：
		？

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day121 Thursday, August 30, 2012

1. 
	* bug fix test 
	* houyi api 需要 slf4j-log4j12-1.5.8.jar依赖
		jboss可不要？
	* slb v2 ，houyi api
		cache梳理，是否提供reload方法？


2. bug fix test 

	create_vm
		image使用
	reset_vm
		image的检查
	create_image	     (create_snapshot)
		
	remove_image

	start_vm后，收到MQ的状态改变可确定vm是否启动成功。

3. 控制系统维护vmName?
	报vm exists

4. create_snapshot过程中，master重启
	ec master reboot ,but agent at nc is still working ,they send the latest message to db or master 
5. slb v2 ，houyi api cache梳理，是否提供reload方法？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day122 Friday, August 31, 2012

1. 
	* user_reform & big region test
		instance
		image
		iso


	* 缓存方案 ，简单缓存方案(需要有缓存更新机制)
		缓存超时



2. mysql执行计划，sql执行计划
	mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

	mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

3. 既然使用这些载体或工具，要想发挥其应有的能力，就需要去了解它，熟悉它，会用工具，用好工具，让它们帮忙我们更好的实现目标。-tip-
	linux iptables
	....
4. Customized Image
	from System Snapshot

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day123 Saturday, September 01, 2012

1. 
	* 

2. 

3. slb
	临时预发布环境信息：

	ag 10.250.6.36

	master 192.168.1.16

	lvs: 192.168.1.111 - 112

	haproxy: 192.168.1.113

			192.168.1.115

	rs: 192.168.1.116-119

	db: mysql -h 10.250.6.1 -uroot

	qa回归用机器：10.250.6.37


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day124 Monday, September 03, 2012

1. 
	* code，msg采用英文编码，避免中文问题
	* 测试用户默认region为非大二层region，能正常调用接口

2. linux进程系统参数
	ps aux | grep -i java 

	cat /proc/7314/limits | grep 'open files'
	Max open files            655360               655360               files     

	进程打开最大文件数：655360
3. 测试用户默认region为非大二层region，能正常调用接口	  (新老api share db，非空字段的地方是否ok？)
	8.214上
	用户未非大二层region
	region表加入此region
	zone表加入zone

	259 ，229的子用户，设置非大二层region，测试：
		detail_vm
		list_snapshot
		query_vm_device
		create_snapshot
		detail_snapshot
		mount_snapshot
		list_mounted_snapshot
		unmount_snapshot
		restart_vm
		stop_vm
		remove_snapshot
			在mount快照过后执行remove_snapshot操作，报状态不对删除不了；再unmount_snapshot，执行删除同样问题；
			<rsp>
			  <code>-912</code>
			  <msg>device or snapshot is not ready</msg>
			</rsp>

		query_available_isos
		list_vm_status
		monitor_vm 无数据（vm监控数据）
		monitor_vm_topn 同上

		query_nc_resources
		query_vm_security.

		add_disk
		remove_disk
		detail_nc
		query_instance_type
		query_available_ncs
		list_vlans
		query_zones
		query_regions
		release_ip
		assign_ip
		query_available_imgs
		query_unassigned_ips

		rollback_snapshot
		list_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day125 Tuesday, September 04, 2012

1. 
	* big region 
		历史bug
	* api_user_reform在加入了大region的db修改后，接口测试



2. 业务
	mount_snapshot
		vm1的快照，挂载到vm2，需要验证vm1，vm2的关系
	pending,startfail
		master第一次启动失败pending，成功后为stop
		api根据MQ和显示调用更新状态，pending只能通过MQ收到，故detail_vm会从starting到pending。


3. api_user_reform在加入了大region的db修改后，接口测试
	query_regions
	query_zones
	list_vlans
	query_instance_type

	detail_vm
	query_vm_device
	query_available_isos
	list_vm_status

	monitor_vm（无数据）
	monitor_vm_topn

	create_snapshot
		控制系统返回-1的码，api统一报-95，如快照名称重复
	detail_snapshot
	cancel_create_snapshot
		已cancel的再去cancel，控制系统报：
		-1,"desc":  "cancel failed
		-95给用户
	mount_snapshot
	list_mounted_snapshot
	unmount_snapshot
	remove_snapshot
	restart_vm
	stop_vm
	rollback_snapshot
	query_unassigned_ips
	query_available_imgs
	assign_ip
	release_ip
	query_available_ncs
	detail_nc
	add_disk
	query_vm_security
	query_nc_resources



4. fdisk	   linux分区	    * fdisk
	fdisk -l
	fdisk /dev/hda
	n
	1
	10
	w
	reboot
	fdisk -l
	vgcreate guestvol /dev/hda6
		No physical volume label read from /dev/hda6
		Physical volume "/dev/hda6" successfully created
		Volume group "guestvol" successfully created
	lvcreate -nubuntu01 -L5.4G /dev/guestvol
		Rounding up size to full physical extent 5.40 GB
		Logical volume "ubuntu01" created


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day126 Wednesday, September 05, 2012

1. 
	* 线上环境，vm创建后起不来原因定位，无pending？


2. 线上环境，vm创建后起不来原因定位，无pending？
		已定位为资源不足

3. 业务,日志查看，控制系统日志，问题排查
	iso在nuwa本地pangu，image同步工具
	nuwa(master日志)
		从reigon找nuwa地址，ssh上去，/apaxxx/nuwa/xxx.Log查看 日志，控制系统日志

	api-kfc(httpd-record service name and address,do forward)-master/netc-agent-operate

	控制系统角色查看 (AG上查看)/apsara/deploy/Fuxisrvd -v houyi status 	       （ag作为master访问入口admin gateway）
	master、netc
	history |grep status
	/apsara/deploy/Fuxisrvd -v houyi status
		查看控制系统，集群的角色（由多少nc组成，有哪些服务角色，各自在那个ip上）
	ps axf |grep master
	vim /var/log/houyi/master/HouyiMaster.LOG
	vim /var/log/houyi/netc/HouyiNetcLOG

	vim /var/log/xen/xend.log
	
	eg：
		在6.33的api，看nuwa，找ag，看master日志

	pending状态需要结合配置，保证start_vm ok。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day127 Thursday, September 06, 2012

1. 
	*  wiki
	* 6.33日志
		release_vm时master调netc释放ip失败，在ag 6.27上找到netc地址，上去看log


2. 
	
		
3. 抛砖引玉的效果
	demo

4. /apaxx目录下熟悉各组件，总线服务
	nuwa
	pangu
	...

5. lvs			       * tcpdump	 * Wireshark
	- Wireshark(以前是ethereal)是Windows下非常简单易用的抓包工具。	
		-------------
		TCP segment of a reassembled PDU？

		> - Or is this part of a bigger application packet that has multiple TCP
		> pkts (and all with the same Info:..TCP segment of a reassembled PDU).

		YES! The message means that TCP handed of the dissection to a higher
		layer protocol dissector. This dissector told the TCP dissector to
		collect multiple TCP segment to construct one PDU. If all goes well,
		the packet that contains the lasat part of the application PDU will
		have full dissection of the application protocol. If this does
		not happen, please file a bug on http://bugs.wireshark.org and
		attach the capture file of that particular tcp session.

		You can disable the reassembly of TCP segments by unchecking the
		"Allow subdissector to desegment TCP streams" in the TCP protocol
		preferences. That way, all parts of the application PDU will be 
		displayed on their own.
		-------
		from: http://www.wireshark.org/lists/wireshark-users/200806/msg00047.html
		PS: 可以在配置按钮的弹出框中，找到protocol，tcp，取消“Allow subdissector to desegment TCP streams”选项以禁用tcp块重组

	- 
	tcpdump -n -i any port 80		   tcp包查看

	eg:
	------
	Examples
		To print all packets arriving at or departing from devo:
		tcpdump host devo
		1. To print traffic between gil and either devo or bevo:
		tcpdump ip host gil and \(devo bevo\)
		2. To print all IP packets between bevo and any host except gil:
		tcpdump ip host bevo and bevo gil
		3. To print all traffic between local hosts and hosts on network 192.100.192:
		tcpdump net 192.100.192
		4. To print traffic neither sourced from nor destined for local hosts:
		tcpdump ip and not net localnet
		5. To print the start and end packets (the SYN and FIN packets) of each TCP conversation that
		involves a non-local host:
		tcpdump \(tcp[13] \& 3 !=0 and not src and dst net localnet\)
		6. To print all ICMP packets that are not echo requests or replies (not ping packets):
		tcpdump \(icmp[0] !=8 and icmp[0] !=0\)
		7. To immediately print packet information, enter
		tcpdump -I
		8. To specify the token-ring interface to listen on, enter:
		tcpdump -i tr0
		9. To print packet information to the file TraceInfo, enter:
		tcpdump -wTraceInfo
	------


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day128 Friday, September 07, 2012

1. 
	* wanwang 连调
		缓存deviceNo等数据，重新生成缓存
	* 

					

2. wanwang 连调 ，业务
	release_vm失败丢失group信息。
	vm stopped，group

	join group多次fail，no log


														
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day129 Monday, September 10, 2012

1. 
	* big region连调支持
		a. 环境原因导致的netc调用释放ip超时
		b. image的版权问题，密码问题
		c. 老master的无资源启动问题
		d. vm的连通性授权访问问题（默认规则不能访问，参考api文档）
		e. 


	* ec了解
	* 新项目讨论
		a. 计费需求(安全提供查询接口)
		b. ace4j
		c. big region项目2新增接口进行user reform改造
		d. big region包括api和master的bug fix
		e. houyi计量推送优化
		f. houyi api优化，部分重构；本地cache的优化（统一cache实现，提供cache更新方案-自动或被动调用）
	* ace4j(lxc)需要api提供几个防火墙的接口，看master提供的接口说明
		添加ip白名单（ip放行）
		删除ip白名单
		查询ip白名单列表
			补偿描述
		http://10.250.6.111/wiki/index.php/Firewall_add_white_list
		
	* 并发测试
		环境
	* 双开发布
		region查询存在的limit 1问题。
		

2. 联调 big region
	api log > master log (master位置从ag中调用命令查看)> nc log(xen log)	nc_id位置从master的log中确定，nc ip从api接口中查询

	liveMigrateFailed 不对外，统一报-95

3. 数据库索引，数据库优化

	从数据库的查询方式分析优化方案，参考数据库提供的优化功能，比如各种索引等。

	指导方针：
			要了解跑在数据库上的应用程序/用户，使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，
		如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day130 Tuesday, September 11, 2012

1. 
	* ace4j对houyi api的需求背景说明
		master提供的3个接口熟悉，对应api的接口设计
	* openstack分享
		中心授权，组件化运行，MQ消息

		loadbalance，分布式存储

		网络：
		http://www.cnblogs.com/biangbiang/archive/2013/05/17/3083421.html



2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day131 Wednesday, September 12, 2012

1. 
	* big region发布
		数据模拟订正，slbv1表检查   region_mapping

2. 底层
	/home/admin/apasara

3. pssh
	python实现，便于从一台nc批量执行命令到其他多个nc等需要。

4. 系统
	API，命名服务，master，xx，分布式kv存储

	cluster规模逐渐增大后，程序的维护，更新及发布，需要自动化，面对的是大量的nc节点，除了配置信息操作基本一致。
	执行前check，执行后check，最终check，需要自动化更高的手段。
		抽象出过程中可以独立的操作，做为一个执行单元（可以包含准备，执行，检查等）

	这样的工具开发，采用高级语言认为还是很合适的，比如python（pssh工具）。
		依据脚本和配置自动化执行nc操作。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day132 Thursday, September 13, 2012

1. 
	* big region release值守
	

2. 系统
	youchao Structured  Data Processing,pangu Storage,fuxi Scheduler,shennong Monitor,nuwa Naming, kuafu Communication,  cangjie Language,Security

	shennong : 
		A distributed data collecting system that collects data from both system and user programs, aggregates them according to customizable rules, 
		and provides them according to user requirements. 

3.部署实践 -tip-
	- 建议将配置文件与安装目录分离
		便于日后升级版本的时候配置文件不被覆盖，减少我们对配置文件的维护
	- 

4. kv存储如monodb，以键值对方式存储数据，区别于分布式存储系统(文件系统，如HDFS)，两者有区别有联系。
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day133 Friday, September 14, 2012

1. 
	* 


2. /etc/hosts	      主机名 ，host name ，ssh互通
	127.0.0.1               localhost.localdomain localhost
	10.250.1.199    mydev.test.com.cn	

	ssh-keygen生成密钥对，对公钥末尾部分的host名修改为hosts中设置的名称
	拷贝到需要连到本机的主机的ssh auth文件中。

	本机生成密钥对，将公钥拷贝到目标机的ssh授权文件中，这样就能无密码ssh从本机登陆到目标机（注意用户角色和host解析）。

	保证目标机对host名的正确解析（可以在目标机的host定义文件中定义host名到ip的映射关系）

3. SLB 
	lvs test
	2 vm,lvs
	using LVS as a module as this approach is easier and more exible.
	kernel: http://www.kernel.org/pub/linux/kernel/v2.6/longterm/v2.6.34/linux-2.6.34.13.tar.bz2
	ipvs: http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz
	Compiling ipvsadm on different Linux distributions:
		http://kb.linuxvirtualserver.org/wiki/Compiling_ipvsadm_on_different_Linux_distributions
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day134 Monday, September 17, 2012

1. 
	* ace4j Firewall
		prd会

2. ace4j防火墙接口
	LXC内部网络跨vm访问，跨过arp FireWall，支持LXC每个容器一个私网IP(此私网为LXC的网络)。
	arp FireWall -> ip FireWall

	lxc网络规划(internal)

	一些接口参数校验：
		ip，ip段，ip range - 合法性（格式，范围）
		PRD讨论，暂只支持单个ip

	定义返回结果pojo类的xml映射
		XStream		

	具体验证，设计时考虑

3. parse pojo to xml
	eg: XStream

	定义返回结果pojo类的xml映射 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day135 Tuesday, September 18, 2012

1. 
	* ace4j firewall kick off
		create wiki
	



2. Ace4j firewall
	TODO:
		- Call set firewall operation after add or remove white ip list ,like join or leave group.
			add white ip list > call master set firewall	(new command)
			remove white ip list > call master set friewall (new command)

			 VM_PUSH_ACL(1),

		- 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day136 Wednesday, September 19, 2012

1. 
	* 快照
	* 主备切换/读写分离

2. keepalived
	失败恢复ok
	主备切换？
		linu防火墙的问题，导致主备切换失败，可能是阻止了lvs机之间的vrrp交互。

	测试成功
	后面针对keepalived的防火墙要求，做细化控制，不关闭防火墙 待？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day137 Thursday, September 20, 2012

1. 
	* wiki
	* slb
		lvs
		keepalived
		haproxy

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day138 Friday, September 21, 2012

1. 
	* slb测试通过后，测试slb下的mysql负载均衡(读负载均衡) -tip-
		数据库部分部分应用读的压力大于写的压力，通过mysql的主从复制，读写分离实现db层的高可用，高并发。
	* mysql
		主从复制，
		主备切换/failover，    通过vip漂移（如：keepalived）
		读写分离
		
	
2. lvs主备切换
	/etc/init.d/iptables stop

	lvs主备切换如果工作不正常，确认是不是防火墙的原因（防火墙阻止了keepalived的功能），下面是查找主备不切换，每个lvs启动后都是master状态：
	------
		Hi,

		I found that it is always best if possible to turn off the firewall and see if it works,
		then turn on the firewall.

		On 05/24/2012 08:16 AM, lakshmi priya wrote: 
	------
	from : http://comments.gmane.org/gmane.linux.keepalived.devel/3864

	根据上面的提示，测试成功，确实是linux防火墙导致keepalived的主备切换功能失效，具体应该是vrrp协议的交互受阻，下面是测试成功的log：
		Sep 20 02:46:39 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
		Sep 20 02:46:40 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 added
		Sep 20 02:46:40 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 added
		Sep 20 02:46:45 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 10.1.171.253
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Received higher prio advert
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) Entering BACKUP STATE
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: VRRP_Instance(VI_1) removing protocol VIPs.
		Sep 20 02:49:26 mytest02 Keepalived_vrrp: Netlink reflector reports IP 10.1.171.253 removed
		Sep 20 02:49:26 mytest02 Keepalived_healthcheckers: Netlink reflector reports IP 10.1.171.253 removed
	
	ps：
		iptalbles全部关闭不建议，可以查看keepalived的端口占用说明，开放其需要的端口即可。

3. lvs+keepalived负载均衡测试
	分摊请求

4. mysql
	参考：http://www.blogjava.net/dongbule/archive/2010/08/22/329602.html
	log
		/var/log/mysqld.log

	yum install mysql.i386
	1) 主服务器上进行的操作
	/opt/mysql/init.d/mysql start
	/opt/mysql/bin/mysql -uroot -p'new-password'
	
	授权给从数据库服务器192.168.10.131
	mysql> GRANT REPLICATION SLAVE ON *.* to 'rep1'@'192.168.10.131' identified by 'password';

	查询主数据库状态
	Mysql> show master status;
		+------------------+----------+--------------+------------------+
		| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |
		+------------------+----------+--------------+------------------+
		| mysql-bin.000005 | 261 | | |
		+------------------+----------+--------------+------------------+
	记录下 FILE 及 Position 的值，在后面进行从服务器操作的时候需要用到。

	2)从服务器操作


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day139 Monday, September 24, 2012

1. 
	* 梳理user_reform的api proxy转发规则
	升级到大region需要做的修改：
		

2. 梳理user_reform的api proxy转发规则（定位region）
	根据vm_name
	根据ip
	根据region_no
	根据aliyun_idkp/session_id

	对应接口是否都处理了的问题，可对照文档。
	
	join_group/		region_no
	leave_group/		region_no
	query_group_vm/	region_no
	reload_cache/		无vm_name,ip,region_no	      ，不关注
	set_master_region/	region_no
	refresh_vm_acls/	vm_name
	touch_master/		region_no
	flush_control_ip_chain/	vm_name

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day140 Tuesday, September 25, 2012

1. 
	* ace4j kick off
	* api proxy 接口根据api文档与qa确认
	* 9.27 design doc send mailz 

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day141 Wednesday, September 26, 2012

1. 
	* 大region二期
		ace4j
			详细设计文档
				补充接口逻辑处理说明
		快照计费，aliyun_idkp透传master(快照接口)
			

2. 大region二期
	
	ace4j
		拉分支
		详细文档细化程序处理流程逻辑
		代码：
			command参考 VmPushAclSetFireWallCommand
	快照计费
		api需求分析
			快照相关接口列出(需要传aliyun_idkp)
				create_snapshot
			是否调用了master
				message_vm ？
			控制系统是否要修改接口，相应的对api的影响
		idkp只做标识，不做验证？	    透传master
	OSS存储打通
		整理需要跨小region操作的接口，API是否支持或需要支持，master是否支持或需要支持
			add_disk 已支持
			mount_snapshot
			rollback_snapshot
			create_vm


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day142 Thursday, September 27, 2012

1. 
	* 大region二期
		create_snapshot接口透传aliyun_idkp
		mount_snapshot等接口中snapshot跨region使用，需要将cluster_id等消息传给master	       （oss大region内互通[http]）
			已传入快照cluster_id
		add_disk已实现跨region的快照使用,带入了快照的cluster_id到master	 (AddDiskCommand)	- 忽略	      
	* 线上bug处理
		nic=INTERNET
2. 
	mount_snapshot
		snapshot clusterId
	add_disk
		snapshot clusterId
	start_vm
		imageClusterId=snapshot clusterId
	reset_vm
		imageClusterId=snapshot clusterId
	create_vm
		imageClusterId=snapshot clusterId

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day143 Friday, September 28, 2012

1. 
	* 大region二期kick off
	* 老版本api，启动模式问题
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/tags/20120426_473751_trunk trunk上打的tag

		create_vm没设置启动模式参数

		原因：
			sql是旧版本，创建default值为init类型

			sql版本维护的问题？

2. 
防火墙
	消息给master

3. 老api

	  InstanceStartupMode.java
	public static InstanceStartupMode getInstance(String name)
	{
		for (InstanceStartupMode mode : InstanceStartupMode.values())
		{
			if (mode.getName().equals(name))
			{
				return mode;
			}
		}
		return InstanceStartupMode.NORMAL;
	}
	若模式没找到，则返回normal=0

	创建vm时，为0，找不到也为0，直接传递给master为0

	确认创建时，startup_mode为3，不为0

	故，此版本start_vm需要传 startup_mode=init

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day144 Saturday, September 29, 2012

1. 
	* 线上问题处理
		报image找不到
			饶入一个偏题			
				最终，由于使用的账户问题，image_using_mode自能用自己的。

2. 发布管理，版本管理（相关API，master等的版本），文档管理，工具管理
	后面查询时，有统一的地方可查。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day145 Monday, October 08, 2012

1. 
	* ace4j
		pojo
			nic，command	  ,api返回pojo，
		
	* 大region二期task见redmine
		设计文档下周一评审，内容包括：
			a. 取消快照数据推送逻辑
			b. 创建快照接口带入用户标识
			c. 确认快照相关接口已带入cluster_id，若没有则需要带入
			
		http://redmine.aliyun-inc.com/issues?set_filter=1&f%5B%5D=status_id&op%5Bstatus_id%5D=o&v%5Bstatus_id%5D%5B%5D=1&f%5B%5D=project_id&op%5Bproject_id%5D=%3D&v%5Bproject_id%5D%5B%5D=214&f%5B%5D=assigned_to_id&op%5Bassigned_to_id%5D=%3D&v%5Bassigned_to_id%5D%5B%5D=me&f%5B%5D=&c%5B%5D=project&c%5B%5D=tracker&c%5B%5D=priority&c%5B%5D=subject&c%5B%5D=author&c%5B%5D=assigned_to&c%5B%5D=updated_on&c%5B%5D=fixed_version&c%5B%5D=start_date&c%5B%5D=due_date&c%5B%5D=done_ratio&group_by=
	* new wiki
		http://10.250.6.111/wiki/index.php
			API接口wiki说明由PD维护。

2. 项目各种文件版本管理
	PRD
	需求文档
	数据库变更

	项目管理软件管理(redmine)？wiki管理？svn管理？
		eg: redmine管理

3. houyi.json
	后羿角色的配置	 cc,nc,netc,master,monitor

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day146 Tuesday, October 09, 2012

1. 
	* ace4j development
		nic error define
			GroupErrorMessage
			ServerErrorMessage
	* image跨小region调用
		原来通过region_alias表的字段实现image可以在打通KFC的小region间使用，现在不需要KFC打通实现的
		image跨小region调用，而是大region内的http方式调用。API层需要修改使用image时过滤条件？
		
2. 接口设计，参数设计
	OO思想，参数对象化
	结果统一处理
		配置状态码对应返回值
		command自封装内部处理，对外统一结构返回
		参数对象化，验证逻辑封装（常用验证-按功能，按业务逻辑的封装后统一调用），类似struts的form bean
		验证逻辑与主业务逻辑分开，主逻辑只处理参数正常的情况
	统一调用

	系统优化：-tip-
		参考struts，在action处理请求时，将请求参数注入到到定义的参数对象中，无需在action类中再去取键对应的值。

3. jtester
	commandexecute进行mock测试时，注意spring配置实用mock的executor来测试。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day147 Wednesday, October 10, 2012

1. 
	* ace4j今天提测
		service层单元测试补充(add已ok)
		补上其他action(add已ok)
		action层单元测试

		与master连调

		ace4j关于大region业务，用户体系改造业务分析：
			大region业务已处理；
			用户体系改造，代理商逻辑，在vm统一验证时已处理，即支持代理商调用。
		
		-tip-
			程序各层逻辑分明，单元测试保证单元逻辑测试通过，层层独立分工，保证整体逻辑清晰准确。

		开发环境搭设API服务，准备和master进行连调测试
			10.250.8.214
			打包已有部署目录：tar -cvf ../houyi-ace4j/service.tar service/
			清楚旧项目日志，程序等内容
			修改，svn地址
			修改apache配置文件httpd.conf，以本项目的conf文件启动
				配置access_log
					<IfModule log_config_module>
					    #
					    # The following directives define some format nicknames for use with
					    # a CustomLog directive (see below).
					    #
					    # LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
					    # LogFormat "%h %l %u %t \"%r\" %>s %b" common

					    LogFormat "\"%{X-Forwarded-For}i\" %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{Host}i\" \"%{Accept-Encoding}i\"" common
					    CustomLog "/home/admin/houyi-ace4j/service/logs/openapi/access_log" common

					    <IfModule logio_module>
					      # You need to enable mod_logio.c to use %I and %O
					      # LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" %I %O" combinedio
					    </IfModule>

					</IfModule>					
			修改项目配置文件
				job.properties
			编译，部署，运行

			集成测试类（ApiTest）中加入上面3个接口的测试用例

				

	* big region二期项目
		大region内，跨小region使用image，snapshot需求
			现有API限制image不跨小region使用(KFC打通并在region_alias配置能跨小region使用的region除外)。
				上面的逻辑变动要进入到设计文档中：涉及使用image的接口整理对应的改动

				根据api文档中，有image_no参数的接口列出待检查的接口：
					create_vm
					reset_vm
					create_image	     image_no已保证表内唯一
					remove_image	     已在大region范围删除image
					revise_vm

					selectParentImage没有原有kfc打通可跨小region使用image逻辑
					
2. 设计 系统api
	通过visitor或者factory来实现bean，pojo的生产

3. test
	add_firewall_whitelist 
	remove_firewall_whitelist 
	list_firewall_whitelist

	集成测试：
		正常流程
		异常流程
			参数错误
			操作不允许

4. 业务，系统业务
	kfc对应参数格式错误的情况会自己捕获，并抛出异常，但不做response，这样api在参数发送错误时，报kfc超时异常。
		eg: api to nuwa to netc 
			可以看netc的日志，报参数格式错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day148 Thursday, October 11, 2012

1. 
	* ace4j测试用例评审
		白名单无限加问题
		vm状态控制问题(非released的vm)
			代码已修改提交
	*　tdc设计评审
		device - tdc子进程
		oss存储 bucket
	*　
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day149 Friday, October 12, 2012

1. 
	* ace4j,计量，mac-net项目周会
		项目需求阶段，需要考虑测试环境问题（特别对于依赖）
	* ace4j计量
		增加，删除白名单接口，不支持nic=all的类型
	* 大region二期设计文档初评审
		

2. 系统业务			      * master
	master: 总控模块，负责调度/与cc连接状态监控
	cc : 路由模块，同时负责监控与nc连接情况
	nc: vm管理模块，负责最终对vm的操作
	network controller : 负责网络安全，group互通管理

	命名服务
3. ace4j改动
	reversion：625581
	ace4j项目改动：
	1）3个接口都增加vm状态限制，released状态的vm调用时会报错，详细说明见设计文档
	2）增加，删除白名单接口，不支持nic=all的类型，只支持nic=internet和nic=intranet
4. 大region二期设计文档初评审，需求变动及增加点
	1)  部分使用快照的接口需要从master查询快照后，将新增的字段 snapshot_type 再传给master
		修改点：
			增加snapshot_type涉及接口改动：
				detail_snapshot 返回值增加snapshot_type值
				list_snapshot 返回值增加snapshot_type值
				create_snapshot 返回值增加snapshot_type值
			需要传递snapshot_type涉及接口改动：
				mount_snapshot 增加传递快照的snapshot_type给master
				add_disk 同上
				start_vm 同上
				reboot_vm 同上
				reset_vm 同上
				rollback_snapshot 同上
				recover_vm 同上
	2) image可以在大region下跨小region使用后，对于老image（非buckut方式存储、http方式访问的image，本次项目上线前已有的image）将不能被使用，master新增对应的错误码，
	API需处理此错误码


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day150 Monday, October 15, 2012

1. 
	* 大region二期设计评审
		
	
		
		

2. 大region二期设计评审
	1）对于KFC打通可以跨小region使用image的逻辑，现定为在本项目发布前，通过线上变更将kfc下线掉。API不修改逻辑，在image
	同步工具同步了需要同步的image后，更新houyi库去掉kfc打通的表关系记录。
	2）跨小region操作快照时，原有vm，device，snapshot所属关系的检查master将不能check，如何解决？
		方案一：废弃已不再使用的参数（文档标记为过时），API只做必要的check，下面列出涉及的接口：
			mount_snapshot	去掉snapshot_at_vm,device参数，只验证snapshot_id和vm_name的user是否为同一用户（类似add_disk，只传递snapshot_id，API验证user即可）
			add_disk			已有check
	3）API使用image的调度策略考虑到老image不可用，master报错误的情况？
		避免用户体验下降
	4）snapshot_type参数现定为由控制系统自己维护，不需要API将此参数传递给master，如此相关接口无需改动。


3. 业务
	 跨region的image的流程如下：
		0、启动vm
		1、传递image id -> open api
		2、open api查询 -> houyi.image； 找出snapshot id
		3、open api查询snapshot对应的OSS -> 通过houyi master（image所在的集群）查询 -> houyidb.snapshot
		4、open api把启动参数（包括上面查出的快照参数） -> houyi master
		5、houyi master -> houyi nc
		6、houyi nc用给的快照参数 -> 启动tdc
	·from:http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=7209612

	OSS中的Object源信息和数据文件都是存放在KV Engine上，在kv存储上封装一个API层，开放调用。

	kfc
		 is the communication component in ApsaraOS. It is the fundamental communication layer of Apsara services like Fuxi, Pangu, Nuwa, etc. 
		It provides a remote procedure call (RPC) interface and enables developers to easily build network-distributed applications.

		有重试机制
		jetty httpclient也有重试机制

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day151 Tuesday, October 16, 2012

1. 
	* 大region二期设计评审修改后再评审
		确认问题方案

		create_vm选择image逻辑
			原有逻辑调度（region，zone）需要考虑image可用性（本小region，kfc打通跨小region，即调度源region列表来自可用region列表），、
			现有逻辑大region下小region间都可使用

			master在查询快照接口提供snapshot_type参数，供API在image调度时保证image可用和保证调度的小region列表为可用image的小region列表。
				若为bucket类型，调度候选小region列表为大region下所有的小region
				若为hash_on_kfc，调度候选小region列表为当前region和kfc打通region

				查询image时，只根据image_no条件得到image及可使用region的map列表
		

		

2. 业务
	if any of the zone,rack,vlan_no,nc is not setted，then need schedule
	VM调度
		大region > 小region > zone > rack > NC > VM；
		其中小region有优先级，优先级region.weight越高，小region越优先被使用。
		将NC按照nc_resource.priority[0,99]分成若干梯度,值越高，NC越优先被使用。
		nc_resource.health[0,5]表示NC的健康程度，在startvm成功时+1,失败则-1。

		将多个小region在逻辑上进行资源统一调度，视作一个大region。
		多个梯度之间做密集调度。
		单个梯度之内做NC的均摊调度。
		VM对region间的选择由API做出。
		控制系统负责VM在region内的调度，选择目标NC。

	]调度方法（从API到控制系统）
		API在启动VM时，优先选择region.weight数值高的集群。
		API发现有多个region.weight一样时，分别让多个控制系统计算库存值并上报，库存值是指每个zone的每个梯度内能启动指定配置VM的库存个数。
		根据汇总的库存值信息，API优先选择高梯度的NC资源，选择高梯度中NC资源最充足的zone，并向这个zone发送create_vm指令。
		控制性收到create_vm信息后，根据nc_r.priority > nc_r.health > nc_load的优先顺序选择一个NC使用，并扣除资源，创建一个pending状态的VM。
		控制系统优先使用权值高的NC，保留低权值的NC资源。
		如果多个NC梯度一致，优先使用健康度（health）高的NC。
		在其他因素一样的情况下，同一梯度、同样健康的的NC资源，优先选择空闲的使用。

	涉及的接口
		api：create_vm
		rpc: CreateVm，QueryVmVolume(vcpus,memory,diskSize)
		nc_resource.priority, region.weight值需要手动设置DB
	
	from：http://10.250.6.111/wiki/index.php/VM%E5%9C%A8%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98

	原有逻辑调度考虑image可用性（本小region，kfc打通跨小region），现有逻辑大region下小region间都可使用

3. 业务
	上传的image和自定义image的区别？
		自定义image基于snapshot
		从image表的字段分析：
			
4. BSS 业务
	快照系统: 虚拟机的快照系统
	BlockStorageServices

	eg:
		blkfront：Dommain U 前端驱动。
		blkback：Dommain 0 后端驱动。
		blktap：转发blkback IO请求的虚拟块设备驱动。
		tapdisk：转发blkback IO请求的用户态进程。
		tdc：也即td connector，将VM的IO请求转发到分布式存储。 TapDisk Connector
		apsara：飞天，分布式平台系统。
		pangu：飞天的一个组件，实现分布式存储。
		BSS： Block Storage System，块存储系统，也即镜像存储系统。
		OSS： Open Storage System, 开放存储系统，也即快照存储系统。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day152 Wednesday, October 17, 2012

1. 
	* 二期设计文档问题梳理，以及

2. 
	create_vm image调度

		先根据image_no查找parent image，因为parent image大region内只有一个，其他的都是为了同步到其他region而复制的，如果删除任意一个，则包括
		parent image及其子image都被删除。故使用时，要确保parent image是存在的。（houyi.image）

		查询出parent image
		根据parent image填充instance的imge基本信息
		调度image具体在那个小region起


		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day153 Thursday, October 18, 2012

1. 
	* 大region二期设计文档问题
		老快照兼容性问题（不能跨小region）
		image调度问题（是否将image的存储类型，存入API作为冗余字段，减少跨系统查询次数）
	* 大region二期已确定需要开发


2. create_vm
	若没有指定zone创建vm：
		原有逻辑是查询出image_no可以被使用的region列表，然后根据算法得出最优的region以及其对应的zone，若没资源或不可用则选择下一梯度，
		直到找到可用的zone（此为已有大region调度逻辑）

		然后从选出的这个最优region中查询（先从本地找，若没有则从KFC找）出对应的image作为启动vm的image	

	能否在image表增加存储类型字段，标识image存储类型，避免跨系统查询。

3. 业务
	新的快照，在大region中只有一份，通过http方式跨小region使用；基于其的image将也是新image
	上线有device订正操作，后面打的快照将都是bucket类型的
		device迁移
	原有的快照不变，即老快照还是存在

	新proxy方案，新老快照都能用。大master？

4. 
snapshot_type取值为int   :    1（HASH_ON_KFC），2（BUCKET_ON_KFC），3（BUCKET_ON_HTTP）


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day154 Friday, October 19, 2012

1. 
	* big region二期开发
		dao层单元测试，jtest注意
			程序jdbc配置在当前用户的目录中；测试框架配置在各自项目jtester配置文件中。
		
2. big region二期开发
	修改原有方法，对应的单元测试方法，在提交时检查是否都修改正确。

3. region别名表，kfc region查询业务说明
	select 
		region_no 
	from region_alias alias 
	where exists (select 1 
			from region_alias 
			where region_no='AT-HOUYIDEV' 
			and real_region_no=alias.real_region_no);	


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day155 Monday, October 22, 2012

1. 
	* 大region二期需求变动
		snapshot_type值在API这边保存一份冗余
			image表，非空，hash或kfc
			涉及的相关改动

		数据库变动，需要DBA review通过
	* 大region二期灰度发布		   需求
		master的小region，按阶段分批升级，API目前是大region升级，需要考虑小region的灰度发布。
		之前的方案：
			- 新存储，大二层网络等通过简单的代码hack方式
			- 通过上层proxy转发，部署不同版本
			- OR 从架构设计上支持灰度发布？

		API和master各自梳理，分析可行性。（proxy方式）

	* 二期，参数废弃待PD确认？


2. 大region二期灰度发布接口整理及支持
	create_vm		老image不跨小region；新快照的image可跨小region
		兼容新老master的调用
	reset_vm		老image不跨小region；新快照的image可跨小region
		参数：vm_name
	mount_snapshot	校验快照user ; 老快照不跨小region，新快照可跨小region ；snapshot_at_vm,device_no文档标注废弃；API到master不再传递snapshot_at_vm和device_no参数;
		参数：vm_name
	unmount_snapshot	校验快照user ; snapshot_at_vm,device_no文档标注废弃 ; API到master不再传递snapshot_at_vm和device_no参数 ; 
		参数：vm_name
	detail_snapshot		master返回值增加snapshot_type
	list_snapshot		master返回值增加snapshot_type ; 
	list_mounted_snapshot	master返回值增加snapshot_type ; 
	create_snapshot	传递aliyun_idkp到master
	add_disk			校验快照user ; 老快照不跨小region，新快照可跨小region ; snapshot_at_vm,device_no文档标注废弃 ; 
	
	
	问题：
		master给出灰度发布带来的影响（比如未发布的小region是否能用http的快照？） - 控制系统整理
		proxy将region没有升级的调用（vm_name对应的vm所在的region是否升级）发送到老的API上。
		新API调老master
		参数废弃
	
3. 设计，规范，编码规范
	参数传递时，封装为对象OR通过多个原子参数来传递？
		封装面向对象，但在中间层不能明显知道底层逻辑和上层逻辑
		单独参数传递，参数个数增加，但条件明显

		参看，开源系统
4. sql修改
	image表：
		alter table image add snapshot_type int(4) NOT NULL COMMENT DEFAULT 1 '@desc 快照存储类型 1-hash_on_kfc;2-bucket_on_kfc';

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day156 Tuesday, October 23, 2012

1. 
	* 大region二期，部分开发继续
	* 二期灰度发布方案讨论，目前两种方案
		- API兼容新老master，以及是否支持新老KFC
		- master兼容新老TDC
		

2. 

3. mysql * mysql myisam ,innodb
	myisam不支持事务，建表语句，show create命令查看表的存储引擎类型是Myisam，改为Innodb类型即可

	jtester db模块插入数据没有回滚，小不解了一番。。。

4. ibatis属性转换，自定义转换
	通过在mapping文件中直接定义或者统一定义
	（1）各自的mapping文件中	（sqlMap）
		<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
		<typeAlias alias="snapshotStorageTypeHandler" type="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>	
		<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER" typeHandler="snapshotStorageTypeHandler"/>
	（2）在config文件中统一配置（sqlMapConfig）
		<typeAlias alias="snapshotStorageType" type="com.aliyun.houyi.constant.SnapshotStorageType"/>
		<typeHandler javaType="snapshotStorageType" callback="com.aliyun.houyi.dao.support.SnapshotStorageTypeHandler"/>

		<result property="snapshotType" column="snapshot_type" javaType="snapshotStorageType" jdbcType="INTEGER"/>

	ibatis参数对象，返回对象的定义问题，注意坑啊。。。

5. 

		     image.xml
		     /houyi-console-dao/src/main/resources/ibatis/image.xml


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day157 Wednesday, October 24, 2012

1. 
	* 二期灰度发布方案
	* 二期开发连调环境搭设
		

2. 设计
	灰度发布功能与业务逻辑剥离，即灰度发布对业务程序是透明的。可有好的方案或设计？灰度发布的粒度问题，API是大region粒度，master是小region粒度。
		根据粒度范围进行灰度，如API是以大region为粒度的，在

alter table 

3. 系统 代码风格 代码规范 重构 优化
	houyi api
		查询快照等的逻辑调用其service层即可，无需再实现。
		commandexecute无需mock

4. 二期开发连调环境搭设
	API ：
		APIf访问地址：6.32
		数据库地址：6.32
		数据库数据：qa测试环境API的数据库
			'mysql -uhouyi -phouyiat03 -h10.230.204.19 houyi --auto-rehash --default-character-set=utf8'
	master环境：
		进入方式：6.27 admin go2houyi1 >  go2houyi3
		ag: 10.230.204.19
		Local_nuwa: 10.230.204.24
		Local_mysql: 10.230.204.19
	MQ：message.properties 
		houyi.message.host=10.230.204.67
		#10.249.38.101  
		houyi.message.port=5672
		houyi.message.username=guest
		houyi.message.password=guest
		houyi.message.queueName=queue1
		houyi.message.retryTime=10
		houyi.message.flag=false
		white.ip=10.230.204.24,10.249.195.162
		lb.server.url=http://10.249.182.102:8088		

	操作：
		拷贝6.33的环境：
			service目录，去掉log等文件；
			/usr/ali/下jboss ，maven，httpd等需要的程序
		修改6.32的环境变量 PATH HOME等
		取到数据库：
			mysqldump -hxx -uxx -pxx dbname > ./xx.sql
			修改相应的表：（保证数据可用）
				region
					at03
				zone
					cluster=3
				region_alias
				master_region

			修改新API的jdbc配置指向到上面的新库
		MQ配置修改：配置mq地址，访问账户，端口等

		bigRegionNo=cn-hangzhou-xy2-test01

		houyimonitor0过大，mysql报：ERROR 1030 (HY000): Got error 28 from storage engine			


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day158 Thursday, October 25, 2012

1. 
	* 二期灰度方案讨论
		API做代码兼容的方案
	* slb api文档内部评审
		准备对外开放
		流量接口带宽，计量库存最近时间带宽瞬时值，API给出为时间段的平均带宽
	* create_vm		 系统
		ballon参数校验

2. 二期灰度方案讨论
	API做代码兼容的方案
		- 二期涉及的接口兼容问题
		- 原有的接口是否能兼容的评估
	
		
3. 参数废弃问题基于灰度方案的确定
	- API兼容新老master则，废弃参数需要在master都升级完时公布，返回值废弃可发布开始后公布；
	- master兼容底层时，废弃参数和返回值废弃都可在发布时公布

 select image_no,user_id from image where region_no='AT03-HOUYI3' and status=0 and image_no not like '%lyytest%' and user_id=229;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day159 Friday, October 26, 2012

1. 
	* 二期灰度方案3API修改代码评估
	* 
		

2. 看jdk源码一个方法的写法     源码学习 方法引用 deprecated

	javax.management.MBeanServerFactory.findMBeanServer(String agentId)

	/**
	* <p>Return a list of registered MBeanServer objects.  A
	* registered MBeanServer object is one that was created by one of
	* the <code>createMBeanServer</code> methods and not subsequently
	* released with <code>releaseMBeanServer</code>.</p>
	*
	* @param agentId The agent identifier of the MBeanServer to
	* retrieve.  If this parameter is null, all registered
	* MBeanServers in this JVM are returned.  Otherwise, only
	* MBeanServers whose id is equal to <code>agentId</code> are
	* returned.  The id of an MBeanServer is the
	* <code>MBeanServerId</code> attribute of its delegate MBean.
	*
	* @return A list of MBeanServer objects.
	*
	* @exception SecurityException if there is a SecurityManager and the 
	* caller's permissions do not include or imply <code>{@link
	* MBeanServerPermission}("findMBeanServer")</code>.
	*/
	public synchronized static ArrayList<MBeanServer> findMBeanServer(String agentId) {
		....
	}				
	方法名；参数说明；返回值；异常返回都定义的清楚明了，看到这些说明这个方法如何用也就一目了然了。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day160 Monday, October 29, 2012

1.
	* ace4j发布
	* 大region二期
		cache部分，可提供内部管理用接口，只供内部调用
		接口粒度的访问控制（是否可访问与访问频度），通过前端OR内部支持？
	* 二期delay（错开飞天发布）
	* 飞天升级前拆除KFC
		步骤：
			- 同步kfc通的image
			- 订正device数据，houyi库
			- 跨kfc使用image订正，跨打快照订正
			- 拆kfc

2. 二期delay（飞天发布）
	当前开发状态：
		- 参数废弃部分，需求待确定，代码没变动
		- 灰度发布，改动一部分代码
			从create_vm开始（未修改完）

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day161 Tuesday, October 30, 2012

1. 
	* bugfix项目需求
	* API优化部分
		缓存方案统一，功能完善 待
	* 

2. 

3. 问题分析与解决方案 -tip-
	若小region不能访问（断电，网络异常等），导致大量后端请求超时，耗尽web服务器的线程资源，最终正常region的请求服务不可用。
		瞬时操作与耗时操作分开线程池执行？如何区别是否耗时？
		continue机制，非堵塞机制
	
	region有status状态属性来标识region是否可用，但region拦截器查询时没有加入status状态。
		region的状态提供HA机制（如果可访问则状态为可访问，若检测结果确认为不可访问状态则置为不可访问），然后程序调用前判断此状态即可。减少无谓的超时等待。
		通过程序来check服务可用性结合是否可用的配置，尽量减少可感知的超时等待消耗。

	region拦截器查询region逻辑是否要修改？是否有接口可运行region关闭时操作

	全部down过后的恢复问题
		服务启动步骤，大量服务并发启动要考虑的问题等
	
	严重异常问题的提前考虑：
		目标保证服务可用。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day162 Wednesday, October 31, 2012

1. 
	* 问题分析
	* AOne2.0培训
	* 
2. 

3. jstack ，kill -3
	执行sudo kill -3 PID获取thread dump log（PID是第一步获取）。 
	注意：在不同的linux环境下执行输出的日志的地方可能不同。在IBM的PowerPC小型机上的linux上执行kill -3 pid会在工作目录下产生类似javacore.20100409.161739.7614.0001.txt的文件。JBOSS默认环境下，thread dump log输出到jboss console，所以thread dump信息会输出到个人定义的控制台(如jboss的控制台log)打印log中。 
	部分示例如下所以：

	man java  jvm通过SIGQUIT信号产生线程dump（来自java的man说明）
		Sun’s JVM uses SIGQUIT to perform thread dumps

	线程死锁堆栈数据分析：
	------------
		"ajp-0.0.0.0-8009-1504" daemon prio=10 tid=0x00007f81a518f800
		nid=0x6554 waiting for monitor entry [0x00007f8142c29000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.numBuffers(RAMFile.java:79)
			- waiting to lock <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:87)
			at org.apache.lucene.store.RAMInputStream.readBytes(RAMInputStream.java:73)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:82)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.MultiTermQueryWrapperFilter.getDocIdSet(MultiTermQueryWrapperFilter.java:131)
			at org.apache.lucene.search.ConstantScoreQuery$ConstantWeight.scorer(ConstantScoreQuery.java:139)
			at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:298)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:391)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)

		we have 1172 threads in same state.

		there are two threads which already lock the object:

		"ajp-0.0.0.0-8009-548" daemon prio=10 tid=0x00007f81a510b000
		nid=0x1c64 waiting for monitor entry [0x00007f81897d5000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.getBuffer(RAMFile.java:75)
			- locked <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:97)
			at org.apache.lucene.store.RAMInputStream.readBytes(RAMInputStream.java:73)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:82)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.TermCollectingRewrite.collectTerms(TermCollectingRewrite.java:40)
			at org.apache.lucene.search.TopTermsRewrite.rewrite(TopTermsRewrite.java:58)
			at org.apache.lucene.search.MultiTermQuery.rewrite(MultiTermQuery.java:296)
			at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:378)
			at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:378)
			at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:589)
			at org.apache.lucene.search.Searcher.createNormalizedWeight(Searcher.java:167)
			at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:661)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)


		"ajp-0.0.0.0-8009-663" daemon prio=10 tid=0x00007f81c503d800
		nid=0x225b waiting for monitor entry [0x00007f8182462000]
		   java.lang.Thread.State: BLOCKED (on object monitor)
			at org.apache.lucene.store.RAMFile.numBuffers(RAMFile.java:79)
			- locked <0x000000054b1daa98> (a org.apache.lucene.store.RAMFile)
			at org.apache.lucene.store.RAMInputStream.switchCurrentBuffer(RAMInputStream.java:87)
			at org.apache.lucene.store.RAMInputStream.readByte(RAMInputStream.java:63)
			at org.apache.lucene.store.DataInput.readVInt(DataInput.java:105)
			at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:64)
			at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)
			at org.apache.lucene.search.FilteredTermEnum.next(FilteredTermEnum.java:77)
			at org.apache.lucene.search.FilteredTermEnum.setEnum(FilteredTermEnum.java:56)
			at org.apache.lucene.search.WildcardTermEnum.<init>(WildcardTermEnum.java:65)
			at org.apache.lucene.search.WildcardQuery.getEnum(WildcardQuery.java:59)
			at org.apache.lucene.search.MultiTermQueryWrapperFilter.getDocIdSet(MultiTermQueryWrapperFilter.java:103)
			at org.apache.lucene.search.ConstantScoreQuery$ConstantWeight.scorer(ConstantScoreQuery.java:139)
			at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:298)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:524)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:391)
			at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:298)
	------------
	上面第一个线程在等待锁，下面两个线程已经拿到锁。如果拿到锁的一直不释放，则等待锁的线程将BLOCKED在哪里，随着时间推移，线程池中资源将被耗尽~~

4. java.net.socketinputstream.socketread0 hangs thread
	socket read一直hang住，原因：
		- 依赖服务不稳定
		- 数据量太大，处理时候很长。
	解决方案：
		- 提升服务稳定性
		- 调用者设定超时


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day163 Thursday, November 01, 2012

1. 
	* 6.33搭设ace4j API+6.27master
		更新api包
	* slbapi问题
		db断线后，请求过来，导致too many open files
		jdbc配置域名，mysql命令行可连上mysql，java程序报 java.net.UnknownHostException

		java dns缓存
		重启服务OR命令行中配置不缓存
	* bugfix项目需求讨论

2. 

3. 禁用Java DNS缓存-Disable DNS caching
	http://itindex.net/blog/2007/01/22/1169462290428.html

	java命令中加上参数：Dsun.net.inetaddr.ttl=0 


4. too many open files 问题
	场景：
		linux打开大量socket
		socket没有正常关闭。为了定位问题是否由Java进程引起，通过Java进程号查看当前进程占用文件描述符情况： 
		Java代码  
		lsof -p $java_pid 每个文件描述符的具体属性  
		lsof -p $java_pid | wc -l  当前Java进程file descriptor table中FD的总量  
		ls /proc/$PID/fd | wc -l
		ls /proc/8633/fd/ -al |grep socket 查看进程打开的socket数

			分析命令的结果，可判断问题是否由非正常释放资源所引起。


5. nuwa命名服务
	kuafu http proxy http_proxy
	kfc协议的支持需要同cluster，规模受限，通过proxy方式，跨cluster

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day164 Friday, November 02, 2012

1. 
	* 

2. 

3. wiki维护
	API线上问题：
		http://wiki.ec.alibaba-inc.com/index.php/API/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98
4. nslookup


5. 域名不能解析，mysql命令行却能访问的问题
	测试场景：
		6.33 API
			JDBC的数据库地址配域名指向6.32
			启动API,访问正常
			修改/etc/hosts
			修改上面指向6.32的域名
			大量调用API访问数据库，API错误日志再大量请求时会报：Caused by: java.net.UnknownHostException: xxx；但是，请求量小时，不会报上面的错误
				是因为连接池中，有指向原来域名指向的IP，新建的连接由于域名改变，不能解析，出现的条件是，请求量大到需要再建立连接时报错，对API启动时已
				创建的连接不影响。

		6.32 DB

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
November 05, 2012 - November 07, 2012
take some days off



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day165 Thursday, November 08, 2012

1. 
	* bugfix项目
		http proxy替换
		join/leave group接口支持用户体系改造逻辑
	* SLB的大region兼容改造&发布计划
		数据订正check
	* 
2. 
	项目管理从redmine迁移到aone
		http://aone.alibaba-inc.com/aone2/project/134/task?_token=e18619aa-95f5-4590-9fda-b88be2554147
	bugfix API branch：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bugfix_201211
	http proxy doc：
		http://wiki.ec.alibaba-inc.com/index.php/Http_proxy%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0#HA.E6.9C.BA.E5.88.B6.EF.BC.9A
		http proxy的功能 http proxy http_proxy kuafu 
			取代并兼容目前kfc内置的http服务器	
				kuafu协议支持的集群规模有限,不能跨cluster，通过proxy层来实现跨集群访问
			从houyiAPI接收http请求，转化为kfc request

3. resourceChecker
	instanceServiceImplTest

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day166 Friday, November 09, 2012

1. 
	* bugfix项目开发
		
	* 
		

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day167 Monday, November 12, 2012

1. 
	* bugfix项目
		remove_disk接口使用问题：
			新增mount,unmount disk接口，并修改查询disk接口的返回值，带上挂载状态便于remove_disk接口确认待删除的盘。
			mount_disk
			unmount_disk
			detail_disk
	* 双11，线上问题
	* list_mounted_snapshot
		返回值中：device_no是原snapshot基于的device
	* 网络存储
		并发IO问题(如第一次的读取ISO，有限制)

2. 线上问题
	-----
	问题1：创建VM（AY12111011204528c1514），控制系统在执行以下操作时存在deadlock
	【API收到控制系统返回】：
	2012-11-11 00:33:00,665  ERROR [ajp-127.0.0.1-8109-25] (ApsaraCommandExecutor.java:79) - failed to call houyi system,command:CreateVm, parameters: {"rackId":"","recoverable":0,"imageUrl":"","isoName":"","vcpus":1,"intranetRx":-1,"canBalloon":0,"baseUrl":"","ioValue":5,"ncId":"","userId":"29629","hostName":"AY12111011204528c1514","deviceId":"","vType":"","imageDeviceId":"70000006","internetRx":-1,"cpuValue":5,"startupMode":"init","imageClusterId":"1007","kernelId":"","ramdiskUrl":"","baseSize":0,"kernelUrl":"","vmName":"AY12111011204528c1514","isBlind":0,"imageVersion":"1","baseVersion":"","vlanId":"","intranetTx":-1,"imageSnapshotId":"259911","imageId":"centos5u4_32_20G_alibase_v01.vhd","mountType":1,"rate":-1,"lbType":"","baseType":0,"ballonEnable":0,"baseId":"","dataAvail":1,"imageSize":20,"internetTx":1024,"memory":1536,"snapshotSize":20,"zoneId":"cn-hangzhou-dg108-a","canMigrate":0,"groupId":"142837","initPasswd":"acff3fd1","pubKey":"","netValue":5,"ramdiskId":"","isoPath":"","imageType":2,"diskSize":40}; result: {"code":  -5025,"desc":  "mysql error","isSuccess":  "FALSE"}.

	【控制系统内部日志】：
	[2012-11-11 00:33:00.641520] [ERROR] [15519] [build/debug64/houyi/common/houyi_metadata_process.cpp:2700] [method=update MAC]:update MAC fail[sql=update mac set name='AY12111011204528c1514', scope = 2, gmt_modify='2012-11-11 00:33:00' where mac='00:16:3e:12:12:1b']:[mysql error=Deadlock found when trying to get lock; try restarting transaction]


	问题2：补偿重试创建VM（AY12111011204528c1514）时，控制系统报存在该VM的数据。
	PS:该VM第一次创建时，控制系统提示“mysql error“，API收到控制系统创建失败的信息，对该VM记录进行了回滚，但控制系统的VM记录并没有回滚。

	【API收到控制系统返回】：
	2012-11-11 01:14:13,336  ERROR [ajp-127.0.0.1-8109-3] (ApsaraCommandExecutor.java:79) - failed to call houyi system,command:CreateVm, parameters: {"rackId":"","recoverable":0,"imageUrl":"","isoName":"","vcpus":1,"intranetRx":-1,"canBalloon":0,"baseUrl":"","ioValue":5,"ncId":"","userId":"29629","hostName":"AY12111011204528c1514","deviceId":"","vType":"","imageDeviceId":"70000006","internetRx":-1,"cpuValue":5,"startupMode":"init","imageClusterId":"1007","kernelId":"","ramdiskUrl":"","baseSize":0,"kernelUrl":"","vmName":"AY12111011204528c1514","isBlind":0,"imageVersion":"1","baseVersion":"","vlanId":"","intranetTx":-1,"imageSnapshotId":"259911","imageId":"centos5u4_32_20G_alibase_v01.vhd","mountType":1,"rate":-1,"lbType":"","baseType":0,"ballonEnable":0,"baseId":"","dataAvail":1,"imageSize":20,"internetTx":1024,"memory":1536,"snapshotSize":20,"zoneId":"cn-hangzhou-dg108-a","canMigrate":0,"groupId":"142837","initPasswd":"acff3fd1","pubKey":"","netValue":5,"ramdiskId":"","isoPath":"","imageType":2,"diskSize":40}; result: {"code":  -15017,"desc":  "this vm name already exists","isSuccess":  "FALSE"}. 

	问题3：API后台日志看到存在distributed_flag_lock表的Deadlock异常

	Caused by: com.ibatis.common.jdbc.exception.NestedSQLException:
	--- The error occurred in ibatis/distributed_flag_lock.xml.
	--- The error occurred while applying a parameter map.
	--- Check the distributed_flag_lock.unLockAllLockedRecordsBeforeDate-InlineParameterMap.
	--- Check the statement (update failed).
	--- Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction
		at com.ibatis.sqlmap.engine.mapping.statement.MappedStatement.executeUpdate(MappedStatement.java:107)
		at com.ibatis.sqlmap.engine.impl.SqlMapExecutorDelegate.update(SqlMapExecutorDelegate.java:457)
		at com.ibatis.sqlmap.engine.impl.SqlMapSessionImpl.update(SqlMapSessionImpl.java:90)
		at org.springframework.orm.ibatis.SqlMapClientTemplate$10.doInSqlMapClient(SqlMapClientTemplate.java:413)
		at org.springframework.orm.ibatis.SqlMapClientTemplate.execute(SqlMapClientTemplate.java:209)
		... 18 more
	Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction

	问题4：VM（AY12111112291654c6269）第一次启动失败(失败原因的日志如下)，第二次启动是成功的
	【NC日志】：
	[2012-11-11 01:36:06.145832] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:617] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:AddRule failed ret:-1
	[2012-11-11 01:36:06.146052] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:128] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:SetControlIpChain failed ret:-1
	[2012-11-11 01:36:06.146104] [DEBUG] [24254] [build/debug64/houyi/nc/nc_firewall.cpp:186] [vmName=AY12111112291654c6269][type=1][versionFrom=2]:SetInternetAllFireWall fail
	[2012-11-11 01:36:06.238157] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2059] config redhat ip 00:16:3e:12:15:7d eth1 42.121.53.76 255.255.252.0 42.121.55.254:0:success
	[2012-11-11 01:36:06.422903] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2086] config redhat default_gw 42.121.55.254:0:success
	[2012-11-11 01:36:06.573502] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2114] config redhat route 192.168.0.0 16 10.200.127.254 eth0:0:success
	[2012-11-11 01:36:06.663574] [INFO] [16733] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:967] Msg:vm[iso-AY12111112291654c6269] stopped 5 second after shutdown
	[2012-11-11 01:36:06.683631] [ERROR] [16733] [build/debug64/houyi/nc/handlers/nc_vm_handler.cpp:733] [vmname=AY12111112291654c6269]:init vm failed, do not start vm
	[2012-11-11 01:36:06.693163] [DEBUG] [16733] [build/debug64/houyi/nc/handlers/nc_handler.cpp:29] Msg:succeed to send response:StartVmRsp:sequence:4358921489341223957
	[2012-11-11 01:36:06.710829] [DEBUG] [18769] [build/debug64/houyi/nc/vm_xen_wrapper.cpp:2114] config redhat route 172.16.0.0 12 10.200.127.254 eth0:0:success

	-----

3. 组件化
	组件化设计 模块热插拔 模块化 
		面向统一的接口，热部署组件（功能）
	OSGI 
		类似eclipse，可以通过插件的方式增加其功能。
	openfire

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day168 Tuesday, November 13, 2012

1. 
	* 
	* slb v2 
		cache ，mark in doc
	* slb v2
		region_no参数传递问题：定位slb后端地址，是否在api层维护lbId和region_no关系，除创建LbId，其他接口可不传region_no？待分析
	* kfc拆除c，d，API的instance缓存需要清除（缓存了image_id）
		
		
	

2. slb 生产环境 slb api
	10.250.6.37 
	sarah.wangq@shterm.aliyun-inc.com
	slb api
	slbapi(mysql)		       go2

	check
		update vm region_no to bigRegionNo(1 to 1)
	原多个vm region对一个lb region，现一个vm big region对应一个lb region
	
3. too many open files

	--------
	2012-10-16 21:05:14,658 ERROR [com.aliyun.slb.api.service.impl.RsServiceImpl] - [error occur] java.net.SocketException: Too many open files
		at java.net.Socket.createImpl(Socket.java:397)
		at java.net.Socket.getImpl(Socket.java:460)
		at java.net.Socket.bind(Socket.java:577)
		at sun.reflect.GeneratedMethodAccessor59.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.apache.commons.httpclient.protocol.ReflectionSocketFactory.createSocket(ReflectionSocketFactory.java:139)
		at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:125)
		at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)
		at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
		at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
		at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
		at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
		at com.aliyun.slb.api.util.http.HttpUtil.sendRequest(HttpUtil.java:52)
		at com.aliyun.slb.api.service.impl.RsServiceImpl.queryIpByName(RsServiceImpl.java:42)
	--------
	场景：
		master服务不可用，并发请求 queryIpByName且超时过长或不超时，导致sock打开过多？ 待验证

		java的socket实现类会根据需要创建TCP或者UDP socket（具体创建由native方法去做）	- 参考 java.net.Socket.createImpl	* 本地方法 JNI (java native interface)JNA(java native access)

		本地方法设置socket超时例子： java.net.PlainSocketImpl private native void socketConnect(InetAddress address, int port, int timeout) 


	总结：
		对于系统依赖部分逻辑，需要考虑超时问题，避免因为第三方服务不稳定影响自身服务的稳定。
		打开的流要关闭
		根据并发量配置linux进程打开文件数属性：ulimit -a ；ulimit -n 4096 ；修改/etc/security/limits.conf 添加如下一行：	      * - nofile 1006154 修改/etc/pam.d/login添加如下一行 session required /lib/security/pam_limits.so

4. timeout问题 超时问题 socket超时
	apache的commons-httpclient-3.1.jar封装的socket默认超时为0，即不会超时，需要显式的设置超时时间。
	设置超时说明为：Sets the default socket timeout (SO_TIMEOUT) in milliseconds which is the timeout for waiting for data

	比如设置超时30s，在一定的并发下可保证服务的稳定，一旦超过一个阀值，连接池被耗尽，再继续并发，大量socket拥堵达到文件打开数上限（待验证）

	ulimit -a 配置信息
	ulimit -p $PID 查看PID打开的文件数
5. find . "*.log" | xargs grep -H "UnknownHostException: my3320.mysql.aliyun.com"
	linux查询字符串，查询文本，查询内容

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day169 Wednesday, November 14, 2012

1. 
	* bugfix201211
		release_ip
		modify_flow_limit
	* 连调测试
		

2. log4j配置
	web.xml
	<context-param>
		<param-name>log4jConfigLocation</param-name>
		<param-value>file:${user.home}/.houyi/log4j.xml</param-value>
	</context-param>
	<!-- 配置重加载 -->
	<context-param>
		<param-name>log4jRefreshInterval</param-name>
		<param-value>10000</param-value>
	</context-param>

	log4j放在上下文中的属性。其他方式。。

3. log日志不更新小问题 -tip-
	java web服务以admin起动，但是之前以root启动过，导致log等文件的权限都是root的，这样java服务是ok的，但log始终不会更新，排除了log4j的配置问题和其他可能，最后定为是
	linux系统文件写权限问题，囧。。。。

	chown -hR admin:admin logs/

	修改后，若不重启java服务，日志还是不会更新（why？），重启即可。

4. 频度控制 -tip-
	对于API接口的频度控制：基于IP，基于调用者?
		独立于API之外的服务来控制调用频度/调用频率

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day170 Thursday, November 15, 2012

1. 
	* bugfix201211连调
		modify_flow_limit
			shutted状态问题？
		query_group_vm 此接口不支持用户体系改造，是否修改？
			确定修改

	* slb api httpclient连接关闭问题
2. maven clean时，linux中若文件被ln连接引用，需要删除引用（如target中的war包被引用）


3. too many open files错误
	httpclient的连接别样被关闭？
		slb v2 设置了连接超时，等待数据超时
		但是没有关闭connection
		假设，系统在设定的时间过后，关闭socket

		测试：
			系统回收socket时间周期内，发送超过操作系统限制的进程打开文件数，抛出异常。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day171 Friday, November 16, 2012

1. 
	* 连调
		query_group_vm接口单元测试编写
2. 

3. CLOSE_WAIT
	TCP/IP协议说明，由于被动关闭连接会产生CLOSE_WAIT状态。
	测试httpclient：
		测试sendRequest方法
		参数：url=www.baidu.com,method=get
		循环次数：num=1000
		执行好后sleep 2min
		
		测试2种场景：
			1）关闭连接
				HttpClient httpClient = new HttpClient(new SimpleHttpConnectionManager(true));
			2）不关闭连接
				HttpClient httpClient = new HttpClient();				

		对比上面两种场景的检测数据：
			ps -ef | grep java 找到当前测试运行的java进程PID
			netstat -anpc |grep 220.181.111.148 |grep CLOSE_WAIT - 查看CLOSE_WAIT状态的连接

		分析结果：
			场景1）中，没有CLOSE_WAIT瞬时状态; 关闭连接的情况要处理好，数据没有读取完毕就关闭连接报java.net.SocketException: Connection reset异常
				执行好后，没有到www.baidu.com的socket连接	，netstat -anpc |grep 220.181.111.148为空
			场景2）中保持有170个的CLOSE_WAIT状态的socket，直到测试进程结束才会断开socket。
			netstat -anpc |grep 220.181.111.148

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day172 Monday, November 19, 2012

1. 
	* API事务lock分析
		pool exhausted ？
			有慢数据库连接
	* review代码阅读
		id=182672 kelude
		=173658
2. API事务lock分析
	pool exhausted ？
		有慢数据库连接占满pool
		maxactive数不够
		pool中的连接有问题
		工具自身bug
3. shell

4. starting状态  业务
	一直处于starting状态的原因之一：master重启，导致状态不一致


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day173 Tuesday, November 20, 2012

1. 
	* slb api数据检查
	* houyi api
		并发add_disk,remove_disk的问题
		40 (+ 5 + 5 - 5 concurrent) = 45 ？50

		http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9252783


	* httpclient3.1
		CLOST_WAIT过多问题
	
		(1) 通过设置请求头参数：
			httpMethod.setRequestHeader("connection", "close"); //此消息头参数参考：http://www.ietf.org/rfc/rfc2616.txt Hypertext Transfer Protocol -- HTTP/1.1	第14.10节
				----
				HTTP/1.1 defines the "close" connection option for the sender to signal that the connection will be closed after completion of the response. For example,
				Connection: close
				in either the request or the response header fields indicates that the connection SHOULD NOT be considered `persistent' (section 8.1) after the current request/response is complete.
				----
				from: http://www.ietf.org/rfc/rfc2616.txt
		(2) 通过httpclient中simpleconnnectionmanager的带参构造函数实现，单元测试ok，但运行时计量推送逻辑有问题，报错如下：
			Caused by: java.lang.NoSuchMethodError: org.apache.commons.httpclient.SimpleHttpConnectionManager.<init>(Z)V
			at com.aliyun.houyi.util.HttpUtil.sendRequest(HttpUtil.java:48)
			根据错误，是找不到对应的方法。？

		连接复用与多线程并发问题：连接复用，连接保持，connection persistence
			可以通过httpclient提供的			
	* master(java) 无状态 ，多个平级master管理一个多nc的大region
		选型 
			Dubbo http://baike.baidu.com/view/6901431.htm

2. slb api数据检查
	当前slb api数据库，
	DB地址:	10.242.252.41 slbapi
	139dc81f48f-cn-hangzhou-dg-a01,10.241.2.118	(rs表没有此lb_id，也没有此ip)
	13a0a5e12cc-cn-hangzhou-dg-a01,10.200.2.34	(rs表有这个lb_id，但没有这个ip的记录)
	13ae9d4087f-cn-hangzhou-dg-a01,10.200.115.236	 (rs表没有此lb_id，也没有此ip)

	根据上面的分析，“上述三个lb – rs(ip)的对应关系不存在于api的数据库中”

3. 同时修改同一数据的问题
	select instance_no,disk from instance where instance_no='mytest2012-11-1' for update;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day174 Wednesday, November 21, 2012

1. 
	* slb v2 聚石塔项目slb后端api有变动，api分析是否需要相应的变动，详见邮件
	* bugfix201211代码review
	* user_reform后代理商自己的vm的释放问题
	* slb后端直接配置的vip，现需要通过slb api来配置，对应的slb api数据库订正问题
	* slb api线上日志分析，add_rule报错
		
2.  代码review
	(1) create_vm的disk参数，如果传入了非空，但却没有校验（大小范围，格式）？	  还是这个值就该废弃，即用户指定disk时会有问题
		后面有不为空时的参数校验，此处ok
	(2) 
3. user_reform后代理商自己的vm的释放问题
	release_vm时API要做的处理：
	1) 退出 vm 所在的所有组
		- 根据instanceId查询出vm所在的groupId列表：
			SELECT group_id
			FROM group_instance
			WHERE instance_id = #instanceId#
		- 根据group所在的bigRegionNo找到其对应的masterRegion	作为目标regionNo
			SELECT
					 id,
					big_region_no,
					master_region_no,
					gmt_create,
					gmt_modify
			FROM master_region
			WHERE big_region_no = #bigRegionNo#
		- 生成一条设置防火墙规则到api数据库，返回messageId(主键)
			sfw_command表：event=6(leaveGroup)，data={"groupId":xxx,"instanceId":xxx}，target=xxxRegionNo(instance.getRegionNo())，gmt_create=xxx,gmt_modify=xxx
			返回 messageId
		- 构造leaveGroup的RPC请求：
			ExitGroup 
			regionNo=上面的目标regionNo
			messageId，groupId，vmName
			发送到netc
		- 上面leaveGroup的RPC成功调用后，删除group_instance表对应的记录
			delete from group_instance 
			where group_id = #groupId# 
			and instance_id = #instanceId#
		- 构造下发防火墙的RPC请求
			SetFireWall
			messageId=xxx（上面的主键ID），type=6，data={groupId=xxx,vmName=xxx}(Map)
			发送到netc
			 regionNo=
				根据bigRegionNo找到其对应的小reginNo列表，依次遍历得到的小region并调用上面的RPC下发防火墙（只记录失败，不回滚操作）			
	2) 释放IP
		- RPC查询vm的公网ip列表(List<String>) ，得到公网ip列表
			GetPublicIpsByName
			regionNo=instance.getRegionNo()
			vmName=intance.getIntanceNo()

			结果处理：（是否已有此RPC功能的脚本命令？）
				取publicIpList对应的内容，ip列表
		- RPC查询vm的vip列表(List<String>)，得到vip列表和port列表
			GetMemberInfo
			vmName=instance.getInstanceNo()
			port=-1
			发送到netc
		-RPC调用释放vm的公网ip和vip
			RemovePublicIp
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			发送到netc
	3) 释放VM(兼容处理控制系统是否有此vm)
		- RPC查询vm，判断vm在控制系统是否存在
			GetVmInfo
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			发送到master
		- 若上面的返回成功（取json串的isSuccess的值-true/false），RPC调用控制系统释放vm，(CLC释放？)
			DestroyVm
			regionNo=instance.getRegionNo()
			vmName=instance.getInstanceNo()
			clearDatabase=0
			发送到master
	4) 释放VM后，检出待释放的VIP
		- RPC遍历查询步骤2)得到的vip地址列表，去掉列表中不存在的vip-port
			GetVipInfo						
			vip=xxx
			vipPort=xxx
			userId=instance.getUserId()
			发送到netc
		- 合并步骤2)得到的ip列表和上面处理过的vip列表（没有使用？）
	5) 更新API数据库的vip表
		delete from `vip`
		where instance_no=#instanceNo#
	6) 更新API数据库的instance信息
		instance表：
			statusComment=""
			status=8
			instanceNo=instance.getInstanceNo()

	具体操作的工具实现通过脚本：
		python		

4. slb后端直接配置的vip，现需要通过slb api来配置，对应的slb api数据库订正问题
	
5. slb api线上日志分析，add_rule报错
	http://10.200.219.250/slb/api?action=add_rule&aliyun_idkp=146&frontend_port=80
	&lb_id=13a8663a28d-cn-hangzhou-dg-a01%0D%0A&region_no=cn-hangzhou-dg-a01
	&rule_list=%5B%7B%22domain%22%3A%22tzm123456.aliapp.com%22%2C%22rs_pool_name%22%3A%22tzm123456.aliapp.comace4j%22%7D%5D
	&session=b9ALSaJIBZaMJd3UwH%2BAFw%3D%3D&timestamp=2012-11-20+19%3A34%3A13&sign=nHwrhyW%2BOUcmCSIr42b%2BVA%3D%3D&sign_type=MD5

	13a8663a28d-cn-hangzhou-dg-a01%0D%0A 
		这里后面多了个换行符 "\r\n"	utf-8 = %0D%0A
	
	请求到slb api时，lb_id作为参数，末尾带了 \r\n 是允许的；但api提供的rest接口，在用lb_id构造uri后，请求此uri时报错。
		api需要捕获这个异常，即透明构造请求后端的url时，需要做基本的校验，便于用户知道哪里错了？
			构造uri时需要校验参数，保证uri是合法的。

	http://10.250.8.214/open/services%0D%0A?
		500 tomcat错误页面
			需要包装下。
			比如，上面的uri不合法，是否在nginx层就拦截掉并指向到友好的界面？
				还是服务器自己定位吧，nginx只转发，职责清晰。

6. 错误处理 -tip-
	错误重定向，比如对500,503等错误定向到友好的提醒页面（对于uri不合法的错误定向）
		
	系统建议

7. slb后端绕过api陪的vip重新从api走，db订正
	insert into xx (vm_name,ip,rs_pool_name,user_id,lb_id,region_no) values('vmName','10.241.48.113','1313-80-http',39314,'1394c332d0a-cn-hangzhou-dg-a01','cn-hangzhou-dg-a01');
	...
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day175 Thursday, November 22, 2012

1. 
	* bugfix201211 review
	* 事务
	* api并发接口测试，Full GC导致TPS抖动问题


2. 事务 中间状态 并发控制
	接口操作的事务控制，比如并发去start_vm，release_vm时，并发修改vm的状态需要控制。
	可以用悲观锁来串行化修改状态的操作，然后释放锁，这个状态在操作完成后再更新。

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day176 Friday, November 23, 2012

1. 
	* TIME_WAIT状态
	* Full GC问题



2. 大量TIME_WAIT状态的问题		       * TIME_WAIT
		客户端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口
	状态为TIME_WAIT
	 
	是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？
	有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？
	 
	主动关闭的一方在发送最后一个ack 后
	就会进入TIME_WAIT 状态 停留2MSL（max segment lifetime）时间
	这个是TCP/IP必不可少的，也就是“解决”不了的。
	也就是TCP/IP设计者本来是这么设计的

	通过设置系统socket相关参数，比如linux下：
		调整内核参数解决，
		vi /etc/sysctl.conf

		编辑文件，加入以下内容：
		net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
		net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
		net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
		net.ipv4.tcp_fin_timeout 修改系統默认的 TIMEOUT 时间
		 
		然后执行 /sbin/sysctl -p 让参数生效。
		
	TIME_WAIT状态的意义：
		主动关闭的一方在发送最后一个ack 后
		就会进入TIME_WAIT 状态 停留2MSL（max segment lifetime）时间
		这个是TCP/IP必不可少的，也就是“解决”不了的。
		也就是TCP/IP设计者本来是这么设计的
		主要有两个原因
		1。防止上一次连接中的包，迷路后重新出现，影响新连接
		  （经过2MSL，上一次连接中所有的重复包都会消失）
		2。可靠的关闭TCP连接
		  在主动关闭方发送的最后一个ack(fin) ，有可能丢失，这时被动方会重新发
		  fin, 如果这时主动方处于CLOSED 状态 ，就会响应rst 而不是ack。所以
		  主动方要处于TIME_WAIT 状态，而不能是CLOSED 。
		TIME_WAIT 并不会占用很大资源的，除非受到攻击。
		还有，如果一方send 或recv 超时，就会直接进入CLOSED 状态

3. java DNS缓存  java dns * dns缓存
	不缓存DNS		
	-Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0

	通过在 JAVA_OPTS 参数中设置值(执行shell时设置一些参数)：
		export JAVA_OPTS="-Xms128m -Xmx1024m -XX:MaxPermSize=256m -Xrunjdwp:transport=dt_socket,address=8788,server=y,suspend=n -Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0 $JAVA_OPTS"

		$JAVA_OPTIONS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n
			注意：这里suspend参数表示启动时是否挂住等待调试连接，一般设置为n，若需要启动时就进行调试可以设置为y

	
4. agent's vm
	set its own user_id as agent_id to release vm.

5. Full GC问题
	目标减少full gc：
		full gc的触发是由于年轻代被耗尽，中老两代空间也被用完。
		年轻代，年老代，
	造成full gc的原因：
		主要原因可能为，程序代码所致（产生大量的对象，忘记释放资源等）
		再者可能与框架有关

	分析办法：
		可通过排除法，从最简单的逻辑，通过测试排除来找到导致频繁full gc的原因。
6. nc资源被耗尽
	xm list
7. 零拷贝(zero-copy)和环形队列缓存队列问题 队列结构的实现
	
	BlockingQueue
	ConsistentHashMap

	参考：http://www.cnblogs.com/wanderxjtu/archive/2009/04/25/1443518.html Zero Copy I: User-Mode Perspective
	
8. jetty continuation & servlet3.0(NIO)
	"Continuations will be replaced by standard Servlet-3.0 suspendable requests once the specification is finalized. Early releases of Jetty-7 
	are now available that implement the proposed standard suspend/resume API"
	from: http://docs.codehaus.org/display/JETTY/Continuations

	continuaton缺点，导致编程模型复杂，需要切分io操作。
	
	continuation and servlet3.0 ：http://webtide.intalio.com/2009/07/continuations-to-continue-2/
	
	Servlet3.0
		Tomcat7支持

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day177 Monday, November 26, 2012

1. 
	* 验证java DNS缓存参数配置，不缓存域名到ip的映射
	* 数组，链表，零拷贝(zero-copy) 数据结构  对象拷贝
		在数组等基本数据结构上，再封装的列表等数据结构
			list结构，内部实现为数组，在扩容时，要重新分配一个数组并进行拷贝；队列等结果也通过数组实现，插入效率高，知道下标时访问快速，
			但查找/删除慢其容量固定，特别是在数组指定位置（如头尾之间加或减）（内部通过System类的arraycopy方法实现数组复制）
		...
	参考书籍：
		Data Structures and Algorithms in Java (Robert Lafore)

2. 验证java DNS缓存参数配置，不缓存域名到ip的映射
	-Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0

	8.214 slbapi
	验证：当域名指向的IP被修改时，能正确连接到新的IP

	slb api数据库连接不上，报user illegal？不合适

	验证通过：
		通过在命令行中设置上述参数后，测试时，服务器启动后请求API，API调用了数据库，并在sql日志中可以看到；
		此时，将jdbc中域名指向的ip改为其他的ip（此时，需要将原来IP指向的机子的mysql服务需要停掉~），再次调用API，API日志是否正确打出日志；结合 mysql的命令show processlist；
		以确认数据库调用是否正确切换了IP，根据测试结果，加入上述参数后，API能正确切换IP。
	小节：
		在切换IP时被坑，原因是不了解java内部处理域名IP映射关系的更新机制，目前来看是在原域名指向的IP服务不可用时才会重新解析域名。
			这个现象是否与web程序缓存了数据库连接池有关系？
		另外，若ttl不配置，jvm默认不是永久缓存dns信息，而是缓存30秒（在jdk/jre/lib/java.security文件中有说明）



3. slbapi启动日志查看及一些warning的排除(tomat+nginx+slbapi)		  * log4j * 日志
	tomcat日志 开发环境 linux tomcat7
		- 权限问题导致的某些日志，临时文件夹没有访问权限（修改权限，并以admin来操作）
		- 报maxThread这个配置找不到对应的属性（属性名错误，应该为maxThreads）
		 - log4j:WARN No appenders could be found for logger (org.springframework.web.context.ContextLoader). —— 未配置spring的这个装载器的日志项，可以配置在root中，或者专门一个spring的appender。
			log4j的配置，appender可以有多个（可以定向到文件或标准console），logger定义了实际需要记录日志并使用前面定义的appender
			（全局logger记录自定义logger未包含的部分的日志输出，比如自定义的logger并没有定义spring的log输出，则可以在root级别定义其日志或其中框架的日志。例子见下面）。
	
	目的：
		启动日志无异常情况或非正常warning

	log4j配置例子：
	------
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">
		<log4j:configuration xmlns:log4j="http://jakarta.apache.org/log4j/">
			<appender name="stdout" class="org.apache.log4j.ConsoleAppender">
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d  %5p [%t] (%F:%L) - %m%n" />
				</layout>
			</appender>

			<!--sql debug log file -->
			<appender name="SQL_DEBUG"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/debug.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="debug" />
					<param name="LevelMax" value="debug" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--sql info log file -->
			<appender name="SQL_INFO"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/info.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="info" />
					<param name="LevelMax" value="info" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--sql error log file -->
			<appender name="SQL_ERROR"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/ibatis/error.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="error" />
					<param name="LevelMax" value="error" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slb.api debug log file -->
			<appender name="APP_DEBUG"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/debug.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="debug" />
					<param name="LevelMax" value="debug" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slbapi info log file -->
			<appender name="APP_INFO"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/info.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="info" />
					<param name="LevelMax" value="info" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!--slbapi error log file -->
			<appender name="APP_ERROR"
				class="com.aliyun.slb.api.log.TimeSizeRollingFileAppender">
				<param name="File" value="logs/slbapi/error.log" />
				<param name="MaxBackupIndex" value="300" />
				<param name="Encoding" value="UTF-8" />
				<param name="MaxFileSize" value="200MB" />
				<param name="DatePattern" value="'.'yyyy-MM-dd" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
				<filter class="org.apache.log4j.varia.LevelRangeFilter">
					<param name="LevelMin" value="error" />
					<param name="LevelMax" value="error" />
					<param name="acceptOnMatch" value="true" />
				</filter>
			</appender>

			<!-- api called log-->
			<appender name="openapi_all" class="org.apache.log4j.RollingFileAppender">
				<param name="file" value="logs/slbapi/all.log" />
				<param name="MaxFileSize" value="1000KB" />
				<param name="MaxBackupIndex" value="100" />
				<layout class="org.apache.log4j.PatternLayout">
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n" />
				</layout>
			</appender>


			<!--other debug log file-->                                                                                                                                
			<appender name="OTHER_DEBUG" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                 
				<param name="File" value="logs/slbapi/other/other_debug.log"/>                                                                                
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="debug"/>                                                                                                 
					<param name="LevelMax" value="debug"/>                                                                                                 
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>                                                                                                                                            
																					       
			<!--other info log file-->                                                                                                                                 
			<appender name="OTHER_INFO" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                  
				<param name="File" value="logs/slbapi/other/other_info.log"/>                                                                                 
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="info"/>                                                                                                  
					<param name="LevelMax" value="info"/>                                                                                                  
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>                                                                                                                                            
																					       
			<!--other error log file-->                                                                                                                                
			<appender name="OTHER_ERROR" class="com.aliyun.houyi.log.TimeSizeRollingFileAppender">                                                                 
				<param name="File" value="logs/slbapi/other/other_error.log"/>                                                                                
				<param name="MaxBackupIndex" value="30"/>                                                                                                      
				<param name="Encoding" value="UTF-8"/>                                                                                                         
				<param name="MaxFileSize" value="200MB"/>                                                                                                      
				<param name="DatePattern" value="'.'yyyy-MM-dd"/>                                                                                              
				<layout class="org.apache.log4j.PatternLayout">                                                                                                
					<param name="ConversionPattern" value="%d{ISO8601} %p [%c] - [%m]%n"/>                                                                 
				</layout>                                                                                                                                      
				<filter class="org.apache.log4j.varia.LevelRangeFilter">                                                                                       
					<param name="LevelMin" value="error"/>                                                                                                 
					<param name="LevelMax" value="error"/>                                                                                                 
					<param name="acceptOnMatch" value="true"/>                                                                                             
				</filter>                                                                                                                                      
			</appender>
			 
			<logger name="com.aliyun.slb.api.interceptor" additivity="false">
				<level value="all" />
				<appender-ref ref="openapi_all"/>
			</logger>
			<!--java.sql assign to sql log-->
			<logger name="java.sql" additivity="false">
				<level value="debug"/>
				<appender-ref ref="SQL_DEBUG"/>
				<appender-ref ref="SQL_INFO"/>
				<appender-ref ref="SQL_ERROR"/>
			</logger>
			<!--ibatis assign to sql log 这个有问题，日志出不来-->
			<logger name="com.ibatis" additivity="false">
				<level value="debug" />
				<appender-ref ref="SQL_DEBUG" />
				<appender-ref ref="SQL_INFO" />
				<appender-ref ref="SQL_ERROR" />
			</logger>

			<!--com.aliyun.slb.api assign to app log -->
			<logger name="com.aliyun.slb.api" additivity="false">
				<!--com.aliyun.slb.api assign to app log -->
				<level value="debug" />
				<appender-ref ref="APP_DEBUG" />
				<appender-ref ref="APP_INFO" />
				<appender-ref ref="APP_ERROR" />
			</logger>

			<!--other class assign to other log-->
			<root>
				<level value="info"/>
				<appender-ref ref="OTHER_DEBUG"/>
				<appender-ref ref="OTHER_INFO"/>
				<appender-ref ref="OTHER_ERROR"/>
			</root>

		</log4j:configuration>
	------
	上面的配置，spring（struts等框架及其他组件）的日志会在  OTHER_DEBUG，	 OTHER_INFO  ，OTHER_ERROR中输出。
			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day178 Tuesday, November 27, 2012

1. 
	* bugfix201211预发布
	* houyi api
		resetfailed
		startfailed
			master不保存此状态，通过MQ，api得到状态变化
	* master重构 ？待201301
		设置houyi api计量数据部分：
			计量数据由nc采集 (以python替换cpp)，然后直接写入(或者做缓冲层或错开并发)到OMS，采集并保存过程完成。
			API从OMS取需要的数据：
				涉及，与OMS沟通：
					是否满足简单的查询需求（根据现有的数据库查询逻辑）
					性能上大量nc同时写入是否ok，tps能否满足，上限是多少？（会影响nc是直接写入OMS还是需要缓存层，降低OMS压力）
  
  2. 

3. java nio包中缓存类的实现
	Buffer(Abstract) -> DoubleBuffer(Abstract) -> HeapDoubleBuffer(Class) -> HeapDoubleBufferR(Class read-only)
		内部通过数组结构实现；内存复用(减少内存拷贝)；

4. 走不通？绕一绕。。。 -tip-
	release_vm接口mock控制系统进行测试。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day179 Wednesday, November 28, 2012

1. 
	* api region 找不到问题分析

2. 清代理商自己的VM
	- 模拟用户体系改造前用户角色，创建VM（加入组等其他操作）
	- 对上面用户进行用户体系改造并重启API，但对vm没有订正数据（测试结果vm将不能被释放，代理商不允许有自己的资源）
	- 模拟上面用户的一个子用户创建VM，便于验证不影响子用户的操作。
	- 将用户的agent_id值指向自己，再重启API
		确认这样的代理商(agent_id指向自己)，不影响子用户正常操作   （测试不影响，agent_id指向自己只在判断是否user一致时起作用）
		也不影响此代理商正常操作（测试通过，detail_vm子用户的vm；不能创建资源）
		最后，调用release_vm操作（可以debug去走，保证过程都ok）（测试结果：）

3. region找不到错误分析
	API日志记录：
		2012-11-27 19:47:29,193  ERROR [ajp-127.0.0.1-8109-260] (RegionAwareInterceptor.java:100) - regionNo: not exist
			这里regionNo为空，报了找不到（RegionAwareInterceptor.java 100行，根据vm找region时报错），action中继承的查找region的方法没有将region设置到regionHolder中？，

	vm_name=AD1211270747158d19115
		创建vm成功后，
		调start_vm报vm not exists - 根据vm_name找region时，找region ,失败
		再调start_vm报resource has no corresponding region
		再调start_vm报resource has no corresponding region
	vm_name=AT121127073000bec4779
		创建vm成功后
		调assign_ip，报resource has no corresponding region - 找不到region

	定位start_vm时，action根据vm_name找到的regionNo=""，即为空（不是null）。

	找region的顺序：
		拦截器先调用action的找region逻辑来查找regionNo，并在找不到且为null的情况下报vm not exists，拦截器判断action的查找结果，若失败（如报：vm not exists）则报error日志：查询资源信息时发生错误!，
		拦截器判断action找regionNo成功，则以regionNo为键从缓存中取对应的region对象。（但regionNo可能是个空字符串，此时校验时拦截器报：regionNo:" +regionNo + " not exist）

	AbstractResourceLocator类的locateRegion(Class<T> type, String resourceNo)方法可能有问题？
		有一个缓存Map，区分group,instance,ipAddress，ipSegment，以前面4种资源的No(instance_no,group_no,...)作为key，并将各自资源的dao查询到对应的region，存入各自的map缓存中。

		resourceRegionCache这个缓存map，如果在创建vm时，regionNo还没有确定下来，这时数据库的region_no为空，此时若有更新这个map缓存的操作进来，比如detail_vm，就会导致，将
		vm_name和regionNo=‘’的映射存入缓存。下次根据vm_name找regionNo时，直接从map缓存返回空，导致错误，报-141 resource has no corresponding region。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day180 Thursday, November 29, 2012

1. 
	* vm_name&regionNo缓存问题小节
		整理现场日志
			
	* 服务器端无阻塞编程
		阻塞的地方有哪些，有什么方式实现无阻塞，系统提供了什么，编程模型提供了什么，什么场景都适用吗？

2. API线上问题记录及分析
	- 数据库数据不一致（数据同步）
		不同时间段查看时，同样的查询数据不一致
		AD1211270747158d19115这个vm的创建时间和更新时间28号看是一样的（异常值），29号就不一样（正常值），其29号的创建时间和28号的创建时间都不一致，why？

	- create_vm用时1分16秒
		vm_name=AD1211270747158d19115
	- vm_name=AT1211270647235655446
		regionNo=''
		创建时间，更新时间相同：2012-11-27 18:48:13
		info，error日志没有此vm_name对应的字符串，可能确实没有包含vm_name的日志输出，但在instance表有记录且数据由问题，在日志中应该有其他错误日志？

		调度：disk=40 ,mem=512,cores=1

		定位：
			又出现regionNo=''的记录，定位到数据库在主备切换，导致数据丢失。



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day181 Friday, November 30, 2012

1. 
	* key，pair 生成user的key和id ==	    签名
		UserService
	* python
		monitor计量重构

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day182 Monday, December 03, 2012

1. 
	* DB HA alternate problem
	* dubbo test
	* big region extend project
		go on design and development
		time to commit to QA at about 20
	* slb v2 requirement


2. DB HA alternate problem
	
	What's the problem that cause the HA Switching bettween master DB and backup DB frequently.？
		HA architecture：
			2Mysql(1 master,1 backup)
			vip

3. dubbo test
	follow by readme
	svn co http://code.alibabatech.com/svn/dubbo/trunk dubbo
	mvn clean install -Dmaven.test.skip=false
	... see readme doc	   OR README file
	
4. slb v2 requirement
	commit to QA at 12/15/2012
	requirement list: http://aone.alibaba-inc.com/aone2/req/productReq/339?_token=c849d35a-2347-4912-a520-e19b18249dbd
	- 计量数据接口，SLB后端计量库表名修改，相应API需要修改
		表名修改
			这次ospf项目中，计划对monitor库的变动主要在修改表的名称，表结构没变：

			haproxy_stats_${DATE} => proxy_stats_${DATE}
			haproxy_rule_stats_${DATE} => proxy_rule_stats_${DATE}
			haproxy_rule_hourly_stats_$DATE_MONTH => proxy_rule_hourly_stats_$DATE_MONTH
			haproxy_daily_stats_$DATE_YEAR => proxy_daily_stats_$DATE_YEAR

			对于haproxy_rule_stats_xxx的查询也需要改一下表名称了。

	- API使用的httpclient的socket关闭问题。
		使用不复用connection的方式
	- 前端调用的参数包含非法字符(如/r/n)，导致API构造出的请求后端的URI不合法，报错：-2001,"msg":"backend service exception"
		确保请求后端的URI格式合法，验证lb_id值的格式合法性（对lbId进行URL编码，这样）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day183 Tuesday, December 04, 2012

1. 
	* slb v2 requirement development
		httpclient的连接复用问题，若每次都创建连接，耗性能；超时释放
	* 大region二期
		设计文档再梳理，
	* api发布小版本(分布式lock问题)

			

2. slb v2的httpclient3使用MultiThreadedHttpConnectionManager，复用
	//这种方式，每次都新建连接，如果并发非常大，延迟高时，同一时间有大量请求时，是否会超过socket数上限？待验证
	//但连接毕竟还是会回收，在达到socket最大值后，那些请求将不能被处理
	HttpClient httpClient = new HttpClient(new SimpleHttpConnectionManager(true));


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day184 Wednesday, December 05, 2012

1. 
	* slb v2
		补充加入需求：
			 java启动参数设置不缓存DNS信息
				-Dsun.net.inetaddr.ttl=0(地址不缓存) -Dsun.net.inetaddr.negative.ttl=0(域名错误信息不缓存)
	* 大region二期
	* python
	* 灰度发布功能设计
		相关的表设计，逻辑实现设计，目标为加入配置实现灰度发布。业务强耦合的问题，如何抽象为统一模型？

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day185 Thursday, December 06, 2012

1. 
	* big region二期再kick off
		流量推送需求取消，在bugfix201211项目中做
		快照和image都会同步到其他region，这个对快照的跨region使用的影响？
			了解快照同步，image同步的逻辑：
				快照同步过后，API到指定的region上去detail_snapshot时，返回的快照的cluster_id应该就是本region的cluster_id？快照同步到各个小region后，对应的
				cluster_id都为各自region的cluster_id；同步后在不同region的同一个快照，可以视为独立的快照，只是他们的快照内容是一样的；
			image同步逻辑同快照同步逻辑。
				image同步后，有src_image_id字段标识image是源image还是由源image同步出来的。
			
			按照上面逻辑，说快照不能跨小region使用是ok的。

			在大region下查询某个image_no对应的源image_no时，可能会重？
				imageNo,userId,bigRegionNok
				imageNo,userId,region_no,

			需要考虑这个问题		
			image_no="windows2003cnstdr2.32.20110926.01.vhd" and src_image_id=0; 
			image_no="windows2008r2stden.64.20110605.01.vhd" and src_image_id=0;

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day186 Friday, December 07, 2012

1. 
	* bigregion二期，将原branch修改merger到基于最新trunk拉的分支上。
	* 数据库培训
		taobao数据库演化，自动化运维（自动切换的数据丢失问题，自动扩容，迁移，合并），余量模型
	* python



2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day187 Monday, December 10, 2012

1. 
	* slb api准备连调测试 8.214
		master 10.250.6.45:8088
		monitor db

	* 大region二期，补充细化控制系统兼容的设计文档及开发
	* 大region下，imageNo,user_id,bigRegionNo不能唯一确定一个image,这样对外的query_available_imgs接口可能返回2个或以上重名的imageNo，对用户
	会有歧义；api已保证通过api接口创建的image在大region下唯一，上传工具需要修改，也保证这点。


2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day188 Tuesday, December 11, 2012

1. 
	* 大region二期设计评审及问题讨论
		- list_mounted_snapshot控制系统返回值增加cluster_id，便于api识别其region
		- bucket类型image，以hash_on_kfc类型同步到老region，保证发布过程中bucket类型的imageNo在老region可使用
			即满足大region下，相同imageNo对应的存储类型bucket和hash_on_kfc可共存
			大regionNo，userId,imageNo对应的记录可以多条但必须保证为同一个image（其他的为副本）
		- region调度时，bucket类型返回所有new的region，再加上有hash_on_kfc的region，作为源调度列表
		- 使用image，优先bucket类型

	* slb api连调


2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day189 Wednesday, December 12, 2012

1. 
	* 大region二期开发
		基于C,D的kfc去掉前提，去掉原代码中kfc逻辑
	* 大region二期，工具评审，与api相关部分的确认
	* slb连调，表部分改动
		ok
	* 系统间交互，超时设置梳理，避免第三方服务影响主要业务的稳定性 -tip-

2. 

	select distinct r_alias.region_no,image.snapshot_type  
	from region_alias r_alias
	left join image image on image.region_no=r_alias.region_no
	where  r_alias.big_region_no='cn-hangzhou2' 
	and image.image_no = '' 
	and (image.user_id=0 or image.visibility=1)

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day190 Thursday, December 13, 2012

1. 
	* 大region二期开发
		- 基于vm1大的快照snapshot1，挂载到vm2上后，对应vm2上生成新device2，master限制此device2不能再打快照，只能使用。
		这样clusterId-deviceNo-snapshotId中快照和device有相同的clusterId。
		- 设计部分修改：新增兼容性接口修改
		master返回码待定



2. 设计
	pojo类设计
		系统对接的地方pojo类设计，本系统的pojo定义，接收第三方系统的pojo定义，分别定义构成映射，利于扩展。snapshot,snapshotExt


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day191 Friday, December 14, 2012

1. 
	* 大region二期开发
		及单元测试用例编写
		ERROR_SNAPSHOT_TYPE_NOT_SUPPORT = -30005 master快照不支持

	* slb api提测前检查及验证

	* linux生成core文件 -tip-
		本次由于关闭web服务时，java命令行多指定了远程调试参数，报端口被占用ERROR，ulimit -a 没有关闭core文件，于是每次关闭时生成core文件。
		core文件可通过gdb命令来查看

2. /etc/hosts文件配置错误，导致jboss启动失败		      -tip-
	Caused by: java.lang.RuntimeException: Exception creating identity: pangu_master_3: pangu_master_3
	[MainDeployer] Could not create deployment: file:/home/admin/houyi-ace4j/service/.default-open/conf/jboss-service.xml
	-------
	...
		Caused by: javax.management.MBeanRegistrationException: preRegister() failed: [ObjectName='jboss.remoting:service=NetworkRegistry', Class=org
	.jboss.remoting.network.NetworkRegistry (org.jboss.remoting.network.NetworkRegistry@23e45a5c)]
		at org.jboss.mx.server.registry.BasicMBeanRegistry.invokePreRegister(BasicMBeanRegistry.java:713)
		at org.jboss.mx.server.registry.BasicMBeanRegistry.registerMBean(BasicMBeanRegistry.java:211)
		at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.jboss.mx.interceptor.ReflectedDispatcher.invoke(ReflectedDispatcher.java:155)
		... 51 more
	Caused by: java.lang.RuntimeException: Exception creating identity: pangu_master_3: pangu_master_3
		at org.jboss.remoting.ident.Identity.get(Identity.java:211)
	...
	-------

	看上面的错误， Exception creating identity: pangu_master_3: pangu_master_3,在创建标识时报错，是因为本地回环(127.0.0.1)没有配置上上面这个hostname（pangu_master_3），
	配置上如下一项即可：
		127.0.0.1               pangu_master_3

	ref: https://community.jboss.org/thread/63869?tstart=0		

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day192 Monday, December 17, 2012

1. 
	* 大region二期
		- 6.33设置开发测试环境，部分连调
		- 单元测试用例
		- master多次发布，API是否需要重启的问题验证
			reload缓存接口


	* python
	* houyi api user 表
		access_id有unique约束，创建user时有默认值

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day193 Tuesday, December 18, 2012

1. 
	* 大region二期，自测，连调（master环境未完全ok）
		create_snapshot
		create_image
		...
	* 2013目标会
		目标及任务
			大控制系统重构
				nc上部分工具用python替换cpp实现，简化复杂度和维护成本（基于对性能要求不高）
		vpc分享
			自定义网络，网络层间通过网关交互

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day194 Wednesday, December 19, 2012

1. 
	* 大region二期，单元测试 ，连调
	* python
		python的GC，与java的GC对比 垃圾回收算法
			都提供标记-清除算法 mark-and-sweep
			
			其他：
				引用计数回收
				分代回收
				等等

				JVM参数设置不同的方式，或者自动根据情况选择GC回收算法


	* mysql主备切换，读写分离，一主多备，主库HA 自动切换 （根据现有的业务压力和需求决定是否需要这么做，一般主备切换是基本的）
		ref: http://code.google.com/p/mysql-master-ha/

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day195 Thursday, December 20, 2012

1. 
	* 大region二期连调
		aliyunIdkp=alisys_vms 用于oss测试环境账号(否则创建bucket失败)
		mount_snpashot接口，deviceNo传给master保持不变，值来自快照ID
			-tip- 改进，对master少传参数的情况，可以报错，等待超时返回太耗性能...
		
		- 27,28左右新API老master连调结束

	* python
		mark-and-sweep 有应用短时间不可用和内存碎片问题    GC
		引出，stop-and-copy回收算法,解决内存碎片问题需要2倍的heap内存且只能真正使用其中的一半(ref: http://www.brpreiss.com/books/opus7/html/page428.html)
		引出，Mark-and-Compact
			The mark-and-compact algorithm consists of two phases: In the first phase, it finds and marks all live objects. The first phase is called the mark phase. In the second phase, 
			the garbage collection algorithm compacts the heap by moving all the live objects into contiguous memory locations. The second phase is called the compaction  phase. 
	
		print "\n".join(["%s:%s" % (k,v) for k,v in gc.__dict__.items()])
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day 196 Friday, December 21, 2012

1. 
	* 大region二期连调
		快照接口：create_snapshot

2. 大region二期连调
	快照接口：
		add_disk,create_snapshot
		创建系统盘快照

		create_image
		mount_snapshot 挂自己的快照，挂用户其他vm的快照
		unmount_snapshot 卸载快照

		retain_snapshot
		rollback_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day197 Monday, December 24, 2012

1. 
	* houyi api连调
	* houyi api返回xml格式时，data标签的问题
		有data时，即使数据为空，标签需要返回；
		若本就没有data数据，不出现data标签
	* 数据库切换功能的支持问题
		rds提供数据库自动切换，需要与应用统一，即应用需要支持数据库动态切换的功能。
			针对API，清楚数据库动态切换需要做什么工作？DNS缓存
	* 数据库查询缓存问题	      * 数据库缓存架构	      查询结果进行缓存 查询缓存		       * ibatis结合memcached * ibatis扩展
		目标：减小数据库load
		对于大数据查询，重复查询等，考虑加一个查询缓存，减小数据库的load
			是否考虑用memcached做统一缓存，这其中涉及memcached集群及HA问题
			or tair系统？
		
		解决方法：
		ibatis提供了CacheController接口，当不满足于内置的缓存实现时，可扩展自定义的缓存实现。
			CacheController接口的设计

		在web服务各层缓存中，本次考虑的缓存为：
			数据库查询缓存

		延伸：
			web服务的各层都可以缓存，最佳实践有哪些？

			再延伸：
				框架或插件，一般都在设计时针对实现会改变的地方会提供扩展的能力，会用和用好是不同的层次，给我感觉是要熟悉你所使用的东西

2. 

Merry Christmas !

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day198 Tuesday, December 25, 2012

1. 
	* 大region二期连调
		detail_snapshot接口snapshot_id的deviceNo检查问题？
			API不检查，给master只有snapshot_id无法检查，master都返回200，只是snapshot_id是否为空的不同。
			API是否需要校验deviceNo来判断snapshot是否存在，或者交给master校验？
	* memcached java客户端gwhalin实现分析
		cosistent hash 一致性哈希
			避免key在服务节点列表上的重新发分布；
			部分算法还实现了虚拟节点，缓存在节点间的分布更加均匀
			tree-map实现，Entry的left，right属性用于在环中定位相邻Entry
				基于Red-Black tree实现
		socket pool
		health check
		server weight
				   
		目标：* 设计
			许多Web 应用程序都将数据保存到RDBMS中，应用服务器从中读取数据并在浏览器中显示。但随着数据量的增大，访问的集中，就会出现REBMS的负担加重，
			数据库响应恶化，网站显示延迟等重大影响。  Memcached是高性能的分布式内存缓存服务器。一般的使用目的是通过缓存数据库查询结果，减少数据库的访问次数，
			以提高动态Web 应用的速度、提高扩展性。
	
	* vm信息收集推送逻辑预整理
		原逻辑实现：master->nc->vm_info_catcher.cpp

2. 连调问题？
	快照ID中deviceNo校验问题，大region遗留问题
	
	影响接口：(需要传入snapshot_id到API)
		mount_snapshot
		unmount_snapshot
		add_disk(传snapshot_id时)
		remove_snapshot
		rollback_snapshot
		cancel_create_snapshot
		retain_snapshot
		create_image

	解决方案：
		1）API传入必要参数给master，master来判断快照是否存在(master自身查询唯一快照的必要参数)，对应API映射到一个错误码即可
		2）API使用快照的接口，查询出快照后，比对deviceNo的一致性，判断快照是否存在
	
	还有一个相关的问题，同时有device_no和snapshot_id时，还需比较deviceNo一致性，涉及接口如下：
		rollback_snapshot
		remove_snapshot  直接将deviceNo给master，没查询快照；若API校验，API自身接口需要变动
		retain_snapshot

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day199 Wednesday, December 26, 2012

1. 
	* 大region二期连调
		- add_disk			  (补单元测试)
			指定snapshot_id
		- detail_snapshot接口API到master接口变动
			增加传入快照的clusterId和所基于的deviceNO，master判断快照是否存在（并新快照不存在的错误码）

			上面修改，API需要兼容新老master的情况

		- 同时传deviceNO,snapshot_id给API的接口，API需要比较2个devieNO是否一致，否则报快照不存在：
			-910, "snapshot id not exists" (master错误码为：-30006,snapshot not exist)

			确认增加上面的校验，不会影响老master（没做兼容处理）
		- 查询快照的逻辑，零散发布，改为统一调用快照service层 待？
			

	* slb api
		去掉alisoft-xplatform-asf-cache.jar，没有使用，也没找到反射的引用
		xmlsec.jar修改，从：
			<dependency>
				<groupId>org.apache</groupId>
				<artifactId>xmlsec</artifactId>
				<version>1.4.3</version>
			</dependency>
		改为：
			<dependency>
				<groupId>org.apache.santuario</groupId>
				<artifactId>xmlsec</artifactId>
				<version>1.4.3</version>
			</dependency>
		houyi api已替换。
	
	* slb api并发性能优化问题
		以list_loadbalancers接口为例
			1）http连接保持，多线程并发

2. mount_iso问题
	running mount_iso (bug),shutted mount_iso
	for fix use
3. 整理deviceNO校验需求变动，更新到设计文档

4. API问题 ？？
	查询快照逻辑，统一接口调用，不应该各处有独立的实现


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day200 Thursday, December 27, 2012

1. 
	* deviceNo校验问题
		影响的接口，单元测试的修改
		连调

	* remove_snapshot接口，判断快照是否能删除问题
		若快照被自定义为image，则不能删除(可先删除image，再去删除快照)
		API的判断快照是否为image逻辑有问题：
			1) snapshot_id在大region内不唯一，会查出其他集群的snapshot
			2) image 可以update的,image.snapshot_id可以upadte,如果之前的 snapshot_id已经在VM上使用了，删除该快照，下次reset_vm会有问题

	* 拉末日曙光项目代码，与大region二期比较，评估合并代码风险	
	* SLB API兼容新老SLB后端问题
		除去本次流量接口修改不兼容，保证其他接口都兼容（master有2个版本）
	* SLB API并发性能问题 待？
		节后分析
		从压测的某些接口入手，找到原因以及优化方案：
			需要：
				压测环境（SLB API + MASTER）开发集成环境
			slb api通过拦截器，记录了请求进来到处理结束的时间差记录，便于分析性能瓶颈
	* master环境切换
		/apsarapangu/disk4/apsara-0.8.6/houyi-bigregion
		sh ../build-deploy-start-houyi.sh
	* houyi api打包名改变，对应提测模板改变，大region二期提测时需注意（若在末日曙光项目提测之后提测则没问题）
	* houyi api空指针问题 -tip-										 ？待修复
		platform数据有问题时，没有判断null
			如：数据库记录了错误的类型值，程序找不到对应的类型。

		程序对于空指针的判断需要处理好，对于存在空指针可能的逻辑都需要做判断，保证程序的健壮性。
	
	* jetty环境熟悉
		配置
		性能

			


2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day201 Friday, December 28, 2012

1. 
	* 大region二期连调，单元测试修改提交
	* 通过vnc登陆到VM
		ip:port
		username
		password

		进入vm检查add_disk
			df -a
			df -k
				显示挂载到的位置
			mount
			fdisk -l

	* 状态同步
		主动同步(显示调用更新状态)
		被动同步（通过消息机制，如MQ）
	* vm磁盘挂载，mount add_disk	    * linux挂载硬盘
		添加磁盘
		找到磁盘
			fdisk -l
		分区
			fidsk /dev/xxx
			n
			w
			...
		格式化
			mkfs -t ext3 /dev/xxx
		创建目录，并挂载上面的分区
			mkdir /disk
			mount /dev/xxx /disk
		验证挂载情况
			df -k
		设置开机自动挂载
			vi /etc/fstab
			/dev/xxx               /disk                 ext3    defaults        0 0
	
	* 大region二期与末日曙光项目合并风险检查
		检出末日曙光代码
		将大region二期代码merger到上面的代码中
		test
		
		测试合并结果，冲突不多
		
		
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day202 Saturday, January 04, 2013

1. 
	大雪，在家办公


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day203 Saturday, January 05, 2013

1. 
	* slb api性能问题
		slb api + slb后端
		针对个别接口，通过slbapi日志分析性能瓶颈
		性能测试方案

	* 看master关于vm监控数据部分逻辑
		source insight
		cpp
		namespace
			class
				

2. slb api集成测试环境	      slb测试环境
	10.250.6.32
	ssh root@10.230.130.1
	go2v2api

3. 缓存框架，缓存系统，缓存模块
	应用自身设计缓存接口，包含各种缓存操作
	根据接口，针对不同的缓存实现提供各自的接口实现

4. 使用image的条件，imageNo+userId+bigRegonNo 唯一
	api
	image工具



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day204 Sunday, January 06, 2013

1. 
	* nc上vm监控数据工具逻辑
		VmWrapper -> VmXenWrapper -> connect to Xen Supervisitor(libvirt库virConnectPtr) -> get info
		通过libvirt API来访问xen hypervistor，libvirt库为统一抽象的虚拟化API，支持多种不同hypervistor，对外提供统一API管理接口
		这样，通过libvirt API对应的python sdk调用即可？
			根据libvirt官网说明：
				Bindings for other languages: Libvirt supports C and C++ directly, and has bindings available for other languages:

				Python: Libvirt comes with direct support for the Python language.
					If your libvirt is installed as packages, rather than compiled by you from source code, ensure you have the appropriate package installed.
					This is named libvirt-python on RHEL/Fedora, python-libvirt on Ubuntu, and may be named differently on others.
				直接支持python，但需要安装 libvirt-python 包(RHEL/Fedora系统上)，当然也提供了其他语言的调用支持。

				For usage information：http://libvirt.org/python.html 使用说明
				There is not much to comment about it, it really is a straight mapping from the C API, the only points to notice are:
					1) the import of the module called libvirt
					2) getting a connection to the hypervisor, in that case using the openReadOnly function allows the code to execute as a normal user.
					3) getting an object representing the Domain 0 using lookupByName
					4) if the domain is not found a libvirtError exception will be raised
					5) extracting and printing some information about the domain using various methods associated to the virDomain class.
			
			libvirt-python包



2. zookeeper
	应用
		命名服务
		集群管理
		配置管理   发布&订阅服务
		共享锁服务
		队列管理

	实践

3. python访问libvirt API
	需要 libvirt-python 包
	例子：
	--------
		import libvirt
		import sys

		conn = libvirt.openReadOnly(None)
		if conn == None:
		    print 'Failed to open connection to the hypervisor'
		    sys.exit(1)

		try:
		    dom0 = conn.lookupByName("Domain-0")
		except:
		    print 'Failed to find the main domain'
		    sys.exit(1)

		print "Domain 0: id %d running %s" % (dom0.ID(), dom0.OSType())
		print dom0.info()
	--------

	安装libvirt-python包，安装时注意选择正确的python版本，可能同时存在多个python版本，需要指定安装位置到要使用的版本上，比如python2.7

	yum install libvirt-python.x86_64 --installroot=/user/xxx
	安装好，对应的python版本即可导入 libvirt
		import libvirt

	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day205 Monday, January 07, 2013

1. 
	* 大region二期上线步骤准备及数据订正脚本
	* python访问libvirt API
	* 周四kickoff MSS(Monitor Storage Service)改造
		目标：替换agent取监控数据上报所有逻辑
			API只是调用者
			嫦娥系统也需要查询监控数据
		要做的工作
			原业务-永生，祥云

		时间安排
			
		
2. 上线订正脚本
	参考：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/tools/trunk/fix_data/ec_big_region2
	用python实现订正脚本，完成订正过程：
		订正数据  （订正脚本只涉及插入数据/更新数据，表结构修改或增加由DBA执行订正脚本不负责这个）
		验证

	导入已有python库的db封装: pypet库，地址：http://svn.simba.taobao.com/svn/luban/houyiops/pet/trunk/lib/pypet
		from pypet.houyi import db

3. python访问lbivirt API
	正确安装好 libvirt-python 包后
	import libvirt
	参考API说明，编写逻辑

4. 根据API代码规范编写		   改进
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day206 Tuesday, January 08, 2013

1. 
	* 大region二期，数据订正脚本完善，需要review
		发布相关问题，参考：末日曙光项目上线步骤	
		

	* MSS项目kick off文档整理
		时间规划图，visio->项目日程->时间线
		需求整理
		任务整理

	* 原nc agent采集上报monitor，monitor写入库的逻辑分析
	* MSS将VM监控数据推送到OTS可行性分析
		读写性能要求
		查询要求
		OTS文档？
		从OTS存入的数据，是否可以通过OMS获取？

		* OTS Open Table Service

	* 大region二期，sql相关修改整理，需要DBAreview ？ 待
	* 大region二期，上线步骤分析 ，API不重启
		API目前不允许region表的region是不可用，即关闭的；这样调用到关闭的region时会等超时。？待解决
		解决：
			API在根据imageNO找可用region时（ImageService的listRegionsByImageNo方法），排除掉关闭的region再做调度。
		
2. nc采集vm监控数据逻辑分析
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day207 Wednesday, January 09, 2013

1. 
	* 大region二期发布步骤
		API不重启，Master一个个单独发布
		订正脚本放到：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/tools/trunk/fix_data/ec_big_region2/API
		需要注意：
			用到pypet库，具体执行时确认所使用的python的版本已安装此库
				python xxx.py
			有2个订正脚本，一个更新image表：订正所有的image的snapshot_type为1，即都为老hash类型image
				w-image
			另一个插入region_status表

	* MSS重构
		OTS文档说明
		OTS Python SDK
		与PE确认VM监控数据的调用方式&频率：
			万网，portal
		存入OTS的数据，不能从OMS直接读取，如何处理？待
	* 大region二期API代码review
		整理review结果
		处理review结果
			ImageServiceImplTest
			代码修改	 doing
			单元测试修改 doing

2. 大region二期发布步骤
	- API Proxy来拦截小region发布时，对应此region的调用直接返回友好提示；
	- 对于个别错误的跨region调用的情况(vmName所在region是运行的，但操作的其他资源的region已关闭的情况)，	还是会报系统错误，只在少数
	- HouyiAPI在create_vm接口调度region时，在待调度region列表中去掉status=0即状态不可用的region。  （保证create_vm接口允许某个或某些region关闭）
	- 调用Master的接口处，初始化region endpoint时，已保证region状态为可用
		但对于status=0即状态不可用的region直接抛异常不合适，可以细化为region找不到，还是region状态不可用。？待
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day208 Thursday, January 10, 2013

1. 
	* 大region二期review结果处理
		
	* 大region二期，开发测试环境搭建及新老master兼容测试工作		  测试环境
		从QA处借用一个老region，结合开发自用的新region，组成一个集成环境
			regionNo=AT03-HOUYI2
			AG:
				6.27		
				go2houyi1
				go2houyi2		
			
		api配置数据库信息

	* rabbitmp
		6.33
		配置
		启动
	* 下周一 MSS项目kick off
		预定会议室
		人员

2. 新老master兼容测试
	使用image
	使用snpashot

3. create_vm
	原调度region逻辑，在查询region资源时，若发生错误将不会将此region及其zone加入调度；大region二期，加上region状态判断，不可用时直接移出待调度列表。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day209 Friday, January 11, 2013

1. 
	* 发布脚本review处理
	* 大region连调
	* 集群安装，批量部署，批量更新方法 ？待
	* MSS重构与OTS确认性能是否满足？
		


2. 大region连调
	环境：
		2个已升级的region
		大regin二期API
	测试场景：
		VM调度场景
		1) 验证create_vm逻辑调度时排除status=0的region
			修改region表，关闭一个region
			更新缓存 PASS
			create_vm，不指定zone
			观察日志，应该查询到可用的master，不应该去查询status=0的master PASS
			结果应该为创建成功 PASS

		2) region状态从不可用更新为正常后，create_vm会将其加入待调度列表中
			更新region表
			更新缓存
			create_vm，不指定zone
			观察API日志，到master查询此region的资源信息 PASS

		快照使用场景（注意：create_vm时，保证使用本region的image，开发测试环境底层lazyload可能有问题，不影响测试跨region使用snapshot）			
		1) mount_snapshot接口-新region不能挂载其他region的老快照，否则报找不到
			新region，用老image创建vm（对于2个region都升级时，可修改region_status表来强制使用老imge），add_disk（先更新region状态为已升级后）后打一个新快照 (前置条件A)


	问题：
		master开发测试环境，使用远程的image时，lazyload会有问题，先通过使用本地的image方式继续测试
			更新region状态为未升级
			更新缓存
			指定老zone，会使用本地image
		

3. 终端小tip 测试环境
	MySql,API,AG(可临时跳到Nc等其他地方),Master
		go2nc
		go2houyi
		go2xxx

4. python的output/input,file python输入与输出，命令行参数
					
	Command-Line Arguments
		sys.argv is the list of command-line arguments
		len(sys.argv) is the number of command-line arguments(aka argc)
	from: core python programming.2nd,edition

5. 快照类型与image新老没关系 业务
	只有升级前的为老，后面都为新快照。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day210 Monday, January 14, 2013

1. 
	* 大region二期API发布步骤wiki整理				  
	* MSS重构monitor逻辑
		cpp
		vm_xen_wrapper.cpp
			DoGetAllVmInfo方法
				连接hypervisitor；从API获取所有domain的id数组；遍历domId数组并根据id调用API查询domain；若domain存在则再调用API获取其info；
				调用API取得domain的name

	* MSS重构OTS表的设计
	* 大region二期兼容性连调
		环境
			新master打老快照，修改device的状态为old即可

	* 大region二期，API发布不停机方案
		通过转移访问流量的方式，实现API热部署，分析可行性；对于一套API不同版本不能同时提供服务，比如必选参数不一致的情况。
	* 大region二期，开发测试环境，新增一个二期版本的region
		AG=10.250.8.211
		region，region_alias，region_status,zone
		regon_no=atdev (可取与集群名称一致)
		cluster_id=15
		zone_no=cn-qd-aa-a,cn-qd-aa-b
		nuwa=10.250.8.211

2. 大region二期API发布步骤wiki整理
	http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#.E5.9B.9E.E6.BB.9A.E6.96.B9.E6.A1.88
	准备工作：
		修改imge表结构
		创建region_status表，并初始化数据
	发布
		xxx		
	
3. MSS重构OTS表的设计
	查询场景：
		1) 流量计费，如定时任务，查询条件为：
			定时(每隔一小时)查询一个时间段所有记录的部分列(vm流量相关的几个列)，以时间(time_stamp)作为范围条件，并根据name分组
		2) 监控数据，有业务方会定时(3~10min)调用API来获取指定时间点vm的所有监控数据
			- 万网目前为10min取一次(后续可能调整为3min)，取上一个10min对应时间点vm的所有监控数据；
			- portal 是5分钟取一次监控数据，每次取的是前一个5min对应时间点vm产生的所有监控数据。
		查询条件为：
			query_monitor_vms接口：
				查询指定时间点当前用户下所有vm监控数据的记录，并按照某些列进行排序name,cores,mem
			monitor_vm_topn接口：
				查询指定时间点根据TOPn的排序指标排序(参数值可以为：cpu、memory、tx_intranet、rx_intranet、tx_internet、rx_internet、flow、bandwidth)后，位于排序
				前几名的vm的监控数据。
			monitor_vm接口
				查询指定时间点当前用户下某个vm监控数据的记录，并按照某些列进行排序name,cores,mem
		上面的查询，由于有多种排序方式，考虑用OTS的视图来加速查询速度，根据OTS的文档，需要将待排序的列加入主键的列中方可成为视图主键

		结合OTS提供的查询功能，根据其API中的GetRowsByRange，GetRow方法说明，传入对应的主键列进行数据过滤及查询;
		GetRowsByRange调用返回的最大数据量	1MB	一次GetRowsByRange请求如果返回超过1MB的用户数据，OTS会返回错误给应用。如果应用需要读取超过1MB的数据，
		请升级Java/Python SDK的版本改用带NextToken的GetRowsByRange接口分多次读取数据。

		与业务方邮件确定调用方式后，在OTS邮件中确认表设计讨论 ？ 待
	数据分片键：
		time_stamp	不合适，所有VM在某个时间点的数据都在一个数据分片中，达不到分片的目的
		name	建议采用，vmName为字符串varchar(80)，且唯一
		user_id	不合适（目前就几个（2个）用户）
		选择name作为分片键
	主键：
		time_stamp
		name
		user_id
		3个列的联合主键

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day211 Tuesday, January 15, 2013

1. 
	* MSS重构表设计
		如果查询VM监控数据的业务方需要根据region来查询，则表中需要增加region_no/cluster_id字段，以及nc如何获取此字段？
	* API发布脚本，模板化，可定制
		--prepare
			sub task
		--deploy
			sub task
	* 大region二期API发布步骤整理
		
2. 大region二期API发布步骤整理 go on
	二期wiki：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#API.E5.87.86.E5.A4.87.E5.B7.A5.E4.BD.9C	
	参考：http://wiki.ec.alibaba-inc.com/index.php/AY13B%E5%8D%87%E7%BA%A7API/%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F#.E5.8F.91.E5.B8.83.E9.98.B6.E6.AE.B5
	流程：
		1) 发布中心
			取所有需要的包
		2) 准备阶段
			数据订正
				region_status表数据导入
				region表status字段修改（Master后续发布时，API不停，Master停）

		3) 发布阶段
			备份
			部署
		4) 回滚方案
			回滚


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day212 Wednesday, January 16, 2013

1. 
	* 大region二期发布步骤
		增加更新region表status字段的python脚本
			用于master发布前，修改对应region的状态为不可用，master发布完成后修改状态为可用
	* MSS重构
		整理监控参数及其获取方式
	* deploy.py根据之前发布的项目使用
	有svn地址

2. 大region二期发布步骤
	设置maserRegion，reloadCache都通过go2houyiapi来执行

3. fuxi上的http_proxy作为桥梁，解决kuafu不能跨各个小集群访问的问题(kuafu自带了一个http proxy服务接口，只支持同步调用)	     http proxy
	可到fuxi机器查看proxy的状态（me）
4. osgi
	
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day213 Thursday, January 17, 2013

1. 
	* 大region二期提测
		其他项目修改了API的pom，本项目配管打包时找不到包，对应修改pom即可
	* MSS重构
		pync：一个python实现的框架，
			提供服务注册（定时任务注册，注册一个定时器，并配置触发策略）、
				心跳服务
				采集推送服务
			方法调用（master调用nc）
		OTS多机房部署问题确认？
			以及关联到的定时任务多机房部署&安全数据是否多机房部署&OMS是否需要多机房部署
			
			问题源于：
				OTS是否需要多机房部署，如果需要

	* 大region二期API发布步骤
		杭州云配置目录:http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/outer-pro-env
		测试环境配置目录：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/test-env
		双开环境配置目录：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20121129/inner-pro-env
		参考：http://wiki.ec.alibaba-inc.com/index.php/Bugfix11%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF%E6%AD%A5%E9%AA%A4

2. 

3. edit plus开发python的配置
	参考：http://blog.csdn.net/hendyyou/article/details/4694973

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day214 Friday, January 18, 2013

1. 
	* MSS重构
		监控项及其生成逻辑整理
	* fab发布工具 fab 					  * fab
		6.27
		/home/admin/fabdeploy
		svn:
			http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/fabdeploy
		发布工具fab作者：鱼总
		使用步骤：
			source env_profile && fab houyiapi.api_prepare:url=http://xx,md5=xxx
				备份原API部署目录，并拉取待发布的API包并校验MD5值
			source env_profile && fab -H 10.249.243.62 houyiapi.api_stop
				停API
			source env_profile && fab -H 10.249.243.62 houyiapi.api_deploy
				部署新API包
			source env_profile && fab -H xx.xx.xx.xx houyiapi.api_start
				启动API
		
		帮助查看：
			先source env_profile
			然后 fab --list
			Avaliable command:
				apiproxy.first_install  first full install, example: "fab -R [ROLE] apiproxy.first_install"
				apiproxy.proxy_deploy   proxy deploy, example: "fab -R [ROLE] apiproxy.proxy_deploy:branch=[BRANCH],version=[VERSION]"
				apiproxy.proxy_reload   proxy reload, example: "fab -R [ROLE] apiproxy.proxy_reload"
				apiproxy.proxy_start    proxy start, example: "fab -R [ROLE] apiproxy.proxy_start"
				apiproxy.proxy_stop     proxy stop, example: "fab -R [ROLE] apiproxy.proxy_stop"
				apitask.deploy          apitask deploy, example: "fab -R [ROLE] apitask.deploy"
				apitask.prepare         download zip into local, example: "fab apitask.prepare:url=[URL],md5=[MD5]"
				apitask.start           apitask start, example: "fab -R [ROLE] apitask.start"
				apitask.stop            apitask start, example: "fab -R [ROLE] apitask.stop"
				houyiapi.api_deploy     push open.war to houyiapi server, example: "fab -R [ROLE] houyiapi.api_deploy"
				houyiapi.api_prepare    download tar.gz into local, example: "fab houyiapi.api_prepare:url=[URL],md5=[MD5]"
				houyiapi.api_rollback   rollback open.war, example: "fab -R [ROLE] houyiapi.api_rollback:[WAR]"
				houyiapi.api_start      start houyiapi service, example: "fab -R [ROLE] houyiapi.api_start"
				houyiapi.api_stop       stop houyiapi, example: "fab -R [ROLE] houyiapi.api_stop"
		
		prepare的输出如下：
		-------
			--2013-02-27 10:13:21--  http://jenkins.aliyun-inc.com/package/houyi/ec/openapi_trunk-1.0.19.1457720/openapi_trunk-1.0.19.1457720.tar.gz
			正在解析主机 jenkins.aliyun-inc.com... 10.230.226.113
			正在连接 jenkins.aliyun-inc.com|10.230.226.113|:80... 已连接。
			已发出 HTTP 请求，正在等待回应... 200 OK
			长度： 20584872 (20M) [application/x-gzip]
			正在保存至: “openapi_trunk-1.0.19.1457720.tar.gz”

			100%[=================================================================================================>] 20,584,872  11.2M/s   花时 1.8s  

			 
			2013-02-27 10:13:22 (11.2 MB/s) - 已保存 “openapi_trunk-1.0.19.1457720.tar.gz” [20584872/20584872])

			[localhost] local: md5sum openapi_trunk-1.0.19.1457720.tar.gz | awk '{print $1}'
			[localhost] local: mv open.war open.war.20130227101322
			[localhost] local: tar zxf openapi_trunk-1.0.19.1457720.tar.gz
			[localhost] local: mv openapi_trunk-1.0.19.1457720 open.war

			Done. 
		-------
	* 新项目
		工信部数据上报项目，houyi API提供符合要求的VM数据给数据上报中心，由数据上报中心负责将数据给工信部。

2. http chunk
	http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html
	http://www.cnblogs.com/jcli/archive/2012/10/19/2730440.html http协议之Transfer-Encoding及HttpCore实现

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day215 Monday, January 21, 2013

1. 
	* MSS重构暂停，优先上报项目
	* 工信部上报项目，上报数据项整理以及是否需要增加与master的接口分析      doing	
	* 工信部上报项目，拉分支基于1/22/2013号发布的项目 待
	* 工信部上报项目，增加系统维护中状态，对应region关闭状态（涉及调用到关闭region的情况，报状态）
		若需求调整，则时间不定	
	* 工信部上报项目，增加缓存重构需求
		将regionNo对应控制系统地址的缓存重构，使之支持reload缓存接口
	* http chunk (http1.1 protocol) 方式实现接口提供大量数据
	* 与上报中心确认houyi api提供的接口？
		邮件已发出，待确认
	* 需要变的配置，需要从项目部署包中拉出来，发布都是以war包或jar包为单位，不便于修改配置

2. 工信部上报项目，上报数据项整理以及是否需要增加与master的接口分析
	尽快确定houyi api给出的接口是否满足要求？
	评估API取数据对Master的变化需求？

3. 通过socket实现简单的http server与http client来测试http chunked
	
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day216 Tuesday, January 22, 2013

1. 
	* httpclient文档说明，支持chunked
		socket模拟http server，测试chunked

	* 上报中心项目基于
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bandwidth_fix 发布后从trunk啦分支

2. httpclient
	StringEntity entity = new StringEntity("important message",
	"text/plain; charset=\"UTF-8\"");
	entity.setChunked(true);
	HttpPost httppost = new HttpPost("http://localhost/acrtion.do");
	httppost.setEntity(entity);

3. http响应
	一个简单的HTTP响应体：
	"HTTP/1.0 200 OK[\r][\n]"
	"Server: a simple java httpServerContent-type: text/html[\r][\n]"
	"Content-Length: 24[\r][\n]"
	"[\r][\n]"
	"<html>hello world</html>"	

	也可基于servlet来返回chunked响应
		根据maven内置archtype中的java web类型创建maven支持的web project
			创建servlet，配置servlet，访问测试

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day217 Wednesday, January 23, 2013

1. 
	* DCISP数据上报项目新开分支申请
	* DCISP数据上报项目，数据项逻辑整理
		
	* MSS重构
		定时任务，嫦娥等查询VM监控数据都为统计用，数据量打，请求频繁；只有API的查询监控数据接口，是只返回原始数据不做统计，
		这样是否考虑采用RDS或其他支持简单统计功能的存储产品？
	* SLB API聚石塔项目发布 (新搭集群)
		1.24号发布支持， API改动，数据库表初始化及更新(青岛slb master地址改动)
		发布wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9256383
		环境：ssh sarah.wangq@shterm.aliyun-inc.com
	* 大region二期，周五前合并代码，周五再次提测
		API合并代码 merger代码 代码merger
			将trunk上的改动合并到branch上，最好是每一个版本发布改动都及时合如branch
			步骤：
				1）拉后续发布的trunk代码
				2）将trunk上的变化合并到当前branch上
				3）提交合入当前branch的修改到当前branch支上
				
				合入的其他项目的修改，在再次合并到trunk上时会有冲突，这种方式不合适，可基于最新的trunk再开一个分支，
				将本branch的修改合并入此新分支，后续基于此新分支继续开发。
			
			后面，此分支再merger到trunk时，步骤为：
				1）拉trunk最新代码
				2）将当前branch变化merger到上面的trunk上    （对于trunk上已删除的内容？）
				3）提交修改后的trunk代码到trunk上

			从trunk拉个分支，带上当时trunk的reversion，不好？
				根据邮件时间来猜分支基于trunk那个revision拉的，结合比较工具，重新拉下来比较

			方案3，合并时，拉最新的trunk，将当前branch修改合并到trunk上，前提是冲突不多的情况。
2. 

3. 标签 ，tag
	归类内容

4. chunked
	边接收边处理
	对于xml，html服务端如何分解chunk以及客户端如何一个个chunk去处理？
		每个chunk都是一个完整的文档格式，比如xml格式，每个chunk都是标准的xml格式，有头和尾。带来的问题，处理chunk数据ok，但
		所有chunk的汇总数据是格式不可用的。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day218 Thursday, January 24, 2013

1. 
	* 工信部上报IDCISP项目
	* MSS重构项目
	* 大region二期	
	* SLB API聚石塔项目	
	* 线上SLB API的nginx access log中有大量空的日志，分析产生原因？
		100.100.100.2 - - [27/Jun/2012:02:10:52 +0800] "-" 400 0 "-" "-" "-"
	
2. 大region二期
	- 对于API，如果后续有项目对trunk做大量改动，和二期的版本有大量冲突，可以考虑现在基于最新trunk再拉一个分支，
		将二期的修改合入新分支中，后续基于此新分支提交。？

2. MSS重构项目
	- 与OTS分析适用场景，并与RDS讨论是否可用RDS来方便调用方的统计需求（分布式RDS？），与RDS人员评估使用RDS做为存储
	VM监控数据的源是否合适
	- RDS对于大量短连接并发会有压力，需要加个中间层，也不建议每次都查询原始数据来扫描，而是有个数据归并功能，来自动归并数据，便于统计类的查询。
		
	这样若选择OTS，也可以另外起个归并任务来归并数据并再存入OTS中供统计查询用
	
3. 工信部上报IDCISP项目
	- 确认工信部上报IDCISP项目分支
	- 并对已确认需求的进行修改
	- PD确认上报中心与API的需求 今天？
		邮件已确认并增加2个字段nc.hostname,nc.ip，修改好接口文档后，再邮件发出
	- 以http chunked方式提供数据返回接口，只提供json格式，不提供xml格式（涉及xml头和尾的问题）

4. SLB API聚石塔项目
	 -  在线支持 晚11:30
		发布步骤wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9256383
		SLB API 目前管理不同版本的后端，对于表名的修改，在老库上以别名方式来兼容API的修改。

		聚石塔slb后端升级，slb api现管2个后端，另一个不升级，对于表名改动通过别名来兼容。？这里应该是视图，即通过创建视图来兼容来的表名的查询
		注意修改启动脚本，加入java参数：-Dsun.net.inetaddr.ttl=5 -Dsun.net.inetaddr.negative.ttl=5
			由于线上脚本和api svn上的配置有不同的地方，为减小不同点，此处发布可以在发布时修改线上的脚本，在tomcatctl脚本的export JAVA_OPTS="xxxx"内容下增加
			一行：export JAVA_OPTS="$JAVA_OPTS -Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0"

	- API运维wiki整理		
		http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9251044
		相应的简要发布步骤整理

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day219 Friday, January 25, 2013

1. 
	* MSS重构		
		OTS归并 统计需求
	* IDCISP项目
		

	* 提测模板介绍
		项目，脚本，sql变化都有对应的项可填
		项目发布完，通知配管，更新发布信息
		弹性计算-后羿-提测模板介绍 http://wiki.qa.aliyun-inc.com/index.php?title=弹性计算-后羿-提测模板介绍
		
2. MSS重构
	选择OTS作为数据源来存储VM监控数据，对监控数据的查询场景主要有2种：
		一种是根据条件比如vmName，timestamp，返回相应的记录（内容和原始数据基本一致，不需要再做统计，如API的计量查询接口）；
		另一种，是根据小时，或天查询出需要的数据来做统计，比如定时任务，嫦娥。
	对于第一种场景，与OTS同学确认是可以支持的；对第二种场景，由于频繁的查询出大量的数据且只为做统计用，消耗大量OTS和调用者的性能及带宽。
	为此，与大家讨论后建议可以增加一个归并任务，根据业务需要从OTS取出原始数据按小时、或天或更大周期做归并，然后再存回OTS中。这样，对于
	统计类的查询，直接查询归并的数据即可无需几时查询大量数据做统计用。
		根据上面说明，这个归并任务适合由那个角色来担当，即由谁来做这个工作，请大家献策 

3. IDCISP项目
	   邮件确认接口定义 done
	   部分开发工作可以进行
	   接口确认过后，设计与Master的接口定义



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day220 Monday, January 28, 2013

1. 
	* MSS重构
		数据存储到OTS后，houyi定时任务采集回去并整合进安全的数据，	再推送到OMS，OMS在归并推到BOSS；这里也有个归并过程，
		是否和MSS所需的归并连同考虑
	* IDCISP上报项目
		开发，单元测试，jetty容器调试
	* java.net.SocketException: Software caused connection abort: recv failed
		httpclient请求错误
		curl请求ok


2. MSS重构
	确认数据调用方
		houyi任务，嫦娥，houyi api，（boss，portal？）
	从而确认归并的问题

3. IDCISP项目
	GlobalErrorMessage系统对外错误码定义
	CLCErrorCode系统与Master交互内部错误码定义
	通过ErrorMessageUtils将内部错误码映射为对外错误码
		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day221 Tuesday, January 29, 2013

1. 
	* IDCISP上报
	* 大region二期
		
2. IDCISP上报
	测试环境部署，调试
	任务开发
	region查询时，若region没有设置任何属性，则ibatis的动态构造where时将会带入int的默认值0，注意这点。
	API新接口修复zone找不到时的空指针错误
		再提测

3. 大region二期
	拉出新分支，将二期的API修改合并入此新分支中，？待

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day222 Wednesday, January 30, 2013

1. 
	* IDCISP项目
		加入user缓存支持reload功能
	* 大region二期

2. IDCISP项目
	开发


3. 大region二期
	- 加入需求，指定imageNo去reset_vm时，保证所使用的image所在的集群为可用状态，尽量保证reset_vm成功  待分析？
		region已升级，使用bucket类型image时，需要判断image所在的region是否可用，若不可用则找本地hash类型image。
	- 将二期修改合入新branch：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_bigregion2_base0102upgrade
		并测试基本功能是否ok
		开发测试环境部署（换容器jetty）

		原来apache与jboss通过ajp协议，现在nginx与jetty通过http or what others?	   在httpd.conf中配置			
			1) 暂且直接配置为http方式通讯：
				<IfModule proxy_module>
					ProxyPass /open http://127.0.0.1:8080/open #静态文件的请求不需要转发，由apache直接返回，需要配置DocumentRoot 为程序目录(为防止冲突，建议配虚拟机)
				</IfModule> 
			2) 若需要，也可以配置为ajp方式通讯，主要配置如下：
				加载需要的模块：
					LoadModule proxy_module modules/mod_proxy.so
					LoadModule proxy_ajp_module modules/mod_proxy_ajp.so
					LoadModule proxy_balancer_module modules/mod_proxy_balancer.so
				配置httpd.conf：
					<IfModule proxy_ajp_module>
						ProxyPass open ajp://127.0.0.1:8190/open
						#ProxyPassReverse /open ajp://127.0.0.1:8080/open/api #rewrite if need
					</IfModule>
				确保backend的ajp端口与上面配置的一致（8190）。

4. 

5. URL rewrite URL重写 伪静态页
	apache的rewrite module，jboss，....

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day223 Thursday, January 31, 2013

1. 
	* IDCISP上报
		开发
	* 大region二期
		测试
	* OTS培训
2. IDCISP上报
	idcisp pojo 类 -> instance扩展信息service类 -> Dao类 -> command类 ->IP段等处理工具类 ->  action类 -> spring配置 -> 单元测试


3. OTS培训 pangu	* OTS
	内存写，多份内存数据保证可靠（多份ok，才能成功），不考虑小概率事件
	写比读快
	REDO Log
		全量Data
	Shard

	web portal展示监控数据，以及统计图表展示
	预发环境

	表，视图，需要在开始时创建，可动态加普通列，不能动态加主键列

	分片键设计，均匀分摊到多个分片，减少热点，也利于并发查询。

	倒入大量数据，建议多线程并发，调用者保证每个线程只操作一个分片来加快导入速度
	
	建议大数据表；不建议小表

	架构：
		基于飞天(pangu存储，nuwa命名，fuxi调度,shennong监控)

	与mongodb比较
		内存数据，与disk数据不一致问题

	+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	day224 Friday, February 01, 2013

	1. 
		* IDCISP上报
			2/20/2013号连调
			与Master连调，在开发测试环境临时部署此版本来测试
		* 
	2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day225 Monday, February 04, 2013

1. 
	* IDCISP上报
		
	* 

2. IDCISP上报
	- IP转换
		IP转为long类型 整型
		IP段
	- 返回值对象的设计 设计 返回值设计 return object design * 设计 返回值设计 pojo设计
		既要返回正常情况下的数据流，
		又要返回下层各个调用发生错误时，错误结果的返回、

		这时，需要设计一个综合的结果类，返回对象，来封装正确的数据返回和异常的错误返回，上层根据是否成功来判断结果是数据结果还是异常结果并
		做相应处理即可。

		Result<R>
			code
			isSuccess
			resultData
			...
		
		还有一种方式，通过方法的返回值来封装正确的数据调用返回；通过地址的参数传递方式来获取方法的其他返回信息（比如讲错误信息放到对象参数中返回）。
	- 返回view的设计
		可以在resultdomain中加上一个viewtype属性来标识action需要指向到的result

3. abstract action可以多做些公用的逻辑 建议
	比如使用struts框架时，获取request对象，请求参数等，这些逻辑在一个抽象类里搞定即可，无需再侵入到子类中。	

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day226 Tuesday, February 05, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	20号提测
		自测，与Master连调
	单元测试，自测
		API一些配置信息都移到env.properties文件，且API源码中无此文件，需要在测试环境或其他环境中拷贝一份下来 ，源码中有test.env.properties只是一个测试用的，内容为空？

	service ，action，dao，util工具类单元测试

	zone访问的权限控制？
		user角色

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day227 Wednesday, February 06, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	- API调用计量库部分缓存支持reload，或被动reload
		从而支持动态添加region时，无需重启API
			关闭region时，计量数据查询？
	 - jetty continuation方式增加region状态判断，可在request请求对象的参数中传递信息。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day228 Thursday, February 07, 2013

1. 
	* IDCISP项目	

2. IDCISP项目
	- chunked方式读取测试
	- regionNo到计量库数据源缓存的更新
		新增region时，更新region缓存，调用到计量查询逻辑时，应该触发cache更新操作，可查看日志验证


3. API到Master的通讯 HTTP Proxy
	API-(rpc)-Http Proxy-(kuafu)-Nuwa-(kuafu)-Master-(kuafu)-Nuwa-(kuafu)-cc-...

	每个小region一个http proxy，proxy将API的请求转发给kfc，kfc agent去访问nuwa并处理请求
	kfc每个小region独立
	
	API-over HTTP protocol->HTTP Proxy-over KFC protocol>KFC agent->Nuwa agent

	region表的proxy ip地址，以http方式与proxy交互，proxy得到请求角色的nuwa地址，proxy与KFC agent交互，KFC agent与nuwa agent交互
		nuwa://localcluster:10240/sys/houyi/master


4. command，要具体执行到那个region，可以将目标regionNo作为Command的属性，这样工具类就可以从这里获取，而无需一层层传递regionNo。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day229 Saturday, February 16, 2013

1. 
	* IDCISP

2. IDCISP
	-
	chunked输出测试，输出时设定等待时间来达到一块块的给	
	httpclient在获取输出流时，以chunked方式来处理
	若输出流为非chunked方式则需要读取到流结束才能解析，由于未说明content-length
	 - continuation方式的region状态判断 参考day227第2条
	VmDetailExecuteAction类的execute方法处独立判断region状态？
	- spring的AOP方法执行拦截，通过suspend注解避免显式的suspend
		<aop:config>
			<aop:pointcut id="continuation"
			<aop:advisor advice-ref="continuationBeforeAdvice"
			...
		Continuation处理步骤	* Continuation	jetty Continuation
		1）Proxy Action处设置当前线程的Continuation对象到ThreadLocal中
		2）进入Action
		3）调用Service方法(方法有Suspend注解且Service类已实现ContinuationListener类)，并处理Advice
			spring配置此注解需要在Service方法执行前执行，以suspend请求及其他操作，如下：
			continuation.addContinuationListener(listener);
			continuation.setTimeout(getTimeout(target));//Service类实现ContinuationTimeoutHolder接口设置
			continuation.suspend();//挂起并等待异步响应事件
				Service类和Listener合并是否合适？易误解

			suspend方法说明：
				DOC
				-------
				Suspend the processing of the request and associated ServletResponse. 

				After this method has been called, the lifecycle of the request will be extended beyond the return to the container from the Servlet.service(ServletRequest, ServletResponse) 
				method and Filter.doFilter(ServletRequest, ServletResponse, FilterChain) calls. When a suspended request is returned to the container after a dispatch, then the container will 
				not commit the associated response (unless an exception other than ContinuationThrowable is thrown). 

				When the thread calling the filter chain and/or servlet has returned to the container with a suspended request, the thread is freed for other tasks and the request is held until either: 

				1) a call to resume(). 
				2) a call to complete(). 
				3) the timeout expires. 
				Typically suspend with no arguments is uses when a call to resume() is expected. If a call to complete() is expected, then the suspend(ServletResponse) method should be used 
				instead of this method.

		4）上述Advice处理好后，请求挂起，进入Service方法体逻辑
			处理业务并在完成时调用Continuation的complete方法以通知处理完成
				判断是否完成通过在Continuation中设置键来判断
			Service业务逻辑处理ok后（通过回调实现业务逻辑调用处理），触发Continuation的complete方法
		5）Continuation的complete方法触发后，Service的onComplete方法监听到此事件并处理
			（之前spring AOP的MethodBeforeAdvice类中已经将Service类这个Listener设置到Continuation的监听器属性中）
		6）在onComplete方法中向Response写入返回结果

		确定Continuation方式下判断region状态的方案：
			在ApsaraCommandExecutor2的类中增加判断region状态，并将错误结果放到回调函数的onException方法中，Service中处理回调逻辑时，判断异常的类型，若为CLC异常
			则在Continuation中设置错误结果；然后在onComplete方法中取到此结果输出给用户。
		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day230 Sunday, February 17, 2013

1. 
	* IDCISP
	* MSS

2. IDCISP
	- 在Service逻辑中判断region状态，若为不可用则将错误信息放到Continuation中，在Continuation注册的Listener的onComplete方法中
		返回给用户。	
		每个按照当前Continuation方式实现的Service处都需要判断region的状态。

	- 连调环境确定，确保有环境可用于连调，邮件确认
	- 连调后准备提测
		
	- 开始准备发布步骤
		参考最新项目的发布步骤：（svn log）
			api_bugfix_201212
				双开发布步骤：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%8C%E5%BC%80%E5%8F%91%E5%B8%83%E6%AD%A5%E9%AA%A4
				Bugfix12项目上线步骤：http://wiki.ec.alibaba-inc.com/index.php/Bugfix12%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF%E6%AD%A5%E9%AA%A4
		步骤整理地址：
			http://wiki.ec.alibaba-inc.com/index.php/IDCISP%E6%95%B0%E6%8D%AE%E4%B8%8A%E6%8A%A5%E9%A1%B9%E7%9B%AE



3. MSS
		青岛OTS有计划部署，但北京OTS可能需要到，2012年4,5月的样子，这样，会存在杭州，青岛都是OTS提供监控数据查询，北京还是原有的数据库的方式，这样涉及到查询监控数据的
	调用方（如：houyi api，定时任务，嫦娥等）需要处理北京云的数据源还是老的数据源方式的逻辑。

4. java事务
	本地事务
	分布式事务
		MQ，分布式锁
	http://www.cnblogs.com/CloudTeng/archive/2013/02/16/2913694.html Java事务处理全解析（一）——Java事务处理的基本问题
5. java concurrent包
	与原有的同步方式相比较	
	切入点：memcached java客户端的优化
		http://www.infoq.com/cn/articles/memcached-java
		通过jprofiler分析性能

6. rss的实现

7. java NIO
	
8. struts2的interceptor部分异常问题
	可能导致无log输出·

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day231 Monday, February 18, 2013

1. 
	* IDCISP上线步骤
	* python

2. IDCISP
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day232 Tuesday, February 19, 2013

1. 
	* IDCISP
	* python
	* HouyiAPI增加根据小regionNo和控制系统命令名称来判断调用是否允许

2. IDCISP上线步骤
	
	发布工具+项目发布脚本
	
	发布工具：	
		http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/fabdeploy

	Master的python发布脚本位置：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_controller/
	HouyiAPI的python发布脚本位置：
		http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/

3. HouyiAPI增加根据小regionNo和控制系统命令名称来判断调用是否允许
	若为不允许，则返回维护中状态码
	需求场景：
		飞天升级，涉及region中OSS相关操作将不可用（影响创建快照和lazyload），但其他操作允许以减小影响时间
	控制系统影响到的接口如下：
		CreateSnapshot
		RollbackSnapshot
		MountSnapshot
		ResetVm
	根据上面控制系统影响到的接口整理出影响到的API接口如下：
		create_snapshot
		rollback_snapshot
		mount_snapshot
		reset_vm
	实现方式：
		- PD给出那些region的那些控制系统命令不可调用，HouyiAPI在数据库中维护这个(regionNo,Command名称)关系，表示
		某个小region下某些接口不可用，调用时报维护中状态码
		- region增加升级中这个状态，只有这个状态的调用才去过滤哪些接口不能调（性能考虑）
		- region状态为关闭时，所有接口调用都返回维护中状态码
	配置方式：
		- 升级某个或某几个小region时，若要过滤某些接口不可调用但其他接口可调用，则需要将哪些region的哪些接口不能调用的黑名单记录记录到HouyiAPI
		数据库中，然后调用接口reload对应的cache以生效。；
		- 升级结束，黑名单中的命令可调用时，需要从数据库中去掉这些记录，然后调用接口reload对应的cache以生效。
			
	项目Aone：
		http://aone.alibaba-inc.com/aone2/project/701/portal

	问题确认：PD
		


4. HouyiAPI返回json格式data键的值为null的缺陷 QA记录
	{"code":-95,"data":null,"msg":"invoke houyi system error"}
5. 
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day233 Wednesday, February 20, 2013

1. 
	* IDCISP
		原-100,no small region改为-131
	* 开路先锋项目

2. 开路先锋项目 2.28发布
	- 合并原IDCISP项目中加入维护中状态的代码修改到此新项目中（提前发布）
		（通过svn工具将原来此bugId的修改保存为patch/diff，然后apply patch到新项目中 apply patch；）不推荐
		直接merger branch方便，用patch后续有冲突，merger时使用场景为：
		对一个branch有多个版本的修改，现在需要对这多个版本的修改合并到其他branch上 -tips-
			打patch时注意，若patch生成时所基于的版本与将要apply到的版本不同，即中间不一致则apply时会有冲突，需要手工解决。
				打patch时的版本要与应用patch到的版本一致即可无冲突
					从打patch的原理来理解
			
	- 由于region增加维护中状态，需要调用Master那部分的region缓存可更新，故需要合入调Master缓存支持reload的代码patch
		merger tow different trees
	- 需要屏蔽的控制系统命令根据邮件继续更新

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day234 Thursday, February 21, 2013

1. 
	* 开路先锋项目
	* IDCISP连调时间
		下下周
	* SLB朝阳门项目API设计文档阅读
		
2. 开路先锋项目
	开发+自测
	2.28号发布于前端涅槃项目冲突，暂定在其后面发，具体时间PD先确认涅槃项目发布结束时间点。
	6.33部署测试 部分

list_vm_status接口这样跨多个region查询的情况，有一个在维护中，则返回维护中。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day235 Friday, February 22, 2013

1. 
	* IDCISP
	* 开路先锋
	* 确保开路先锋项目早于IDCISP项目先发布，然后在发IDCISP项目
2. IDCISP项目
	- 去掉已移到开路先锋项目发布的需求
		调用Master部分的cache支持reload
		访问关闭的region时，返回-100维护中错误码
	- 协助连调

3. 开路先锋项目
	- 2.28号发布延迟，安排在前端涅槃项目之后
		2.29周五紧急发布

	- 脚本工具提供
		python
	- 发布
		wiki地址：http://wiki.ec.alibaba-inc.com/index.php/开路先锋项目
		确认将要发布的集群
			所有集群？
			顺序，双开环境飞天已经升级，可排到后面发布，飞天升级到的region，API对应都需要升级。

		 参考：http://wiki.ec.alibaba-inc.com/index.php/%E5%8F%8C%E5%8D%87%E9%A1%B9%E7%9B%AE 简单通用API发布步骤
		 线上发布AY32C_AG、双开发布采用AY03NEW_AG

		分内部生产、线上生产。

		数据订正工具：
			svn地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/
				在这里提交工具文件

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day236 Monday, February 25, 2013

1. 
	* 开路先锋
	* IDCISP
2. 开路先锋
	- 集群发布计划
		此计划，PE周五会整理，作为下周发布计划，PM需要在发布前一周整理好
		http://wiki.ec.alibaba-inc.com/index.php/集群发布计划
			发布开始时间，结束时间与PE确认
	- 上线步骤整理
		脚本编写自测
			svn：http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20130228trailbreaker
				根据已有的工具所放地址来参考
	- 邮件确认建表语句和SQL
	- 提测（提前自测）
		邮件提测
			
		代码合并，合并到trunk
			修改少且可控可直接合Trunk来测试，否则先Branch，然后合入Thunk回归。
				本次合并入Trunk来测试
	- 发布相关
		周一提测
			提测好后，配管会对应给出出包说明的wiki，build地址：   http://scm.aliyun-inc.com/view/builds/
			发布步骤中的包信息来自配管的wiki
		周一到周三完成脚本
			PE负责reload cache
			脚本负责更新DB
		周四发双开 21:00
		周五发线上 21:00 （此时间点与涅槃项目错开，涅槃项目是否周四发布待确认）
	- 代码Review
		周三 2.27 定会议室
		邮件发布Review申请 待？
	- 数据订正工具
		依赖pypet来访问数据库（MySql）
		在不同集群发布时，需要确认好对应的pypet


3. IDCISP
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day237 Tuesday, February 26, 2013

1. 
	* 开路先锋项目
	* IDCISP项目
	* 大region二期
	* 周五，工作周报

2. 开路先锋项目
	- 脚本工具
		pypet如何切换不同集群的数据库？
			线上集群AG,内部集群AG，各自选取一个AG，在此AG上执行，pypet库保证其连接到正确的houyi库
				选择AY03-NEW-AG作为内部集群发布操作houyi库的AG
				选择AY41A-AG作为线上集群发布操作houyi库的AG
		工具开发及自测
		脚本不允许关闭Region或设置Region在升级中状态，提示Master region不能修改状态，需要切换其他Region为Master region，然后再修改此Region的状态。
			切换Master region的工具？地址

	- 代码Review邮件
	- 实现步骤整理好后
		DBA
			PE将表结构变动及新增通过窗口提交给DBA，作为数据订正工单处理
		PE
		相关人员代码Review
			会议室
		邮件确认

3. IDCISP项目
	- regionNo返回为大regionNo
		修改并提交
	- 去掉已移入开路先锋项目的需求部分代码修改
		houyi.console.service/src/test/java/com/aliyun/houyi/service/support/MasterEndpointCacheManageTest.java	D
		houyi.console.service/src/main/java/com/aliyun/houyi/service/support/MasterEndpointCacheManage.java	D	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day238 Wednesday, February 27, 2013

1. 
	* 开路先锋项目
	* IDCISP项目


2. 开路先锋项目
	- 确认飞天升级延期到3.14，确认涅槃项目在3.28，确认上面的过后，开路先锋项目建议3.4号发布
	- 代码Review
	- 本周四双开
	下周2，线上及其他内部集群

3. IDCISP项目
	提测准备


4. concurrent包，NIO ,Servlet3.0,Comet
	- concurrent包
		-  ReentrantLock
		   A reentrant mutual exclusion Lock with the same basic behavior and semantics as the implicit monitor lock accessed using synchronized methods and statements, but with extended capabilities. 

		   取锁逻辑如下：
			Acquires the lock unless the current thread is interrupted. 

			Acquires the lock if it is not held by another thread and returns immediately, setting the lock hold count to one. 

			If the current thread already holds this lock then the hold count is incremented by one and the method returns immediately. 

			If the lock is held by another thread then the current thread becomes disabled for thread scheduling purposes and lies dormant until one of two things happens: 

			The lock is acquired by the current thread; or 
			Some other thread interrupts the current thread. 
			If the lock is acquired by the current thread then the lock hold count is set to one. 

			PS: 如果锁被其他线程占用，则当前线程




5. jetty,tomcat
	架构
	使用NIO等的剖析
	tomcat架构：
		ref： http://www.cnblogs.com/tinylittlebunny/archive/2012/08/24/2654705.html
6. java对象的hashcode方法
	与集合类的关系
7. 一致性hash
	解决某些场景下hash重新计算问题

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day239 Thursday, February 28, 2013

1. 
	* 开路先锋项目

2. 开路先锋项目
	19:00发布

3. tomcat ,nio,comet
	结合tomcat源码分析NIO
		Http11NioProtocol

4. nginx做反向代理
	转发规则：轮询
5. jprofiler
	http://yufeimen.iteye.com/blog/70721 利用JProfiler对应用服务器内存泄漏问题诊断一例（转）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day240 Friday, March 01, 2013

1. 
	* 大region二期
	* IDCISP项目
	* 开路先锋

2. IDCISP项目
	提测 时间点定于开路先锋线上发布过后，避免冲突
		用户缓存支持reload

3. 大region二期
	上线步骤整理：
		http://wiki.ec.alibaba-inc.com/index.php/Bigregion2%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B#.E5.8D.87.E7.BA.A7.E6.80.BB.E4.BD.93.E6.80.9D.E8.B7.AF

4. 开路先锋
	设置region状态和黑名单的工具，在关闭Master Region时不是强制不允许关闭，而是给出警告，并提示是否继续操作。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day241 Monday, March 04, 2013

1. 
	* IDCISP

2. IDCISP
	连调
	数据写入，也是查询一个region写入一个region，从而充分发挥chunked方式的优势：
		边处理边返回，不然需要缓存大量的数据。	目前是传入zone_id，一次性拿到所有数据再分块输出。待优化？
		

3. hashtable与concurrenthashmap
	切入点：改进的点，为什么存在，有什么优点？
	通过细粒度化锁来实现最大化的并发操作
	ref: http://www.iteye.com/topic/1103980

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day242 Tuesday, March 05, 2013

1. 
	* IDCISP
	* 开路先锋项目发布

2. IDCISP
	chunked编码输出的边处理边输出实现方式？	struts2 chunked			  -tip-
	Action中启动线程循环整理数据并放到Struts的ValueStack中并返回View，程序执行到Result的处理部分，Resutl从ValueStack中取到队列并消费其中的
	对象以chunk输出，直到消费结束，Result处理结束响应用户请求结束。
	
	生产者消费者模式中，队列的选择 数据结构的选择 -tip-
		数组实现的队列
			根据下标访问（random access）快，增加删除可能慢
		链表实现的队列
			查找需要遍历，按顺序访问速度快，增加删除方便
		
		类似 ArrayList与LinkedList的区别
			从内部基于数组实现和基于链表的基本数据结构看区别
				从内存中的发布看本质

		对上面两种队列的性能测试

		上面这种场景下，增加删除操作频繁，对访问可以顺序访问不要求随机访问，链表实现的队列相对更合适

		生产者生产完毕，通知消费者。这样处理结束信号。

3. 性能测试
	比如程序突然加载大量内容，对内存的占用
	GC的观察
		
4. 通过SLB API为某个应用加上loadbalance服务的过程

5.  开路先锋项目发布
	线上环境QA无法回归关闭Region等会影响API操作的功能；只能通过侧面的detail_vm；验证版本正确；数据库正确来尽量保证发布ok。
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day243 Wednesday, March 06, 2013

1. 
	* IDCISP
	* 
		
2. IDCISP
	chunked
	边处理边输出

	另外，配置文件的路径改从java启动参数中取：jetty容器替换时做的变动
		BASE_HOME=/home/xxx/xxx
		JAVA_OPTIONS=" -Dapp.config.dir=$BASE_HOME/conf $JAVA_OPTIONS "
	用jetty-client来处理chunked输出：
	ref: http://aliali.iteye.com/blog/405444

3. jstat jinfo jps

D:\workspace2\api_dcisp\houyi.console.openapi\target\open.war

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day244 Thursday, March 07, 2013

1. 
	* IDCISP

2. IDCISP
	nginx默认不支持chunked输出，测试时从jetty返回的内容结果nginx就不支持chunked输出，而直接访问jetty web响应支持chunked输出。 -tip-
	问题描述：
		本机的一个javaweb应用，通过Servlet来输出chunked数据，作为测试样例
			通过apache的http client和jetty client测试ok
		API测试环境，通过访问nginx来访问jetty下的web服务
			通过apache的http client和jetty client测试都无法按chunked读取，只能读到所有数据才输出

	排查的场景：
	
	结论：
		此问题需要在连调时，模拟线上的场景来测试。QA会覆盖此问题
		nginx需要升级到支持chunked编码的版本(eg:1.2.xx)

3. 运维
	API提供了建表sql，还需要提供最小可运行数据初始化sql，搭建新api，新集群，自动化运维时需要考虑 -tip-

4. java代码优化 -tip-
	对于大集合对象，确认不在使用时，显式的clear掉，便于GC回收
		GC触发机制
			jmap -heap pid

	可通过
		jps
		jmap -histo:live pid | grep xxx 来确认那些没用的对象还在内存中
	比如cacheServiceImpl在spring中配置为prototype，则使用了几个就会有几个实例在内存中：
	#jmap -histo:live 18470 | grep com.aliyun | grep CacheServiceImpl
	705:             4            192  com.aliyun.xxx.xxx.CacheServiceImpl
5. python



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day245 Friday, March 08, 2013

1. 
	* IDCISP
	* MSS

2. IDCISP
	提测
		提测项：user缓存支持reload
		基于branch提测，待确定发布日期后合入主干再回归

		控制系统提测时，build失败，由于Master的trunk上有了新的变动，需要基于trunk拉一个新分支，将IDCISP控制系统的变动合入新分支
		后续基于此新分支发布。

	8.214开发自测环境，升级nginx到1.2以支持chunked编码传输 * nginx
		下载1.2.7版本源码包并安装：
		wget http://nginx.org/download/nginx-1.2.7.tar.gz /usr
		cd /usr
		tar -xvf nginx-1.2.7.tar.gz
		cd nginx-1.2.7
		./configuration --prefix=/usr/nginx1.2.7
		make
		make install

		修改nginx.conf
		启动
		/usr/nginx1.2.7/sbin/nginx


3. MSS
	python
	样例程序

3. 创建userd的key和id例子	       access key access id
	--------
		@Test
		public void createUser() throws Exception{
			UserHolder.setCurrentUser(new User());
			//
			UserService userService = new UserServiceImpl();
			Method m = UserServiceImpl.class.getDeclaredMethod("initUser", User.class);
			User user = new User();
			user.setEmail("ecscreate_test@aliyun.com");
			user.setUserName("aliyuncom_test");
			m.setAccessible(true);
			User newUser = (User)m.invoke(userService, user);
			System.out.println("id:"+newUser.getServiceAccessId()+"\nkey:"+newUser.getServiceSecretKey());
			Assert.assertTrue(true);
			
		}
	--------

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day246 Monday, March 11, 2013

1. 
	* IDCIPS
	* MSS

2. IDCISP
	- user缓存
		QA问题
		144下的子用户259,
		修改259用户的accessId为其他accessId，is_agent为非agent，agent_id为空
		reload用户缓存
		使用144的id、key用259的idkp访问259的vm能访问？
			问题

	- nginx支持chunked输出
	关闭buffer？
		配置nginx.conf：
			proxy_buffering off;
		上面这种配置方式，会导致所有proxy的转发都禁用buffer，影响性能。

		如果只是个别接口需要关闭buffer来支持chunked输出，可以在发送方设置一个请求头X-Accel-Buffering : no来告诉
		nginx此请求不进行buffer即可。
		此请求头，只出现在应用服务器与nginx之间，不暴露给用户

	关于nginx升级：
		由于使用了chunked编码；nginx需要支持此编码格式就需要支持HTTP1.1协议，故nginx需要升级。

3. release_ip接口
	释放公网IP时报 ip not exists，由于zone_ip表未正确初始化
		释放SLB 使用的vm的时候，释放公网IP报错：ip not exists

		ip_address_with_zone

		根据ip初始化regionNo时会报ip not exists
			查询ZoneIp表
				where条件为IP转为Long类型，判断是否在区间内
	每个Zone分配那些ip及其段的记录，应该每个Region的每个Zone有单独的段。
	
	wiki描述：http://ops.ecs.alibaba-inc.com/wiki/%E5%BC%B9%E6%80%A7%E8%AE%A1%E7%AE%97EC/%E6%97%A5%E5%B8%B8%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C/2013.03.11_SLB_%E5%85%AC%E7%BD%91%E5%9C%B0%E5%9D%80%E5%88%9D%E5%A7%8B%E5%8C%96%E5%9C%A8houyiapi%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E6%95%B4%E7%90%86

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day247 Tuesday, March 12, 2013

1. 
	* IDCISP上报项目

2. IDCISP上报项目
	与QA一起确定nginx版本与测试方案

3. 飞天
	component
	http://10.202.66.27/apsara_release/apsara0.10.2/

4. loadbalance
	
5. 去中心化

http://baike.baidu.com/view/5784548.htm


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day248 Monday, March 18, 2013

1. 
	* 大region二期


2. 大region二期
	oss 以lvs做为前端对外作为http服务入口
	考虑到下面的场景，API在使用image的调度逻辑在双11推广高峰时会有问题，需要调整：
		一个大region的小region跨2个机房(3-1,4-1)分布，当只有4-1机房的某个region有资源创建vm，但image却在3-1机房的某个region上（没有使用
		本地hash类型的image是因为后面将去掉这种类型的image的使用），这样image加载就需要通过lvs进行跨机房传输，高峰期流量时可能会打垮lvs
		。
	解决方案：
		bucket类型image支持多个，在需要使用此bucket image的region中再上传一份bucket类型image。image调度逻辑调整为：
		本地bucket类型image -> 大region范围内bucket类型image -> 本地hash类型image

		对于原逻辑，为了避免跨region加载image，将bucket类型image通过image工具同步为hash类型的方案？暂不用？

	评估变动：
		原来大region下只有一个bucket类型image，现在支持每个region都上传一个
			相关的sql，逻辑判断需要修改
	
	基于二期API的新分支修改并提交：
		
	- 使用Image的逻辑，涉及create_vm，reset_vm接口
		查找image逻辑修改为：
			本地bucket类型image -> 大region范围内bucket类型image -> 本地hash类型image
	
	改动提测时间：
		3.21	

3. 迭代开发，不是一口吃成胖子

4. 深入java虚拟机

5. zk test


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day249 Tuesday, March 19, 2013

1. 
	* 大region二期
	* MSS重构
	* IDCISP项目
	* SLB API交接


2.  大region二期
	修改
	自测

3. MSS重构
	OTS表初步设计稿（考虑HouyiAPI，Houyi定时任务，未考虑嫦娥的查询业务支持）
		关于嫦娥的查询需求，未确定由谁负责提供支持？
4. IDCISP项目
	QA测试完毕，测试通过，待确定发布日期后，合入trunk，QA测试API支持动态增加region功能，基于trunk发布
	waiting
4. dubbo
	dubbo了解
	SLB API暴露dubbo服务

5. 飞天升级步骤参看
	http://wiki.aliyun-inc.com/projects/apsara/wiki/VMOnlineUpgradeNew

6. houyi重构
	region master暴露dubbo服务，由前端来路由请求到具体的region master。
	wiki: http://wiki.ec.alibaba-inc.com/index.php/%E5%A4%A7%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84#.E7.AE.80.E5.8C.96.E6.8E.A5.E5.8F.A3

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day250 Wednesday, March 20, 2013

1. 
	* MSS重构
	* 大region二期
	* 了解SLB API集成dubbo
		   后续ec服务也需要暴露dubbo服务
	* IDCISP项目
2. MSS重构
	表初步设计，依据OTS说明文档以及业务查询需求

3. 大region二期
	API到控制系统查询一个不存在的snapshotId，控制系统返回成功？根据snapshotId是否存在来来判断快照是否存在？		      910 912
		对于已删除的快照，控制系统200返回本次不修改，否则unmount已挂载上但随后快照就被删除的情况，无法unmount -tip-
		本次不修
	create_image查找母盘信息时，selectCustomImage中的sql错误，影响创建自定义image

4. IDCISP项目
	- 发布步骤完善
		发布前准备
	- 
	上报中心与各个业务系统大连调，需要提供生成环境的数据以与其他业务系统的数据能正确对应上，
	目前有2种方案提供大连调数据：
		1) 使用QA环境（更接近线上环境）从线上导入部分数据
		2) 提前线上发布

5. HTTP慢连接攻击    慢速连接攻击 Slowloris 
		

6. 云计算 安全团队 攻击防范
	从服务器防范攻击保证服务稳定上分析云服务器的优势
		传统的IDC对防御网络攻击的能力有限
		小型站点，受限于硬件资源，防御攻击能力有限

7. 控制系统角色
	monitor
	master
	nc_controll
	netc
	cc

	依赖AOS ，飞天
		fuxi
		nuwa
		pangu

8. linux负荷，负载
	w
	top

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day251 Thursday, March 21, 2013

1. 
	* IDCISP项目
	* 大region二期

2. IDCISP项目
	控制系统发布二个版本（一个基于0.8.0.6，一个基于0.10.2），以解决飞天升级过程中，每个大region的控制系统版本不一致问题
	计划3.27发
	4.20为与工信部连调的deadline

3. 大region二期
	bugfix
	明天提测：多个小region允许都上传同一份bucket image

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day252 Friday, March 22, 2013

1. 
	* 大region二期
	* IDCISP项目
	* MSS

2. 大region二期
	bugfix
		create_image查找母盘信息时，selectCustomImage中的sql错误，影响创建自定义image
		create_image
			查询母盘信息（根据创建image所基于的快照的信息，拿到母盘Image的imageNo，若拿不到则为非可启动Image，不允许创建Image；这是由控制系统在打快照时
			对系统盘的快照存入了对应的imageNo，而数据盘的快照imageNo列是空的）
			DB查询是否重名imageNo
	
	提测

	发布
		API一次性发布，控制系统分批次在飞天已升级到0.10.2的region上发布（API兼容新老版本控制系统）


3. IDCISP项目
	
	与QA确认测试资源（测试0.8.6,0.10.2二个版本的控制系统），
	确定发布日期    3.28
		并填写到发布计划中（周五）
	合入trunk	 
	并基于trunk提测		
		控制系统也从new分支合入trunk与api的trunk一起提测
		紧急patch在上面之前先单独提测

	deadline 4.20 与工信部连调

	发布
		API一次性发布，API Proxy一次性发布（提前发布，降低风险）
		控制系统根据飞天版本不同分别基于支持10.2的trunk上和原来8.6版本的trunk发布，QA需要进行控制系统基于新老飞天2个版本的回归
		后续，基于0.8.6飞天的控制系统升级时，需要将控制系统基于0.10.2飞天再编译后发布（飞天升级时需要做的步骤）
	
	配管基于0.8.6的线上版本控制系统拉一个紧急patch，作为老飞天region的升级版本，出包

	发布计划：
		API Proxy提前发布，发双开，发线上部分集群（观察），发其他所有集群
		3.25 21:00双开Proxy发布
		3.26 23:00线上Proxy发布
		3.28 21:00双开
		3.29 21:00北京云(0.10.2)，AY41C(0.8.6)
		4.2 21:00其他所有集群
	
	新增一个内部集群：AY03B
	10.125.250.49，10.125.250.48
ay03b的api机器
AG:10.125.251.1
c_api:http://10.249.0.101/open/services
api的地址如上



4. MSS
	监控数据存储产品选择：
	OTS
		不提供汇总，统计功能；无法满足类似嫦娥这样统计查询较多的业务方

	SLS(Simple Log Service)
		底层基于OTS实现，并提供自定义的数据汇总功能（利用ODPS汇总），出入口都为SLS服务。
		支持统计，归并

		http://olsweb.aliyun-inc.com，需要了解的地方可以咨询我们的PM 荣惠。
		wiki: http://wiki.aliyun-inc.com/projects/apsara/wiki/ShennongOpenService
		
5. 落日弓项目，需要API将每次版本的sql变动都放入统一的sql文件中 比如houyi_ddl.sql
	将用户体系改造中的sql变动加入上面的sql文件中

6. svn权限重新分配
	read only
	过期？

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day253 Monday, March 25, 2013

1. 
	* IDCISP项目
	* 大region二期
	* MSS重构

2. IDCISP项目
	QA测试接口，连调无法保证数据正确性
		控制系统接口漏掉SLB使用的vm的信息，sql关联问题
	双开API Proxy发布
		proxy执行关闭命令后，加上检查是否已关闭的步骤，wiki步骤添加 
		check out文件时，svn账号需要输入 
		/usr/ali/nginx1.2.7/sbin/nginx -v检查version


3. 大region二期
	create_image
		查询快照
		查询快照所基于的源Image信息，并设置给新生成的Image
			尽管同imageNo对应多条记录，region不同，snapshotType不用，但只获取Image自身信息，limit 1是可以的。
		在API库的image表增加一条image记录

	API提测
	query_avaliable_img接口的逻辑，抄送下邮件，imageNo返回多条记录的情况
		另外，snapshotId需要处理为三段式（记录缺陷，后续项目修复）


4. MSS重构
	SLS熟悉，作为监控数据的存储源

5. HTTP POST Attack
	测试

6. 设计 架构 -tip-
	产品只关注自己应该关注的侧重点
	对于那些依附逻辑可以解耦到上层业务层处理。

	如用户体系与基础ECS服务
	ECS只有userId标识资源所属，至于角色，权限，账户间关系等逻辑，可以交由上层业务去封装。这样，将易变的东西与产品核心服务分离，


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day254 Tuesday, March 26, 2013

1. 
	* IDCISP项目
	* MSS重构

2. IDCISP项目
	控制系统接口漏掉SLB使用的vm的信息，sql关联问题
		已修改后提测
		修改wiki
	API Proxy包多打了pid文件，重新打包，修改wiki步骤
	API修复
		zone_id找不到zone的判断
		region_id的判断（原为interceptor拦截region_no）
		chunk分块时，末尾vm重复
		region_id,zone_id两者存在zone_id即可，待

		已有bug：
			format传入错误时，api空指针

	线上API Proxy发布 23:00
	
	QA对新增接口的质量保证，自测无法覆盖质量的各个方面

3. MSS重构
	SLS熟悉
	python



6. TMD
	C/S
	tmd server / tmd client
	与机器学习


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day255 Wednesday, March 27, 2013

1. 
	* IDCISP项目
	* MSS重构

2. IDCISP项目
	上报中心同学需要双开的key，以便于明天发布后测试 
		双开环境借QA的测试账号，提醒只进行读取操作
		问PE，线上账号？上报中心已经有账号
	query_unasigned_ip接口
		修改default region和default zone时，代理商身份未reload cache直接返回中已生效，但end user需要reload cache生效，原因？

3. MSS重构
	SLS
	Python

4. dubbo
	了解

5. 团队
	定位
	晋升
	区别

6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day256 Thursday, March 28, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	双开发布
		控制系统发布前检查状态，双开出现扩容导致多个master的问题，tubo配置conf有问题，重启后问题出现；控制系统发布nc，monitor，houyi，引用同一套库
		CC启动有延时，后续可提供可视化的web界面，以形象的呈现各个角色的服务状态


3. 
	单个region规模有限(xx)
	结构复杂,外部依赖多，导致单个region运维成本很高,无法快速扩容
	手动搭建一个新region需要两周事件，而且交付质量无法保证
	随着规模的增长，region数过多，管理维护成本高
	配置数据分散在houyidb/apidb/regiondb 三个层次几十个db instance中，层次不清，结构复杂
	vm运行数据分散在每个region的monitor db中，管理利用非常不方便，运维成本也高
	数据流与控制流并行，对系统处理能力产生过大压力
	vm管理/网络管理）等业务管理的接口消息量并不大；
	前端定时查询所有vm运行状态，流量非常大，而且随着vm的增长而增长；
	nc和vm的心跳消息量也很大，也随vm增长而增长；
	缺乏消息发布/订阅模型，无法主动推送数据，应用实现复杂
	开发效率较低，难以即时响应业务需求
	发布代价大，经常要白天发布

4. instance缓存
	RegionAwareIntercept.getCurrentRegion() > ResultMessage resultMesseage = resourceRegionLocator.getResourceRegionNo(params, regionNoHolder);


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day257 Friday, March 29, 2013

1. 
	* IDCISP项目

2. IDCISP项目
	线上部分集群发布
		一个大region的API发布过后，下次某个小region升级前，通过根据设置region的状态为关闭后再发布，API无需关闭。发布步骤补充
	AY03B发布

3.
	rpc - > rpc.jar > kfc

4. 内网冒头代码review
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_politics


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day258 Monday, April 01, 2013

1. 
	* 广渠门项目
	* IDCISP项目

2. IDCISP项目
	所有未发布的集群发布
	API合入bugfix分支的修改，一起发布？
		未发布的集群用新API包，其他不变；已发的集群重新发布API包即可；
	
3. 广渠门项目
	4.15提测
	与dubbo集成是否冲突？

	API的HA方案，参考master的方案：
		keepalived
		lvs agent 接受控制指令
		参考wiki: http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9248400

		slb api ha方案wiki: http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9260270

	SLB syn攻击防御，让lvs具有防御syn-flood ddos攻击的能力：
		lvs上为每个vip新增两个计数项: syn包的数目, SYN_RECV状态的连接数
		lvs agent采集这两个计数项上报给master
		master定时对vip的这些计数项进行检查, 判断是否需要打开或者关闭synproxy

	让lvs具有防御syn-flood ddos攻击的能力。当syn-flood攻击发生时，lvs自动对攻击进行检测，并且采取一定机制进行防御，保证lvs不会被syn-flooding打垮；
	当flood结束后，lvs切换回正常状态。

	设计要点：
	1)LVS上对DDoS的防护策略是，首先保障LVS本身不受DDoS影响，并保护LVS上的VIP业务，其次要尽量保护被攻击VIP业务不受影响。
	2)DNAT的单臂模式不具备Full-NAT中syn-proxy完美的[SYN-Cookie+TCP Proxy]防护能力，DNAT是单臂(只有进流量经过lvs，出流量不经过lvs)模式，
	只能选择功能有局限的防护方案。
	3)由于DNAT是单臂模式，DNAT在LVS避免受到CC流量攻击有天然成本优势。(注:只是LVS系统业务本身不受影响，并未考虑攻击带来的带宽成本因素)
	4)在非攻击场景下，DNAT的设备成本优势明显(目前SLB的流量统计，in:out = 1:8-10)
	5)本方案同OSPF Cluster方案组合效果最佳

4. dubbo	
	zookeeper registry

	dubbo项目的pom文件中定义了assemble逻辑，打包时去掉了demo，simple等测试用的模块，并将dubbo正式各个模块打为一个jar包（含registry，common等模块），这样
	在样例的demo，simple项目中引入此dubbo依赖包，即可去实现dubbo的服务和功能。-tip-

	对zookeeper是透明的，通过registry模块来使用zookeeper作为registry。

	Install the zookeeper registry:

	cd ~
	wget http://www.apache.org/dist/zookeeper/zookeeper-3.3.5/zookeeper-3.3.5.tar.gz
	tar zxvf zookeeper-3.3.3.tar.gz
	cd zookeeper-3.3.3/conf
	cp zoo_sample.cfg zoo.cfg
	vi zoo.cfg
	- edit: dataDir=/home/xxx/data
	cd ../bin
	./zkServer.sh start

	cd ~/dubbo/dubbo-demo-provider/conf
	vi dubbo.properties
	- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
	cd ../bin
	./restart.sh

	cd ~/dubbo/dubbo-demo-consumer/conf
	vi dubbo.properties
	- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
	cd ../bin
	./restart.sh

	cd ~/dubbo/dubbo-simple-monitor/conf
	vi dubbo.properties
	- edit: dubbo.registry.adddress=zookeeper://127.0.0.1:2181
	cd ../bin
	./restart.sh


5. API并发问题
	在2台API上并发add_disk
	横向扩展的集群系统，在并发操作一个资源时，需要一个全局锁来解决并发问题

	目前group相关接口通过唯一的数据库记录作为全局锁
	zookeeper？

6. 向阳花木易为春 -tip-
	谈团队中长你的工作所处的位置

7. java分布式系统
	hadoop？
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day259 Tuesday, April 02, 2013

1. 
	* IDCISP项目
	* 大region二期项目
	* 内网冒头项目
	* 广渠门项目

2. IDCISP项目
	合入谭总的修改分支，用最新包先发布已发集群的API，然后发布剩下的其他集群
	控制系统发布前，停止API，修改发布步骤wiki


3. 大region二期项目
	API与控制系统的错误码细化和修改，具体见邮件

4. 广渠门项目
	SLB API的HA方案，涉及SLB API的部署架构？

5. 内网冒头项目API代码review
	VlanQueryAction2中获取idkp的逻辑应该从userholder中取出，用户角色是什么？
	
6. 代码email
	设计模式
	优雅
7. SLB API数据库切换 晚上23:00
	一台API机器的access.log日志不正确
	data的日期正确

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day260 Wednesday, April 03, 2013

1. 
	* 广渠门项目

2. 广渠门项目 SLB API
	check out分支
		注意，SLB这边Master和API是在同一个svn路径下的，即时一个整体，这样每次迭代拉分支时，2者提交到同样的分支上。

	设计文档编写

	API的HA方案有待后续讨论确定？

3. CM6机房
	dg的AY41系统集群
	参考wiki说明：http://wiki.ec.alibaba-inc.com/index.php/Xen虚拟化/线上常用信息

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day261 Sunday, April 07, 2013

1. 
	* 广渠门项目

2. 广渠门项目
	QA建立keluda项目
	细分需求到独立的任务
	开发
		slb api支持部分region关闭时，返回维护中错误码
		struts2 拦截器中直接返回结果	* struts struts2
			将结果设置到ValueStack中，然后在interceptor方法中直接返回View名称即可。
			-------
			public class RegionAwareInterceptor implements Interceptor {
				...
				@Override
				public String intercept(ActionInvocation invocation) throws Exception {
					...
					if(targetRegion != null && targetRegion.getStatus() == GlobalConstants.REGION_STATUS_UNAVAILIABLE){
						ResultDomainVisitor.setResultDomain(ServletActionContext.getContext().getValueStack(), 
								GlobalErrorMessage.SLB_SYSTEM_MAINTAINING);
						return Action.SUCCESS;
					}
					return invocation.invoke();
				}
			...
			-------
			拦截器层加判断，会导致一些只涉及API操作的接口也会受影响，是否可以下沉到具体的接口操作时再去判断region状态，从而对应
			相应处理逻辑。？即，处理逻辑只放在需要关心的层中处理 -tip-
				如，找到访问后端的逻辑入口，在哪里判断region状态。
				如此，一些维护接口，比如clear_cache就可以继续使用，只有真正调用到后端时才会提示维护中错误。
				

3. struts2封装表单参数到bean中，对于web service这种普通get请求是否提供拦截器辅助处理

4. HouyiAPI的zone_id表修改，是否使用了缓存？比如IP扩容时
	待确认

5. 测试
	apache + tomcat集群配置
	ref: http://www.iteye.com/topic/1017961

	多个tomcat实例
	配置好 jvmroute，端口
	应用的web.xml文件中，配置<distributeable/>标签 —— 如此session才会被复制到集群到其他tomcat上
	log里打印出 Manager session state send xxx received in xx ms
	测试session复制

	tomcat集群搭建好，然后配置前端proxy来实现负载均衡
		配置apache2或者nginx
			转发规则？轮询，权重，健康检查			
			nginx轮询 done 见 * nginx nginx实现负载均衡
				
			apache2
	
	tomcat集群session复制方式：
		1）all-to-all复制方式（DeltaManager ），打开下面的注释即可
			<Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
			缺点：session会复制到集群的每个节点（包含没有部署相应应用的节点上），集群规模不能大
		3）BackupManager
			This manager only replicates the session data to one backup node, and only to nodes that have the application deployed. Downside of the BackupManager: not quite as battle tested 
			as the delta manager. From doc of tomcat
			

	新加节点
		添加新tomcat服务器
	下线节点
		下线tomat服务器

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day262 Monday, April 08, 2013

1. 
	* 广渠门项目

2. 广渠门项目
	keluda在slb产品线下
	单元自测
	详细设计添加到设计文档中

3. hashcode与hashtable
	hashtable capacity·最后能提前预估，避免扩容时的再次hash代价和分配空间代价
	hashtable中有个modCount成员变量，记录此table修改的次数，比如增加，删除都会修改，用于iterator的fail-fast机制。
	rehash的触发：This method is called automatically when the number of keys in the hashtable exceeds this hashtable's capacity and load factor(capacity * loadFactor).

	数组+链表的数据结构
		每个entry以数组存放，以取模定位下标；
		每个bucket中的entry以链表存放

4. SLB API的rs表
	select ip,lb_id from rs where lb_id is not NULL 这条语句，从slb api的数据库获取数据，是否需要去重？	
	select ip,count(lb_id) from rs where lb_id is not NULL group by ip having count(lb_id)>1;
	163 rows in set (0.01 sec)

	select ip,lb_id,count(*) from rs where lb_id is not NULL group by ip,lb_id having count(*)>1;
	8 rows in set (0.05 sec)
	存在完全一样的表记录，排查原因？待
	select * from rs where ip='10.241.220.70'; 3条记录

	
5. hibernate?
	sucks

	观察者模式 jdk实现


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day263 Tuesday, April 09, 2013

1. 
	* 广渠门项目

2. 广渠门项目
	明确VM的内网IP不变，从而从缓存的RS表中根据vmName取到IP，不再去HouyiAPI查询
	下面的sql查询现有rs表，检查是否有vmName对应对个IP的记录：
		select t1.vm_name,count(t1.vm_name) from (select vm_name from rs group by vm_name,ip) t1 group by t1.vm_name having count(t1.vm_name)>1;
		Empty set (0.05 sec)

		即还是满足上面的一个vmName与内网IP一一对应，可以用：select distinct vm_name,ip from rs where vm_name='xxx' 来取到vmName对应的IP结果。
	
3. Service层的DaoAccessException异常捕获
	spring+ibatis
	spring事务管理

4. Service层，DAO层
	对于那些简单DAO原子操作，在Service层很薄，没有业务逻辑，是否臃肿？
		网络讨论结果不一，保持thin的Service层以备业务增加之需。

5. 围绕xen虚拟化基础 ecs服务
	在xen的基础上提供产品服务，需要做哪些工作
	硬件
		硬件的支持和投资
	软件
		封装xen的API，以规范易用的API对外
		解决vm的存储问题，使用分布式存储（IO稳定与IO效率高低，备份与恢复问题）
		解决vm的网络问题（zone，VLAN等，集群规范大了，网络如何设计以适应更大的集群，更多的vm，以及变化的业务）
		镜像/快照管理，与存储相关，但需要细分管理
		底层分布式集群系统的支持（nc规模上去后，nc宕机将是常态，如何提供稳定的服务集群）
		周边服务的提供（负载均衡，安全，存储等）
		运维

6. spring与ibatis结合分析
	spring通过工厂类返回sqlmapclient对象（通过ibatis的SqlMapConfigParser和SqlMapParser实现）
	然后注入到spring的template类中
	template类通过回调执行dao操作
	ibatis的session通过SqlMapExecutorDelegate执行具体sql

7. interview
	带出来的都是积极的，太诚实了就是伤自己，厚黑学
	最近在研究啥，看啥书？
		JVM
		NIO
		设计模式
		SLB
		HA
	MQ
	alipay
		hibernate准备好，都忘的差不多了吧。。。
	DB
		mysql
		oracle
		sql server
	前端
		jquery
		Jsp
			struts2标签
			EL表达式
		session管理

	深入基础

	细致和深入的理解专长，少而精；面覆盖到了，点就不容易突出，需要积累。

	高到不可替代，否则帽子摘不掉；唯有卧薪尝胆，另辟蹊径
		有感于前辈
	
	当地高校+关系+强技术背景（公司）牛人+外包，业务为主，自我成长
		所以外包转正可能性微乎其微






+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day264 Wednesday, April 10, 2013

1. 
	* 广渠门项目
	* 助力申牌项目

2. 广渠门项目
	自测，HA方案
3. 助力申牌项目
	上报中心连调发现部分VM的数据有问题，nc_host_name为空
	经确认，控制系统的vm表没有对应vm记录，但ip表有vm的记录，sql查询不是以vm为主表，导致一些数据丢失并返回给API。
		确认解决方案
		确认垃圾数据产生原因及如何避免

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day265 Thursday, April 11, 2013

1. 
	* 广渠门项目

2. 广渠门项目
	连调
		add_vm	ok
		delete_vm		ok
		add_rs	ok
		delete_rs	ok
	SLB后端也有采集监控数据的逻辑（python实现），可以参考 * python

	从API到后端，源码级别梳理add_vm所操作的流程，分析SLB作用的机制
		add_rs
		xuanyuan-plugin-slb-RestRsPool

	LB类型
		compact 类型：类似Amazon方式设置LB，一个LB对应一个LbId，一个VIP，可以执行addVm操作（内部对于rsPool/vmPool的操作对用户透明，方便操作）
		hybird类型：V1版的LB，一个LB对应一个LbId，一个VIP，对VIP可以设置Rule（内部为对rsPool的操作）；有rsPool的概念，用户可以自行addRs（用户需要自己管理）
		http类型：为ACE用户简化的LB类型
	
3. lsof 
	lsof -p 123 查看123进程打开的文件
	lsof -i:3306
		查看3306端口被谁占用
		结合netstat使用

4. NIO技术原理
	Reactor
	AIO

5. JVM GC
	分配大对象时，如果超出了eden space大小，则会分配到old spance，这样容易导致年老代占满，触发FullGC

	
6. mytest mavenlize	项目导入 导项目 导maven项目 eclipse项目导入
	error
	project properties
		java compile
			annotation processing disable
			factory path disable

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

day266 Friday, April 12, 2013

1. 
	* 广渠门项目
	* 助力申牌项目
		接口“垃圾”数据过滤

2. 广渠门项目
	HA方案

3. SLB API-SLB MASTER
	add_rs流程梳理
	xuanyuan-plugin-slb-RestRsPool
		
		

4. NIO
	IBM developerworks
		NIO
	sun对ServerSocketChannel的实现：sun.nio.ch.ServerSocketChannelImpl 源码分析
		socket方法分析：获取server socket对象
			判断连接是否关闭
			判断是否bound
			创建FileDescriptor（FD）
			调用本地方法Accepts a new connection
				setting the given file descriptor to refer to the new socket
				Returns 1 on success, or IOStatus.UNAVAILABLE (if non-blocking and no connections are pending) or IOStatus.INTERRUPTED


5. thinking in java
	16.2 观察者模式 JDK的实现
		java.util包
		Observable
			This class represents an observable object, or "data" in the model-view paradigm. It can be subclassed to represent an object that the application wants to have observed. 
			
			An observable object can have one or more observers. An observer may be any object that implements interface Observer. After an observable instance changes, 
			an application calling the Observable's notifyObservers method causes all of its observers to be notified of the change by a call to their update method. 

			notifyxxx
			addObserver
				Vector实现监听者列表

		Observer
			A class can implement the Observer interface when it wants to be informed of changes in observable objects.

6. network networking

7. hibernate in action
	first level cache
		session cache
			load,get.etc cache objects
	second level cache

9. JDK1.6源码		
	C:\Users\wb_shen.chengs\Documents\j2se\src\windows\classes

10. design patten
	Provider
	Factory
	Visitor
	Adaptor
	Observer

11. Freedom
	
12. Thread类的interrupt方法
	中断线程
	JSR-51 DOC comment

	Thread.interrupt()
	--------
	Interrupts this thread. 

	Unless the current thread is interrupting itself, which is always permitted, the checkAccess method of this thread is invoked, which may cause a SecurityException to be thrown. 

	If this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), 
	methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException. 

	If this thread is blocked in an I/O operation upon an interruptible channel then the channel will be closed, the thread's interrupt status will be set, and the thread will receive a java.nio.channels.
	ClosedByInterruptException. 

	If this thread is blocked in a java.nio.channels.Selector then the thread's interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, 
	just as if the selector's wakeup method were invoked. 

	If none of the previous conditions hold then this thread's interrupt status will be set. 

	Interrupting a thread that is not alive need not have any effect.
	--------

	
13. 复习的一些小得	-tip-
	用不到的东西，光靠主动学习，终不深刻，纵知其所以然，也不免假以时日，所剩无几。
	纸上谈兵终觉浅，谙熟于心要躬行
	何以躬行？

	有刻意的准备，才有效果。只得闲暇之余继续苦读 ~~

	与所处的环境对成长直接有关，只搭过鸡窝，那来盖大厦的心得。不过略有耳闻所见罢了。

14. 工作虽苦却很愉快，视野也长了不少；愉快的开始，也就让它愉快的结束，该继续赶路了，继续前行
	专业，深层次
	业务，大数据，高并发

15. 优势在哪里
	全能选手 lol

	劣势在哪里
		分工细化背景下找不到特别突出的地方
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day267 Monday, April 15, 2013

1. 
	* 广渠门项目

2. 广渠门项目
	提测
		1) SLB API增加逻辑，对于已关闭的region，API不去调用，返回集群维护中错误
		2) 删除，切换vm或者rs时，slb api不需要再去houyi db查询vm信息，而是直接在slb api数据库查询
		3) slb api 支持只关闭对某个region下slb的调用，而不影响对其他region下slb的调用
	HA方案预设计

	SLB API的svn分支包含在SLB Master的分支下，是否单独拉出来比较合适，开发时互不影响？

3. 大表，大数据
	
4. 实践、沉淀 -tip-
		
5. 大二层网络定义
	OSI网络模型中，二层为链路层（MAC，ARP）
	跨数据中心的二层，不可避免需要走三层网络，通过路由到达目的端，为了实现此目的，隧道技术的采用是不可避免的

6. SLB API-SLB MASTER
	create_loadbalance
		接受API参数并处理
		查询可用eip(for update查询)
			没有找到则抛异常（可设计优化为返回错误码而不是以异常来做为返回，不以异常做为逻辑分支）
		创建LB
		绑定eip到lb instance上
		将LB加入上下文缓存中

		注：全程DB操作
	
	add_vm
		接受API参数并处理
		调用service层进行addVm操作
		service层以Command模式将必须的参数传递给addVm操作类并调用process()以执行,参数有lbId,user_id,lvs_realserver_task,proxy_realserver_task,vm_list
			注意：这里传入了addLvsRealServerTask, addProxyRealServerTask这2个对象封装了add_lvs,add_proxy的操作。定义代码如下：
			-------
			LvsRealServerTask addLvsRealServerTask;
			ProxyRealServerTask addProxyRealServerTask;
			LvsRealServerTask deleteLvsRealServerTask;
			ProxyRealServerTask deleteProxyRealServerTask;
			LvsRealServerTask switchLvsRealServerTask;
			ProxyRealServerTask switchProxyRealServerTask;
			-------
		到rs_pool表找到lbId对应的所有RsPool	 （如果有则认为是add_rs操作）
			如果没有rsPool与此lbId对应：
				则将本次vm和lbId信息，插入到vm (ip_addr, weight, lb_id, gmt_create)表中
				执行成功，返回结果

			如果有rsPool记录：
				将本次vm和lbId信息，插入到vm (ip_addr, weight, lb_id, gmt_create)表中
				根据vmList和rsPoolId，到real_server(ip_addr,weight,rs_pool_id,gmt_create,gmt_modify)表创建记录
				因为lbId有对应的rsPool记录，查询对应的vip（select * from vip where lb_id=）
					若lbId对应的vip存在，则add rs hc status ，参数为vmList,vip对应的rspoolId，vipId	 ，rs_hc_status(ip_addr,vip_id,rs_pool_id,gmt_create,gmt_modify)
					检查并设置vip的状态，CheckVipList(vipList, Action.CONFIG,lbDo.getUserId(), tcpVipList, httpVipList) ，（vip状态：NONE("none"), CONFIG("config"), ACTIVE("active"), INACTIVE("inactive"), UPDATE("update"), SUCCESS("success"), ERROR("error");）
						遍历vip列表，调用service修改vip状态，
							根据vip当前状态获得下一个状态的操作方法枚举对象，并将action传递过去，返回下一个vip状态值（CONFIGURING("configuring")）；
							同样获取下一个action对象（Action.CONFIG）
								------
									RUNNING	STOPPED   STOPPING    STARTING    CONFIGURING    STARTING_FAIL    STOPPING_FAIL    CONFIGURING_FAIL
									===================================================================================================
									------------------------------------------------ vip的状态机 -------------------------------------------------------------------
									CONFIGURING     -         -           -             -               -                -                   -       |   config
									-          STARTING     -           -             -               -                -                   -       |   active
									STOPPING        -         -           -             -          STOPPING         STOPPING            STOPPING     |   inactive
									-             -         -           -             -          STARTING         STOPPING           CONFIGURING   |   update
									-             -       STOPPED     RUNNING      RUNNING            -                -                   -       |   success
									-             -     STOPPING_FAIL STARTING_FAIL  CONFIGURING_FAIL  -               -                   -       |   error
									----------------------------------------------- 对vip操作的迁移图  --------------------------------------------------------------
									config         none       -           -             -               -                -                   -       |   config
									-           active      -           -             -               -                -                   -       |   active
									inactive        -         -           -             -            inactive         inactive            inactive   |   inactive
									none          none       -           -             -            update           inactive            update     |   update
									none          none      none         none        none           none              none                none      |   success
									none          none      none         none        none           none              none                none      |   error
									====================================================================================================
								------
							如果nextAction为None且netStatus不为null，不成立，则将vip的状态更新到vip表中
							返回Action对象
						如果返回的Action与传入的相同，则跳过不处理
						判断vip的类型，HTTP or TCP 并加入对应参数中的tcpVipList, httpVipList)中
						根据上面列表，检查instance和proxy
							根据lbId查询lbInstance，若未找到，日志打no lb instance bound to lb
							若有lbInstance则遍历
								调用service检查lbInstance（checkInstance(lbInstance.getId(), action)）
					判断tcpVipList, httpVipList两者那个有值，对应的调用lvsRealServerTask或proxyRealServerTask执行process(vipMap)方法,参数类型为：Map<List<RealServerDo>, List<VipDo>>
						Task调用lvsMessageService或者proxyMessageService根据vip和rs构造消息
							根据lbId找对应的ip记录（select ip_addr from ip where lb_id =），得到eip列表
							遍历eip列表
								根据ip的lbInstance属性，查找lbInstance
								若未找到，则log记录 ip xxx not bound to instance，跳过不处理
								为单个vip构建ips字段
								根据lbIntanceId找到lbNode列表
								遍历lbNode列表，将ipList消息映射到某个lvs上
								组装lbNodesMap
						返回lbNodesMap
					调用common service发送事件给agent（具体事件在子类的getEvent方法中，如AddLvsRealServerTaskImpl，DeleteLvsRealServerTaskImpl etc.）, Event定义了各事件对应的操作码
						sendParallelly(lbNodesMap, event,Constants.LVS_AGENT_TYPE, Constants.SEND_LVS_TIMEOUT)
							异步RPC调用到agent（lvs_agent,proxy_agent），传入回调函数处理异步返回值
							------
							rpcPoint.asynCall(address, port, event, 1, RestUtil.getJsonValue(data), new ResponseHook() {
											
											public void onResponse(Message response) {
												if (response != null) {
													String rspBody = new String(response.getBuffer(),
															Charset.forName("utf-8"));

													logger.info("sendMessage to agent, event : " + event
															+ ", agent address : " + address + ", response : "
															+ rspBody + ", sequence: " + response.getSequence());
													if(MessageUtil.checkResponse(rspBody))
														successCountDL.countDown();
												} else {
													logger.warn("sendMessage to agent, request timeout, event : "
															+ event + ", agent address : " + address);
												}
												countDL.countDown();
											}
										});	
							------
							PS:
								异步回调或者消息传递方式实现异步操作。

							
					操作成功，更新vip状态的DB中
						
					
									

							
		根据task返回值，构造结果，返回



				


	add_rs流程梳理
		xuanyuan-plugin-slb-RestRsPool
	
	=Spring JDBC=
	使用spring提供的jdbctemplate类使用jdbc操作数据库（spring jdbc模块）
	使用spring编程式事务
		PlatformTransactionManager
		----
		DefaultTransactionDefinition def = new DefaultTransactionDefinition(TransactionDefinition.PROPAGATION_REQUIRED);
		...
		TransactionStatus tstatus = transactionManager.getTransaction(def);
		...
		transactionManager.commit(tstatus);
		...
		transactionManager.rollback(tstatus);
		...
		----

		----
		<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
			<property name="dataSource" ref="dataSource"></property>
		</bean>
		----

	对于固定句型的sql（比如insert语句），可以用PreparedStatement来优化
		----
		This method is optimized for handling parametric SQL statements that benefit from precompilation. If the driver supports precompilation, the method prepareStatement 
		will send the statement to the database for precompilation. Some drivers may not support precompilation. In this case, the statement may not be sent to the database until 
		the PreparedStatement object is executed. This has no direct effect on users; however, it does affect which methods throw certain SQLException objects. 
		----
	
	org.springframework.jdbc.support.KeyHolder
		Interface for retrieving keys, typically used for auto-generated keys as potentially returned by JDBC insert statements. 

	org.springframework.jdbc.support.GeneratedKeyHolder
		Default implementation of the KeyHolder interface, to be used for holding auto-generated keys (as potentially returned by JDBC insert statements). 
	
	在jdbcTemplate类下面这个方法中用到：
		public int update(final PreparedStatementCreator psc, final KeyHolder generatedKeyHolder)


7. 了解云磁盘项目

8. command模式

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day268 Tuesday, April 16, 2013

1. 
	* MSS重构

2. MSS重构
	存储产品选型，云监控？待评估
	数据及时性是否满足
	数据归并汇总是否满足
	读写性能是否满足
	如何部署

	云监控的产品进度不一定能跟上本项目，故暂以SLS作为设计时的存储
	云监控作为所有产品监控数据的存放源？产品总体规划

	SLB
		SDK?
		APIVersion	服务版本号 多服务版本 version dubbo？ -tip-
			指定需要访问API的版本，支持不同版本API的访问

	pync了解
	
	参考SLB xuanyuan agent的实现，将python版的monitor agent作为xuanyuan的一个agent运行。




3. 24种设计模式复习
	head first design patten

4. spring validation
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day269 Wednesday, April 17, 2013

1. 
	* MSS


2. slb流程梳理
	changlaobang


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day270 Thursday, April 18, 2013

1. 
	* MSS
	* 大region二期

2. 大region二期
	bugfix
	image.status=0为可用

	根据image查询可用region时，if语句只执行一次而不是跳出for语句。
	
	存储结构：
		lvs每个region一套（主备）-> OSS Master -> pangu多个Master -> kv存储（一个region多份拷贝）
		region间通过lvs访问各自OSS服务
	
	23号合代码到trunk



3. zookeeper分布式锁应用

4. slb流程梳理

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day271 Friday, April 19, 2013

1. 
	* MSS


2. MSS
	数据写入方案暂讨论为：写入云监控同时，也写入到monitor库
	API暂时还是从monitor库取，后续改为从云监控取数据（或建议用户直接走云监控接口，减小API数据流的访问流量）

3. 装饰器模式(Wrapper or Decorator patten)
	chunked输出可以重构为使用装饰器模式，继承自DataOutputStream或者FilterOutputStream

	 javax.servlet.ServletRequestWrapper也是一个例子
	DOC
	---------
	Provides a convenient implementation of the ServletRequest interface that can be subclassed by developers wishing to adapt the request to a Servlet. 
	This class implements the Wrapper or Decorator pattern. Methods default to calling through to the wrapped request object.


4. SLB流程梳理
	RPC调用部分（如master到lvs agent或其他），异步RPC调用的实现（回调函数）

	The HttpExchange class is intended to be used by a developer wishing to have close asynchronous interaction with the the exchange.

	jetty http client分析
	ref: http://blog.csdn.net/pwlazy/article/details/7389204

	apsa2的rpc采用blocking模式，回调函数处理返回，使用jetty client的NIO机制


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day272 Tuesday, April 23, 2013

1. 
	* MSS
	* 大region二期
	* slb

2. MSS
	SLS对MSS的读写场景和性能支持评估、以及部署
	后续写入会到云监控，需要评估云监控对SLS的包装方式，在此基础上评估读写云监控的可行性
	

3. 大region二期
	代码合并？
		新的修改需要加入api，暂不合入代码
	发布步骤补充完整

	由于新插入项目，延期合代码到trunk

4. SLB bug查看
	id=290300
	-2003出现场景
		api执行action出错，捕获异常并返回-2003，具体看api log
	grep slbapi/logs/slbapi/*.log -e create_vip

5. 
操作系统概念》（第六版）（Operating System Concepts, Sixth Edition [John Wiley & Sons]

6. pssh
	pssh -i -H10.250.8.214 'echo 1'
	pssh -i -h host_file_name 'echo 1 && ls -al'

7. nio
	selector
		nio实现所基于操作系统底层的支持方式

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day273 Wednesday, April 24, 2013

1. 
	* 大region二期

2. 大region二期
	发布前演练

3. 

4. nio
	selector基于不同操作系统平台有相应的实现
	select方法在收到事件前会blocking

	selectorImpl类继承nio的抽象selector类，实现公有逻辑后（参数判断、同步等），将变化的部分交给抽象方法doSelect，由底层的实现类去实现。

	sun.nio.ch.NativeDispatcher的本地实现调用本地方法执行操作

5. 根深蒂固
	不可缘木求鱼
	才能开枝散叶

6. servlet
	servlet3.0>servlet>struts2流程

7. struts2框架
	研究框架，学习设计、设计模式的应用等 -tip-
	servlet？
		被Filter，Action取代

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day274 Thursday, April 25, 2013

1. 
	* 大region二期
	* MSS重构

2. 大region二期
	QA环境演练，api包未被正确替换（sql日志中无snapshot_type字段打出），查找原因
		PE再执行一次观察发布过程，确定原因，确认为QA houyi2的AG发布工具版本过低，导致api未发布
	houyi2,houyi1组成一个大region

3. MSS重构
	参考slb的xuanyuan_agent的python实现的agent
	http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/xuanyuan_agent

4. aps2类同步rpc与异步rpc的实现
	异步rpc基于jetty http client的异步调用
		
	同步rpc在异步基础上加了同步锁实现
		或者使用jetty http client的waitForDone()方法
			源码如下：
			-----
			public static final int STATUS_START = 0;

			private AtomicInteger _status = new AtomicInteger(STATUS_START);

			public int waitForDone() throws InterruptedException
			    {
				synchronized (this)
				{
				    while (!isDone())
					this.wait();
				    return _status.get();
				}
			    }
			-----
			PS: 在设置HTTP状态时，使用了Concurrent包中的AtomicInteger对象来实现状态修改的原子操作

	jetty http client的client.setConnectBlocking(true)，属性的作用？ * jetty http client jetty client
		HttpClient的 startConnection 方法org.eclipse.jetty.client.SocketConnector实现类的部分逻辑
		-----
		if (_httpClient.isConnectBlocking())
		{
			channel.socket().connect(address.toSocketAddress(), _httpClient.getConnectTimeout());
			channel.configureBlocking(false);
			_selectorManager.register( channel, destination );
		}
		else
		{
			channel.configureBlocking(false);
			channel.connect(address.toSocketAddress());
			_selectorManager.register(channel,destination);
			ConnectTimeout connectTimeout = new ConnectTimeout(channel,destination);
			_httpClient.schedule(connectTimeout,_httpClient.getConnectTimeout());
			_connectingChannels.put(channel,connectTimeout);
		}
		-----
		PS: 无论setConnectBlocking是否为true，通道都是非阻塞的；区别在于上面这段代码的分支中，建立连接是否会阻塞
		如果为false，则connect方法立即返回，由应用去保证连接已建立以及获取结果的逻辑处理

4. QA测试环境	AT03-HOUYI-AG
	10.250.6.27
	ssh 10.230.204.19
	go2houyi2
	api: 10.230.226.146

5. apsa
	pangu/disk1

6. TCP/IP详解
	socket > 2 types of socket > TCP/IP,UDP > book
7. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day275 Friday, April 26, 2013

1. 
	* 
2. 

4.jetty http client

5. design patten的例子整理
	chunked输出采用decorator模式重构
		流输出jdk已经提供了类，此场景需要再做包装以支持chunk输出，故可利用此模式以扩展jdk自带类的功能
		apache的org.apache.commons.httpclient.ChunkedOutputStream/ChunkedInputStream也是这样实现的，可以参考或直接使用
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day276 Saturday, April 27, 2013

1. 
	* 广渠门项目


2. 广渠门项目
	bugfix	298458
	是因为根据master返回值中的ip无法找到vmName，log中打印result is null，并发的去调用delete_rs和delete_rs_pool，会不会
	在delete_rs_pool 后端成功返回但api还没根据ip得到vmName前，调用了delete_rs操作，将rs表中记录删除，导致delete_rs_pool无法根据ip找到vmName

	access_log
	30330 10.230.130.1 - - [22/Apr/2013:14:12:44 +0800] "GET /slb/api?aliyun_idkp=1234567890&timestamp=2013-04-22%2014%3A19%3A27&sign=5t2Rvo0AI5N      d5wFVnWVgzA%3D%3D&session=0nyJ6lBPsku1F2TALWdFMA%3D%3D&rs_pool_name=czPerformTest_Thread-57&action=delete_rs&region_no=fake-vrrp-houyi-      region&rs_list=%5B%7B%22vm_name%22%3A%22slb-vrrp-01%24%2410.230.138.245%22%7D%5D HTTP/1.1" 200 148 "-" "-" "-"
	30331 10.230.130.1 - - [22/Apr/2013:14:12:44 +0800] "GET /slb/api?aliyun_idkp=1234567890&timestamp=2013-04-22%2014%3A19%3A27&sign=vF8r0nqty%2      BH8qiU95icXww%3D%3D&session=0nyJ6lBPsku1F2TALWdFMA%3D%3D&rs_pool_name=czPerformTest_Thread-57&action=delete_rs_pool&region_no=fake-vrrp      -houyi-region HTTP/1.1" 200 172 "-" "-" "-"
	
	事务问题及解决方案：
			由于涉及slb后端和slb api的表关联操作，本质上是一个跨应用的数据库事务问题，即在slb后端删除rspool时，要开启事务保证此时rspool以及
		其上面的rs不被其他事务修改，这样delete_rs需要等待delete_rs_pool的事务完成才能进行（因为rspool被删除delete_rs会报rspool不存在错误）
	

4. slb api
	对返回结果需要统一处理的，可以用decorator模式来设计

5.crontab
	定时任务执行，比如切割应用的日志

6. 一次配置jtester的例子 -tip-
	jtester与spring配合时，如果配置了jtester.properties配置文件，则需要启用spring module，否则spring不会被加载，更不会打印spring加载的log；出错了可以借助错误分析哪里
	出的问题，一点信息都没有时，要思考是否哪里最基本的设置有问题，因为错误都没触发。

	如果已熟悉unitils.modules可以配置是否启用相应的模块时，此问题也不复存在。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day277 Sunday, April 28, 2013

1. 
	* 广渠门

2. 广渠门
	bug待master那边排查是否为事务问题



兔子月薪5千，打算用20万建一个窝。　　狼不允许，说私自建就是违章建筑，只允许向王八买。　　王八是搞房地产的，先用20万贿赂狼取得开发权，再用50万元向狼买这块地，投资10万元把兔子窝盖好，向兔子要价200万元。　　兔子拿不出这么多钱于是向狐狸借200万元，连本带利300万，20年还清，　　兔子全家二十年给狐狸打工。　　狼、狐狸、王八都挣了钱，只有兔子亏，连孩子也不敢生了。　　兔子越来越少，狼觉得这样下去大家没肉吃，于是调控。　　狼显得非常重视兔窝价格太贵的问题，研究 部署了遏制兔窝价格过快上涨的政策措施。最后认定兔窝价格卖得太高的原因是因为有的兔子买了兔窝后自己不住而进行倒卖所致。　　于是狼规定：兔子买了兔窝5年内卖了的，要向狼交纳营业税。　　结果兔窝价格没降下来，狼却发了大财。　　狼又对狐狸说：只借钱给首先交了更多钱的兔子，并提高高利贷的利息，多买兔子窝的不借，全交现钱。 
　　这样狐狸在兔子的购窝过程中也发了财。　　王八借着兔窝价格上涨的行情，以更高的价格向狼买地，并转嫁到兔窝价格上，再加价后卖给兔子。　　看到狼辛苦地为自己操劳，兔子很感谢狼，但还是发现兔窝价格越来越贵。　　狼说：这事挺复杂，还真不太好办，不过兔子们放心，我们将继续调控，可以向已经有兔窝的兔子征收兔窝税┉　　看见的转发一下，因为有些兔子还不明白。近日，世界银行高级副行长、首席经济学家林毅夫一针见血地指出：“穷人把钱存入银行，实际上是补贴富人”。在中国有一个奇怪的现象：穷人到银行存款，富人到银行贷款。结果穷人越来越穷，富人越来越富！中国的老百姓只要坚持3个月之内不存钱，房价将跌穿，银行 破产。中国的很多问题就可迎刃而解 。群多的转发吧，有多少转发多少，总有一天物价会降,这个信息够狠的。因为我们大部分人都是兔子。三十年前你们宣传“计划生育好，政府来养老”，我们信了； 
二十年前你们改为“计划生育好，政府帮养老”，我们依然可以接受；十年前你们彻底颠覆了过去的承诺，改成了“养老不能靠政府，要求加社保”，我们交钱养老也认了！ 现在我们老了，又说适时推迟养老计划！现在该信谁？谁才可信？中国政府下半年援助欧盟1000亿美金，援助东盟100亿美金，昨天又宣 布无偿援助文莱40亿美金，40万人的小文莱相当于每人1万美金。著名经济学家、耶鲁大学陈志武教授一针见血地指出：“中国的钱美国可以用，非洲可以，朝鲜可以，政府可以，官员可以，富二代可以，二奶可以，唯独老百姓不能用”＂如果三个月没有1百万人转的话这表示我们中国人真的败了，是中国人就转起来! 让我们铭记这耻辱。＂ -----白岩松

3. 用tcpdump观察chunked编码的数据chunk，服务器是否会返回状态码（长连接）
	tcpdump port 80 and host 10.1.171.192

4. failed to load the jni shared library
JDK是32位，下载的eclipse也需要是32位的；如果是64位的eclipse，则JDK也需要64位 -tip-
因为你的jdk装的是32位的，而eclipse装的是64位的，换个eclipse就好了

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day278 Thursday, May 02, 2013

1. 
	* 大region二期
	* python

2. 大region二期
	master返回查询快照的接口返回值中，对于已被删除的快照，snapshotType返回的是一个随机的整数，而非1或2，API是否有问题？
	API在处理master的结果时，若果有snapshotType参数且值不为1或2，则不会设置属性snapshotType；
	快照的getSnapshotType方法在：createImage，和SnapshotServiceImpl的isSnapshotCanUseInTargetRegion方法中用到，前者会将空传递给DAO层（表字段默认为1，即hash类型）
	以默认值存储，后者已判断snapshotType是否为空，为空则报错（-50, "snapshot not exists"）。

3. 通过wireshark分析chunked传输过程
	tcp3次握手后建立连接，client发出http请求，server返回一个tcp ack，接着继续返回http 200 ok以及的一个chunk的数据,client收到后返回一个tcp ack，
	server开始以http返回数据(不包含状态码)，client收到后返回tcp ack，这样循环直到server返回chunk的结束标志，接着返回/r/n，client返回tcp ack，此时chunk数据
	传输结束

4. design patten & concurrency

5. mysql短连接，随机建立连接慢的问题
	dns反向解析？

6. callback,回调模式
	spring支持hibernate提供的HibernateCallback（HibernateTemplate使用）
	spring支持jdbc的JdbcTemplate用到的多个callback
		ConnectionCallback：
			Generic callback interface for code that operates on a JDBC Connection. Allows to execute any number of operations on a single Connection, using any type and number of Statements. 
		StatementCallback：
			Generic callback interface for code that operates on a JDBC Statement. Allows to execute any number of operations on a single Statement, for example a single executeUpdate 
			call or repeated executeUpdate calls with varying SQL. ）

	spring支持jndi访问的JndiCallback，
	DOC
	-------
	org.springframework.jndi.JndiCallback
	
	Callback interface to be implemented by classes that need to perform an operation (such as a lookup) in a JNDI context. This callback approach is valuable in simplifying 
	error handling, which is performed by the JndiTemplate class. This is a similar to JdbcTemplate's approach. 

	Note that there is hardly any need to implement this callback interface, as JndiTemplate provides all usual JNDI operations via convenience methods.

	PS: callback接口的设计，简化异常的捕获；spring有大量模板类使用这种模式，比如JdbcTemplate也是这样，集中捕获/转换异常，关闭连接等操作。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day279 Friday, May 03, 2013

1. 
	* mss python

2. 

3. 

4. zookeeper paxos
	http://zookeeper.apache.org/doc/r3.1.2/zookeeperInternals.html

5. factory patten
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day280 Monday, May 06, 2013

1. 
	* 

2. jetty http client
	org.eclipse.jetty.util.thread.ExecutorThreadPool
	DOC
	-----------
	Jetty ThreadPool using java 5 ThreadPoolExecutor This class wraps a ExecutorService as a ThreadPool 

		
	支持socketConnector和SelectConnector（epoll支持）
	缓存的使用（Direct（系统支持，减少数据拷贝次数），与NonDirector），request，response缓存	  * directbuffer * nio

	---------
		如果我们构造一个ByteBuffer仅仅使用一次，不复用它，那么Direct Buffer和Heap Buffer没有明显的区别。两个地方我们可能通过Direct Buffer来提高性能： 
		1）大文件，尽管我们Direct Buffer只用一次，但是如果内容很大，Heap Buffer的复制代价会很高，此时用Direct Buffer能提高性能。这就是为什么，
		当我们下载一个大文件时，服务端除了用SendFile机制，也可以用“内存映射”，把大文件映射到内存，也就是MappedByteBuffer，是一种Direct Buffer，
		然后把这个MappedByteBuffer直接写入SocketChannel，这样减少了数据复制，从而提高了性能。 

		2）重复使用的数据，比如HTTP的错误信息，例如404呀，这些信息是每次请求，响应数据都一样的，那么我们可以把这些固定的信息预先存放在
		Direct Buffer中（当然部分修改Direct Buffer中的信息也可以，重要的是Direct Buffer要能被重复使用），这样把Direct Buffer直接写入SocketChannel就比
		写入Heap Buffer要快了。 
	---------
	from: http://eyesmore.iteye.com/blog/1133335
	ref: http://stackoverflow.com/questions/5670862/bytebuffer-allocate-vs-bytebuffer-allocatedirect 
	PS: 学习jetty http client，缓存了各种对象到buffer中

	aps2类结构：-tip-
		RpcEndPoint接口定义了通过RPC与其他系统交互的接口方法，提供关闭，启动组件，以及支持同步，异步调用，以及针对异步是否有返回值，通过回调
	拿到异步结果；Kuafu2RpcEndPoint接口继承自RpcEndPoint，针对kuafu协议上的RpcEndpoint定义，并提供一个抽象类AbstractKuafu2RpcEndPoint（在底层实现提供
	的异步调用基础上实现同步调用，底层实现只需提供异步调用即可）；JettyRpcEndPoint、NettyRpcEndPoint为实现上面抽象类的实现类，提供了具体的异步调用
	实现；aps2类引用RpcEndPoint接口的实现，以作为rpc组件包与API的桥梁CommandExecutor接口的实现。
		异步调用目前为jetty continuation方式实现。
		另外，由于目前的RPC调用是，API将请求以http的方式发送给 http proxy，proxy将请求转换为RPC协议格式来请求kuafu，故API的rpcendpoint中没有实际构造
	RPC请求的逻辑。



3. servlet3
	异步请求
	tomcat7.x trunk: http://svn.apache.org/repos/asf/tomcat/tc7.0.x/trunk/


4. hb3
	session的创建及执行
	不求甚解 or 知其所以然
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day281 Tuesday, May 07, 2013

1. 
	* SLB广渠门
	* 

2. SLB广渠门
	新增需求：RDS从v1迁到v2，需要用到SLB产品，但是其提供的vm只能提供ip，这样涉及rs，vm，rspool操作的接口需要支持用户传入ip的支持
	确认传入ip时，是否需要验证ip对应的vm的所属权限？
		原vmName参数，会用当前用户的账号去ECS查询vm，如果没有权限会返回错误。
		此功能是否也开放给其他用户，如何处理规则？

		待RDS先确认

	API的rs表，vm没有vmName，只有ip

	整理涉及的接口列表：

3. ivy ant+ivy
	 tipsofreads

	 ant - from: Agile java development with spring ,hibernate and eclipse
	 ivy - from doc files in its zip distribution

	 zookeeper项目采用ant+ivy

4. 方法论 -tip-
	先解决基本问题，在考虑隐性问题
	减少不必要的钻牛角尖

5. MQ分析 发布订阅 消息服务
	分析已有的message module：
	库：
		amqp-client-2.2.0（rabbitmq实现）
	步骤：
		1）new一个com.rabbitmq.client.ConnectionFactory工厂，需要提供host、port、username，password
		2）从工厂取到一个 com.rabbitmq.client.Connection（Public API: Interface to an AMQ connection. ）
		3）基于上面的Connection创建com.rabbitmq.client.Channel（Public API: Interface to an AMQ channel）
		4）创建一个com.rabbitmq.client.QueueingConsumer（Convenience class: an implementation of Consumer with 
		straightforward blocking semantics），并将channel作为参数传入其构造方法中，此为队列消费者
		5）往Channel中注册consumer消费者，提供queue名称、是否autoAck、以及consumer，从而取到Public API - Start a non-nolocal, non-exclusive consumer
			
			一种数据结构，IPC机制的实现：
			com.rabbitmq.utility.BlockingCell<T>
			Simple one-shot IPC mechanism. Essentially a one-place buffer that cannot be emptied once filled

			往通道注册消费者代码如下:
				com.rabbitmq.client.impl.ChannelN
				--------
				public String basicConsume(String queue, boolean autoAck, String consumerTag,
							       boolean noLocal, boolean exclusive, Map<String, Object> arguments,
							       final Consumer callback)
					throws IOException
				    {
					BlockingRpcContinuation<String> k = new BlockingRpcContinuation<String>() {
					    public String transformReply(AMQCommand replyCommand) {
						String actualConsumerTag = ((Basic.ConsumeOk) replyCommand.getMethod()).consumerTag;
						_consumers.put(actualConsumerTag, callback);
						// We need to call back inside the connection thread
						// in order avoid races with 'deliver' commands
						try {
						    callback.handleConsumeOk(actualConsumerTag);
						} catch (Throwable ex) {
						    _connection.getExceptionHandler().handleConsumerException(ChannelN.this,
													      ex,
													      callback,
													      actualConsumerTag,
													      "handleConsumeOk");
						}
						return actualConsumerTag;
					    }
					};

					rpc(new Basic.Consume(TICKET, queue, consumerTag,
							      noLocal, autoAck, exclusive,
							      false, arguments),
					    k);

					try {
					    return k.getReply();
					} catch(ShutdownSignalException ex) {
					    throw wrap(ex);
					}
				    }
				--------
			


		6）取queue中的数据，如果没有则等待
			实现采用了concurrent包的：
			 java.util.concurrent.LinkedBlockingQueue<E>
			DOC
			-----------
			An optionally-bounded blocking queue based on linked nodes. This queue orders elements FIFO (first-in-first-out). The head of the queue is that element that 
			has been on the queue the longest time. The tail of the queue is that element that has been on the queue the shortest time. New elements are inserted at the tail 
			of the queue, and the queue retrieval operations obtain elements at the head of the queue. Linked queues typically have higher throughput than array-based queues 
			but less predictable performance in most concurrent applications. 

			The optional capacity bound constructor argument serves as a way to prevent excessive queue expansion. The capacity, if unspecified, is equal to Integer.MAX_VALUE. 
			Linked nodes are dynamically created upon each insertion unless this would bring the queue above capacity. 

			This class and its iterator implement all of the optional methods of the Collection and Iterator interfaces. 


		7）AMQCommand调用transmit方法发送command，传入channel对象
			从channel对象获取connection以完成数据写入
			写入单位为：
				com.rabbitmq.client.impl.Frame
				Represents an AMQP wire-protocol frame, with frame type, channel number, and payload bytes.
			
			一个心跳线程，在发送frame后发送一个信号（signal）：
				com.rabbitmq.client.impl.HeartbeatSender
				Manages heartbeat sending for a AMQConnection. 
				Heartbeats are sent in a dedicated thread that is separate from the main loop thread used for the connection.



		

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day282 Wednesday, May 08, 2013

1. 
	* SLB广渠门

2. SLB广渠门
	邮件确认新增需求取消，RDS继续沿用直接调用slb master的方式

	后期若确实需要支持，这里如何设计？

3. Java MapReduce编程框架

4. interview

	1.参与或负责淘宝视频中心及视频导购系统的研发


	原淘宝网岗位
	岗位要求1. 本科以上学历，两年以上JAVA开发经验；
	2. 熟悉WEB开发相关技术和开源框架，如HTML、Struts、Spring、iBatis等；
	3. 有较大规模系统的设计和开发经验；
	4. 有较丰富的数据存储和查询系统（如Oracle/Mysql, Redis, HBase等）经验，对性能优化有一定的经验；
	5. 学习能力强，适应能力好，对技术充满热情，良好的沟通能力

	Ibatis
		cachemodel
	Oracle
		


5. 系统优化 -tip-
	由于houyi api的部署有多个，且各自相互独立，如果启用缓存，可能会出现一台API机器RS1缓存了某些数据，但另一台RS2却修改了db数据，RS2的缓存
		根据配置会随即更新，但RS1的缓存却无法触发更新。

		解决方法之一：使用同一缓存，比如使用memcached统一缓存；统一缓存部分设计为可替换方式，比如后面如果需要替换缓存实现服务。
		其他解决方法？独立缓存消耗宝贵的内存，还是统一分布式缓存较好（关注网络、HA、以及序列化的性能），

		注：分布式缓存的实现又涉及到对象序列化的问题，

	根据上面的描述，重构优化的一个分支：
		系统统一缓存的设计（接口设计（考虑扩展性，维护性），
							部署结构与HA设计（与下面的HA有关系，分布式部署保证HA，采用一致性哈希，缓存热点问题），
							序列化性能考虑，
							网络稳定考虑，
							内部具体各种缓存接口与统一缓存接口的交互及设计）


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day283 Thursday, May 09, 2013

1. 
	* 

2. 大region二期周会


3. 

4. 获取java运行的版本，采取不同的逻辑，比如高版本才支持的功能的使用
	org.springframework.core.JdkVersion
	-------
		static {
			javaVersion = System.getProperty("java.version");
			// version String should look like "1.4.2_10"
			if (javaVersion.indexOf("1.7.") != -1) {
				majorJavaVersion = JAVA_17;
			}
			else if (javaVersion.indexOf("1.6.") != -1) {
				majorJavaVersion = JAVA_16;
			}
			else if (javaVersion.indexOf("1.5.") != -1) {
				majorJavaVersion = JAVA_15;
			}
			else {
				// else leave 1.4 as default (it's either 1.4 or unknown)
				majorJavaVersion = JAVA_14;
			}
		}
	-------
		

5. mapreduce，hbase（hadoop，zookeeper）
	zookeeper与paxos


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day284 Friday, May 10, 2013

1. 
	* 大region二期

2. 大region二期
	代码合trunk

3. 

4. ReentrantLock的底层实现 java concurrent
	公平锁
	非公平锁
	lock时
		若取不到锁线程不参加cpu调度，并等待

	ReentrantLock类lock的实现委托给了Sync抽象类的子类，Sync子类有FairSync、NonfairSync即公平锁和不公平锁

	* 公平锁和非公平锁
		如果获取一个锁是按照请求的顺序得到的，那么就是公平锁，否则就是非公平锁。
		
		这两种锁出现的原因：
				在没有深入了解内部机制及实现之前，先了解下为什么会存在公平锁和非公平锁。公平锁保证一个阻塞的线程最终能够获得锁，因为是有序的，
			所以总是可以按照请求的顺序获得锁。不公平锁意味着后请求锁的线程可能在其前面排列的休眠线程恢复前拿到锁，这样就有可能提高并发的性能。
			这是因为通常情况下挂起的线程重新开始与它真正开始运行，二者之间会产生严重的延时。因此非公平锁就可以利用这段时间完成操作。这是非公平锁
			在某些时候比公平锁性能要好的原因之一。
		
		前面说过java.util.concurrent.locks.AbstractQueuedSynchronizer （AQS)是Lock的基础，对于一个FairSync而言，lock()就直接调用AQS的acquire(int arg);

		AQS DOC说明：抽象队列同步器
			java.util.concurrent.locks.AbstractQueuedSynchronizer
			---------
			Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues. This class is designed to be a useful basis for most kinds 
			of synchronizers that rely on a single atomic int value to represent state. Subclasses must define the protected methods that change this state, and which define what that state means in terms of this object being 
			acquired or released. Given these, the other methods in this class carry out all queuing and blocking mechanics. Subclasses can maintain other state fields, but only the atomically updated int value manipulated using 
			methods getState, setState and compareAndSetState is tracked with respect to synchronization. 

			Subclasses should be defined as non-public internal helper classes that are used to implement the synchronization properties of their enclosing class. Class AbstractQueuedSynchronizer does not implement any 
			synchronization interface. Instead it defines methods such as acquireInterruptibly that can be invoked as appropriate by concrete locks and related synchronizers to implement their public methods. 

			This class supports either or both a default exclusive mode and a shared mode. When acquired in exclusive mode, attempted acquires by other threads cannot succeed. Shared mode acquires by multiple threads 
			may (but need not) succeed. This class does not "understand" these differences except in the mechanical sense that when a shared mode acquire succeeds, the next waiting thread (if one exists) must also determine 
			whether it can acquire as well. Threads waiting in the different modes share the same FIFO queue. Usually, implementation subclasses support only one of these modes, but both can come into play for example in a 
			ReadWriteLock. Subclasses that support only exclusive or only shared modes need not define the methods supporting the unused mode. 

			This class defines a nested ConditionObject class that can be used as a Condition implementation by subclasses supporting exclusive mode for which method isHeldExclusively reports whether synchronization is 
			exclusively held with respect to the current thread, method release invoked with the current getState value fully releases this object, and acquire, given this saved state value, eventually restores this object to its 
			previous acquired state. No AbstractQueuedSynchronizer method otherwise creates such a condition, so if this constraint cannot be met, do not use it. The behavior of ConditionObject depends of course on the 
			semantics of its synchronizer implementation. 

			This class provides inspection, instrumentation, and monitoring methods for the internal queue, as well as similar methods for condition objects. These can be exported as desired into classes using an 
			AbstractQueuedSynchronizer for their synchronization mechanics. 

			Serialization of this class stores only the underlying atomic integer maintaining state, so deserialized objects have empty thread queues. Typical subclasses requiring serializability will define a readObject method that 
			restores this to a known initial state upon deserialization. 

			Usage
			To use this class as the basis of a synchronizer, redefine the following methods, as applicable, by inspecting and/or modifying the synchronization state using getState, setState and/or compareAndSetState: 

			tryAcquire 
			tryRelease 
			tryAcquireShared 
			tryReleaseShared 
			isHeldExclusively 
			Each of these methods by default throws UnsupportedOperationException. Implementations of these methods must be internally thread-safe, and should in general be short and not block. Defining these methods is 
			the only supported means of using this class. All other methods are declared final because they cannot be independently varied. 
			You may also find the inherited methods from AbstractOwnableSynchronizer useful to keep track of the thread owning an exclusive synchronizer. You are encouraged to use them -- this enables monitoring and 
			diagnostic tools to assist users in determining which threads hold locks. 

			Even though this class is based on an internal FIFO queue, it does not automatically enforce FIFO acquisition policies. The core of exclusive synchronization takes the form: 

			 Acquire:
			     while (!tryAcquire(arg)) {
				enqueue thread if it is not already queued;
				possibly block current thread;
			     }

			 Release:
			     if (tryRelease(arg))
				unblock the first queued thread;
			 
			(Shared mode is similar but may involve cascading signals.) 
			Because checks in acquire are invoked before enqueuing, a newly acquiring thread may barge ahead of others that are blocked and queued. However, you can, if desired, define tryAcquire and/or tryAcquireShared to disable barging by internally invoking one or more of the inspection methods. In particular, a strict FIFO lock can define tryAcquire to immediately return false if getFirstQueuedThread does not 
			return the current thread. A normally preferable non-strict fair version can immediately return false only if hasQueuedThreads returns true and getFirstQueuedThread is not the current thread; or equivalently, that 
			getFirstQueuedThread is both non-null and not the current thread. Further variations are possible. 

			Throughput and scalability are generally highest for the default barging (also known as greedy, renouncement, and convoy-avoidance) strategy. While this is not guaranteed to be fair or starvation-free, earlier queued 
			threads are allowed to recontend before later queued threads, and each recontention has an unbiased chance to succeed against incoming threads. Also, while acquires do not "spin" in the usual sense, they may 
			perform multiple invocations of tryAcquire interspersed with other computations before blocking. This gives most of the benefits of spins when exclusive synchronization is only briefly held, without most of the 
			liabilities when it isn't. If so desired, you can augment this by preceding calls to acquire methods with "fast-path" checks, possibly prechecking hasContended and/or hasQueuedThreads to only do so if the 
			synchronizer is likely not to be contended. 

			This class provides an efficient and scalable basis for synchronization in part by specializing its range of use to synchronizers that can rely on int state, acquire, and release parameters, and an internal FIFO wait 
			queue. When this does not suffice, you can build synchronizers from a lower level using atomic classes, your own custom java.util.Queue classes, and LockSupport blocking support. 

			Usage Examples
			Here is a non-reentrant mutual exclusion lock class that uses the value zero to represent the unlocked state, and one to represent the locked state. While a non-reentrant lock does not strictly require recording of the 
			current owner thread, this class does so anyway to make usage easier to monitor. It also supports conditions and exposes one of the instrumentation methods: 

			 class Mutex implements Lock, java.io.Serializable {

			   // Our internal helper class
			   private static class Sync extends AbstractQueuedSynchronizer {
			     // Report whether in locked state
			     protected boolean isHeldExclusively() {
			       return getState() == 1;
			     }

			     // Acquire the lock if state is zero
			     public boolean tryAcquire(int acquires) {
			       assert acquires == 1; // Otherwise unused
			       if (compareAndSetState(0, 1)) {
				 setExclusiveOwnerThread(Thread.currentThread());
				 return true;
			       }
			       return false;
			     }

			     // Release the lock by setting state to zero
			     protected boolean tryRelease(int releases) {
			       assert releases == 1; // Otherwise unused
			       if (getState() == 0) throw new IllegalMonitorStateException();
			       setExclusiveOwnerThread(null);
			       setState(0);
			       return true;
			     }

			     // Provide a Condition
			     Condition newCondition() { return new ConditionObject(); }

			     // Deserialize properly
			     private void readObject(ObjectInputStream s)
				 throws IOException, ClassNotFoundException {
			       s.defaultReadObject();
			       setState(0); // reset to unlocked state
			     }
			   }

			   // The sync object does all the hard work. We just forward to it.
			   private final Sync sync = new Sync();

			   public void lock()                { sync.acquire(1); }
			   public boolean tryLock()          { return sync.tryAcquire(1); }
			   public void unlock()              { sync.release(1); }
			   public Condition newCondition()   { return sync.newCondition(); }
			   public boolean isLocked()         { return sync.isHeldExclusively(); }
			   public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); }
			   public void lockInterruptibly() throws InterruptedException {
			     sync.acquireInterruptibly(1);
			   }
			   public boolean tryLock(long timeout, TimeUnit unit)
			       throws InterruptedException {
			     return sync.tryAcquireNanos(1, unit.toNanos(timeout));
			   }
			 }
			 
			Here is a latch class that is like a CountDownLatch except that it only requires a single signal to fire. Because a latch is non-exclusive, it uses the shared acquire and release methods. 

			 class BooleanLatch {

			   private static class Sync extends AbstractQueuedSynchronizer {
			     boolean isSignalled() { return getState() != 0; }

			     protected int tryAcquireShared(int ignore) {
			       return isSignalled()? 1 : -1;
			     }

			     protected boolean tryReleaseShared(int ignore) {
			       setState(1);
			       return true;
			     }
			   }

			   private final Sync sync = new Sync();
			   public boolean isSignalled() { return sync.isSignalled(); }
			   public void signal()         { sync.releaseShared(1); }
			   public void await() throws InterruptedException {
			     sync.acquireSharedInterruptibly(1);
			   }
			 }
			 
			Since:
			1.5
			--------
			PS:
				 java concurrnt包提供Semaphore的实现java.util.concurrent.Semaphore。A counting semaphore. Conceptually, a semaphore maintains a set of permits. 区别于单个锁
				 一般用于只允许一定数目线程的去访问资源（物理或逻辑）的场景，比如用于对象池的控制 。下面是一个使用Semaphore的例子，摘自其DOC:
				 -------
				class Pool {
				   private static final int MAX_AVAILABLE = 100;
				   private final Semaphore available = new Semaphore(MAX_AVAILABLE, true);

				   public Object getItem() throws InterruptedException {
				     available.acquire();
				     return getNextAvailableItem();
				   }

				   public void putItem(Object x) {
				     if (markAsUnused(x))
				       available.release();
				   }

				   // Not a particularly efficient data structure; just for demo

				   protected Object[] items = ... whatever kinds of items being managed
				   protected boolean[] used = new boolean[MAX_AVAILABLE];

				   protected synchronized Object getNextAvailableItem() {
				     for (int i = 0; i < MAX_AVAILABLE; ++i) {
				       if (!used[i]) {
					  used[i] = true;
					  return items[i];
				       }
				     }
				     return null; // not reached
				   }

				   protected synchronized boolean markAsUnused(Object item) {
				     for (int i = 0; i < MAX_AVAILABLE; ++i) {
				       if (item == items[i]) {
					  if (used[i]) {
					    used[i] = false;
					    return true;
					  } else
					    return false;
				       }
				     }
				     return false;
				   }

				 }
				 -------
				 PS: 先Semaphore.acquire()拿到锁，然后调用同步方法（有多个线程并发操作）getNextAvailableItem()方法以获取资源。-tip-

		from: http://www.blogjava.net/xylz/archive/2010/07/07/325410.html
	
6. 并行开发 ，svn，多个branch并行开发
	对于公用部分的修改，必须加注释，以便与与其他分支合并代码时解决冲突

7. org.springframework.web.filter.CharacterEncodingFilter
	设置request和response的http编码头
	-----
	if (this.encoding != null && (this.forceEncoding || request.getCharacterEncoding() == null)) {
		request.setCharacterEncoding(this.encoding);
		if (this.forceEncoding) {
			response.setCharacterEncoding(this.encoding);
		}
	}
	-----

	-----
	<filter>
		<filter-name>encodingFilter</filter-name>
		<filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>
		<init-param>
			<param-name>encoding</param-name>
			<param-value>GBK</param-value>
		</init-param>
	</filter>
	-----

8. grep
	匹配项前几行，后几行
	jstack 18600 | grep RUNNABLE -B3 -A10


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day285 Monday, May 13, 2013

1. 
	* 大region二期
2. 大region二期
	- 连调测试
		imageNo： rhel5u7_64_20G_alibase_v01.vhd
		create_vm
		start_vm 
			running
	- 

	8.212搭建api环境
	jetty-env: 
		cd /home/admin/houyi
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/console/jetty-env/houyi/ .
		mkdir src
		vim build.sh
	java env
	maven env
		add mvn to $PATH
			vim ~/.bash_profile
			export PATH=/xxx/bin:$PATH
			source ~/.bash_profile
		chmod +x mvn






4. JVM Speci	jvm规范阅读	* jvm spec
Chapter 2. The Structure of the Java Virtual Machine
	2.1 The class File Format
	2.2 Data Types
		Like the Java programming language, the Java Virtual Machine operates on two kinds of types: primitive types and reference types. There are, correspondingly, two kinds of values 
		that can be stored in variables, passed as arguments, returned by methods, and operated upon: primitive values and reference values.
	2.3 Primitive Types and Values
	2.4 Reference Types and Values
		There are three kinds of reference types: class types, array types, and interface types. Their values are references to dynamically created class instances, arrays, or class instances or 
		arrays that implement interfaces, respectively.
	2.5 Run-Time Data Areas
		The Java Virtual Machine defines various run-time data areas that are used during execution of a program. Some of these data areas are created on Java Virtual Machine start-up and 
		are destroyed only when the Java Virtual Machine exits. Other data areas are per thread. Per-thread data areas are created when a thread is created and destroyed when the thread exits.
		2.5.1 The pc Register
			The Java Virtual Machine can support many threads of execution at once (JLS §17). Each Java Virtual Machine thread has its own pc (program counter) register. At any point, 
			each Java Virtual Machine thread is executing the code of a single method, namely the current method (§2.6) for that thread. If that method is not native, the pc register contains the 
			address of the Java Virtual Machine instruction currently being executed. If the method currently being executed by the thread is native, the value of the Java Virtual Machine's pc register 
			is undefined. The Java Virtual Machine's pc register is wide enough to hold a returnAddress or a native pointer on the specific platform.
		2.5.2. Java Virtual Machine Stacks
			Each Java Virtual Machine thread has a private Java Virtual Machine stack, created at the same time as the thread. A Java Virtual Machine stack stores frames (§2.6). A Java Virtual 
			Machine stack is analogous to the stack of a conventional language such as C: it holds local variables and partial results, and plays a part in method invocation and return. Because the 
			Java Virtual Machine stack is never manipulated directly except to push and pop frames, frames may be heap allocated. The memory for a Java Virtual Machine stack does not need to
			be contiguous.

			线程栈大小的可配置
			A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of Java Virtual Machine stacks, as well as, in the case of dynamically expanding 
			or contracting Java Virtual Machine stacks, control over the maximum and minimum sizes.

			The following exceptional conditions are associated with Java Virtual Machine stacks:
				If the computation in a thread requires a larger Java Virtual Machine stack than is permitted, the Java Virtual Machine throws a StackOverflowError.

				If Java Virtual Machine stacks can be dynamically expanded, and expansion is attempted but insufficient memory can be made available to effect the expansion, or if insufficient memory can be 
				made available to create the initial Java Virtual Machine stack for a new thread, the Java Virtual Machine throws an OutOfMemoryError.

		2.5.3. Heap
			The Java Virtual Machine has a heap that is shared among all Java Virtual Machine threads. The heap is the run-time data area from which memory for all class instances and arrays is allocated.

			The heap is created on virtual machine start-up. Heap storage for objects is reclaimed by an automatic storage management system (known as a garbage collector); objects are never explicitly 
			deallocated. The Java Virtual Machine assumes no particular type of automatic storage management system, and the storage management technique may be chosen according to the implementor's
			system requirements. The heap may be of a fixed size or may be expanded as required by the computation and may be contracted if a larger heap becomes unnecessary. The memory for the heap 
			does not need to be contiguous.

			A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the heap, as well as, if the heap can be dynamically expanded or contracted, control 
			over the maximum and minimum heap size.

			The following exceptional condition is associated with the heap:
				If a computation requires more heap than can be made available by the automatic storage management system, the Java Virtual Machine throws an OutOfMemoryError.

		2.5.4. Method Area
			The Java Virtual Machine has a method area that is shared among all Java Virtual Machine threads. The method area is analogous to the storage area for compiled code of a conventional 
			language or analogous to the "text" segment in an operating system process. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and 
			constructors, including the special methods (§2.9) used in class and instance initialization and interface initialization.

			The method area is created on virtual machine start-up. Although the method area is logically part of the heap(逻辑上属于heap), simple implementations may choose not to either garbage collect 
			or compact it. This version of the Java Virtual Machine specification does not mandate the location of the method area or the policies used to manage compiled code. The method area may be of a fixed size 
			or may be expanded as required by the computation and may be contracted if a larger method area becomes unnecessary. The memory for the method area does not need to be contiguous.

			A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the method area, as well as, in the case of a varying-size method area, control over 
			the maximum and minimum method area size.

			The following exceptional condition is associated with the method area:
				If memory in the method area cannot be made available to satisfy an allocation request, the Java Virtual Machine throws an OutOfMemoryError.

		2.5.5. Run-Time Constant Pool
			A run-time constant pool is a per-class or per-interface run-time representation of the constant_pool table in a class file (§4.4). It contains several kinds of constants, ranging from numeric 
			literals known at compile-time to method and field references that must be resolved at run-time. The run-time constant pool serves a function similar to that of a symbol table for a conventional 
			programming language, although it contains a wider range of data than a typical symbol table.

			Each run-time constant pool is allocated from the Java Virtual Machine's method area (§2.5.4). The run-time constant pool for a class or interface is constructed when the class or interface is 
			created (§5.3) by the Java Virtual Machine.

		2.5.6. Native Method Stacks
			An implementation of the Java Virtual Machine may use conventional stacks, colloquially called "C stacks," to support native methods (methods written in a language other than the Java 
			programming language). Native method stacks may also be used by the implementation of an interpreter for the Java Virtual Machine's instruction set in a language such as C. Java Virtual Machine 
			implementations that cannot load native methods and that do not themselves rely on conventional stacks need not supply native method stacks. If supplied, native method stacks are typically 
			allocated per thread when each thread is created.

			This specification permits native method stacks either to be of a fixed size or to dynamically expand and contract as required by the computation. If the native method stacks are of a fixed size, 
			the size of each native method stack may be chosen independently when that stack is created.

			A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the native method stacks, as well as, in the case of varying-size native method stacks, 
			control over the maximum and minimum method stack sizes.

		more...

	ref: http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-2.html

5. OOB（Out of Band Management System）带外管理系统
	
6. 定位工作目录
	cd `dirname $0`/..	CD到执行文件所在目录的上级目录
	BASE_HOME=`pwd`	取到目录路径

7.java序列化
	memcached java客户端对set进去的对象的序列化 * memcached client分析
	它提供了NativeHandler类来优化一些标准java类型的编码以提升性能：Handle encoding standard Java types directly which can result in significant memory savings: 

	比如对于boolean类型，client存储时先判断是否为标准且支持本地优化的类型，如果是，则以byte[]的方式存入远程memcached服务器中，get时，也是读取byte[]
	来判断，并在client端构造对象返回，从而省去了双向序列化的消耗。

	public class ObjectInputStream extends InputStream implements ObjectInput, ObjectStreamConstants
		ObjectInputStream首先是一个流对象，继承了InputStream；然后具有ObjectInput功能；实现ObjectStreamConstants接口以使用对象序列化过程中要用到的常量。
	ObjectInput接口继承自DataInput接口，扩展了对象input的支持（比如对象，数组，和字符串）：
		DataInput includes methods for the input of primitive types, ObjectInput extends that interface to include objects, arrays, and Strings.
	

	
8. StringBuilder，StringBuffer相对String，在大量字符串拼接时的优势在哪里？
	String是不可变对象，每次修改都会产生新的字符串对象，GC回收压力大；
	StringBuilder，StringBuffer在字符串拼接时，不会产生新的字符串，而是在申请的缓存区域存入了字符串的byte[]数据，以细粒度的方式存储最新的字符串的byte[]数组
	表示

9. 不只是为求一份工作而读书

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day286 Tuesday, May 14, 2013

1. 
	* 大region二期

2. 大region二期
	连调
	add_disk
	create_snapshot
		data disk
		system disk
	create_image
	基于自定义image，create_vm
	start_vm






4.  in two's complement binary form.
	二进制格式

5. memcached java client * memcached client
	cient在调用set存入integer类型对象时，不是直接将其byte[]存入memcached中，而是做了转换：
	-----
	protected static byte[] getBytes( int value ) {
			byte[] b = new byte[4];
			b[0] = (byte)((value >> 24) & 0xFF);
			b[1] = (byte)((value >> 16) & 0xFF);
			b[2] = (byte)((value >> 8) & 0xFF);
			b[3] = (byte)((value >> 0) & 0xFF);
			return b;
	}
	-----
	后续将此byte[]存入服务器中,写入时，分两行一行为命令、超时，key等消息，换行行写入value消息，都以byte[]方式写入流中，flush输出流后，开始
	阻塞读取socket的输入流。
	-----
	//存入了value的长度，以便于读取时根据长度取到value的byte[]，/r/n可能会在value中出现，故不能作为分隔符
	String cmd = String.format( "%s %s %d %d %d\r\n", cmdname, key, flags, (expiry.getTime() / 1000), val.length );
	sock.write( cmd.getBytes() );
	sock.write( val );
	sock.write( "\r\n".getBytes() );
	sock.flush();
	-----

	支持数据压缩：
		java.util.zip.GZIPOutputStream通过这个过滤器流对数据压缩后写入，装饰器模式（过滤器模式），装饰DeflaterOutputStream类，
			在java.util.zip.*包下，包含与压缩相关的api
				
				CRC-32	循环冗余校验：通过CRC32类，在写入结束时将校验码写在尾部，校验码在初始化时为0，每写入一次生成一个int类型的校验码并作为下次计算的
				基础，将最后一个数据byte[]的校验码放到输出流尾部；通过查看其解压的逻辑，如何去校验数据的准确性，在读入输入流的最后时校验尾部的校验码与当前
				读取生成的码是否一致：
					------
					// Uses left-to-right evaluation order
						if ((readUInt(in) != crc.getValue()) ||
						    // rfc1952; ISIZE is the input size modulo 2^32
						    (readUInt(in) != (inf.getBytesWritten() & 0xffffffffL)))
						    throw new IOException("Corrupt GZIP trailer");
					    }
					------
				PS: 作为使用者，只要使用JDK提供的GZIPOutputStream、GZIPInputStream即可，它内部来保证数据的正确性。

				java.util.zip.CRC32
				A class that can be used to compute the CRC-32 of a data stream.

				java.util.zip.Deflater
				-------
				This class provides support for general purpose compression using the popular ZLIB compression library. The ZLIB compression library was initially developed as part of 
				the PNG graphics standard and is not protected by patents. It is fully described in the specifications at the java.util.zip package description. 

				The following code fragment demonstrates a trivial compression and decompression of a string using Deflater and Inflater. 

				 try {
				     // Encode a String into bytes
				     String inputString = "blahblahblah\u20AC\u20AC";
				     byte[] input = inputString.getBytes("UTF-8");

				     // Compress the bytes
				     byte[] output = new byte[100];
				     Deflater compresser = new Deflater();
				     compresser.setInput(input);
				     compresser.finish();
				     int compressedDataLength = compresser.deflate(output);

				     // Decompress the bytes
				     Inflater decompresser = new Inflater();
				     decompresser.setInput(output, 0, compressedDataLength);
				     byte[] result = new byte[100];
				     int resultLength = decompresser.inflate(result);
				     decompresser.end();

				     // Decode the bytes into a String
				     String outputString = new String(result, 0, resultLength, "UTF-8");
				 } catch(java.io.UnsupportedEncodingException ex) {
				     // handle
				 } catch (java.util.zip.DataFormatException ex) {
				     // handle
				 }
				-------

6. OCM UMM 业务
	OSS Control Module（简称 OCM）为 OSS 上层的应用提供控制 OSS 的接口，
	同时方便 PE、运营同学查询、调节 OSS 参数使用。OCM 继续遵循 OSS 的 REST 接口风格，所有请求被抽象成四类请求：PUT，GET，HEAD 和 DELETE。O

	用户管理组件（User Management Module, UMM）负责管理飞天对外服务1的所有用户以及用户的 Access ID/Key。本文档是用户管理组件的设计、开发指南。
	描述了用户管理模块中的基本概念、提供的服务以及可用的 API。



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day287 Wednesday, May 15, 2013

1. 
	* 大regino二期

2. 大regino二期
	脚本review


4. BufferedOutputStream
	byte[] buffered

	设计模式：BufferedOutputStream也是继承自 FilterInputStream ，此类使用装饰器模式(或叫做过滤器模式)，内部操作的是其他inputsteam，作为一个装饰器模式
	中的一个抽象装饰类，看它的说明：
		A FilterInputStream contains some other input stream, which it uses as its basic source of data, possibly transforming the data along the way or providing additional functionality. 

	比如DataInputStream也是继承自FilterInputStream。

	A BufferedInputStream adds functionality to another input stream-namely, the ability to buffer the input and to support the mark and reset methods. 
	BufferedOutputStream在原inputsteam的基础上，提供了buffer输入流以及mark和reset输入流的方法
	
	下面是缓存数组的声明，是volatile类型的(在进入同步块前及出同步块后，都需要将变化更新回主存)：
		protected volatile byte buf[];
	看BufferedOutputStream提供的2个操作此byte的方法的定义：
		 public synchronized int read() throws IOException
		 public synchronized int read(byte b[], int off, int len) throws IOException
	都为synchronized方法，存在并行操作byte缓存的可能，故对此变量声明为volatile类型，所有线程都从主存中读取和操作，不做线程的私有拷贝。
		
5. design patten	 命令模式 从JDK中看设计模式的应用
	Command Patten
	命令和命令的执行者，通过抽象类过接口解耦和，命令只要关注业务并返回结果，不关心执行；执行者只关心执行，不关心命令的实现；

	eg:
		 java.util.concurrent.ScheduledExecutorService
		 以submit方法来执行所有Runnable的实现类，这些被执行的对象都有一个run方法，都返回结果或没有结果。
	
	houyi api的aps2类就是命令模式中的接受者，负责接收并执行命令；那些command及其实现为命令接口和命令实现；Service层为请求者将命令交给接受者。

	JDK中设计模式的应用：
		
6. java.lang.Thread.State 线程状态及其转换
	


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day288 Thursday, May 16, 2013

1. 
	* 新项目
		锻炼+业务
	* 大region二期
		发布演练

2. 新项目
	需求整理，明天kickoff
	需求若涉及控制系统修改则去掉（避免与大region二期冲突），只做与api和api task相关的需求
	本项目在大region 二期生产环境发布API成功后发布

	image的大小，开始由PE上传时，插入db；后续根据此image创建的vm打的系统盘快照创建的自定义image的大小也取自原image大小。（
	打的快照为系统盘全量快照，即盘快照，包含了数据和空闲空间大小的总和）
	
	问题：
	1）create_image中参数image_no限制特殊字符的输入    ：细化规则
		待PD确认

	2）-99返回码整合到-95

	3）API 接口增加一个token 字段，在校验时不对这个参数校验（该参数用来查询一个请求在系统中的处理流程，预计未来在API Proxy中生成这个token，本期只是在API端先进行处理）
		token生成：token会传给api（可能由api proxy生成）
		token目的：标识一个请求的处理流程（从api到控制系统，本项目只需支持api可接受token参数即可）
		token具体设计：api接受token，api做签名验证时，去掉token参数后再校验签名，即token对用户透明（后续可以将token放入ThreadLocal中）
	4）Houyi Task需求中imageSize大小的精确度，老image实际大小与db记录大小不一致问题，由PD确认用户是否认可

	5）query_available_imgs增加区分系统镜像和用户自定义镜像的返回值
		API是否能区分系统镜像和用户自定义镜像？
		src_image_id标识当前Image是Image同步工具同步过来并插入的，还是用户自定义创建的，若为0则为新创建的，若不为0则为从image_id=src_image_id所指向的Image同步过来的。

		PE建议通过user_id=0来区分PE上传的Image和用户自定义Image。
	
	kick off会议5.17 14:00-15:00 道格拉斯



3. 每套API自身的角色范围域
	API每套都是对等的，API自身并不知道其应该转发的域（比如DG的API应该只将请求发送到DG的集群，如果请求是其他集群的，报错也不合适。因为对外
	API就是一个统一的服务，用户并不知道API的多套部署，用户只有一个入口；必须通过一个转发层将请求转发到正确的API上，来实现各套API分辖各自Master
	的目的）

	后面Master重构为region master，由region master直接管理nc，此时每个region master应该管辖那些nc的列表应该是确定的（？），region master可以水平扩展。


4. 线程状态以及转换
	Object对象的wait,notify,notifyall方法
		取得对象锁后才能操作
	Thread类的sleep，yield，join


5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day289 Friday, May 17, 2013

1. 
	* 大region二期
	* 合唱团项目
2. 大region二期
	bugfix
	ApsaraCommandExecutor2类抛出的CLCSuspendedException异常被部分service捕获，且没有继续抛出，导致AbstractExecuteAction类无法捕获此错误，也就无法
	将-100, "houyi System is maintaining"抛出。

	解决：
		排查代码中ApsaraCommandExecutor2类返回到AbstractExecuteAction类的过程中，拦截了并消化了CLCSuspendedException异常的点，修改为继续抛出CLCSuspendedException
		异常。
		-----
		catch (CLCSuspendedException e) {
			logger.info(e.getMessage());
			throw e;
		}
		-----

		修改点：      从apsa2的execute方法反查，并结合全局搜索service层捕获Exception和Throwable的地方
			InstanceServiceHelper
				98
			InstanceServiceImpl
				1297
				249
			IpAddressServiceImpl
				257
				280
				498
				521
				581
				695
				767
			CommandExecutorServiceImpl
				21
				38
			GroupServiceImpl
				251
		
		演练：
		发布步骤修改：
			版本修改
			关闭region的脚本，替换为支持检查是否为masterRegion的脚本
				http://svn.alisoft-inc.com/repos/alisoft/houyi/deploy/houyi_api/20130228trailbreaker
				此版本用的mysql账号是读写账号，用db.Houyi()拿到的是只读账号，需要如此定义：db.Houyi(read_only=False)
		API提供版本信息，每次发布好后，QA等人员可以判断部署的版本。
			
3. 合唱团项目
	kickoff
	部分需求再明确
		过滤接口参考aws？

	AOne中细分任务和开发人

	设计文档编写
		确认需求
		设计
		
		开发
4. design patten
	命令模式
		封装方法调用，

		应用场景：如log，undo操作等




+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day290 Monday, May 20, 2013

1. 
	* 大region二期

2. 大region二期
	group相关接口：join_group,leave_group等在某个Master为维护状态时，命令仍需要执行，不应该抛错，而是通过补偿来保证一致。

	这样从API接口操作与所作用的集群个数上看，调用目标为某个region的接口，如果此region在维护应该返回维护中错误；但对于作用于
	多个region的接口并提供了region不可用的补偿机制时，即使某个region不可用，其他region可用时，此接口还是应该返回200成功。
	否则，想create_vm接口，在执行join_group时会应该某个region状态不可用导致接口调用失败。

3. API create_vm并加入group流程
	调用master创建vm成功后，执行加入group操作，若加入group出错则回滚创建vm操作，下面具体说明加入group过程：
		1）查询指定的group信息（DB）
		2）取到group和instance的分布式锁（DB实现）
		3）先后嵌套同步group和instance锁，执行加入group操作
		4）取本地执行锁
		5）检查group信息（与user所属，上限等）
		6）执行加入操作
		7）根据group，instance生成加入group的消息MsgId
		8）拿到master region，生成调用命令（包含MsgId）并调用Master
		9）返回Master执行加入组命令的结果（Master region）
		10）如果命令执行成功，则API加instance加入组的信息持久化到DB中；若失败则向上返回错误结果，并回滚创建vm的操作
		11）instance加入组成功并加信息成功持久化后，执行下发防火墙命令（MsgId,groupId,instanceNo）
		12）遍历大region下所有下region，下发防火墙命令，失败不会滚，向上只返回成功
	
	destroy_vm离开所有组时，要保证master region可用，否则在leave all group时会失败，返回-95

	QueryGroupVmInfoExecuteAction DB操作，底层未抛出-100 
	ModifyVmHostNameAction DB操作，底层未抛出-100 
	FlushControlIpChainExecuteAction 底层未抛出-100
	TouchMasterExecuteAction 底层未抛出-100
	QueryRegionMasterExecuteAction DB操作，底层未抛出-100 
	SetMasterRegionExecuteAction DB操作，底层未抛出-100 
	SetRegionMasterExecuteAction DB操作，底层未抛出-100 
	AdjustGroupExecuteAction 底层未抛出-100，未转换，service在AdjustGroupAuthComand命令部分需要转换为-100结果返回给action
	AuthorizeGroupExecuteAction 老的方式抛出CLCSuspendedException异常，无需在action处理转换
	RevokeGroupExecuteAction 老的方式抛出CLCSuspendedException异常，无需在action处理转换

	补充：
		VmCreateExecuteAction 转换-100


	加入组，修改组授权等调用master region一次，成功后，在分别在每个小region上调用下发相关防火墙命令（允许失败）。

	某些接口，会多次调用控制系统，其中有些命令允许失败，此时就不应该返回-100，而是应该继续操作，这点要注意！

	小节：
		一个修改点，一个修改方案，影响到的点需要考虑全面。
	
	代码回滚到merge到trunk时状态，qa资源不够，本次bug只影响用户体验，放到下期项目修复。

	
	 
4. 提测地址
	http://10.250.4.42/form/
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day300 Tuesday, May 21, 2013

1. 
	* 大region二期
	* 合唱团项目

2. 大region二期
	双开发布
		api包内带版本信息，以便于解压后也方便确认版本。

3. 合唱团项目
	设计文档，根据需求整理设计文档
	imageNo命名规则，create_image中参数image_no限制特殊字符的输入，只允许：字母（包含大小写）、数字以及如下符号("-"、"_"、".")，长度限制在1～100字符，首字符只能为字母,
	正则：^[a-zA-Z][0-9a-zA-Z.\-_]{0,99}
	((?![.]{2})[\w!.])* 不包含连续2个.符号


4. java服务器端编程实践
	Nio
		EpollSelector
	concurrent包
		线程池
			阻塞任务的重新调度，如磁盘IO，网络IO等block状态时，从执行池中拿出，等待异步通知后继续执行
		调度
			链表阻塞队列
				队列长度
		工作线程
		连接线程
	
	高并发

	参考：IM开源项目，比如openfire spark


5. 二次开发 -idea-
	openfire?
	or more.

	基于nio框架开发？
	mina
	netty


6. memcached java client
	

7.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day301 Wednesday, May 22, 2013

1. 
	* 合唱团项目

2. 合唱团项目
	设计文档


4.缓存系统
	memcached - ibatis缓存实现采用memcached - redis缓存系统 - tair一个分布式kv系统，抽象了缓存api（底层支持多种kv引擎，如memcached，redis等）

	缓存减轻DB压力，提高请求响应

5. ArrayList与LinkedList
	LinkedList采用双向链表实现，查找对象时，需要遍历链表
	ArrayList采用数组实现，查找对象时，可以采用二分查找等查找算法，根据下标访问对象，效率较高

6. netty socket编程
	socket编程
	并发
	IO/NIO
	调度

	* netty
		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day302 Thursday, May 23, 2013

1. 
	*  
2. 

4. hibernate+memcached
	mybatis+memcached
	* mybatis
		插件
			memcached作为二级缓存的插件
			分库分表插件

5. 分库发表
	
6. ibatis cache ibatis缓存部分 与hibernate比较
	参考ibatis资料

	ibatis只提供了二级缓存，即查询缓存；hibernate提供了一级缓存，即session缓存，session关联了本次请求所有涉及到的持久化对象，

	分布式缓存，同步更新问题，参考下面一篇介绍chubby的文章，看它是如何设计主从功能以及实现分布式缓存更新问题的：

	-----
		为 了安全性和容错的考虑，所有的replicas（包括master）都维护的同一个DB的拷贝。但是，只有master能够接受client提交的操作对 DB进行读和写，
		而其它的replicas只是和master进行通信来update它们各自的DB。所以，一旦一个master被选举出来后，所有的 client端都之和master进行通信（如图所示），
		如果是读操作，那么master一台机器就搞定了，如果是写操作，master会通知其它的 replicas进行update。这样的话，一旦master意外停机，那么其它的replicas
		也能够很快的选举出另外一个master。
		....
		最后谈谈client与cell的交互部分

		这里大致包含两部分的内容：cache的同步机制和KeepAlive握手协议。

			为 了降低client和cell之间通信的压力和频率，client在本地会保存一个和自己相关的Chubby文件的cache。例如如果client通过 Chubby library在cell上创建了一个文件，
		那么在client本地，也会有一个相同的文件在cache中创建，这个cache中的文件的内容和cell 上文件的内容是一样的。这样的话，client如果想访问这个文件，就可以
		直接访问本地的cache而不通过网络去访问cell。
		
			cache有两个状态，有效和无效。当 有一个client要改变某个File的时候，整个修改会被master block，然后master会发送无效标志给所有cache了这个数据的client
		（它维护了这么一个表），当其它client端收到这个无效标志 后，就会将cache中的状态置为无效，然后返回一个acknowledge；当master确定收到了所有的acknowledge
		之后，才完成整个 modification。

			需要注意的是，master并不是发送update给client而是发送无效标志给client。这是因为如果发送update给client，那么每 一次数据的修改都需要发送一大堆的update，
		而发送无效标示的话，对一个数据的很多次修改只需要发送一个无效标示，这样大大降低了通信量。
	-----
	PS:
		主从架构设计，只允许Master去修改数据（如DB），其他从节点只提供读取服务；
		对于cache更新，对cache修改会被master block住，然后master通知所有缓存了此对象的client此缓存失效。

7. 落日弓web
	熟悉一个请求的整体流程
	页面统一由extjs的js文件生成，extjs封装了各种web富客户端需要用到的组件，对外提供属性设置的方式供调用。


8. 对比memcached java client
	一致性hash算法，md5计算hash值，字节转java基本类型

	java基本数据类型和byte[] 之间的转换,java基本类型和字节的转换
	ref: http://hi.baidu.com/wangkaijiangg/item/d3d825dfd36081f492a97406

	MessageDigest返回的byte[]换行为java long类型

	 计算MD5 hash值方法：
	----
	private static long md5HashingAlg( String key ) {
			MessageDigest md5 = MD5.get();
			md5.reset();
			md5.update( key.getBytes() );
			byte[] bKey = md5.digest();
			long res = ((long)(bKey[3]&0xFF) << 24) | ((long)(bKey[2]&0xFF) << 16) | ((long)(bKey[1]&0xFF) << 8) | (long)(bKey[0]&0xFF);
			return res;
		}
	----
	PS: MD5计算结果为128bit的大整数，但是一致性hash算法需要的hash值范围为int型的最大值，即4个byte，所以对MD5的值进行移位操作，并计算得到
	整数值，做为hash值；对节点和数据都采用上面相同的hash算法。
	
	----
	/**
	 * Gets the first available key equal or above the given one, if none found,
	 * returns the first k in the bucket 
	 * @param k key
	 * @return
	 */
	private Long findPointFor( Long hv ) {
		// this works in java 6, but still want to release support for java5
		//Long k = this.consistentBuckets.ceilingKey( hv );
		//return ( k == null ) ? this.consistentBuckets.firstKey() : k;

		SortedMap<Long,String> tmap =
			this.consistentBuckets.tailMap( hv );

		return ( tmap.isEmpty() ) ? this.consistentBuckets.firstKey() : tmap.firstKey();
	}
	----
	PS: 根据hash值从TreeMap中，找到正确的bucket（此处即服务器地址host）

	初始化一致性哈希环的 com.meetup.memcached.SockIOPool.populateConsistentBuckets方法
	----
	// list of all servers
	private String[] servers;
	private Integer[] weights;
	private Integer totalWeight = 0;
	...
	private void populateConsistentBuckets() {
		if ( log.isDebugEnabled() )
			log.debug( "++++ initializing internal hashing structure for consistent hashing" );

		// store buckets in tree map，k=hashcode , v=server host
		this.consistentBuckets = new TreeMap<Long,String>();

		MessageDigest md5 = MD5.get();

		//初始化totalWeight变量，为所有server的weight值之和，若部分weight未初始化则取1
		if ( this.totalWeight <= 0 && this.weights !=  null ) {
			for ( int i = 0; i < this.weights.length; i++ )
				this.totalWeight += ( this.weights[i] == null ) ? 1 : this.weights[i];
		}
		else if ( this.weights == null ) {//若未设置server的weight配置，则totalWeight变量初始化servers数组的长度，即每个server的weight默认都为1
			this.totalWeight = this.servers.length;
		}
		
		for ( int i = 0; i < servers.length; i++ ) {
			int thisWeight = 1;
			if ( this.weights != null && this.weights[i] != null )
				thisWeight = this.weights[i];

			double factor = Math.floor( ((double)(40 * this.servers.length * thisWeight)) / (double)this.totalWeight );
			
			for ( long j = 0; j < factor; j++ ) {
				byte[] d = md5.digest( ( servers[i] + "-" + j ).getBytes() );
				for ( int h = 0 ; h < 4; h++ ) {//4个虚拟节点，解决热点问题
					Long k = 
						  ((long)(d[3+h*4]&0xFF) << 24)
						| ((long)(d[2+h*4]&0xFF) << 16)
						| ((long)(d[1+h*4]&0xFF) << 8)
						| ((long)(d[0+h*4]&0xFF));

					consistentBuckets.put( k, servers[i] );
					if ( log.isDebugEnabled() )
						log.debug( "++++ added " + servers[i] + " to server bucket" );
				}				
			}

			// create initial connections
			if ( log.isDebugEnabled() )
				log.debug( "+++ creating initial connections (" + initConn + ") for host: " + servers[i] );

			for ( int j = 0; j < initConn; j++ ) {
				SockIO socket = createSocket( servers[i] );
				if ( socket == null ) {
					log.error( "++++ failed to create connection to: " + servers[i] + " -- only " + j + " created." );
					break;
				}
				
				//上面初始化hash环，此处初始化每个server的socket池，Map<String,Map<SockIO,Long>> pool，key=server host ,value=IdentityHashMap<SockIO,Long> socketio与当前时间值
				addSocketToPool( availPool, servers[i], socket );
				if ( log.isDebugEnabled() )
					log.debug( "++++ created and added socket: " + socket.toString() + " for host " + servers[i] );
			}
		}
	}
	----
	PS: 回头看上面consistentBuckets这个treemap（其他sortedMap的实现也可）实现的hash环是如何初始化的


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day303 Friday, May 24, 2013

1. 
	* 
2. 

3. 落日弓
	落日弓wiki：http://wiki.ec.alibaba-inc.com/index.php/弹性计算与落日弓
	svn: http://svn.alisoft-inc.com/repos/alisoft/houyi/luorigong/branches/luorigong_for_bigregion
		orange框架包含在内

	Orange Python框架：wiki: http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9249291

	配置maven库以下载下面的依赖，以配置SSO登陆
	-----
	<dependency>
			<groupId>com.alibaba.platform.shared</groupId>
			<artifactId>buc.sso.client</artifactId>
			<version>0.1.20</version>  <!-- 根据下面第3点不同的web.xml配置，选择相应的版本。建议使用最新版本 -->
		</dependency>
		<dependency>
			<groupId>com.alibaba.platform.shared</groupId>
			<artifactId>buc.sso.common</artifactId>
			<version>0.1.20</version>
		</dependency>
	-----

	来自下面的库：
	-----
	<repository>
		<id>nexus</id>
		<url>http://repo.alibaba-inc.com/nexus/content/groups/alirepositiry/</url>
		<releases>
			<enabled>true</enabled>
		</releases>
		<snapshots>
			<enabled>false</enabled>
		</snapshots>
	</repository>
	-----

	mvn test
	eclipse update maven dependency 
	done
	
	看用户登陆，用户验证 ，SSO
		通过Filter拦截需要验证的请求，与SSO服务的验证中心交互，验证通过后，拿到一个标识，存入当前请求线程的ThreadLocal中


		

4. extjs * extjs
	- 官网 
		http://www.sencha.com/products/extjs/
	- 
	--------
	历史 

	最初的ExtJS只是YUI的一个扩展包，自1.1版开始独立发布。它是一个开源软件，遵守GPL 3.0协议。
	2007年12日4日推出Ext JS 2.0版.
	2009年7日6日推出Ext JS 3.0版.Ext JS 3.1 版中增加可分组的列标题。
	2010年6月, Ext JS更名为Sencha（Sencha是日本的煎茶），并且集成jQTouch和Raphal库，这是世界上第一个基于HTML5的移动应用框架，全面兼容 Android 和 Apple iOS。
	2011年4月26日, 推出Ext framework 4.0版，引入了Config和Mixins概念，另外还新增class, 开发人员可以在一个class包含另一个class.
	许可证 [编辑]

	Extjs之前使用LGPL和商业授权的双重协议，在08年时改成了现在使用的GPL和商业授权的双重协议，也遵守其他的开源软件协议。

	功能描述 

	Ext包括多种控件，可以实现各种各样的功能
	文本框和文本域控制，可以控制文本框和文本域中的内容过滤，实现所见即所得的编辑形式。
	单选框和复选框控制
	Grid control(表格控件)：可以轻松的实现表格数据统计，拖放。
	树形控制：生成树形目录，编辑管理树，点击展开或是关闭。
	Tabs：可活动的标签页，标签页组，可自由添加和删除的标签页，功能丰富。
	工具条：在面板中可以方便的插入顶部工具条或是底部工具条，实现各种复杂的功能。
	桌面应用程序菜单：可以制作类似于Windows桌面的网页菜单。
	灵活的面板布局：将一个面板划分为东南西北中(ESWNC)五个部分，每个部分可以放不同的内容。
	滚动条：用滚动条来控制数据的显示。
	Flash图表：flash制作的数据图表功能。

	优点和不足

	Ext集成了CSS样式文件，窗口、面板都有现成的样式，甚至都不需要美工进行特别的美化就可以直接使用。功能涵盖了一个Web 2.0网站所需要的几乎所有的功能，非常完备。但是相应的文件大，加载速度并不理想，而且在低版本的浏览器上显示效果不佳。
	--------
	ref: https://zh.wikipedia.org/wiki/Extjs

5. 一种检查方法入参的方式，在方法体逻辑执行前，由另一个检查方法来否则校验	-tip- check方法
	java.lang.String
	-----
	public String(byte bytes[], int offset, int length) {
		checkBounds(bytes, offset, length);
		char[] v  = StringCoding.decode(bytes, offset, length);
		this.offset = 0;
		this.count = v.length;
		this.value = v;
	}

	...
	private static void checkBounds(byte[] bytes, int offset, int length) {
		if (length < 0)
			throw new StringIndexOutOfBoundsException(length);
		if (offset < 0)
			throw new StringIndexOutOfBoundsException(offset);
		if (offset > bytes.length - length)
			throw new StringIndexOutOfBoundsException(offset + length);
	}
	-----
	PS: 来自JDK String类的构造方法

https://code.google.com/p/shardbatis/wiki/UserGuide2x

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day304 Monday, May 27, 2013

1. 
	* 落日弓web

2. 落日弓web
	熟悉
	资源文件统一管理
		mvn tomcat:run时tomcat采用源码中的webapps目录下，导致冲突

		采用外部的tomcat来部署测试（using the Tomcat Manager application.）：

		1）配置tomcat的用户（To access the Tomcat Web Application Manager, you must use a name/password with a manager role in Tomcat's tomcat-users.xml file.）
		<?xml version='1.0' encoding='utf-8'?>
		<tomcat-users>
		  <role rolename="manager"/>
		  <user username="test" password="test" roles="manager"/>
		</tomcat-users>
		2）配置maven（ settings.xml file, I need to create a server entry specifying a name for my tomcat server and the manager name and password）
		<server>
			<id>mytomcat</id>
			<username>test</username>
			<password>test</password>
		</server>
		3）配置pom.xml（added a tomcat-maven-plugin entry to the "mywebapp" project's pom.xml.）
		<plugin>
			<groupId>org.codehaus.mojo</groupId>
			<artifactId>tomcat-maven-plugin</artifactId>
			<configuration>
				<url>http://192.168.1.7:8080/manager</url>
				<server>mytomcat</server>
				<path>/mywebapp</path>
			</configuration>
		</plugin>





	编译测试

	wiki: http://wiki.ec.alibaba-inc.com/index.php/落日弓
	后端api svn: http://svn.alisoft-inc.com/repos/alisoft/houyi/luorigong/branches

	日志分级别记录

	后端api返回的json值增加字段等变化情况时，与现有前端web定义的pojo冲突报错，可采取兼容后端api字段变化，但记录log，表示有变化未处理

	后期规划：
		操作流，在现有功能基本满足情况下，设计自动化操作流，无需人工点击各个操作步骤。

3. apache http client * http client
	MultiThreadedHttpConnectionManager
		HttpConnectionManagerParams params = client.getHttpConnectionManager().getParams();
		params.setConnectionTimeout(1000 * 30);
		params.setDefaultMaxConnectionsPerHost(10240);
		params.setMaxTotalConnections(10240);
		params.setSoTimeout(1000 * 30);
		params.setTcpNoDelay(true);
	采用连接池方式，复用http连接，下面是部分复用HttpConnection对象的源码：
	1）
	-------
	httpMethod.releaseConnection();
	-------
	
	2）释放连接的输出流以重用连接
	org.apache.commons.httpclient.HttpMethodBase
	-------
	public void releaseConnection() {
		try {
		    if (this.responseStream != null) {
			try {
			    // FYI - this may indirectly invoke responseBodyConsumed.
			    this.responseStream.close();//关闭响应输入流
			} catch (IOException ignore) {
			}
		    }
		} finally {
		    ensureConnectionRelease();//确保连接对象被回收到池中
		}
	    }
	-------
	
	3）
	org.apache.commons.httpclient.HttpMethodBase
	-------
	private void ensureConnectionRelease() {
		if (responseConnection != null) {
		    responseConnection.releaseConnection();
		    responseConnection = null;//置当前方法对象对连接的引用为null，GC考虑
		}
	    }
	-------

	4）
	org.apache.commons.httpclient.HttpConnection
	-------
	public void releaseConnection() {
		LOG.trace("enter HttpConnection.releaseConnection()");
		if (locked) {
		    LOG.debug("Connection is locked.  Call to releaseConnection() ignored.");
		} else if (httpConnectionManager != null) {
		    LOG.debug("Releasing connection back to connection manager.");
		    httpConnectionManager.releaseConnection(this);//此处的实现为MultiThreadedHttpConnectionManager；this指当前getmethod对象（占用此连接资源）
		} else {
		    LOG.warn("HttpConnectionManager is null.  Connection cannot be released.");
		}
	    }
	-------

	5）
	 org.apache.commons.httpclient.MultiThreadedHttpConnectionManager
	-------
	public void releaseConnection(HttpConnection conn) {
		LOG.trace("enter HttpConnectionManager.releaseConnection(HttpConnection)");

		if (conn instanceof HttpConnectionAdapter) {
		    // connections given out are wrapped in an HttpConnectionAdapter
		    conn = ((HttpConnectionAdapter) conn).getWrappedConnection();
		} else {
		    // this is okay, when an HttpConnectionAdapter is released
		    // is releases the real connection
		}

		// make sure that the response has been read.
		SimpleHttpConnectionManager.finishLastResponse(conn);

		connectionPool.freeConnection(conn);
	    }
	-------

	6）复用连接前，确保前一个请求已处理完毕，若没有处理完毕则取出响应流并关闭它，将HttpConnection对象所引用的输出赋值为null
	org.apache.commons.httpclient.SimpleHttpConnectionManager
	/**
	     * Since the same connection is about to be reused, make sure the
	     * previous request was completely processed, and if not
	     * consume it now.
	     * @param conn The connection
	     */
	-------
	static void finishLastResponse(HttpConnection conn) {
		InputStream lastResponse = conn.getLastResponseInputStream();
		if (lastResponse != null) {
		    conn.setLastResponseInputStream(null);
		    try {
			lastResponse.close();
		    } catch (IOException ioe) {
			conn.close();
		    }
		}
	    }
	-------

	7）标记连接对象为空闲
	org.apache.commons.httpclient.MultiThreadedHttpConnectionManager
	-------
	public void freeConnection(HttpConnection conn) {

		    HostConfiguration connectionConfiguration = configurationForConnection(conn);

		    if (LOG.isDebugEnabled()) {
			LOG.debug("Freeing connection, hostConfig=" + connectionConfiguration);
		    }

		    synchronized (this) {
			
			if (shutdown) {
			    // the connection manager has been shutdown, release the connection's
			    // resources and get out of here
			    conn.close();
			    return;
			}
			
			HostConnectionPool hostPool = getHostPool(connectionConfiguration, true);

			// Put the connect back in the available list and notify a waiter
			hostPool.freeConnections.add(conn);
			if (hostPool.numConnections == 0) {
			    // for some reason this connection pool didn't already exist
			    LOG.error("Host connection pool not found, hostConfig=" 
				      + connectionConfiguration);
			    hostPool.numConnections = 1;
			}

			freeConnections.add(conn);
			// we can remove the reference to this connection as we have control over
			// it again.  this also ensures that the connection manager can be GCed
			removeReferenceToConnection((HttpConnectionWithReference) conn);
			if (numConnections == 0) {
			    // for some reason this connection pool didn't already exist
			    LOG.error("Host connection pool not found, hostConfig=" 
				      + connectionConfiguration);
			    numConnections = 1;
			}

			// register the connection with the timeout handler
			idleConnectionHandler.add(conn);

			notifyWaitingThread(hostPool);//Notify通知工作线程池，有连接可用
		    }
		}
	    }
	-------

	8）
	 org.apache.commons.httpclient.MultiThreadedHttpConnectionManager.ConnectionPool
	-------
	public synchronized void notifyWaitingThread(HostConnectionPool hostPool) {

		    // find the thread we are going to notify, we want to ensure that each
		    // waiting thread is only interrupted once so we will remove it from 
		    // all wait queues before interrupting it
		    WaitingThread waitingThread = null;
			
		    if (hostPool.waitingThreads.size() > 0) {
			if (LOG.isDebugEnabled()) {
			    LOG.debug("Notifying thread waiting on host pool, hostConfig=" 
				+ hostPool.hostConfiguration);
			}
			waitingThread = (WaitingThread) hostPool.waitingThreads.removeFirst();
			waitingThreads.remove(waitingThread);
		    } else if (waitingThreads.size() > 0) {
			if (LOG.isDebugEnabled()) {
			    LOG.debug("No-one waiting on host pool, notifying next waiting thread.");
			}
			waitingThread = (WaitingThread) waitingThreads.removeFirst();
			waitingThread.hostConnectionPool.waitingThreads.remove(waitingThread);
		    } else if (LOG.isDebugEnabled()) {
			LOG.debug("Notifying no-one, there are no waiting threads");
		    }
			
		    if (waitingThread != null) {
			waitingThread.interruptedByConnectionPool = true;
			waitingThread.thread.interrupt();
		    }
		}
	-------
	
	 org.apache.commons.httpclient.HttpMethodBase的getResponseBodyAsString方法读取响应的实现，
	 默认最大响应字节数组大小为整型的最大值，也可通过允许自定义大小的多态方法来满足其他要求
	-------
	public byte[] getResponseBody() throws IOException {
		if (this.responseBody == null) {
		    InputStream instream = getResponseBodyAsStream();
		    if (instream != null) {
			long contentLength = getResponseContentLength();
			if (contentLength > Integer.MAX_VALUE) { //guard below cast from overflow
			    throw new IOException("Content too large to be buffered: "+ contentLength +" bytes");
			}
			int limit = getParams().getIntParameter(HttpMethodParams.BUFFER_WARN_TRIGGER_LIMIT, 1024*1024);
			if ((contentLength == -1) || (contentLength > limit)) {
			    LOG.warn("Going to buffer response body of large or unknown size. "
				    +"Using getResponseBodyAsStream instead is recommended.");
			}
			LOG.debug("Buffering response body");
			ByteArrayOutputStream outstream = new ByteArrayOutputStream(
				contentLength > 0 ? (int) contentLength : DEFAULT_INITIAL_BUFFER_SIZE);
			byte[] buffer = new byte[4096];
			int len;
			while ((len = instream.read(buffer)) > 0) {
			    outstream.write(buffer, 0, len);
			}
			outstream.close();
			setResponseStream(null);
			this.responseBody = outstream.toByteArray();
		    }
		}
		return this.responseBody;
	    }
	-------
	
	SimpleHttpConnectionManager
		只维护一个连接，如果配置为复用也可。默认new HttpClient()为只复用一个连接。如果每次都实例化一个，就没有复用连接了。

	多线程测试连接池使用方式

	测试时，流未结束被重置报：connection reset错误 ？（www.baidu.com）
		流读取关闭再release连接
		与服务端是否关闭有关系，测试时，可模拟服务端，比如用tomcat的某个servelet作为响应，保证服务端不会关闭连接或限制连接数。

		测试连接：http://localhost:8080/examples/servlets/servlet/HelloWorldExample，未出现连接重置异常

		通过wireshark抓包，发现收到baidu的RST信号，重置连接，这与服务器的保护策略？待 -tip-

		httpclient要与服务端保持http长连接需要带上:connection:keep-alive，这样告诉服务端请求保持连接；但服务端可能处理socket会就关闭了，看
		下面的DOC说明：
		java.net.SocketOptions 定义了socket一些设置项
		-------
		When the keepalive option is set for a TCP socket and no data has been exchanged across the socket in either direction for 2 hours (NOTE: the actual value is implementation dependent), 
		TCP automatically sends a keepalive probe to the peer. This probe is a TCP segment to which the peer must respond. One of three responses is expected: 1. The peer responds with the 
		expected ACK. The application is not notified (since everything is OK). TCP will send another probe following another 2 hours of inactivity. 2. The peer responds with an RST, which tells 
		the local TCP that the peer host has crashed and rebooted. The socket is closed. 3. There is no response from the peer. The socket is closed. The purpose of this option is to detect if the 
		peer host crashes. Valid only for TCP socket: SocketImpl
		-------
		根据上面，百度响应了http请求后就主动关闭了连接，访问量如此高的服务器采用长连接也不实际，而且是请求响应方式无需保持连接（这里connection:keep-alive保持
		的是四层TCP连接，此点有待验证？10个并发长连接请求百度，到结束时client发送链接重置信号给服务器（HTTP RST ACK）

		简单的通过chrome浏览器请求tomcat的servlet，采用的是keep-alive的请求，可以用netstat查看连接情况，有tcp保持的记录，

		下面来看tomcat服务端，对Tcp参数connection:keep-alive是如何处理的，此处看的是tomcat的DOC，对应"The HTTP Connector"章节，这里解释了HTTP Connector能设置的参数
		
		maxKeepAliveRequests	
		The maximum number of HTTP requests which can be pipelined until the connection is closed by the server. Setting this attribute to 1 will disable HTTP/1.0 keep-alive, as well as HTTP/1.1 keep-alive 
		and pipelining. Setting this to -1 will allow an unlimited amount of pipelined or keep-alive HTTP requests. If not specified, this attribute is set to 100.
		ref: http://tomcat.apache.org/tomcat-5.5-doc/config/http.html

		wireshark设置百度的rs IP作为过滤方便分析，根据vip找到其中rs的ip进行访问即可，eg:
			ip.addr eq 10.1.170.131 and ip.addr eq 220.181.112.143




	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day305 Tuesday, May 28, 2013

1. 
	* 落日弓web
	* 大region二期
		晚上线上发布

2. 落日弓web
	extjs4
		mvc
		根据例子实践学习
		http://equin0xe.blogspot.com/2012/07/tutorial-to-start-using-extjs-4-and.html

		http://www.showframework.com/blog/2012/08/28/how-to-study-extjs/	新手如何学习ExtJS 4

		下载extjs4源码+文档+demo
	
	后端API测试地址：
		#luorigong.api=http://10.230.223.191:9999	 开发测试
		luorigong.api=http://10.250.6.145:9999	测试环境
		sso.server.url=https://login-test.alibaba-inc.com		用户认证

	Json到java bena的转换，采用jackson库：
		<dependency>
			<groupId>org.codehaus.jackson</groupId>
			<artifactId>jackson-mapper-asl</artifactId>
			<version>1.9.4</version>
		</dependency>
		
		转换方式：
		ObjectMapper om = new ObjectMapper();
		SimpleSSOUser user = om.readValue(userJsonStr, SimpleSSOUser.class);
			这里，需要json字符串与bean 的属性定义一一对应？是否有设置可以允许不一一对应

		TypeReference抽象类：（ This class is used to pass full generics type information, and avoid problems with type erasure (that basically removes most usable type references from runtime Class objects).）
			if (json.startsWith("[") && json.endsWith("]")) {
			// array of AclRule
			TypeReference<List<AclRule>> ref = new TypeReference<List<AclRule>>() {
			};
			List<AclRule> aclRules = (List<AclRule>) JsonUtil.mapper.readValue(json, ref);
			return aclRules;
			}
	
	后端API提供HTTP curl方法来操作，如GET,DELETE,POST,PUT
	具体见后端API的文档说明

	spring MVC流程：
		通过servlet接受自定义格式uri的请求
		org.springframework.web.servlet.handler.SimpleUrlHandlerMapping中定义请求与处理bean的映射

	对于静态文件，比如图片，js，css等，可以开启缓存，加快响应
		HTTP header:
			last-Modified
	
	Chome等浏览器对请求的时间以及处理渲染的时间有记录，便于调试性能瓶颈。
		Blocking
		Sending
		Waiting
		Receiving

	Extjs4
		查看组件的属性，方法等可在其DOCS中查看，官网地址：也可从下载的包中的DOCS目录下查看，对于例子需要WEB服务器的支持。
			http://docs.sencha.com/extjs/4.2.1/
		
		导入extjs与extjs的展示原理： get View->get Data -> Render
		首页，在web.xml中配置下，或者取名为index.html则默认为index页显示；在主页中导入extjs的css，js等资源和库文件；
		这样后续的窗口页面，都是通过这基础的内容通过异步请求来呈现，具体过程为先请求js的view，然后view再去调用
		web服务获取view所需要的jason数据，请求完毕。具体见下面分析。

		对于浏览器已缓存的js文件，可以直接从缓存中拿到（Last-Modified HTTP header）


		页面的js通过异步请求服务器，拿到extjs js格式的view，渲染后展示出来，如下面一个请求例子（资源视图-所有资源-核心路由管理）：
			h ttp://localhost:8080/luorigongweb/app/view/resource/grids/ManageCoreRouteGridPanel.js?_dc=1369726140183
		view中的动态数据，会再次请求服务获取数据：
			h ttp://localhost:8080/luorigongweb/services/coreRoute/list.json?_dc=1369726140420&nodeId=1&type=idcId&page=1&start=0&limit=25&filter=%5B%7B%22property%22%3A%22ip%22%7D%2C%7B%22property%22%3A%22ip%22%7D%5D
		
		Store为数据的来源，定义了proxy，可配置是否主动下载数据。
		内容展示，从store中取服务器数据或本地store的数据。
		提交表单数据的逻辑，定义的Form上提交等按钮的触发函数上，
		
		阅读自带Guides:

		根据文档写简单mvc例子
		
		页面结构：
			Viewport.js作为最顶层的view，下一层是一级Tab页ViewportChildTab.js，后面就是具体的各个view，form等资源。

	
	
	applicationContext-security.xml配置文件？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day306 Wednesday, May 29, 2013

1. 
	* 落日弓web

2. Extjs DOC
	建议的目录结构：
	-------
	- appname
		- app
			- namespace
				- Class1.js
				- Class2.js
				- ...
		- extjs
		- resources
			- css
			- images
			- ...
		- app.js
		- index.html
	-------
	PS: app中为用户自定义的js文件，namespace定义为view、store、module、controller，再其下的子目录还可以在根据业务模块划分。
	@appname is a directory that contains all your application's source files
	@app contains all your classes, the naming style of which should follow the convention listed in the Class System guide
	@extjs contains the Ext JS 4 SDK files
	@resources contains additional CSS and image files which are responsible for the look and feel of the application, as well as other static resources (XML, JSON, etc.)
	@index.html is the entry-point HTML document
	@app.js contains your application's logic
	注意：此目录结构为官方约定，若不一致默认情况下会无法加载js文件。比如application中可以设置autoCreateViewport: true属性来自动加载viewport文件。

	运行一个HelloWorld示例
	搭建maven web项目，后续用此测试项目模拟相同环境测试。
	extjs4+tomcat6+jdk1.6+spring+apache httpclient
	配置m2e插件，配置运行mvn tomcat:run命令来调试

	extjs SDK目录
		若页面用的是debug版本的库，则会引用src目录下的js文件；若为编译版的则不会使用src目录下的js，这样生成环境部署时，可使用编译后的库，然后去掉src目录
		从而，减小sdk的大小。
	
	extjs4项目部署：（Sencha SDK Tools打包用到的最新库，用于生成环境打包）
		参考官方Guide: http://docs.sencha.com/extjs/4.2.1/#!/guide/getting_started
		--------
		The newly-introduced Sencha SDK Tools (download here) makes deployment of any Ext JS 4 application easier than ever. The tools allow you to generate a manifest of all JavaScript 
		dependencies in the form of a JSB3 (JSBuilder file format) file, and create a custom build containing only the code that your application needs.

		Once you've installed the SDK Tools, open a terminal window and navigate into your application's directory.

		cd path/to/web/root/helloext
		From here you only need to run a couple of simple commands. The first one generates a JSB3 file:

		sencha create jsb -a index.html -p app.jsb3
		For applications built on top of a dynamic server-side language like PHP, Ruby, ASP, etc., you can simply replace index.html with the actual URL of your application:

		sencha create jsb -a http://localhost/helloext/index.html -p app.jsb3
		This scans your index.html file for all framework and application files that are actually used by the app, and then creates a JSB file called app.jsb3. Generating the JSB3 first gives us a chance to 
		modify the generated app.jsb3 before building - this can be helpful if you have custom resources to copy, but in most cases we can immediately proceed to build the application with the second command:

		sencha build -p app.jsb3 -d .
		This creates 2 files based on the JSB3 file:

		all-classes.js - This file contains all of your application's classes. It is not minified so is very useful for debugging problems with your built application. In our example this file is empty because our 
		"Hello Ext" application does not contain any classes.
		app-all.js - This file is a minimized build of your application plus all of the Ext JS classes required to run it. It is the minified and production-ready version of all-classes.js + app.js.
		An Ext JS application will need a separate index.html for the production version of the app. You will typically handle this in your build process or server side logic, but for now let's just create a new file 
		in the helloext directory called index-prod.html:

		<html>
		<head>
		    <title>Hello Ext</title>

		    <link rel="stylesheet" type="text/css" href="extjs/resources/css/ext-all.css">
		    <script type="text/javascript" src="extjs/ext.js"></script>
		    <script type="text/javascript" src="app-all.js"></script>
		</head>
		<body></body>
		</html>
		Notice that ext-debug.js has been replaced with ext.js, and app.js has been replaced with app-all.js. If you navigate to http://localhost/helloext/index-prod.html in your browser, you should see the 
		production version of the "Hello Ext" application.
		--------
		PS: 下载了Sencha Cmd 3.1.2
		官网关于CMD工具的说明：
			--------
			Sencha Cmd is the cornerstone to build your Sencha application. From scaffolding a new project, to minifying and deploying your application to production, Sencha 
			Cmd provides a full set of lifecycle management features to compliment your Sencha project.
			--------
			PS: 搭建新项目、精简化以及部署应用到生成环境，及项目生命周期中相关需要用到的功能




	bubbly.cc
	panac.cc
	erland.cc


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day307 Thursday, May 30, 2013

1. 
	* 落日弓web

2. 落日弓web
	执行流程
	页面组织结构：子页面嵌套关系及与目录树的关系

	一切都从webcontent目录下的index.html和app.js开始： 目录结构及项目结构符合extjs4的官方建议结构 -tip-
	app.js为新项目定义的开始，是衔接extjs4库和用户自定义js内容的桥梁，当然app.js是在index.html中随同extjs库和资源文件一起被引入的。

	app.js中定义了application，application中的：
		autoCreateViewport: true
	属性会触发加载app\view\viewport.js文件，此文件里定义了页面需要用的子模块，比如：
	requires: ['LuoRiGong.view.ViewportChildTab'],

	extjs4根据require的模块，自动加载对应的文件，注意：自动加载是基于app目录和app.js的名称定义，以及app目录下的文件的命名要统一，与官方定义一致
	否则浏览器console会报加载不了js文件（比如chrome）。
	
	Extjs4命名规范：
	1）Class类
	类名只能包含字母数字，不推荐使用数字，除非是常用词。不要用下划线中化纤等非字母数字字符。

	MyCompany.useful_util.Debug_Toolbar 不合法
	MyCompany.util.Base64 合法
	类应该组织在包或者说命名空间下面，并且至少要有一个顶层命名空间，例如：

	MyCompany.data.CoolProxy
	MyCompany.Application
	顶层命名空间和真正的类，应该采用驼峰式命名，其他一律小写，例如：

	MyCompany.form.action.AutoLoad
	非Ext官方类，不可以在Ext顶层命名空间下（这是为了防止冲突）

	首字母组合词也要采用驼峰式命名，例如：
	
	2）Source File源文件
	类的命名和源文件存放路径是对应的，例如：
		Ext.util.Observable 存放在 path/to/src/Ext/util/Observable.js
		Ext.form.action.Submit 存放在 path/to/src/Ext/form/action/Submit.js
		MyCompany.chart.axis.Numeric 存放在 path/to/src/MyCompany/chart/axis/Numeric.js
	这里面的path/to/src就是程序跟目录下的那个app目录，所有类都应该这样组织，保证维护性

	3）Methods and Variables 方法和成员变量
	和类名一样只能用字母和数字，其他符号不可以
	同样是驼峰命名，但是首字母小写，首字母组合词也如此

	4）Properties 属性
	跟成员变量一致
	如果是常量

	ExtJs MVC
	Defining a Controller 定义一个控制器
	控制器是应用的粘合剂，它们所作的事情就是监听事件并执行动作


3. domain
	reland.cc
	yl-4x


4. extjs4 eclipse插件 安装及配置 * extjs4 spket
	地址： http://www.agpad.com/update
	下面是官方使用说明：
	-----
	Create JavaScript profile

	Select the menu item Window > Preferences... to open the workbench preferences.
	Select the Spket > JavaScript Profile preference page to display the installed JavaScript Profiles.
	Click the New.. button. In the Name field, type ExtAIR as the name for the new profile. Then click OK.
	Click the Add Library button. From the Library drop-down list, select AIR. Then click OK.
	Select profile ExtAIR then click the Add Library button. From the Library drop-down list, select ExtJS. Then click OK.
	Click the Add File button, choose ext.jsb which can be found in Ext source folder
	Select the ExtAIR profile created in step 3, click the Default button make it the default profile for all project. The default profile can also be configured per project by using Configure Project Specific Settings... link.
	Click on OK to save the preferences.


	Start coding

	From the menu bar, select File > New > File
	In the File name field, type test.js as the name for the new file. Then click Finish.
	-----
	from: http://www.spket.com/ext-air-tutorials.html
	PS: 就是插件安装好后，需要设置插件，增加profile配置，并指向到extjs4的目录下；新建js文件，打开时采用spket插件提供的编辑器；




SEVERE: Can't create channelSocket
 31 java.lang.ClassFormatError: Code segment has wrong length in class file org/apache/jk/common/ChannelSocket
 环境原6.0.x，换为6.3.x即可（AJP端口正确打开）


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day308 Friday, May 31, 2013

1. 
	* 落日弓web

2. 落日弓web
	extjs速度慢的优化：squid做前端缓存
		考虑对静态资源做缓存，直接从缓存读取而不去web服务器获取
		从chrome的加载记录可以看出，慢的原因在于需要加载大量js文件，如果用前端缓存速度相对会提高不少，可配置测试下 待？

3. Spring MVC对文件上传的支持 MultipartResolver接口
	Strategy Patten策略模式的应用，底层上传文件实现还是采用apache common upload包
	------
	org.springframework.web.multipart.MultipartResolver
	A strategy interface for multipart file upload resolution in accordance with RFC 1867. Implementations are typically usable both within an application context and standalone. 
	------
	PS: MultipartResolver一个策略接口用于多媒体文件上传处理

	org.springframework.web.servlet.DispatcherServlet
	这个转发servlet采用策略模式，根据配置来设置各种解析器Resolver，需要替换直接在配置文件中替换实现即可；DispatcherServlet定义了多个策略的成员变量
	在初始化策略对象时，若未在BeanFactory配置则取默认实现或者为空，下面为部分源码：
	-----
	/** MultipartResolver used by this servlet */
	private MultipartResolver multipartResolver;

	/** LocaleResolver used by this servlet */
	private LocaleResolver localeResolver;
	...
	...
	/**
	 * Initialize the strategy objects that this servlet uses.
	 * <p>May be overridden in subclasses in order to initialize further strategy objects.
	 */
	protected void initStrategies(ApplicationContext context) {
		initMultipartResolver(context);
		initLocaleResolver(context);
		initThemeResolver(context);
		initHandlerMappings(context);
		initHandlerAdapters(context);
		initHandlerExceptionResolvers(context);
		initRequestToViewNameTranslator(context);
		initViewResolvers(context);
		initFlashMapManager(context);
	}
	-----

	spring MVC: URL MAPPING
	org.springframework.web.servlet.handler.SimpleUrlHandlerMapping

4. ExtJs4
	根据用到的组件和属性来属性各个组件。

	1) xtype的定义
	------
	This property provides a shorter alternative to creating objects than using a full class name. Using xtype is the most common way to define component instances, especially in a container. 
	For example, the items in a form containing text fields could be created explicitly like so:

	 items: [
	     Ext.create('Ext.form.field.Text', {
		 fieldLabel: 'Foo'
	     }),
	     Ext.create('Ext.form.field.Text', {
		 fieldLabel: 'Bar'
	     }),
	     Ext.create('Ext.form.field.Number', {
		 fieldLabel: 'Num'
	     })
	 ]
	But by using xtype, the above becomes:

	 items: [
	     {
		 xtype: 'textfield',
		 fieldLabel: 'Foo'
	     },
	     {
		 xtype: 'textfield',
		 fieldLabel: 'Bar'
	     },
	     {
		 xtype: 'numberfield',
		 fieldLabel: 'Num'
	     }
	 ]
	When the xtype is common to many items, Ext.container.AbstractContainer.defaultType is another way to specify the xtype for all items that don't have an explicit xtype:

	 defaultType: 'textfield',
	 items: [
	     { fieldLabel: 'Foo' },
	     { fieldLabel: 'Bar' },
	     { fieldLabel: 'Num', xtype: 'numberfield' }
	 ]
	Each member of the items array is now just a "configuration object". These objects are used to create and configure component instances. A configuration object can be manually used to 
	instantiate a component using Ext.widget:

	 var text1 = Ext.create('Ext.form.field.Text', {
	     fieldLabel: 'Foo'
	 });

	 // or alternatively:

	 var text1 = Ext.widget({
	     xtype: 'textfield',
	     fieldLabel: 'Foo'
	 });
	This conversion of configuration objects into instantiated components is done when a container is created as part of its {Ext.container.AbstractContainer.initComponent} process. As part of the 
	same process, the items array is converted from its raw array form into a Ext.util.MixedCollection instance.

	You can define your own xtype on a custom component by specifying the xtype property in Ext.define. For example:

	Ext.define('MyApp.PressMeButton', {
	    extend: 'Ext.button.Button',
	    xtype: 'pressmebutton',
	    text: 'Press Me'
	});
	Care should be taken when naming an xtype in a custom component because there is a single, shared scope for all xtypes. Third part components should consider using a prefix to avoid collisions.

	Ext.define('Foo.form.CoolButton', {
	    extend: 'Ext.button.Button',
	    xtype: 'ux-coolbutton',
	    text: 'Cool!'
	});
	See Ext.enums.Widget for list of all available xtypes.
	------

	2) Ext.container.ContainerView
	Base class for any Ext.Component that may contain other Components. Containers handle the basic behavior of containing items, namely adding, inserting and removing items.
	eg:
	--------
	// Explicitly create a Container
	Ext.create('Ext.container.Container', {
	    layout: {
		type: 'hbox'
	    },
	    width: 400,
	    renderTo: Ext.getBody(),
	    border: 1,
	    style: {borderColor:'#000000', borderStyle:'solid', borderWidth:'1px'},
	    defaults: {
		labelWidth: 80,
		// implicitly create Container by specifying xtype
		xtype: 'datefield',
		flex: 1,
		style: {
		    padding: '10px'
		}
	    },
	    items: [{
		xtype: 'datefield',
		name: 'startDate',
		fieldLabel: 'Start date'
	    },{
		xtype: 'datefield',
		name: 'endDate',
		fieldLabel: 'End date'
	    }]
	});
	--------

	3) Ext.container.Viewport
	属性：
	


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day309 Monday, June 03, 2013

1. 
	* 落日弓web


2. 落日弓web
	
	对象实例化方法：
	创建一个新的My.sample.Person实例使用的是Ext.create()方法，使用new关键字也可以创建实例（new My.sample.Person()），但是不推荐使用new，
	应该养成使用Ext.create的习惯，因为这样可以利用到动态加载的好处

	介绍Extjs4的几个基本对象及方法：
	1) Ext.define( className, data, createdFn ) : Ext.Base	  define方法，return Ext.Base(The root of all classes created with Ext.define.)
		Defines a class or override. A basic class is defined like this:
		---
		 Ext.define('My.awesome.Class', {
		     someProperty: 'something',

		     someMethod: function(s) {
			 alert(s + this.someProperty);
		     }

		     ...
		 });

		 var obj = new My.awesome.Class();

		 obj.someMethod('Say '); // alerts 'Say something'
		---

	2）Ext.create方法 
		定义：
		create( [name], [args] ) : Object
		Instantiate a class by either full name, alias or alternate name.
		---
		If Ext.Loader is enabled and the class has not been defined yet, it will attempt to load the class via synchronous loading.

		For example, all these three lines return the same result:	   各种创建对象的方法

		 // alias 别名，注意别名要注册到widget中
		 var window = Ext.create('widget.window', {
		     width: 600,
		     height: 800,
		     ...
		 });

		 // alternate name
		 var window = Ext.create('Ext.Window', {
		     width: 600,
		     height: 800,
		     ...
		 });

		 // full class name 全类名
		 var window = Ext.create('Ext.window.Window', {
		     width: 600,
		     height: 800,
		     ...
		 });

		 // single object with xclass property:
		 var window = Ext.create({
		     xclass: 'Ext.window.Window', // any valid value for 'name' (above)
		     width: 600,
		     height: 800,
		     ...
		 });

		Parameters
			name : String (optional)
			The class name or alias. Can be specified as xclass property if only one object parameter is specified.
			args : Object... (optional)
			Additional arguments after the name will be passed to the class' constructor.
		Returns
			Object
			instance
		---
	
	Ext.define定义类时，类体中的proxy，model，extend等等属性是哪里来的？
		来自其基础的父类Class，比如Ext.data.Store的所有子类都可以覆盖父类的proxy属性。这也体现了此框架面向对象编程的应用，继续看看proxy属性在Stroe类
		的定义说明：
			proxy : String/Ext.data.proxy.Proxy/Object
			The Proxy to use for this Store. This can be either a string, a config object or a Proxy instance - see setProxy for details.

			Ext.data.proxy.Proxy继续了解，关于Proxy instance的说明：
			Proxies are used by Stores to handle the loading and saving of Model data. Usually developers will not need to create or interact with proxies directly.
	
		Ext.data.proxy.Ajax为Proxy的子类，通过AJAX请求从服务端加载数据，看一个例子：
		---
		Ext.define('User', {
		    extend: 'Ext.data.Model',
		    fields: ['id', 'name', 'email']
		});//上面为Model的定义

		//The Store contains the AjaxProxy as an inline configuration
		var store = Ext.create('Ext.data.Store', {
		    model: 'User',
		    proxy: {
			type: 'ajax', //指明所定义的Proxy子类的类型，剩下的属性都是对子类属性的定义
			url : 'users.json'
		    }
		});

		store.load();
		---
		PS: 通过AJAX来请求的数据的方式的限制为：不能从其他domain获取数据，是由于浏览器安全考虑，具体见文档说明：
			-------
			Limitations

			AjaxProxy cannot be used to retrieve data from other domains. If your application is running on http://domainA.com it cannot load data from http://domainB.com because browsers have a built-in 
			security policy that prohibits domains talking to each other via AJAX.

			If you need to read data from another domain and can't set up a proxy server (some software that runs on your own domain's web server and transparently forwards requests to http://domainB.com, 
			making it look like they actually came from http://domainA.com), you can use Ext.data.proxy.JsonP and a technique known as JSON-P (JSON with Padding), which can help you get around the problem 
			so long as the server on http://domainB.com is set up to support JSON-P responses. See JsonPProxy's introduction docs for more details.
			-------
			
			继续，静态Store的定义，即此Store无需动态获取数据，事先已定义好，比如以下下拉列表数据：
			-----
			-----

	上面描述了store定义，下面继续说说其他组件的定义

	Model定义：
		-----
		 // Set up a model to use in our Store
		 Ext.define('User', {
		     extend: 'Ext.data.Model',
		     fields: [
			 {name: 'firstName', type: 'string'},
			 {name: 'lastName',  type: 'string'},
			 {name: 'age',       type: 'int'},
			 {name: 'eyeColor',  type: 'string'}
		     ]
		 });//fields属性，限定了其定义的对象需要符合field对象的要求，具体见field的定义说明

		 var myStore = Ext.create('Ext.data.Store', {
		     model: 'User',
		     proxy: {
			 type: 'ajax',
			 url: '/users.json',
			 reader: {
			     type: 'json',
			     root: 'users'
			 }
		     },
		     autoLoad: true
		 });
		-----
		PS: 此例子定义了一个Model和一个使用此Model的Store
	
	View定义：
		




3. 根据项目提交内容分析增加新功能与维护现有功能的部分流程细节
	

4. 除了apache的poi包，落日弓web用jexcelapi包处理excel
	

5. sso账号申请

6. extjs4
	Inline data
	inline configuration
	inline ...
	比如stroe中proxy的{...}配置方式

7. 二期修改发布步骤 dg api

8. 一个应用服务器集群，session共享，统一缓存例子


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day310 Tuesday, June 04, 2013

1. 
	* 落日弓web

2. 落日弓web
	ACL模块的熟悉 ，"顺藤摸瓜式的扫荡"
	
	一、从viewport.js开始分析，位于app>view>viewport.js，由app.js根据默认路径加载，代码如下：
		-----
		Ext.define('LuoRiGong.view.Viewport', {
		    extend: 'Ext.container.Viewport',
		    requires: [
			'LuoRiGong.view.ViewportChildTab'
		    ],
		    
		    layout:  {
			type: 'fit',
			defaultMargins: {top: 5, right: 0, bottom: 0, left: 0}
		    },
		    
		    items: [
			{
					xtype: 'viewportChildTab'
			}
		    ]
		});
		-----
		PS: 继承于Ext.container.Viewport，显示的入口，viewport的定义：
			-----
			A specialized container representing the viewable application area (the browser viewport).

			The Viewport renders itself to the document body, and automatically sizes itself to the size of the browser viewport and manages window resizing. There may only be one 
			Viewport created in a page.

			Like any Container, a Viewport will only perform sizing and positioning on its child Components if you configure it with a layout.

			A Common layout used with Viewports is border layout, but if the required layout is simpler, a different layout should be chosen.

			For example, to simply make a single child item occupy all available space, use fit layout.

			To display one "active" item at full size from a choice of several child items, use card layout.

			Inner layouts are available because all Panels added to the Viewport, either through its items, or the add method of any of its child Panels may themselves have a layout.

			The Viewport does not provide scrolling, so child Panels within the Viewport should provide for scrolling if needed using the autoScroll config.
			-----
			PS: 一个页面一般只创建一个viewport，关于布局中layout的fit（只有一个对象呈现时，填充所有区域）、card(有多个对象，某一时刻只有一个对象填充所有区域时)\border(
			类型java的swing布局，border表示分块布局，东南西北等) 、hbox（水平划分布局，在同一个水平线上排列组件，高度可通过align属性配置）
		属性说明：
		1）layout
			-----
			Important: In order for child items to be correctly sized and positioned, typically a layout manager must be specified through the layout configuration option.
			
			The sizing and positioning of child items is the responsibility of the Container's layout manager which creates and manages the type of layout you have in mind. For example:
			
			If the layout configuration is not explicitly specified for a general purpose container (e.g. Container or Panel) the default layout manager will be used which does nothing but 
			render child components sequentially into the Container (no sizing or positioning will be performed in this situation).

			layout may be specified as either as an Object or as a String:
			Specify as an Object
			Example usage:

			layout: {
			    type: 'vbox',
			    align: 'left'
			}
			@type
			The layout type to be used for this container. If not specified, a default Ext.layout.container.Auto will be created and used.

			Valid layout type values are listed in Ext.enums.Layout.
			@Layout specific configuration properties

			Additional layout specific configuration properties may also be specified. For complete details regarding the valid config options for each layout type, see the layout class 
			corresponding to the type specified.

			Specify as a String
			Example usage:

			layout: 'vbox'
			-----
		2）requires
			-----
			requires : String[]4
			List of classes that have to be loaded before instantiating this class. For example:

			Ext.define('Mother', {
			    requires: ['Child'],
			    giveBirth: function() {
				// we can be sure that child class is available.
				return new Child();
			    }
			});
			-----
			PS: 在实例化当前类之前，预加载进来所需的类，这里为LuoRiGong.view.ViewportChildTab，避免在解析时再从服务器下载类，影响用户体验。
		3）items
			-----
			items : Object/Object[]1
			A single item, or an array of child Components to be added to this container

			Unless configured with a layout, a Container simply renders child Components serially into its encapsulating element and performs no sizing or positioning upon them.

			Example:

			// specifying a single item
			items: {...},
			layout: 'fit',    // The single items is sized to fit

			// specifying multiple items
			items: [{...}, {...}],
			layout: 'hbox', // The items are arranged horizontally
			-----
			PS: 组件的布局需要配置layout配置实现

			另外这里还有个xtype属性，定义如下：
			xtype : Ext.enums.Widget
			This property provides a shorter alternative to creating objects than using a full class name. Using xtype is the most common way to define component instances, especially in a container.
			PS: 方便实例化对象，特别是在容器中，下面是个对照例子：
				-----
				 items: [
				     Ext.create('Ext.form.field.Text', {
					 fieldLabel: 'Foo'
				     }),
				     Ext.create('Ext.form.field.Text', {
					 fieldLabel: 'Bar'
				     }),
				     Ext.create('Ext.form.field.Number', {
					 fieldLabel: 'Num'
				     })
				 ]

				But by using xtype, the above becomes:

				 items: [
				     {
					 xtype: 'textfield',
					 fieldLabel: 'Foo'
				     },
				     {
					 xtype: 'textfield',
					 fieldLabel: 'Bar'
				     },
				     {
					 xtype: 'numberfield',
					 fieldLabel: 'Num'
				     }
				 ]
				-----
	二、接着，viewportChildTab分析
		定义如下：
		-----
		Ext.define('LuoRiGong.view.ViewportChildTab', {
			extend: 'Ext.tab.Panel',
			xtype: 'viewportChildTab',
			
			requires: [
				'LuoRiGong.view.datacenter.DataCenterContainer',
			'LuoRiGong.view.resource.ResourceViewContainer',
			...
			...
			],
			
			defaults: {
			layout: {
			    type : 'hbox',
			    align: 'stretch'
			}
		    },
			
			items: [
			{
			    title: '控制系统',
			    xtype: 'dataCenterContainer'
			},
			
			{
			    title: '资源视图',
			    xtype: 'resourceViewContainer'
			},
		       ...
		       ...       
		    ],
		    
		    listeners: {
			tabchange: function(tabPanel, newCard, oldCard, eOpts) {
				if (newCard.title == '控制系统') {
					Ext.getStore('DataCenterTreeStore').load();
				}
				
				if (newCard.title == '资源视图') {
					Ext.getStore('ResourceViewTreeStore').load();
				}
				...
				...
			}
		    }
		});
		-----
		PS: 这个类中定义了页面的主要版面和大体布局，继承于Ext.tab.Panel，关于Panel的定义看下面：
			-----
			A basic tab container. TabPanels can be used exactly like a standard Ext.panel.Panel for layout purposes, but also have special support for containing child Components (items) 
			that are managed using a CardLayout layout manager, and displayed as separate tabs.

			Note: By default, a tab's close tool destroys the child tab Component and all its descendants. This makes the child tab Component, and all its descendants unusable. To enable re-use of a tab, 
			configure the TabPanel with autoDestroy: false.
			-----
		属性说明：
		1）xtype
			-----
			xtype : Ext.enums.Widget10
			This property provides a shorter alternative to creating objects than using a full class name. Using xtype is the most common way to define component instances, especially in a container.
			...
			...
			When the xtype is common to many items, Ext.container.AbstractContainer.defaultType is another way to specify the xtype for all items that don't have an explicit xtype:

			 defaultType: 'textfield',
			 items: [
			     { fieldLabel: 'Foo' },
			     { fieldLabel: 'Bar' },
			     { fieldLabel: 'Num', xtype: 'numberfield' }
			 ]
			-----
			PS: AbstractContainer.defaultType is another way to specify the xtype for all items that don't have an explicit xtype:

		2）defaults
			-----
			defaults : Object/Function
			This option is a means of applying default settings to all added items whether added through the items config or via the add or insert methods.

			Defaults are applied to both config objects and instantiated components conditionally so as not to override existing properties in the item (see Ext.applyIf).

			If the defaults option is specified as a function, then the function will be called using this Container as the scope (this reference) and passing the added item as the first parameter. 
			Any resulting object from that call is then applied to the item as default properties.

			For example, to automatically apply padding to the body of each of a set of contained Ext.panel.Panel items, you could pass: defaults: {bodyStyle:'padding:15px'}.

			Usage:

			defaults: { // defaults are applied to items, not the container
			    autoScroll: true
			},
			items: [
			    // default will not be applied here, panel1 will be autoScroll: false
			    {
				xtype: 'panel',
				id: 'panel1',
				autoScroll: false
			    },
			    // this component will have autoScroll: true
			    new Ext.panel.Panel({
				id: 'panel2'
			    })
			]
			-----
			PS: 对添加都此Panel的所有组件设置默认配置，不会覆盖子组件已有配置

		3）listeners
			-----
			listeners : Object
			A config object containing one or more event handlers to be added to this object during initialization. This should be a valid listeners config object as specified in the 
			addListener example for attaching multiple handlers at once.
			-----
			PS: 一个配置对象，在初始化Panel对象时添加一个或多个事件处理器。此配置对象需要符合标准的listener配置，参考addListener方法中添加多个handler的
			说明

			本例中，tabPanel会触发tabchange事件，故在配置listener配置时，编写了触发tabchange事件的处理逻辑。时间处理函数的参数，查阅事件的文档说明，下面为摘取：
				-----
				tabchange( tabPanel, newCard, oldCard, eOpts )1
				Fires when a new tab has been activated (activated by setActiveTab).
				-----
			
			下面，说下本初用到store的说明：
				Ext.getStore获取store
					Ext.getStore
					-----
					getStore( store ) : Ext.data.Store
					Shortcut to Ext.data.StoreManager.lookup.

					Gets a registered Store by id

					Available since: 4.0.0

					Parameters
					store : String/Object
					The id of the Store, or a Store instance, or a store configuration
					-----
					PS: 根据store id获取store对象的快捷方法，也可根据实例或配置
					此处，获取了左边树要的数据

				Store.load方法获取数据
					-----
					load( [options] )
					Loads data into the Store via the configured proxy. This uses the Proxy to make an asynchronous call to whatever storage backend the Proxy uses, 
					automatically adding the retrieved instances into the Store and calling an optional callback if required. Example usage:

					store.load({
					    scope: this,
					    callback: function(records, operation, success) {
						// the operation object
						// contains all of the details of the load operation
						console.log(records);
					    }
					});
					If the callback scope does not need to be set, a function can simply be passed:

					store.load(function(records, operation, success) {
					    console.log('loaded records');
					});
					-----
					PS: 通过proxy配置，加载数据到Store中
			
			listener做的事情：
				加载新tab页需要的store的数据
				关闭旧tab页的task，如Ext.TaskManager.stop(...)
					这些task是在globalutilities.js文件中定义的全局对象（由function genJobStatusTask(componentType, componentId, statusType, interval, map, panel) 方法定义），
					此处为刷新操作状态的。	     全局任务

	三、 ResourceViewContainer 分析 (就是tab页的资源视图，里面的内容都在此容器里配置；其他tab页和此tab平级，故这里以本tab为例子说明)
		定义如下：
		-----
		Ext.define('LuoRiGong.view.resource.ResourceViewContainer', {
		    extend: 'Ext.container.Container',
		    xtype: 'resourceViewContainer',
		    
		    requires: [
			'LuoRiGong.view.resource.ResourceViewList',
			'LuoRiGong.view.LuoRiGongContainer'
		    ],

		    items: [
			{
			    xtype: 'resourceViewList',
			    margin: '5, 3, 5, 5',
			    flex: 1
			},
			
			{
				xtype: 'luoRiGongContainer',
			    id   : 'resourceViewContainer'
			}
		    ]
		});
		-----
		PS: require包含进来2个组件；并在items属性上配置上面2个组件以显示，对于第一个组件同时配置了其显示属性（
		margin：此处为xtype定义的子组件的属性，文档说明如下：
			-----
			margin : Number/String6
			Specifies the margin for this component. The margin can be a single numeric value to apply to all sides or it can be a CSS style specification for each style, 
			for example: '10 5 3 10' (top, right, bottom, left).
			-----
		flex：	 Ext.layout.container.HBox的属性
			-----
			flex : Number3
			This configuration option is to be applied to child items of the container managed by this layout. Each child item with a flex property will be flexed (horizontally in hbox, vertically in vbox) 
			according to each item's relative flex value compared to the sum of all items with a flex value specified. Any child items that have either a flex = 0 or flex = undefined will not be 'flexed' (the 
			initial size will not be changed).			
			-----
			作于与layout定义的子items的布局配置，第一个item flex=1，第二个为4，即第一个占水平长度的1/5
		）

		属性说明：
		1）id （items配置的第二个item有id属性）
			-----
			id : String
			The unique id of this component instance.

			It should not be necessary to use this configuration except for singleton objects in your application. Components created with an id may be accessed globally using Ext.getCmp.

			Instead of using assigned ids, use the itemId config, and ComponentQuery which provides selector-based searching for Sencha Components analogous to DOM querying. 
			The Container class contains shortcut methods to query its descendant Components by selector.

			Note that this id will also be used as the element id for the containing HTML element that is rendered to the page for this component. This allows you to write id-based CSS rules 
			to style the specific instance of this component uniquely, and also to select sub-elements using this component's id as the parent.

			Note: To avoid complications imposed by a unique id also see itemId.

			Note: To access the container of a Component see ownerCt.

			Defaults to an auto-assigned id.
			-----

	四、对于上面2个子组件的分析
		
		第一个为：ResourceViewList (即页面左边的树展示)
			定义如下：
			-----
			Ext.define('LuoRiGong.view.resource.ResourceViewList', {
				extend: 'Ext.tree.Panel',
				xtype: 'resourceViewList',

				useArrows: false,
				frame: true,

				store: 'ResourceViewTreeStore',

				setActiveResourceList: function(record) {
					idcId = record.get('nodeId');
					
					var resourceViewContainer = Ext.getCmp('resourceViewContainer');
				    resourceViewItem = Ext.create('LuoRiGong.view.resource.IdcResourceContainer');
				    
				    resourceViewItem.down('idcResourceList').setTitle(record.get('text'));
				    
				    resourceViewContainer.removeAll(true);
				    resourceViewContainer.add(resourceViewItem);
				},

				listeners: {
					itemclick: function(me, record, item, index, e, eOpts) {
						if(record.isLeaf()) {
							this.setActiveResourceList(record);
						} 
					},
					
					itemcontextmenu: function(me, record, item, index, e, eOpts ) {
						if (record.get('depth') == '0') {
							var allResourcesContextMenu = Ext.create('LuoRiGong.view.resource.menu.AllResourcesContextMenu');
						allResourcesContextMenu.showAt(e.getX(), e.getY());
						} else if (record.get('depth') == '1') {
							areaId = record.get('nodeId');
							var areaContextMenu = Ext.create('LuoRiGong.view.resource.menu.AreaContextMenu');
						areaContextMenu.showAt(e.getX(), e.getY());
						} else if (record.get('depth') == '2') {
							idcId = record.get('nodeId');
							var idcContextMenu = Ext.create('LuoRiGong.view.resource.menu.IdcContextMenu');
							idcContextMenu.showAt(e.getX(), e.getY());
						}
					e.preventDefault();
					}
				}
			});			
			-----
			PS: 组件继承的是Ext.tree.Panel，是tree包下的Panel（还有其他类型的Panel，比如Ext.form.Panel、Ext.tab.Panel、Ext.grid.Panel等）；
			listener中的逻辑后续移到Controller中，遵循MVC

			属性说明：
			1）useArrows  表示是否使用箭头图标，默认为false；定义在Ext.tree.Panel上
			2）frame Ext.tree.Panel
				-----
				frame : Boolean
				True to apply a frame to the panel.
				Defaults to: false
				Overrides: Ext.AbstractComponent.frame
				-----
			3）store 数据源配置
				-----
				store : Ext.data.TreeStore REQUIRED
				The Store the tree should use as its data source.

				Available since: 4.0.4

				Overrides: Ext.panel.Table.store
				-----
				PS: 注意到，标识为REQUIRED，表示此属性必须配置

				这里的Store类型为Ext.data.TreeStore，定义如下：
				-----
				The TreeStore is a store implementation that is backed by by an Ext.data.Tree. It provides convenience methods for loading nodes, as well as the ability to use the 
				hierarchical tree structure combined with a store. This class is generally used in conjunction with Ext.tree.Panel. This class also relays many events from the Tree for 
				convenience.

				Using Models

				If no Model is specified, an implicit model will be created that implements Ext.data.NodeInterface. The standard Tree fields will also be copied onto the Model for 
				maintaining their state. These fields are listed in the Ext.data.NodeInterface documentation.

				Reading Nested Data

				For the tree to read nested data, the Ext.data.reader.Reader must be configured with a root property, so the reader can find nested data for each node (if a root is not 
				specified, it will default to 'children'). This will tell the tree to look for any nested tree nodes by the same keyword, i.e., 'children'. If a root is specified in the config make 
				sure that any nested nodes with children have the same name. Note that setting defaultRootProperty accomplishes the same thing.
				-----
			4）setActiveResourceList
				为自定义的一个属性，此处自定义属性指向一个函数

			5）listener	这些控制脚本可移到Controller中去
				itemclick( this, record, item, index, e, eOpts )
					Fires when an item is clicked.
					Parameters
						this : Ext.view.View
						record : Ext.data.Model
						The record that belongs to the item
						item : HTMLElement
						The item's element
						index : Number
						The item's index
						e : Ext.EventObject
						The raw event object
						eOpts : Object
						The options object passed to Ext.util.Observable.addListener.

				itemcontextmenu( this, record, item, index, e, eOpts )
					Fires when an item is right clicked.
					Parameters
						this : Ext.view.View
						record : Ext.data.Model
						The record that belongs to the item
						item : HTMLElement
						The item's element
						index : Number
						The item's index
						e : Ext.EventObject
						The raw event object
						eOpts : Object
						The options object passed to Ext.util.Observable.addListener.




		第二个为：luoRiGongContainer
			此组件是一个空的Container模板，多个tab页共用，根据id定义来区分。


		
	五、ResourceViewTreeStore分析（用于上面的ResourceViewContainer中的ResourceViewList TreePanel）
		定义如下：
		-----
		Ext.define('LuoRiGong.store.ResourceViewTreeStore', {
		    extend: 'Ext.data.TreeStore',
			model: 'LuoRiGong.model.TreeItem',
			autoLoad: false,
		    
		    proxy: {
			type: 'ajax',
			url: 'services/tree/resourceView/list.json',
			reader: {
			    type: 'json',
			    root: 'children'
			}
		    },
		    
		    root: {
			text: '所有资源',  
			expanded: false
		    },
		    
		    folderSort: true,
		    sorters: [{
			property: 'text',
			direction: 'ASC'
		    }],
		    
		    listeners: {
			beforeload: function(store, operation, eOpts) {
				operation.params.nodeId = operation.node.get('nodeId');
			}
		    }
		});
		-----

		属性说明：
		1）model : String
	 		Name of the Model associated with this store. The string is used as an argument for Ext.ModelManager.getModel.
		2）autoLoad : Boolean/Object
			If data is not specified, and if autoLoad is true or an Object, this store's load method is automatically called after creation. If the value of autoLoad is an Object, this 
			Object will be passed to the store's load method.
		3）proxy : String/Ext.data.proxy.Proxy/Object
			The Proxy to use for this Store. This can be either a string, a config object or a Proxy instance - see setProxy for details.

			type：指定proxy的类型
				下面是Ext.data.proxy.Ajax的定义：
				-----
				Ext.define('Ext.data.proxy.Ajax', {
				    requires: ['Ext.util.MixedCollection', 'Ext.Ajax'],
				    extend: 'Ext.data.proxy.Server',
				    alias: 'proxy.ajax',
				    alternateClassName: ['Ext.data.HttpProxy', 'Ext.data.AjaxProxy'],
				-----
				PS: type来自其" alias: 'proxy.ajax'"的定义，其他地方类推
			url：
			reader：
				reader : Object/String/Ext.data.reader.Reader1
				The Ext.data.reader.Reader to use to decode the server's response or data read from client. This can either be a Reader instance, a config object or just a valid 
				Reader type name (e.g. 'json', 'xml').


			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day311 Wednesday, June 05, 2013

1. 
	* 落日弓web
	* 大region二期发布
		AY48C
		AY81A
		AY81B

		青岛大region，发布控制系统

2. 落日弓web
	1）继续上次的分析

	2）落日弓的业务熟悉
	从wiki的集群搭建步骤开始
	a. 到资源视图，找到机房，大region，资源视图的树可以右键添加

	Acl中的宏与规则，宏定义了某个角色的所有IP组合，比如houyiapi宏表示所有houyiapi的ip集合；规则表示宏到宏之间的具体acl规则。

	页面的按钮调用，不只是顺序调用还有循环调用

	houyiAPI以域名（vip）的方式管理；然后，在集群信息找可以看到houyiapi与大region的关系

	新集群搭建与扩容：
		集群搭建，首先在资源视图中加对应的资源（对于大region共享的，可以不用再添加）
		然后到控制系统，集群信息中补充更多新增集群的信息，并配置好代码源、数据库、网段、物理机等资源；

	物理机资源（nc资源）的管理由Armory管理，落日弓访问其服务获取信息；对于测试环境的nc，未在Armory中管理，需要手工整理后上传到落日弓中。
		Armory中的机器管理，要新建或扩容而利用nc资源时，从Armory的Buffer组中获取，集群搭建关闭后，置buffer组为server组。
		
	

	失效功能或需完善功能：
		控制系统-集群部署-环境检查 基本不用，因为环境变化太大
		控制系统-集群部署-一键部署 未使用
		控制系统-集群配置-aworkshot和apiproxy发布，为人工操作
		控制系统-集群配置-Monitor测试 QA方功能未实现
		控制系统-扫尾-集群交付 可用，但未用


3. slb部署流程
	http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=9261407

4. Areasolve为大禹
	用于部署飞天，落日弓agent部署于集群的AG上，nc上的操作通过大禹完成。

	落日弓部署结构图：
	Portal(java web)   (部署2个，f5均衡)
	|
	API(python web)
	----------------------
	|				|
	Agent1（AG1）	Agent2(AG2)
	----------------------
	|				|
	Arearesolve		Arearesolve

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day312 Thursday, June 06, 2013

1. 
	* 落日弓web
2. 

3. 有各种开源，各种服务，各种成熟架构，还少什么让我们成功？
	环境？魄力？资金？人才？方案？

4. houyimon库
	采用了分库，分表
	一个集群1个到多个monitor库，每个库的表按照天进行分表。

5. Armory
	测试地址
	http://opsdbtest.ops.aliyun-inc.com/ admin



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day313 Friday, June 07, 2013

1. 
	* 落日弓web

2. 落日弓web
	api文档
	java部分优化分析

	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day314 Saturday, June 08, 2013

1. 
	* 落日弓web

2. 落日弓web
	继续day310第2条分析

	SSO通过cookie实现，存了token在cookie中

	spring MVC有哪些参数校验框架，可进行配置，类似struts2的可配置校验

3. man 的帮助 :h出现man的帮助说明
	-----
	SUMMARY OF LESS COMMANDS

	      Commands marked with * may be preceded by a number, N.
	      Notes in parentheses indicate the behavior if N is given.

	  h  H                 Display this help.
	  q  :q  Q  :Q  ZZ     Exit.
	 ---------------------------------------------------------------------------

				   MOVING

	  e  ^E  j  ^N  CR  *  Forward  one line   (or N lines).
	  y  ^Y  k  ^K  ^P  *  Backward one line   (or N lines).
	  f  ^F  ^V  SPACE  *  Forward  one window (or N lines)
	-----

4. javax.servlet.http.HttpSessionListener
	需要在web.xml配置此Listener，以拦截session事件与统一session缓存配合使用

	+一致性哈希


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day315 Sunday, June 09, 2013

1. 
	* 落日弓web

2. 落日弓web
	继续day310第2条分析
	
	左边树的加载
		第一次取的是node=root的节点记录
		看DB对树形数据的存储结构定义：
			第一级节点：区域，定义在district表；
			第二级节点：大region，定义在big_region表，通过dc_id关联到district表，定义其属于哪个区域
			第三级节点：小region，定义在region表，通过big_region_id关联到big_region表；并且冗余存储了dc_id，room_id

	
	并行发布：
		多region并行发布；各个步骤的进度，各个region的进度
	
	工作流：
		抽象出每次发布的job，提供页面供选择以生成发布操作流；并支持自定义job已满足特殊操作。
	

3. openstack
	cloudxy

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day316 Thursday, June 13, 2013

1. 
	* 落日弓web

2. 落日弓web
	继续day310第2条分析	

3. spring mvc + extjs + JSR303验证规范
	一个例子：
	git clone https://github.com/wswijaya/spring-mvc-forms.git
	文档 http://myxaab.wordpress.com/2011/03/22/integrating-jsr303-with-spring-mvc-3-and-extjs-forms/

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day317 Friday, June 14, 2013

1. 
	* 落日弓web
	* 大region二期
		新增cn-fujian-ck-c02，76a集群，需要发布大region二期版本api，修改发布wiki增加步骤
		AG相同？
		DB相同
		现版本为二期之前的版本api


2. 落日弓web
	继续day310 

3. extjs * extjs
	对于js文件大的情况，可以考虑压缩源文件的方式，类似库文件都提供了压缩后的版本，用于生成环境。

4. MQ服务
	稳定
	HA
	消息持久化
5. acl
	-----
	API ACL规则梳理
	规则描述	 规则原因
	APIProxy机器要能够访问所有API Server机器的8080端口	 转发API请求
	APIProxy机器要能够访问houyi数据库，一般端口范围为3000到4000	 APIProxy需要根据ip/vm等信息查询在哪个region
	APIProxy机器要能够访问sls服务 （service.ols.aliyun-inc.com）	 推送日志
	API Sever机器要能够访问houyi数据库，一般端口范围为3000到4000；	 API访问自己的数据库
	API Sever机器要能够访问大Region中所有小Region的houyi monitor数据库，一般端口范围为3000到4000	 API访问Monitor数据库获取VM的性能信息。
	API Server机器要能够访问大Region中所有小Region的fuxi vip的31267端口	 http_proxy部署在fuxi上, api请求通过http_proxy转发
	API Server机器能够访问rabbitmq机器的5672端口	 状态同步
	API Taskserver机器能够访问houyi数据库，一般端口范围为3000到4000	 流量推送开关（region_need_statistics表）与推送日志（statistics_log表）等
	API Taskserver机器要能够访问大Region中所有小Region的houyi monitor数据库，一般端口范围为3000到4000	 获取vm监控信息
	API Taskserver机器要能够访问计量OMS服务（service.oms.aliyun-inc.com，内部生产集群不需要）	 计量服务
	API Taskserver机器要能够访问大Region中所有小Region的fuxi vip的32167端口	 获取vm公网ip地址
	API Taskserver机器要能够访问安全流量服务（10.135.252.105:8080，内部生产集群不需要）	 获取vm的带宽信息
	落日弓 AG要能够访问所有APIProxy、API Server、API Taskserver机器的22端口	 部署API服务
	AG要能够访问API Server的22端口与8080端口	 日常运维
	AY03-NEW的AG要能够访问内部生产集群的API Server/APIProxy/API Taskserver机器的22端口	 内部集群API发布机
	AY32C的AG要能够访问外部售卖生产集群的API Server/APIProxy/API Taskserver机器的22端口	 外部集群API发布机
	业务方要能够访问APIProxy vip	 外部调用
	-----

6. jetty，tomcat容器配置，一些部署环境的搜集整理

	BASE_BIN_DIR=`dirname $0`

	JAVA_HOME=/usr/ali/java
	JETTY_HOME=/usr/ali/jetty
	BASE_HOME=/home/admin/houyi
	JETTY_PORT=8080

	export TMPDIR="$BASE_HOME/tmp"
	export JETTY_PID="$BASE_HOME/logs/jetty.pid"
	export JETTY_LOGS="$BASE_HOME/logs"

	export START_INI="$BASE_HOME/start.ini"
	export JETTY_ARGS="--ini=$START_INI"
	export JETTY_CONF="$BASE_HOME/etc/jetty.conf"

	安装于部署分离，虚拟主机方式


7. notepad++
	free open source 
	plugin
	
	
	
Honeymon

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day318 Thursday, June 27, 2013

1. 
	* 落日弓

2. 落日弓
	去掉了python API层，整合到portal层，采用struts2+spring3+ibatis
	直接访问luorigong数据库

	现在的结构为：java暴露接口，AG上的python agent做任务，它们的交互通过MQ实现（之前的结构是python API与agent通过MQ交互，也不会直接相互调用）

	java端，采用Ext+JQuery方式，jquery搭建页面架子，组件用Ext生成并注入。

	采用spring配置事务，service间的事务通过传播传递

	python API部分：
		代码目录下的master.py定义了URI到接受请求的Handler的映射，handler的post，get等方法处理对应的http请求。
		逻辑包括与数据库交互，及与MQ交互

	工作：
		1）资源视图中，将原python API的逻辑移植到java web上
			原python API逻辑梳理
			java编码
		2）控制系统发布于扩容逻辑移植
			原逻辑梳理
			java编码
		3）前端由Ext MVC替换为Ext+Jquery，逐步过渡

	例子：
		参考已有的：资源视图-大region管理，熟悉页面js修改到逻辑从python API移植过来的过程。
		struts.xml的package定义namespace，action的name属性定义uri，通过下面在action uri和所请求的action方法名之间加上叹号的方式定位到方法，称为动态方法调用。
		参考* struts
		
		struts2请求方式：http://localhost:8080/luorigong/resourceManagerAction!listBigRegion.action?_dc=1372

		本项目改为，action，dao的spring配置通过spring注解实现（@Component，@Controller），但是service的配置还是在xml文件中并结合其他注解达到和xml配置一样的效果。
		eg:
		-----
		@Component("testAction")
		@Scope(BeanDefinition.SCOPE_PROTOTYPE)	 //定义scope
		-----

		action的返回都通过其result成员变量传递：
		-----
		<global-results>
			<result type="json" name="success">
				<param name="root">result</param>
				<param name="excludeProperties">
					data.*\.creatorUser,data.*\.modifyUser
				</param>
			</result>
			<result type="json" name="successByUser">
				<param name="root">result</param>
				<param name="excludeProperties">
					data.*\.modifyUser
				</param>
			</result>
		</global-results>
		-----
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day319 Friday, June 28, 2013

1. 
	* 落日弓

2. 落日弓
	extjs 找到组件对应的js文件，以进行下一步的编辑，可通过chrome的提供的信息来查看连接请求的js文件，此文件生成显示的内容组件

	以大region管理为例：
		找到ManageBigRegionGridPanel.js文件
		里面的render加载内容
		Action返回内容为List<BigRegionVo>数据结构，转为json格式；render根据json中的key映射到对应行的value。
		
		BigRegionVo这里为用于映射Ext的数据而定义的bean，本项目用于dao的bean也是单独定义的。
	
	实战：修改集群管理标签（先从显示列表页开始）
		1）找到对应列表页的js
			ManageClusterGridPanel.js

			下面的render对显示做了转换，比如从数值映射到文字描述，注意render的用法：
			-----
			columns: [	
				{
					text: '集群类型',
					flex: 1,
					dataIndex: 'type',
					renderer: function(value) {
						if (value === 'test') {
						    return '测试集群';
						} else if (value == 'native_sale') {
							return '对内生产';
						} else if (value == 'foreign_sale') {
							return '对外销售';
						} else {
							return value;
							alert('集群类型不合法！');
						}
					}
				},
			-----

		2）找到对应store所请求的URI
			store: 
				Cluster
				api: {
				    read: 'services/cluster/list.json',
				    create: 'services/cluster/create.json' 
				},

				BigRegion.js的store已改为：
				api: {
				    read: 'resourceManagerAction!listBigRegion.action'
				},
		3）根据URI从java代码中找到对应到后端API的URI
			从之前项目代码查看：services/cluster/list.json 转换为后端的URI
			spring servlet拦截/services/*请求，转到ClusterServiceImpl拦截/cluster映射，再到映射/list的方法

		4）根据后端URI找到python API的handler
			UrlUtil.getResourceClusterUrl() 获取请求后端的URI，再根据wiki API说明确定http请求类型（GET or POST or Others），或者直接从Bo代码中查看http请求类型。
			此处list方法为get类型

		5）分析对应接口逻辑
			从handle中找到db等操作
			lrgdb.py 封装了luorigong库的操作

		6）转为java实现
			Dao层继承父类DAO
			dao的实现，可采用回调模式Callback，避免太多的异常捕获等代码
			通过注解注入，Domain-Driven Design 


3. paxos
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day320 Monday, July 01, 2013

1. 
	* 落日弓

2. 落日弓
	MQ部分完善
		同步消息			
		异步消息
			一些任务的消息
		
		有发消息
		有收消息
		
		queue.py


	资源视图部分迁移功能到java（包含前后端）

	proxyaction添加
		去掉.action /.do配置，action=xxx.xxx，action对应值的的一部分为action名称，第二部分为方法名，实现action重用目的，解决action膨胀问题。
		通过proxyaction统一处理公有逻辑
		

3. rabbitmq 环境
	10.250.6.228
	rabbitmqctl

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day321 Tuesday, July 02, 2013

1. 
	* 落日弓
		ResourceTreeStore

2. 落日弓
	资源视图：
		1）左边树修改
			修改了action请求方式，对应修改代码部分
			ResourceViewTreeStore.js
				来自app的目录层次结构，reource/ResourceViewList.js
			ResourceTreeStore
				中间树store
				根据这里的定义，找到每个panel的定义：
					ManageBigRegionGridPanel.js
						从而找到具体的操作store等的定义
						store: BigRegion.js
			
			ManageBigRegionGridPanel.js
				大region管理列表显示页
				然后找到Form的定义：
					AddBigRegionForm.js
					用到了各个store，修改对应url即可
				双击修改form：
					UpdateBigRegionForm.js
					原update逻辑在BigRegionServiceImpl.java.java中
		2）集群管理		
			manageClusterGridPanel
				

	结合现有javaweb代码+python API代码，转为java代码
		ClusterServiceImpl.java
			这里的逻辑为主
			将原查询API获取的数据用sql代替
			逻辑不变，比如用到哪些字段，完全移植即可
		python API中逻辑为sql查询操作
	


3. 控制系统部署流程说明
	资源视图-配置新建小region的各种资源信息
	控制系统-

4. svn update后，配置文件中汉字有乱码
	待分析


5. struts2 json插件 * struts2
	默认不支持父类bean的属性转换，可以配置，如下：
	-----
	<global-results>
		<result type="json" name="success">
			<param name="root">result</param>
			<param name="ignoreHierarchy">false</param><!-- 配置此处，支持父类属性的转换，否则不会转换父类的属性 -->
			<param name="excludeProperties">
				data.*\.creatorUser,data.*\.modifyUser
			</param>
		</result>
	</global-results>
	-----

6. 多线程问题
	由于ExecuteActionFactory,getExecuteAction(String name) ;方法返回的是自己的缓存集合，每次返回的都是单例，需要注意多线程问题。
	目前方案为Action实现中，不放全局可变的成员变量。

6. 
	idc_id: room表id
	dc_id: area表id，area为逻辑概念，对应district表，从而有了dcId的命名

	district即area
	room即idc即机房
	
	bigregion
	apibigregion 页面封装bean，即现在的vo
		ApiModel2WebModelTransfer.java做转换工作
	
	BeanTransformUtils类的转换，看之间的转换关联关系
		依据先的vo到dao bean映射来修改
		可参考老的api bean定义

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day322 Wednesday, July 03, 2013

1. 
	* 落日弓

2. 落日弓
	1）
	vo与bean的对应关系
	大region管理：
		列表页面-realserver列的值关联自big_region_realserver表，其为big_region表和realserver表的中间表
		在BigregionDao中增加操作big_region_realserver中间表的接口做级联操作

		bigregionrealserver表dao操作编码
			查询时直接关联查询
			增加和更新独立定义

	
	
	DAO测试时，创建记录语句需要结合ibatis的key select配置来返回id
	-----
	<selectKey resultClass="long" keyProperty="id">  
    	<![CDATA[
    	SELECT LAST_INSERT_ID() AS ID 
    	]]>    
	</selectKey>
	-----

	resourcedao, resourceserver中关于bigregion的功能移到bigregion相关的层中去。



	有些事务涉及的并发处理操作很多,将其称为大事务
	
	2）cluster 集群管理
		列表页面内容参考原javaweb逻辑
		请求后端URI: 
			/resource/cluster，根据传入的参数返回不同的列表内容
				district_id
				big_region_id
				room_id(idcId)
				id：clusterId

		根据 /resource/cluster 找到：
			orange/webapp/master.py -> ResClusterHandler -> ResClusterHandler.py	
			SQL语句定义在 lrgdb.py中
		
			Cluster的sql查询，都在region表中，cluster表自身没用到

			Service，Dao还是以cluster命名，具体操作指向到region表

		到room表查询idc的name信息：
			/resource/room
		
		小节：
			集群列表页面为，从region表查基本数据，然后到关联字段对应表找详细信息注入后，响应给用户
			改为sql关联查询
		
		EXTJS
			store的定义中
			reader: {
			    type: 'json',
			    root: 'data'
			}
			root表示json的数据节点key，具体的内容从此key对应的json对象中获取

		原资源查询都支持根据请求的参数对结果进行筛选，比如bigregion查询，可以根据区域dcId、机房idcId、id或所有数据等。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day323 Thursday, July 04, 2013

1. 
	* 落日弓
2. 落日弓
	1）集群管理/Cluster
		list
		add
		edit
	clusterDao移入regionDao，表与dao对应；clustter的逻辑写在regionDao中

	2）网段管理/NetSpace
		ManageNetSpaceGridPanel.js
		NetSpace.js
		原list请求URI=services/netSpace/list.json

		对应 subnet 表	 ，关联字段及对应表如下：
			room_id	room表
			vlan_id	
			trans_id
			zone_id
			region_id	region表

		store配置好json值对象的key名称为：root: 'data'

		form中的store取数据触发逻辑，写在了双击触发弹窗的gridPanel文件中（逻辑无处不在啊）

		idc / room
		涉及 room 表：
			dc_id：与district表的id映射，即与area/district区域关联




4. jtester框架的事务与测试方法事务不在同一事务中？
	待


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day324 Friday, July 05, 2013

1. 
	* 落日弓

2. 落日弓
	1）extjs更新form值回显逻辑	* Extjs form表单相关
		以ManageNetSpaceGridPanel.js为例
		弹出更新表单定义在双击事件中，回去加载表单用到的store，store中的model定义，与store请求所返回json的映射配置。
			注意：这里服务端返回的json对象，要与store的model一一对应，并且属性类型也许一致。-tip-
			vo全部用String类型

		UpdateNetSpaceForm.js

		LuoRiGong.store.Cluster
		LuoRiGong.model.Cluster

		grid页面的clusterId字段为null，导致回显映射失败；grid页面的双击触发更新form页面逻辑中，回去form中用到的store取数据，并与grid中此行的record对应，
		从而显示原值。
		通过调试，发现grid列表页的json值中，clusterId为null，虽然此列的显示值不为空；extjs的映射是根据key对应的value来处理的，显示出来了代表value也不为空。-tip-

		服务端返回数据，填充进store，页面从store中取数据，store的数据受model定义，如果model未定义则页面取不到数据。
			服务端返回的json，store中的model，grid中的dataindex，form中的name

		熟悉extjs的grid和form中，那些关键属性，显示属性，值属性等等。
			Grid中列的值为dataIndex属性指向store取回json对象的key对应的value
			Form中的name，等属性，要在对应的store中找到值，若为null则无法显示。
	2）网段管理
		更新
			更新机房时，数据被移到其他机房下面显示了，不是问题，注意下；因为，现在的数据基本上是根据机房筛选显示的。
	3）集群管理
		新增
			拿到：big_region_id、room_id、region_type、
			根据big_region_id查询并更新bigregion 的ossId等数据
				cluster_id =big_region['cluster_id_curr']
				oss_id = big_region['oss_id_curr']

			下面为插入region逻辑：
			lrgdb.py
			-----
			def region_add(self, room_id, big_region_id,
			    cluster_id, oss_id, info):
		    
			now = get_time_now()
		    
			big_region = self.big_region_get_by_id(big_region_id)
		    
			result = \
			    self.db.insert('region', 
				big_region_id = big_region_id,
				room_id = room_id, 
				oss_id = oss_id,
				cluster_id = cluster_id,
				dc_id = big_region.dc_id,
				cluster_name = info['cluster_name'],
				region_type = info['region_type'],
				#mac_start = info['mac_start'],

				#add default value
				pangulog_checkpoint_freedisk_limit = 0,
				netc_iptable_version_checkout_time = 300,
				nc_iptable_version_checkout_time = 600,
				master_with_macnat = 0,
				master_memory_low_ratio = 50,
				pangu_app_copy = "1-1,2-3",
				vcpu = 40,
				vmemory = 80000,
				vdisk = 6000,

				gmt_create = now,
				gmt_modify = now,
		    
		       )
			-----

			修改bigregion表字段时，通过select for update保证原子操作

	4）DNS管理
		extjs使用时，js文件验证安装mvc分目录，以及根据业务区分不同的子目录，很方便查找文件做维护修改 -tip-

		ManageDnsGridPanel.js

		业务简单，只关联room表
		从ibatis mapping文件，到dao，到service，到单元测试的步骤
	5）嫦娥管理
		ManageMoonmmGridPanel.js
		
		表：moom_mm，只以room_id关联room表

		以Dns的一套为模板拷贝修改


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day325 Monday, July 08, 2013

1. 
	* 落日弓

2. 落日弓
	6）代码源管理
		from dao to action

		md5字段的赋值逻辑，页面无此字段

		表：codesrc
	7）数据库管理
		表：odbs
	8）MQ管理
		表：mq
	9）HouyiAPI域名管理
		表：houyiapi

3. apache common lang包
	StringUtils.indexOfAny(str,str[])
		提供在指定字符串中，查找目标字符串集合中的一个的工具方法
	containsAny(String str, char[] searchChars)

4. svn目录release下，有sql变动
	涉及一些资源加了 product 字段，标识资源属于哪个产品线
		产品线参数设置默认值，不允许修改；系统自动在对应的产品线页面上注入值

	odbs表，将关联id的横向标识，代替为一个db_type加id来一起标识，无需因为产品增加odbs表就增加对应的外键定义。

5. 面向服务端编程

6. java 反射
	通过反射调用业务方法时，jdk的调用方法已经封装了反射过程中会出现的各种异常，如果上层业务关心异常的类型，可以通过InvocationTargetException提供的getTargetException()方法
	来获取业务层实际的异常。

7. Extjs Form提交显示问题
	form异步提交数据后，根据返回是否成功做不同提示。
	看form的文档说明
	-----
	form.submit({
		url: 'services?action=mqAction.update',
		method: 'POST',
				
		success: function(form, action) {
			Ext.Msg.alert('Success', action.result.msg);
			Ext.ComponentQuery.query('updateMqForm')[0].close();
		},

		failure: function(form, action) {
		switch (action.failureType) {
				    case Ext.form.action.Action.CLIENT_INVALID:
					Ext.Msg.alert('Failure', '表单内容不合法！');
					break;
				    case Ext.form.action.Action.CONNECT_FAILURE:
					Ext.Msg.alert('Failure', '连接错误');
					break;
				    case Ext.form.action.Action.SERVER_INVALID:
				       Ext.Msg.alert('Failure', action.result.msg);
			       }
		}
	});
	-----
	{"code":2,"data":null,"forward":"success","info":"通过反射动态调用函数异常","success":false,"total":0} 走failure逻辑
	若success为true则走success逻辑
	
	form方式提交表单时，ext框架默认更新返回json中的success字段的为true还是false，从而认为提交是否成功。-tip-
	看Ext.form.Basic的例子：http://docs.sencha.com/extjs/4.2.1/#!/api/Ext.form.Basic-method-submit submit方法说明



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day326 Tuesday, July 09, 2013

1. 
	* 落日弓

2. 落日弓
	关于使用jtester测试时，dbfit做的sql操作和到的操作事务互不可见的原因分析？
		现象为dbfit准备数据，dao逻辑看不到；且dao 的事务会提交而不是和测试框架的事务一样在测试方法结束后回滚

	根据已有jtester测试dao正常的项目为例，并结合dao操作时源码debug分析，发现当前有问题项目的dao，在测试时，会开启新的db连接和事务，但正常的
	测试dao例子中会取已有的连接和事务。

	于是看两者的dao配置，同样都是用org.springframework.orm.ibatis.SqlMapClientTemplate类，一个是在spring里注入了sqlMapClient对象及其datasource；另一个
	是直接配置了sqlMapClient对象并注入datasource，然后获取SqlMapClientTemplate类来使用。
	原方式：public class BaseDao extends SqlMapClientDaoSupport { 其他dao继承baseDao，然后在baseDao通过注解注入org.springframework.orm.ibatis.SqlMapClientFactoryBean返回
	的sqlMapClient。

	两者的SqlMapClientTemplate实例中datasource成员变量，正确的为null，有问题的是有datasource的

	问题：阻塞在sqlexecutor的executeUpdate

	Dbfit如何处理事务？
		jtester采用自己的db配置生成datasource实例，并提供spring容器中的datasource实例，以保证测试框架和业务程序使用相同的datasource。

	JTesterClassPathXmlApplicationContext 提供了proxy datasource来统一进行dao操作，
	但本项目却debug不进来，why？
		在debug链上看getbean的调用关系，
		JTesterSpringTestListener的beforeTestSetUp方法，进行测试方法前的初始化
	
	10）RealServer管理
		表：realserver

	11）Aresolve管理 大禹客户端管理
		表：aresolve
		Wiki : /resource/aresolve
		dao test ok then front-end

		eclipse其配置好的tomcat:run

3. 区域、机房等资源增加产品标识字段
	增加product字段标识此资源所属的产品

	相应的一级资源树那里，将所有资源改为ESC，并增加2个并列的SLB、OSS
		
	
4. 		

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day327 Wednesday, July 10, 2013

1. 
	* 落日弓

2. 落日弓
	其他资源移植，及odbs表结构变动修改
			create	list
	District	done		done
	Region	done
	CodeSrc
	Subnet	done
	Room	done
	Odbs	done
	这几个类查询时需要加product字段过滤，在action层传入产品product类型给service层,service层传入product参数以根据产品类型筛选数据。

	12）Slb管理
		slb表
		slb_region表在其他地方产生关联，此处只是slb单表操作

		提供根据dc_id区域查询条件，关联到room表的dc_id
	13）RDS管理
		rds表
		lrg.py 单表insert操作

		Extjs对表单字段的验证支持，通过使用内置的Filed来保证，比如ip filed，会自动校验是否为ip格式 * extjs
	14）OTS管理
		ots表

	处理odbs表结构变更，以及一些资源表增加product字段以标识其所属于的产品。
		页面不动，根据不同类型，修改bean并持久化
	
	15）区域管理
		在resourceAction中

		ResourceViewList.js 左边一级树页面js文件
			store: ResourceViewTreeStore.js


		ManageAreaGridPanel.js

	16）机房管理

	区域>机房>

	注：资源视图的树，区域下要显示机房，需要此区域下有大region记录，才会出现+号

			


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day328 Thursday, July 11, 2013

1. 
	* 落日弓
2. 落日弓

	action的命名，包位于控制系统包下，action名称自定义
	
	1）控制系统-资源申请- ImageSlbVip申请
	container:
		ClusterResourcePrepareContainer.js
	fieldSet:(类型：字段集合)
		ImageSlbVipApplyForFieldSet.js
		按钮逻辑在此filed的事件中
	ViewImageSlbVipsWindow.js 查看列表页
		url: services/slb/viewImageSlbVips.json
	
	SlbVipHandler.py
	
	表：region_slb slb产品属于哪个region的关联表
			region_id,
			slb_id
			记录region和slb的关联关系

			slb_usage_type 记录此region下的slb的使用类型，目前有：ecs（内部ecs产品使用），forsale（对外售卖用）

		slb slb产品主表
			room_id 关联机房

		region region表

		lb_info slb产品下具体lbId等消息表，为slb的子表
			slb_id关联slb表


	2）控制系统-集群配置-生成数据库SQL
		对于houyi库，已提供接口，参考其文档说明



3. mq
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day329 Friday, July 12, 2013

1. 
	* 落日弓

2. 落日弓
	部分资源加了product字段，在操作时（新增、查询等）注意其逻辑，避免筛选过滤时出现数据不一致问题

	1）SLB VIP申请

	2）houyi数据库导入
		通过houyi api提供的几个接口，将新一个集群即region需要的数据，导入houyi库
	3）Ext.tree.panel
		有例子，位于extjs文档的guide的tree中

		doing
	4）控制系统-集群部署-部署飞天客户端	
		熟悉java端构造数据，将job名称，后端function名称（job表）等信息，发送到MQ，然后MQ会广播消息，各个agent收到消息后，判断是否为自己感兴趣的消息，
		做相应处理。


3. 将业务实现和使用的第三方库或组件交互的地方，抽象出一层做转接，避免直接内嵌在业务逻辑中使用，那样后续不方便替换实现，也不便于单元测试。-tip- 设计
	将关联其他组件的地方，都抽象出来；具体业务只与抽象层依赖，抽象层可以通过IOC替换具体实现。
	

4. URL编码，
	slb创建vip的请求中有json串参数，请求前先进行url编码，http请求会报不合法

5. extjs button事件处理
	-----
	handler	: function(button, e) {
			Ext.Msg.prompt('申请EcsVip', '请输入申请VIP数量:', function(buttonId , text) {
				if(buttonId == 'ok') {
					if (Ext.isNumeric(text)) {
						Ext.Ajax.request({
								url: 'services?action=resourceApplyAction.applyForImageSlbVips',
								method: 'POST',
								params: {nodeId: clusterId, type: 'clusterId', num: text},
								timeout: apiMaxTimeout,
								
								callback: function(options, success, response) {
									if (success) {
										var responseTextObject = Ext.JSON.decode(response.responseText);
										if (responseTextObject.success == true) {
											var store = Ext.getStore('ImageSlb');
											store.loadRawData(responseTextObject.data);
											var win = Ext.create('LuoRiGong.view.datacenter.window.ViewImageSlbVipsWindow');
									win.show();
										} else {
											Ext.Msg.alert('失败', responseTextObject.info);
										}
									} else {
										Ext.Msg.alert('失败', '服务器内部错误，解析错误或者连接超时');
									}
								}
							});
					} else {
						Ext.Msg.alert('提示', '请输入一个数字！')
					}
				}
			}, window, false, '1');
	-----
	PS: 具体属性看文档说明

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day330 Tuesday, July 16, 2013

1. 
	* 落日弓

2. 落日弓
	1）落日弓slb vip申请，action加页面修改
	2）控制系统-集群配置
		（1）从部署神农开始
			逻辑可参考原javaweb+python api的逻辑

		ClusterConfigOperateFormPanel.js
		-----
		items: [
			{
					xtype: 'splitbutton',
				text    : '部署神农',
					    handler	: function(button, e) {
						var requestUrl = 'services/dayu/deployShennong.json';
						btnAjaxRequest1(requestUrl, clusterId, button, successTrueFn1, successFalseFn1, failureFn1);
					    }
				    }
		-----
		PS: 按钮都定义在form对象的items集合中
		原请求url为：services/dayu/deployShennong.json
		btnAjaxRequest2 方法为工具方法中的一个，定义在 globalutilities.js 中 ， successTrueFn1等回调方法的定义也在此全局js文件中定义。
		
		原入口：DayuServiceImpl
			java web端部署神农的逻辑，由于和其他大部分nc部署操作类型，目前都是通过dayu来部署的，故java web定义了一个deployDayu方法，通过不同参数，
			实现不同操作功能。
			已写好service层定义，在 DayuService中，其实现继承了OperateAbstract类，用于抽象调用dayu共用的组装参数逻辑（不同调用间共用参数较多，避免重复逻辑）。
				组装dayu参数时，涉及dayu_path表记录一部分数据，主要为一些常用命令、脚本，配置的路径及名称等（比如：bin_me名称指向/bin/me命令路径，再比如落日弓脚本
				的目录等），以此定位命令脚本等的目录位置。

				另外，dayu客户端执行时，需要roledef_src，roledef_updated两个配置项，这个应该是dayu自身定义的参数 OR python api会再转换？

		dayuservice组装好参数后，交给mqservice进行消息发送，参数格式为：action名称+参数对象
			mq的发送消息逻辑：
				a. 根据action名称及job名称，从job表找到对应的job消息，从而拿到此job对应干活agent所要执行的function（job表的agent_func_name字段）
					此次设计job的3张表：job，job_instance,job_workflow
					workflow,workflow_instance
				b. 根据之前构造的Map参数对象中的region对象，拿到要请求到的agent的名称（以region.getClusterName()为agent名称）
				c. 将构造好的map参数对象，再作为值放入请求agent的请求参数map中，丢到mq中广播
				d. 处理mq返回结果，ok的话就将此新job持久化到job_instance表中；否则报错
		
		由于ecsDayuAction.deployShennong没有在job表定义，无法连调，待？
		
		（2）停止盘古
			URL: services/apsara/stopPangu.json
				定位到原 apsaraService ，并处理现有的 apsaraService
				PS: 此按钮用到了飞天操作的service类，之前为dayu操作，小节下就是，具体的nc操作可以归为几个大类，对应几个service及实现
			
			job名称：ecsApsaraAction.stopPangu

			在原组装参数基础上，再组装进pangu的一些参数
				组装参数的逻辑，写在原来的python api端，需要阅读，根据java web传入的action定位到python代码逻辑。 
				注：java web的action到后端python的映射定义在ApiAction类中，里面注释了请求的url格式，比如飞天操uri为： /job/apsara，dayu为/job/dayu等
					apsara: JobApsaraHandler.py
					dayu: JobDayuHandler.py

					java web传递参数给python api，api来组装参数并发送消息给mq

			然后和（1）一样，丢消息给mq并处理响应


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day331 Wednesday, July 17, 2013

1. 
	* 落日弓

2. 落日弓
	1）继续：控制系统-集群配置
	（3）添加盘古APP
		ClusterConfigOperateFormPanel.js
		JobApsaraHandler.py
		-----
		 def post(self):

			try:
			    body  = self.request.body
			    body  = json.loads(body)
			    param = body['param'] if body.has_key('param') else {}
			    if body.has_key('cluster_name'):
				cluster_name = body['cluster_name']
			    
			    if body.has_key('region_id'):
				region_id = body['region_id']

			    action = body['action']

			    region = self.db_api.region_get_by_cluster_name(cluster_name)

			    job = "ApsaraWorker.ApsaraJob.%s" % action
			    param['region'] = region
			    param['env'] = self.db_api.config_path_to_dict()
			
			    getattr(self, action)(cluster_name, job, param)

			    self.write({'code' : 200, "msg" : 'OK'})

			except Exception, e:
			    self.write({'code' : get_code(e), "msg" : wrap_exc(self.logger, e)})
		-----
		PS: 上面这个post方法，处理javaweb发送来的飞天job命令；具体的路由是通过action名称，以getattr方法将action名称映射到方法名称，从而调用对应的方法（具体见getattr方法
		方法注释说明）。-tip- python getattr方法	* python
			getattr方法注释
			-----
			getattr Found at: __builtin__
			getattr(object, name[, default]) -> value
			    
			    Get a named attribute from an object; getattr(x, 'y') is equivalent to x.y.
			    When a default argument is given, it is returned when the attribute doesn't
			    exist; without it, an exception is raised in that case.
			-----
			PS: getattr(x, 'y') is equivalent to x.y

		javaweb调python api的：
			action=add_pangu_app
		
		clusterName为region.getClusterName()，即为AgentName，后续会发送消息到MQ，对应此名称的agent应该消费此消息。
			mq客户端发布消息默认为async，通过锁的方式(线程同步)在异步基础上实现同步。

		从而了解整体调用流程。

		取到pangu app数据，根据clusterName取到对应的db，db从odbs表获取（里面有db类型标识）houyidb，从而获取对应集群db中pangu app数据。
			根据odbs中db的配置信息，创建db连接来使用。

		使用spring提供的jdbctemplate来执行第二方DB的操作。

		db.select('pangu_app', what='*', _test=_test)	      ？这里_test作用是什么？
			db为orange/orange/database.py
			self.db = web.database(dbn='mysql', host=host, port=port, user=user, passwd=passwd, db=dbname, mincached=mincached)

		看houyidb的pangu_app表
			app_name 
			min_copy 
			max_copy
			zone			

		python appent方法
		-----
		for n in nc_zones:
		    if not r.has_key(n.zone_id):
			r[n.zone_id] = []
			self.logger.debug('get zone: %s' % n.zone_id)
		    r[n.zone_id].append(n.ip)
		    self.logger.debug('zone %s append nc %s' % (n.zone_id, n.ip))
		-----
		PS: append方法是list(列表)的方法，在列表最后加上这个元素

		添加panguapp的具体逻辑是否有描述？

		actionName=ecsApsaraAction.addPanguApp

		模式为，有共同参数，对应不同操作，有相应细节参数需要加入

		查看LOG功能的实现：
			JobLogStatusServiceImpl.java
			逻辑在globalutilities.js中
				getLogFromOffset1方法
				setLogTask方法
			url： services/jobLogStatus/getJobLog.json
				后端url：/job/log
					JobLogHandler.py

			根据参数从服务端取log数据，并render到指定按钮查看日志窗口中
	（4）停止KV
	（5）启动KV
	（6）添加KV
	（7）启动houyi
		url: services/houyi/startHouyi.json

		job表action_name - agent_func_name映射
	（8）启动arproxy
	（9）重启tdc
	（10）创建monitor表
	（11）同步rc.local
		url: services/env/syncRcLocalForDeploy.json
		/job/env
		JobEnvHandler.py

		目前template文件放在class路径下
	（12）同步rc.sysinit
		参考第11步
	（13）API接入
		url: services/houyiApi/reloadHouyiapiCache.json

		HouyiApiService

		BaseHandler 在webx.py文件中定义
	（14）APIPROXY发布
		pass 功能在另一个页面处理

	（15）NC解锁
		url: services/clusterConfigOperate/unlockNcList.json
		/job/pet

		nc，vm操作通过pet执行

		insert into job(name,component,owner,job_type,need_param,action_name,description,agent_func_name) values('环境检查','houyi','shangshu@alibaba-inc.com','system',0,'clusteredDeployAction.checkEnvironment','precheck','EnvWorker.EnvJob.precheck_cluster');
		agent的function名称和之前保持一致

		原action统一作为function名称
			pet操作，job的actionFuncName为共用，在参数中传入action给agent以确定具体的操作；
			其他job都是唯一的funcName
		
		初始化job数据：
		insert into job(name,component,owner,job_type,need_param,action_name,description,agent_func_name) values('NC解锁','houyi','shangshu@alibaba-inc.com','system',0,'ecPetAction.unlockNcs','unlock ncs','PetWorker.PetJob.run');

		job发送后，根据uuid来标识每个job（如后续的日志查看等需要）

		干活Agent的log查看：
			agent地址： 10.250.6.228-atzy
			log目录：tail -f /tmp/orange/orange.jobmaster.debug.log
		
		log查看查看log.js请求JobInstAction


		





		



	2）region表的默认值，sql定义了默认值，若程序中为null则不执行插入，保持db默认值
		product字段





+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day332 Thursday, July 18, 2013

1. 
	* 落日弓

2. 落日弓
	继续day331第二条

	ClusterConfigOperateFormPanel.js


	
3. java获取当前路径
		//This will print a complete absolute path from where your application has initialized.
		System.getProperty("user.dir"));

		D:\workspace2\luorigongweb3
		\

4. python
	file.read()方法
	-----
	file.read([size]) 
	Read at most size bytes from the file (less if the read hits EOF before obtaining size bytes). If the size argument is negative or omitted, read all data until EOF is reached. 
	The bytes are returned as a string object. An empty string is returned when EOF is encountered immediately. (For certain files, like ttys, it makes sense to continue reading after an EOF is hit.) 
	Note that this method may call the underlying C function fread() more than once in an effort to acquire as close to size bytes as possible. Also note that when in non-blocking mode, less data 
	than was requested may be returned, even if no size parameter was given.
	-----
	PS: 搜索read，找到file method

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day333 Friday, July 19, 2013

1. 
    * 落日弓

2. 落日弓
	日志查看功能
	页面提供：componentType、componentId、offset、jobName参数
	根据jobName找到job，再去查询jobInst，最后去agent查询日志数据

	buttonTextToUrlMapping.js 定义了每个按钮的jobName

	componentId对应到业务表id，比如houyi类型的到region表
	
	请求到不存在的region，导致等待超时

	插入job记录时，根据原job名称，action名称，插入记录；一个job会有多个action操作


	API接入job初始化：
		insert into job(name,component,owner,job_type,need_param,action_name,description,agent_func_name) values('API接入','houyi','shangshu@alibaba-inc.com','system',0,'reload_houyiapi_cache','reload api cache','HouyiAPIWorker.HouyiAPIJob');

	Agent的python逻辑，在master.py中，main方法是其入口，消费MQ的消息，并交给callback函数处理。

	agent_fun_name为3段式，对应agent代码的：handlerName + className + functionName 
		eg: HouyiAPIWorker.HouyiAPIJob.reload_houyiapi_cache
		HouyiAPIWorker.py + HouyiAPIJob(class) + reload_houyiapi_cache(function)

		PetWorker.PetJob.run 此job就一个function，里面的具体操作依据参数中的action来定位
			

	异步job，执行后的状态如何回显？
		job发送到mq后，状态为running，直到mq收到agent工作结果状态并更新job状态后，页面才会定时刷新此状态

	集群配置
	（1）创建VM
	pet操作直接操作，不发送mq？

	。。。

	（1）部署QA代码
	javaweb- handler - worker
		在handler层将jobName和actionName组合为 3段式结构
		



3. get方式对汉字需要编码处理，或用post请求


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day334 Monday, July 22, 2013

1. 
	* 落日弓

2. 落日弓
	1）机房添加后，要显示下级，需要手动DB添加大region信息。
	2）连调测试集群配置
		与agent连调，经过mq
	3）资源视图变动
		原大region管理，去掉realserver列显示
			修改表单也去掉realserver表单项
		原realserver管理，加上大region列显示（从big_region_realserver取关联关系）；
			增加realserver的表单中，增加2种类型（RMS,RHS），并增加vip表单项；注：houyiapi的vip在houyiapi表中
	4）代码源命名变化修改
		store定义修改：SourceCodeType.js
		extjs render修改：gridColumnRenderer.js


3. jtester测试
	datasource未被代理proxy datasource替换，原因？
	debug JTesterClassPathXmlApplicationContext的getBean方法，此处会替换被使用的dataSource实例。

4. luorigong数据库部分表有默认值情况，采用默认值，insert语句不包含哪些列

5. jdbctemplate ，DriverManagerDataSource
	因为事务，连接未自动关闭（放到线程上下文ThreadLocal中了）
	-----
	public static void doReleaseConnection(Connection con, DataSource dataSource) throws SQLException {
		if (con == null) {
			return;
		}

		if (dataSource != null) {
			ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource);
			if (conHolder != null && connectionEquals(conHolder, con)) {
				// It's the transactional Connection: Don't close it.
				conHolder.released();
				return;
			}
		}

		// Leave the Connection open only if the DataSource is our
		// special SmartDataSoruce and it wants the Connection left open.
		if (!(dataSource instanceof SmartDataSource) || ((SmartDataSource) dataSource).shouldClose(con)) {
			logger.debug("Returning JDBC Connection to DataSource");
			con.close();
		}
	}
	-----

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day335 Tuesday, July 23, 2013

1. 
	* 落日弓

2. 落日弓
	1）日志查看功能
		修改 buttonTextToUrlMapping.js ，jobName设置为agentFuncName
		修改DataCenterList.js（搜ConfigMenu），在动态配置按钮时，修改componentType的houyi 为houyictrl，原houyiapi，apiproxy类型不变

		jobName，componentType，offset，传给服务端即可
	2）realserver资源视图，修改		     extjs 取表单，取表单项 * extjs
		AddRealServerForm.js
		-----
		,
						
		{
		xtype: 'combobox',
		fieldLabel: '类型',
		store: 'RealServerType',
		queryMode: 'local',
		valueField: 'type',
		displayField: 'displayName',
		typeAhead: true,
		forceSelection: true,
		emptyText: '选择RealServer类型',
		name: 'type',
		listeners: {
			select: function(combo, records, eOpts) {
				VipField = combo.nextSibling('textfield[name="vip"]');
				bigRegionCombobox = combo.nextSibling('combobox[name="bigRegionId"]');
				if (combo.value != REALSERVER_TYPE_APIPROXY) {
					bigRegionCombobox.setVisible(true);
					if(combo.value == REALSERVER_TYPE_RHS){//rhs
						VipField.setVisible(true);
					}else{
						VipField.reset();
						VipField.setVisible(false);
					}
				} else {//apiproxy
					bigRegionCombobox.reset();
					bigRegionCombobox.setVisible(false);
					VipField.reset();
					VipField.setVisible(false);
				} 
			}
		}
		},
		-----

		双击，弹出更新表单，也需要根据不同type显示对应的表单
		-----
		itemdblclick: function(me, record, item, index, e, eOpts) {
			var win = Ext.create('LuoRiGong.view.resource.forms.UpdateRealServerForm');
			VipField = win.down('textfield[name="vip"]');
				bigRegionCombobox = win.down('combobox[name="bigRegionId"]');
				rsType = record.get('type');
				if (rsType != REALSERVER_TYPE_APIPROXY) {
					bigRegionCombobox.enable(true);
					bigRegionCombobox.setVisible(true);
					if(rsType != REALSERVER_TYPE_RHS){//rhs
						VipField.disable(true);
						VipField.setVisible(false);
					}
				} else {//apiproxy
					bigRegionCombobox.disable(true);
					bigRegionCombobox.setVisible(false);
					VipField.disable(true);
					VipField.setVisible(false);
				}
				...
		-----
		PS: 双击grid的行时，获得record对象，从而获取列值
			通过win.down(xxx)方法，获取将要打开窗口中的表单项

	3）代码源
		类型中，去掉后羿API源，并入后羿源；并写数据订正脚本到sql中提交svn
	4）初始化job的agentFuncName
		即java服务端设置job名称并给agent去执行，此agentFuncName与agent的jobXXXhandler中定义的job名称+函数名称匹配。

	
3. extjs定义全局变量
	定义变量在js中，在页面上提前include加载，后续的js代码可以引用 ；此即为js所支持的；

	extjs的debug可以在chrome的工具中进行

	通过alert(xxx),打印信息。
4. 更新DAO对象时，如果会有因为type的不同，某些列会变化的情况，可以显式的设置0或空，以避免与dao mapping中定义的非null才更新的逻辑。-tip-
	对于有关联表的情况，会更复杂，看情况可以限制修改某些表单，通过删除记录，重新建来支持。

5. 
tail -f /tmp/orange/orange.jobmaster.debug.log -n 300

6. agent的job抽象
	根据操作的工具即组件的不同，抽象出一组组的job。如：env，houyi ，apsara，apsara_client,arpproxy,houyiapi ,file etc.

	jobXXXhandler为原接受java web请求的处理类，它处理后会继续发给mq，由agent消费消息并执行具体job。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day336 Wednesday, July 24, 2013

1. 
	* 落日弓

2. 落日弓
	集群部署

	ClusterDeployOperateFormPanel.js 按钮页面

	ClusteredDeployAction.java

	1）安装iptables mock
	2）安装大禹客户端 Aresolve
	3）安装大禹 dayu
		jobdayuhandle.py中下面的逻辑，没出现在dayuservice实现中？ 重写baseParams方法中已处理
		param['roledef_src'] = "%s/dayuroledef" % \
                self.db_api.config_path_get_by_name(PATH_DIR_LUORIGONG)
            param['roledef_updated'] = "%s/dayuroledef_updated" % \
                self.db_api.config_path_get_by_name(PATH_DIR_LUORIGONG)
	。。。
	部署OSS Server
	dayuservice
	ossserverservice
	...

	=== 从ApiAction定义中的注释，找到对应的jobXXXhandler，进入逻辑 ===

	资源视图-左边树
		新增一个区域 ，在此区域下增加一个机房，机房无法显示，db数据正确，分析原因？
		DistrictAction.listResource

	定时刷新Llog功能修复：
		js循环调用jobInstAction.viewLog，以显示日志并更新按钮执行状态。

		globalutilities.js中定义的setLogTask方法为定时刷新任务逻辑。
		此时报错，查看请求参数是jobName为空，到服务端时报错

		logTextArea.addListener('change', function(logTextArea, newValue, oldValue) {
			setLogTask(logTextArea, newValue, oldValue, jobName, componentType, componentId);
		});
		PS: 可以看出，只有当textarea产生change事件时，才会触发setLogTask方法，从而去刷新textarea的内容。
		点击“查看日志”时，会去服务器取数据并填充到textarea中(textarea.setValue(xxx)参考extjs DOC)，此时应该触发change事件。
			没有触发原因是，返回对象的key名字变了，改为正确的key即可取到数据，从而填充textarea。done

		globalutilities.js的genJobStatusTask方法，会刷新按钮的执行状态；它是通过Job.js这个store来发送ajax请求的。
		在 ClusterOperatePanel.js 中初始化了刷新job状态的任务逻辑，在tab change事件触发时做相应处理。
		原逻辑，Action有一个getJob方法返回job列表数据（job名称，状态等信息），js遍历job并更新页面上对应job的状态。
			lrgdb.py中job_get方法返回的数据
			componentType：区分job类型，为houyictrl、houyiapi，apiproxy
			componentId：区分job类型对应的id，即如果type为houyictrl则为clusterId，若为houyiapi则为realserverId

			比如：取出集群部署页面所有job按钮的最新job信息。

			action返回job状态信息后，页面js进行处理。genJobStatusTask


3. 测试jtester事务问题
	测试框架事务与dao事务不一致？
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day337 Thursday, July 25, 2013

1. 
	* 落日弓

2. 落日弓
	1）根据 ClusterOperatePanel.js 页面传入的componentType类型，修改对应job的类型
		houyictrl
		houyiapi
		apiproxy
		它们已划分到不同的Tab页作为集合。

	2）控制系统-扫尾
	ClusterOperatePanel.js -> ClusterConfigOperateEndFormPanel.js 即为扫尾页面
	（1）添加到嫦娥系统
		services/moonmm/joinUpMoonmm.json

		ThirdpartyMoonmmHandler.py

		odbs表去掉原which_id字段，以type替换之,以标识db所属的类型houyictrl，apsara，oss_server etc。
	（2）修改weight值
		HouyiApiWeightHandler.py
		直接到houyi库操作？OR 接口
	（3）集群postcheck
	（4）完成部署
		DeployregionHandler.py



	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
da338 Friday, July 26, 2013

1. 
	* 落日弓

2. 落日弓
	继续扫尾部分

	houyiapi测试环境： 10.230.227.11	 ATDEV01
	admin,admin
	houyi
	10.230.227.11:3306/houyi，houyi，houyi                       
	
	调用houyiapi时，根据regionId找到调用的url的逻辑：
		realserver表，type为apiproxy
		regionId->bigRegionId->	houyiapi  找到vip即可
		select
			rs.ip ip
		from region r
		left join big_region br on br.id=r.big_region_id
		left join houyiapi hyapi on hyapi.id=br.id_houyiapi
	key和id，设置为可配。


	
3. 规范，算法与实现
	规范，算法是一定的，实现可以千变万化。-tip-

4. zk test

5. extjs chrome type pending
	chrome页面异步XMLHttpRequest请求失败
	请求时，没有任何cookie，请求也无任何响应？
		跳转 OR 缓存？

	-----
	Ext.define('LuoRiGong.store.Cluster', {
	    extend: 'Ext.data.Store',
	    model: 'LuoRiGong.model.Cluster',
	    autoLoad: false,
		
	    proxy: {
		type: 'ajax',		
		api: {
		    read: 'services?action=clusterAction.listClusters'
		},
		
		reader: {
		    type: 'json',
		    root: 'data'
		}
	    }
	});
	-----
	PS: 原store定义

	-----
	Ext.define('LuoRiGong.store.Cluster', {
	    extend: 'Ext.data.Store',
	    model: 'LuoRiGong.model.Cluster',
	    autoLoad: false,
		
	    proxy: {
		type: 'ajax',
		method: 'GET',
		withCredentials: true,
		useDefaultXhrHeader: false,

		headers: {
		    "Accept": "application/json"
		},
		
		api: {
		    read: 'services?action=clusterAction.listClusters'
		},
		
		reader: {
		    type: 'json',
		    root: 'data'
		}
	    }
	});
	-----
	PS: 修改后的store，待验证？

6. java * java 
	String.valueOf(obj) 与 (String)obj 的区别？
	第二种方式为，已知obj为String类型时做转换；第一种为，obj的类型可能为多种，调用obj的toString方法转换。
		eg: 如果obj为Integer类型


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day339 Monday, July 29, 2013

1. 
	* 落日弓
2. 落日弓
	继续
	1）扫尾->完成部署	done
		Armory client: 
			/test/orange/orange/armory.py
				batch_update

		Armory接口说明：	 http://wiki.ec.alibaba-inc.com/index.php/落日弓与armory
			
	2）部署后羿	done
		集群部署，增加部署后羿按钮（原部署后羿逻辑包含在部署飞天中）
		基本参数和其他命令一致

	3）集群配置 pet操作，页面弹出框没有做不为空验证 
		ClusterConfigOperateFormPanel.js
	4）查看交付报告
		

	问题：
		rc.local和pet操作中，一个jobName对应多个job的情况，在生成log时有问题，是否独立拆分？ 待
		或者，在job标识上，再加上action的名称，2者组合实现唯一，然后在ajax请求log，有action的按钮带上对应的action即可，服务端从job表匹配。
	解决，在db中存待标识的agent_func_name，在mq构造消息时，将尾部的job name标识去掉。
		agent_func_name唯一，实现log的独立显示；

3. 设计 代码复用 -tip-
	独立的功能尽量抽取出来共用

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day340 Tuesday, July 30, 2013

1. 
	* 落日弓
2. 落日弓
	1）提测相关
		安装包与配置单独打rpm包，部署时只需要安装即可
			类似window下的安装包，里面有默认配置，也可自定义配置安装，方便安装，升级。
		conf中的配置，在打包时根据对应的环境拷贝对应的配置，故配置文件修改要同步到对应的配置文件。
	2） log显示修复
	3）sql修改，后续以追加的方式，alert或update，不修改已有的sql变更
	4）ISO,Image上传
	ISO:
		ManageIsoPanel.js
		级联菜单，在下拉框内容变化时，触发事件，更新下一级菜单数据，以此类推。

		java web uri: 
			services/isoManage/isoUpload.json
		IsoServiceImpl
			isoUpload方法

		python api uri:
			/job/iso

	Image:
		ManageImagePanel.js


3. rpm打包
	http://svn.alisoft-inc.com/repos/alisoft/houyi/luorigongweb/branches/luorigongzhuge/rpmbuild

4. 业务
	http://wiki.qa.aliyun-inc.com/index.php/云监控

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day341 Wednesday, July 31, 2013

1. 
	* 落日弓

2. 落日弓
	1）ISO上传
		ManageIsoPanel.js
		获取request对象，从而获取文件内容：
			 MultiPartRequestWrapper mpRequest = (MultiPartRequestWrapper) ServletActionContext.getRequest();
			根据clusterName获取regionId，clusterName都为相同（需要发给指定cluster的agent去处理）
	
	ISO上传（Excel）		
	
	上传ISO状态
		状态显示Store： IsoJob.js
			services/jobLogStatus/getIsoJobs.json
			JobLogStatusServiceImpl.java
				getIsoJobs
			在tab页切换时，触发store取log
		状态显示Grid： UploadJobStatusGrid.js
			
		与JobInstAction对接，获取job的log
	2）Image上传
		ManageImagePanel.js
		ImageServiceImpl.java

		Store: ImageJob.js


	3）部署后羿 修改 待？
		还需要加两个参数houyi_resource_path，revision
		查询codesrc， 得到这个region的houyictrl代码源的url 和revision


	

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day342 Thursday, August 01, 2013

1. 
	* 落日弓

2. 落日弓
	1）按钮状态同步修复	      doing
		集群部署页面 为例

		原更新按钮状态逻辑为：
			取到相关job的最新信息，遍历当前Panel下所有按钮，匹配上后更新状态。

		ClusterDeployOperateFormPanel.js
		globalutilities.js 的 btnAjaxRequest1 方法发送按钮点击ajax请求
			successTrueFn1
			successFalseFn 
			这2个函数只根据返回值是否成功，弹出执行成功或失败
		btnAjaxRequest1 方法在java服务端返回成功时，就将按钮状态置为执行完成，这点需要修改，改为java返回后将状态置为执行中，然后通过定时刷新任务来
		刷新按钮状态。
		
		界定状态：
			正在执行 - 异步请求发给服务端，服务端处理后返回ok时，为此状态（此时服务端任务还在异步处理中）
			执行完成 - 后端异步任务执行结束，返回结果状态时
		
		ClusteredDeployAction

		是否因为异步消息机制？
		查看原代码，确实是否为同步机制，消息发出去后同步等待消费mq消息后再返回
		以 大禹环境检查 为例：
			JobDayuHandler.py
			webx.py
				send2agent方法
				PS: 调用此方法发送消息给MQ
		
		定时刷新按钮状态任务：
			ClusterOperatePanel.js 任务触发在这个Panel里
			tab切换时，调用 genJobStatusTask 方法生成刷新按钮状态的任务

			Store: Job.js
			Model: Job.js

			通过在js代码中加alert(xxx)调试 genJobStatusTask 方法的处理逻辑；并结合action的返回值与job model的一一对应。

			问题定位：
				1）store中model定义和返回值对应，并与函数中使用方式一致
				2）字符串转json时，调用方式要正确，可从浏览器调试控制台看到js的错误提示，比如对象undefined
					需要找原因，js正确处理后再继续往下走
					var jobResult = Ext.JSON.decode(records[i].get('result'));
					var code = jobResult.code;
					var code = jobResult.get('code');//此用法报，对象没有get方法，采用上面的方式获取json对象中的code值。

			在 buttonTextToUrlMapping.js 中，定义了各个tab页的按钮集合。比如 clusterDeployOperateFormPanelMap 定义了部署页面的按钮集合。

			js遍历结果集时，少了部分结果，从console看到js解析json出错了，导致后续结果集无法遍历 -tip- * extjs * js
				调试JS，碰到困惑的问题，赶快看js的console吧，看看是不是js执行出错导致的!!! so important!!! To save you valuable time~~
			



	2）部署飞天客户端     done
		加一个step=deploy
	3）部署后羿 修改 done
		还需要加两个参数houyi_resource_path，revision
		查询codesrc， 得到这个region的houyictrl代码源的url 和revision
	4）部署OSS Server done
		加参数，oss_resource_path = param['oss_resource_path']

	调试：
		查看agent的log，/usr/local/python/bin/python jobworker/master.py orange.conf
	

3. rabbitmq
	Channel
	Connection
	Broker
	ConnectionFactory
	Queue
	Consumer
	connection.createChannel()
	channel.exchangeDeclare(exchange, type)
	channel.queueBind(replyQueueName, exchange, replyQueueName)
	channel.basicPublish(exchange, "", basic, msg.getBytes())
	channel.basicConsume(replyQueueName, true, new Consumer() {...

	-----
	   public void basicConsume(String queue, CallbackService callback) {
		int attempt = 10;
		Channel channel = null;
		try {
		    while (attempt > 0 && !isConnectionOpen()) {
			connection = brokerConfigurationService.createConnection();
			attempt--;
		    }

		    if (attempt == 0) {
			throw new Exception("connection failed");
		    }

		    channel = connection.createChannel();
		    channel.queueDeclare(queue, true, false, false, null);
		    channel.queueBind(queue, exchange, "");
		    QueueingConsumer consumer = new QueueingConsumer(channel);
		    channel.basicConsume(queue, true, consumer);
		    channel.basicQos(100);

		    while (true) {
			QueueingConsumer.Delivery delivery = consumer.nextDelivery();
			String message = new String(delivery.getBody());
			callback.callback(message);
		    }
		} catch (Exception e) {
		    logger.error(e);
		} finally {
		    try {
			if (channel != null) {
			    channel.close();
			}
		    } catch (Exception e) {
			logger.error(e);
		    }
		}
	    }
	-----
	PS: 消费，循环监听消费消息；
		nextDelivery方法实现中，采用Blocking Queue，private final BlockingQueue<Delivery> _queue，只有队列中有数据才继续，否则等待。
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day343 Friday, August 02, 2013

1. 
	* 落日弓

2. 落日弓
	1）fixbug
	2）houyiapi key id
	3）在部署houyi之后增加一个按钮： 部署运维工具
	PetoolsWorker.deploy_petools 
	step =  kuorong/deploy
	pe_resource_path = param["pe_resource_path"]
	revision = param['revision'

	Agant启动命令：/usr/local/python/bin/python jobworker/master.py orange.conf
	4）去掉重启TDC按钮

	10.250.6.228-MySql root 123456

	根据集群类型的不同，有些按钮会变为不可用，如果集群后端agent不存在，则状态刷新也会没效果。
	
	QA java web环境：
	go2houyi1
	atzy - go2houyi1 - ssh 10.230.226.112 
	Agetn: HOUYI1: go2houyici 

3. MapReduce:The Free Lunch Is Not Over
	并行计算
	Map Reduce编程模型，编程框架

4. struts2的请求处理流程
	每个action都在独立的线程里执行完成，这样ThreadLocal中的数据就不会有并发问题
	源码分析：

5. extjs js 调试
	页面没反应，菜单点击没反应等情况，都可以看看js执行控制台输出，看看是不是有错误了 -tip-
	eg: 点击菜单没反应 
		页面js中注释掉了 重启TDC 按钮，但是按钮配置map中没有去掉，导致给对象赋值null报错。

6. zk locks shared lock ，distribute lock ， in practise
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day344 Monday, August 05, 2013

1. 
	* 落日弓

2. 落日弓
	fixbug
	1）集群配置->同步rc.local，中间同步文件，异步 OR 同步？
	JobEnvHandler.py 
		_sync_rc_file 
			self.send2agent(cluster_name, 'FileWorker.FileJob.save', param, sync=True)
		同步文件为同步操作，最后job为异步job

		异步job，需要将job持久化到数据库中；同步操作不进行持久化job操作。

		/tmp/orange/orange.jobmaster.error.log ERROR日志记录了错误，debug里没有记录部分日志 

		Agent报错
		-----
		[Errno 2] No such file or directory: 'null/rc.native'
		-----

		DEBUG log
		-----
		16885 KeyError: 'path_dir_luorigong'
		16886 [2013-08-05 13:49:01,177 4766 47421085352176] DEBUG (master.py:98) 
		16887 [jobuuid:33c2b453-5af5-4b3d-a174-67fc127f55e8] ========EnvWorker.EnvJob.sync_rcfile end========  		
		-----

		rc.sysinit 
			Agent收到后，解析json出错，python不能处理tab键\t，替换模板文件中的tab为4个空格即可 :%s/\t/    /g  * python -tip-

	2）资源视图-添加houyiapi域名的表单，增加 accessId，accessKey，aliyunIdkp3个字段，以满足不同大region houyiapi采用的	账号不同。
		并修改原配置方式

	3）集群配置-apiproxy发布 修改 类似这样的对外API接口，可以开放出去，便于与其他系统集成
		http://wiki.ec.alibaba-inc.com/index.php/API_Proxy%E4%B8%8EAPI

	新增region
	前提：api 数据库中已经有新增region的记录
	步骤：在落日弓API服务器调用：curl http://apiproxy_realserver_host/reset/regions
	返回：{"code": 200, "msg": "reset all regions success."}
	
	apiproxy发布步骤时，调用apiproxy机器上面的连接即可。
		

3. vim 替换所有 :%s/sourceStr/targetStr/g

4. 工具类Utils，可以抽象部分公用代码

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day345 Tuesday, August 06, 2013

1. 
	* 落日弓

2. 落日弓
	QA环境
	XY2_TESTAG 10.230.226.112
	sudo mysql
	web服务也在此AG上
	
	apiproxy
		apiproxy增加时，在big_region_realserver中不会有关联，而是通过houyiapi关联？
		正解：
			regionId-bigRegionId-houyiapiId+type=多个apiproxy rs
		
		big_region_realserver表只记录了houyiapi rs和bigregion的关联，没有其他类型rs的关联。 业务啊~

		ApiProxy有多个，需要每个都调用。
	
	创建houyiapi域名时，增加3个表单项accessId,accessKey,aliyunIdkp
		regionId > bigRegionId >从big_region表拿到houyiapi_id，从而拿到id,key...

3. js处理时，decode json出错，导致按钮状态出问题
	返回的json是个空
	-----
	{"beginTime":"2013-08-06 10:07:12","clusterName":null,"component":"houyictrl","componentId":12,"componentName":"HOUYICI","endTime":null,"flowStepNo":null,"gmtCreate":null,"gmtModify":null,"id":null,"jobActionName":null,"jobId":null,"jobName":"EnvWorker.EnvJob.install_iptables_mock","jobNeedParam":null,"name":"EnvWorker.EnvJob.install_iptables_mock","params":null,"pid":null,
		"result":null,"status":"finished","statusArr":null,"uuid":"e18cb9fc-bafa-4824-bd02-c86e5370585c","workflowInstanceId":null}
	-----
	js debug调试
	PS; chrome方便查看js错误


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day346 Wednesday, August 07, 2013

1. 
	* 落日弓

2. 落日弓
	houyiapi账户订正语句，分线上，测试环境
	session过期，本地和线上tomcat没问题，QA的jetty环境session很快过期

	houyiapi表的订正：
		houyiapi
		big_region
		big_region_realserver

	查看ECS SLB VIP申请日志：
		tail -f -n200 logs/2013_08_07.stderrout.log | grep Slb
		HTTP超时后，会报对应的友好提示，按钮状态可优化
	
	Image,ISO上传bug分析：
		从QA环境看
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day347 Thursday, August 08, 2013

1. 
	* 落日弓
2. 落日弓
	完成部署后-集群信息页面修改
	Tab页：
		ClusterDetailPanel.js
	子Tab页，集群信息：
		ClusterResourceReadOnlyFormPanel.js

	默认代码源表单项类型为combobox，即可能会有多条记录：
		defaultType: 'combobox', 
	参考 clusterresource/SourceCodeInfoFormPanel.js 页面，代码源配置页面，Store都是独立的
	
	集群部署Tab页切换时，报：
		com.aliyun.luorigong.exception.WebException
			at com.aliyun.luorigong.workflow.action.JobInstAction.getJobStatus(JobInstAction.java:110)
		tab页切换时，触发了globalutilities.js中定义取job状态的请求，其中参数componentType作为key是错误的，需改为component
		错误请求：10.1.170.193 -  -  [08/Aug/2013:15:47:13 +0800] "GET /services?action=jobInstAction.getJobStatus&_dc=1375948336041&componentType=houyi&componentId=12&statusType=running%2Cfinished&page=1&start=0&limit=25 HTTP/1.1" 200 101 
	

3. 加入product字段的几张表，排查
	District	done		done
	Region	done
	CodeSrc	done
	Subnet	done
	Room	done
	Odbs	done	

4. 落日弓开放接口
	接口规范定义
	业务接口需求分析
5. 连接池DBCP提供的验证连接可用性功能的测试
	问题现象：
		slbapi通过连接池与DB交互，当DB做主备切换（DNS将域名解析到备库的IP上）到备库（由只读状态改为可读写状态）时，
		slbapi还有连接会连原来的主库（切换过后为只读状态），写操作时报Read Only。

		主备切换过程：备库设置可读写->修改域名DNS解析->切断原主库已有的DB连接，并设置原主库为只读 ； 主备切换

	org.apache.commons.dbcp.BasicDataSource的testOnBorrow属性配置为true时，根据其文档说明，会验证连接是否可用，如果不可用则从新获取连接
	关键：
		上面，从新获取连接时，如果jdbc配置的是域名，新连接是从已解析出来的IP获取，还是重新解析域名拿到IP，从而生成新连接？

	验证上面的问题：
		模拟DB主备切换过程，分析连接池中连接的更新状态
		连接是否可用的判断依据？
			依托于Socket的连接是否可用？
		根据源码，判断连接是否可用是基于db查询操作或其他机制来判断的，看接口对应此方法的说明：
		
		-----
		boolean java.sql.Connection.isValid(int timeout) throws SQLException
			Returns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that 
			positively verifies the connection is still valid when this method is called. 			
			
			The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.
		-----
		DBCP连接池，底层使用JDBC驱动提供的Driver来获取连接的。


		OS dns cache linux操作系统自身不缓存dns信息
			On Linux (and probably most Unix), there is no OS-level DNS caching unless nscd is installed and running. Even then, the DNS caching feature of nscd is disabled by
			default at least in Debian because it's broken. The practical upshot is that your linux system very very probably does not do any OS-level DNS caching.		
			from: http://stackoverflow.com/questions/11020027/dns-caching-in-linux

	ttl=0的方式去掉了java的dns缓存使用是ok的。

	SOCKET底层基于TCP协议，TCP协议保证连接可用性，只要在SOCKET超时时间之内，即使交互的两端网络断电，在网路恢复后SOCKET连接依然可用。
	简单验证：
		起个需要连接DB的服务，然后将网线拔掉再插上即可。  -tip-
	
	基于上面这点：
	1）网络异常断电
		DB切换时，交换机断电10min，恢复供电后，应用端的数据库连接池的连接还是访问到原主库的地址；原因为，断电后管理员无法连接到原主库去执行kill
		操作且原socket连接还未超时，则继续可用。
	2）正常切换时
		比如演练时，管理员会登到原来饿主库机器
		并kill掉已有的DB连接而且阻止新DB连接的建立，这样应用端使用时发现连接被关闭，就会去掉老连接并重新解析DNS到IP，然后建立新的连接以缓存。

	上面的经历网络断电，socket依旧可用，还需要证明一点，即DB连接池的socket超时时间大于10min？
		Mysql驱动源码分析，mysql-connector-java-5.1.18.jar，com.mysql.jdbc.ConnectionImpl类，是通过工厂方法获得，此Connection实现类中，实现了
		获取DB连接的逻辑，在createNewIO方法中，以com.mysql.jdbc.MysqlIO类的实例封装到DB的连接信息，其构造函数可传递socketTimeout时间，如下：
		this.mysqlConnection.setSoTimeout(socketTimeout);//即为socket的方法，表示读取超时，为0表示永不超时

		socketFactory为创建socket的工厂，其实现有基于命名管道（NamedPipe）和基于标准socket的工厂	 ；
		在com.mysql.jdbc.StandardSocketFactory实现中，看到String keepAlive = props.getProperty(TCP_KEEP_ALIVE_PROPERTY_NAME, TCP_KEEP_ALIVE_DEFAULT_VALUE);
		默认不设置时，在其configureSocket方法中，Socket的keepalive为true。
	-----
	java socket参数详解:KeepAlive .
		keepalive不是说TCP的常连接，当我们作为服务端，一个客户端连接上来，如果设置了keeplive为true，当对方没有发送任何数据过来，超过一个时间(看系统内核参数配置)，
		那么我们这边会发送一个ack探测包发到对方，探测双方的TCP/IP连接是否有效(对方可能断点，断网)。如果不设置，那么客户端宕机时，服务器永远也不知道客户端宕机了，
		仍然保存这个失效的连接。
		
		当然，在客户端也可以使用这个参数。客户端Socket会每隔段的时间（大约两个小时）就会利用空闲的连接向服务器发送一个数据包。这个数据包并没有其它的作用，
		只是为了检测一下服务器是否仍处于活动状态。如果服务器未响应这个数据包，在大约11分钟后，客户端Socket再发送一个数据包，如果在12分钟内，服务器还没响应，
		那么客户端Socket将关闭。如果将Socket选项关闭，客户端Socket在服务器无效的情况下可能会长时间不会关闭。
		
		尽管keepalive的好处并不多，但是很多开发者提倡在更高层次的应用程序代码中控制超时设置和死的套接字。同时需要记住，keepalive不允许你为探测套接字终点（endpoint）
		指定一个值。所以建议开发者使用的另一种比keepalive更好的解决方案是修改超时设置套接字选项。
		
		说白了：这个参数其实对应用层的程序而言没有什么用。可以通过应用层实现了解服务端或客户端状态，而决定是否继续维持该Socket。
		from: http://hi.baidu.com/sei_zhouyu/item/59a973c25fe9ff000bd93af7
	-----
	
	-----
	TCP长连接与短连接的区别
		1). TCP连接

		当网络通信时采用TCP协议时，在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接时它们可以释放这个连接，
		连接的建立是需要三次握手的，而释放则需要4次握手，所以说每个连接的建立都是需要资源消耗和时间消耗的

		经典的三次握手示意图：



		经典的四次握手关闭图：



		2). TCP短连接

		我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，
		这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。
		从上面的描述看，短连接一般只会在client/server间传递一次读写操作

		短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段

		3)TCP长连接

		接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，
		后续的读写操作会继续使用这个连接。

		首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，
		使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务器端检测到这种半开放的连接。

		如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：

		客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
		客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个
		这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。
		客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
		客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。
		从上面可以看出，TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，
		遇到恶意的连接时，保活功能就不够使了。

		在长连接的应用场景下，client端一般不会主动关闭它们之间的连接，Client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚
		有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；如果条件再允许就可以
		以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。

		长连接和短连接的产生在于client和server采取的关闭策略，具体的应用场景采用具体的策略，没有十全十美的选择，只有合适的选择。
		from: http://www.cnblogs.com/liuyong/archive/2011/07/01/2095487.html
	-----
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day348 Friday, August 09, 2013

1. 
	* 落日弓

2. 落日弓
	1）集群信息-nc信息
		ClusterResourceReadOnlyFormPanel.js
		ncGridPanel.js NC信息Grid页面
		Store: Nc.js

		参考集群信息配置页面： NcGroupPanel.js

	2）

	3）开放API
		pet对开放接口的需求整理



3. IO模型
	search IO模型
4. 网络物理结构
	
	核心路由	7K		7K
				|	|	 |	|
				5K	5K	5K	5k
				|
				2K ...

	Mac规划，由于大二层网络Mac量大，核心路由上的Mac表只能保存一定数量的Mac，需要规划，8K的vm的mac


5. 根据UUID找日志内容
	UUID关联到一次请求的所有处理过程，记录相关log即可

6. DBCP连接池报错
	配置了testOnBorrow选项
	但某些情况下报： 
	-----
	[DEBUG] 2013-08-09 16:50:17 [CallbackServiceImpl:19]--{"body": {"job_status": "finished", "job_uuid": "071c9156-557f-411e-9d4a-b94670026768", "result": "{\"code\" : 200, \"msg\" : \"OK\"}"}, "to": "luorigongapi"}
	[DEBUG] 2013-08-09 16:50:17 [SqlMapClientTemplate:168]--Opened SqlMapSession [com.ibatis.sqlmap.engine.impl.SqlMapSessionImpl@3fa36899] for iBATIS operation
	[DEBUG] 2013-08-09 16:50:17 [SqlMapClientTemplate:185]--Obtained JDBC Connection [org.apache.commons.dbcp.PoolableConnection@76cd119c] for iBATIS operation
	[DEBUG] 2013-08-09 16:50:17 [SQLErrorCodesFactory:199]--Looking up default SQLErrorCodes for DataSource [org.apache.commons.dbcp.BasicDataSource@1e883644]
	[WARN ] 2013-08-09 16:50:17 [SQLErrorCodesFactory:227]--Error while extracting database product name - falling back to empty error codes
	org.springframework.jdbc.support.MetaDataAccessException: Error while extracting DatabaseMetaData; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.
		at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:296)
		at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:320)
		at org.springframework.jdbc.support.SQLErrorCodesFactory.getErrorCodes(SQLErrorCodesFactory.java:214)
		at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.setDataSource(SQLErrorCodeSQLExceptionTranslator.java:141)
		at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.<init>(SQLErrorCodeSQLExceptionTranslator.java:104)
		at org.springframework.jdbc.support.JdbcAccessor.getExceptionTranslator(JdbcAccessor.java:99)
		at org.springframework.orm.ibatis.SqlMapClientTemplate.execute(SqlMapClientTemplate.java:203)
		at org.springframework.orm.ibatis.SqlMapClientTemplate.update(SqlMapClientTemplate.java:378)
		at com.aliyun.luorigong.base.dao.BaseDao.update(BaseDao.java:132)
		at com.aliyun.luorigong.dao.impl.JobInstDaoImpl.updateByUuid(JobInstDaoImpl.java:22)
		at com.aliyun.luorigong.base.service.impl.CallbackServiceImpl.callback(CallbackServiceImpl.java:48)
		at sun.reflect.GeneratedMethodAccessor131.invoke(Unknown Source)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
		at java.lang.reflect.Method.invoke(Method.java:597)
		at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:318)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
		at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:110)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
		at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:90)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
		at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
		at $Proxy60.callback(Unknown Source)
		at com.aliyun.luorigong.base.service.impl.MQServiceImpl.basicConsume(MQServiceImpl.java:167)
		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)


		Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was 59,583,429 milliseconds ago.  The last packet sent successfully to the server was 59,583,432 milliseconds ago. is longer than the server configured value of 'wait_timeout'. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Connector/J connection property 'autoReconnect=true' to avoid this problem.
		at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
		at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
		at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
		at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
		at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)
		at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1116)
		at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3364)
		at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1983)
		at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2163)
		at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2618)
		at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2568)
		at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1557)
		at com.mysql.jdbc.DatabaseMetaData.getUserName(DatabaseMetaData.java:6731)
		at org.apache.commons.dbcp.DelegatingConnection.toString(DelegatingConnection.java:123)
		at org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.toString(PoolingDataSource.java:355)
		at java.lang.String.valueOf(String.java:2826)
		at java.lang.StringBuilder.append(StringBuilder.java:115)
		at org.springframework.orm.ibatis.SqlMapClientTemplate.execute(SqlMapClientTemplate.java:185)
		... 31 more
	Caused by: java.net.SocketException: Broken pipe
		at java.net.SocketOutputStream.socketWrite0(Native Method)
		at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)
		at java.net.SocketOutputStream.write(SocketOutputStream.java:136)
		at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
		at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
		at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3345)
		... 42 more
	[DEBUG] 2013-08-09 16:50:17 [SQLErrorCodeSQLExceptionTranslator:283]--Unable to translate SQLException with Error code '0', will now try the fallback translator
	    [DEBUG] 2013-08-09 16:50:17 [SQLStateSQLExceptionTranslator:95]--Extracted SQL state class '08' from value '08003'
	    [DEBUG] 2013-08-09 16:50:17 [DataSourceTransactionManager:861]--Should roll back transaction but cannot - no transaction available
	    [ERROR] 2013-08-09 16:50:17 [MQServiceImpl:170]--org.springframework.dao.DataAccessResourceFailureException: SqlMapClient operation; SQL [];
	--- The error occurred in com/aliyun/luorigong/bean/config/JobInst.xml.
	--- The error occurred while executing update.
	--- Check the    update job_instance set gmt_modify=now()         ,    status=?      ,    result=?               ,    end_time=?            where uuid=?  .
	--- Check the SQL Statement (preparation failed).
	--- Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.; nested exception is com.ibatis.common.jdbc.exception.NestedSQLException:
	--- The error occurred in com/aliyun/luorigong/bean/config/JobInst.xml.


	--- Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.; nested exception is com.ibatis.common.jdbc.exception.NestedSQLException:
	--- The error occurred in com/aliyun/luorigong/bean/config/JobInst.xml.
	--- The error occurred while executing update.
	--- Check the    update job_instance set gmt_modify=now()         ,    status=?      ,    result=?               ,    end_time=?            where uuid=?  .
	--- Check the SQL Statement (preparation failed).
	--- Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed.
	    [DEBUG] 2013-08-09 16:50:17 [DataSourceUtils:332]--Returning JDBC Connection to DataSource
	    [DEBUG] 2013-08-09 16:50:17 [DataSourceUtils:297]--Could not close JDBC Connection
	    java.sql.SQLException: Already closed.
		at org.apache.commons.dbcp.PoolableConnection.close(PoolableConnection.java:114)
		at org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.close(PoolingDataSource.java:191)
		at org.springframework.jdbc.datasource.DataSourceUtils.doReleaseConnection(DataSourceUtils.java:333)
		at org.springframework.jdbc.datasource.DataSourceUtils.releaseConnection(DataSourceUtils.java:294)
		at org.springframework.jdbc.datasource.DataSourceUtils$ConnectionSynchronization.beforeCompletion(DataSourceUtils.java:452)
		at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCompletion(TransactionSynchronizationUtils.java:106)
		at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCompletion(AbstractPlatformTransactionManager.java:937)
		at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:738)
		at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:723)
		at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:393)
		at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:120)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
		at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:90)
		at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
		at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
		at $Proxy12.basicConsume(Unknown Source)
		at com.aliyun.luorigong.base.service.impl.ReceiveMessage$ReceiveMessageThread.run(ReceiveMessage.java:23)
	-----
	PS: 环境为,java1.6,jetty容器，DBCP1.4，MqSQL5.1.40-community-log
		配置如下：
		-----
		<bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource">
			<property name="testOnBorrow" value="true" />
			<property name="validationQuery" value="SELECT 1 FROM DUAL" />
			<property name="driverClassName" value="${jdbc.driverClass}" />
			<property name="url" value="${jdbc.url}" />
			<property name="username" value="${jdbc.username}" />
			<property name="password" value="${jdbc.password}" />
			<property name="minIdle" value="${jdbc.minimumConnectionCount}" />
			<property name="maxActive" value="${jdbc.maximumActiveTime}" />
			<property name="maxIdle" value="${jdbc.maximumConnectionCount}" />
		</bean>
		-----
	
	模拟MySQL服务器超时情况，来验证DBCP连接池的功能。
		设置mysql超时较短，测试dbcp
		在本地mysql环境，设置连接超时时间为10秒：
			set interactive_timeout=10
			此方法，只作用于当前会话。

		修改这两个值是分为两种修改的。	   -tip-		       * mysql
		-----
		1）修改当前会话的这两个属性值。所谓的当前会话就是你当前获取的连接池的连接。比如你打开黑窗口那个会话。这个修改比较简单，直接set wait_timeout=10;就行了，
		你怎么知道这么修改仅仅修改的是当前会话？很简单，你把这个黑窗口关了，你再重新开一个，再重新查，你发现没改啊。
		2）修改全局的属性值。一般这个用的多，你到你的数据库安装包下找到my.ini，在最下面添加wait_timeout=10就可以了，然后重新启动mysql服务，我说的重新启动服务，
		不是你关闭这个黑窗口，重新启动一个黑窗口。服务在我的电脑右键服务里去找。
		-----
		from: http://www.esnsc.com/news644.html

		报错的DB连接16个小时没有用到；数据库配置的是默认的8小时后，连接过期；

	网络解决方案：
		testOnBorrow="true"
		testWhileIdle="true"
	
	验证：
		待？
		
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day349 Monday, August 12, 2013

1. 
	* 落日弓
	
2. 落日弓
	1）集群配置-配置houyiapi
		监控表和 zone_ip表的初始化有问题
		DatabaseGenAction
			initDbForHouyiDeploy
		log grep HouyiApiOperationUtils

		变化：问题源头是因为 生成数据库SQL 步骤所生成的insert语句在 查看数据库SQL 中未显示出来。

		分析：生成数据库SQL 逻辑
		databaseGenAction.generateDeploySql
		表： inner_sql
			用于存储初始化数据库数据的insert语句

		还是？原来的直接DB操作，替换为了接口调用
		GenDbSqlServiceImpl
			genDbSql
		
		确实改为了接口调用操作
		HouyiApiServiceImpl
			initHouyiDeploy

	2）设计方案，验证day348第6条的数据库连接池配置
		命令行的连接超时过后会重连；
		但java应用貌似超时过后，还可以刷新连接的状态 ，show processlist;的Time会更新 ？
			是TCP的keepalive配置在保持连接，此时如果把网线断掉，超出mysql的超时时间以外，则？
				

		手动kill调mysql的连接后，debug代码，在org.apache.commons.dbcp.PoolableConnectionFactory的validateObject会验证到异常，连接已关闭
			java.sql.SQLException: validateConnection: connection closed
		然后，会连接池重新建立一个DB连接。

	3）查看集群信息
		ClusterResourceReadOnlyFormPanel

		nc信息

			给共用的panel传参，以决定panel中某些组件的属性
			panel中配置config属性
			create时把参数带进去
			create("panelName",{para1:val1,param2:val2})
			-----
			Ext.define('SmartPhone', {
			     config: {
				 hasTouchScreen: false,
				 operatingSystem: 'Other',
				 price: 500
			     },
			     constructor: function(cfg) {
				 this.initConfig(cfg);
			     }
			});

			var iPhone = new SmartPhone({
			     hasTouchScreen: true,
			     operatingSystem: 'iOS'
			});

			iPhone.getPrice(); // 500;
			iPhone.getOperatingSystem(); // 'iOS'
			iPhone.getHasTouchScreen(); // true;
			-----
			from: http://docs.sencha.com/extjs/4.2.1/#!/api/Ext.Class-cfg-config
	4) backup扩容
		rc.local按钮日志及状态
		ClusterChangeContainer.js
		clusteredChangeAction.syncRcLocalForKuorong
		修改为区分job的方式：js，java，数据库订正
		EnvServiceImpl


3. 大region命名
	国家-区域-机房-a(外售)/b(内部)/c(第三方)

4. extjs
	1) 使用别处已定义好的panel，作为查看用
	-----
	{
    		title: 'NC信息',
            
            items: [
	            {
			        xtype: 'ncGroupPanel'
	            }
	        ],
	        
	        listeners: {
            	expand: function(f, eOpts) {
            		var items = Ext.ComponentQuery.query('ncGroupPanel',f.up('form'));
            		items[0].load(clusterId, 'clusterId');
            	}
            }
    	},
	-----
	PS: 通过require属性引入进来，然后通过xtype方式引用此组件（会通过构造函数初始化）；最后，通过listener事件来实际加载Store的数据。			    * extjs组件查找 对象查找 
	这里涉及，extjs查找组件的方法，extjs提供多种方式，参考
		-----
		在Extjs4.0中，依然可以沿用Extjs3.x中查找组件的方式，但是在Extjs4.0中，可以利用ComponentQuery，更方便找到对应组件。
		(1) 通过组件ID获取组件："#组件ID”，如果通过这种方式，那么一定要记住在组件ID前添加#号。
			// 通过ID获得组件:#ID
			//   var items = Ext.ComponentQuery.query('#btn2',panel);
		(2) 得到某一组件下所有的指定类型的组件："panel>button”，这种方式是查找所有panel组件下的所有button组件
			// 获得panel下的所有button,这个需要注意，button必须在panel下的第一层，如果中间跨层是找不到的，如：'viewport>button'是找不到button的，因为中间有一层panel
			//   var items = Ext.ComponentQuery.query('panel>button',panel);
		(3) 通过xtype："treepanel”或".treepanel
			// 如果是多个类别，可以逗号隔开，如：'gridpanel,treepanel'
			// var items = Ext.ComponentQuery.query('button',panel);
		(4) 如果想获取所有button并且action为save的button，则可以使用"button[action=save] "，又或者获取所有panel，并且autoscroll属性为true的panel，则可以使用"panel[autoScroll=true]"
			  // 通过组件的属性来查找
			  //   var items = Ext.ComponentQuery.query('button[id=btn2]',panel);
			  note:通过属性查找的时候中括号要紧挨着类名，如上据代码button和[id=btn1]之间不能有空格！
		(5) 还有两种方式，是查找某一组件的子组件或上级组件，例如
			a、查找window下的form：win.down(“form”)
			b、查找button的父组件window:button.up(“window”);
		-----
		from: http://blog.csdn.net/yanwushu/article/details/8434754
	
	这个例子，也学习如何从无到有来创建一个extjs显示页面，包含多个组件。



backup houyi
zone_ip
	AT03-HOUYI1-A | AT03-HOUYI1 | 10.249.1.1-10.249.250.254     |  184090881 |  184154878 |
| AT03-HOUYI1-A | AT03-HOUYI1 | 110.75.177.0-110.75.177.32    | 1850454272 | 1850454305 |
| AT03-HOUYI1-B | AT03-HOUYI1 | 10.249.204.2-10.249.204.10    |  184142850 |  184142858 |
| AT03-HOUYI1-B | AT03-HOUYI1 | 110.75.177.32-110.75.177.63   | 1850454304 | 1850454335 |

mysql> select * from region;
+-----------+-------------+---------------+--------+-------------------+---------+------------+--------+---------------------+
| region_no | region_name | nuwa_address  | status | big_ether_network | upgrade | visibility | weight | router_address      |
+-----------+-------------+---------------+--------+-------------------+---------+------------+--------+---------------------+
| HOUYICI   | HOUYICI     | 10.230.204.55 |      1 |                 1 |       1 |          1 |      0 | 10.230.204.55:38930 |
+-----------+-------------+---------------+--------+-------------------+---------+------------+--------+---------------------+

mysql> select * from monitor_datasource;
+--------------------------------------------------------------------------------------+----------+--------+-----------+-----------------+-----------------------+----------+------------+----------+--------------------+
| url                                                                                  | username | passwd | region_no | index_at_region | driver_class          | min_idle | max_active | max_idle | validation_query   |
+--------------------------------------------------------------------------------------+----------+--------+-----------+-----------------+-----------------------+----------+------------+----------+--------------------+
| jdbc:mysql://10.230.204.55:3306/houyimon?useUnicode=true&amp;characterEncoding=utf-8 | apsara   | 123456 | HOUYICI   |               0 | com.mysql.jdbc.Driver |       10 |         20 |       20 | SELECT 1 FROM DUAL |
+--------------------------------------------------------------------------------------+----------+--------+-----------+-----------------+-----------------------+----------+------------+----------+--------------------+

create_monitor_db


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day250 Tuesday, August 13, 2013

1. 
	* 落日弓

2. 落日弓
	1）rc.local,rc.sysinit
		在扩容页面，backup扩容页面的日志查看问题修复
		注意，这里有2个页面都有此按钮，莫混淆

		修改ok，backup扩容页面的日志查看

		再修复扩容页面的2个按钮日志
			ClusterChangeContainer.js
			ClusterEnlargeFormPanel.js	扩容页面
			ClusterBackUpEnlargeFormPanel.js		backup扩容页面


			clusteredChangeAction.syncRcLocalForKuorong
			clusteredChangeAction.syncRcSysInitForKuorong



		clusteredChangeAction.syncRcLocalForKuorong
	2）映射zone，失败
		将nc所在zone的信息，映射到houyidb的rack表中
			机架映射到zone
			zone信息来自集群信息中的配置，一般为1个或2个
			nc和rack的映射关系，从Armory中获取，rack和zone的关系由此处生成

			最后，会将这些映射关系存到houyidb中，以便控制系统可以指定zone起VM。

		syscontrolAction.listBufferNcRacks
			查询buffer组nc的rack列表
		
		原因：从Armory无法获取测试集群的nc数据（为QA手动导入），这样程序需要增加逻辑，判断为测试集群则不去Armory找，直接走DB查询。
			从db查询buffer组的nc列表，从rack_zone表找到已经做了映射的rack列表，返回为在rack_zone做映射的nc列表数据。
			nc从armory同步过来就有cluster的标识
		
		nc表的rackId即为其值，不是外键
	3）API初始化缺少ZONE_IP，monitor_datasource表初始化。
		create_cluster接口报region不存在的错，因为region_alias表有houyici这个小region记录，而region表的记录已被删除


3. houyiai测试环境
	ATDEV01_AG
	10.230.227.11
	admin,admin
	
	mysql服务连接被占满：
		[admin@HOUYICI_AG]$ mysql -uxxx -pxxx
		ERROR 1040 (HY000): Too many connections

		可通过 show processlist;看那些服务占用大量连接资源
	
	因为暴露的是80口，需要root权限启动houyiapi

	log在logs/openapi下

	落日弓，通过houyiapi接口，插入大region，小region，zone_ip，zone等新建一个大region或小region所需要的数据。
	大region数据，由agent插入，具体是在那个步骤或按钮上？
		以便构造数据，否则houyiapi报regionNo找不到
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day251 Wednesday, August 14, 2013

1. 
	* 落日弓

2. 落日弓
	1）API初始化缺少ZONE_IP，monitor_datasource表初始化。	
		create_cluster 清除houyi库的region，region_alias,region_status,region_need_statistics
		create_zone zone
		join_zone_addresses zone_ip
		
		houyiapi在大region管理页面，选择大region对应的houyiapi。

		route_ip_segment

		global		
		中定义的ajax请求有2个方法，一个是处理异步按钮，一个为同步按钮，选择的方法不同，对应的按钮状态分同步和异步：
		-----
		{
		//xtype: 'splitbutton',
		text: 'API接入',
			    handler: function(button, e) {
				var requestUrl = 'services?action=clusterConfigureAction.reloadCache';
				btnAjaxRequest2(requestUrl, clusterId, button, successTrueFn1, successFalseFn1, failureFn1);
			    }
		    },
		    
		    {
		text: 'APIProxy接入',
		handler: function(button, e) {
			var requestUrl = 'services?action=clusterConfigureAction.reloadCacheOfApiProxy';
				btnAjaxRequest2(requestUrl, clusterId, button, successTrueFn1, successFalseFn1, failureFn1);
			//Ext.Msg.alert('提示', '联系张勇添加集群，根据版本号在API PROXY页面发布');
		}
		},
		-----
		PS: 同步按钮

		RackMapToZoneWindow.js
			映射后，还需要将nc表的zone_id更新为目标zone
			原逻辑没有更新nc表zoneId逻辑，why?
		ResRackHandler.py
		rackZoneAction.addRackZoneMappings

	2）落日弓open api
		参考Armory open api 
		http://docs.alibaba-inc.com/

		PET对接口需求：		    详见Aone：http://aone.alibaba-inc.com/aone2/task/19431
			会在Aone上提需求
			1）查询regionNo列表接口
				以type参数，区分线上，测试，或全部的region列表
			2）根据regionNo，以及待查询配置的key集合，返回对应key的value集合

			3）查询配置项是否有更新的接口（可延后）
				最近10min是否有配置项变动
		open api wiki: http://wiki.ec.alibaba-inc.com/index.php/落日弓



3. 提测
	a. 出包
		落日弓前端打包说明

		1). 登陆10.250.6.23机器
		2). cd /home/admin/wysh/luorigongweb/
		3). checkout或者svn up需要打包分支的代码
		4). cd 分支/rpmbuild
		5). 打包源代码RPM：    cd rpm_code;python rpm_code.py
		6). 打包配置文件RPM:   cd rpm_conf;python rpm_conf.py [dev|qa|product]
		7). 将打包好的rpm拷贝到/var/www/html/luorigong/{date}的目录下,可以通过http://10.250.6.23/luorigong/{date}访问
		落日弓后端打包说明

		1). 登陆10.250.6.23机器
		2). cd /home/admin/wysh/luorigongweb/agent
		3). cd rpm
		4). 打包源代码RPM：    python create_rpm.py agent 版本号
		5). 将打包好的rpm拷贝到/var/www/html/luorigong/{date}的目录下,可以通过http://10.250.6.23/luorigong/{date}访问

		PS: apache服务，提供http方式的包访问下载

	b. aone上提测，加内容评论
		8.14提测:
		api: http://10.250.6.23/luorigong/20130814/luorigongweb-0.0.1-2599755.x86_64.rpm
		修复问题: 修复已有bug
		地址：http://aone.alibaba-inc.com/aone2/task/21633
	
	http://10.250.6.23/luoriogng/20130814
	