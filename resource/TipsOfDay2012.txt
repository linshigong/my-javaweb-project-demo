
本机ip 10.1.171.132

通过svn管理记录文件 eg google code  TortoiseSVN
搭建centos测试系统(vmware7) ssh连接
wiki scheng 
Linux Container - LXC	
openapi rds  (关系型数据库服务)
	ref: http://www.ibm.com/developerworks/linux/library/l-lxc-containers/
test
	https://my-javaweb-project-demo.googlecode.com/svn
google 检索 apache site:*.apache.org 高级搜索

* 数据库优化，索引
	 - SQL Server 索引
		 -------
			  SQL Server索引进阶第十五篇：索引的最佳实践

			    索引设计是数据库设计中比较重要的一个环节，对数据库的性能其中至关重要的作用，但是索引的设计却又不是那么容易的事情，性能也不是那么轻易就获取到的，很多的技术人员因为不恰当
			    的创建索引，最后使得其效果适得其反，可以说“成也索引，败也索引”


			    在本篇文章中，我们在学习了之前的知识之后，推荐14条指导方针。这14条指导方针可以帮助你更好的为数据库构建索引。

			    本篇文章的格式使用了由Addison Wesley出版社出版的<Framework Design Guidelines>中使用的格式。每一个最佳实践之前都使用了如下4个动词：要，考虑，避免、不要，分别代表如下意思:

			    要(Do):这个原则要坚决遵守

			    考虑(Consider):通常情况下都要遵循这个原则，但如果你对原则背后的原理有了深入了理解，可以根据实际情况不采用这个原则

			    避免(Avoid):考虑的反义词,意味着避免做某这类事，但同样，如果你了解了背后的原理，则可以根据实际情况做这类事。

			    不要(Do Not)：避免的增强版,意思是无论什么时候都不要做这类事。

			 
			指导方针

			要了解跑在数据库上的应用程序/用户

			    使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。

			    当然，如果你全程参与了程序的设计和开发，那再好不过。但这种情况少之又少，大多数情况都是你直接接手数据库和应用程序，这时你就需要两步走的了解你所接手的东西-通过外部和内部。

			    外部方法包括从用户那里了解程序相关的信息，观察他们使用程序的过程，阅读用户文档和交接文档。

			    内部方法是去看程序本身对数据库产生的操作。比如说Activity Monitor, Profiler等工具，也可以使用sys.dm_db_index usage_stats和sys.dm_db_missing_index_XXX系列DMV中找到所需信息，这些信息包
			    括用的最多的查询，用的最多的索引，用的少的索引以及本应建却没有建的索引。

			    通过找到拖累系统性能的查询，比如报表服务中用到的语句，agent中执行的T-SQL，SSIS中执行的T-SQL以及存储过程。找到这类信息就可以知道优化该从何处下手。

			    得到上面的信息后，就可以知道哪些索引应当存在，哪些索引应该删除。

			不要过度创建索引

			    过多的索引和太少的索引都不是好事。表中该有多少索引可不是一个固定的数字。当你为主键，候选键和外键建立了索引之后，剩下的索引该怎么建就需要谨慎分析后再做定夺了。

			要明白这点:同样的数据库在不同的环境下要有不同的索引

			    在忙时或是闲时；在OLTP环境或是OLAP环境下，所需要的索引是不同的。

			    比如每天晚上一次性大量更新数据的报表数据库在这时只需要少量索引，而在日间忙时则需要大量索引。数据库上跑少量查询要比数据库跑大量查询需要更少的索引。

			要给每个表设置主键

			    虽然SQL Server并不强制要求设置主键。但一个没有主键的表无论在OLTP还是OLAP环境下都是一件危险的事，因为没有主键就不能保证每行是唯一的。这时你就无法知道同一行数据是否在表
			    中存在两条，尤其是在你还没有足够的信息去分析这点时。

			    尽管SQL Server不强制要求设置主键，但主键是关系数据库的一个关键理论。如果没有主键约束，那么与之关联的唯一索引或是连接操作就有可能产生意料之外的性能问题。

			    除此之外，很多第三方开发工具或插件也要求表有主键，比如说吧，ADO.Net的SqlCommandBuilder和Entity Data Modeler都依赖表中存在主键约束。另外，主键约束会创建一个同名的唯一索引来保
			    证主键的唯一性。

			考虑给每个表设置聚集索引

			    本系列第三篇关于聚集索引的文章阐述了聚集索引带来的好处。使用聚集索引表中的数据就是按聚集索引键的顺序存在而不再以堆存放。使用聚集索引的好处是使得数据按照聚集索引键的顺序
			    存放，并使得后插入的元素依然保持这个顺序。

			    如果你遵循了上一个建议，那么每个表都应该有主键，因此，每一个表都应该有一个或多个索引，让其中的一个索引成为聚集索引。聚集索引本身并不会使得表上多了一个索引，而是让表的结
			    构更好的组织。

			    选择聚集索引键时，要记住第六篇文章中所说的，聚集索引键应该唯一，短和尽量不需要改动。

			考虑使用外键作为聚集索引键的最左列

			    将外键设置为聚集索引的最左列就是将表中的数据按照这列的值进行汇总和组织，这也是查询所需。比如说你用信用卡消费这个行为是和卡关联最强的的，而不是和你刷卡的商场以及处理这笔
			    消费的银行。则将信用卡号作为消费记录表中聚集索引的最左列，使得所有同一张卡的消费信息就会存在连续的页中。

			    当然了，你还需要另外一个很少变动的列和这个信用卡号列组合起来保证聚集索引键的唯一性。

			考虑为索引添加包含列

			    （译者注：这里作者文章有BUG，这段和上段一样，我就大胆的写一下原因吧。）为索引添加包含列的原因是减少对索引所在表的书签查找。因为包含列不会占用索引的非叶子节点空间，所以
			    不会影响B树的高度，通过在叶子节点附加上一些列，使得索引更容易的“覆盖”所请求的查询，从而减少了书签查找，降低了查询成本。

			    但同样，使用包含列使得非聚集索引占用的空间增加了，所以使用包含列时要综合考虑。

			避免为重复值很多的未过滤列创建非聚集索引

			    更早之前的一条建议“永远不要索引性别列”，是由于这列只会存在男性和女性两个值。当遇到WHERE Gender=的语句时使用表扫描要远远好于书签查找，查询优化器无法从这个索引中获益。

			考虑为列中重复值最多的值创建过滤索引

			    如果某列大量的行中都存在相同的值，这个值可以是NULL，那么使用过滤索引将这个值过滤掉，剩下的值所生成的索引就会更小，小索引使得查询优化器选择书签查找而不是表扫描，SQL 
			    Server也就更容易使用索引。

			考虑使用填充因子来面对未来的数据增长

			    假如一个表中只有几个月的数据，但这个表年底的数据已经可以估算出来时，重建索引的过程中将填充因子设置为7或8，这将使索引占用的页和年底占用的页大致相同，这可以更早的暴漏性能
			    问题，比如说表扫描时IO的占用。

			考虑使用填充因子来减少页分裂

			    加入表中的数据已经达到了页所能容纳的最大值。那么再插入数据就会导致页分裂了。因此重建索引时可以使用填充因子，如果数据库写大于读的话，设置填充因子为75，如果读写大致相等的
			    话，设置填充因子为90到95.

			要在创建非聚集索引之前，先创建聚集索引

			    与之对应的指导方针是：在删除聚集索引之前，先删除非聚集索引。如果你不按照这条方针做，则会导致无意义的重建非聚集索引。将表由聚集索引变为堆会使得表上的
			    非聚集索引重建，因为非聚集索引的书签由聚集索引键变为RID。

			要根据索引的使用频率定期整理索引碎片或是重建索引

		    如果一个索引经常用于扫描，正如我们在第11篇文章中所说，那么外部碎片对于性能的影响就变得非常大。这时你就需要考虑在外部碎片到达10%的时候整理索引了。
		    当外部碎片达到30%时就需要重建索引。对于OLTP环境来说，上面的值是一个分界点，这个点就是整理或重建索引的代价小于其带来的性能提升。
		 -------
	
* NFS services
	
* 机器学习
	
* NAT
	网络地址转换（NAT）简介
	NAT概述
	　　NAT（Network Address Translation，网络地址转换）是将IP 数据包头中的IP 地址转换为另一个IP 地址的过程。在实际应用中，
	NAT 主要用于实现私有网络访问公共网络的功能。这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用IP 地址空间的枯竭。
	　　说明：
	　　私有 IP 地址是指内部网络或主机的IP 地址，公有IP 地址是指在因特网上全球唯一的IP 地址。
	　　RFC 1918 为私有网络预留出了三个IP 地址块，如下：
	　　A 类：10.0.0.0～10.255.255.255
	　　B 类：172.16.0.0～172.31.255.255
	　　C 类：192.168.0.0～192.168.255.255
	　　上述三个范围内的地址不会在因特网上被分配，因此可以不必向ISP 或注册中心申请而在公司或企业内部自由使用。
	NAT工作流程
	　　①如右图这个 client 的 gateway 设定为 NAT 主机，所以当要连上 Internet 的时候，该封包就会被送到 NAT 主机，这个时候的封包 Header 之 source IP 为 192.168.1.100 ；
	　　②而透过这个 NAT 主机，它会将 client 的对外联机封包的 source IP ( 192.168.1.100 ) 伪装成 ppp0 ( 假设为拨接情况 )这个接口所具有的公共 IP ，因为是公共 IP 了，
	所以这个封包就可以连上 Internet 了！同时 NAT 主机并且会记忆这个联机的封包是由哪一个 ( 192.168.1.100 ) client 端传送来的；
		注：这里NAT主机会记忆信息以区分不同client的包
	　　③由 Internet 传送回来的封包，当然由 NAT 主机来接收了，这个时候， NAT 主机会去查询原本记录的路由信息，并将目标 IP 由 ppp0 上面的公共 IP 改回原来的 192.168.1.100 ；
	　　④最后则由 NAT 主机将该封包传送给原先发送封包的 Client 。

	from: http://baike.baidu.com/view/16102.htm
* lvs DR			slb
	- lvs安装
		系统编译进内核方式，或者从源码编译安装
		源码安装好后，要修改系统加载（grub，lilo）配置，内核指向打了lvs的patch编译出的内核，启动时选择此内核。

		查看：ls /lib/modules/xxx

	- DR 
	Direct Routing: Packets from end users are forwarded directly to the real server. The IP
	packet is not modified, so the real servers must be configured to accept traffic for the
	virtual server's IP address. This can be done using a dummy interface or packet filtering
	to redirect traffic addressed to the virtual server's IP address to a local port. The real
	server may send replies directly back to the end user. Thus, the linux director does not
	need to be in the return path.
		第一次需要修改，后续可以直接enduser和realservr通信
	- NAT
		
	- Tunnel
		类似DR，但realserver可以和LD不在同一网络。
	

* linux 系统信息 查看
	linux如何查看系统信息
	一：cpu
	   [root@srv /]# more /proc/cpuinfo | grep "model name"
	 model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	  model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	model name    : Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	[root@srv /]# grep "model name" /proc/cpuinfo | cut -f2 -d:
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	Intel(R) Xeon(R) CPU          X3220 @ 2.40GHz
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	二：内存
	[root@srv /]# grep MemTotal /proc/meminfo
	MemTotal:        614400 kB
	[root@srv /]# free -m
			   total        used        free    shared     buffers    cached
	Mem:          600       23       576           0           0           0
	-/+ buffers/cache:       23       576
	Swap:          0           0           0
	[root@srv /]# free -m |grep "Mem" | awk '{print $2}'
	600

	三：查看CPU位数(32 or 64)
	[root@srv /]# getconf LONG_BIT
	32

	四：查看linux版本
	[root@srv /]# more /etc/redhat-release
	CentOS release 5 (Final)
	[root@srv /]# more /etc/issue
	CentOS release 5 (Final)
	Kernel \r on an \m
	[root@srv /]# more /proc/version
	Linux version 2.6.18-92.1.18.el5.028stab060.2PAE ([email=root@rhel5-32-build-xemul]root@rhel5-32-build-xemul[/email]) (gc
	c version 4.1.2 20071124 (Red Hat 4.1.2-42)) #1 SMP Tue Jan 13 12:31:30 MSK 2009

	五：查看内核版本
	[root@srv /]# uname -r
	2.6.18-92.1.18.el5.028stab060.2PAE
	[root@srv /]# uname -a
	Linux srv.eddiechen.cn 2.6.18-92.1.18.el5.028stab060.2PAE #1 SMP Tue Jan 13 12:31:30 MSK 2009 i686 i686 i386 GNU/Linux

	六：查看时区
	[root@srv /]# date -R
	Wed, 25 Feb 2009 02:20:50 +0000
	[root@srv /]# mv /etc/localtime /etc/localtime.save
	[root@srv /]# cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
	[root@srv /]# date -R
	Wed, 25 Feb 2009 10:24:26 +0800

	七：主机名
	查看主机名
	[root@srv /]# hostname
	www.ifuoo.com
	修改主机名
	[root@srv /]# cat /etc/sysconfig/network
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	八：查看selinux情况
	[root@srv /]# sestatus
	SELinux status:                disabled

	九：网络
	IP
	[root@srv /]# ifconfig | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'
	207.154.202.216
	网关
	[root@srv /]# cat /etc/sysconfig/network
	NETWORKING="yes"
	GATEWAY="192.0.2.1"
	HOSTNAME="srv.eddiechen.cn"
	dns
	[root@srv /]# cat /etc/resolv.conf
	nameserver 208.74.168.131
	nameserver 208.74.168.132
	nameserver 4.2.2.1
	修改Host文件
	[root@srv /]# cat /etc/hosts
	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	十：已经安装的软件包
	[root@srv /]# rpm -qa | wc -l
	197
	[root@srv /]# yum list installed | wc -l
	198

	十一：磁盘和分区
	[root@srv /]# df -h
	Filesystem          Size    Used          Avail Use    %    Mounted on

	/dev/simfs              10G     353M              9.7G       4%    /

	[root@srv /]# du -sh

	353M

	[root@srv /]# du /etc -sh

	4.6M     /etc

	linux如何查看系统信息（转） - 飞翔天空 - 飞翔天空

	九：查看键盘布局

	cat /etc/sysconfig/keyboard

	cat /etc/sysconfig/keyboard | grep KEYTABLE | cut -f2 -d=

	十二：查看默认语言

	echo $LANG $LANGUAGE

	cat /etc/sysconfig/i18n

	==================================

	http://hi.baidu.com/mypc007

	通过以下命令，可以查看RS/6000系统配备的物理内存的大小。

	　　lsdev -Cc memory

	　　查看RS/6000配置的物理内存设备，下面为其输出示例：

	　　mem0 Available 00-00 Memory

	　　L2cache0 Available 00-00 L2 Cache

	　　再使用命令

	　　lsattr -El mem0

	　　输出如下

	　　size 512 Total amount of physical memory in Mbytes False

	　　goodsize 512 Amount of usable physical memory in Mbytes False

	　　此例说明机器的物理内存为512MB。如果前面lsdev的输出中有设备名 mem1，则使用同样的命令查看其对应的大小并依此类推。L2cache0 为系统二级缓存(Level 2 Cache)的设备名。同样，使用命令：

	　　lsattr -El L2cache0

	　　可以查看其大小。

	查看LINUX系统位数

	1.编程实现：

	在程序中返回sizeof(int)的值，返回的结果是操作系统的字节数。若返回4则是32位操作系统，返回8即是64位。

	2.getconf命令：

	getconf命令可以获取系统的基本配置信息，比如操作系统位数，内存大小，磁盘大小等。

	例如：

	确定磁盘 hdisk0 大小，若是 root 用户，则输入：

	getconf DISK_SIZE /dev/hdisk0

	确定实际内存大小：getconf REAL_MEMORY

	确定是否机器硬件是 32 位或 64 位：getconf HARDWARE_BITMODE

	确定是否内核是 32 位或 64 位： getconf KERNEL_BITMODE

	若以上的getconf KERNEL_BITMODE方法不成功(在我的机器上就不成功)，可能是因为版本不一致，可以再尝试用：getconf WORD_BIT，这个命令返回int类型的长度，与sizeof(int)一致。
* diff和patch使用指南
　　diff和patch是一对工具，在数学上来说，diff是对两个集合的差运算，patch是对两个集合的和运算。
　　diff比较两个文件或文件集合的差异，并记录下来，生成一个diff文件，这也是我们常说的patch文件，即补丁文件。
　　patch能将diff文件运用于 原来的两个集合之一，从而得到另一个集合。举个例子来说文件A和文件B,经过diff之后生成了补丁文件C,那么着个过程相当于 A -B = C ,
	那么patch的过程就是B+C = A 或A-C =B。	
	
　　	因此我们只要能得到A, B, C三个文件中的任何两个，就能用diff和patch这对工具生成另外一个文件。
　　这就是diff和patch的妙处。下面分别介绍一下两个工具的用法:
　　1). diff的用法
　　diff后面可以接两个文件名或两个目录名。 如果是一个目录名加一个文件名，那么只作用在那么个目录下的同名文件。
　　如果是两个目录的话，作用于该目录下的所有文件，不递归。如果我们希望递归执行，需要使用-r参数。
　　命令diff A B >C ,一般A是原始文件，B是修改后的文件，C称为A的补丁文件。

　　	不加任何参数生成的diff文件格式是一种简单的格式，这种格式只标出了不一样的行数和内容。我们需要一种更详细的格式，可以标识出不同之处的上下文环境，
	这样更有利于提高patch命令的识别能力。这个时候可以用-c开关。	
　　2). patch的用法
　　patch用于根据原文件和补丁文件生成目标文件。还是拿上个例子来说
　　patch A C 就能得到B, 这一步叫做对A打上了B的名字为C的补丁。
　　之一步之后，你的文件A就变成了文件B。如果你打完补丁之后想恢复到A怎么办呢？
　　patch -R B C 就可以重新还原到A了。
　　所以不用担心会失去A的问题。
　　其实patch在具体使用的时候是不用指定原文件的，因为补丁文件中都已经记载了原文件的路径和名称。patch足够聪明可以认出来。但是有时候会有点小问题。比如一般对两个目录diff的时候可能已经包含了原目录的名字，但是我们打补丁的时候会进入到目录中再使用patch,着个时候就需要你告诉 patch命令怎么处理补丁文件中的路径。可以利用-pn开关，告诉patch命令忽略的路径分隔符的个数。举例如下：
　　A文件在 DIR_A下，修改后的B文件在DIR_B下，一般DIR_A和DIR_B在同一级目录。我们为了对整个目录下的所有文件一次性diff,我们一般会到DIR_A和DIR_B的父目录下执行以下命令
　　diff -rc DIR_A DIR_B >C
　　这个时候补丁文件C中会记录了原始文件的路径为 DIR_A/A
　　现在另一个用户得到了A文件和C文件，其中A文件所在的目录也是DIR_A。 一般，他会比较喜欢在DIR_A目录下面进行patch操作，它会执行	   
　　
	patch
　　但是这个时候patch分析C文件中的记录，认为原始文件是./DIR_A/A，但实际上是./A，此时patch会找不到原始文件。为了避免这种情况我们可以使用-p1参数如下
　　patch -p1	     
　　此时，patch会忽略掉第1个”/”之前的内容，认为原始文件是 ./A，这样就正确了。
　　最后有以下几点注意：
　　1). 一次打多个patch的话，一般这些patch有先后顺序，得按次序打才行。
　　2). 在patch之前不要对原文件进行任何修改
　　3). 如果patch中记录的原始文件和你得到的原始文件版本不匹配(很容易出现)，那么你可以尝试使用patch, 如果幸运的话，可以成功。大部分情况下，会有不匹配的情况，此时patch会生成rej文件，记录失败的地方，你可以手工修改。

	from: http://www.linuxsky.org/doc/admin/200712/213.html

* xen 内存管理
	xm info 查看总内存和可使用的内存

	xm list
	也看查看dom0的内存数

	free -m 查看dom0的内存使用情况

	如果dom0占用过多内存，可以通过
	xm mem-set 0 xxx设置dom0的内存

	centos5 xen3
	创建domu时，报内存问题：

		网上搜索确定为xen的一个bug，可通过打patch解决。

	想到centos5上安装xen4，但Redhat 和Cent OS系统现在集成的是Xen3.x的版本，如果你不愿意折腾自行编译安装Xen4,下面教你用第三方Yum源快速安装xen4：
		$ cd /etc/yum.repos.d
		$ sudo wget http://www.gitco.de/repo/GITCO-XEN4.0.0_testing_x86_64.repo
		$ sudo yum update
		Dependencies Resolved
		==========================================================================================
		Package Arch Version Repository Size
		==========================================================================================
		Updating:
		xen x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 12 M
		xen-devel x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 408 k
		xen-libs x86_64 4.0.0-3.el5 gitco-xen4.0.0-testing 366 k
		Transaction Summary
		==========================================================================================
		Install 0 Package(s)
		Update 3 Package(s)
		Remove 0 Package(s)
		Total download size: 13 M
		Is this ok [y/N]: y
		grub.conf添加记录
		title CentOS (2.6.18-164.15.1.el5xen)
		root (hd0,0)
		kernel /xen.gz-4.0.0
		module /vmlinuz-2.6.18-164.15.1.el5xen ro root=/dev/VolGroup00/LogVol00 rhgb quiet
		module /initrd-2.6.18-164.15.1.el5xen.img
		重启即可
		$ sudo reboot
		from: http://bbs.linuxtone.org/thread-7259-1-1.html

		xen第三方源：http://www.gitco.de/repo/

* linux 安装方式
	系统集成了的软件安装
	源码编译安装
		如果需要打patch，则打好相应的patch后再编译安装
	第三方源安装
* linux c 开发
	eg：keepalived目录结构
		bin		- 制作好的rpm包
		patch	- svn更新patch
		source	- 源码包
		spec - 用于制作rpm包

* 打开outlook的时候，错误提示“无法启动Microsoft Office Outlook。无法打开Outlook窗口”	* 修复 *系统修复　* 自修复
	    重启机器仍无法解决问题。
	    解决办法：
	    Win7：开始> 搜索程序和文件夹里》输入“Outlook.exe /resetnavpane”回车
	    WinXP：开始>执行>输入“Outlook.exe /resetnavpane”回车
	    然后正常启动就可以了。
	怕你输错，直接把我引号里的复制过去。

	ps：
		这个自修复功能还是蛮不错的

* IP转发 * ip forward ,在Linux中使能IP转发
	
	应用：iptables中配置ip转发规则，需要开启ip转发功能。

	Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统，使用下面命令：
	cat /proc/sys/net/ipv4/ip_forward
 	如果上述文件中的值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。
	要想打开IP转发功能，可以直接修改上述文件：
	echo 1 > /proc/sys/net/ipv4/ip_forward
	把文件的内容由0修改为1。禁用IP转发则把1改为0。
	上面的命令并没有保存对IP转发配置的更改，下次系统启动时仍会使用原来的值，要想永久修改IP转发，需要修改/etc/sysctl.conf文件，修改下面一行的值：
	net.ipv4.ip_forward = 1
	修改后可以重启系统来使修改生效，也可以执行下面的命令来使修改生效：
	sysctl -p /etc/sysctl.conf
	进行了上面的配置后，IP转发功能就永久使能了
	from: http://easwy.com/blog/archives/enable-ip-forward-on-linux/

	How to enable IP Forwarding in Linux
		By default any modern Linux distributions will have IP Forwarding disabled. This is normally a good idea, as most peoples will not need IP Forwarding, but if we are setting up a Linux router/gateway or maybe a VPN server (pptp or ipsec) or just a plain dial-in server then we will need to enable forwarding. This can be done in several ways that I will present bellow.
		Check if IP Forwarding is enabled
		We have to query the sysctl kernel value net.ipv4.ip_forward to see if forwarding is enabled or not:
		Using sysctl:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 0
		or just checking out the value in the /proc system:
		cat /proc/sys/net/ipv4/ip_forward
		0
		As we can see in both the above examples this was disabled (as show by the value 0).
		Enable IP Forwarding on the fly
		As with any sysctl kernel parameters we can change the value of net.ipv4.ip_forward on the fly (without rebooting the system):
		sysctl -w net.ipv4.ip_forward=1
		or
		echo 1 > /proc/sys/net/ipv4/ip_forward
		the setting is changed instantly; the result will not be preserved after rebooting the system.
		Permanent setting using /etc/sysctl.conf
		If we want to make this configuration permanent the best way to do it is using the file /etc/sysctl.conf where we can add a line containing net.ipv4.ip_forward = 1
		/etc/sysctl.conf:
		net.ipv4.ip_forward = 1
		if you already have an entry net.ipv4.ip_forward with the value 0 you can change that 1.
		To enable the changes made in sysctl.conf you will need to run the command:
		sysctl -p /etc/sysctl.conf
		On RedHat based systems this is also enabled when restarting the network service:
		service network restart
		and on Debian/Ubuntu systems this can be also done restarting the procps service:
		/etc/init.d/procps.sh restart
		Using distribution specific init scripts
		Although the methods presented above should work just fine and you would not need any other method of doing this, I just wanted to note that there are also other methods to enable IP Forwarding specific to some Linux distributions.
		For example Debian based distributions might use the setting:
		/etc/network/options:
		ip_forward=no
		set it to yes and restart the network service.
		Also RedHat distributions might set this using:
		/etc/sysconfig/network:
		FORWARD_IPV4=true
		and again restart the network service.
		Regardless the method you have used once you have completed this you can check it out using the same method shown above:
		sysctl net.ipv4.ip_forward
		net.ipv4.ip_forward = 1
		cat /proc/sys/net/ipv4/ip_forward
		1
		If the result is 1 then the Linux system will start forwarding IP packets even if they are not destined to any of its own network interfaces.
		ps. I was setting up a VPN dial-in server when I wrote this post 

* keepalived是VRRP的完美实现，因此在介绍keepalived之前，先介绍一下VRRP的原理。
	VRRP协议简介
	在现实的网络环境中，两台需要通信的主机大多数情况下并没有直接的物理连接。对于这样的情况，它们之间路由怎样选择？主机如何选定到达目的主机的下一跳路由，
	这个问题通常的解决方法有二种：
	·        在主机上使用动态路由协议(RIP、OSPF等)
	·        在主机上配置静态路由
	很明显，在主机上配置路态路由是非常不切实际的，因为管理、维护成本以及是否支持等诸多问题。配置静态路由就变得十分流行，但路由器(或者说默认网关default gateway)却经常
	成为单点。
	VRRP的目的就是为了解决静态路由单点故障问题。

	VRRP通过一竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。

	工作机制

	在一个VRRP虚拟路由器中，有多台物理的VRRP路由器，但是这多台的物理的机器并不能同时工作，而是由一台称为MASTER的负责路由工作，其它的都是BACKUP，MASTER并非一成不变，VRRP让每个VRRP路由器参与竞选，最终获胜的就是MASTER。MASTER拥有一些特权，比如 拥有虚拟路由器的IP地址，我们的主机就是用这个IP地址作为静态路由的。拥有特权的MASTER要负责转发发送给网关地址的包和响应ARP请求。

	VRRP通过竞选协议来实现虚拟路由器的功能，所有的协议报文都是通过IP多播(multicast)包(多播地址 224.0.0.18)形式发送的。虚拟路由器由VRID(范围0-255)和一组IP地址组成，对外表现为一个周知的MAC地址。所以，在一个虚拟路由 器中，不管谁是MASTER，对外都是相同的MAC和IP(称之为VIP)。客户端主机并不需要因为MASTER的改变而修改自己的路由配置，对他们来 说，这种主从的切换是透明的。

	在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP广告包(VRRPAdvertisement message)，BACKUP不会抢占MASTER，除非它的优先级(priority)更高。当MASTER不可用时(BACKUP收不到广告包)， 多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(<1s)，以保证服务的连续性。

	由于安全性考虑，VRRP包使用了加密协议进行加密。

	==========================================

	vrrp简介
	随着Internet的迅猛发展，基于网络的应用逐渐增多。这就对网络的可靠性提出了越来越高的要求。斥资对所有网络设备进行更新当然是一种很好的可靠性解决方案；但本着保护现有投资的角度考虑，可以采用廉价冗余的思路，在可靠性和经济性方面找到平衡点。

	  虚拟路由冗余协议就是一种很好的解决方案。在该协议中，对共享多存取访问介质（如以太网）上终端IP设备的默认网关(Default Gateway)进行冗余备份，从而在其中一台路由设备宕机时，备份路由设备及时接管转发工作，向用户提供透明的切换，提高了网络服务质量。 

	一、协议概述

	  在基于TCP/IP协议的网络中，为了保证不直接物理连接的设备之间的通信，必须指定路由。目前常用的指定路由的方法有两种：一种是通过路由协议（比如：内部路由协议RIP和OSPF）动态学习；另一种是静态配置。在每一个终端都运行动态路由协议是不现实的，大多客户端操作系统平台都不支持动态路由协议，即使支持也受到管理开销、收敛度、安全性等许多问题的限制。因此普遍采用对终端IP设备静态路由配置，一般是给终端设备指定一个或者多个默认网关(Default Gateway)。静态路由的方法简化了网络管理的复杂度和减轻了终端设备的通信开销，但是它仍然有一个缺点：如果作为默认网关的路由器损坏，所有使用该网关为下一跳主机的通信必然要中断。即便配置了多个默认网关，如不重新启动终端设备，也不能切换到新的网关。采用虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)可以很好的避免静态指定网关的缺陷。

	  在VRRP协议中，有两组重要的概念：VRRP路由器和虚拟路由器，主控路由器和备份路由器。VRRP路由器是指运行VRRP的路由器，是物理实体，虚拟路由器是指VRRP协议创建的，是逻辑概念。一组VRRP路由器协同工作，共同构成一台虚拟路由器。该虚拟路由器对外表现为一个具有唯一固定IP地址和MAC地址的逻辑路由器。处于同一个VRRP组中的路由器具有两种互斥的角色：主控路由器和备份路由器，一个VRRP组中有且只有一台处于主控角色的路由器，可以有一个或者多个处于备份角色的路由器。VRRP协议使用选择策略从路由器组中选出一台作为主控，负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。当由于某种原因主控路由器发生故障时，备份路由器能在几秒钟的时延后升级为主路由器。由于此切换非常迅速而且不用改变IP地址和MAC地址，故对终端使用者系统是透明的。 

	二、工作原理

	  一个VRRP路由器有唯一的标识：VRID，范围为0—255。该路由器对外表现为唯一的虚拟MAC地址，地址的格式为00-00-5E-00-01-[VRID]。主控路由器负责对ARP请求用该MAC地址做应答。这样，无论如何切换，保证给终端设备的是唯一一致的IP和MAC地址，减少了切换对终端设备的影响。

	  VRRP控制报文只有一种：VRRP通告(advertisement)。它使用IP多播数据包进行封装，组地址为224.0.0.18，发布范围只限于同一局域网内。这保证了VRID在不同网络中可以重复使用。为了减少网络带宽消耗只有主控路由器才可以周期性的发送VRRP通告报文。备份路由器在连续三个通告间隔内收不到VRRP或收到优先级为0的通告后启动新的一轮VRRP选举。

	  在VRRP路由器组中，按优先级选举主控路由器，VRRP协议中优先级范围是0—255。若VRRP路由器的IP地址和虚拟路由器的接口IP地址相同，则称该虚拟路由器作VRRP组中的IP地址所有者；IP地址所有者自动具有最高优先级：255。优先级0一般用在IP地址所有者主动放弃主控者角色时使用。可配置的优先级范围为1—254。优先级的配置原则可以依据链路的速度和成本、路由器性能和可靠性以及其它管理策略设定。主控路由器的选举中，高优先级的虚拟路由器获胜，因此，如果在VRRP组中有IP地址所有者，则它总是作为主控路由的角色出现。对于相同优先级的候选路由器，按照IP地址大小顺序选举。VRRP还提供了优先级抢占策略，如果配置了该策略，高优先级的备份路由器便会剥夺当前低优先级的主控路由器而成为新的主控路由器。

	  为了保证VRRP协议的安全性，提供了两种安全认证措施：明文认证和IP头认证。明文认证方式要求：在加入一个VRRP路由器组时，必须同时提供相同的VRID和明文密码。适合于避免在局域网内的配置错误，但不能防止通过网络监听方式获得密码。IP头认证的方式提供了更高的安全性，能够防止报文重放和修改等攻击。

	三、 应用实例

	  最典型的VRRP应用：RTA、RTB组成一个VRRP路由器组，假设RTB的处理能力高于RTA，则将RTB配置成IP地址所有者，H1、H2、H3的默认网关设定为RTB。则RTB成为主控路由器，负责ICMP重定向、ARP应答和IP报文的转发；一旦RTB失败，RTA立即启动切换，成为主控，从而保证了对客户透明的安全切换。

	  在VRRP应用中，RTA在线时RTB只是作为后备，不参与转发工作，闲置了路由器RTA和链路L1。通过合理的网络设计，可以到达备份和负载分担双重效果。让RTA、RTB同时属于互为备份的两个VRRP组：在组1中RTA为IP地址所有者；组2中RTB为IP地址所有者。将H1的默认网关设定为RTA；H2、H3的默认网关设定为RTB。这样，既分担了设备负载和网络流量，又提高了网络可靠性。

	  VRRP协议的工作机理与CISCO公司的HSRP（Hot Standby Routing Protocol）有许多相似之处。但二者主要的区别是在CISCO的HSRP中，需要单独配置一个IP地址作为虚拟路由器对外体现的地址，这个地址不能是组中任何一个成员的接口地址。

	  使用VRRP协议，不用改造目前的网络结构，最大限度保护了当前投资，只需最少的管理费用，却大大提升了网络性能，具有重大的应用价值。

* linux
	- run level 运行级别
		 Linux下有7个运行级别：

		0 系统停机模式，系统默认运行级别不能设置为0，否则不能正常启动，机器关闭。
		1) 单用户模式，root权限，用于系统维护，禁止远程登陆，就像Windows下的安全模式登录。
		2) 多用户模式，没有NFS网络支持。
		3) 完整的多用户文本模式，有NFS，登陆后进入控制台命令行模式。
		4) 系统未使用，保留一般不用，在一些特殊情况下可以用它来做一些事情。例如在笔记本电脑的电池用尽时，可以切换到这个模式来做一些设置。
		5) 图形化模式，登陆后进入图形GUI模式，X Window系统。
		6) 重启模式，默认运行级别不能设为6，否则不能正常启动。运行init 6机器就会重启。

		运行级别原理：

		1).在目录/etc/rc.d/init.d下有许多服务器脚本程序，一般称为服务(service)
		2).在/etc/rc.d下有7个名为rcN.d的目录，对应系统的7个运行级别
		3).rcN.d目录下都是一些符号链接（即软链接）文件，这些链接文件都指向/etc/rc.d/init.d目录下的service脚本文件，命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位阿拉伯数字。
		4).系统启动时，会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件：对于以K开头的文件，系统将终止对应的服； 对于以S开头的文件，系统将启动对应的服务
		5).查看运行级别用：runlevel
		#表示当前系统运行在level 3模式下
		6).进入其它运行级别用：init N，如果init 3则进入终端模式，init 5则登录图形GUI模式
		#表示运行级别由3进入到5
		#再次输入init 3，则运行级别由5回到3
		7).另外init0为关机，init 6为重启系统
		 注意：输入init 0，系统会关机；输入init 6，系统会自动重启。这两个命令要非常小心！

		标准的Linux运行级别为3或5，如果是3的话，系统就在多用户状态；如果是5的话，则是运行着X Window系统。
		不同的运行级别有不同的用处，也应该根据自己的不同情形来设置。
		例如，如果丢失了root口令，那么可以让机器启动进入单用户状态来设置。
		1). 在启动后的GRUB界面输入e；
		2).光标选择kernel那一行，再次输入e；
		3).在最后添加“空格single”，回车；
		4).按b键进入单用户模式；
		5).通过passwd root命令，修改root的密码；
		6).重启系统。
	- 

* 分布式存储
	http://www.cnblogs.com/jason-one/archive/2008/12/17/1356461.html

* 单点问题，单点故障
	- 单点session问题，采用分布式session实现无单点故障的分布式session服务
		·memcache + 
* iptables * 防火墙 * linux防火墙设置
	--------
		 linux防火墙基础和管理设置iptables规则

		 一、linux防火墙基础
		防火墙分为硬件防火墙和软件防火墙。
		1.概述
		linux 防火墙体系主要工作在网络层，针对TCP/IP数据包实施过滤和限制，属于典型的包过滤防火墙。
		包过滤机制：netfilter
		管理防火墙规则命令工具：iptables
		netfilter 指linux内核中实现包过滤防火墙的内部结构，不依程序或文件的形式存在，属于“内核态”的防火墙功能体系
		iptables 指管理linux防火墙的命令工具，属于“用户态”的防火墙管理体系
		2.iptables的规则表、链结构
		iptables的作用在于为包过滤机制的实现提供规则，通过不同的规则作出不同的反应.
		iptables管理4个表、以及他们的规则链
		   filter,用于路由网络数据包。
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包从服务器流出
		FORWARD 网络数据包经服务器路由
		   nat,用于NAT表.NAT(Net Address Translation )是一种IP地址转换方法。
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		OUTPUT 网络数据包流出服务器
		   mangle,用于修改网络数据包的表，如TOS(Type Of Service),TTL(Time To Live),等
		INPUT 网络数据包流向服务器
		OUTPUT 网络数据包流出服务器
		FORWARD 网络数据包经由服务器转发
		PREROUTING 网络数据包到达服务器时可以被修改
		POSTROUTING 网络数据包在即将从服务器发出时可以被修改
		   raw, 用于决定数据包是否被跟踪机制处理
		OUTPUT 网络数据包流出服务器
		PREROUTING 网络数据包到达服务器时可以被修改
		3.数据包过滤匹配流程
		1>.规则表之间的优先顺序
		依次应用：raw、mangle、nat、filter表
		2>.规则链之间的优先顺序
		入站数据流向
		转发数据流向
		出站数据流向
		3>.规则链内部各条防火墙规则之间的优先顺序
		 
		二、管理和配置Iptables规则
		1.iptables的基本语法格式
		iptables [-t 表名] 命令选项 [链名] [条件匹配] [-] 目标动作或跳转
		表名链名用于指定iptables命令所做对象，未指定默认filter表，命令选项指于管理iptables规则的方式（插入、删除··）；条件匹配指定对条件的符合而处理；目标动作或跳转指定数据包的处理方式。
		2.管理iptables规则
		控制选项
		 -A 在链尾添加一条规则
		　-D 从链中删除一条规则
		 -I 在链中插入一条规则
		 -R 修改、替换某链的某规则
		 -L 列出某个链上的规则
		 -F 清空链，删除链上的所有规则
		 -N 创建一个新链
		 -X 删除某个规则链
		 -P 定义某个链的默认策略
		     -n 数字形式显示结果
		 -v 查看规则列表详细信息
		 -V 查看iptables命令工具版本
		 -h 查看命令帮助信息
		 -line-numbers 查看规则列表，显示顺序号
		增加、插入、删除和替换规则
		相关规则定义的格式为：
		iptables  [-t表名]  <-A | I | D | R> 链名 [规则编号] [-i | o 网卡名称] [-p 协议类型] [-s 源IP地址 | 源子网] [--sport 源端口号] [-d目标IP地址 | 目标子网] [--dport目标端口号] <-j动作>
		参数说明如下。
		[-t表名]：定义默认策略将应用于哪个表，可以使用filter、nat和mangle，如果没有指定使用哪个表，iptables就默认使用filter表。
		-A：新增加一条规则，该规则将会增加到规则列表的最后一行，该参数不能使用规则编号。
		-I：插入一条规则，原本该位置上的规则将会往后顺序移动，如果没有指定规则编号，则在第一条规则前插入。
		-D：从规则列表中删除一条规则，可以输入完整规则，或直接指定规则编号加以删除。
		-R：替换某条规则，规则被替换并不会改变顺序，必须要指定替换的规则编号。
		<链名>：指定查看指定表中哪个链的规则列表，可以使用INPUT、OUTPUT、FORWARD、PREROUTING、OUTPUT和POSTROUTING。
		[规则编号]：规则编号用于插入、删除和替换规则时用，编号是按照规则列表的顺序排列，规则列表中第一条规则的编号为1。
		[-i | o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出。网卡名称可以使用ppp0、eth0和eth1等。
		[-p 协议类型]：可以指定规则应用的协议，包含TCP、UDP和ICMP等。
		[-s 源IP地址 | 源子网]：源主机的IP地址或子网地址。
		[--sport 源端口号]：数据包的IP的源端口号。
		[-d目标IP地址 | 目标子网]：目标主机的IP地址或子网地址。
		[--dport目标端口号]：数据包的IP的目标端口号。 
		<-j动作>：处理数据包的动作，各个动作的详细说明可以参考表10-3。 
		1>.添加及插入规则
		   在Filter表的INPUT链的末尾添加一条防护墙规则
		[root@s2 ~]# iptables -t filter -A INPUT -p tcp -j ACCEPT
		   在Filter表的INPUT链中插入一条防护墙规则
		[root@s2 ~]# iptables -I INPUT -p udp -j ACCEPT
		   在在Filter表的INPUT链中插入一条防护墙规则（为链中第二条规则）
		[root@s2 ~]# iptables -I INPUT 2 -p icmp -j ACCEPT
		2>.查看规则表
		   查看Filter表的INPUT链中的所有规则，同时显示顺序号
		[root@s2 ~]# iptables -L INPUT --line-numbers
		Chain INPUT (policy ACCEPT)
		num  target     prot opt source               destination         
		1    ACCEPT     udp  --  anywhere             anywhere            
		2    ACCEPT     icmp --  anywhere             anywhere            
		3    REJECT     icmp --  anywhere             anywhere  
		   查看filter表各链中所有规则的详细信息，以数字形式显示地址和端口信息
		[root@s2 ~]# iptables -vnL
		Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
		pkts bytes target     prot opt in     out     source               destination         
		1189  154K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 ACCEPT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           
		   0     0 REJECT     icmp --  *      *       0.0.0.0/0            0.0.0.0/0           reject-with icmp-port-unreachable 
		2449  221K ACCEPT     udp  --  *      *       0.0.0.0/0            0.0.0.0/0           
		3>.删除、清空规则
		   删除Filter表的INPUT链中的第2条规则
		[root@s2 ~]# iptables -D INPUT 2
		   清空filter表、nat表、mangle表各链中的所有规则	
		[root@s2 ~]# iptables -F
		[root@s2 ~]# iptables -t nat -F
		[root@s2 ~]# iptables -t mangle -F
		4>.设置规则链的默认策略
		最基本的两种策略为ACCEPT（允许）、DROP（丢弃）
		   将filter表中的FORWARD规则链的默认策略设为 DROP
		[root@s2 ~]# iptables -t filter -P FORWARD DROP
		   将filter表中的 OUTPUT规则链的默认策略设为 ACCEPT
		[root@s2 ~]# iptables -P OUTPUT ACCEPT
		5>.获得iptables相关选项用法的帮助信息
		   查看iptables命令中关于icmp协议的信息
		[root@s2 ~]# iptables -p icmp -h
		6>.新增、删除自定义规则链
		   清空raw表中自定义的所有规则链
		[root@s2 ~]# iptables -t raw -X
		3.条件匹配
		1>.通用条件匹配
		一般直接使用，而不依赖于其他的条件匹配及其扩展。常见匹配方式如下：
		协议匹配：用于检查数据包的网络协议
		拒绝进入防火墙的所有icmp协议数据包
		[root@s2 ~]# iptables -I INPUT -p icmp -j REJECT
		允许防火墙转发除icmp协议以外的所有数据包（“！”反取）	
		[root@s2 ~]# iptables -A FORWARD -p ! icmp -j ACCEPT
		[root@s2 ~]# iptables -L FORWARD
		Chain FORWARD (policy DROP)
		target     prot opt source               destination         
		ACCEPT    !icmp --  anywhere             anywhere    
		地址匹配：用于检查数据包的IP地址、网络地址。
		拒绝转发来自192.168.1.11主机的数据，允许来自192.168.0.0/24网段数据
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.11 -j REJECT
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT
		网络接口匹配：用于检查数据包从防火墙的哪个接口进入或离开
		丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROP
		[root@s2 ~]# iptables -A INPUT -i eth1 -s 10.0.0.0/8 -j DROP
		封堵IP地址段！并2小时后解锁
		[root@s2 ~]# iptables -I INPUT -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# iptables -I FORWARD -s 10.20.30.0/24 -j DROP
		[root@s2 ~]# at now +2 hours
		at> iptables -D INPUT 1
		at> iptables -D FORWARD 1
		at> <EOT>
		job 1 at 2010-04-25 17:43
		2>.隐含条件匹配
		通常需要以指定的协议匹配为前提，对应功能由iptables自动装载内核。常见的隐含匹配方式如下：
		端口匹配：用于检查数据包的TCP或UDP端口号
		仅允许系统管理员从202.13.0.0/16网段使用SSH方式远程登录防火墙主机
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 22 -j DROP
		允许本机开放TCP端口的 20 ~ 1024 提供的应用服务
		[root@s2 ~]# iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPT
		[root@s2 ~]# iptables -A OUTPUT -p tcp --sport 20:1024 -j ACCEPT
		允许转发来自192.168.0.0/24局域网段的DNS解析请求数据包
		[root@s2 ~]# iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPT
		[root@s2 ~]# iptables -A FORWARD -d 192.168.0.0/24 -p udp --sport 53 -j ACCEPT
		TCP标记匹配：用于检查数据包的TCP标记位
		拒绝从外网接口（eth1）直接访问防火墙本机的数据包，但允许响应防火墙TCP请求的数据包进入
		[root@s2 ~]# iptables -P INPUT DROP
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags SYN, RST, ACK SYN -j REJECT
		[root@s2 ~]# iptables -I INPUT -i eth1 -p tcp --tcp-flags ! --syn -j ACCEPT
		ICMP类型匹配：用于检查ICMP数据包
		禁止其他主机ping防火墙主机，但是允许防火墙能ping其他主机
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Request -j DROP
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type Echo-Reply -j ACCEPT
		[root@s2 ~]# iptables -A INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT
		显示条件匹配：需要额外的内核模块提供，因此需要手工指定匹配方式
		MAC地址匹配：主要检查数据包的源MAC地址
		[root@s2 ~]# iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3F -j DROP
		多端口匹配：检查数据包的源端口、目标端口时，用于匹配多个不连续的端口号。
		[root@s2 ~]# iptables -A INPUT -p tcp -m multiport --dport 20.21.24.11.1250:1280 -j ACCEPT
		多IP地址匹配：检查数据包的源地址、目标地址时，用于匹配一段范围内的IP地址
		[root@s2 ~]# iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP
		状态匹配：基于iptables的状态跟踪机制，检查数据包的连接状态
		禁止转发与正常TCP连接无关的非--syn请求数据包
		[root@s2 ~]# iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP
		4.数据包控制
		最常见处理方式;
		ACCEPT:允许数据包通过
		DROP：直接丢弃数据包，不给任何回应信息
		REJECT：拒绝数据包通过，必要时发个响应信息
		LOG: 记录日志信息，将数据包递给下一条规则
		对于尝试通过SSH方式登录防火墙主机的访问数据，记录日志信息并禁止访问
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j DROP
		[root@s2 ~]# iptables -I INPUT -p tcp --dport 22 -j LOG
		用户自定义链：将数据传给用户自定义的链进行处理
		自定义一个链MYLAN 转发至192.168.1.0/24 网段数据包交给该链中的规则处理。
		[root@s2 ~]# iptables -t filter -N MYLAN
		[root@s2 ~]# iptables -A FORWARD -s 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A FORWARD -d 192.168.1.0/24 -j MYLAN
		[root@s2 ~]# iptables -A MYLAN -p icmp -j DROP
		SNAT:（源地址转换）修改数据包的源IP地址
		DNAT:（目标地址转换）修改数据包的目标IP地址
		 

		from: http://xiaozhuang.blog.51cto.com/4396589/874244

	--------
* redis
		redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。

* jboss优化，服务器优化，系统优化

	   JBOSS访问缓慢，查看jboss的并发请求数及其TCP连接状态：
	netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
	LAST_ACK 5
	SYN_RECV 263
	CLOSE_WAIT 30
	ESTABLISHED 308
	FIN_WAIT1 499
	FIN_WAIT2 71
	CLOSING 20
	TIME_WAIT 19070
	检查发现TIME_WAIT 状态链接很高, 这样就需要对内核做些优化，
	Vi /etc/sysctl.conf
	net.ipv4.tcp_fin_timeout = 30
	net.ipv4.tcp_keepalive_time = 300
	net.ipv4.tcp_syncookies = 1
	net.ipv4.tcp_tw_reuse = 1
	net.ipv4.tcp_tw_recycle = 1
	net.core.netdev_max_backlog =8096
	net.ipv4.ip_local_port_range = 1024    65000
	net.ipv4.tcp_max_tw_buckets = 5000
	 
	修改完记的使用sysctl -p 让它生效

	以上参数的注解
	/proc/sys/net/ipv4/tcp_tw_reuse
	该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接。

	/proc/sys/net/ipv4/tcp_tw_recycle
	recyse是加速TIME-WAIT sockets回收

	对tcp_tw_reuse和tcp_tw_recycle的修改，可能会出现.warning, got duplicate tcp line warning, got BOGUS tcp line.上面这二个参数指的是存在这两个完全一样的TCP连接，这会发生在一个连接被迅速的断开并且重新连接的情况，而且使用的端口和地址相同。但基本上这样的事情不会发生，无论如何，使能上述设置会增加重现机会。这个提示不会有人和危害，而且也不会降低系统性能，目前正在进行工作

	/proc/sys/net/ipv4/tcp_keepalive_time
	表示当keepalive起用的时候,TCP发送keepalive消息的频度。缺省是2小时

	/proc/sys/net/ipv4/tcp_fin_timeout    最佳值和BSD一样为30
	fin_wait1状态是在发起端主动要求关闭tcp连接，并且主动发送fin以后，等待接收端回复ack时候的状态。对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。

	/proc/sys/net/core/netdev_max_backlog
	该文件指定了，在接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
	net.ipv4.ip_local_port_range = 1024    65000
	表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
	 
	net.ipv4.tcp_max_tw_buckets = 5000
	表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。
	 
	 
	其它查看连接数据命令：
	1)统计80端口连接数
	netstat -nat|grep -i "80"|wc -l
	1
	2）统计httpd协议连接数
	ps -ef|grep httpd|wc -l
	1
	3）、统计已连接上的，状态为“established'
	netstat -na|grep ESTABLISHED|wc -l
	2
	4)、查出哪个IP地址连接最多,将其封了.
	netstat -na|grep ESTABLISHED|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
	 
	netstat -na|grep SYN|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -r +0n
	iptables的设置:
	 
	防止同步包洪水（Sync Flood）
	# iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT
	也有人写作
	#iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT
	--limit 1/s 限制syn并发数每秒1次，可以根据自己的需要修改
	防止各种端口扫描
	# iptables -A FORWARD -p tcp --tcp-flags SYN,ACK,FIN,RST RST -m limit --limit 1/s -j
	ACCEPT
	Ping洪水攻击（Ping of Death）
	# iptables -A FORWARD -p icmp --icmp-type echo-request -m limit --limit 1/s -j ACCEPT
	 
	 
	修改JBOSS连接池：
	Vi /usr/local/jboss/server/default/deploy/jbossweb-tomcat55.sar/server.xml
	<Connector port="80" address="${jboss.bind.address}"
		 maxThreads="500" strategy="ms" maxHttpHeaderSize="8192"
		 emptySessionPath="true" maxKeepAliveRequests="1"
		 enableLookups="false" redirectPort="8443" acceptCount="100"
		 connectionTimeout="10000" disableUploadTimeout="true"/>
	 
	 
	修改JBOSS内存：
	Vi /usr/local/jboss/bin/run.conf
	if [ "x$JAVA_OPTS" = "x" ]; then
	   JAVA_OPTS="-Xms1024m -Xmx2048m -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.rmi.dgc.server.gcInterval=3600000"
	fi
	 

	from:http://kerry.blog.51cto.com/172631/161179

* What Is a Socket
		A socket is one end-point of a two-way communication link between two programs running on the network. 
	Socket classes are used to represent the connection between a client program and a server program. The java.net package provides 
	two classes--Socket and ServerSocket--that implement the client side of the connection and the server side of the connection, respectively. 
* log * log4j
	logger.error(e) vs logger.error("xxx",e)
	看log4j的error方法说明，直接传对象接收的是message消息对象，如何给的是非message对象，可能没有重写tostring方法，输出的日志内容为对象而不是异常的内容。

* nginx
	  ---------
	  ...
		   server {
			listen       80;
			server_name  openapi.aliyun.com;

			charset UTF-8;

			proxy_connect_timeout 600;
			proxy_read_timeout 600;
			proxy_send_timeout 600;

			#access_log  logs/host.access.log  main;

			if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
			{ 
			  set $domain $1; 
			  set $new_uri /openapi/$domain$request_uri;
			} 

			location /{
			    proxy_set_header        X-Real-IP $remote_addr;
			    proxy_set_header        Host $host;
			    proxy_pass http://127.0.0.1:8080$new_uri;
			
			}

		       location /slb/api{
				   proxy_set_header        X-Real-IP $remote_addr;
				   proxy_set_header        Host $host;
	...
	---------
	部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
			
			小结：
					当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
				启动失败了，即服务器是起来了，但应用确没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
				ok的情况下极可能就是应用启动失败）。
					这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。
* concurrent包 ，java concurrent
	java concurrent 探秘
		我们都知道，在JDK1.5之前，Java中要进行业务并发时，通常需要有程序员独立完成代码实现，当然也有一些开源的框架提供了这些功能，
	但是这些依然没有JDK自带的功能使用起来方便。而当针对高质量Java多线程并发程序设计时,为防止死蹦等现象的出现，比如使用java之前的wait()、notify()和synchronized等，
	每每需要考虑性能、死锁、公平性、资源管理以及如何避免线程安全性方面带来的危害等诸多因素，往往会采用一些较为复杂的安全策略，加重了程序员的开发负担.万幸的是，
	在JDK1.5出现之后，Sun大神（Doug Lea）终于为我们这些可怜的小程序员推出了java.util.concurrent工具包以简化并发完成。开发者们借助于此，将有效的减少竞争条件（race conditions）
	和死锁线程。concurrent包很好的解决了这些问题，为我们提供了更实用的并发程序模型。

	Executor                  ：具体Runnable任务的执行者。
	ExecutorService           ：一个线程池管理者，其实现类有多种，我会介绍一部分。我们能把Runnable,Callable提交到池中让其调度。
	Semaphore                 ：一个计数信号量
	ReentrantLock             ：一个可重入的互斥锁定 Lock，功能类似synchronized，但要强大的多。
	Future                    ：是与Runnable,Callable进行交互的接口，比如一个线程执行结束后取返回的结果等等，还提供了cancel终止线程。
	BlockingQueue             ：阻塞队列。
	CompletionService         : ExecutorService的扩展，可以获得线程执行结果的
	CountDownLatch            ：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。
	CyclicBarrier             ：一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点
	Future                    ：Future 表示异步计算的结果。
	ScheduledExecutorService ：一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。

	接下来逐一介绍
	from：http://www.cnblogs.com/aurawing/articles/1887056.html
* volatile / Java中的volatile关键字	 
	关于volatile
		我们知道，在Java中设置变量值的操作，除了long和double类型的变量外都是原子操作，也就是说，对于变量值的简单读写操作没有必要进行同步。这在JVM 1.2之前，Java的内存模型实现
	总是从主存读取变量，是不需要进行特别的注意的。而随着JVM的成熟和优化，现在在多线程环境下volatile关键字的使用变得非常重要。在当前的Java内存模型下，线程可以把变量保存在
	本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，
	造成数据的不一致。要解决这个问题，只需要像在本程序中的这样，把该变量声明为volatile（不稳定的）即可，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。
	一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。
	
	Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 
	Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才与共享成员变量的原始值对比。 
	这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。 
	而volatile关键字就是提示VM：对于这个成员变量不能保存它的私有拷贝，而应直接与共享成员变量交互。 
	使用建议：在两个或者更多的线程访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，不必使用。 
	由于使用volatile屏蔽掉了VM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。
	from: http://www.cnblogs.com/xwdreamer/archive/2012/05/13/2498615.html
* svn 代码
	版本控制，代码管理，使用
	整个SVN代码管理可以看做一棵倒置的树

		1、Branches做为分支，它就像树枝，最终还是合并到主干，用来控制新需求、需求变更、BUG修改等，每个分支都有一个专用的目的，分支编号将跟特定目标关系与需求管理文档内容关联。
		2、Tags做为里程碑，它就像树根，每一次Tag的生成都要根深蒂固，才能站稳，用来控制分支测试版本和生产正式版本，标志着一个时期。
		3、Trunk做为主干，它就是雄壮的树干，由它来生出树枝，扎下树根，他的作用是保存着最稳定，功能最全面的程序代码，用来管理整个项目。
	- svn 命令
		svn log -r486678 查看某个reversion log

* tddl	  取模，拆分，定位
	参考: http://rdc.taobao.com/team/jm/archives/1645

search in index find pdf 
* 平台，产品线，生态
	一个好的平台，衍生出多种产品线，构建良好的生态
* OSGi
		（OOSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。
	OSGi Alliance是一个由Sun Microsystems、IBM、爱立信等于1999年3月成立的开放的标准化组织，最初名为Connected Alliance。该组织及其标准原本主要目的在于使服务提供商通过住宅网关，为各种家庭智能设备提供各种服务。目前该平台逐渐成为一个为室内、交通工具、移动电话和其他环境下的所有类型的网络设备的应用程序和服务进行传递和远程管理的开放式服务平台。
	该规范和核心部分是一个框架 ，其中定义了应用程序的生命周期模式和服务注册。基于这个框架定义了大量的OSGi服务： 日志、配置管理、偏好，HTTP（运行servlet）、XML分析、设备访问、软件包管理、许可管理、星级、用户管理、IO连接、连线管理、Jini和 UPnP。
	这个框架实现了一个优雅、完整和动态的组件模型。应用程序（称为bundle）无需重新引导可以被远程安装、启动、升级和卸载（其中Java包／类的管理被详细定义）。API中还定义了运行远程下载管理政策的生命周期管理。服务注册允许bundles去检测新服务和取消的服务，然后相应配合。
	OSGi原先关注于服务网关，其实可用于多个方面。现在OSGi规范已经用于从移动电话到开源的Eclipse（其中包括了与IBM的OSGi框架SMF兼容的开源版本）。 OSGi服务平台的应用包括：服务网关、 汽车、移动电话、 工业自动化、建筑物自动化、 PDA 网格计算、娱乐（如iPronto）、和 IDE。
	OSGi规范是由成员通过公开的程序开发，对公众免费而且没有许可证限制。但是OSGi Alliance的兼容性程序只对成员开放，目前有12个兼容的实现。
	2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。ProSyst是面向OSGi开发者的Eclipse插件。
	2003年10月， 诺基亚、摩托罗拉，ProSyst 和其他OSGi成员组建了Mobile Expert Group (MEG)为下一代智能手机规范业务平台，做为对 MIDP 和CDC的补充。
	
	eclipse 3.7.2提供了OSGI控制台

* IaaS（Infrastructure as a Service），即基础设施即服务

* BVT (Build Verification Test)
	　　BVT是在所有开发工程师都已经检入自己的代码，项目组编译生成当天的版本之后进行，主要目的是验证最新生成的软件版本在功能上是否完整，主要的软件特性是否正确。
	如无大的问题，就可以进行相应的功能测试。BVT优点是时间短，验证了软件的基本功能。缺点是该种测试的覆盖率很低。因为运行时间短，不可能把所有的情况都测试到。

	自动化测试：通过脚本语言，比如python（丰富的库），建立各个测试用例，配置测试数据，编写测试逻辑，自动化测试，并输出结果。

* cgroups
	What are CGroups?
		You might be wondering at this point what CGroups actually are ? At a high level, it is a generic mechanism the kernel provides for grouping of processes and applying controls to those groups. 
	The grouping is done via a virtual filesystem called “cgroup”. Within this filesytem, each directory defines a new group. Thus groups can be arranged to form an arbitrarily nested hierarchy simply 
	by creating new sub-directories.

		Tunables within a cgroup are provided by what the kernel calls ‘controllers’, with each controller able to expose one or more tunable or control. When mounting the cgroups filesystem it is possible to
	indicate what controllers are to be activated. This makes it possible to mount the filesystem several times, with each mount point having a different set of (non-overlapping) controllers. Why might separate 
	mount points be useful ? The key idea is that this allows the administrator to construct differing group hierarchies for different sets of controllers/tunables.

	memory: Memory controller
	    Allows for setting limits on RAM and swap usage and querying cumulative usage of all processes in the group
	cpuset: CPU set controller
	    Binding of processes within a group to a set of CPUs and controlling migration between CPus
	cpuacct: CPU accounting controller
	    Information about CPU usage for a group of processes
	cpu: CPU schedular controller
	    Controlling the priorization of processes in the group. Think of it as a more advanced nice level
	devices: Devices controller
	    Access control lists on character and block devices
	freezer: Freezer controller
	    Pause and resume execution of processes in the group. Think of it as SIGSTOP for the whole group
	net_cls: Network class controller
	    Control network utilization by associating processes with a ‘tc’ network class

		This isn’t the blog post to go into fine details about each of these controllers & their capabilities, the high level overview will do. Suffice to say that at this time, the libvirt LXC driver (container based virtualization) 
	will use all of these controllers except for net_cls and cpuset, while the libvirt QEMU driver will only use the cpu and devices controllers. 

* SQL分页语句 分页
	- mysql通过limit语句实现分页；
				  
	- sql server分页
		摘自网络
		---------
			有关分页 SQL 的资料很多，有的使用存储过程，有的使用游标。本人不喜欢使用游标，我觉得它耗资、效率低；使用存储过程是个不错的选择，
			因为存储过程是经过预编译的，执行效率高，也更灵活。先看看单条 SQL 语句的分页 SQL 吧。

			方法1：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id NOT IN
				  (
				  SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
				  )
			ORDER BY id

			方法2：
			适用于 SQL Server 2000/2005
			SELECT TOP 页大小 *
			FROM table1
			WHERE id >
				  (
				  SELECT ISNULL(MAX(id),0) 
				  FROM 
					(
					SELECT TOP 页大小*(页数-1) id FROM table1 ORDER BY id
					) A
				  )
			ORDER BY id

			方法3：
			适用于 SQL Server 2005
			SELECT TOP 页大小 * 
			FROM 
				(
				SELECT ROW_NUMBER() OVER (ORDER BY id) AS RowNumber,* FROM table1
				) A
			WHERE RowNumber > 页大小*(页数-1)

			说明，页大小：每页的行数；页数：第几页。使用时，请把“页大小”和“页大小*(页数-1)”替换成数字。

			其它的方案：如果没有主键，可以用临时表，也可以用方案三做，但是效率会低。
			建议优化的时候，加上主键和索引，查询效率会提高。

			通过SQL 查询分析器，显示比较：我的结论是:
			分页方案二：(利用ID大于多少和SELECT TOP分页）效率最高，需要拼接SQL语句
			分页方案一：(利用Not In和SELECT TOP分页)   效率次之，需要拼接SQL语句
			分页方案三：(利用SQL的游标存储过程分页)    效率最差，但是最为通用
		    ---------

* LVM
		LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分
	区管理的灵活性。前面谈到，LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。
	物理卷（physical volume）物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备（如RAID），是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，
	却包含有与LVM相关的管理参数。
	　　Linux用户安装Linux操作系统时遇到的一个最常见的难以决定的问题就是如何正确地给评估各分区大小，以分配合适的硬盘空间。而遇到出现 某个分区空间耗尽时，
	解决的方法通常是使用符号链接，或者使用调整分区大小的工具（比如PatitionMagic等），但这都只是暂时解决办法，没有根本解决问题。随着Linux的逻辑盘卷管理功能的出现，
	这些问题都迎刃而解，用户在无需停机的情况下方便地调整各个分区大小。	

	lvm howto：http://blog.haohtml.com/archives/10298

* VNC
	VNC (Virtual Network Computing)是虚拟网络计算机的缩写。VNC是一款优秀的远程控制工具软件，由著名的AT&T的欧洲研究实验室开发的。
	VNC是在基于UNIX和Linux操作系统的免费的开放源码软件，远程控制能力强大，高效实用，其性能可以和Windows和MAC中的任何远程控制软件媲美。 
	在Linux中，VNC包括以下四各命令：vncserver，vncviewer，vncpasswd，和vncconnect。大多数情况下我只需要其中的两个命令：vncserver和vncviewer。
	
	TightVNC
	　　应用平台： Win9x/NT/2000/XP/2003 Linux/unix
	　　自由软件，遵循GPL条款，源代码开源，个人、企业使用均无任何限制。
		vnc的加强，短小精悍，功能强大。
* RPC
	 - 通过socket进行RPC调用
		 --------
		 ...
			OutputStream localOutputStream = paramSocket.getOutputStream();

			BufferedWriter localBufferedWriter = new BufferedWriter(new OutputStreamWriter(localOutputStream));
			localBufferedWriter.write("GET /?address=");
			localBufferedWriter.write(this.mRemoteAddress);
			localBufferedWriter.write("&method=");
			localBufferedWriter.write(MethodName);
			localBufferedWriter.write("&timeout=");
			localBufferedWriter.write(Integer.toString(this.mRpcTimeout));
			localBufferedWriter.write("&client=");
			localBufferedWriter.write(this.mRpcClientName);
			localBufferedWriter.write("&token=");
			localBufferedWriter.write(this.mRpcToken);
			localBufferedWriter.write(" HTTP/1.1\r\n");
			localBufferedWriter.write("HOST: *\r\n");
			localBufferedWriter.write("Content-Length: ");
			localBufferedWriter.write(Integer.toString(this.mRpcParameter.length));
			localBufferedWriter.write("\r\nConnection: Keep-Alive\r\n");
			localBufferedWriter.write("\r\n");
			localBufferedWriter.flush();

			localOutputStream.write(this.mRpcParameter);
			localOutputStream.flush();

			InputStream localInputStream = paramSocket.getInputStream();
			paramSocket.setSoTimeout(this.mRpcTimeout);
		...
		--------

	 - 介绍：
			RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，
		 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。
		 在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易
			RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程
		发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息的到达为止。
		当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程
		接收答复信息，获得进程结果，然后调用执行继续进行。
	　　	目前，有多种 RPC 模式和执行。最初由 Sun 公司提出。IETF ONC 宪章重新修订了 Sun 版本，使得 ONC RPC 协议成为
		IETF 标准协议。现在使用最普遍的模式和执行是开放式软件基础的分布式计算环境（DCE）。

* xml
	- <![CDATA[]]>

* 测试 
	- 性能测试工具 ab	   (ApacheBench)  
		-----------
		简介
		ab的全称是ApacheBench，是 Apache 附带的一个小工具，专门用于 HTTP Server 的benchmark testing，可以同时模拟多个并发请求。前段时间看到公司的开发人员也在用它作一些测试，看起来也不错
		，很简单，也很容易使用，所以今天花一点时间看了一下。
		通过下面的一个简单的例子和注释，相信大家可以更容易理解这个工具的使用。
		一个简单的例子
		/*在这个例子的一开始，我执行了这样一个命令 ab -n 10 -c 10 http://www.google.com/。这个命令的意思是启动 ab ，向 www.google.com 发送10个请求(-n 10) ，并每次发送10个请求(-c 10)——也就是说
		一次都发过去了。跟着下面的是 ab 输出的测试报告，红色部分是我添加的注释。*/

		C:\Program Files\Apache Software Foundation\Apache2.2\bin>ab -n 10 -c 10 http
		://www.google.com/
		This is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0
		Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
		Copyright 1997-2005 The Apache Software Foundation, http://www.apache.org/
		Benchmarking www.google.com (be patient).....done    
		Server Software:        GWS/2.1
		Server Hostname:        www.google.com
		Server Port:            80
		Document Path:          /
		Document Length:        230 bytes
		Concurrency Level:      10

		/*整个测试持续的时间*/

		Time taken for tests:   3.234651 seconds

		/*完成的请求数量*/

		Complete requests:      10

		/*失败的请求数量*/

		Failed requests:        0

		Write errors:           0

		Non-2xx responses:      10

		Keep-Alive requests:    10

		/*整个场景中的网络传输量*/

		Total transferred:      6020 bytes

		/*整个场景中的HTML内容传输量*/

		HTML transferred:       2300 bytes

		/*大家最关心的指标之一，相当于 LR 中的 每秒事务数 ，后面括号中的 mean 表示这是一个平均值*/

		Requests per second:    3.09 [#/sec] (mean)

		/*大家最关心的指标之二，相当于 LR 中的 平均事务响应时间 ，后面括号中的 mean 表示这是一个平均值*/

		Time per request:       3234.651 [ms] (mean)

		/*这个还不知道是什么意思，有知道的朋友请留言，谢谢 ^_^ */

		Time per request:       323.465 [ms] (mean, across all concurrent requests)

		/*平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题*/

		Transfer rate:          1.55 [Kbytes/sec] received

		/*网络上消耗的时间的分解，各项数据的具体算法还不是很清楚*/

		Connection Times (ms)

			      min  mean[+/-sd] median   max

		Connect:       20  318 926.1     30    2954

		Processing:    40 2160 1462.0   3034    3154

		Waiting:       40 2160 1462.0   3034    3154

		Total:         60 2479 1276.4   3064    3184

		/*下面的内容为整个场景中所有请求的响应情况。在场景中每个请求都有一个响应时间，其中 50％ 的用户响应时间小于 3064 毫秒，60 ％ 的用户响应时间小于 3094 毫秒，最大的响应时间小于 
		3184 毫秒*/

		Percentage of the requests served within a certain time (ms)

		  50%   3064

		  66%   3094

		  75%   3124

		  80%   3154

		  90%   3184

		  95%   3184

		  98%   3184

		  99%   3184

		 100%   3184 (longest request)

		更多信息

		ab 不像 LR 那么强大，但是它足够轻便，如果只是在开发过程中想检查一下某个模块的响应情况，或者做一些场景比较简单的测试，ab 还是一个不错的选择——至少不用花费很多时间去学习 LR 
		那些复杂的功能，就更别说那 License 的价格了。

		下面是 ab 的详细参数解释，大家有兴趣的可以研究一下，最近没有足够多的时间研究，如果哪位朋友有兴趣希望可以帮忙翻译一下每个参数的含义，有问题讨论也欢迎在这里回帖 ^_^

		ab [ -A auth-username:password ] [ -c concurrency ] [ -C cookie-name=value ] [ -d ] [ -e csv-file ] [ -g gnuplot-file ] [ -h ] [ -H custom-header ] [ -i ] [ -k ] [ -n requests ] [ -p POST-file ] [ -P proxy-auth-username:password ]
		[ -q ] [ -s ] [ -S ] [ -t timelimit ] [ -T content-type ] [ -v verbosity] [ -V ] [ -w ] [ -x <table>-attributes ] [ -X proxy[:port] ] [ -y <tr>-attributes ] [ -z <td>-attributes ] [http://]hostname[:port]/path

		-A auth-username:password

		Supply BASIC Authentication credentials to the server. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the server needs it (i.e., has sent an
		401 authentication needed).

		-c concurrency

		Number of multiple requests to perform at a time. Default is one request at a time.

		-C cookie-name=value

		Add a Cookie: line to the request. The argument is typically in the form of a name=value pair. This field is repeatable.

		-d

		Do not display the "percentage served within XX [ms] table". (legacy support).

		-e csv-file

		Write a Comma separated value (CSV) file which contains for each percentage (from 1% to 100%) the time (in milliseconds) it took to serve that percentage of the requests. This is usually more useful than the 'gnuplot' file; as the
		results are already 'binned'.

		-g gnuplot-file

		Write all measured values out as a 'gnuplot' or TSV (Tab separate values) file. This file can easily be imported into packages like Gnuplot, IDL, Mathematica, Igor or even Excel. The labels are on the first line of the file.

		-h

		Display usage information.

		-H custom-header

		Append extra headers to the request. The argument is typically in the form of a valid header line, containing a colon-separated field-value pair (i.e., "Accept-Encoding: zip/zop;8bit").

		-i

		Do HEAD requests instead of GET.

		-k

		Enable the HTTP KeepAlive feature, i.e., perform multiple requests within one HTTP session. Default is no KeepAlive.

		-n requests

		Number of requests to perform for the benchmarking session. The default is to just perform a single request which usually leads to non-representative benchmarking results.

		-p POST-file

		File containing data to POST.

		-P proxy-auth-username:password

		Supply BASIC Authentication credentials to a proxy en-route. The username and password are separated by a single : and sent on the wire base64 encoded. The string is sent regardless of whether the proxy needs it (i.e., has
		sent an 407 proxy authentication needed).

		-q

		When processing more than 150 requests, ab outputs a progress count on stderr every 10% or 100 requests or so. The -q flag will suppress these messages.

		-s

		When compiled in (ab -h will show you) use the SSL protected https rather than the http protocol. This feature is experimental and very rudimentary. You probably do not want to use it.

		-S

		Do not display the median and standard deviation values, nor display the warning/error messages when the average and median are more than one or two times the standard deviation apart. And default to the min/avg/max values.
		(legacy support).

		-t timelimit

		Maximum number of seconds to spend for benchmarking. This implies a -n 50000 internally. Use this to benchmark the server within a fixed total amount of time. Per default there is no timelimit.

		-T content-type

		Content-type header to use for POST data.

		-v verbosity

		Set verbosity level - 4 and above prints information on headers, 3 and above prints response codes (404, 200, etc.), 2 and above prints warnings and info.

		-V

		Display version number and exit.

		-w

		Print out results in HTML tables. Default table is two columns wide, with a white background.

		-x <table>-attributes

		String to use as attributes for <table>. Attributes are inserted <table here >.

		-X proxy[:port]

		Use a proxy server for the requests.

		-y <tr>-attributes

		String to use as attributes for <tr>.

		-z <td>-attributes

		String to use as attributes for <td>.

		相关链接

		ab 是 Apache 的一个安装组件，所以需要下载 Apache 安装后才能使用，可以访问 Apache 的项目主页来下载 http://httpd.apache.org/download.cgi

		ab 的更多信息可以参加 Apache 主页上的描述

		http://httpd.apache.org/docs/2.0/programs/ab.html

		from: http://www.cnblogs.com/jackei/archive/2006/07/18/454144.html
		-----------
	- 部署打开debug
		远程shell(调用python封装好的各个接口调用，执行命令，传入参数即可)执行请求，ide debug处理过程
* yum 
	- yum 安装指定目录，指定安装目录
		--installroot=[path]  set install root
	- yum源设置
		比如使用163镜像站，可以参考其提供的使用帮助,下面为摘取部分：
			CentOS镜像使用帮助
			使用说明
				首先备份/etc/yum.repos.d/CentOS-Base.repo
				    mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
			下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份)
				•CentOS5
				•CentOS6
			运行yum makecache生成缓存
			from: http://mirrors.163.com/.help/centos.html
						
	- yum的使用:  
	    1)包的更新  
	    1.1)检查可更新包: yum check-update  
	    1.2)更新所有包: yum update  
	    1.3)更新指定包: yum update package_name  
	    1.4)版本升级: yum upgrade  
	    2)包安装与删除  
	    2.1)yum install package_name  
	    2.2)yum remove package_name  
	    3)包搜索  
	    3.1)搜索特定包: yum search package_name  
	    3.2)搜索包含特定文件名的包:yum provides name  
	    4)包列表  
	    4.1)列出所有安装或更新的包: yum list  
	    4.2)列出指定包:yum list name  
	    4.3)列出可更新包:yum list updates  
	    4.4)列出已安装包:yum list installed  
	    4.5)列出已安装但不包含在资源库中的包:yum list extras  

	CentOS yum源设定
	    2.1)加快yum下载速度: yum -y install yum-fastestmirror,在CentOs 4上名字叫做yum-plugin-fastestmirror  
	    2.2)yum源文件:/etc/yum.repos.d/CentOS-Base.repo  
	    2.3)CentOS 5的yum源设为上海交通大学网站 

* vim
	- vimdiff
		vimdiff 命令比较文本，比较文件，文件比较 对比工具
	- 替换
		vi/vim 中可以使用 :s 命令来替换字符串
		:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
		:s/vivian/sky/g 替换当前行所有 vivian 为 sky
		:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
		:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
		n 为数字，若 n 为 .，表示从当前行开始到最后一行
		:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
		:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
		可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
		:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	
	- set paste 保持黏贴格式
	- 
		~/.vimrc - vim对当前用户的配置文件
		~/.vim/colors 目录下放自己的颜色方案文件  ，用户自己的设置

		颜色方案下载地址：http://www.vim.org/scripts/script.php?script_id=1651

	- 可以设置编辑的颜色方案
		通常, 如果工作在终端模式下, 你只有一个黑色的背景和白色的前景色. 这种配色太单调了, 看起也太暗淡了. 其实颜色方案是可以设计的.
		默认的, 你在终端下打开Vim时的的颜色和你打开的终端的颜色是一样的. 不过Vim给了用户一个权力来改变颜色的. 最常使用的就是配色方案文件. 这些文件通常放在Vim安装目录下的colors目录下.
		你可以简单地通过下面的命令在己安装的本色方案中切换
			:colorscheme mycolors
		mycolors要换成安装的配色方案的名称. 如可你不知道安装了哪些配色方案, 可以在写下下面的命令后:
			:colorscheme
		通过按tab键来在安装的配色方案的名字间切换. 当发现了想要的配色方案后 就可以按回车键来应用它.
		配色方案不仅只是应用在前景色和背景色, 也可以设置代码的高亮显示, 错误如何标识, 和其他的一些文本的可视化标识. 
		
		安装配色方案：
			root@ag # rpm -qa | grep -i vim	      - 找到vim的安装包
			vim-common-7.0.109-6.el5
			vim-enhanced-7.0.109-6.el5
			vim-minimal-7.0.109-6.el5
			root@ag # rpm -ql vim-common-7.0.109-6.el5 | grep colors		- 找到colors目录位置      - 
			/usr/share/vim/vim70/colors
			/usr/share/vim/vim70/colors/README.txt
			/usr/share/vim/vim70/colors/blue.vim
			/usr/share/vim/vim70/colors/darkblue.vim
			/usr/share/vim/vim70/colors/default.vim
			/usr/share/vim/vim70/colors/delek.vim
			/usr/share/vim/vim70/colors/desert.vim
			/usr/share/vim/vim70/colors/elflord.vim
			/usr/share/vim/vim70/colors/evening.vim
			/usr/share/vim/vim70/colors/koehler.vim
			/usr/share/vim/vim70/colors/morning.vim
			/usr/share/vim/vim70/colors/murphy.vim
			...

			将配色方案文件 *.vim，拷贝到colors目录下，
			切换颜色方案：
			:colorscheme SchemeFileName 
		
	-
		:reg 查看剪贴板内容
	- search
		type '/' > type words > key 'n' for next match
	- 在整个文件里面有效移动光标
		VIM 有很多命令，可以用来到达文件里面你想到达的地方。下面是一些在文件里面移动的命令：
	　　<C-F>：向下移动一屏。
	　　<C-D>：向下移动半屏。
	　　<C-B>：向上移动一屏。
	　　<C-U>：向上移动半屏。
	　　G：到文件尾
	　　numG：移动光标到指定的行（num）。（比如 10G 就是到第 10 行）
	　　gg：到文件首
	　　H：移动光标到屏幕上面
	　　M：移动光标到屏幕中间
	　　L：移动光标到屏幕下面
	　　*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。
	　　/text：从当前光标处开始搜索字符串 text，并且到达 text 出现的地方。必须使用回车来开始这个搜索命令。如果想重复上次的搜索的话，按 n移动到下个 text 处，N 移动到上一个 text 处 。
	　　？text：和上面类似，但是是反方向。
	　　m{a-z}：在当前光标的位置标记一个书签，名字为 a-z 的单个字母。书签名只能是小写字母。你看不见书签的存在，但它确实已经在那里了。
	　　`a：到书签 a 处。注意这个不是单引号，它一般位于大部分键盘的 1 的左边。
	　　`.：到你上次编辑文件的地方。这个命令很有用，而且你不用自己去标记它。
	　　%：在成对的括号等符号间移动，比如成对的 [ ] ， { }， ( ) 之间。将光标放到任意符号上，然后通过 % 来移动到和这个符号匹配的符号上，% 还可以正确的识别括号的嵌套层数，总是移动到真正匹配的位置上。因此这个命令在编辑程序代码的时候非常有用，可以让你方便的在一段代码的头尾间移动。
	　　6、它主要应用在--Linux系统
	- VIM 复制黏贴
		内容：
		用vim 这么久 了，始终也不知道怎么在vim 中使用系统粘贴板，通常要在网上复制 一段代码都是先gedit打开文件，中键粘贴后关闭，然后再用vim 打开编辑，真的不 爽；上次论坛上有人问到了怎么在vim 中使用系统粘贴板，印象里回复很多，有好几页的回复却没有解决问题，今天实在受不了了又在网上找办法，竟意外地找到 了，贴出来分享一下。

		如果只是想使用系统粘贴板的话直接在输入模式按Shift+Inset（粘贴）就可以了，下面讲一下vim 的粘贴板的基础知识，有兴趣的可以看看，应该会有所收获的。
		vim 帮助文档里与粘贴板有关的内容如下：

		    vim 有12个粘贴板，分别是0、1、2、...、9、a、“、＋；用:reg命令可以查看各个粘贴板里的内容。在vim 中简单用y只是复制 到“（双引号)粘贴板里，同样用p粘贴的也是这个粘贴板里的内容；

		    要将vim 的内容复制 到某个粘贴板，需要退出编辑模式，进入正常模式后，选择要复制 的内容，然后按"Ny（注意带引号）完成复制 ，其中N为粘贴板号(注意是按一下双引号然后按粘贴板号最后按y)，例如要把内容复制 到粘贴板a，选中内容后按"ay就可以了，有两点需要说明一下：
			“号粘贴板（临时粘贴板）比较特殊，直接按y就复制 到这个粘贴板中了，直接按p就粘贴这个粘贴板中的内容；
			+号粘贴板是系统粘贴板，用"+y将内容复制 到该粘贴板后可以使用Ctrl＋V将其粘贴到其他文档（如firefox、gedit）中，同理，要把在其他地方用Ctrl＋C或右键复制 的内容复制 到vim 中，需要在正常模式下按"+p；

		    要将vim 某个粘贴板里的内容粘贴进来，需要退出编辑模式，在正常模式按"Np，其中N为粘贴板号，如上所述，可以按"5p将5号粘贴板里的内容粘贴进来，也可以按"+p将系统全局粘贴板里的内容粘贴进来。

		注意：在我这里，只有vim.gtk或vim.gnome才能使用系统全局粘贴板，默认的vim.basic看不到+号寄存器。安装vim.gnome使用apt-get install vim-gnome，然后vim自动会链接到vim.gnome。
		（二）
		yy  複製游標所在行整行。或大寫一個 Y。
		2yy 或 y2y  複製兩行。ㄟ，請舉一反三好不好！:-)
		y^  複製至行首，或 y0。不含游標所在處字元。
		y$  複製至行尾。含游標所在處字元。
		yw  複製一個 word。
		y2w 複製兩個字。
		yG  複製至檔尾。
		y1G 複製至檔首。
		p   小寫 p 代表貼至游標後（下）。
		P   大寫 P 代表貼至游標前（上）。
		    整行的複製，按 p 或 P 時是插入式的貼在下（上）一行。非整行的複製則是貼在游標所在處之後（前）。
		"ayy  將本行文字複製到 a 緩衝區
		    a 可為 26 個英文字母中的一個，如果是小寫的話，原先的內容會被清掉，如果是大寫的話是 append 的作用，會把內容附加到原先內容之後。
		    " 是 Enter 鍵隔壁的那一個同上符號（ditto marks）。
		"ap  將 a 緩衝區的內容貼上。
		    緩衝區的術語在 vim 稱為 registers，vim 擴充了相當多的功能，有興趣深入的朋友請 :h registers。您用 d、c、s、x、y 等指令改變或刪除的內容都是放在 registers 中的。例如：您用 dd 刪除的一行，也是可以使用 p 來貼上的。只要是在緩衝區的內容都可以使用 p 來貼上，不是一定要 y 起來的內容才能用 p。因此您認為 p 是 paste 也可以，認為是 put 可能較正確。
		5"ayy  複製五行內容至 a 緩衝區。
		5"Ayy  再複製五行附在 a 內容之後，現在 a 中有十行內容了！
		    ㄟ！不要我一直用 a 您就認為只有 a 可以用喔。26 個英文字母都可以的，交叉運用下，您會發覺 vi(m) 肚量不小。
		    問題來了！忘記誰是誰的時候怎麼辦？ :reg（冒號命令）就會列出所有 registers 的代號及內容。您現在就試著按看看。咦！怎麼還有數目字、特殊符號的緩衝區，原來您剛剛刪除（複製）的內容就預設放在 " 這個緩衝區，然後依序是 0,1,2,...9。也就是說您按 p 不加什麼的話，是取出 " 緩衝區的內容的。% 指的是目前編輯的檔案，# 指的是前一次編輯的檔案。還有其它的呀！因為沒什麼重要，就請 :h registers 吧！registers 有個 "s" 結尾，不要搞錯了，而且 Tab 的補全鍵 vim 也支援的，也就是說您鍵入 :h regi 再按 Tab 鍵，vim 就會幫您補全，按了 Tab 後發現不是您要的，那就繼續按，總會出現您要的。:-)
		    Tab 補全的功能，elvis 也有，但叫出 registers 列表的命令則沒有，您得自行記憶在您的腦袋瓜子裡。而且 elvis 的補全能力並沒 vim 強。

		另外,按下v键,可以进入可视模式,这个时候可以更自由更灵活的选取要复制的段落,区块了.

* 一致性hash算法（consistent hashing） hash圆环 ，环形hash
	http://www.cnblogs.com/liyulong1982/articles/2497731.html
* API 用户体验
	开发的api遵循一定的规范：（整齐划一，看着清爽）
		接口命名
		返回码规划（分段）
		错误提示格式 比如驼峰式书写
		语义描述统一
* error
	cannot find symbol —— maven test项目时报此错误，可能和eclipse编译的冲突，先清除eclipse的编译文件，再执行mvn test

* debug
	* 提奥斯
	从日志看，应用或者服务器日志；
	错误可能被应用屏蔽，没有输出，此时只能看应用的日志。

* virtual networking 虚拟网络
	
* 业务熟悉 熟悉业务
	文档
	从数据库表理解
	代码

* NIO 非阻塞操作/ 阻塞操作 消息驱动
	上图就是这个项目的总体结构图，从图中可以看出该程序分为这几大块：连接侦听线程、连接对象队列、发送线程池、接收线程池、分发线程、
	事件处理对象、监控处理对象。下面我将描述下整个连接处理过程：
	1、 连接侦听线程循环接收一个连接请求，如果有连接请求过来，则返回一个连接Socket对象，否则该线程就阻塞等待，直到有一个连接请求过来。
	2、 封装该返回的Socket对象（主要是封装获取完整包数据，发送方法，关闭方法等）成Connection对象，并把封装好的Connection对象放入连接对象队列。
	3、 分发线程不停的轮询连接对象队列，如果发现有可接收数据的连接对象，则扔给接收线程池去处理；如果发现有可发送数据的连接对象，则扔给发送线程池
	去处理。如果轮询一圈发现既没有可发送数据的连接对象也没有可接收数据的连接对象，则该线程会休眠一段时间，休眠过后又接着循环。
	4、 发送线程池内有一个连接对象队列，从队列中取出一个连接对象并发送数据，且记录连接状态信息。
	5、 接收线程池内也有一个连接对象队列，从队列中取出一个连接对象并接收一个数据包，且记录连接状态信息。如果接收的数据包是心跳检测包则更新连接状态，
	如果是数据包则通过事件处理对象发送给probe系统。
	    从上面的过程来看，我们可能看不出设计上面的漏洞，但有几个地方确实非常影响效率，在这里我想先提出来：
	1、 连接侦听线程一直在侦听，有连接请求过来则会返回，没有则会阻塞；这样这个线程就会一直挂着；如果时时刻刻都有很多的连接过来，这个线程还会充分发挥
	它的作用，但其实大部分时候，连接请求并没有这么频繁，所以这个线程大部分时间是阻塞的；这样为了这样一个功能单独利用一个线程就有点浪费了。
	2、 分发线程不停的轮询过程是导致整个系统效率低下最严重的一块，分发线程不停的轮询连接对象队列，其实分发线程并不知道哪个线程需要发送数据，哪些线程
	需要接收数据，而他只是盲目地从队列的头遍历到队列的尾部，如果发现没有可操作的连接对象则休眠一段时间；其实在大部分情况下，连接对象并不是时时刻刻
	都有数据发送和接收，所以这个分发线程大部分时间空循环，白忙了；并且这个休眠时间也不好控制，如果时间长了，则程序的即时性不够，如果太短了，程序似乎
	就是在空跑了。
	3、 在连接对象上发送和接收数据包的时候，这些方法都是阻塞操作的；所以当有大量的数据可接收和发送的时候，这种阻塞的操作时非常浪费资源的。
	    以上所提出的问题，如果是在并发规模比较小的情况下，是没有什么问题；但确实有很大的改进空间。上面的问题归结起来主要是两个：
	1、 当有连接请求过来或者有Socket连接有数据可读可写的时候，我们不会立即知道，我们必须要一个一个的轮询，我们能否有一种机制，即是，当有连接请求过来或者
	连接有数据可读或者可写的时候，直接通知我们来处理，而不需要我们主动轮询。
	2、 当读数据或者写数据的时候，所有的方法都阻塞了，能不能有一种办法当我们写数据或者接收数据的时候不用阻塞，而是直接返回，这样就明显提高了线程的使用率了。
	    值得我们庆幸的是，在Java的JDK1.4之后的版本，提供了NIO包，这里提出了事件驱动的I/O编程模式和非阻塞信道的概念，NIO里面的Selector对象解决了上面提出分发
	    和轮询的问题，Channel接口解决了阻塞读写的问题。我相信这些组件能够帮我们解决上面所提出的所有问题。所以下面有很大一部分篇幅来介绍NIO的使用和一些底层的机制。
	from: http://www.cnblogs.com/phoebus0501/archive/2010/12/05/1897245.html

* visio
	- 输出图片格式
		
	- 提供多种图的绘制支持，比如uml，需要安装模板。
	- 序列图，可以用横版画图；宽度还不够的话，可以将名称换行(选中文本工具，即可编辑一些形状的名称)
	- 有些地方不可编辑，可能是保护原因，在形状上右键格式的保护力设置
	- 取消保护后，可以根据文本是文本或者文本块（选中某中文本按钮移上去后会以图表方式提示鼠标位置是文本还是文本块），
	  选中相应按钮，来调整形状的文字说明
	- 修改图层次序，在形状上右键的格式中设置
	- 对于名称，不能直接用文本按钮来设置，还是需要在名称属性里填上值，然后通过文本工具来设置文本格式，否则可能名称为空。
* redmine * 项目管理系统
	- redmine
		Redmine是用Ruby开发的基于web的项目管理软件，是用ROR框架开发的一套跨平台项目管理系统，据说是源于Basecamp的ror版而来，
		支持多种数据库，有不少自己独特的功能，例如提供wiki、新闻台等，还可以集成其他版本管理系统和BUG跟踪系统，例如SVN、CVS、TD等等。
		这种 Web 形式的项目管理系统通过“项目（Project）”的形式把成员、任务（问题）、文档、讨论以及各种形式的资源组织在一起，大家参与更新任务、
		文档等内容来推动项目的进度，同时系统利用时间线索和各种动态的报表形式来自动给成员汇报项目进度。

* 测试环境
	单台linux物理机 > xen虚拟多个vm (vm的lxc下多个app,eg:jetty)> 疏通vm网络 > 在vm上部署haproxy+keepalived以及web应用实现软负载均衡 > ...
	/etc/sysconfig/network-scripts/ifcfg-eth0
	/etc/sysconfig/network
	/etc/hosts
	域名服务器配置文件：/etc/resolv.conf
	
	 -------------------------
	 slbapi测试环境：
		mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
		http://10.230.204.24/slb/api?
 * spring
	- spring抽象类注入，spring接口注入有区别
		抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	- spring通过aop拦截器，拦截自定义注解所注解的方法 参考day52
		参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/
	- ioc时注意，有些ioc是直接通过注解注入的，故在配置文件中找不到，这个细节要注意
		@Autowired(required = true)
		public void setXX(@Qualifier("xx") xx xx) {
			//
		}
	- 编程式事务一例：
		spring 编程式事务管理
		1）bean配置
		<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
		   <property name="dataSource" ref="dataSource" />
		</bean>

		<bean id="transactionTemplate" class="org.springframework.transaction.support.TransactionTemplate" >
		   <property name="transactionManager" ref="transactionManager"/>
		</bean>

		<bean id="servie" class="SimpleService">
		  <property name="transactionTemplate" ref="transactionTemplate"/>
		</bean>

		TransactionTemplate是线程安全的，不同的service可以共用一个bean实例，其配置状态也是一致的。
		如果要用到不同的配置状态，则需要配置不同的TransactionTemplate Bean

		2）在Service中，定义TransactionTemplate全局变量

		public class SimpleService implements Service {
		  
		  private final TransactionTemplate transactionTemplate;

		  public void setTransactionTemplate(TransactionTemplate transactionTemplate) {
		    this.transactionTemplate = transactionTemplate;
		  }

		  public Object someServiceMethod() {
		    return transactionTemplate.execute(new TransactionCallback() {

		      // the code in this method executes in a transactional context
		      public Object doInTransaction(TransactionStatus status) {
			updateOperation1();
			return resultOfUpdateOperation2();
		      }
		    });
		  }
		}

		3）使用status.setRollbackOnly()方法回滚事务

		transactionTemplate.execute(new TransactionCallbackWithoutResult() {

		  protected void doInTransactionWithoutResult(TransactionStatus status) {
		    try {
		      updateOperation1();
		      updateOperation2();
		    } catch (SomeBusinessExeption ex) {
		      status.setRollbackOnly();
		    }
		  }
		});

		doInTransaction方法一旦执行完毕，事务自动提交；如果在catch块中设置了回滚setRollbackOnly，方法执行完毕将“提交”回滚。

		4、有返回值，使用TransactionCallback；如果没有返回值，使用TransactionCallbackWithoutResult
 * word * office word
	- word的列表问题，多级列表调整缩进样式，选中列表项，右键选“调整列表缩进”，具体看哪个对话框。

* 消息系统 消息中间件 MQ
	消息队列 消息队列框架 message queue ，MQ
	发布/订阅
	MQ的特点：
			MQ的消费-生产者模型的一个典型的代表，一端往消息队列中不断的写入消息，而另一端则可以读取或者订阅队列中的消息。MQ和JMS类似，
		但不同的是JMS是SUN JAVA消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品。
	使用场景(异步处理需求):
		　　最近在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从
		而提高了系统的吞吐量。

	- Jafka - 一个高性能的消息系统 : http://www.blogjava.net/xylz/archive/2012/05/10/377759.html
		淘宝内部使用的Kafka克隆版metaq,内部做了大量的改进和附加组件。如果你需要一个全功能的“复杂”系统，可以试试metaq: 
			https://github.com/killme2008/Metamorphosis
	
	- Rabbitmq erlang实现的消息中间件
		http://www.rabbitmq.com/
	- JMS
		JMS是一种与厂商无关的 API，用来访问消息收发系统。它类似于 JDBC(Java Database Connectivity)：这里，JDBC 是可以用来访问许多不同关系数据库的 API，
	而 JMS 则提供同样与厂商无关的访问方法，以访问消息收发服务。许多厂商目前都支持 JMS，包括 IBM 的 MQSeries、BEA的 Weblogic JMS service和 Progress 的 
	SonicMQ，这只是几个例子。 JMS 使您能够通过消息收发服务（有时称为消息中介程序或路由器）从一个 JMS 客户机向另一个 JMS客户机发送消息。消息是 JMS 
	中的一种类型对象，由两部分组成：报头和消息主体。报头由路由信息以及有关该消息的元数据组成。消息主体则携带着应用程序的数据或有效负载。根据有效
	负载的类型来划分，可以将消息分为几种类型，它们分别携带：简单文本 (TextMessage)、可序列化的对象 (ObjectMessage)、属性集合 (MapMessage)、字节流
	(BytesMessage)、原始值流 (StreamMessage)，还有无有效负载的消息 (Message)。
	
	JMS提供者实现
	　　要使用Java消息服务，你必须要有一个JMS提供者，管理会话和队列。现在既有开源的提供者也有专有的提供者。 　　
		开源的提供者包括： 　　
			Apache ActiveMQ —— is the most popular and powerful open source messaging and Integration Patterns server
			http://activemq.apache.org/

* loadbalance 负载均衡	      * slb software load balance * lb 
	haproxy + keepalived 方式实现软负载均衡
	slb的优点（相对于dns实现的lb）：
	SLB has several benefits, which is why it is such a highly successful and widely
	employed technology. Three main benefits directly address the concerns and
	needs of highly trafficked, mission-critical web sites:
	Flexibility
		SLB allows the addition and removal of servers to a site at any time, and the
		effect is immediate. Among other advantages, this allows for the maintenance
		of any machine, even during peak hours with little or no impact to the site. A
		load balancer can also intelligently direct traffic using cookies, URL parsing,
		static and dynamic algorithms, and much more.
	High availability
		SLB can check the status of the available servers, take any nonresponding
		servers out of the rotation, and put them in rotation when they are functioning
		again. This is automatic, requiring no intervention by an administrator.
		Also, the load balancers themselves usually come in a redundant configuration,
		employing more than one unit in case any one unit fails.
	Scalability
		Since SLB distributes load among many servers, all that is needed to increase
		the serving power of a site is to add more servers. This can be very economical,
		since many small- to medium-sized servers can be much less expensive
		than a few high-end servers. Also, when site load increases, servers can be
		brought up immediately to handle the increase in traffic.
	
* html/css模板 ，有此类网站搜集页面模板
	http://www.html-themes.com/free/
				
* 正则表达式 例子
	通过一些小正则工具来验证表达式
	
	整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
	只能输入数字："^[0-9]*$"。 
	只能输入n位的数字："^\d{n}$"。 
	只能输入至少n位的数字："^\d{n,}$"。 
	只能输入m~n位的数字：。"^\d{m,n}$" 
	只能输入零和非零开头的数字："^(0|[1-9][0-9]*)$"。 
	只能输入有两位小数的正实数："^[0-9]+(.[0-9]{2})?$"。 
	只能输入有1~3位小数的正实数："^[0-9]+(.[0-9]{1,3})?$"。 
	只能输入非零的正整数："^\+?[1-9][0-9]*$"。 
	只能输入非零的负整数："^\-[1-9][]0-9"*$。 
	只能输入长度为3的字符："^.{3}$"。 
	只能输入由26个英文字母组成的字符串："^[A-Za-z]+$"。 
	只能输入由26个大写英文字母组成的字符串："^[A-Z]+$"。 
	只能输入由26个小写英文字母组成的字符串："^[a-z]+$"。 
	只能输入由数字和26个英文字母组成的字符串："^[A-Za-z0-9]+$"。 
	只能输入由数字、26个英文字母或者下划线组成的字符串："^\w+$"。 
	验证用户密码："^[a-zA-Z]\w{5,17}$"正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。 
	验证是否含有^%&',;=?$\"等字符："[^%&',;=?$\x22]+"。 
	只能输入汉字："^[\u4e00-\u9fa5]{0,}$" 
	验证Email地址："^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$"。 
	验证InternetURL："^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$"。 
	验证电话号码："^(\(\d{3,4}-)|\d{3.4}-)?\d{7,8}$"正确格式为："XXX-XXXXXXX"、"XXXX-XXXXXXXX"、"XXX-XXXXXXX"、"XXX-XXXXXXXX"、"XXXXXXX"和"XXXXXXXX"。 
	验证身份证号（15位或18位数字）："^\d{15}|\d{18}$"。 
	验证一年的12个月："^(0?[1-9]|1[0-2])$"正确格式为："01"～"09"和"1"～"12"。 
	验证一个月的31天："^((0?[1-9])|((1|2)[0-9])|30|31)$"正确格式为；"01"～"09"和"1"～"31"。 
	匹配中文字符的正则表达式： [\u4e00-\u9fa5] 

	匹配双字节字符(包括汉字在内)：[^\x00-\xff] 
	-  more -
			正则表达式语法 
		在典型的搜索和替换操作中，必须提供要查找的确切文字。这种技术对于静态文本中的简单搜索和替换任务可能足够了，但是由于它缺乏灵活性，因此在搜索动态文本时就有困难了，甚至是不可能的。 

		使用正则表达式，就可以： 

		•测试字符串的某个模式。例如，可以对一个输入字符串进行测试，看在该字符串是否存在一个电话号码模式或一个信用卡号码模式。这称为数据有效性验证。
		•替换文本。可以在文档中使用一个正则表达式来标识特定文字，然后可以全部将其删除，或者替换为别的文字。
		•根据模式匹配从字符串中提取一个子字符串。可以用来在文本或输入字段中查找特定文字。 
		例如，如果需要搜索整个 web 站点来删除某些过时的材料并替换某些HTML 格式化标记，则可以使用正则表达式对每个文件进行测试，看在该文件中是否存在所要查找的材料或 HTML 格式化标记。用这个方法，就可以将受影响的文件范围缩小到包含要删除或更改的材料的那些文件。然后可以使用正则表达式来删除过时的材料，最后，可以再次使用正则表达式来查找并替换那些需要替换的标记。

		另一个说明正则表达式非常有用的示例是一种其字符串处理能力还不为人所知的语言。VBScript 是 Visual Basic 的一个子集，具有丰富的字符串处理功能。与 C 类似的 Jscript 则没有这一能力。正则表达式给 JScript 的字符串处理能力带来了明显改善。不过，可能还是在 VBScript 中使用正则表达式的效率更高，它允许在单个表达式中执行多个字符串操作。

		一个正则表达式就是由普通字符（例如字符 a 到 z）以及特殊字符（称为元字符）组成的文字模式。该模式描述在查找文字主体时待匹配的一个或多个字符串。正则表达式作为一个模板，将某个字符模式与所搜索的字符串进行匹配。

		这里有一些可能会遇到的正则表达式示例：


		JScript VBScript 匹配 
		/^\[ \t]*$/ "^\[ \t]*$" 匹配一个空白行。 
		/\d{2}-\d{5}/ "\d{2}-\d{5}" 验证一个ID 号码是否由一个2位数字，一个连字符以及一个5位数字组成。 
		/<(.*)>.*<\/\1>/ "<(.*)>.*<\/\1>" 匹配一个 HTML 标记。 



		下表是元字符及其在正则表达式上下文中的行为的一个完整列表：


		字符 描述 
		\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 后向引用、或一个八进制转义符。例如，'n' 匹配字符 "n"。'\n' 匹配一个换行符。序列 '\\' 匹配 "\" 而 "\(" 则匹配 "("。 
		^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 '\n' 或 '\r' 之后的位置。 
		$ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 '\n' 或 '\r' 之前的位置。 
		* 匹配前面的子表达式零次或多次。例如，zo* 能匹配 "z" 以及 "zoo"。 * 等价于{0,}。 
		+ 匹配前面的子表达式一次或多次。例如，'zo+' 能匹配 "zo" 以及 "zoo"，但不能匹配 "z"。+ 等价于 {1,}。 
		? 匹配前面的子表达式零次或一次。例如，"do(es)?" 可以匹配 "do" 或 "does" 中的"do" 。? 等价于 {0,1}。 
		{n} n 是一个非负整数。匹配确定的 n 次。例如，'o{2}' 不能匹配 "Bob" 中的 'o'，但是能匹配 "food" 中的两个 o。 
		{n,} n 是一个非负整数。至少匹配n 次。例如，'o{2,}' 不能匹配 "Bob" 中的 'o'，但能匹配 "foooood" 中的所有 o。'o{1,}' 等价于 'o+'。'o{0,}' 则等价于 'o*'。 
		{n,m} m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。刘， "o{1,3}" 将匹配 "fooooood" 中的前三个 o。'o{0,1}' 等价于 'o?'。请注意在逗号和两个数之间不能有空格。 
		? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 "oooo"，'o+?' 将匹配单个 "o"，而 'o+' 将匹配所有 'o'。 
		. 匹配除 "\n" 之外的任何单个字符。要匹配包括 '\n' 在内的任何字符，请使用象 '[.\n]' 的模式。 
		(pattern) 匹配pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 '\(' 或 '\)'。 
		(?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 "或" 字符 (|) 来组合一个模式的各个部分是很有用。例如， 'industr(?:y|ies) 就是一个比 'industry|industries' 更简略的表达式。 
		(?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如， 'Windows (?=95|98|NT|2000)' 能匹配 "Windows 2000" 中的 "Windows" ，但不能匹配 "Windows 3.1" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 
		(?!pattern) 负向预查，在任何不匹配Negative lookahead matches the search string at any point where a string not matching pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如'Windows (?!95|98|NT|2000)' 能匹配 "Windows 3.1" 中的 "Windows"，但不能匹配 "Windows 2000" 中的 "Windows"。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始  
		x|y 匹配 x 或 y。例如，'z|food' 能匹配 "z" 或 "food"。'(z|f)ood' 则匹配 "zood" 或 "food"。  
		[xyz] 字符集合。匹配所包含的任意一个字符。例如， '[abc]' 可以匹配 "plain" 中的 'a'。  
		[^xyz] 负值字符集合。匹配未包含的任意字符。例如， '[^abc]' 可以匹配 "plain" 中的'p'。  
		[a-z] 字符范围。匹配指定范围内的任意字符。例如，'[a-z]' 可以匹配 'a' 到 'z' 范围内的任意小写字母字符。  
		[^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，'[^a-z]' 可以匹配任何不在 'a' 到 'z' 范围内的任意字符。  
		\b 匹配一个单词边界，也就是指单词和空格间的位置。例如， 'er\b' 可以匹配"never" 中的 'er'，但不能匹配 "verb" 中的 'er'。  
		\B 匹配非单词边界。'er\B' 能匹配 "verb" 中的 'er'，但不能匹配 "never" 中的 'er'。 
		\cx 匹配由x指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。 x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 'c' 字符。  
		\d 匹配一个数字字符。等价于 [0-9]。  
		\D 匹配一个非数字字符。等价于 [^0-9]。  
		\f 匹配一个换页符。等价于 \x0c 和 \cL。 
		\n 匹配一个换行符。等价于 \x0a 和 \cJ。 
		\r 匹配一个回车符。等价于 \x0d 和 \cM。 
		\s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 
		\S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 
		\t 匹配一个制表符。等价于 \x09 和 \cI。 
		\v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 
		\w 匹配包括下划线的任何单词字符。等价于'[A-Za-z0-9_]'。  
		\W 匹配任何非单词字符。等价于 '[^A-Za-z0-9_]'。  
		\xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如， '\x41' 匹配 "A"。'\x041' 则等价于 '\x04' & "1"。正则表达式中可以使用 ASCII 编码。. 
		\num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，'(.)\1' 匹配两个连续的相同字符。  
		\n 标识一个八进制转义值或一个后向引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为后向引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 
		\nm 标识一个八进制转义值或一个后向引用。如果 \nm 之前至少有is preceded by at least nm 个获取得子表达式，则 nm 为后向引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的后向引用。如果前面的条件都不满足，若  n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。 
		\nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 
		\un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。 

		常用正则：
		1.验证用户名和密码：（ "^[a-zA-Z]\w{5,15}$ "）正确格式： "[A-Z][a-z]_[0-9] "组成,并且第一个字必须为字母6~16位； 
		2.验证电话号码：（ "^(\d{3.4}-)\d{7,8}$ "）正确格式：xxx/xxxx-xxxxxxx/xxxxxxxx； 
		3.验证身份证号（15位或18位数字）：（ "^\d{15} ¦\d{18}$ "）； 
		4.验证Email地址：( "^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$ ")； 
		5.只能输入由数字和26个英文字母组成的字符串：( "^[A-Za-z0-9]+$ ") ; 
		6.整数或者小数：^[0-9]+\.{0,1}[0-9]{0,2}$ 
		7.只能输入数字： "^[0-9]*$ "。 
		8.只能输入n位的数字： "^\d{n}$ "。 
		9.只能输入至少n位的数字： "^\d{n,}$ "。 
		10.只能输入m~n位的数字：。 "^\d{m,n}$ " 
		11.只能输入零和非零开头的数字： "^(0 ¦[1-9][0-9]*)$ "。 
		12.只能输入有两位小数的正实数： "^[0-9]+(.[0-9]{2})?$ "。 
		13.只能输入有1~3位小数的正实数： "^[0-9]+(.[0-9]{1,3})?$ "。 
		14.只能输入非零的正整数： "^\+?[1-9][0-9]*$ "。 
		15.只能输入非零的负整数： "^\-[1-9][]0-9 "*$。 
		16.只能输入长度为3的字符： "^.{3}$ "。 
		17.只能输入由26个英文字母组成的字符串： "^[A-Za-z]+$ "。 
		18.只能输入由26个大写英文字母组成的字符串： "^[A-Z]+$ "。 
		19.只能输入由26个小写英文字母组成的字符串： "^[a-z]+$ "。 
		20.验证是否含有^%& &apos;,;=?$\ "等字符： "[^%& &apos;,;=?$\x22]+ "。 
		21.只能输入汉字： "^[\u4e00-\u9fa5]{0,}$ " 
		22.验证URL： "^http://([\w-]+\.)+[\w-]+(/[\w-./?%&=]*)?$ "。 
		23.验证一年的12个月： "^(0?[1-9] ¦1[0-2])$ "正确格式为： "01 "～ "09 "和 "1 "～ "12 "。 
		24.验证一个月的31天： "^((0?[1-9]) ¦((1 ¦2)[0-9]) ¦30 ¦31)$ "正确格式为； "01 "～ "09 "和 "1 "～ "31 "。
		25."^\d+$ "　　//非负整数（正整数 + 0） 
		26."^[0-9]*[1-9][0-9]*$ "　　//正整数 
		27."^((-\d+) ¦(0+))$ "　　//非正整数（负整数 + 0） 
		28."^-[0-9]*[1-9][0-9]*$ "　　//负整数 
		29."^-?\d+$ "　　　　//整数 
		30."^\d+(\.\d+)?$ "　　//非负浮点数（正浮点数 + 0）
		31."^(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*))$ "　　//正浮点数 
		32."^((-\d+(\.\d+)?) ¦(0+(\.0+)?))$ "　　//非正浮点数（负浮点数 + 0） 
		33."^(-(([0-9]+\.[0-9]*[1-9][0-9]*) ¦([0-9]*[1-9][0-9]*\.[0-9]+) ¦([0-9]*[1-9][0-9]*)))$ "　　//负浮点数
		34."^(-?\d+)(\.\d+)?$ "　　//浮点数 
		35."^[A-Za-z]+$ "　　//由26个英文字母组成的字符串
		36."^[A-Z]+$ "　　//由26个英文字母的大写组成的字符串 
		37."^[a-z]+$ "　　//由26个英文字母的小写组成的字符串 
		38."^[A-Za-z0-9]+$ "　　//由数字和26个英文字母组成的字符串 
		39."^\w+$ "　　//由数字、26个英文字母或者下划线组成的字符串
		40."^[\w-]+(\.[\w-]+)*@[\w-]+(\.[\w-]+)+$ "　　　　//email地址
		41."^[a-zA-z]+://(\w+(-\w+)*)(\.(\w+(-\w+)*))*(\?\S*)?$ "　　//url 
		42.提取信息中的网络链接: (h ¦H)(r ¦R)(e ¦E)(f ¦F) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		43.提取信息中的邮件地址: \w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)* 
		44.提取信息中的图片链接: (s ¦S)(r ¦R)(c ¦C) *= *( &apos; ¦ ")?(\w ¦\\ ¦\/ ¦\.)+( &apos; ¦ " ¦ * ¦ >)? 
		45.提取信息中的ip地址: (\d+)\.(\d+)\.(\d+)\.(\d+) 
		46.提取信息中的中国手机号码: (86)*0*13\d{9} 
		47.提取信息中的中国固定电话号码: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{8} 
		48.提取信息中的中国电话号码（包括移动和固定电话）: (\(\d{3,4}\) ¦\d{3,4}- ¦\s)?\d{7,14} 
		49.提取信息中的中国邮政编码: [1-9]{1}(\d+){5} 
		50.提取信息中的中国身份证号码: \d{18} ¦\d{15} 
		51.提取信息中的整数： \d+ 
		52.提取信息中的浮点数（即小数）：(-?\d*)\.?\d+ 
		53.提取信息中的任何数字 ： (-?\d*)(\.\d+)? 
		54.提取信息中的中文字符串： [\u4e00-\u9fa5]* 
		55.提取信息中的双字节字符串 (汉字)：[^\x00-\xff]* 
		56.提取信息中的英文字符串：\w*
		57.提取任意HTML标记之间的内容：<script[\s\S]+</script *>
		58.高强度日期验证
		     ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-))$

		59.高强度日期+时间验证
		    ^((((1[6-9]|[2-9]\d)\d{2})-(0?[13578]|1[02])-(0?[1-9]|[12]\d|3[01]))|(((1[6-9]|[2-9]\d)\d{2})-(0?[13456789]|1[012])-(0?[1-9]|[12]\d|30))|(((1[6-9]|[2-9]\d)\d{2})-0?2-(0?[1-9]|1\d|2[0-8]))|(((1[6-9]|[2-9]\d)(0[48]|[2468][048]|[13579][26])|((16|[2468][048]|[3579][26])00))-0?2-29-)) (20|21|22|23|[0-1]?\d):[0-5]?\d:[0-5]?\d$

		从上面我们可以看到: "^ "表示后面紧跟着的字符为开头;与之相对应的式 "$ "以紧跟前面的字符为结尾.但是要注意的式当 "^ "位于 "[] "里时,表示 "非 "的意思,例如:[^AZ]表示不能为 "AZ "中的任一个字符. "[] "表示当中的一个字符. "{} "可以取得一个范围,例如 "{9} "表示9个,而 "{1,9} "表示1到9个字符. 

		正则调试工具：
		/Files/yasin/RegexTester.zip 
		来自：http://www.cnblogs.com/yasin/archive/2009/07/20/1527013.html
* Squid cache 
	- 代理服务器和Web缓存服务器
	- Lighttpd->Squid->Apache :架构：
			上述处理链，Lighttpd在最前面，专门处理静态内容的请求，把动态内容请求通过 Proxy模块转发给Squid，如果Squid中有该请求的内容且没有过期，
		则直接返回给Lighttpd。新请求或者过期的页面请求交由Apache 中的脚本程序来处理。经过Lighttpd和Squid的两级过滤，Apache需要处理的请求大大减少，
		减少了Web应用程序的压力。同时这样的构架，便于把不同的处理分散到多台计算机上进行，由Lighttpd在前面统一分发。 
			在这种架构下，每一级都是可以进行单独优化的，比如Lighttpd可以采用异步IO方式，Squid可以启用内存来缓存，Apache可以启用 MPM（Multi -Processing Modules，
		多道处理模块）等，并且每一级都可以使用多台机器来均衡负载，伸缩性好。
	- summary
			Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. 
		Squid has extensive access controls and makes a great server accelerator. It runs on most available operating systems, including Windows and is licensed under the GNU GPL.
			Making the most of your Internet Connection
			Squid is used by hundreds of Internet Providers world-wide to provide their users with the best possible web access. Squid optimises the data flow between client and server to improve 
		performance and caches frequently-used content to save bandwidth. Squid can also route content requests to servers in a wide variety of ways to build cache server hierarchies which 
		optimise network throughput.
			Website Content Acceleration and Distribution
			Thousands of web-sites around the Internet use Squid to drastically increase their content delivery. Squid can reduce your server load and improve delivery speeds to clients. Squid can also be used 
		to deliver content from around the world - copying only the content being used, rather than inefficiently copying everything. Finally, Squid's advanced content routing configuration allows you to build 
		content clusters to route and load balance requests via a variety of web servers.
		
		[The Squid systems] are currently running at a hit-rate of approximately 75%, effectively quadrupling the capacity of the Apache servers behind them. This is particularly noticeable when a large surge 
		of traffic arrives directed to a particular page via a web link from another site, as the caching efficiency for that page will be nearly 100%. " - Wikimedia Deployment Information. 

* hadoop
	这里先大致介绍一下Hadoop.
		本文大部分内容都是从官网Hadoop上来的。其中有一篇介绍HDFS的pdf文档，里面对Hadoop介绍的比较全面了。我的这一个系列的Hadoop学习笔记
	    也是从这里一步一步进行下来的，同时又参考了网上的很多文章，对学习Hadoop中遇到的问题进行了归纳总结。
		言归正传，先说一下Hadoop的来龙去脉。谈到Hadoop就不得不提到Lucene和Nutch。首先，Lucene并不是一个应用程序，而是提供了一个纯Java的高性能
	全文索引引擎工具包，它可以方便的嵌入到各种实际应用中实现全文搜索/索引功能。Nutch是一个应用程序，是一个以Lucene为基础实现的搜索引擎应用，
	Lucene为Nutch提供了文本搜索和索引的API，Nutch不光有搜索的功能，还有数据抓取的功能。在nutch0.8.0版本之前，Hadoop还属于Nutch的一部分，而从nutch0.8.0开始，
	将其中实现的NDFS和MapReduce剥离出来成立一个新的开源项目，这就是Hadoop，而nutch0.8.0版本较之以前的Nutch在架构上有了根本性的变化，那就是完全构建在
	Hadoop的基础之上了。在Hadoop中实现了Google的GFS和MapReduce算法，使Hadoop成为了一个分布式的计算平台。
	   其实，Hadoop并不仅仅是一个用于存储的分布式文件系统，而是设计用来在由通用计算设备组成的大型集群上执行分布式应用的框架。
	   Hadoop包含两个部分：

	   1)HDFS

	      即Hadoop Distributed File System (Hadoop分布式文件系统)
			HDFS具有高容错性，并且可以被部署在低价的硬件设备之上。HDFS很适合那些有大数据集的应用，并且提供了对数据读写的高吞吐率。HDFS是一个master/slave的结构，
	      就通常的部署来说，在master上只运行一个Namenode，而在每一个slave上运行一个Datanode。
	      HDFS支持传统的层次文件组织结构，同现有的一些文件系统在操作上很类似，比如你可以创建和删除一个文件，把一个文件从一个目录移到另一个目录，
	      重命名等等操作。Namenode管理着整个分布式文件系统，对文件系统的操作（如建立、删除文件和文件夹）都是通过Namenode来控制。 
	     下面是HDFS的结构：

			从上面的图中可以看出，Namenode，Datanode，Client之间的通信都是建立在TCP/IP的基础之上的。当Client要执行一个写入的操作的时候，命令不是马上就发送
	      到Namenode，Client首先在本机上临时文件夹中缓存这些数据，当临时文件夹中的数据块达到了设定的Block的值（默认是64M）时，Client便会通知Namenode，
	      Namenode便响应Client的RPC请求，将文件名插入文件系统层次中并且在Datanode中找到一块存放该数据的block，同时将该Datanode及对应的数据块信息告诉Client，
	      Client便这些本地临时文件夹中的数据块写入指定的数据节点。
			HDFS采取了副本策略，其目的是为了提高系统的可靠性，可用性。HDFS的副本放置策略是三个副本，一个放在本节点上，一个放在同一机架中的另一个节点上，
	      还有一个副本放在另一个不同的机架中的一个节点上。当前版本的hadoop0.12.0中还没有实现，但是正在进行中，相信不久就可以出来了。

	   2) MapReduce的实现

		      MapReduce是Google 的一项重要技术，它是一个编程模型，用以进行大数据量的计算。对于大数据量的计算，通常采用的处理手法就是并行计算。至少现阶段而言，
	      对许多开发人员来说，并行计算还是一个比较遥远的东西。MapReduce就是一种简化并行计算的编程模型，它让那些没有多少并行计算经验的开发人员也可以开发并行应用。
			MapReduce的名字源于这个模型中的两项核心操作：Map和 Reduce。也许熟悉Functional Programming（函数式编程）的人见到这两个词会倍感亲切。简单的说来，
	      Map是把一组数据一对一的映射为另外的一组数据，其映射的规则由一个函数来指定，比如对[1, 2, 3, 4]进行乘2的映射就变成了[2, 4, 6, 8]。Reduce是对一组数据进行归约，
	      这个归约的规则由一个函数指定，比如对[1, 2, 3, 4]进行求和的归约得到结果是10，而对它进行求积的归约结果是24。
	      关于MapReduce的内容，建议看看孟岩的这篇MapReduce:The Free Lunch Is Not Over!

	   好了，作为这个系列的第一篇就写这么多了，我也是刚开始接触Hadoop，下一篇就是讲Hadoop的部署，谈谈我在部署Hadoop时遇到的问题，也给大家一个参考，少走点弯路。

	- 公钥认证过程 数字签名 非对称加密
		简单的说，在dbrg-1上需要生成一个密钥对，即一个私钥，一个公钥。将公钥拷贝到dbrg-2，dbrg-3上，这样，比如当dbrg-1向dbrg-2发起ssh连接的时候，
	dbrg-2上就会生成一个随机数并用dbrg-1的公钥对这个随机数进行加密，并发送给dbrg-1；dbrg-1收到这个加密的数以后用私钥进行解密，并将解密后的数发送回dbrg-2，
	dbrg-2确认解密的数无误后就允许dbrg-1进行连接了。这就完成了一次公钥认证过程。

* mina
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
	It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
* Confluence 2.9.
	- 企业级 wiki ，便于交流互动 ，文档修改并记录历史类似版本控制，可以回滚，很是方便
* junit
	- 参考开源框架使用junit的方式 eg: metaq
	- junit fixture工作
		方法执行前准备工作，可以通过注解来配置，比如 @Before表示在每个用例执行前都行执行这个before注解的方法。

	-	请牢记！请牢记这一条 JUnit 最佳实践：测试任何可能的错误。单元测试不是用来证明您是对的，而是为了证明您没有错。
		JUnit 深入
		当然，JUnit 提供的功能决不仅仅如此简单，在接下来的内容中，我们会看到 JUnit 中很多有用的特性，掌握它们对您灵活的编写单元测试代码非常有帮助。
		Fixture
			何谓 Fixture ？它是指在执行一个或者多个测试方法时需要的一系列公共资源或者数据，例如测试环境，测试数据等等。在编写单元测试的过程中，
		您会发现在大部分的测试方法 在进行真正的测试之前都需要做大量的铺垫——为设计准备 Fixture 而忙碌。这些铺垫过程占据的代码往往比真正测试的代码多得多，
		而且这个比率随着测试的复杂程度的增加而递增。当多个测试方法都需要做同样的铺垫时，重复代 码的“坏味道”便在测试代码中弥漫开来。这股“坏味道”会弄脏您的代码，
		还会因为疏忽造成错误，应该使用一些手段来根除它。
			JUnit 专门提供了设置公共 Fixture 的方法，同一测试类中的所有测试方法都可以共用它来初始化 Fixture 和注销 Fixture。和编写 JUnit 测试方法一样，
		公共 Fixture 的设置也很简单，您只需要：
		1).使用注解 org,junit.Before 修饰用于初始化 Fixture 的方法。
		2).使用注解 org.junit.After 修饰用于注销 Fixture 的方法。
		3).保证这两种方法都使用 public void 修饰，而且不能带有任何参数。

* test * mock  * jmock		       * 单元测试 * 集成测试
	- 单元测试ok后，可以进行集成测试，以测试集成逻辑调用是否ok，比如各个环节的集成调用。
		
	- 查找框架已提供的mock类
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。
	- jtester ,用jmock框架
		写期望 Expectations 时，要注意按照调用次序写 -tip-
				a. 
					when(resourceQueryFacade.query(Instance.class, (String[])any)).thenReturn(new Instance[]{new Instance(),new Instance()}); //java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Lcom.aliyun.houyi.entity.Instance;
				b. 
					//resourceQueryFacade.query(Instance.class, (String[])any);
					//returnValue(new Instance[]{new Instance(),new Instance()});
				上面2中写法结果不一样。
		报 unexpected invocation 错误时，一般为expectation顺序不对，或者个数不对，比如某个方法有2个拦截器判断，就需要写2个expectation
			可以通过一步步 debug 找到那里写的不对（笨了点，但实用，终极解决 ~~）
				主要是通过反射执行代码，debug时要注意。debug也帮助理解mock测试的过程。比如：方法执行前会先执行方法拦截器。 -tip-
				“ ----------- 一步步的debug，验证执行逻辑是否符合预期，也能知道是什么原因导致用例执行失败。----------"
					是expectation顺序不对，还是数目不对或是其他，都可找到。
		如果一个对象被mock了，那么每次调用的expectation需要编写，否则返回null（在一些场合就会报错）
	- void mock 无返回值方法mock mock void
		直接mock那个对象或相应的方法，不做处理即可。
	- new Expectations(){
		理解Expectations的含义：
			Expectations即期望，录制期望发生的动作（设置期望返回值），执行时，按照期望的顺序执行（如不是期望定义的顺序会报错）。
		期望Expectations与mock的关系？
			expectations里 要按照执行顺序写期望逻辑。
				否则报调用错误 unexpected invocation xxx
		参考下面jmock的说明：
			JMockit Expectations

			TheJMockit Expectationsmocking API provides arecord-replaymodel for writingbehavior-basedtests. In this model, a test
			begins by setting one or moreexpectationson the invocations made from code under test to its collaborators (dependencies). 
				The classes and instances for such dependencies are established through the declaration of one or
			moremocked typesinside the test class/method. Such mocked types can be declared through instance fields of the test
			class or of an Expectations anonymous subclass inside a test method, and also through parameters of test methods
			(even though JUnit and TestNG don't allow regular test methods to have parameters). After expectations are defined in
			thisrecording phase, the test transitions to thereplay phase, when the code under test is exercised. The invocations that
			actually occur on the mocked collaborators are handled according to the mocked type declarations and the corresponding
			expectations recorded on them (if any). At the end of the replay phase, those expectations for which one or more
			invocations were expected are automatically verified so that missing invocations can be detected.
	- mock私有方法时，参数的设置方式如下，否则报类似错误：Invalid null value passed as argument 0 (instead of null, provide the Class object for the parameter type)
		
	- 单元测试
		做的好处多，特别对于合作开发，对可变情况的检测，功能完整性，逻辑错误等等。
	- junit mock
		执行顺序
			是否可以手动顺序调用用例？
		数据库测试支持 ，类似jtester?
	- easymock与junit结合 
		EasyMock:
			http://www.easymock.org/
			EasyMock provides Mock Objects for interfaces (and objects through the class extension) by generating them on the fly using Java's proxy mechanism. Due to EasyMock's unique style of recording expectations, most refactorings will not affect the Mock Objects. So EasyMock is a perfect fit for Test-Driven Development.
		例子：
			-----
			...
				public void testRegisterUser() {   
					User user = new User();   
					user.type = "vip";   
					userDao = createMock(UserDao.class);   
					expect(userDao.insertUser(user)).andReturn(true);   
					replay(userDao);   
					userService.setUserDao(userDao);   
					assertEquals(true, userService.registerUser(user));   
					verify(userDao);  
				} 
			...
			-----
* struts
	- ValueStack valueStack = con.getValueStack();
			ResultDomain result = (ResultDomain)valueStack.findValue(ResultDomainVisitor.RESULT_KEY, ResultDomain.class);
	- ActionContext
		内部实现为 ThreadLocal
	- struts拦截器测试 ，interceptor 测试
		struts2框架提供了相应的mock类，便于测试 ，比如：
			com.opensymphony.xwork2.mock.MockActionInvocation
		spring框架页提供了struts框架等框架类的mock实现，方便测试 比如：org.springframework.mock.web.MockHttpServletRequest
		
		技巧：
				要想找某个接口是否有现成的mock类供使用，可以查看接口的所有实现，查找是否存在框架已提供的mock类，要点就是框架提供一些类的mock类时，
			这些类，也需要继承这个接口。

* bat 批处理 不继续执行  (搜素 bat 调用mvn - 对于bat执行好mvn后就不继续执行其他操作的问题解决搜索关键词)
	- mavn web project 自动部署启动容器脚本(bat脚本)
		-------
			rem Eclipse 开发 maven web project部署脚本，便于部署调试

			echo stop tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call shutdown.bat

			echo build...
			echo
			cd D:\workspace\SLB-API-v2
			call mvn clean package

			echo delpoy...
			echo
			cd target
			cp -r slb.war D:\apache-tomcat-6.0.35\webapps

			echo start tomcat...
			echo
			cd %CATALINA_HOME%\bin
			call startup.bat

			:end
		-------
	-
		在于不熟悉bat。联想到shell脚本，shell脚本会继续执行
		-------
			bat中mvn命令执行完后不继续执行的解决方法
			2012-04-24 17:29codeif.com 比如有下面一段批处理程序
			mvn clean
			echo “hello world”

			输出如下
			…..
			[INFO] BUILD SUCCESSFUL
			[INFO] ————————————————————————
			[INFO] Total time: 25 seconds
			[INFO] Finished at: Tue Apr 24 17:21:55 CST 2012
			[INFO] Final Memory: 43M/123M
			[INFO] ————————————————————————
			D:\test>

			hello world并没有输出,没有达到我们的预期
			在mvn前加上call,改为如下后
			call mvn clean
			echo “hello world”

			hello word就会输出了

			cmd命令行中Call的使用如下:
			Call 从一个批处理程序调用另一个批处理程序，并且不终止父批处理程序。
		------

* rest
	rest方式的请求，根据uri定位资源 ，各种http方法发送的请求 可以用matrix url请求rest服务

* Redis
	　　redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)和zset(有序集合)。
	这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。
	与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，
	并且在此基础上实现了master-slave(主从)同步。
	http://redis.io/

* Memcached  
	- 使用外部缓存框架，对应程序，通过统一接口调用，
	- memcached的交互接口
			    memcached的客户端通过TCP连接与服务器通信（UDP协议的接口也可以使用，详细说明请参考”UDP 协议”部分）。一个给定的运行中的memcached服务器在某个（可配置的）端口上监听连接；客户端连接该端口，发送命令给服务器，读取反馈，最后关闭连接。
	       没有必要发送一个专门的命令去结束会话。客户端可以在不需要该连接的时候就关闭它。注意：我们鼓励客户端缓存它们与服务器的连接，而不是每次要存储或读取数据的时候再次重新建立与服务器的连接。memcache同时打开很多连接不会对性能造成到大的影响，这是因为memcache在设计之处，就被设计成即使打开了很多连接（数百或者需要时上千个连接）也可以高效的运行。缓存连接可以节省与服务器建立TCP连接的时间开销（于此相比，在服务器段为建立一个新的连接所做准备的开销可以忽略不计）。
	       memcache通信协议有两种类型的数据：文本行和非结构化数据。文本行用来发送从客户端到服务器的命令以及从服务器回送的反馈信息。非结构化的数据用在客户端希望存储或者读取数据时。服务器会以字符流的形式严格准确的返回相应数据在存储时存储的数据。服务器不关注字节序，它也不知道字节序的存在。memcahce对非结构化数据中的字符没有任何限制，可以是任意的字符，读取数据时，客户端可以在前次返回的文本行中确切的知道接下来的数据块的长度。
	       文本行通常以“"r"n”结束。非结构化数据通常也是以“"r"n”结束，尽管"r、"n或者其他任何8位字符可以出现在数据块中。所以当客户端从服务器读取数据时，必须使用前面提供的数据块的长度，来确定数据流的结束，二不是依据跟随在字符流尾部的“"r"n”来确定数据流的结束，尽管实际上数据流格式如此。

	c 实现
	项目主页: http://code.google.com/p/memcached/wiki/Clients	
	说明：
		memcached is a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load. 
	Danga Interactive developed memcached to enhance the speed of LiveJournal.com, a site which was already doing 20 million+ dynamic page views per day for 1 million users with a bunch of webservers and a bunch of database servers. memcached dropped the database load to almost nothing, yielding faster page load times for users, better resource utilization, and faster access to the databases on a memcache miss. 
	If you're a developer, or interested in helping us along, please help test the latest beta release on the download page. We work hard to ensure the beta releases are of high quality, but as with all beta software, be warned. 
	
	 开源的东西，潜力与生俱来
	
	启动：
		memcached -d -m 10 -u root -l 192.168.232.162  -p 12000 -c 256 -P /tmp/memcached.pid
		
		client: 官网说明：
			http://code.google.com/p/memcached/wiki/Clients
	安装：
		
		- 需要libevent库 需要制定prefix
			wget http://github.com/downloads/libevent/libevent/libevent-2.0.18-stable.tar.gz --no-check-certificate
			tar -zxvf libevent-2.0.18-stable.tar.gz
			./configure --prefix=/usr
			make
			make install
			再继续memcache安装
			例子：
					Linux下Memcache服务器端的安装
					服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。
					下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz
					另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装）
					官网：http://www.monkey.org/~provos/libevent/
					下载：http://www.monkey.org/~provos/libevent-1.3.tar.gz

					用wget指令直接下载这两个东西.下载回源文件后。
					1.先安装libevent。这个东西在配置时需要指定一个安装路径，即./configure –prefix=/usr；然后make；然后make install；
					2.再安装memcached，只是需要在配置时需要指定libevent的安装路径即./configure –with-libevent=/usr；然后make；然后make install；
					这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：

					    1.分别把memcached和libevent下载回来，放到 /tmp 目录下：
					    # cd /tmp
					    # wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz
					    # wget http://www.monkey.org/~provos/libevent-1.2.tar.gz

					    2.先安装libevent：
					    # tar zxvf libevent-1.2.tar.gz
					    # cd libevent-1.2
					    # ./configure –prefix=/usr
					    # make
					    # make install

					    3.测试libevent是否安装成功：
					    # ls -al /usr/lib | grep libevent
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -> libevent-1.2.so.1.0.3
					    -rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3
					    -rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a
					    -rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la
					    lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -> libevent-1.2.so.1.0.3
					    还不错，都安装上了。

					    4.安装memcached，同时需要安装中指定libevent的安装位置：
					    # cd /tmp
					    # tar zxvf memcached-1.2.0.tar.gz
					    # cd memcached-1.2.0
					    # ./configure –with-libevent=/usr
					    # make
					    # make install
					    如果中间出现报错，请仔细检查错误信息，按照错误信息来配置或者增加相应的库或者路径。
					    安装完成后会把memcached放到 /usr/local/bin/memcached ，

					    5.测试是否成功安装memcached：
					    # ls -al /usr/local/bin/mem*
					    -rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached
					    -rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug 

					安装Memcache的PHP扩展
					1.在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。
					2.安装PHP的memcache扩展

					    tar vxzf memcache-2.2.1.tgz
					    cd memcache-2.2.1
					    /usr/local/php/bin/phpize
					    ./configure –enable-memcache –with-php-config=/usr/local/php/bin/php-config –with-zlib-dir
					    make
					    make install

					3.上述安装完后会有类似这样的提示：

					    Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/

					4.把php.ini中的extension_dir = “./”修改为

					    extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”

					5.添加一行来载入memcache扩展：extension=memcache.so

					memcached的基本设置：
					1.启动Memcache的服务器端：
					# /usr/local/bin/memcached -d -m 10 -u root -l 192.168.0.200 -p 12000 -c 256 -P /tmp/memcached.pid

					    -d选项是启动一个守护进程，
					    -m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，
					    -u是运行Memcache的用户，我这里是root，
					    -l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
					    -p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
					    -c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
					    -P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid，

					2.如果要结束Memcache进程，执行：

					    # kill `cat /tmp/memcached.pid`

					也可以启动多个守护进程，不过端口不能重复。

					3.重启apache，service httpd restart

					Memcache环境测试：
					运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。开始领略Memcache的魅力把！
					< ?php
					$mem = new Memcache;
					$mem->connect(”127.0.0.1″, 11211);
					$mem->set(’key’, ‘This is a test!’, 0, 60);
					$val = $mem->get(’key’);
					echo $val;
					?>
					来自：http://blog.csdn.net/21aspnet/article/details/6827316
					
				服务端启动ok
				设置client调用？

	- 访问linux虚拟机中的memcache,需要设置linux防火墙规则，否则不能访问服务 key=centos memcache 访问
		-------
			在虚拟机里安装了centos，在centos里安装memcached服务器,可是在本机里使用memcached的php扩展来访问虚拟机里centos的memcached服务时，没有响应，发现PHP的日志里有以下信息：
			[html] view plaincopyprint?
			01.[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。  
			[29-Mar-2012 19:01:37] PHP Notice:  Memcache::set() [<a href='memcache.set'>memcache.set</a>]: Server 192.168.98.63 (tcp 11211) failed with: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。


			后来在网上找了一些资料，才找到解决办法。即是在centos的iptable增加两条规则，让用户可以访问虚拟机的memcached的服务。
			命令如下：
			#/sbin/iptables -I INPUT -p tcp --dport 11211 -j ACCEPT
			#/sbin/iptables -I INPUT -p udp --dport 11211 -j ACCEPT
			/etc/ini.d/iptabls save/status
			如果启动memcached服务时用了其他端口，在将你的端口号代替11211. 
		-------
	- 用了gwhalin 的Memcached-Java-Client  api，基本操作ok
	------
		public class test {

			public static void main(String[] args) {
				
				MemcachedClient mc = new MemcachedClient();
				
				mc.add("a", 1);
				
				System.out.println(mc.get("a"));
				
			}
			
			
			//inital iopool
			static {
				String[] serverlist = { "192.168.232.162:12000" };

				SockIOPool pool = SockIOPool.getInstance();
				pool.setServers(serverlist);
				pool.initialize();	
			}

			
		}
	------
* mongodb

* Elastic IP 弹性IP
	Elastic IP Addresses – Elastic IP addresses are static IP addresses designed for dynamic cloud computing. An Elastic IP address is associated with your account not a 
	particular instance, and you control that address until you choose to explicitly release it. Unlike traditional static IP addresses, however, Elastic IP addresses allow you to 
	mask instance or Availability Zone failures by programmatically remapping your public IP addresses to any instance in your account. Rather than waiting on a data technician 
	to reconfigure or replace your host, or waiting for DNS to propagate to all of your customers, Amazon EC2 enables you to engineer around problems with your instance or
	software by quickly remapping your Elastic IP address to a replacement instance. In addition, you can optionally configure the reverse DNS record of any of your Elastic IP
	addresses by filling out this form.

* json
	- 测试 json转换为map对象
		String str3 = "{\"code\":200,\"msg\":\"successful\",\"data\":{ \"lb_id\":\"123\",\" eip\":\"10.250.6.36\"}}";
		Map map3 = (Map)JSONObject.toBean(JSONObject.fromObject(str3),HashMap.class);
		System.out.println(map3.get("msg"));//successful
* ibatis
	- where calse的共用需要设计好，否则反而增加维护
		<isNotEqual>语句需要注意，类似if..else，可能会意外带入条件，最好还是用匹配上的条件去判断<isNotEmpty>,<isEqual>
	- in查询，条件sql
		select 
			xx
		 from xx
		 where  
		 <iterate property="userIds" prepend=" xx " open="(" close=")" conjunction=",">
			#ids[]#
		 </iterate> 
	- ibatis mapping文件检查       ，ibatis启动
		会验证每个语句的传入参数/对象是否和定义的名称一致，不一致报出来相应的语句错误。	单元测试加载ibatis框架以验证mapping文件格式正确。
	- * SQL预编译
		下面我们就来详细看一下有关预编译的一些知识。
		   1、什么是预编译语句
		   预编译语句PreparedStatement 是java.sql中的一个接口，它是Statement的子接口。通过Statement对象执行SQL语句时，需要将SQL语句发送给DBMS，由DBMS首先进行编译后再执行。预编译语句和Statement不同，在创建PreparedStatement 对象时就指定了SQL语句，该语句立即发送给DBMS进行编译。当该编译语句被执行时，DBMS直接运行编译后的SQL语句，而不需要像其他SQL语句那样首先将其编译。
		   2、什么时候使用预编译语句
		   一般是在需要反复使用一个SQL语句时才使用预编译语句，预编译语句常常放在一个fo r或者while循环里面使用，通过反复设置参数从而多次使用该SQL语句。为了防止SQL注入漏洞，在某些数据操作中也使用预编译语句。
		   3、为什么使用预编译语句
		   预编译机制除了在开篇提到的可以防止SQL注入外，还有一下两方面的优点：
		   (1)提高效率
		   数据库处理一个SQL语句，需要完成解析SQL语句、检查语法和语义以及生成代码，一般说来，处理时间要比执行语句所需要的时间长。预编译语句在创建的时候已经是将指定的SQL语句发送给了DBMS，完成了解析、检查、编译等工作。因此，当一个SQL语句需要执行多次时，使用预编译语句可以减少处理时间，提高执行效率。
		   (3)提高代码的可读性和可维护性
		   将参数与SQL语句分离出来，这样就可以方便对程序的更改和扩展，同样，也可以减少不必要的错误。
		   4、预编译语句的使用
		   代码段二中创建了包含带两个 IN 参数占位符的 PreparedStatement 对象，在执行之前，必须设置每个 ? 参数的值。这可通过调用 setXXX 方法来完成，该方法的第一个参数是要设置的参数的序数位置，第二个参数是设置给该参数的值，其中 XXX 是与该参数相应的类型。例如，以下代码将第一个参数设为 “tom”，第二个参数设为 “123456a”：
		   pstmt.setString(1, “tom”);
		   pstmt.setString(2, “123456a”);
		   一旦设置了给定语句的参数值，其值将一直保留，直到被设置为新值或者调用clearParameters()方法清除它为止。
		   问题延伸：请大家看一下以下的代码：
		    String sqlSt = “sel ect* from table1 where name=”+tb_name+” and passwo rd=”+tb_pwo rd;
		   PrepareStatement pst = con.createPreparementStatement();
		   ResultSet rsPst = pst.exe cuteQuery(sqlSt);
		 
		    那么在安全性和执行效率方面会不会有问题呢？请感兴趣的同事可以自己尝试一下吧。
		    from：http://www.52testing.com/showart.asp?id=67

	- ibatis 与sql注入
		假设用户执行
		    select * from product where id = 5 
		    这条语句。其中5是有用户输入的。
		    SQL注入的含义就是，一些捣蛋用户输入的不是5，而是
		    5;  delete  from  orders
		    那么原来的SQL语句将会变为，
		    select * from product where id=5;  delete  from  orders 
		    在执行完select后，还将删除orders表里的所有记录。（如果他只删了这些记录，已经谢天谢地了，他可能会做更可怕地事情）。
		    不过庆幸的是，Ibatis使用的是预编译语句（PreparedStatement
		    s ）。

		    上述语句会被编译为，
		    select * from product where id=? 
		    从而有效防止SQL注入。
		    不过当你使用$占位符时就要注意了。
		     
		    例如：动态的选择列和表
		    SELECT * FROM $TABLE_NAME$ WHERE $COLUMN_NAME$ = #value# 
		     
		    这时你一定要仔细过滤那些值以避免SQL注入。当然这种情况不只存在Ibatis中。		
			参考资料：
			【iBATIS in Action】3.5.2 SQL injection 
		    from: http://www.2cto.com/Article/201203/124648.html
		
		总结：
			正如上文所说，动态选择列或表或构造排序等操作时，需要手工过滤那些值以避免sql注入。
			当需要编程来避免sql注入时，可以通过工具类处理错位参数的字符，转义特殊字符。

	- ibatis配置文件的 typeHandler 标签配置类型转换处理方式
		·实现 com.aliyun.slb.api.dao.support.TypeHandlerCallback 接口
	- 动态where条件
		<dynamic prepend="WHERE">
			<isNotEmpty property="ip">
				ip=#ip#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="lbId">
				lb_id=#lbId#
			</isNotEmpty>
			<isNotEmpty prepend="AND" property="rsPoolName">
				rs_pool_name=#rsPoolName#
			</isNotEmpty>
		</dynamic>	
	- ibatis debug sql 执行语句位置
		com.ibatis.sqlmap.engine.execution.SqlExecutor
			public void executeQuery(StatementScope statementScope, Connection conn, String sql, Object[] parameters, int skipResults, int maxResults, RowHandlerCallback callback) throws SQLException {
* aqua 
	ctrl + d -- desc table
* 遍历 map.entrySet()
		Map<String,IMetaData> map = (Map<String,IMetaData>)result;
		
		Assert.assertEquals(map.size(), 2);
		Set<Entry<String,IMetaData>> set = map.entrySet();
		for(Entry<String, IMetaData> data:set){
* mysql
	- mysql执行计划，sql执行计划
		mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

		mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
		|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
		+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
		更多见mysql计划ppt说明

	- mysql数据dump
		mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
		source /home/xx.sql
	- 从文件导大量数据到数据库时，可以用
		source path/file eg: source d:\xx.sql
		如果拷贝出来去执行速度很慢。
		linux下：
			mysql -uxx -pxx -Ddbname < xx.sql
		需要相应权限
	-  mysql账户管理，账户授权
		GRANT ALL PRIVILEGES ON *.* TO 'monty'@'localhost' IDENTIFIED BY 'some_pass' WITH GRANT OPTION;
	- 一些命令使用，可以参考gui工具执行命令的sql参考 比如：Aqua Data Studio ，在alter table 时可以查看preview sql
	insert into vip (host,port,gmt_create,gmt_modify)values('host3',80,'2012-12-12 00:00:00','2012-12-12 00:00:00'); //id为自增列
	 select last_insert_id() as id from vip limit 1 
	 - select * from `group`
		group是mysql的关键词，需要引起来查询
		（mysql  Ver 14.14 Distrib 5.1.40, for unknown-linux-gnu (x86_64) using readline 5.1）
	- mysql>system ls
		mysql下执行shell，命令行命令方式
	- mysql where条件字符串不区分大小写
		？是否哪里可以设置要区分大小写
	- mysql 区分大小写
		参考day66
Apply address:http://www.taobao.ali.com/chanpin/wb/Lists/List4/view.aspx
* php 从小例子入手
	- shell中执行php
		chengs@houyi-vm19.dev.sd.aliyun.com $ vi foo.php

		#!/usr/local/bin/php -q
		<?
			$var = 'foo';
			echo $var."\n";
		?>

		"foo.php" [New] 5L, 62C written                                                                                  
		chengs@houyi-vm19.dev.sd.aliyun.com $ php foo.php 
		foo
		chengs@houyi-vm19.dev.sd.aliyun.com $ 

* eclipse 插件开发 eclipse plugin
	http://code.google.com/p/eclipse-fonts/ 这是简单设置编辑器字体大小的插件，可以学习eclipse的plugin编程 ?
	
* ide * eclipse
	- debug时，保证被debug的程序和当前源码一致，否则可能debug异常（比如debug不进来）
	- eclipse debug时，可以激活 break points窗口中的skip all break points按钮，这样会跳过所有debug点。
		debug点图标上会多个右斜线
	- 设置文件默认打开编辑器：general - appearance - editors - file associations 比如设置文本方式打开xml文件
	- 对于同时要打开重名项目的需求，可以通过放到不同的workspace中，单独打开操作，避开重名冲突。
	- 字体大小
		当设置字体的按钮不能用时，我就碰到了点的没反应，我们可以下载eclipse设置字体相关的插件，
		通过插件间接设置我们想要的字体，大小等。（官方文档都是基于IDE的设置窗口，但按钮是失效的，也是是bug）
		http://code.google.com/p/eclipse-fonts/ 这是其中一个插件
			
	- Eclipse取消Show in Breadcrumb
		随手右键启用这个功能，半天么找到如何取消，囧。。。
		百度了下，方且搞定，位置在：
			window > customize perspective > tool bar visibility > editor presentation > toggle greadcrumb
		工具栏上有个按钮，也可直接取消选中。
		后记：不过，对eclipse的使用及设置又学了一招。
	ctrl + shift + L 列出所有快捷键列表
	- 字母大小写
		ctrl + shift + x (大写)/ ctrl + shift + y (小写)
	- eclipse 文件夹上下关系 project property - build path -move
		source folder ，设置源码包 build path - change to source folder
		xml 标签自动提示，schema ，dtd定义正确即可
		类似aqua data studio 通过快捷键查看表结构；通过 CTRL+T 快捷键查看类型的结构(实现，继承等)
	- eclipse 快捷键 
		ctrl + t;
		ctrl + 1 quick fix ，如改包名等
		ctrl + shift + r 查找资源类
			在open按钮处选择打开方式，后面会以此方式为默认
		ctrl + shift + t 查找类型(比如某个jar包中的某个类)
	- debug插件，远程debug时，有时报错，
		一般是已打开了其debug模式，可以关闭debug（有多个debug在进行时，需要在debug面板选择需要操作的debug实例），重新打开remote debug，
		再不行，可以尝试重启eclipse再debug
	- eclipse 的 type hierarchy 面板应用
		在测试时，比如jtester测试，如果只想执行某一个方法的测试，可以在这个视图的方法上右击执行（通过反射执行，不用执行每个用例）
* php 
	 Discuz
	 开源bug管理系统bugfree：
		 http://www.bugfree.org.cn/blog/?page_id=9
* 测试，测试框架，测试插件
	* jtester
		- jtester顺序执行，按次序执行，类似集成测试的方式
			观察jtester执行用例的方式，是以方法名排序的，通过加入字符人工干预其排序达到顺序执行用例，解决依赖测试问题（比如要先创建LB，才能查询LB,删除LB等等）。
		- jtest 事务回滚测试，事务测试，unitils测试事务
			@Transactional(TransactionMode.DISABLED)
				测试事务时，需要关闭测试框架的事务，否则会出现在测试框架开启的事务中，又开启新的事务，导致交叉，不能准确的测试事务一致性。
		- 
			jtester框架测试，用dbfit测试数据库，默认以jtester.properties的数据库操作，若要动态跨数据库操作可以在wiki文件里配置，格式如下：

			指定需要连接的库
				|connect|jdbc:mysql://10.10.10.10/databaseName?useUnicode=true&amp;characterEncoding=utf-8|userName|password|com.mysql.jdbc.Driver|
				|clean table|`tableName`|
				|insert|`table|`tableName`|`|
				|id|name|
				|1|jack|
				|2|tom|
			采用默认库
				|connect|
				|clean table|`tableName`|
		- 测试异常抛出
			-----
			...
				new Expectations(){
					{	when(xx).thenReturn(xx);
						throwException(new RuntimeException(xxx));
					}
				};
				try{
					xxx.execute();
				}catch (Exception e) {
					Assert.assertEquals(e.getClass(), RuntimeException.class);
					Assert.assertEquals(e.getMessage(), xxx);
				}
			...
			-----
		- 一个测试方法，含多个测试点的时候
			可以按照顺序依次测试（在同一个方法中），不过expectation需要新建（从之前的拷贝过来即可），改动点需要设置的地方，再assert即可。
		- 测试框架，提供了各种测试方式及支持，比如mock，通过反射测试私有类等的工具JTesterReflector ，完整的去用一个测试框架。阅读其说明文档
		- 提供集成测试支持(如数据库等)
		- jtester是结合其他框架基础上的，比如@Test 注解用的就是testing框架，此时eclipse插件就下载testing(TestNG )的插件，即可在ide执行测试。ide比如eclipse执行单元
		测试框架的测试用例是根据框架的注解来解析执行的，找到框架的ide插件即可。
		下载地址：http://testng.org/doc/index.html 从其jar里找到网站信息
			http://beust.com/eclipse-old/ 5.14.0.1 新版本有问题，用这个旧版本
		- TestNG is designed to cover all categories of tests:  unit, functional, end-to-end, integration, etc...
			TestNG is a testing framework inspired from JUnit and NUnit but introducing some new functionalities that make it more powerful and easier to use
		- 新项目加入jtester步骤：
			1）加入依赖
				<repositories>
					<repository>
					<id>jtester-maven</id>
					<name>JTester</name>
					<url>http://java-tester.googlecode.com/svn/maven2/</url>
					</repository>
				</repositories>		
				<dependencies>
					<dependency>
					<groupId>org.jtester</groupId>
					<artifactId>jtester</artifactId>
					<version>1.0.1</version>
					<scope>test</scope>
				</dependency>				
			2）添加jtester.properties配置文件到classpath
				
			3）创建抽象父类，进行测试前的资源初始化操作
				@SpringApplicationContext({
					"classpath:houyi-spring-test.xml",
					"classpath:houyi-spring-dao.xml",
				    "classpath:houyi-spring-db.xml",
				    "classpath:houyi-openapi.xml",
					})
				@AutoBeanInject(maps = { @BeanMap(intf = "**.*", impl = "**.impl.*Impl") })
				public abstract class BaseJtester extends JTester {
				}
				这里 classpath:houyi-spring-test.xml 是配置了jdbc等配置文件信息的参数信息，要配置正确
			4）测试类继承上面的抽象类（db，mock，etc）
				public class ZoneDaoImplTest extends BaseJtester {
					
					@SpringBeanByName
					ZoneDao zoneDao;
					
					@DbFit(when={"ZoneDaoImplTest.testQueryClusterIdByZoneId.when.wiki"})
					@Test
					public void testQueryClusterIdByZoneId(){
						String clusterId = zoneDao.queryClusterIdByZoneId("testZoneId");
						Assert.assertEquals("testClusterId", clusterId);
					}
		- 配置jtester时，报属性文件找不到
			Caused by: java.io.FileNotFoundException: C:\Users\wb_shen.chengs\.houyi\jdbc.properties (系统找不到指定的路径。)
				查找jtester抽象父类，导入的配置文件中，是否那个配置文件引用了错误的路径；如果原配置文件不能动，可以再test包下的resource中对其
			做个拷贝，修改相应值，替代原配置文件导入。

* 简称
	 业务运营支撑系统(BOSS) 
	 弹性计算(Elastic Computing - EC) 
	 云引擎(Cloud Engine - CE) 
	 开放存储服务(Open Storage Service - OSS) 
	 云数据库服务(Cloud Database Service - CDS) 
	 阿里邮箱(Ali Mail - AM) 
	 开放表服务（Open Table Service - OTS）
* 精度转换
	Long.valueOf(String.valueOf(compensationFailureJobHour * HOUR_SEC))
* maven
	- maven 循环依赖问题，依赖交叉
		可通过将接口抽取到一个模块中，被其他实现模块引用；接口模块自身不依赖或只依赖类似model的中立模块

	- 忽略测试失败
		mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	- 测试覆盖率插件 surefire-report
		mvn surefire-report:report-only
	- maven项目分为多个子项目debug时，如果debug到的类不在当前子项目中，会找不到源码，可把关联的子项目源码包位置指定给ide，指定class的目录，比如com.xxx.xx
	- mavne 插件使用说明，查阅其官方说明：
		eclipse插件：maven-eclipse-plugin http://maven.apache.org/plugins/maven-eclipse-plugin/
		mvn某些goal执行错误时，可以尝试eclipse中clean项目再执行。
			如果eclipse使用的jdk和maven使用的jdk不是同一个的话，会报编译错误；保证2者使用同一个jdk。

	- maven可以通过参数执行特定的goal，或测试某个用例，不需要全部执行，灵活 (-Dxxx=)
		mvn test -Dtest=AppDaoImplTest
	- maven 打包后，将jar包install到本地库中
		mvn package install

	- maven web project ,maven通过选择不同的 Archetype 快速建立对应的项目目录骨架。 maven构建
	web项目(eg:webx3.0项目)
		- 比如 group id 为 org.apache.maven.archetypes 下有多种Archetype。如何自定义Archetype？
		- 还有pom文件中必须引入servlet，jsp的相关jar包，scope设置为provided，表示它们最终不会打包到war项目中
	- mvn -Dmaven.surefire.debug=true -Dtest=OpenApplicatonControllerTest test
	- maven test 
		test 时需要debug，可以利用测试插件提供的方法，结合ide(eclipse)进行debug
			比如： Surefire Plugin 测试环节的插件，支持test时，进行debug ，下面为maven的官网说明摘取：
				Forked Tests
					By default, Maven runs your tests in a separate ("forked") process. You can use the maven.surefire.debug property to debug your forked tests remotely, like this:
						mvn -Dmaven.surefire.debug test	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
				launch configuration via the menu command "Run" > "Open Debug Dialog..."
					If you need to configure a different port, you may pass a more detailed value. For example, the command below will use port 8000 instead of port 5005.
						mvn -Dmaven.surefire.debug="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000 -Xnoagent -Djava.compiler=NONE"  test
				Non-forked Tests
					You can force Maven not to fork tests by configuring the forkMode configuration parameter.
						mvn -DforkMode=never test
					Then all you need to do is debug Maven itself. Since Maven 2.0.8, Maven has shipped with a "mvnDebug" shell script that you can use to launch Maven with convenient debugging options:
					mvnDebug -DforkMode=never testThen you can attach Eclipse to Maven itself, which may be easier/more convenient than debugging the forked executable.
				上面这段：	
					The tests will automatically pause and await a remote debugger on port 5005. You can then attach to the running tests using Eclipse. You can setup a "Remote Java Application" 
					launch configuration via the menu command "Run" > "Open Debug Dialog..."
				说明如何通过eclipse来进行maven的debug调试。-tip-
				mvn -Dmaven.surefire.debug test  //maven debug
	- maven添加jar到本地库
		mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
		添加源码到本地库 添加source
		 mvn install:install-file -DgroupId=org.apache.velocity -DartifactId=velocity -Dversion=1.6.2 -Dpackaging=jar -Dfile=velocity-1.6.2-sources.jar -DgeneratePom=true -Dclassifier=sources 
	- maven jar包重复问题，可通过
		mvn dependency:tree 查看依赖关系。
		配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
		对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
		只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。
		上面如果没效果：
			通过定义 <dependencyManagement> 来自己管理依赖版本，然后再引用来解决 .work well.
	- maven source:jar 打源码包
	- maven test时一种错误
	需要强制转换。
	- maven构建时报内存溢出解决
		 Windows环境中 
			找到文件%M2_HOME%\bin\mvn.bat	
			set MAVEN_OPTS= -Xms128m -Xmx512m
			E:\test>mvn -version
			E:\test>set MAVEN_OPTS= -Xms128m -Xmx512m
		Linux环境中 
			也可以通过设置环境变量解决该问题， 如，编辑文件 /etc/profile 如下
			MAVEN_OPTS=-Xmx512m
			export JAVA_HOME MAVEN_HOME MAVEN_OPTS JAVA_BIN PATH CLASSPATH
	- maven web project debug ，maven debug tomcat
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS% 启动tomcat调试模式 ，通过socket方式
	- maven 编译错误 
		原因之一：ide的一些操作导致冲突，清楚ide的附加内容(配置，临时文件等等)，mvn clean下，再重新import到ide中即可。
		原因之二：命令行下mvn操作与ide的操作，在缓存文件上导致错误，命令行clean了，但ide上没刷新 。解决就是ide上 maven clean 然后 project clean ，
			命令行就不会报错了。
	- maven 注解不支持 annotations are not supported in  ，显式定义插件，配置参数，设置jdk版本
		Maven default is using JDK1.3 for the project compilation, building or packaging (mvn compile, install). Since JDK1.3 is not support annotation, if your project has annotation, you need to configure your Maven to use the latest JDK version. The solution is very simple, just include the Maven compiler plugin and specify the JDK version. For example,
		<project ....>
		 <build>
		  <plugins>
			<plugin>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>2.3.2</version>
				<configuration>
					<source>1.6</source>
					<target>1.6</target>
				</configuration>
			</plugin>
		   </plugins>
		  </build>
		</project>
		Above declaration tell Maven to use JDK 1.6.
	- maven 编码相关 - maven命令行执行能看到采用的编码
		a. maven插件在处理任务时，如果没有定义编码会自动匹配编码，如果与需要的不符，则运行时报错。解决：定义各插件执行的编码格式，如下：
			可以通过 mvn -version 查看maven默认采用的编码是什么？
			<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-resources-plugin</artifactId>
					<configuration>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
				<plugin>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>2.3.2</version>
					<configuration>
						<source>1.6</source>
						<target>1.6</target>
						<encoding>${file.encoding}</encoding>
					</configuration>
				</plugin>
	- 执行时，设置maven参数
			mvn -Dmaven.test.skip=false test 不跳过测试的test操作
	- No goals needed for project - skipping 跳过测试问题
		大项目下有多个子项目，某些子项目mvn test 不执行里面的test，报：No goals needed for project - skipping
		内部程序配置冲突是原因之一
* 工具类
	 apache commond 
		StringUtils 
		...
* 协作
	”系统间协作的部分，找到相关人员沟通效率就快了，都是人定义的，谁定义谁最清楚 “

* python
	Zope - opensource appserver written by python
	PyDev eclipse python插件 http://www.fabioz.com/pydev/updates
	PyDev for Eclipse 简介 http://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-pydev/index.html
	- python小工具（根据配置文件订正对应的表）
		数据库操作
		文件操作
		读取执行参数

* Google App Engine 
		虽然GAE有很多限制和缺陷，但是我对GAE还是喜爱有加的。GAE是免费的，任何人都可以很轻松的通过GAE实现自己的Web应用。比如，做一些实用的小工具，
	实现一个博客程序来练手。通过GAE，我们可以轻松的搭建属于自己的Blog(micolog)，搭建属于自己的Wiki系统(NancyWiki)。
	没有GAE，就不会有大家都懂的gappproxy，gtap，twiter-feed。是的，你懂的。	
	from: http://www.cnblogs.com/coderzh/archive/2010/11/30/goodby-google-app-engine.html
* powerdesigner  生成er图
	pd12 连接mysql，database菜单-configure data connection - 选择 connection profiles 设置即可

* shell
	- 
	- if [ $# -lt 2 ]; then 命令行参数个数小于2判断
		if [ $# -eq 3 ]; then 参数个数等于3
		shell运算符：
			
	- 判断输入参数个数
		#!/bin/sh
		num=$#
		echo $num
		
	- shell执行时，确保有执行权限
	- shell中调用其他shell ,用点运算符或source命令
		./shell.sh stop
	- 根据参数执行任务shell
		-----
			#!/bin/bash
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    insert) echo "device inserted.";;
			    remove) echo "device removed.";;
			    *) echo "invalid option.";;
			esac
		-----
	- 常用shell ，执行sh后，用tail显示执行log
		-----
			#!/bin/bash

			if [ $# -lt 2 ];
			then
				echo "USAGE: $0 -f server.properties"
				exit 1
			fi
			LOGFILE=$(dirname $0)/../logs/metaServer.log

			nohup sh $(dirname $0)/meta-run-class.sh com.taobao.metamorphosis.server.MetamorphosisStartup $@ 2>&1 >>$LOGFILE &
			tail $LOGFILE -f
		-----
* linux
	-  linux在关机或重启时自动执行某个任务
	　　先写一个脚本放在/etc/rc.d/init.d下，chmod -f 777 ， 再ln -s 到 /etc/rc.d/rc0.d/K01脚本名 与 /etc/rc.d/rc6.d/K01脚本名,同时也要 ln -s 到 /etc/rc.d/rc3.d/S99脚本名 与/etc/rc.d/rc5.d/S99脚本名。
	　　K开头的代表系统关闭的时候执行，S开头的代表开机的时候执行。注意服务器脚本编写的规范，因为有K开通的软链接并不一定会在关机的时候自动去执行，这是为什么呢？
	刚开始一直没搞明白，后来从网上看到，执行K脚本的时候会查询/var/lock/subsys/下是否有与K开头脚本同名的空文件名，如果没有就不去执行，所以要按照服务器脚本编写的规范，
	启动的时候要在/var/lock/subsys/先touch一个与K01后面同名的空文件.同时也要调用/etc/rc.d/init.d/functions能够接受star与stop命令信号，具体可以参考/etc/rc.d/rc文件，
	本人是在/etc/rc.d/rc0.d/K01yum基础上改写实现的。

	补充：
	--------
		linux /etc/rc.d/目录的详解
		分类： Linux 2008-04-09 16:16 1516人阅读 评论(0) 收藏 举报

		rc.d的内容如下：
		init.d/ :各种服务器和程序的二进制文件存放目录。
		rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
		还有三个脚本:rc.sysinit, rc, rc.local

		redhat的启动方式和执行次序是：
		加载内核
		执行init程序
		/etc/rc.d/rc.sysinit # 由init执行的第一个脚本
		/etc/rc.d/rc $RUNLEVEL # $RUNLEVEL为缺省的运行模式
		/etc/rc.d/rc.local
		/sbin/mingetty # 等待用户登录

		在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
		调入keymap以及系统字体
		启动swapping
		设置主机名
		设置NIS域名
		检查（fsck）并mount文件系统
		打开quota
		装载声卡模块
		设置系统时钟
		等等。


		/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
		，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
		从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
		/etc/rc.d/rc3.d/下的脚本。
		值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
		的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

		init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
		action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
		至此，LINUX的启动结束。 

		 

		最后自己补充一些:

		1. 许多网络服务都由超级服务/etc/rc.d/init.d/xinetd启动,这些服务的配置文件在/etc/xinetd.d/目录下,

		如telnet就是由xinetd启动的,其配置文件如下(fc7)

		  1 # default: on
		  2 # description: The telnet server serves telnet sessions; it uses /
		  3 #   unencrypted username/password pairs for authentication.
		  4 service telnet
		  5 {
		  6     flags       = REUSE
		  7     socket_type = stream
		  8     wait        = no
		  9     user        = root
		 10     server      = /usr/sbin/in.telnetd
		 11     log_on_failure  += USERID
		 12     disable     = no
		 13 }
		修改配置文件以后,重启xinetd服务即可.
	from: http://blog.csdn.net/cradmin/article/details/2270497
	--------
		2. 除了直接调用脚本外(如/etc/rc.d/init.d/xinetd),还可以用service命令来控制init.d目录下的服务,

		     如 service xinetd restart,


	ps：上面摘自网络，个人总结：
		要在linux开关机时执行自定义任务，可在 /etc/rc.d/init.d 目录下放脚本；ln到/etc/rc.d/目录下对应启动级别目录下；然后在/var/lock/subsys/目录下建同名文件。
	 
	- text 分辨率修改
		vim /boot/grub/menu.lst 
		kernel行末尾加上 vga=791
	- curl 
		测
	- beep关闭
		1）编辑 /etc/inputrc，找到
		＃set bell style none
		这一行，去掉前面的注释符号。
		2）或者编辑 /etc/profile，添加这一句，	setterm -blength 0即可。
	- md5sum
		计算md5值，验证文件完整性。
	- 设置开机启动
		在 /etc/rc.d/rc.local 	    目录：
			/etc/rc.d目录详解：
			--------
				rc.d的内容如下：
				init.d/ :各种服务器和程序的二进制文件存放目录。
				rcx.d/: 各个启动级别的执行程序连接目录。里头的东西都是指向init.d/的一些软连接。具体的后边叙述。
				还有三个脚本:rc.sysinit, rc,  rc.local

				redhat的启动方式和执行次序是：
				加载内核
				执行init程序
				/etc/rc.d/rc.sysinit            # 由init执行的第一个脚本
				/etc/rc.d/rc $RUNLEVEL          # $RUNLEVEL为缺省的运行模式
				/etc/rc.d/rc.local
				/sbin/mingetty                  # 等待用户登录

				在Redhat中，/etc/rc.d/rc.sysinit主要做在各个运行模式中相同的初始化工作，包括：
				  调入keymap以及系统字体
				  启动swapping
				  设置主机名
				  设置NIS域名
				  检查（fsck）并mount文件系统
				  打开quota
				  装载声卡模块
				  设置系统时钟
				等等。


				/etc/rc.d/rc则根据其参数指定的运行模式(运行级别，你在inittab文件中可以设置)来执行相应目录下的脚本。凡是以Kxx开头的
				，都以stop为参数来调用；凡是以Sxx开头的，都以start为参数来调用。调用的顺序按xx
				从小到大来执行。例如，假设缺省的运行模式是3，/etc/rc.d/rc就会按上述方式调用
				/etc/rc.d/rc3.d/下的脚本。
				值得一提的是，Redhat中的运行模式2、3、5都把/etc/rc.d/rc.local做为初始化脚本中
				的最后一个，所以用户可以自己在这个文件中添加一些需要在其他初始化工作之后，登录之前执行的命令。

				init在等待/etc/rc.d/rc执行完毕之后（因为在/etc/inittab中/etc/rc.d/rc的
				action是wait），将在指定的各个虚拟终端上运行/sbin/mingetty，等待用户的登录。
				至此，LINUX的启动结束。
				from: http://zhidao.baidu.com/question/10963481.html
			--------
	- /etc/init.d/ 目录，存放程序的启动文件，比如mysql，httpd，iptables等等，这里都是程序安装好后，统一把控制脚本放到这里
	- 看程序启动参数
		ps 命令看程序启动命令
	- 系统配置，语言，网络等等
		/etc/sysconfig 目录下
	- 字符编码，语言设置，编码设置	      
		vim的i进入insert模式错误：
		/etc/sysconfig/i18n
		内容修改为：
			LANG="en_US.UTF-8"
			SYSFONT="latarcyrheb-sun16"
		重新加载下：
			source /etc/sysconfig/i18n
		vim按i键，正常进入insert模式

		支持中文 ，解决中文乱码

	- 修改所有者，修改拥有者
		例：要将当前目录下名 title 的文件夹及其子文件的所有者改为geust组的su用户，方法如下：
		#chown -R su.geust title
		-R 递归式地改变指定目录及其下的所有子目录和文件的拥有者。

		chown -R admin src ——修改当前目录中的src目录及其所有内容的所有者为admin

	- 端口占用查询 ，端口查询 linux端口查询
		查询端口被谁占用（linux命令）
		分类： linux 资料或经验 2012-03-26 16:59 118人阅读 评论(0) 收藏 举报
		lsof -i:3306
		查看3306端口被谁占用
		lsof简介
		lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (tcp) 和用户数据报协议 (udp) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。
		lsof使用
		lsof输出信息含义
		在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。
		from: http://blog.csdn.net/shuhuai007/article/details/7395690
	- ls --color=never 或 --color=aways
		命令行 ，终端 ，颜色
	- ssh远程命令行 ，通过 rz ,sz 传递/接受文件
		远程拷贝目录结构：
			scp -r $LIB_DIR/* admin@$1:$LIB_DIR/   #这里需要ssh可以自动登入，比如通过公钥认证
				scp -r xx.zip admin@xx.xx.xx.xx:/home/youDir
			------
				Linux下rz/sz安装及使用方法
				-
				-
				1)    工具说明
				在SecureCRT这样的ssh登录软件里, 通过在Linux界面里输入rz/sz命令来上传/下载文件. 对于RHEL5, rz/sz默认没有安装所以需要手工安装.
				sz: 将选定的文件发送(send)到本地机器;
				rz：运行该命令会弹出一个文件选择窗口, 从本地选择文件上传到服务器(receive).
				下载安装包lrzsz-0.12.20.tar.gz: http://www.ohse.de/uwe/software/lrzsz.html

				2)    软件安装
				首先通过sftp工具把安装文件上传到/tmp目录下.

				# cd /tmp
				# tar zxvf lrzsz-0.12.20.tar.gz && cd lrzsz-0.12.20
				# ./configure && make && make install
				 

				上面安装过程默认把lsz和lrz安装到了/usr/local/bin/目录下, 下面创建软链接, 并命名为rz/sz:

				# cd /usr/bin
				# ln -s /usr/local/bin/lrz rz
				# ln -s /usr/local/bin/lsz sz
				 

				3)    使用说明
				打开SecureCRT软件 -> Options -> session options -> X/Y/Zmodem 下可以设置上传和下载的目录; 然后在用SecureCRT登陆linux终端的时候:
				# sz filename (发送文件到客户端,zmodem接收可以自行启动)
				# rz (从客户端上传文件到linux服务端)

				:)

				来自：http://www.ej38.com/showinfo/linux-183843.htm
			------
	-   $# 是传给脚本(或者函数)的参数个数, $0 是脚本本身的名字, $@ 是传给脚本(或者函数)的所有参数的列表. 举例:

                  QUOTE:
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; cat foo.sh
                  #!/bin/bash

                  echo "script name   : $0"
                  echo "# of arguments: $#"
                  echo "all arguments : $@"
                  echo "arguments in order:"
                  for sArg in "$@"; do
                      echo "  $sArg"
                  done
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa bb cc
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc
                  arguments in order:
                    aa
                    bb
                    cc
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; ./foo.sh aa "bb cc" dd
                  script name   : ./foo.sh
                  # of arguments: 3
                  all arguments : aa bb cc dd
                  arguments in order:
                    aa
                    bb cc
                    dd
                  -(dearvoid@LinuxEden:Forum)-(~/tmp)-
                  [15889 0] ; bye


                  付：
                    $0   这个程式的执行名字       
                    $n   这个程式的第n个参数值，n=1..9       
                    $*   这个程式的所有参数       
                    $#   这个程式的参数个数       
                    $$   这个程式的PID       
                    $!   执行上一个背景指令的PID       
                    $?   执行上一个指令的返回值
	- linux shell命令中Esac是什么意思？
		一些刚刚接触bash编程的人，总是很奇怪bash里的一些关键字，知道它的功能，但不知道为什么要这样写。比如：
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac
		fi是if语句的结束，esac是case语句的结束。Fi和esac这样的关键字是不是很怪异呢？呵，仔细想一想，一点也不怪，考虑一下{} [] 等等，{和}是垂直轴对称的，[和]是垂直轴对称的。现在来看， if和fi及case和esac不也是这样吗？它们刚好反过，分别表示开始和结束。
	- 内核升级 linux 内核 升级 
		下面是centos例子：
			----
				具体的过程如下:
				[root@localhost ~]# uname -r
				2.6.18-194.el5
				1.下载linux-2.6.30内核包到/usr/src目录
				cd /usr/src
				wget ftp://ftp.kernel.org/pub/linux/kernel/v2.6/linux-2.6.30.tar.gz
				tar -xzvf linux-2.6.30.tar.bz2 -C /usr/src
				cd linux-2.6.30
				make mrproper  清除环境变量，即清除配置文件
				make menuconfig 在菜单模式下选择需要编译的内核模块:
				networking support—>networking options—>network packet filtering framework(netfilter)
				(1).core netfilter configuration
				A 勾中”Netfilter connection tracking support”  -m state相关模块是依赖它的，不选则没有。
				B 将netbios name service protocal support(new)   编译成模块,不然后面升级iptables后启动时会出错
				C 勾中“Netfilter Xtables support (required for ip_tables)”
				(2).IP: Netfilter Configuration
				A 将 “IPv4 connection tracking support (require for NAT)” 编译成模块。
				B 勾中IP tables support (required for filtering/masq/NAT) 。
				C 将 “Full NAT” 下的 “MASQUERADE target support” 和 “REDIRECT target support” 编译成模块
				(3).其它模块可以根据自己的需要进行选择,若不懂可以参考内核配置手册.
				make clean  确保所有东西均保持最新状态.
				make bzImage  生成内核文件
				make modules 编译模块
				make modules_install 安装模块
				make install  安装
				mkinitrd  /boot/initrd_2.6.30.img  2.6.30  根据内核版本和指定参数生成映像文件
				cp arch/x86/boot/bzImage /boot/vmlinuz-2.6.30
				cp /usr/src/linux-2.6.30/System.map /boot/System.map-2.6.30
				2.在/etc/grub.conf添加如下2.6.30的信息,并把default=1改为default=0
				[root@localhost ~]# cat /etc/grub.conf
				# grub.conf generated by anaconda
				#
				# Note that you do not have to rerun grub after making changes to this file
				# NOTICE:  You have a /boot partition.  This means that
				#          all kernel and initrd paths are relative to /boot/, eg.
				#          root (hd0,0)
				#          kernel /vmlinuz-version ro root=/dev/VolGroup00/LogVol00
				#          initrd /initrd-version.img
				#boot=/dev/sda
				default=0
				timeout=5
				splashimage=(hd0,0)/grub/splash.xpm.gz
				hiddenmenu
				title CentOS (2.6.18-194.el5)
					root (hd0,0)
					kernel /vmlinuz-2.6.18-194.el5 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.18-194.el5.img
				title CentOS (2.6.30)
					root (hd0,0)
					kernel /vmlinuz-2.6.30 ro root=/dev/VolGroup00/LogVol00 rhgb quiet
					initrd /initrd-2.6.30.img
				3.此步若没有操作,重启会报错”insmod: error inserting ‘/lib/dm-region-hash.ko’: –1 File exits”,原因是重复了，根据网上查到的资料，2.6.x自编译内核会有这个小bug,我测试过不修改直接重启，虽然有报错，但仍然可以进入系统的.

				[root@localhost]cp /boot/initrd-2.6.30.img /tmp
				[root@localhost]cd /tmp/
				[root@localhost tmp]mkdir newinitrd
				[root@localhost tmp]cd newinitrd/
				[root@localhost newinitrd]zcat ../initrd-2.6.30.img |cpio -i
				[root@localhost newinitrd]vi init             删掉重复的如下两行:
				echo “Loading dm-region-hash.ko module”
				insmod /lib/dm-region-hash.ko
				[root@localhost newinitrd]# find .|cpio -c -o > ../initrd
				14765 blocks
				[root@localhost newinitrd]# cd ..
				[root@localhost tmp]# gzip -9 < initrd > initrd-2.6.30.img
				[root@localhost tmp]# ls
				gconfd-root  initrd  initrd-2.6.30.img  mapping-root  newinitrd  scim-panel-socket:0-root
				[root@localhost tmp]# mv /boot/initrd-2.6.30.img /home/
				[root@localhost tmp]# cp initrd-2.6.30.img /boot/
				[root@localhost tmp]#reboot
				4.重启成功后,再看看内核，是2.6.30，ok了。
				[root@localhost ~]# uname -r
				2.6.30 
			----
			from: http://bbs.51cto.com/thread-788212-1.html
		实际：
			make menuconfig 报需要ncurses包(及其devel包)
				yum install ncurses-devel //通过yum安装


	linux command eg 命令
	字符转换 unix字符 window字符
	unix2dos dos2unix

	SERVER=/home/user - 定义=号两边不能有空格

	将shell执行的pid保存到文件，读取文件中的pid关闭程序
	#! /bin/sh
	SERVER=/home/chengs
	java test > $SERVER/server.log & echo $! > $SERVER/server.pid
	
	- 关于Linux网络配置
		一：什么是网络接口卡以及如何查看网络接口的网络信息：
		 在Linux系统中，主机的网络接口卡通常称为“网络接口”，我们可以使用ifconfig命令来查看网络
		 
		接口的信息（普通用户使用/sbin/ifconfig）:
		 [root@lht ~]# ifconfig
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:6712 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1219 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:590780 (576.9 KiB)  TX bytes:156407 (152.7 KiB)
			   Interrupt:177 Base address:0x1080
		 
		lo        Link encap:Local Loopback
			   inet addr:127.0.0.1  Mask:255.0.0.0
			   inet6 addr: ::1/128 Scope:Host
			   UP LOOPBACK RUNNING  MTU:16436  Metric:1
			   RX packets:1654 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:1654 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:0
			   RX bytes:3893045 (3.7 MiB)  TX bytes:3893045 (3.7 MiB)
		 “eth0”是Linux系统中第一块以太网卡的名称，在大多数主机中只有一块物理网卡，因此“eth0”
		 
		代表系统中唯一的网络接口。
		 “lo”是Linux系统中的“环回”网络接口，“lo”并不代表真正的网络接口，而是一个虚拟的网络
		 
		接口，其IP地址永远是“127.0.0.1”；“lo”网络接口通常用于对本机的网络测试，这样在主机没
		 
		有物理网络接口或物理网络接口没有激活时Linux系统仍然可以完成网络相关的操作；
		 查看指定接口网络信息：ifconfig 网络接口名称：
		 [root@lht ~]# ifconfig eth0
		 eth0      Link encap:Ethernet  HWaddr 00:0C:29:D1:42:3F
			   inet addr:192.168.5.247  Bcast:192.168.5.255  Mask:255.255.255.0
			   inet6 addr: fe80::20c:29ff:fed1:423f/64 Scope:Link
			   UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
			   RX packets:832 errors:0 dropped:0 overruns:0 frame:0
			   TX packets:139 errors:0 dropped:0 overruns:0 carrier:0
			   collisions:0 txqueuelen:1000
			   RX bytes:73325 (71.6 KiB)  TX bytes:22844 (22.3 KiB)
			   Interrupt:177 Base address:0x1080
		 
		[root@lht ~]#
		 其中“HWaddr”表示网络接口物理地址（MAC地址），“inet addr”表示网络接口IP地址，“Bcast
		 
		”表示网各接口所在网络的广播地址，“Mask”表示网络接口的子网掩码；另外我们还可以用
		 
		ifconfig -a查看所有网络接口的网络信息。
		 二：查看网关地址和路由信息：
		 1：route:route命令不使用任何命令选项和参数时可以显示当前Linux主机中的路由表信息：
		 [root@lht ~]# route
		 Kernel IP routing table
		 Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
		 192.168.5.0     *               255.255.255.0   U     0      0        0 eth0
		 169.254.0.0     *               255.255.0.0     U     0      0        0 eth0
		 default         192.168.5.1     0.0.0.0         UG    0      0        0 eth0
		 2：使用ping命令测试与其他主机的网络连接：
		 ping 目标主机地址
		 [root@lht ~]# ping 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.123 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.176 ms
		 64 bytes from 192.168.5.104: icmp_seq=3 ttl=64 time=0.163 ms
		 64 bytes from 192.168.5.104: icmp_seq=4 ttl=64 time=0.818 ms
		 
		--- 192.168.5.104 ping statistics ---
		 4 packets transmitted, 4 received, 0% packet loss, time 3004ms
		 rtt min/avg/max/mdev = 0.123/0.320/0.818/0.288 ms
		 注意：ping命令会持续发送测试包，因此会一直在屏幕上显示每个包的测试结果，使用Ctrl+C组合键
		 
		将结束ping命令发送测试数据包；
		 使用ping命令发送指定数量的数据包进行网络测试连接：
		 ping -c 测试数据包的数量 目标的主机地址：
		 [root@lht ~]# ping -c 2 192.168.5.104
		 PING 192.168.5.104 (192.168.5.104) 56(84) bytes of data.
		 64 bytes from 192.168.5.104: icmp_seq=1 ttl=64 time=0.146 ms
		 64 bytes from 192.168.5.104: icmp_seq=2 ttl=64 time=0.170 ms
		 
		--- 192.168.5.104 ping statistics ---
		 2 packets transmitted, 2 received, 0% packet loss, time 1002ms
		 rtt min/avg/max/mdev = 0.146/0.158/0.170/0.012 ms
		 3:使用traceroute命令测试当前主机到目的主机之间经过了哪些网络节点：
		 traceroute 目的主机地址
		 [root@lht ~]# traceroute 192.168.5.104
		 traceroute to 192.168.5.104 (192.168.5.104), 30 hops max, 40 byte packets
		  1   (192.168.5.104)  0.859 ms  0.255 ms  0.625 ms
		 三：查看主机名称信息：
		 1：使用hostname命令查看当前主机名称：
		 [root@lht ~]# hostname
		 lht
		 2：更改主机名称：
		 [root@lht ~]# hostname lihantuan
		 [root@lht ~]# hostname
		 lihantuan
		 3：使用nslookup查询liuux主机中的域名：
		 nslookup->输入需要查询的域名->回车
		 nslookup 待解析的域名
		 四：网络设置方法：
		 1：DHCP网络配置：
		 使用dhclient命令可以从DHCP服务器中申请新的网络配置应用于当前的Linux主机；
		 2：手工网络配置：
		 ip地址配置命令：
		 ifconfig eth0 ip地址 netmask 子网掩码
		 [root@lht ~]# ifconfig eth0 192.168.5.247 netmask 255.255.255.0
		 [root@lht ~]#
		 注意ifconfig命令设置的网络接口属性只在当前系统运行时起效，重启后将按照网络接口配置文件
		 
		ifcfg-xxx重新设置网络接口属性；
		 3：路由配置命令：
		 添加默认网关路由：
		 route add default gw 网关地址
		 [root@lht ~]# route add default gw 192.168.5.104
		 [root@lht ~]#
		 删除默认网关：
		 route del default gw 网关地址：
		 [root@lht ~]# route del default gw 192.168.5.104
		 [root@lht ~]#
		 4：通过修改配置文件进行网络设置：
		 修改网络接口配置文件ifcfg-xxx,其中\"xxx\"是网络接口名称：
		 vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 [root@lht ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0
		 # Advanced Micro Devices [AMD] 79c970 [PCnet32 LANCE]
		 DEVICE=eth0//用于设置网络接口的名称
		 BOOTPROTO=static//用于设置网络接口是配置为静态地址（static）还是配置为dhcp；
		 BROADCAST=192.168.5.255
		 HWADDR=00:0C:29:D1:42:3F
		 IPADDR=192.168.5.247 //设置网络接口地址
		 GATEWAY=192.168.5.1 //设置网络接口的默网关
		 IPV6ADDR=
		 IPV6PREFIX=
		 NETMASK=255.255.255.0 //设置网络接口的子网掩码
		 NETWORK=192.168.5.0
		 ONBOOT=yes
		 保存好配置文件后还得重启网络服务：
		 [root@lht ~]# /etc/init.d/network restart
		 Shutting down interface eth0:                              [  OK  ]
		 Shutting down loopback interface:                          [  OK  ]
		 Bringing up loopback interface:                            [  OK  ]
		 Bringing up interface eth0:                                [  OK  ]
		 5：修改主机配置文件：
		 /etc/sysconfig/network
		 [root@lht ~]# cat /etc/sysconfig/network
		 NETWORKING=yes
		 NETWORKING_IPV6=yes
		 HOSTNAME=lht
		 GATEWAY=192.168.5.1
		 如果改了/etc/sysconfig/network里的主机名，则还需更改/etc/hosts里的主机名
		 [root@lht ~]# cat /etc/host
		 cat: /etc/host: No such file or directory
		 [root@lht ~]# cat /etc/hosts
		 # Do not remove the following line, or various programs
		 # that require network functionality will fail.
		 127.0.0.1               lht localhost.localdomain localhost
		 ::1             localhost6.localdomain6 localhost6
		 再重启系统就生效；
		 系统管理员还可以通过修改hosts文件添加更多的IP地址与主机的对应记录，hosts文件保存后就会立
		刻生效。
		 6：域名服务器配置文件：/etc/resolv.conf
		 [root@lihantuan ~]# cat /etc/resolv.conf
		 nameserver 192.168.6.100
		 nameserver 192.168.6.90
		 nameserver配置选项设置DNS服务器的IP地址，文件中最多可以有3个nameserver记录，linux系统会
		 
		优先使用文件最上面的nameserver记录，当前面的DNS服务器无效时系统会自动使用后面的DNS服务器
		 进行域名解析。

		来自：http://my.oschina.net/adamboy/blog/35109

	kill `cat server.pid` -- 这里注意是波浪号 ，不是单引号
	--------
		############################################################################
		mount -l -t

		sh startup.sh

		############################################################################
		该如何才能知道系统都有什么硬件设备，有如下几种方式：
		方式一：
		使用lsdev命令，可以显示系统中的设备及其特征。
		例如：lsdev -C
		但是一般的系统上可能没有这个命令，比如我装的fedora上面就没有这个命令。
		方法二：
		显示/proc/dev文件，这个文件记录了系统的一些硬件信息，
		例如：cat /proc/dev
		方法三：
		如果要查找特定的usb设备，则可以使用lsusb命令，列出所有的usb设备。
		如果要查找特定的pcmcia设备，则可以使用lspcmcia命令，列出所有的pcmcia设备。
		如果要查找特定的pci设备，则可以使用lspci命令，列出所有的pcm设备。
		来自：达内BBS
		############################################################################

		有些在freebsd下也能用…
		# uname -a               # 查看内核/操作系统/CPU信息
		# head -n 1 /etc/issue   # 查看操作系统版本
		# cat /proc/cpuinfo      # 查看CPU信息
		# hostname               # 查看计算机名
		# lspci -tv              # 列出所有PCI设备
		# lsusb -tv              # 列出所有USB设备
		# lsmod                  # 列出加载的内核模块
		# env                    # 查看环境变量资源
		# free -m                # 查看内存使用量和交换区使用量
		# df -h                  # 查看各分区使用情况
			-h human can read
		# du -sh         # 查看指定目录的大小
		# grep MemTotal /proc/meminfo   # 查看内存总量
		# grep MemFree /proc/meminfo    # 查看空闲内存量
		# uptime                 # 查看系统运行时间、用户数、负载
		# cat /proc/loadavg      # 查看系统负载磁盘和分区
		# mount | column -t      # 查看挂接的分区状态
		# fdisk -l               # 查看所有分区
			/dev/hda4            2946        3916     7799557+   5  Extended
				未分配的空间
				fdisk /dev/hda
				m查看帮助
				n为新建分区
				输入起始和结束cylinders ，可以通过fdisk -l 查看可分配空间，工具也会提示可分配空间

		# swapon -s              # 查看所有交换分区
		# hdparm -i /dev/hda     # 查看磁盘参数(仅适用于IDE设备)
		# dmesg | grep IDE       # 查看启动时IDE设备检测状况网络
		# ifconfig               # 查看所有网络接口的属性
		# iptables -L            # 查看防火墙设置
		# route -n               # 查看路由表
		# netstat -lntp          # 查看所有监听端口
		# netstat -antp          # 查看所有已经建立的连接
		# netstat -s             # 查看网络统计信息进程
		# ps -ef                 # 查看所有进程
		# top                    # 实时显示进程状态用户
		# w                      # 查看活动用户
		# id             # 查看指定用户信息
		# last                   # 查看用户登录日志
		# cut -d: -f1 /etc/passwd   # 查看系统所有用户
		# cut -d: -f1 /etc/group    # 查看系统所有组
		# crontab -l             # 查看当前用户的计划任务服务
		# chkconfig –list       # 列出所有系统服务
			chkconfig  provides  a  simple  command-line  tool  for  maintaining the /etc/rc[0-6].d directory hierarchy by relieving system administrators of 
			the task of directly manipulating the  numerous  symbolic  links  in  those directories.
		# chkconfig –list | grep on    # 列出所有启动的系统服务程序
		# rpm -qa                # 查看所有安装的软件包
		cat /proc/cpuinfo ：查看CPU相关参数
		cat /proc/partitions ：查看硬盘和分区
		cat /proc/meminfo ：查看内存信息
		cat /proc/version ：查看版本，类似uname -r
		cat /proc/ioports ：查看设备io端口
		cat /proc/interrupts ：查看中断
		cat /proc/pci ：查看pci设备的信息
		cat /proc/swaps ：查看所有swap分区的信息
		来自：达内BBS
		############################################################################
		linux目录架构
		/   根目录
		/bin    常用的命令 binary file 的目錄
		/boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内
		     /boot/grub/menu.lst   GRUB设置
		     /boot/vmlinuz   内核
		     /boot/initrd     核心解壓縮所需 RAM Disk
		/dev    系统周边设备     
		/etc    系统相关设定文件
		     /etc/DIR_COLORS   设定颜色
		     /etc/HOSTNAME   设定用户的节点名
		     /etc/NETWORKING   只有YES标明网络存在
		     /etc/host.conf 文件说明用户的系统如何查询节点名
		     /etc/hosts 设定用户自已的IP与名字的对应表
		     /etc/hosts.allow 设置允许使用inetd的机器使用 
		     /etc/hosts.deny 设置不允许使用inetd的机器使用
		     /etc/hosts.equiv 设置远端机不用密码
		     /etc/inetd.conf 设定系统网络守护进程inetd的配置
		     /etc/gateways 设定路由器
		     /etc/protocols 设定系统支持的协议
		     /etc/named.boot 设定本机为名字服务器的配置文件
		     /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP
		     /etc/resolv.conf    设置DNS  
		     /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這兩個 X Server 的設定檔
		     /etc/fstab    记录开机要mount的文件系统
		     /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel
		     /etc/issue 记录用户登录前显示的信息
		     /etc/group 设定用户的组名与相关信息
		     /etc/passwd 帐号信息
		     /etc/shadow 密码信息
		     /etc/sudoers 可以sudo命令的配置文件
		     /etc/securetty 设定哪些终端可以让root登录
		     /etc/login.defs 所有用户登录时的缺省配置
		     /etc/exports 设定NFS系统用的
		     /etc/init.d/   所有服務的預設啟動 script 都是放在這裡的，例如要啟動或者關閉
		     /etc/xinetd.d/  這就是所謂的 super daemon 管理的各項服務的設定檔目錄
		     /etc/modprobe.conf   内核模块额外参数设定
		     /etc/syslog.conf   日志设置文件
		/home   使用者家目录
		/lib    系统会使用到的函数库
		     /lib/modules   kernel 的相关模块
		     /var/lib/rpm   rpm套件安装处 
		/lost+found    系統不正常產生錯誤時，會將一些遺失的片段放置於此目錄下
		/mnt     外设的挂载点
		/media   与/mnt类似
		/opt     主机额外安装的软件
		/proc    虚拟目录，是内存的映射
		      /proc/version   内核版本
		       /proc/sys/kernel   系统内核功能
		/root    系统管理员的家目录
		/sbin    系统管理员才能执行的指令
		/srv     一些服務啟動之後，這些服務所需要取用的資料目錄
		/tmp     一般使用者或者是正在執行的程序暫時放置檔案的地方
		/usr     最大的目录，存许应用程序和文件
		    /usr/X11R6：   X-Window目录 
		    /usr/src：    Linux源代码
		    /usr/include：系统头文件
		    /usr/openwin 存放SUN的OpenWin 
		    /usr/man 在线使用手册
		    /usr/bin           使用者可執行的 binary file 的目錄
		    /usr/local/bin     使用者可執行的 binary file 的目錄
		    /usr/lib           系统会使用到的函数库
		    /usr/local/lib     系统会使用到的函数库
		    /usr/sbin          系统管理员才能执行的指令
		    /usr/local/sbin    系统管理员才能执行的指令
		/var   日志文件
		    /var/log/secure    記錄登入系統存取資料的檔案，例如 pop3, ssh, telnet, ftp 等都會記錄在此檔案中
		    /var/log/wtmp      記錄登入者的訊息資料, last
		    /var/log/messages  幾乎系統發生的錯誤訊息
		    /var/log/boot.log  記錄開機或者是一些服務啟動的時候，所顯示的啟動或關閉訊息
		    /var/log/maillog   紀錄郵件存取或往來( sendmail 與 pop3 )的使用者記錄
		    /var/log/cron      記錄 crontab 這個例行性服務的內容
		    /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log/procmail.log：
		    分別是幾個不同的網路服務的記錄檔
		 
		一些常用的基本命令:
		uname -a    查看内核版本       
		ls -al    显示所有文件的属性
			-R, --recursive            list subdirectories recursively
			ls -a -R 显示子目录文件
		pwd         显示当前路径        
		cd -    返回上一次目录     cd ~    返回主目录
		date s      设置时间、日期          
		cal      显示日历     cal 2006
		bc          计算器具               
		man  & info     帮助手册
		locale     显示当前字体     locale -a    所有可用字体     /etc/sysconfig/i18n设置文件
		LANG=en    使用英文字体            
		sync       将数据同步写入硬盘        
		shutdonw -h now & half & poweroff  关机
		reboot     重启                   
		startx  &  init 5   进入图形介面
		/work  & ?work    向上、下查找文档内容
		chgrp      改变档案群组  chgrp testing install.log    
		chown     改变所属人   chown root:root install.log
		chmod      改变属性     chmod 777 install.log     read=4  write=2  execute=1
		cp   复制   cp filename
		rm   删除文件  rm -rf filename   强制删除文件 
			rm -rf directory or file   -r或-R或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
		rmdir   删除文件夹
		mv  移动    mv 123.txt 222.txt  重命名
		mkdir     创建文件夹  
			mkdir -p /usr/dat.txt  # -p 参数表示如果上级目录不存在则创建
		touch     创建文件  更新当前时间
		cat       由第一行开始显示     cat |more  分页
		nl        在内容前加行号
		more  &  less   一面一面翻动
		head -n filename   显示第N行内容
		tail -n filename  显示后N行内容
			tail -f  显示追加内容
			-f
			 如果输入文件是常规文件或如果 File 参数指定 FIFO（先进先出），那么 tail 命令不会在复制了输入文件的最后的指定单元后终止，而是继续从输入文件读取和复制额外的单元（当这些单元可用时）。如果没有指定 File 参数，并且标准输入是管道，则会忽略 -f 标志。tail -f 命令可用于监视另一个进程正在写入的文件的增长。

			 同时显示多个文件追加的内容，比如用于同时查看多个日志文件场景
			 tail -f -n20 logs/info.log logs/error.log
			
			显示文件前几行内容：
				 If the first character of N (the number of bytes or lines) is a `+',	       print beginning with the Nth item from the start of each file, otherwise,print the last N items in the file.
				 tail -f -n+10

		od        显示非纯文档
		df -h 显示分区空间      (磁盘)
		du  显示目录或文件的大小
		fdisk   分区设置    fdisk -l /dev/hda  显示硬盘分区状态
		mkfs    建立各种文件系统  mkfs -t ext3  /dev/ram15   
		fsck    检查和修复LINUX档案
		ln      硬链接   ln -s  软件链接
			rm -rf open.war
			ln -s /home/admin/houyi/service/src/houyi.console.openapi/target/open.war
		whereis   查找命令
		locate    查找
		find      查找   find / -name "***.***"
			在当前目录下查找包含 hello 字符串的 后缀名为 .c 的文件:
				find . -name "*.c" | xargs grep -H "hello"
		which     查看工具
		whoami    显示当前用户
		gcc -v    查看GCC版本
		chattr +i filename  禁止删除   chattr -i filename  取消禁止
		lsattr    显示隐藏档属性
		updatedb  更新资料库
		mke2fs    格式化   mkfs -t ext3 
		dd if=/etc/passwd of=/tmp/passwd.bak    备份
			用法：dd [操作符]...
			  或：dd 选项
			Copy a file, converting and formatting according to the operands.

			  bs=BYTES        force ibs=BYTES and obs=BYTES
			  cbs=BYTES       convert BYTES bytes at a time
			  conv=CONVS      convert the file as per the comma separated symbol list
			  count=BLOCKS    copy only BLOCKS input blocks
			  ibs=BYTES       read BYTES bytes at a time
			  if=FILE         read from FILE instead of stdin
			  iflag=FLAGS     read as per the comma separated symbol list
			  obs=BYTES       write BYTES bytes at a time
			  of=FILE         write to FILE instead of stdout
			  oflag=FLAGS     write as per the comma separated symbol list
			  seek=BLOCKS     skip BLOCKS obs-sized blocks at start of output
			  skip=BLOCKS     skip BLOCKS ibs-sized blocks at start of input
			  status=noxfer   suppress transfer statistics			

			从dvd制作iso文件：
			  dd if=/dev/cdrom of=/var/lib/libvirt/images/CentOS-6.2-x86_64-bin-DVD1.iso 
		mount     列出系统所有的分区
		mount -t iso9660 /dev/cdrom /mnt/cdrom   挂载光盘
		mount -t vfat /dev/fd0 /mnt/floppy       挂载软盘
		mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
		mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
		Linux-NTFS Project: http://linux-ntfs.sourceforge.net/
		umount /mnt/hda3  缷载
		ifconfig   显示或设置网络设备
			设置ip: ifconfig eth0 192.168.232.162 netmask 255.255.255.0
			ifconfig eth0 hw ether 00:11:33:44:55:66 - set mac
		service network restart   重启网卡  
		ifdown eth0  关闭网卡
		ifup eth0    开启网卡
		clear    清屏
		history    历史记录       !55  执行第55个指令
		stty   设置终端    stty -a
		fdisk /mbr   删除GRUB
		at     僅進行一次的工作排程
		crontab   循環執行的例行性命令    [e]编辑,[l]显示,[r]删除任务
		&       后台运行程序    tar -zxvf 123.tar.gz & --------->后台运行
		jobs    观看后台暂停的程序   jobs -l
		fg      将后台程序调到前台   fg n ------>n是数字,可以指定进行那个程序
		bg      让工作在后台运行
		kill    结束进程    kill -9 PID     [9]强制结束,[15]正常结束,[l]列出可用的kill信号
			kill -9 强制停止进程，kill不了
		ps aux  查看后台程序   
		top     查看后台程序   top -d 2    每两秒更新一次        top -d 2 -p10604   观看某个PID
			top -b -n 2 > /tmp/top.txt ----->將 top 的資訊進行 2 次，然後將結果輸出到 /tmp/top.txt    
		pstree   以树状图显示程序    [A]以 ASCII 來連接, [u]列出PID, [p]列出帐号
		killall   要刪除某個服務    killall -9 httpd
		free      显示内存状态     free -m  -------->以M为单位显示
		uptime    显示目前系统开机时间
		netstat   显示网络状态    netstat -tulnp------>找出目前系統上已在監聽的網路連線及其 PID
		dmesg     显示开机信息    demsg | more
		nice      设置优先权      nice -n -5 vi & ----->用 root 給一個 nice 植為 -5 ，用於執行 vi 
		renice    调整已存在优先权
		runlevel  显示目前的runlevel

		depmod    分析可载入模块的相依性
		lsmod     显示已载入系统的模块
		modinfo   显示kernel模块的信息
		insmod    载入模块
		modprobe   自动处理可载入模块
		rmmod     删除模块
		chkconfig   检查，设置系统的各种服务     chkconfig --list ----->列出各项服务状态
		ntsysv     设置系统的各种服务
		cpio      备份文件
		 

		压缩命令：
		 *.Z      compress 程式壓縮的檔案； 
		 *.bz2    bzip2 程式壓縮的檔案； 
		 *.gz     gzip 程式壓縮的檔案； 
		 *.tar    tar 程式打包的資料，並沒有壓縮過； 
		 *.tar.gz tar 程式打包的檔案，其中並且經過 gzip 的壓縮
		compress filename  压缩文件  加[-d]解压  uncompress
		gzip filename   压缩  加[-d]解压  zcat 123.gz 查看压缩文件内容
		bzip2 -z filename  压缩  加[-d]解压   bzcat filename.bz2  查看压缩文件内容
		tar -cvf /home/123.tar /etc  打包，不压缩
		tar -xvf 123.tar   解开包
		tar -zxvf /home/123.tar.gz  以gzip解压
		tar -jxvf /home/123.tar.bz2  以bzip2解压
		tar -ztvf /tmp/etc.tar.gz   查看tar内容
		cpio -covB  > [file|device]   份份
		cpio -icduv < [file|device]   还原
		 zip -r fileName ./*.txt - 打包当前目录下所有txt文件 -r 表示递归所有子目录
			zip -r foo . -i *.sql 打包当前目录下匹配文件名的文件到foo
		vi一般用法
		一般模式              编辑模式                  指令模式
		h 左               a,i,r,o,A,I,R,O             :w 保存
		j 下                进入编辑模式                :w! 强制保存
		k 上                dd 删除光标当前行           :q! 不保存离开
		l 右                ndd 删除n行                 :wq! 保存后离开
		0 移动到行首        yy 复制当前行                :e! 还原原始档
		$ 移动到行尾        nyy 复制n行                  :w filename 另存为
		H 屏幕最上          p,P 粘贴                     :set nu 设置行号
		M 屏幕中央          u  撤消                      :set nonu 取消行号
		L 屏幕最下          [Ctrl]+r 重做上一个动作       ZZ 保存离开
		G 档案最后一行      [ctrl]+z 暂停退出            :set nohlsearch   永久地关闭高亮显示
		/work 向下搜索                                   :sp 同时打开两个文档 
		?work 向上搜索                                   [Ctrl]+w 两个文档设换
		gg 移动到档案第一行                              :nohlsearch    暂时关闭高亮显示
		 
		认识SHELL
		alias    显示当前所有的命令别名      alias lm="ls -al"   命令别名    unalias lm 取消命令别名
		type      类似which
		exprot    设置或显示环境变量
		exprot PATH="$PATH":/sbin  添加/sbin入PATH路径
		echo $PATH    显示PATH路径
		bash      进入子程序
		name=yang     设定变量
		unset name    取消变量
		echo $name    显示变量的内容
		myname="$name its me"   &   myname='$name its me'     单引号时$name失去变量内容
		ciw=/etc/sysconfig/network-scripts/     设置路径
		env      列出所有环境变量
		echo $RANDOM    显示随意产生的数
		set      设置SHELL
		PS1='[\u@\h \w \A #\#]\$ '     提示字元的設定
		   [root@linux ~]# read [-pt] variable     -----------读取键盘输入的变量
		   參數：
		   -p  ：後面可以接提示字元！
		   -t  ：後面可以接等待的『秒數！』
		declare    声明 shell 变量
		ulimit -a   显示所有限制资料
		 ls /tmp/yang && echo "exist" || echo "not exist"
		 意思是說，當 ls /tmp/yang 執行後，若正確，就執行echo "exist" ,若有問題，就執行echo "not exist" 
		 echo $PATH | cut -d ':' -f 5       以:为分隔符,读取第5段内容
		 export | cut -c 10-20      读取第10到20个字节的内容
		 last | grep 'root'    搜索有root的一行,加[-v]反向搜索
		 cat /etc/passwd | sort    排序显示
		 cat /etc/passwd | wc      显示『行、字数、字节数』
		正规表示法
		[root@test root]# grep [-acinv] '搜尋字串' filename
		       參數說明：
		       -a ：將 binary 檔案以 text 檔案的方式搜尋資料
		       -c ：計算找到 '搜尋字串' 的次數
		       -i ：忽略大小寫的不同，所以大小寫視為相同
		       -n ：順便輸出行號
		       -v ：反向選擇，亦即顯示出沒有 '搜尋字串' 內容的那一行！

		文件内容查找：

		 grep -n 'the' 123.txt     搜索the字符 -----------搜尋特定字串       
		 grep -n 't[ea]st' 123.txt    搜索test或taste两个字符---------利用 [] 來搜尋集合字元
		 grep -n '[^g]oo' 123.txt     搜索前面不为g的oo-----------向選擇 [^] 
		 grep -n '[0-9]' 123.txt  搜索有0-9的数字
		 grep -n '^the' 123.txt 搜索以the为行首-----------行首搜索^
		 grep -n '^[^a-zA-Z]' 123.txt  搜索不以英文字母开头
		 grep -n '[a-z]$' 123.txt    搜索以a-z结尾的行---------- 行尾搜索$
		 grep -n 'g..d' 123.txt     搜索开头g结尾d字符----------任意一個字元 . 
		 grep -n 'ooo*' 123.txt     搜索至少有两个oo的字符---------重複字元 *
			tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'
				grep -v 查看不匹配的行（select non-matching lines）
					如果有多个字符串匹配，先去掉匹配率高的，否则可能导致响应慢
				grep -i 去区分大小写


		sed    文本流编辑器    利用脚本命令来处理文本文件
		awd    模式扫描和处理语言
		 nl 123.txt | sed '2,5d'   删除第二到第五行的内容
		diff     比较文件的差异
		cmp      比较两个文件是否有差异
		patch    修补文件
		pr       要打印的文件格式化
		 

		帐号管理
		/etc/passwd    系统帐号信息
		/etc/shadow    帐号密码信息    经MD5 32位加密
		     在密码栏前面加『 * 』『 ! 』禁止使用某帐号
		/etc/group     系统群组信息
		/etc/gshadow
		newgrp    改变登陆组
		useradd  &  adduser    建立新用户  ---------> useradd -m test  自动建立用户的登入目录
			  useradd -m -g pgroup test --------->指定所属级
		/etc/default/useradd   相关设定
		/etc/login.defs       UID/GID 有關的設定
		passwd    更改密码 -----------> passwd test
		usermod   修改用户帐号
		userdel   删除帐号 ----------->userdel -r test
		chsh      更换登陆系统时使用的SHELL   [-l]显示可用的SHELL;[-s]修改自己的SHELL
		chfn      改变finger指令显示的信息
		finger    查找并显示用户信息
		id        显示用户的ID ----------->  id test
		groupadd   添加组
		groupmod   与usermod类似
		groupdel   删除组
		su test    更改用户   su -    进入root,且使用root的环境变量
		sudo       以其他身份来执行指令
		visudo     编辑/etc/sudoers      加入一行『 test ALL=(ALL) ALL 』
			   %wheel ALL = (ALL) ALL               系统里所有wheel群组的用户都可用sudo
			   %wheel ALL = (ALL) NOPASSWD: ALL     wheel群组所有用户都不用密码NOPASSWD
		       User_Alias ADMPW = vbird, dmtsai, vbird1, vbird3         加入ADMPW组
		       ADMPW ALL = NOPASSWD: !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, \
		       !/usr/bin/passwd root      可以更改使用者密码,但不能更改root密码 (在指令前面加入 ! 代表不可)
		PAM (Pluggable Authentication Modules, 嵌入式模組)
		who & w     看谁在线                     
		last        最近登陆主机的信息
		lastlog     最近登入的時間    读取 /var/log/lastlog 
		talk        与其他用户交谈
		write       发送信息    write test   [ctrl]+d 发送
		mesg        设置终端机的写入权限    mesg n 禁止接收     mesg y 
		wall        向所有用户发送信息    wall this is q test
		mail        写mail   
		/etc/default/useradd    家目录默认设置
		quota      显示磁盘已使用的空间与限制     quota -guvs ----->秀出目前 root 自己的 quota 限制值
			   quota -vu   查询
		quotacheck   检查磁盘的使用空间与限制     quotacheck -avug  ----->將所有的在 /etc/mtab 內，含有 quota 支援的 partition 進行掃瞄
			     [-m] 强制扫描  
		     quota一定要是独立的分区,要有quota.user和quota.group两件文件,在/etc/fstab添加一句:
		     /dev/hda3 /home ext3 defaults,usrquota,grpquota 1 2
		     chmod 600 quota*         设置完成,重启生效
		edquota    编辑用户或群组的quota  [u]用户,[g]群组,[p]复制,[t]设置宽限期限 
			   edquota -a yang       edquota -p yang -u young ----->复制    
		quotaon    开启磁盘空间限制     quotaon -auvg -------->啟動所有的具有 quota 的 filesystem
		quotaoff   关闭磁盘空间限制     quotaoff -a  -------->關閉了 quota 的限制
		repquota -av     查閱系統內所有的具有 quota 的 filesystem 的限值狀態
		Quota 從開始準備 filesystem 的支援到整個設定結束的主要的步驟大概是：
		1、設定 partition 的 filesystem 支援 quota 參數：
		由於 quota 必須要讓 partition 上面的 filesystem 支援才行，一般來說， 支援度最好的是 ext2/ext3 ，
		其他的 filesystem 類型鳥哥我是沒有試過啦！ 啟動 filesystem 支援 quota 最簡單就是編輯 /etc/fstab ，
		使得準備要開放的 quota 磁碟可以支援 quota 囉；
		2、建立 quota 記錄檔：
		剛剛前面講過，整個 quota 進行磁碟限制值記錄的檔案是 aquota.user/aquota.group， 
		要建立這兩個檔案就必須要先利用 quotacheck 掃瞄才行喔！
		3、編輯 quota 限制值資料：
		再來就是使用 edquota 來編輯每個使用者或群組的可使用空間囉；
		4、重新掃瞄與啟動 quota ：
		設定好 quota 之後，建議可以再進行一次 quotacheck ，然後再以 quotaon 來啟動吧！

		开机流程简介
		1、載入 BIOS 的硬體資訊，並取得第一個開機裝置的代號； 
		2、讀取第一個開機裝置的 MBR 的 boot Loader (亦即是 lilo, grub, spfdisk 等等) 的開機資訊； 
		3、載入 Kernel 作業系統核心資訊， Kernel 開始解壓縮，並且嘗試驅動所有硬體裝置； 
		4、Kernel 執行 init 程式並取得 run-level 資訊； 
		5、init 執行 /etc/rc.d/rc.sysinit 檔案； 
		6、啟動核心的外掛模組 (/etc/modprobe.conf)； 
		7、init 執行 run-level 的各個批次檔( Scripts )； 
		8、init 執行 /etc/rc.d/rc.local 檔案； 
		9、執行 /bin/login 程式，並等待使用者登入； 
		10、登入之後開始以 Shell 控管主機。 
		在/etc/rc.d/rc3.d內,以S开头的为开机启动,以K开头的为关闭,接着的数字代表执行顺序
		GRUB vga设定
		彩度\解析度  640x480  800x600  1024x768  1280x1024   bit 
		    256        769      771      773       775      8 bit 
		   32768       784      787      790       793     15 bit 
		   65536       785      788      791       794     16 bit 
		   16.8M       786      789      792       795     32 bit 

		./configure    检查系统信息       ./configure --help | more  帮助信息
		make clean     清除之前留下的文件
		make           编译
		make install   安装
		rpm -q  ----->查询是否安装             rpm -ql ------>查询该套件所有的目录
		rpm -qi ----->查询套件的说明资料       rpm -qc[d] ----->设定档与说明档
		rpm -ivh  ---->安装                    rpm -V  -------->查看套件有否更动过
		rpm -e  ------>删除                    rpm -Uvh ------->升级安装  
		--nodeps ----->强行安装                --test ----->测试安装

		来自：http://blogold.chinaunix.net/u/30619/showart.php?id=249558

		1、alternatives --install /usr/bin/java java /usr/java/jdk1.6.0_24/bin/java 300
		这一句的意思是给java这个LINK多加一个Path。至于什么是Link，请man alternatives，看alternatives命令的帮助，就大概能明白了。
		2、alternatives --config java 会出现一下信息：
		----------------------------------------------------------------------
		*  1           /usr/lib/jvm/jre-1.4.2-gcj/bin/java
		+ 2           /usr/java/jdk1.6.0_24/bin/java
		按 Enter 来保存当前选择[+]，或键入选择号码：2

		shutdown -h now
		halt
	
	############################################################################

		linux下Java环境的配置
		linux下Java环境的配置
			　　现在用linux的朋友越来越多了，前几天就有两个朋友问我linux下怎么配置java环境，我想还有很多朋友想了解学习这方面的东西，就写一个完全一点的linux java环境配置吧，希望对大家有帮助。
		一. 下载jdk5.0 for linux
		　　到sun的主页 http://java.sun.com/j2se/1.5.0/download.jsp 下载jdk安装文件jdk-1_5_0_05-linux-i586.bin
		二. 解压安装jdk
		　　在shell终端下进入jdk-1_5_0_05-linux-i586.bin文件所在目录，执行命令./jdk-1_5_0_05-linux-i586.bin这时会出现一段协议，连继敲回车，当询问是否同意的时候，输入yes，回车。之后会在当前目录下生成一个jdk-1.5.0_05目录，你可以将它复制到任何一个目录下。
		三. 需要配置的环境变量
		　　1.PATH环境变量。作用是指定命令搜索路径，在shell下面执行命令时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。
		　　2.CLASSPATH环境变量。作用是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。
		　　3. JAVA_HOME环境变量。它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。
		四. 三种配置环境变量的方法
		　　1. 修改/etc/profile文件
		　　　　如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
		　　　　·用文本编辑器打开/etc/profile
		　　　　·在profile文件末尾加入：
		　　　　　　JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　PATH=$JAVA_HOME/binPATH
		　　　　　　CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		　　　　　　export JAVA_HOME
		　　　　　　export PATH
		　　　　　　export CLASSPATH
		　　　　·重新登录
		　　　　·注解
		　　　　　　a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
		　　　　　　b. linux下用冒号“:”来分隔路径
		　　　　　　c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值
		　　　　　　　 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种
		　　　　　　　 常见的错误。
		　　　　　　d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
		　　　　　　e. export是把这三个变量导出为全局变量。
		　　　　　　f. 大小写必须严格区分。
		　　2. 修改.bashrc文件
		　　　　
		　　　　这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
		　　　　·用文本编辑器打开用户目录下的.bashrc文件
		　　　　·在.bashrc文件末尾加入：
		　　　　　　
		　　　　　　set JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　export JAVA_HOME
		　　　　　　set PATH=$JAVA_HOME/binPATH
			    　　　export PATH
			    　　　set CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
			    　　　export CLASSPATH
		　　　　·重新登录
		　　3. 直接在shell下设置变量
		　　　　不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
		　　　　只需在shell终端执行下列命令：
		　　　　export JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　export PATH=$JAVA_HOME/binPATH
		　　　　export CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		五. 测试jdk
		　　1. 用文本编辑器新建一个Test.java文件，在其中输入以下代码并保存：
		　　　　public class test {
		　　　　　　public static void main(String args[]) {
		　　　　　　　　System.out.println("A new jdk test !");
		　　　　　　}
		　　　　}
		　　2. 编译：在shell终端执行命令 javac Test.java
		　　3. 运行：在shell终端执行命令 java Test
		　　　　当shell下出现“A new jdk test !”字样则jdk运行正常。
		六. 卸载jdk
		　　·找到jdk安装目录的_uninst子目录
		　　·在shell终端执行命令./uninstall.sh即可卸载jdk。 



		############################################################################


		vi 

		保存退出
		* shift + ： 进入命令行状态
		* 输入wq ，并回车，即保存退出

		:w   保存文件但不退出vi 
		:w file 将修改另外保存到file中，不退出vi 
		:w!  强制保存，不推出vi
		:wq  保存文件并退出vi 
		:wq! 强制保存文件，并退出vi
		q：不保存文件，退出vi
		:q!不保存文件，强制退出vi 
		:e! 放弃所有修改，从上次保存文件开始再编辑



		############################################################################


		命令 结果定向到文件 

		rpm -qa >> /home/show

		查找到安装软件包名 ： java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5

		rpm -ql  java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5 —— 查询该套件所有的目录
		
		查找是否已安装mysql，有则卸载掉
		# rpm -qa | grep -i  mysql
		...
		# rpm -e xxxx

		############################################################################

		安装 bin格式的jdk软件包 
		进到软件包的目录下 ，运行 ./jdk1.6***.bin 即可安装
	--------

* base64 编码
		Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。
	Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符
	（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为
	适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所
	直接看到。

*	vmware7安装centos5 - 自定义方式 -  OS Installlation步骤选择install later(否则后面可能直接进入live CD 模式，不是正常安装模式)	      ，
	新建好VM后，再设置CD/DVD的地方指向ISO镜像，启动后，即可正常选择安装模式，进行安装
		确保ssh模块已安装 ，通过ssh客户端连接vmware中的centos
		vmware 修改磁盘容量 ，分区工具，重新分区
		http://www.cnblogs.com/ZhengGuoQing/archive/2008/04/03/1135803.html

*	虚拟集群,及其相关应用测试【测试】

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day1 2012年3月14日

1. 环境
	..
	eclipse 
		常用插件
			svn 
			mavn 
			spring插件 - 主要编译配置文件定位到java文件,自动提示等便捷功能
			Eclipse Web Tools Platform
			python 插件 pydev http://pydev.org/updates
			uml
			er - http://www.eclipse.org/gef/updates/index.php
			...
		eclipse jre配置设置为jdk
		-vm
		D:\Java\jdk1.6.0_10\bin\javaw.exe —— 这里路径注意下 空格之类处理为 progra~1
		-vmargs
		-Dosgi.requiredJavaVersion=1.5
		-Xms128m
		-Xmx256m	

		ide eclipse 依赖 ，依赖从上到下配置，上面不对会导致下面的类编译报错。

2. svn 
	wiki http://wiki.houyi.alibaba-inc.com/dashboard.action
	申请权限
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/
	和
	http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine

	department
	阿里云-云计算业务发展-基础产品-平台技术

wiki：
	http://wiki.houyi.alibaba-inc.com/dashboard.action

bbs:
	http://bbs.aliyun.com/

feitian SLB ACE（JCE...） (ACE - Ali Cloud Engine云引擎) OSS(kv storage)
	
	ACE php container, nodejs container,jsp container

test evn:
	Latest SLB Build: http://10.1.152.71/release/houyi/slb/trunk/2.0.476963.0/
	Latest Keepalived Build: http://10.1.152.71/release/houyi/slb/system/keepalived/1.1.20-476658.0/
	Latest HAProxy Build: http://10.1.152.71/release/houyi/slb/system/haproxy/1.4.15.1-476658.0/

	Bugfree: http://bugfree.aliyun-inc.com/index.php/bug/list/2

3. Cloud Engine - Cloud Engine是一个基于ACE的web应用托管运行环境，能够提供应用的自动伸缩以及多种核心服务。
	
	Google App Engine
	


4. linux about
	* gdb:
		What is GDB?

		GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another 
		program was doing at the moment it crashed.

		GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act:

		    Start your program, specifying anything that might affect its behavior.
		    Make your program stop on specified conditions.
		    Examine what has happened, when your program has stopped.
		    Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. 

		The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might 
		be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft 
		Windows variants.
		
		DBP实战：
			问题：

			ndb进程cpu达到99%，怀疑存在死循环，需要排查

			1.   ps -eLf | grep nbd-server

			找出那个nbd-server线程占用cpu最高，记住他的ppid（线程id）

			2.   gdb nbd-server <pid>

			启动gdb ， attach到运行的nbd-server进程

			3.  info thread

			查看所有线程

			4. thread 10

			切换到这个线程

			5. bt

			查看线程堆栈

			6. 分析代码

			from:wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=3932212

5. ssh client
	PuTTY
6. 路由  消息订阅

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day2 2012年3月15日

1. 后羿系统
	
	参考资料 Sina App Engine数据存储服务架构
	
2.  svn 账户授权 即 svn 注册用户 
	wb_shen.chengs + pwd

	url
		...houyi/cloudengine
		...houyi/console
			branches-api...-requirement 

3. houyi 异步通知
	
	异步通知是后羿系统提供的一套基于HTTP协议主动向客户系统发送VM操作结果状态的基础服务。其基本流程如下：
	 
	通知系统交互流程说明：
	1. 后羿向外部系统发出通知，即访问外部系统提供的通知接收URL。// 外部系统提供的通知接收URL
	2. 客户系统接到通知请求，根据签名信息验证通知真实性。
	3. 客户系统处理通知。
	摘自：houyi api 说明doc

4. 通过svn checkout 部分houyi项目 熟悉 【配置 svn】
	svn插件拉下项目代码 (svn 项目绑定到对应的svn库上，(对于eclipse，如果绑定错误，先删除原有svn库，从team里重新绑定即可))
	maven插件构建
		部分依赖找不到的情况：(把所在目录下已有的文件删除)通过到依赖库手动下载pom文件和相应jar.swf等文件，放到maven的.m2文件夹中解决。
		nexus http://10.250.6.11:8081/nexus/index.html#welcome 

	maven版本问题，比如编译，打包等用到plugin时，选择合适的版本，配置正确的repo，目前用maven2.2.1
		配置文件配置:
			   <!-- profile
			     | Specifies a set of introductions to the build process, to be activated using one or more of the
			     | mechanisms described above. For inheritance purposes, and to activate profiles via <activatedProfiles/>
			     | or the command line, profiles have to have an ID that is unique.
			     |
			     | An encouraged best practice for profile identification is to use a consistent naming convention
			     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.
			     | This will make it more intuitive to understand what the set of introduced profiles is attempting
			     | to accomplish, particularly when you only have a list of profile id's for debug.
			     |
			     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.
			    -->			
			 <profile>
			      <id>dev</id>

			      <repositories>
				
				<repository>
				  <id>ay32-releases</id>
				  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>

				<repository>
				  <id>nexus-releases</id>
				  <name>nexusre</name>
				  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>
			     
			 </repositories>
				  <pluginRepositories>
				<pluginRepository>
					  <id>ay32-releases</id>
					  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				<pluginRepository>
					  <id>nexus-releases</id>
					  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				  </pluginRepositories>
			    </profile>
	

	通过maven脚本构建测试部署 ？

	ide里编辑，构建工具统一编译测试部署。
	mvn clean install -rf :houyi-console-web-staff 
	参数参考：
		usage: mvn [options] [<goal(s)>] [<phase(s)>]

		Options:
		 -am,--also-make                        If project list is specified, al
							build projects required by the
							list
		 -amd,--also-make-dependents            If project list is specified, al
							build projects that depend on
							projects on the list
		 -B,--batch-mode                        Run in non-interactive (batch)
							mode
		 -C,--strict-checksums                  Fail the build if checksums don'
							match
		 -c,--lax-checksums                     Warn if checksums don't match
		 -cpu,--check-plugin-updates            Ineffective, only kept for
							backward compatibility
		 -D,--define <arg>                      Define a system property
		 -e,--errors                            Produce execution error messages
		 -emp,--encrypt-master-password <arg>   Encrypt master security password
		 -ep,--encrypt-password <arg>           Encrypt server password
		 -f,--file <arg>                        Force the use of an alternate PO
							file.
		 -fae,--fail-at-end                     Only fail the build afterwards;
							allow all non-impacted builds to
							continue
		 -ff,--fail-fast                        Stop at first failure in
							reactorized builds
		 -fn,--fail-never                       NEVER fail the build, regardless
							of project result
		 -gs,--global-settings <arg>            Alternate path for the global
							settings file
		 -h,--help                              Display help information
		 -l,--log-file <arg>                    Log file to where all build outp
							will go.
		 -N,--non-recursive                     Do not recurse into sub-projects
		 -npr,--no-plugin-registry              Ineffective, only kept for
							backward compatibility
		 -npu,--no-plugin-updates               Ineffective, only kept for
							backward compatibility
		 -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates
		 -o,--offline                           Work offline
		 -P,--activate-profiles <arg>           Comma-delimited list of profiles
							to activate
		 -pl,--projects <arg>                   Comma-delimited list of specifie
							reactor projects to build instea
							of all projects. A project can b
							specified by [groupId]:artifactI
							or by its relative path.
		 -q,--quiet                             Quiet output - only show errors
		 -rf,--resume-from <arg>                Resume reactor from specified
							project
		 -s,--settings <arg>                    Alternate path for the user
							settings file
		 -T,--threads <arg>                     Thread count, for instance 2.0C
							where C is core multiplied
		 -t,--toolchains <arg>                  Alternate path for the user
							toolchains file
		 -U,--update-snapshots                  Forces a check for updated
							releases and snapshots on remote
							repositories
		 -up,--update-plugins                   Ineffective, only kept for
							backward compatibility
		 -V,--show-version                      Display version information
							WITHOUT stopping build
		 -v,--version                           Display version information
		 -X,--debug                             Produce execution debug output

		tip:
			parent pom declare most properties ,plugins etc,models under parent,only needs to config special requiments ,if needs to make war package for example and it can references definetions
			from parent pom ,just lile inheritance(eg struts2's configuration file struts.xml).

		maven 插件 ，源码自动下载

5. 熟悉houyi代码，结构
	
	
	
6. xStream javabean 与 xml ，json映射工具
	参考：http://www.cnblogs.com/hoojo/archive/2011/04/22/2025197.html
	部分如下：
		xStream框架

			xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换；

			前面有介绍过json-lib这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/21/2023805.html

			以及Jackson这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/22/2024628.html

			它们都完美支持JSON，但是对xml的支持还不是很好。一定程度上限制了对Java对象的描述，不能让xml完全体现到对Java对象的描述。
			这里将会介绍xStream对JSON、XML的完美支持。xStream不仅对XML的转换非常友好，而且提供annotation注解，可以在JavaBean中完成
			对xml节点、属性的描述。以及对JSON也支持，只需要提供相关的JSONDriver就可以完成转换。 

7. Quartz 调度

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day3 2012年3月16日

1. 项目目录结构 maven
	
	

2. 结合 openapi 接口文档 ，熟悉代码，规范

	以hoyi-console-openapi  为例，熟悉大体框架，配置方式，处理流程
	
	根据应用上下文配置文件(web.xml)，熟悉请求处理流程 （web应用 ,java应用根据程序入口）

		* struts2 ,spring ,ibatis
			spring
				bean管理 - pojo,dao bean ,action
				事务管理
			struts2
				interceptor - default and user defined interceptors / pluggable
				objectfactory = spring
				action继承/接口关系(部分)
					public class RackQueryAction extends PagingInfovalidator implements ExecuteAction {
					-> public abstract class PagingInfovalidator extends AbstractExecuteAction implements ActionValidator{
					-> public abstract class AbstractExecuteAction implements ExecuteAction {

				部分struts源码截取：【struts】
					multi-thread safe
					--------
						package com.opensymphony.xwork2;
						...
						public class ActionContext implements Serializable {
						    static ThreadLocal actionContext = new ThreadLocal();
						...
						    Map<String, Object> context;

						    public ActionContext(Map<String, Object> context) {
							this.context = context;
						    }
						...
						    public static void setContext(ActionContext context) {
							actionContext.set(context);
						    }
						    public static ActionContext getContext() {
							return (ActionContext) actionContext.get();
					--------
					
					--------
					...
					package com.opensymphony.xwork2;
					public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable {
					...
					    public Locale getLocale() {
						ActionContext ctx = ActionContext.getContext();
						if (ctx != null) {
						    return ctx.getLocale();
						} else {
						    LOG.debug("Action context not initialized");
						    return null;
						}
					    }
					...
					--------
					Interface :
						Action - All actions may implement this interface, which exposes the execute() method. 
						Validateable - Provides an interface in which a call for a validation check can be done.
						ValidationAware - ValidationAware classes can accept Action (class level) or field level error messages. Action level messages are kept in a Collection. 
									Field level error messages are kept in a Map from String field name to a List of field error msgs.
						TextProvider - Provides access to ResourceBundles and their underlying text messages.
						LocalProvider - Indicates that the implementing class can provide its own Locale. 
					
					ActionInvocation
							An ActionInvocation represents the execution state of an Action. It holds the Interceptors and the Action instance. By repeated re-entrant execution 
						of the invoke() method, initially by the ActionProxy, then by the Interceptors, the Interceptors are all executed, and then the Action and the Result.
						代理类，维护interceptors集合并依次序传递和执行ActionInvocation的实现类。？




			ibatis openAPI通过spring提供ibatis的template进行dao操作
				部分代码，spring集成ibatis部分
					--------
					package org.springframework.orm.ibatis;
					...
					public class SqlMapClientTemplate extends JdbcAccessor implements SqlMapClientOperations {
						public Object queryForObject(final String statementName, final Object parameterObject)
								throws DataAccessException {

							return execute(new SqlMapClientCallback() {
								public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
									return executor.queryForObject(statementName, parameterObject);
								}
							});
						...
						public Object execute(SqlMapClientCallback action) throws DataAccessException {
							Assert.notNull(action, "Callback object must not be null");
							Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

							// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
							// Connection (potentially transactional) in. This shouldn't be necessary if
							// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
							// we still need it to make iBATIS batch execution work properly: If iBATIS
							// doesn't recognize an existing transaction, it automatically executes the
							// batch for every single statement...

							SqlMapSession session = this.sqlMapClient.openSession();
							if (logger.isDebugEnabled()) {
								logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
							}
							Connection ibatisCon = null;

							try {
								Connection springCon = null;
								DataSource dataSource = getDataSource();
								boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

								// Obtain JDBC Connection to operate on...
								try {
									ibatisCon = session.getCurrentConnection();
									if (ibatisCon == null) {
										springCon = (transactionAware ?
												dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
										session.setUserConnection(springCon);
										if (logger.isDebugEnabled()) {
											logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
										}
									}
									else {
										if (logger.isDebugEnabled()) {
											logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
										}
									}
								}
								catch (SQLException ex) {
									throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
								}

								// Execute given callback...
								try {
									return action.doInSqlMapClient(session);
								}
								catch (SQLException ex) {
									throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
								}
								finally {
									try {
										if (springCon != null) {
											if (transactionAware) {
												springCon.close();
											}
											else {
												DataSourceUtils.doReleaseConnection(springCon, dataSource);
											}
										}
									}
									catch (Throwable ex) {
										logger.debug("Could not close JDBC Connection", ex);
									}
								}

								// Processing finished - potentially session still to be closed.
							}
							finally {
								// Only close SqlMapSession if we know we've actually opened it
								// at the present level.
								if (ibatisCon == null) {
									session.close();
								}
							}
						}	}
					...
					--------
			dbcp - DB connection pool


		* 枚举 enum 
			定义常量(可扩展的)，优于普通常量定义
			 AgreementParameter
			 GlobalErrorMessage
			...
				eg:
				return CloudEngineEvent.NGINX.getEvent();

				public enum CloudEngineEvent {
					REGISTER(10001),
					NGINX(30001),
					FASTCGI(30002),
					SLB(30003),
					MEMCACHED(30004),
					RDS(30005),
					NODEJS(30006)
					;
					
					private CloudEngineEvent(Integer event) {
						this.event = event;
					}
					
					private Integer event;
					public Integer getEvent() {
						return event;
					}
				}

		* 

	openAPI mode 要引用到得其他各层分别在不同的model中: (openapi为houyi项目其中一个model)
		<modules>
		  <module>houyi.console.model</module> 域模型(历史原因有部分分散在其他model中)
		  <module>houyi.console.util</module> 工具
		  <module>houyi.console.acl</module> 访问控制
		  <module>houyi.console.dao</module> DAO
		  <module>houyi.console.clc</module> 对内master交互模块(操作vm等)
		  <module>houyi.console.service</module> 逻辑层
		  <module>houyi.console.message</module> 消息
		  <module>houyi.console.statistics</module>  
		  <module>houyi.console.web/houyi.console.web.support</module>  web这块原先以portal调
		  <module>houyi.console.web/houyi.console.web.staff</module>
		  <module>houyi.console.web/houyi.console.web.admin</module>
		  <module>houyi.console.web/houyi.console.web.isv</module>
		  <module>houyi.console.openapi</module> 对外openapi模块
		</modules>		
	
	openAPI 放开的请求action配置：- 统一出入口 ？
		<package name="instance" extends="houyi-open" namespace="/">
			<action name="services" class="openAPIProxyAction" method="proxy"><!-- action交给spring管理，此action为：open api 的访问代理 -->
			   <result type="userActionResult"></result> <!-- 自定义result -->
			</action>
		</package>
		代理action利用req请求消息，通过工厂方式(目标action都实现相同接口)调用对应的目标acton，目标action通过spring context获得：
			// Return the bean instances that match the given object type (including subclasses), judging from either bean definitions or the value of getObjectType in the case of FactoryBeans. 
			Map map = context.getBeansOfType(ExecuteAction.class);


3. xen 快照 了解  虚拟机快照 【快照】
	虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
	chain 模式 比如 struts的intercepter ，插拔式
	
	http://server.it168.com/a2009/0723/611/000000611079.shtml
4. StringEscapeUtils 
	Escapes and unescapes Strings for Java, Java Script, HTML, XML, and SQL
	commons-lang包

5. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day4 2012年3月19日

1. RESTful REST 请求

http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v2/master/src/main/java/com/aliyun/cloudengine/
JCE的master以REST架构，处理openAPI(为get/post请求规范)请求需要提供一个适配层(将REST请求转换为http方式的get/post请求) ？ - Java Cloud Engine

jce的rest实现基于

rest http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/
	介绍jdk1.6提供的rest接口，master的rest基于jdk的rest接口 javax.ws.rs

基于 REST 的 Web 服务遵循一些基本的设计原则：
    系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的 URI。
    以遵循 RFC-2616 所定义的协议的方式显式地使用 HTTP 方法，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与 HTTP 方法之间的一对一映射：
        若要在服务器上创建资源，应该使用 POST 方法；
        若要检索某个资源，应该使用 GET 方法；
        若要更改资源状态或对其进行更新，应该使用 PUT 方法；
        若要删除某个资源，应该使用 DELETE 方法。
    URI 所访问的每个资源都可以使用不同的形式加以表示（比如 XML 或者 JSON），具体的表现形式取决于访问资源的客户端，客户端与服务提供者使用一种内容协商的机制（请求头与 MIME 类型）来选择合适的数据格式，最小化彼此之间的数据耦合。

【Task】
	以 /houyi-cloudengine-master/src/main/java/com/aliyun/cloudengine/RestAdminApplication.java 为例，熟悉rest方式，并分析rest方式与openapi标准的get/post方式如何转换 ？
	houyi-cloudengine-master 提供几个rest接口供外界调用。
	由于rest方式的请求url不同于普通http请求的url，需要提供一个模块处理标准http请求的处理(接受请求-调用接口-返回结果)
		rest方式URI: persion/123		http方式: persion?id=123
	
	cloudengine 运行是基于xuanyuan的一个组件，xuanyuan负责请求分配。
	
	参考实现的文档，搭建测试环境测试，判断是否支持预想的解决方案。 - tip -

2.  test 测试
JTester
	   http://java-tester.googlecode.com/svn/maven2/

	   http://www.blogjava.net/kiral/archive/2011/02/04/344072.html usage
	

3. 搭建 restful 环境，测试
	jersey + tomcat 的restful测试环境搭建：
		wiki https://wikis.oracle.com/display/Jersey/Main
		参考 http://www.ibm.com/developerworks/cn/web/wa-aj-tomcat/

	@POST 
	@Path("/test")
	@Produces(MediaType.APPLICATION_JSON)
	public String showTime(@FormParam("username") String userName,@Context HttpServletRequest httpRequest) {
	:
	:
	:
	}
	// jersey - 通过context注解获得httprequest对象
	
	对于openAPI调用(待测试)：
		可以给定URI请求，匹配到一个service上，然后取得request对象，做后续处理。
		(要做的步骤：
			配置一个service匹配opanapi的所有请求

		)

Using Entity Providers toMapHTTP Response and
Request Entity Bodies
Entity providers supply mapping services between representations and their associated Java
types. There are two types of entity providers: MessageBodyReader and MessageBodyWriter.
For HTTP requests, the MessageBodyReader is used to map an HTTP request entity body to
method parameters. On the response side, a return value is mapped to an HTTP response entity
body using a MessageBodyWriter. If the application needs to supply additional metadata, such
Responding to HTTP Resources
Chapter 3 • Creating a RESTful Resource Class 19
as HTTP headers or a different status code, a method can return a Response that wraps the
entity, and which can be built using Response.ResponseBuilder.

——jersey文档

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day5 Tuesday, March 20, 2012

1. day4第3条 go on
	* 下载jersey包
	* 新建web项目，导入jersey必要包
	* 配置jersey的请求处理servlet，并正确配置package属性：com.sun.jersey.config.property.packages - 指向你的resource包
	* 部署到tomcat中
	* 测试

	部分代码：
	-----
		<servlet>
			<servlet-name>Jersey REST Service</servlet-name>
			<servlet-class>
			  com.sun.jersey.spi.container.servlet.ServletContainer
			</servlet-class>
			<init-param>
			  <param-name>com.sun.jersey.config.property.packages</param-name>
			  <param-value>test.jersey.service</param-value>
			</init-param>
			<load-on-startup>1</load-on-startup>
		</servlet>
		<servlet-mapping>
		  <servlet-name>Jersey REST Service</servlet-name>
		  <url-pattern>/rest/*</url-pattern>
		</servlet-mapping>

		package test.jersey.service;
		@Path("hello")
		public class HelloResponse {

			@GET
			@Produces(MediaType.TEXT_PLAIN)
			public String sayHello(){
				return "Hello jersey";
			}
	
		}
	------
	[ Test ]
		req: http://localhost:8080/jersey/rest/hello
		resp: Hello jersey

	[ Test ]
		@GET
		@Produces(MediaType.TEXT_PLAIN)
		public String sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
			return "id:"+id+" name:"+name;
		}	
		request: http://localhost:8080/jersey/rest/hello?id=1&name=jack   - 
		response: id:1 name:jack

	[ Test ]
		@Path("/hello")
		public class HelloResponse {

			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			public MyResponse sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
		//		return "NORMAL id:"+id+" name:"+name+"\n";
				return new MyResponse(id,name);
			}
			
			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			@Path("/sayhello/{id}/{name}")
			public Object sayHelloRest(@DefaultValue("1") @PathParam("id") String id,@DefaultValue("1NaN") @PathParam("name") String name){
				return new MyResponse("1","jack");
			}
		}
		web.xml: 
			<servlet-mapping>
				  <servlet-name>Jersey REST Service</servlet-name>
				  <url-pattern>/open/*</url-pattern>
			</servlet-mapping>
		request: http://localhost:8080/jersey/open/hello/sayhello/1/1
		response: 
				<data>
					<id>1</id><
					name>jack</name>
				</data>

	要返回json或xml，需要将返回的对象配置上对象到xml的映射注解，比如利用jaxb等 ，需要提供一个对象到json或者xml的映射机制，如果直接返回
	jdk的list对象会报错，无法转换：
		A message body writer for Java class java.util.ArrayList, and Java type interface java.util.List, and MIME media type application/xml was not found
		eg:http://blog.coderunnr.com/2011/02/clienthandlerexception-a-message-body-writer-for-java-type-class-and-mime-media-type-applicationoctet-stream-was-not-found/
	将返回的pojo通过注解映射到xml即可：
		@XmlRootElement(name="data")
		public class MyResponse {
			
			private String id;
			
			private String name;
			
			public MyResponse(){}
			
			public MyResponse(String id,String name){
				this.id = id;
				this.name = name;
			}
			
			@XmlElement(name="id")
			public String getId() {
				return id;
			}
			public void setId(String id) {
				this.id = id;
			}
			
			@XmlElement(name="name")
			public String getName() {
				return name;
			}
			public void setName(String name) {
				this.name = name;
			}
		}
		

		问题：
			// 这个标签标示注解的方法支持下面定义的 2 种返回数据格式，具体确定？
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			
			如上，可以返回多个MIME，如何选择，确定返回的类型？
				比如，需要返回xml，或者需要返回json 
				看openAPI是根据什么返回指定格式的数据的？
					openAPI通过请求参数 format 来判断client请求的数据格式，故这里需要用到 @queryparam 来取得 format ，从而返回对应的
				格式。
			jersey guide：
					If a resource class is capable of producing more that one MIME media type then the resource method chosen will correspond to the most acceptable media type 
				as declared by the client. More specifically the Accept header of the HTTP request declared what is most acceptable. For example if the Accept header is:
					Accept: text/plain
				then the doGetAsPlainText method will be invoked. Alternatively if the Accept header is:
					Accept: text/plain;q=0.9, text/html
				which declares that the client can accept media types of "text/plain" and "text/html" but prefers the latter, then the doGetAsHtml method will be invoked.
				More than one media type may be declared in the same @Produces declaration, for example:
			方案1：从jersey guide看，可以根据http请求头的 accept定义值返回相应格式。
				但openapi规范提供的是根据get方式的 format参数来确定返回格式的
			方案2:：根据 format 字段，找到rest框架提供的动态自定义返回格式的设置 ？ 在哪里设置？
				在response里设置header，rest框架根据header定义的格式渲染结果。
				通过response根据需要的返回状态(status)取得responsebuilder对象(处理返回内容)，取得请求参数，通过builder设置返回的Cotent-Type类型(MediaType定义的类型)
				builder的entry方法处理需要返回的对象，build()，返回即可。

			【tip】误区，试图设置request的accept值来影响response的返回数据格式，要返回什么样的数据及其格式都可以通过response来设置。
				拥有者或者自身或其相关工具一般会提供操作其自身的值的入口。

				

2. jax-rs 注解(from jax-rs api)
	Consumer - Defines the media types that the methods of a resource class or MessageBodyReader can accept 定义资源可以接受处理的请求类型
	Produces - Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce
	MediaType - An abstraction for a media type. Instances are immutable(不变的). 


3. 对于第1条的REST框架也支持非REST请求uri的转发，这其中，只是转发的作用，不带有业务逻辑，是否可以用nginx的rewrite来实现？
	后续SLB也需要对openapi提供处理层，其中含业务逻辑，选择REST方式。

4. nginx rewrite 重写
	目标：将openapi的标准请求重写为符合REST接口的rest请求。
	nginx的rewrite规则(rewrite模块)：
	http://xx.host/action?id=xx&name=xx rewrite为 http://xx.host/action/xx/xx

	
	URL rewriting is a key element to Search Engine Optimization (SEO). ——　摘自：Nginx HTTP Server p141

		参考 http://chenxiaoyu.org/2011/10/30/nginx-modules.html
	正则表达式 规则 regex
	regular expression(Perl Compatible Regular Expression (PCRE) library):
		Metacharacter
			Description
		^
		Beginning
			The entity after this character must be found at the beginning.
			Example pattern: ^h
			Matching strings: hello, h, hh
			Non-matching strings: character, ssh
		$
		End
			The entity before this character must be found at the end.
			Example pattern: e$
			Matching strings: sample, e, file
			Non-matching strings: extra, shell
		.
		Any
			Matches any character.
			Example pattern: hell.
			Matching strings: hello, hellx, hell5, hell!
			Non-matching strings: hell, helo
		[ ]
		Set
			Matches any character within the specified set.
			Syntax: [a-z] for a range, [abcd] for a set, and [a-z0-9] for
			two ranges
			Example pattern: hell[a-y123]
			Matching strings: hello, hell1, hell2, hell3
			Non-matching strings: hellz, hell4, heloo
		[^ ]
		Negate set
			Matches any character that is not within the specified set.
			Example pattern: hell[^a-np-z0-9]
			Matching strings: hello, hell;
			Non-matching strings: hella, hell5
		|
		Alternation
			Matches the entity placed either before or after the |.
			Example pattern: hello|welcome
			Matching strings: hello, welcome, helloes, awelcome
			Non-matching strings: hell, ellow, owelcom
		( )
		Grouping
			Groups a set of entities, often to be used in conjunction with |.
			Example pattern: ^(hello|hi) there$
			Matching strings: hello there, hi there.
			Non-matching strings: hey there, ahoy there
		\
		Escape
			Allows you to escape special characters.
			Example pattern: Hello\.
			Matching strings: Hello., Hello. How are you?, Hi! Hello...
			Non-matching strings: Hello, Hello, how are you?

		Quantifiers
		So far, you are able to express simple patterns with a limited number of characters. Quantifiers allow you to extend the amount of accepted entities:
		Quantifier
			Description
		*
		0 or more times
			The entity preceding * must be found 0 or more times.
			Example pattern: he*llo
			Matching strings: hllo, hello, heeeello
			Non-matching strings: hallo, ello
		+
		1 or more times
			The entity preceding + must be found 1 or more times.
			Example pattern: he+llo
			Matching strings: hello, heeeello
			Non-matching strings: hllo, helo
		?
		0 or 1 time
			The entity preceding ? must be found 0 or 1 time.
			Example pattern: he?llo
			Matching strings: hello, hllo
			Non-matching strings: heello, heeeello
		{x}
		x times
			The entity preceding {x} must be found x times.
			Example pattern: he{3}llo
			Matching strings: heeello, oh heeello there!
			Non-matching strings: hello, heello, heeeello
		{x,}
		At least x times
			The entity preceding {x,} must be found at least x times.
			Example pattern: he{3}llo
			Matching strings: heeello, heeeeeeello
			Non-matching strings: hllo, hello, heello
		{x,y}
		x to y times
			The entity preceding {x,y} must be found between x and y times.
			Example pattern: he{2,4}llo
			Matching strings: heello, heeello, heeeello
			Non-matching strings: hello, heeeeello
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day6 Wednesday, March 21, 2012

1. openapi 
	OpenAPI - 消息推送/订阅(Message push/subscrible)  -Master 
	
	根据登记在消息服务器上的订阅节点信息，进行push

2. python nodejs 
	python yaml模块 - YAML是一种直观的能够被电脑识别的的数据序列化格式，容易被人类阅读，并且容易和脚本语言交互。YAML类似于XML，但是语法比XML简单得多，对于转化成数组或可以hash的数据时是很简单有效的。

3.  wget 从vmware中的centso访问本机的rest服务
	取得返回内容，cat查看
	sshl连接到centos命令行操作。
	
	环境：
		apache ,
		tomcat,
		nginx,
		mysql,
		eclipse,
		python,(test)
		nodejs,(test)
		linux container(test)

4. CIDR Classless Inter-Domain Routing 了解
	无类别域间路由选择
	ref:
		CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给
	服务提供商（ISP），	再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，
	从而减轻Internet路由器的负担。		

	CIDR	Classless Inter-Domain Routing	无类别域间路由选择	是互联网中一种新的址方式，与传统的 A 类、B 类和 C 类寻址模式相比，CIDR 在 IP 地址分配方面更为高效。
	IP号段是125.203.96.0 - 125.203.127.255， 怎样转换成CIDR格式呢？化cidr格式其实就是找相同:
	125.203.0110 0000.0000 0000
	125.203.0111 1111.1111 1111
	前十九位相同,所以可以写成125.203.96.0/19

5. ce里shell脚本熟悉
	"#!/bin/sh" - 对shell的声明，说明你所用的是那种类型的shell及其路径所在。
	自定义shell function封装常用功能，提高shell编写效率。
		eg: 


6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day7 Thursday, March 22, 2012

1. ace mast agent(python shell) 
	master 职责


2.  ace 计量单位讨论会议，
	字段需要取出推送到消息系统，供后续计量，计费
	主要关于 计量字段需求，及可行性确认
	详见记录
	tip: 由于涉及多个系统的交互，如何处理规则，处理变化的问题，如果适应变化减少依赖耦合。

3. cloudengine 熟悉
	master ,agent 部分
	master调用agent
	agent根据不同的应用类型(目前:php，nodejs，jsp)调用相应的build脚本(配置环境运行环境，部署应用，启动应用，启动agent)

	nodejs http://nodejs.org/
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day8 Friday, March 23, 2012

1. cloudengine 
	trunk
		agent - agent模块(python)
			fastcgi
			memcached
			monitor
			nginx
			nodejs
			test
			yaml
		carrier - Erlang (rebar ...)
		ftpserver - ftp服务(java)
		master - master(java)
		memcahched_pach - memchche部署
		nginx_pach - nginx部署
		nodejs -  nodejs部署(build_agent -> install_agent -> install_nodejs -> upgrade_nodejs)
		php - php部署

2. ACE计量 
	计量单位，字段说明
	oss接口
	ms接口

	目标：将ACE各计量单位取到并以ms要求的格式推送给ms(Metering Service)计量系统系统 ，有一个python的
	的实现可以参考:
		python 
			程序基本结构
			变量，运算 etc
			模块
				MySQLdb
					eg 通过此模块与mysql数据库交互：(下载这个库有linux和win版本)
						conn=MySQLdb.connect(host="localhost",user="root",passwd="sa",db="mytable")
	
			执行
			应用
	* 

	参考 houyi-console/static (java)实现，上述任务 【Task】
	= = URL请求的要求(格式，构造)等可以参考这个实现 = =
		定义数据格式
		定义任务
		spring配置调用执行

		步骤：(公用动作比如推送等已有实现，调用其逻辑处理即可) 细化
			>> 取
				* MS取SLB流量(appid对应的流量，appid指每个具体的应用)	单位 byte
					- 从ACE DB中取得appid对应的slb_id，及应用的id与SLB的id对应关系 1对1
						- 从DB得到app_id对应的slb_id(cloudengine库)

							-- 从DB得到app_id对应的slb_id
							select 
								app.id app_id,
								slb.id slb_id
							from app app,slb_alloc_record slb
							where app.id = slb.id
							
					- 请求Meteriing Service，根据slb_id取数据
						MS接口文档(比如如何查询SLB数据？)
						

					-  MS返回vip对应的流量数据的数据格式
						Flow_detail的格式如下：
						[tcp(VIP:80|2|3|)(VIP:8080|2|3|)][http(www.a.com:80|2|3|)(www.b.com:90|2|3|)]
					
					- 

				* MS取OSS
					- 从app表(cloudengine)取得kv_bucket
						select 
							id app_id,
							kv_bucket
						from app
					- URL格式
						columns: storage;
						where: openid=ace;pid=oss;bid=26842;inst_id=$bucketname;begin_time=13123121400;end_time =132123241500;inst_id,migrate-win2003-vifs
						http://10.1.157.163:8080/aliyun/QS/OSS/RAW
						bid - 用户ID，app所属的用户
						$bucketname对应kv_bucket
					- 
						
				* DB取cpu时间等
					‘cloudengine`.`fastcgi_app_running_info` cpu_acc_usage App的cpu持续使用时间，单位：秒

			>> 处理

			>> 推送 写往MS
				推送数据格式
					* 在 DataFormat里定义枚举 
					*  pojo (实现接口)
					* 请求
						http request header:
						PUT /aliyun.com/QS/SLB/RAW HTTP/1.1（待定，需姜一提供）
						HOST: ms.aliyun.com
						CONTENT‐LENGTH: 12345
						META: uid,string;inst_id,string; time, integer; usetime,integer; total_in,integer;total_out,integer;tcp_flow_in,integer;tcp_flow_out,integer;http_flow_in,integer;http_flow_out,integer;vip_type,string;rs,integer;flow_detail,string;region_id,string;end_time,integer;
						“META为用户发送的数据的格式信息，这部分必须添加在http的header部分，为计量服务(MS)特有字段”
						http://metering.aliyun-inc.com:8080/aliyun/QS/OSS/RAW  —— 线上系统的地址
						http://10.1.157.163:8080/aliyun/QS/SLB/RAW —— 测试时用测试系统地址
					* 整理推送的字段对照 doc ？
						Cpu(ms)、流量(byte)、存储空间(byte)、请求次数、memory-cache(byte)

						属性名			类型			单位			描述
						uid				string							包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务
						time				integer							开始时间(记录当前记录的时刻，为一点态时间，如果用户的计量数据采集并非实时，则time表示抽样开始时间即begin_time，采用可显示的unix时间表示法)
						end_time			integer							结束时间(表示抽样结束时间，同样采用可显示的unix时间表示法)
						inst_id			string							应用id即appid
						cpu				integer			ms				cpu使用时间
						flow				integer			byte				总流量(http流量)
						flow_in			integer			byte				流入流量
						flow_out			integer			byte				流出流量
						app_size			integer			byte				存储空间(oss)
						req_count			integer			个				请求次数(包括pv内的多个异步请求)
						version			integer							版本号，目前为1



						






		uid：包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day9 Monday, March 26, 2012

1. 计量的接口说明 最新的 ？
	

2. 把ace计量初步需求写入文档，
	类似于slb接口文档等
	
	目的：设计ace计量项，并取到后处理然后提交到ms系统
	计量项列表：
	实现：
		计量项获取：
		处理
		推送
	xuanyuan cloudengine数据库表间关系由程序控制，注释说明关系。

3. job的具体实现，失败补偿逻辑，参看console中的static模块
	？


4. 通过powerdesigner的reverse engine ，从database的sql文件将ddl转换为er图，了解db表关系

5. velocity 方便对象格式化到文件
	...
	velocityEngine.init();//spring配置好resourceLoaderPath
	template = velocityEngine.getTemplate(templateFile);
	VelocityContext context = new VelocityContext();
	context.put("datasMap", map);
	writer = new FileWriter(outfile);
	template.merge(context, writer);
	...
6. spring + quartz 执行定时任务
	<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
		<property name="targetObject" ref="task" />
		<property name="targetMethod" value="execute" />
		<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
	</bean>	
	<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
		<property name="jobDetail" ref="collectDataDetail" />
		<property name="cronExpression" value="0 0 */1 * * ?" />
	</bean>  
	<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="triggers">
			<list>
				<ref bean="collectDataTrigger" />
			</list>
		</property>
	</bean>
7. 操作记录及时保存为数据库的日志，后续补偿机制根据数据库补偿并更新 ？
	细节

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day10 Tuesday, March 27, 2012

1. 根据上面ace计量文档，编码
	对于时间如何处理，补偿机制

2. ACE计量先不提供需要访问MS的SLB和OSS数据，暂先考虑DB数据 【task】
	先实现ace监控数据的抽取推送。
		一些dao需要自己定义以取监控数据
		时间校准，以抽取逻辑定义的时间为准，根据定义的时间去取监控数据并汇总，处理，推送
	处理的整体流程：
		关键是发生错误的补偿处理逻辑：
		tasklog表记录task日志。		

3. 表说明
	region - 代表一个集群
测试环境 mysql
mysql -h10.249.153.1 -ucloudengine -pcloudengine2011 -Dcloudengine



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day11 Wednesday, March 28, 2012

1. 设计好补偿处理逻辑
	结合day10第二条的表记录job及其result实现补偿处理。

2. 任务处理已有设计，在已有的任务设计下实现功能
	* job代表每一次执行的任务
		job推送前都记录到数据库，job下的内容保存为临时文件。
	* spring+squza定时任务
	* 日期处理
		DateUtils.java —— 将date日期格式化为需要的格式；date到秒；string+patten到date  (SimpleDateFormat实现)
	* pojo
		TaskLog 任务日志pojo
			private Long id;
			private int status; // 1:success,0:failed
			private String filename;
			private Long taskTime;
			private int jobType; //[0:vm job,1:device job; default 0]
			private Date beginTime;
			private Date endTime;
			OR文件：/houyi-console-dao/src/main/resources/ibatis/TaskLog.xm
				houyi库 statistics_log
	* service
		JobService ：job相关操作
			public boolean addOrModify(TaskLog job);
			public boolean checkStatus(TaskLog job);
			public List<TaskLog> listFailedJobs(long startTime);
			public List<TaskLog> listJobs(long startTime,long endTime);
			public TaskLog getLastJob();
	* dao
		TaskLogDao ：任务日志DAO操作
			void insertTaskLog(TaskLog log) ;
			void updateTaskLog(TaskLog log) ;
			TaskLog getTaskLog(TaskLog log) ;
			TaskLog getLastTaskLog();
			List<TaskLog> getFailedTaskLogs(Long bTime);
			List<TaskLog> getTaskLogs(Long bTaskTime,Long eTaskTime);

	* task 由于时间等内容不好共用，可再设计一个task，并通过spring配置执行。
		或对task进行业务无关的再抽象，只留下共用的逻辑，其他都内聚到job自身中。-tip-

	处理流程：(包括 Task ，JobProducer，需要的service,dao,pojo) - 由程序入口分析
		--> task - execute()定时执行这个方法 - 调用dojob()  —— dojob是单线程的，如果job多或者某个前面的job占用时间长会影响后面的job的执行开始时间 ？ tip 如果是独立的task则不用考虑影响问题
			遍历执行注入的jobproducer实现 (获取方式：beans = (Map<String, JobProducer>) applicationContext.getBeansOfType(JobProducer.class))
		--> jobproducer(具体job逻辑在jobproducer的实现类里编写)\
		--> service
		--> dao
		逻辑就在task，jobproducer,abstract jobproducer中，定义自己的逻辑即可。
			原有任务以task作为主流程控制，jobproducer抽象类及其实现定义了所有逻辑。抽象类提供公用逻辑或抽象方法统一逻辑。-tip-
				取数据 - 存入数据库/文件(通过velocity映射对象集合(以appid为标识)存为文本) - push - 更新状态
3. 模拟实现
	根据原有static模块任务设计
		* 定义数据结构 pojo ,velocity模板(用于对象格式化持久化)
			是否需要将此pojo作为对象查询？即某个查询直接返回此pojo，需要ibatis映射配置，这样只要查询一次关联几张表得到数据；或者分别查询在程序中处理。
			暂定位分别查询。分别查询，减少关联
		* 实现一个job producer
		* 定时task类，可能需要再实现一个并在spring里配置(原task再抽象以下，可配置)，
		参考配置：
			<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
				<property name="targetObject" ref="task" />
				<property name="targetMethod" value="execute" />
				<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
			</bean>	
			<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
				<property name="jobDetail" ref="collectDataDetail" />
				<property name="cronExpression" value="0 0 */1 * * ?" />
			</bean>  
			<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
				<property name="triggers">
					<list> <!-- 此处配置定时要执行的task列表 -->
						<ref bean="collectDataTrigger" /> 
					</list>
				</property>
			</bean>
		* 判断tasklog是否已执行过，通过jobtype类型和jobtime-job开始时间，如果是依据查询的最新执行时间作为job开始时间
			if (jobService.checkStatus(job))
			{
				logger.info("exist job:" + jobTime);
				return true;
			}
		* abstract producer的一些公用成员变量是否可以提供get方法供子类调用，子类不用重复定义 ？
		* task的recoverJob逻辑处理丢失的任务（比如关机等造成的任务丢失），目前任务是能处理丢失10次的任务，是否可以根据做新一次的任务的开始时间
		结合当前时间计算共丢失多少次任务，然后执行所有丢失的任务？
			Task
			------
			...
				/** Get the last record of success in the log table **/
				TaskLog log = jobService.getLastJob();

				/** compensate for missing the task **/
				if (log != null)
				{
					int i = 1;
					while (log.getTaskTime() + i * HOUR_SEC < jobTime)
					{
						/** Compensate for 10 times **/
						if (i == 10)
						{
							break;
						}

						TaskLog job = new TaskLog();
						job.setBeginTime(new Date());
						job.setTaskTime(log.getTaskTime() + i * HOUR_SEC);
						job.setStatus(0);
						jobService.addOrModify(job);
						i++;
					}
				}
			...
			------
		* 一些任务参数是否可以配置到配置文件中，类似abstract job producer的parentpath路径配置 比如：采集间隔，一些补偿机制参数 ？
		* statistics_log表？
		* app的类别区分是哪个字段(php,nodejs,jsp) ?
			templetid?
		* 用到的一些接口需要修改 ，通过的方式过少，是否可修改，其他地方是否有调用？
			比如提供id数组查询。
		* 应用运行时状态表
			fastcgi_app_running_info
			nginx_app_running_info
			memcache_app_running_info
			nodejs_app_running_info
		* console与cloudengine不是同一项目，maven管理依赖，引入cloudengine的包？
			自己重新写maping文件pojo及dao接口和实现。不依赖不相关系统。
			在dao，model等模块加入对应代码。
		* ibatis查询，可以根据外键设置关联查询，减少查询次数
		* 由于是另外一个数据库，需要再配置数据源
		* 在houyi-console-dao里写dao层用到pojo是static中的，是否把pojo，dao，service都按照模块放置，负责dao就要依赖到static中的pojo ？
			static的model不直接提供dao，而是从其他数据组合而成。比如从appdao的查询记录里组合而成。
		* 统计一个时间段的缓存使用量，如何取？暂定为求和
		* 参考master的constant 包定义的常量，帮助了解一些业务知识
			AppType 定义了应用的类型。php.nodejs...
			app 的 language 属性定义apptype类型。
		* 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day12 Thursday, March 29, 2012

1. go on 
	新建maven project开发，独立功能
	参考console的static模块，做成一个任务模块(业务，逻辑分离，易配置)
	wiki地址：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8259199
	svn ：http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk
	web项目 or java进程(jar包main函数启动) or 作为一个组件部署（作为组件部署，有哪些要求，比如 cloudengine 在 xuanyuan 上运行）？
	
	* 导入需要的包
	* 拷贝公用代码 工具类 等
	* dao设计依据master，提供抽象dao实现namespace的spring配置
	* 参考master用jtester测试
		加入jtester依赖包 地址http://java-tester.googlecode.com
		jtester 配置文件中 unitils.modules=database,dbunit,dbfit,inject,spring,tracer ，这里列出了需要的模块
		编译测试，提示编译版本问题时，可以切换下jdk版本，并clean下project。
		测试用例数据，参考master的：eg
			@DbFit(when = {"AgentCheckResultDaoTest.testReadByAgentId.when.wiki"})
		集成spring测试时，可能由于spring配置等问题导致maven test失败；可通过基本的main函数先保证spring的注入式正确的 -tip-
		maven test + main method test
		maven clean + eclipse project clean solve cmplile problems 
	
		如何自动生成测试用例 ？ ，对每个方法都手工去编写基础测试代码过于繁琐
		
		wiki方式数据库测试时，jtester测试时可以根据wiki配置临时清除表数据，做测试，结束后回滚。

	*  wiki project描述

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day13 Friday, March 30, 2012

1. ameasure-data project
	job基础代码与业务代码分离，实现可配置。
	* 配置maven插件,jar (以及插件的参数配置，jar执行main函数配置 etc - 参考maven jar插件说明：http://maven.apache.org/shared/maven-archiver/index.html)
	* 测试报 Could not find Velocity resource: class path resource [VM_global_library.vm
	* 配置maven插件 maven-assembly-plugin ,packaged with-dependencies 打包并加上依赖 ,配置assembly参数，比如jar分别打包，
		打包时可能jar包文件重复，test目录下的测试文件也打包进来，配置一些参数即可，例如：
			-----
			...
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.Test</mainClass>
							</manifest>
						</archive>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				(2)
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<descriptors>
							<descriptor>src/main/assembly/src.xml</descriptor>
						</descriptors>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.StartTask</mainClass>
							</manifest>
						</archive>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0" 
				  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				  xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd">
				  <!-- TODO: a jarjar format would be better -->
				  <id>with-dependencies</id>
				  <formats>
				    <format>zip</format>
				  </formats>
				  <includeBaseDirectory>false</includeBaseDirectory>
				  
				  <dependencySets>
				    <dependencySet>
				      <outputDirectory>/</outputDirectory>
				      <useProjectArtifact>true</useProjectArtifact>
				      <unpack>false</unpack>
				      <scope>runtime</scope>
				    </dependencySet>
				  </dependencySets>
				</assembly>
			...
			-----
			打成上面这种jar包集合方式，在同一文件夹下运行即可，省去classpath配置的麻烦。

		maven clean after close resource opened -tip-
	* 加上shell执行脚本，调用此jar并执行
	* 原有推送逻辑，一次job比如推50条，一条失败就退出，暂处理为本次任务再尝试推送(设定尝试次数)
	*  ibatis 在命令行下运行找不到mapping文件，在eclipse下测试ok 原因？ 待  —— ibatis没问题，spring也ok，字体用的不好(大小写居然相似，
		最后还是仔细看了错误输出，错误点才发现大小写)大小写错误，配置文件配置和实际文件大小写不一致！！！-tip-
		如何避免：提示文件找不到，名称不匹配等等，首要看是否书写错误，能拷贝一定拷贝，不要手工输入，特变是在配置文件场合。 -tip-




2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day14 Saturday, March 31, 2012

1. measure-data
	* 逻辑细化 command
	* quartz ? cluster
		利用quartz实现调度执行，将操作记入日志，失败处理另外实现并
	* 任务测试
		测试表 tasklog `statistics_log`
			CREATE TABLE  `cloudengine`.`statistics_log` (
			  `id` int unsigned NOT NULL AUTO_INCREMENT  COMMENT '@desc 主键ID' ,
			  `status` tinyint NOT NULL COMMENT '@desc 1', 
			  `filename` varchar(128)  COMMENT '@desc filename',
			  `task_time` datetime NOT NULL  COMMENT '@desc tasktime',
			  `begin_time` datetime NOT NULL  COMMENT '@desc begin_time',
			  `end_time` datetime NOT NULL  COMMENT '@desc end_time',
			  `job_type` tinyint NOT NULL COMMENT '@desc 1', 
			  PRIMARY KEY (`id`)
			) ENGINE=InnoDB DEFAULT CHARSET=utf8;
			ALTER TABLE `statistics_log` MODIFY COLUMN `task_time` bigint(20) NOT NULL GO
			测试数据：
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(1,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',3);
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(2,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',1);
	* 提供开启程序，退出程序脚本 ，通过命令操作即可 。可参考tomcatd的脚本
		手工停止任务执行。（或强制停止并处理强制停止任务的恢复逻辑），假如某次job有200条记录在推送了150条时，程序关闭了
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day15 Thursday, April 05, 2012

1. 逻辑实现
计量会议
linux环境：
	10.250.8.214 chengs 123456
shell 下java程序控制：
	  -----
	  ...
		#! /bin/sh

		#启动方法
		start(){

			java -Xms128m -Xmx2048m -jar test1.jar 5 > log.log &
			java -Xms128m -Xmx2048m -jar test2.jar 5 > log.log &
			tail -f result.log
		}
		#停止方法
		stop(){
			ps -ef|grep test|awk '{print $2}'|while read pid
			do
			   kill -9 $pid
			done
		}

		case "$1" in
		start)
		  start
		  ;;
		stop)
		  stop
		  ;;
		restart)
		  stop
		  start
		  ;;
		*)
		  printf 'Usage: %s {start|stop|restart}\n' "$prog"
		  exit 1
		  ;;
		esac

		...
		CLASS_PATH=dayemail.jar
		CLASS_PATH=$CLASS_PATH:lib/activation.jar
		CLASS_PATH=$CLASS_PATH:lib/classes12.jar
		CLASS_PATH=$CLASS_PATH:lib/c3p0-0.9.1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/commons-email-1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/dom4j-1.6.jar
		CLASS_PATH=$CLASS_PATH:lib/jaxen-1.1.1.jar
		CLASS_PATH=$CLASS_PATH:lib/jxl.jar
		CLASS_PATH=$CLASS_PATH:lib/log4j-1.2.16.jar
		CLASS_PATH=$CLASS_PATH:lib/mail.jar

		SERVER=/qzpt/mydayemail
		cd $SERVER   
		  
		case "$1" in   
		  
		  start)   
		    nohup java -Dfile.encoding=UTF8 -Xms64M -Xmx256M -cp $CLASS_PATH com.trendsnet.myemail.EmailShell > $SERVER/server.log 2>&1 &   
		    echo $! > $SERVER/server.pid   
		    ;;   
		  
		  stop)   
		    kill `cat $SERVER/server.pid`   
		    rm -rf $SERVER/server.pid   
		    ;;   
		  
		  restart)   
		    $0 stop   
		    sleep 1   
		    $0 start   
		    ;;   
		  
		  *)   
		    echo "Usage: myshell.sh {start|stop|restart}"  
		    ;;   
		  
		esac   
		  
		exit 0  
	...
	-----
	来自：http://www.iteye.com/topic/1122093
	* 在程序中中增加一个hook,jvm退出时会执行hook中的代码 
	Runtime.getRuntime().addShutdownHook(Thread); 
	kill -15 （SIGTERM）能够执行hook中代码 
	kill -9   (SIGKILL) 不能够执行hook中代码 
	在程序关闭前做处理工作，然后关闭。
	* 启动的时候将shell脚本的PID记录到文件里面，然后关闭的时候就可以直接读文件获取PID，避免用ps查询了，有可能不准确的 
	echo $! > $SERVER/server.pid

2. mvn test package etc 配置好资源文件 如 -tip-
	<resource>
	<directory>src/main/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>

	<resource>
	<directory>src/test/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.wiki</include>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>
	上面，加载包括main和test下的所有配置文件(部分子目录下的文件)。
mvn test生成的报告会说明失败原因，依据错误解决问题。
maven test failure —— 错误报告会告知哪里导致错误，一步步检查 cause 即可。另，test等都是依据pom的配置执行的，pom的配置要细心。
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day16 Friday, April 06, 2012

1. test 抽象类(实现方法，测视类中静态内部类继承) ，私有方法（反射）
	通过反射测试
	

2. Cron expressions  ,quartz
	-----
	...
		Method method = aceCalcJob.getClass().getDeclaredMethod("buildAceCalcStruct", Date.class,Date.class);
			method.setAccessible(true);
			Object result = method.invoke(aceCalcJob,startDate,endDate );
			@SuppressWarnings("unchecked")
			Map<String,IMetaData> map = (Map<String,IMetaData>)result;
	...
	-----
3. acecalc
	* 任务第一次执行时，采集时间点的确定，根据app的创建日期为起点开始采集？
		自动查询数据库得出 or 配置文件配置初始抽取时间点 or 两者都支持
	* 

4. MS 改为 OMS 参看其文档
	开放计量服务(OMS)的数据模型包括以下几个概念:
		 Object
		 Domain
		 Accessid
		 Accesskey
	上面观念划分，体现了OMS的REST服务方式。
	
	推送数据格式：
		* Date 目前Date只支持GMT格式，具体的GMT格式可参考如下示例:
			Wed, 30 Aug 1991 09:13:05 GMT
			更多关于GMT时间格式的信息，请参考RFC|1123
		* 
		
5. 
cpu

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day17 Monday, April 09, 2012

1. 新OMS提交修改

2. 访问次数 pv 所在表
	nginx_app_abstract_running_info 
	nginx_app_running_info
3. 推送测试环境 ？ OMS测试环境提供推送测试
	测试推送逻辑
demo http://svn.simba.taobao.com/svn/Apsara/openapi/trunk/java/src/com/aliyun/openservices/oms/

	uri：http://10.230.201.85:8080/ACE_RAW
	accessid: rot1d0cc9bxp97vpcwjyo98o
	accesskey: 0GC/ahEtRiNReKA1NhuNimJ2b3A

	* 推送格式改为xml
	* 请求头变化
	
	加好各种header后，进行签名，带上content 发送请求。

	
	临时文件名，取名时需要考虑2个或2个以上操作发生在同一秒内的情况。

	403 签名错误 ，
	400 非法参数 InvalidParameterValue <Message>unsuported content-type</Message>
	* put内容的字段变化了 原来的uid，改为3个分开：
		eg:
			#foreach ($data.value in $datasMap.entrySet())
			   <Object><uid>default</uid><pid>ace</pid><bid>aliyun</bid><inst_id>$data.value.appId</inst_id><time>$data.value.startTime</time><cpu_acc_usage>$data.value.cpuAccUsage</cpu_acc_usage><memcache_size>$data.value.memcacheSize</memcache_size><req_count>$data.value.reqCount</req_count><lb_id>$!data.value.lbId</lb_id><version>$data.value.version</version><end_time>$data.value.endTime</end_time></Object>
			#end
	 * OMS client的get方法，查询测试用。
		查询OMS
	main test 输出：
		{response=<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authenticate user</Message>
		<RequestID>41e3d2b9-31d0-2c4f-493b-e4635bff819b</RequestID>
		</Error>
		, status=403}

4. mem_size 暂取为某个计量时间段内的平均值 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day18 Tuesday, April 10, 2012

1. 
	* oms get测试 - pass
	* 一次put多个object测试
	* 启动，关闭脚本修改 
	* 计量值多数据测试，统计的sql是否存在问题，大数据计算精度问题
	* 某些job中app并没有产生任何数据是否应该抛弃，不推送到OMS上，导致的问题是，在某个时间点或者区间查询时导致没有数据。？
	* quartz 挂起api ，正常停止任务，不建议job执行时强制关闭进程（程序逻辑需要处理这种例外）
	* 运行jar的配置文件独立到jar外面便于配置 
		通过spring配置加载外部配置文件。
			spring配置文件也配置在外部(不在classpath上)，spring提供了org.springframework.context.support.ClassPathXmlApplicationContext 以加载classpath之外的配置文件。外部配置文件 -tip-
		log4j提供的配置文件设置类 org.apache.log4j.xml.DOMConfigurator ，可以设置定时检查配置文件修改并重新加载配置。在main函数里初始化如下：
			String log4jfile = System.getProperty("user.dir") +File.separator +"config"+ File.separator +"log4j.xml";
			DOMConfigurator.configure(log4jfile);
		配置文件改为：
			spring和properties文件都移到jar外面，ibatis配置文件还是在jar包中。
			问题是，maven如何打包时，把config文件夹拷贝一份和包在同目录下？ assembly ？
			改为：
				配置文件只把关键的 log4j,job,jdbc 等放在jar外面加载，其他进jar包。
			shell 脚本需要在bin目录下运行，否则有配置文件找不到等错误 -tip- ，如何优化shell脚本
	* 拿到真实环境的相关数据库表机构，是否与本机一致？比如statistics_log表
	

2.  oms get测试

	已push成功的待查询测试数据：
		<?xml version="1.0" encoding="UTF-8"?>
		<Objects>   
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id></lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>
	get查询请求参数：
		"GET /ACE_RAW HTTP/1.1[\r][\n]"
		"Authorization: OMS rot1d0cc9bxp97vpcwjyo98o:yqb7kFIP3prg8z0x4gw5T4lnXEw=[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:30 GMT[\r][\n]"
		"x-oms-filter: time=1334019600[\r][\n]"
		"x-oms-select: uid;pid;bid;inst_id;time;cpu_acc_usage;memcache_size;req_count;lb_id;version;end_time[\r][\n]"
		"User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]"
		"Host: 10.230.201.85:8080[\r][\n]"
		"[\r][\n]"

	返回成功信息：
		"HTTP/1.1 200 OK[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:31 GMT[\r][\n]"
		"Server: Apache/2.2.17 (Unix)[\r][\n]"
		"Content-Length: 322[\r][\n]"
		"Content-Type: text/xml;charset=UTF-8[\r][\n]"
		"[\r][\n]"
		"<?xml version="1.0" encoding="UTF-8" ?>
		<Objects>
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id>0</lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>"

	注：上面put的数据与get返回的数据 lb_id由空变为了0，这是OMS对某些字段如果空会置默认值的逻辑。

	uid+time
	uid+pid+bid+inst_id+time
	目前就这两个你有权限查
	
	domain没有操作权限：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authorize user</Message>
		<RequestID>7a44a74b-211a-fda1-68b6-7f5907108b41</RequestID>
		</Error>	
	查询条件错误：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>InvalidQueryExpressison</Code>
		<Message>query condition not match any dimension</Message>
		<RequestID>66a00276-6ad9-d94f-1bf7-db7f0c4830ba</RequestID>
		</Error>	
3. 部署  程序运行目录定义说明（配置简单操作为好）
		bin - 放运行脚本
		build - 放编译脚本(svn下载，maven构建，部署到设定的目录(到bin,lib,config))
		config - 存放配置文件(log4j,job等的配置文件)
		lib - jar文件
		logs - 日志

		操作从调用build下的脚本开始执行。
		build下放置build好的文件，如何deploy脚本将build好的文件分别部署到相应的目录中去。
		bin下的启动脚本需要在bin当前目录下运行，否则报配置文件找不到？

4. sh -x xx.sh 查看
	脚本可能因为隐藏字符导致错误，执行时 -x 查看即可。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day19 Wednesday, April 11, 2012

1. 
	执行过程中断处理
	那些数据时不用推送的，比如某个时间段都没有产生数据（这压缩数据交给oms？）


2. shell 执行路径问题  shell 必须在当前路径执行，否则路径错误 ，解决？【 spring加载资源文件路径 ，类路径，外部路径 配置路径 路径设置 改变工作目录 当前路径】
	关键：cd 命令，设置当前路径 
	#!/root/bash
	echo `pwd`
	current_dir=$(cd "$(dirname "${0}")";pwd)
	echo $current_dir
	
	pwd会因为执行路径不同而变化，current_dir可以取到shell所在路径。 

	但对于没有动态调用 user.dir 找到classpath之外资源路径的情况，可以在非shell所在目录执行时，在shell里cd到所在base目录，这样
	后续java加载取值时，取得就是cd后的路径。-tip-

	shell执行时，指定java系统参数 user.dir 即可 ，即指定java执行时用户当前目录为程序所在主目录（base目录，其子目录有lib，bin等等）。-tip-
	通过java命令的 -D 参数指定 user.dir ,结合程序逻辑，指定资源文件等的路径path。
		String log4jFile = System.getProperty("user.dir") + File.separator + "config"+ File.separator +"log4j.xml";
		-----
		...
			#!/bin/bash
			BIN_DIR=$(cd "$(dirname "${0}")";pwd)
			BASE_DIR=`dirname $BIN_DIR`
			LIB_DIR=$BASE_DIR/lib
			LOG_DIR=$BASE_DIR/logs
			#set for java to load resource
			USER_DIR=$BASE_DIR
			JAR_NAME=houyi-measuredata-all-0.0.1.jar
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    start)
				cd $BASE_DIR # 转到程序需要的工作路径，比如需要此路径来加载资源文件，spring里从外部文件加载的资源文件相对此$BASE_DIR取路径即可。
				java -Xms64M -Xmx256M -Duser.dir=$USER_DIR -jar $LIB_DIR/$JAR_NAME > $BIN_DIR/server.log 2>&1 &
				echo $! > $BIN_DIR/server.pid
				;;
			    stop)
				kill `cat $BIN_DIR/server.pid`
				rm -rf $BIN_DIR/server.pid
				;;
			    *)
				echo  "invalid option ,usage: $0 [insert|remove]";
				;;
			esac

			exit 0
		...
		-----
		通过 -Duser.dir=xxx 设置user.dir参数好

		执行路径，相对路径 ，程序默认读当前路径，执行路径时，在shell可以 cd 到所需要的当前路径(工作路径)，再执行即可。
		
3. svn 提交 eclipse ，还是用svn客户端 
		eg: TortoiseSVN   
			check for modification - revert  
		可以用客户端管理版本，eclipse只负责项目开发。 不同svn客户端交叉用可能出错误。
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk 
		username
		password
	* svn
		- 各种svn工具操作命令不相同，但svn基本功能都是提供的，只是不熟悉的话要去找找
			比如：TortoiseSVN 查看某个文件的提交记录 ，是调用 show log 菜单 ；eclipse的svn插件用的可能就是 xx history ；熟练度的关系

4. 从svn下载到maven编译到部署运行 ，整个的脚本
	svn取到项目源码
	mvn 构建
		不同机子上构建时依赖可能出现的问题：
			Error transferring file: Connection refused
			Specified destination directory cannot be created: /usr/ali/maven/repository/org/slf4j/slf4j-api/1.5.6 - maven库没有添加jar权限，改为已有的版本绕过
				eg: ls /usr/ali/maven/repository/org/slf4j/slf4j-api


5. 部署说明文档 (测试，部署人员依据此文档操作)
	* 从10.250.8.214机子上拷贝目录measure(/home/admin/measure)到目标机/home/admin目录下，进入该目录 (编译机和运行机都采用上面的目录结构)
	* 执行bulid 目录中的build.sh构建
	* 然后执行build目录下的deploy.sh部署
	* 再执行bin目录下的execute.sh启动和关闭程序，用法如下：
		execute.sh start - 启动程序
		execute.sh stop - 关闭程序
	目录结构说明：
		measure
			- bin 包含执行程序的脚本 execute.sh ，shell执行日志文件server.log,程序的的pid备份server.pid
			- build 包含构建和部署脚本build.sh,deploy.sh
			- config 包含程序配置文件log4j，job，jdbc的属性配置
			- logs 程序执行日志
			- src 存放源码
				- target 打包后的文件(zip)

6. maven换其他环境编译时，依赖找不到解决，看错误日志找到依赖找不到的原因，一般即可解决

7.  shell 脚本  ,字符不认识问题 ，在windows下的文本，通过ssh工具拷贝到linux中后，不能正常执行命令。可能是字符编码或者异常特殊符号(;/r)等问题，可在linux下
新建shell解决，拷贝的一般都有问题。

或者，是因为使用的ssh客户端没设置好，传输时编码问题？从svn下载下来的shell(原在windows下创建)都不能正常执行。 -tip-

原因：unix，dos 字符间需要转换 
	xxx@xxx$ uni
		unicode_start  unicode_stop   uniq           unix2dos       unix_chkpwd
	dos2unix

8. 
unix2dos dos2unix

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 
day20 Thursday, April 12, 2012

1.  
	sql独立，将各自的查询sql独立查询，程序里再组合，编写涉及到表的pojo和映射文件
	dao db wiki 测试
		'file://D:\workspace\measure/target/dbfit/com\aliyun\houyi\measuredata\dao\impl\MemacheAppRunningInfoDaoImplTest.testReadAceCalInfocByTimePeriod.when.html'

2. 
	ls -R 
	shell判断文件是否存在，再做后续操作
		if [ -f urfile ]  then
			./a.sh   
		fi

3. sql独立
	对于数据量可预知且不大的情况下，可以进行关联查询，减少访问数据库次数。对于数据量非常大的表最好单独查询，计量减少关联查询。 -tip-

4. 单元测试，补上db部分的测试，验证sql逻辑等 -tip-
	mvn test -Dtest=AppDaoImplTest 只测试某个用例
5. 
duplicate entry key 
	确认那些字段是唯一的，一条若有多个唯一的，保证都唯一，否则数据库报错可能误报，比如有key3和key8都是unique，此时即使key3是唯一的，但key8
	是重复的，执行后可能会误报key3重复，实际上是key8重复。-tip-

6. vip 表字段修改，测试时注意
	 alter table vip add lb_id varchar(20) default NULL;
	 alter table vip MODIFY COLUMN lb_id varchar(20) default NULL;

7. mysql ,ibatis
	mysql的各种数字统计函数对应的类型不同
		需要定义好。在sql语句里转换好类型。
8. maven test 时报错误，找不到某个类，是因为测试环境和开发环境冲突了，比如在开发环境用了测试的jar，会导致错误，部署时，除去测试的依赖。 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day21 Friday, April 13, 2012

1. 
	*  job 的丢失处理时间和临时文件保留时间改为配
	* ace计量中agent的角色
		计量数据由agent上报，同app同类型数据可能有多个agent上报，统计时，需要注意这点。比如求平均时需要先求时间段内每个agent各自
		数据的平均值，再对平均值求和。
	* JCE OpenAPI
		svn改了新分支，下载新的cloudengine分支
			http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v5/master

2. job 的丢失处理时间
	和临时文件保留时间改为配
	丢失文件查找费时间

3. jce openapi  
	目标：
		标准openapi请求转接到rest服务处理。
	具体：
		根据一个请求路径，比如 /open，将所有对openapi的请求转到openapi调用service来处理，在这个service里，得到openapi的请求参数
	，根据参数调用master提供的service进行处理并返回。其中对参数的验证等可参考rest路径请求进来的处理过程。
			
	RestOpenService.java  供 openapi 调用的service
	目前文档里稳定的接口是 3.1->3.9

4. sql ，app_id,agent_id 一个app_id对应每个agent_id平均值的和,一次分组求平均，一次分组求和，多次分组统计即可 -tip-
	-------
	...
		select
		    app_id,
		    sum(tempmem.memcache_size) as memcache_size
		from (
		    SELECT  
			memcache_agent_id,
			app_id,
			ifnull(avg(mem_bytes),0) as memcache_size 
		    FROM memcache_app_running_info
		    group by memcache_agent_id
		    ) tempmem
		group by tempmem.app_id
	...
	-------
	前提 memcache_agent_id 与 app_id 为一对一或多对一的关系。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day22 Monday, April 16, 2012

1. 
	* 根据mast提供的service和jce openapi ,设计一个供openapi调用，处理普通get,put方式的rest服务。
		目标：此服务通过master提供的接口，实现jce openapi提供的接口服务(比如创建app,删除app等等)
			请求的验证，master在提供的service调用里已有处理，故此服务只根据请求的action定位到service，传递参数。
		
	* wiki 添加ace计量sql语句供review
		- app_id查询时应该不带状态，如果只取已部署的app，可能导致部分app运行数据丢失
		- memcache 计算sql语句错误，app_id和memcache上报agentId是多对多关系。
			
	* ace的部署方式，加上先从svn下载默认目录结构(包含build部署，执行脚本)，然后执行build进行build,然后deploy，最后execute
		这样，部署ace计量程序步骤如下：
			a. 在有写权限的临时路径下执行
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/deploy-env			
			b. 进入上面checkout下来的目录(deploy-env)，找到measure目录，将其拷贝到/home/admin/measure目录下(若没有此目录则新建，若重名就另外取目录名亦可)
				cd deploy-env
				cp -r measure /home/admin/measure
			c. 进入 /home/admin/measure 目录
				cd /home/admin/measure
			d 执行构建脚本
				sh build/build.sh
			e 执行部署脚本
				sh build/deploy.sh
			f 执行启动服务脚本
				sh bin/execute.sh

2. master的rest对openapi，
提供一个rest service接受所有openapi请求，内部通过一个方法接受所有请求并解析后调用对应action，service处理。

jce的openapi调用文档 —— 据此文档解析请求，调用jce master提供的service


3. ots
	http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000

4.maven debug
	mvn -Dmaven.surefire.debug test
	在ide，比如eclipse上配置远程debug(remote java application)，通过socket来debug。
	通过所使用的maven测试插件自带说明来配置debug，文档最清楚 -tip-

	运行上面maven命令后，再到eclipse配置debug run 为remote java application等配置，执行debug即可进入远程debug模式。
5. jce openapi
	根据请求的action的不同，分发到各自的function去处理，如何去分发？
		通过反射？
			定义acton与方法的的对应关系,比如以属性文件方式配置
			根据action通过反射调用service的方法
		还是自定义注解解析请求uri的方式？
			参考Spring MVC ，提供了完全基于注解的配置
				参考：http://www.cnblogs.com/sunwei2012/archive/2010/05/11/1732518.htm
					http://www.infoq.com/cn/articles/cf-java-annotationl
	* jce日志接口调用
		query_app_log这个接口的type类型，应用的日志是在ols(open log service)服务 里获取的
		
6. 自定义 annotation 实现元数据配置 ，自定义注解
	* 定义action注解
		actionName - 请求的action名称
		parms - 对应action所需要的参数(这里每个action参数不一致，引出下面的问题)
			需要rest提供一种方式，可以取到比较原始的请求消息，可以进行自定义再处理，而不是在rest方法里定义好
		需要取那个参数。？
	* 通过注解，由于每个jec open api的请求参数不同，所有需要根据rest规范，得到请求的所有参数，
	参考了sum的RESTfulWeb Services Developer'sGuide(p26)，可以通过context注解来注入请求上下文内容，
	从而获得所有请求参数。再匹配到对应的action取到各自的参数，调用service执行逻辑。-tip-
		----
		...
			Form parameters (indicated by decorating the parameter with javax.ws.rs.FormParam)
			extract information from a request representation that is of the MIME media type
			application/x-www-form-urlencoded and conforms to the encoding specified by HTML
			forms, as described here. This parameter is very useful for extracting information that is
			POSTed by HTML forms. The following example extracts the form parameter named "name"
			from the POSTed form data.
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(@FormParam("name") String name) {
			// Store the message
			}
			If it is necessary to obtain a general map of parameter names to values, use code such as that
			shown in the following example , for query and path parameters.
			@GET
			public String get(@Context UriInfo ui) {
			MultivaluedMap<String, String> queryParams = ui.getQueryParameters();
			MultivaluedMap<String, String> pathParams = ui.getPathParameters();
			}
			Or code such as the following for header and cookie parameters:
			@GET
			public String get(@Context HttpHeaders hh) {
			MultivaluedMap<String, String> headerParams = hh.getRequestHeaders();
			Map<String, Cookie> pathParams = hh.getCookies();
			}
			In general @Context can be used to obtain contextual Java types related to the request or
			response.
			For form parameters it is possible to do the following:
			@POST
			@Consumes("application/x-www-form-urlencoded")
			public void post(MultivaluedMap<String, String> formParams) {
			// Store the message
			}
		...
		-----
		先看了注解源码说明，再依据文档。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day23 Tuesday, April 17, 2012

1. 
	* 通过 rest  的规范中的 @context 注解来取得请求参数，传递给其他函数处理
		action映射在启动时初始化好。
	* jce openapi
	接口文档里面提到的一些param 字符串需要你这边把输入参数转换为json。
		转换的内容在 com.aliyun.cloudengine.model.opeanapi 下，里面以Param结尾的类定义
		siteId是之前跟王永生约定好的，调用方的标识ID
	- com.aliyun.cloudengine.service.openapi.OpenApiFacadeService(定义在spring-base-service.xml中) 处理openapi请求
		需要将请求参数转换为json格式传递
	- 日志查询需要用到ols ？待
		集合jce openapi文档参考ols文档
		关于ACE OpenAPI的日志查询接口说明
			1、操作接口是query_app_log，日志类型是manipulateLog和appRunningLog 
			2、以上两种类型的日志需要通过OTS获取，其他类型的通过调用master接口获取
			3、测试环境调用地址：curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'
			4、具体的调用可参见《开放日志服务接口文档.docx》

2. maven添加jar到本地库
	mvn install:install-file -DgroupId=com.sun.jersey -DartifactId=jersey-servlet -Dversion=1.12 -Dfile=jersey-servlet-1.12.jar -Dpackaging=jar -DgeneratePom=true
	from:http://blog.sina.com.cn/s/blog_4b81125f0100ifnm.html
3. maven jar包重复问题，可通过
	mvn dependency:tree 查看依赖关系。
	配置的jar包，如果存在其他依赖，且jar包里有依赖配置文件，会自动下载附带依赖，不同的jar就可能依赖同一个jar的不同版本导致重复。
	对于有依赖描述的jar包，只需加入此jar即可，不要再去定义它的依赖。
	只定义用到的关键jar，至于jar的附带依赖让maven管理，若maven不能管理，再去手动添加依赖。

	若还是冲突，修改scope为provided，或者通过exclusions来处理。
4. 关于ace计量pv
	nginx_app_abstract_running_info 中的pv包含静态和动态之和； nginx_app_running_info 中的pv只为静态请求次数

5. http状态表示 ，状态常量定义 
	import org.apache.commons.httpclient.HttpStatus;


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day24 Wednesday, April 18, 2012

1. 
	* jce open api
		- jce接口中的site_id就是jce请求的site_user_id ?site_id不是用户调用jce open apisite_user_id这个site_id表示阿里云，万网或是其他的id标识，可以
		   到app表取到(注意：目前取app表的user_id作为site_id,后续会废弃user_id改为app表的site_id的值)这个site_id在到openapi处理时已经附加在用户请求中了
		   参考 产品线接入Open API规范说明_v0.2
		- 由于线上cloudengine的库表结构和最新开发的库表结构可能不一致，从trunk上拿线上版本的表，再测试下 ？
			包括相关的mapping文件pojo等
		- ace计量bid定为26842，测试时用的aliyun
		- 测试oms时，可以到ace_calc_struct.xml把生成数据替换为测试数据测试
		- jce sevice接口调用参数改为传递对象方式，原为json
	* ace计量
		- 对于没有任何app的情况，跳过不处理。

2. firefox 能正确显示json格式，ie8却不能处理 ？
	即content-type = application/json时ie8不认识，不会处理。
	查看ie8支持的媒体类型：

3. 通过注解anotation配置映射信息 ,取代配置文件实现元数据配置。
	------
	...
		@Retention(RetentionPolicy.RUNTIME)
		@Target(ElementType.METHOD)
		public @interface OpenAction {
			
			String actinName();
			String[] paramNames();
			
		}	
	...
	------
4. mysql 
	不同版本统计函数返回的数据类型也是不一致的，

5. jce openapi 日志
	日志类型,manipulateLog、accessLog、jettyRunningLog、appRunningLog
		其中，manipulateLog和appRunningLog类型日志从OLS服务获取，accessLog、jettyRunningLog调用master接口获取。

	OLS测试地址：
		curl 'http://10.230.202.44/GetMetricData?UserId=1&MetricName=summary&BeginTime=0&EndTime=1340000000'	
		服务位置：http://ols.aliyun-inc.com
6. 测试时从类相同路径加载资源文件
	this.getClass().getResourceAsStream("JobServiceImplTest.testPushRequest.xml");
	加载资源的方法有多种，下面摘自网络小节：
			------
				Java中getResourceAsStream的用法
				首先，Java中的getResourceAsStream有以下几种： 
				1). Class.getResourceAsStream(String path) ： path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从
				ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。 
				2). Class.getClassLoader.getResourceAsStream(String path) ：默认则是从ClassPath根下获取，path不能以’/'开头，最终是由
				ClassLoader获取资源。 
				3). ServletContext. getResourceAsStream(String path)：默认从WebAPP根目录下取资源，Tomcat下path是否以’/'开头无所谓，
				当然这和具体的容器实现有关。 
				4). Jsp下的application内置对象就是上面的ServletContext的一种实现。 
				其次，getResourceAsStream 用法大致有以下几种： 
				第一： 要加载的文件和.class文件在同一目录下，例如：com.x.y 下有类me.class ,同时有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("myfile.xml"); 
				第二：在me.class目录的子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.y.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("file/myfile.xml"); 
				第三：不在me.class目录下，也不在子目录下，例如：com.x.y 下有类me.class ,同时在 com.x.file 目录下有资源文件myfile.xml 
				那么，应该有如下代码： 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				总结一下，可能只是两种写法 
				第一：前面有 “   / ” 
				“ / ”代表了工程的根目录，例如工程名叫做myproject，“ / ”代表了myproject 
				me.class.getResourceAsStream("/com/x/file/myfile.xml"); 
				第二：前面没有 “   / ” 
				代表当前类的目录 
				me.class.getResourceAsStream("myfile.xml"); 
				me.class.getResourceAsStream("file/myfile.xml"); 
			------

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day25 Thursday, April 19, 2012

1. 
	* jce open api
		- ols日志部分
			a. 根据jce openapi文档日志查询部分需求，设计接口及实现
			b. 使用master内处理http发送接收请求的代码与日志服务交互
				http交互公用代码
		其余action实现
2. 关于rest的response问题 -tip-
	* 在简单的测试项目中一个pojo service在暴露rest服务并做处理返回时，这个返回对象需要是rest规范定义的response的
	子类，这样rest框架处理时就能正确响应给请求者。
	* 还有一种方式，就是这个rest service继承某个类，或实现接口，其暴露的rest服务方法只返回pojo对象，处理响应交给依赖的
	类去处理
	fire: REST方法的返回对象必须是REST接口定义的Response类的子类。上面的说明还是和所使用的rest框架相关的，下面的 RESTEasy 框架
	rest服务返回的就是直接的pojo对象，框架自身回去处理把pojo构造为标准的http response返回。
3. RESTEasy  框架实现REST服务
	RESTEasy
		RESTEasy is a JBoss project that provides various frameworks to help you build RESTful Web Services and RESTful Java applications. 
	It is a fully certified and portable implementation of the JAX-RS specification. JAX-RS is a new JCP specification that provides a Java API for RESTful Web Services over the HTTP protocol.
		RESTEasy can run in any Servlet container, but tighter integration with the JBoss Application Server is also available to make the user experience nicer in that environment. 
	While JAX-RS is only a server-side specification, RESTEasy has innovated to bring JAX-RS to the client through the RESTEasy JAX-RS Client Framework. This client-side framework allows you to map outgoing HTTP requests to remote servers using JAX-RS annotations and interface proxies.

	from:http://www.jboss.org/resteasy/

	搭建 RESTEasy 测试project。
4. String.valueOf() 注意null值

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day26 Friday, April 20, 2012

1. 
	* 测试jce openapi
		- 由于运行环境不易构建，通过 mock 方式测试用例，mock出需要的条件。
			mock测试目的：测试目标类的功能时，模拟其依赖对象，关键在于测试目标类。
		- openapi把用户请求转发给jce open api前会去校验action是否存在
		- 停止APP的参数不统一？jce open api文档有的参数pojo中没有
	* 参照jce open api对比所有参数正确性 ？ 

2. jtester 可以利用其提供的反射工具类进行特殊方法(如私有方法)的测试
	JTesterReflector 通过反射执行调用测试
	提供集成测试支持(如数据库等)
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day27 Monday, April 23, 2012

1. 
	*jce openapi 
		- post请求 rest 取得post参数集合	
			结合openapi的post请求规范提供服务
		- 日志部分接口定义说明 ，返回码，格式
		- 功能增加，实现
			update OpenApiFacadeService ，svn diff with previous version ，得到新增接口方法，实现对应逻辑及单元测试。


2. rest post请求参数 , get post parameters restful -tip-
	jersey文档说明如下：
		In general @Context can be used to obtain contextual Java types related to the request or response. For form parameters it is possible to do the following:

		Example 2.19. Obtaining general map of form parameters

		@POST
		@Consumes("application/x-www-form-urlencoded")
		 public void post(MultivaluedMap<String, String> formParams) {
		     // Store the message
		 }
	参数集合，自动封装Injection 自动注入 。
		get请求通过uriinfo封装
		post请求直接通过MultivaluedMap封装

3.for test
#for test case 
slb.api.server=1
slb.api.serviceSecretKey=2
slb.api.session=3
slb.api.regionNo=4
ftp.url=1
ftp.address=2
ftp.port=3
dns.server=4

4.  调用过程
	请求处理
	资源分配
	rpc(mina)
		Apache MINA is a network application framework which helps users develop high performance and high scalability network applications easily. 
		It provides an abstract ·event-driven · asynchronous API over various transports such as TCP/IP and UDP/IP via Java NIO.
	结果处理
5. quartz 属性配置文件配置跳过更新检查
	或者通过java命令的 -D参数设置
		-Dorg.terracotta.quartz.skipUpdateCheck=true
6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day28 Tuesday, April 24, 2012

1. 
	* jce openapi 内部联调
		- 测试环境openapi接入前准备
			mysql -utest -ptest
			openapi 
				配置接入参数到 服务表 和 action表
			测试地址：http://10.230.129.182:8088/open?
			jce 测试环境wiki：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8651094
		- master的属性配置到 /src/main/conf/cemaster_env.properties 中，test下的属性只供测试调用
		- rest暴露的服务uri定位 /open 
		- wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=6094915
		- site_id master的接口实现已经做了参数验证，桥接层不需要处理，提供统一的异常提示。
			转接层不做业务相关的处理,让了解业务的逻辑去处理验证是否符合要求。模块责任清晰
			参考 struts2的自动参数注入逻辑，不匹配的置为null
	* 着手 SLB API V2 时间点 4.30
2. 测试环境 mysql
	10.250.8.214
	mysql -utest -ptest
	open api服务接入配置：
	use openapi
		service_provider
			insert into service_provider values(7,'ace','http://10.230.129.182:8088/open?','1.0','ace',now(),now());
		api
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('create_app',60,'create_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_name',60,'check_app_name',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('check_app_domain',60,'check_app_domain',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_web_container_quota',60,'set_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values(set_reverse_proxy_quota',60,'set_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_memcache_quota',60,'set_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_start_args',60,'set_app_start_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_app_stop_args',60,'set_app_stop_args',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('start_app',60,'start_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('stop_app',60,'stop_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('build_app',60,'build_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_build_job',60,'query_build_job',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app',60,'query_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_app',60,'delete_app',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_app_topolgy',60,'query_app_topolgy',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_os_monitor',60,'query_os_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_reverse_proxy_quota',60,'query_reverse_proxy_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_web_container_quota',60,'query_web_container_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_quota',60,'query_memcache_quota',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_memcache_info',60,'query_memcache_info',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_jvm_monitor',60,'query_jvm_monitor',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('set_reverse_proxy_configuration',60,'set_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('test_reverse_proxy_configuration',60,'test_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('get_reverse_proxy_configuration',60,'get_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('delete_reverse_proxy_configuration',60,'delete_reverse_proxy_configuration',1,1,7,now(),now());
			insert into api(api_name,timeout,description,status,level_id,sp_id,gmt_create,gmt_modify)values('query_net_io',60,'query_net_io',1,1,7,now(),now());

			| api_id | api_name                           | timeout | description                        | status | level_id | sp_id | gmt_create          | gmt_modify          |
			+--------+------------------------------------+---------+------------------------------------+--------+----------+-------+---------------------+---------------------+
			|    289 | create_app                         |      60 | create_app                         |      1 |        1 |     7 | 2012-04-24 10:30:45 | 2012-04-24 10:30:45 |
			|    291 | check_app_name                     |      60 | check_app_name                     |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    292 | check_app_domain                   |      60 | check_app_domain                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    293 | set_web_container_quota            |      60 | set_web_container_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    294 | set_reverse_proxy_quota            |      60 | set_reverse_proxy_quota            |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    295 | set_memcache_quota                 |      60 | set_memcache_quota                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    296 | set_app_start_args                 |      60 | set_app_start_args                 |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    297 | set_app_stop_args                  |      60 | set_app_stop_args                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    298 | start_app                          |     600 | start_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    299 | stop_app                           |      60 | stop_app                           |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    300 | build_app                          |      60 | build_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    301 | query_build_job                    |      60 | query_build_job                    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    302 | query_app                          |      60 | query_app                          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    303 | delete_app                         |      60 | delete_app                         |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    304 | query_app_topology                 |      60 | query_app_topolgy                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    305 | query_os_monitor                   |      60 | query_os_monitor                   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    306 | query_reverse_proxy_quota          |      60 | query_reverse_proxy_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    307 | query_web_container_quota          |      60 | query_web_container_quota          |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    308 | query_memcache_quota               |      60 | query_memcache_quota               |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    309 | query_memcache_info                |      60 | query_memcache_info                |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    310 | query_jvm_monitor                  |      60 | query_jvm_monitor                  |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    311 | set_reverse_proxy_configuration    |      60 | set_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    312 | test_reverse_proxy_configuration   |      60 | test_reverse_proxy_configuration   |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    313 | get_reverse_proxy_configuration    |      60 | get_reverse_proxy_configuration    |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    314 | delete_reverse_proxy_configuration |      60 | delete_reverse_proxy_configuration |      1 |        1 |     7 | 2012-04-24 10:31:44 | 2012-04-24 10:31:44 |
			|    315 | query_net_io                       |      60 | query_net_io                       |      1 |        1 |     7 | 2012-04-24 10:31:46 | 2012-04-24 10:31:46 |
	
	文档action名称定义：
		create_app
		check_app_name
		check_app_domain
		set_web_container_quota
		set_reverse_proxy_quota
		set_memcache_quota
		set_app_start_args
		set_app_stop_args
		start_app
		stop_app
		build_app
		query_build_job
		query_app
		delete_app
		query_app_topology
		query_os_monitor
		query_reverse_proxy_quota
		query_web_container_quota
		query_memcache_quota
		query_memcache_info
		query_jvm_monitor
		set_reverse_proxy_configuration
		test_reverse_proxy_configuration
		get_reverse_proxy_configuration
		delete_reverse_proxy_configuration
		query_net_io


3. 产品线接入openapi ，诸如验证，访问控制，负载，api是否开放等等由openapi负责 ，产品线关心业务。 -tip-

4. jce openapi 测试
	测试每一个action ，测试结果以与rest接口暴露的action的返回结果一致为准。
		create_app
			domain_name 格式要求 xxxxxx.aliapp.com ，xx位置格式要求为4-18个字符
		url=http://10.230.129.78:8088/open?oauth_nonce=28587223711112&start_args=test_start_args&oauth_version=1.0&oauth_consumer_key=TestVMFhd506uBsO&app_name=testAppName1088&site_user_id=1088&oauth_signature=sZUqPtyuaPXlsRx1NVnboV0tIaw%3D%0D%0A&oauth_signature_method=HMAC-SHA1&action=create_app&app_language=2&stop_args=test_stop_args&user_id=1&domain_name=ace2012.aliapp.com&git_url=test.git.url&oauth_timestamp=1335258526
		{"data":{"appId":3},"code":200,"msg":"success"}			
	* yaml 格式配置消息 -tip-
		准备此格式配置内容
	* 

5.  SLB API V2
	* 目标
		- 接收用户请求
		- 根据请求消息，构造请求体，调用后端slb，得到结果
			需要根据request信息，查询db得到调用slb后端接口的必要参数
				region_id所属的HOUYI region id
		- 将结果状态处理下 比如 -100 转换为-2100，返回给用户
		- 实现slb后端提供的接口调用(定义的action操作)
	* check out 代码
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 阅读相关文档
	* 查看源码
		框架构成：struts2 + spring + ibatis 
			- bean交给spring管理，struts配置文件引用其名称；action定义于spring配置中 ，通过ApplicationContext的getBeansOfType(Class type)获得所有action的名称实例map
			- 请求映射通过统一的proxyaction接受，并根据请求的action，通过反射执行对应action的接口方法，得到返回结果。
			   其中的action名到对应action实例的映射关系实现通过ExecuteActionFactory初始化，这里的设计，每个action名对应一个
			    action处理类，启动时以bean names as keys and the corresponding bean instances as values初始化到map中。
			- 需要用的参数，拦截器处理好放到threadlocal实现的RequestContextHolder对象中，提供了静态方法，供service调用slb后端
			   时调用

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day29 Wednesday, April 25, 2012

1. 
	* slb api v2
		- 根据上面分析，现在的任务是：
			a. 实现slb后端文档提供的操作Action类，并配置到spring配置中
			b. LoadBalancerService 加入新的功能定义，并实现
				
		- 涉及到vm的信息(比如向lb_id中加vm时) ，需要到后羿vm处去查询  ，数据库 houyi
			配置文件：slbapi.properties 
				ec.api.url=http://10.230.204.65/open/services?
		- 一些交互细节，demo等可参考v1版本的代码(houyi-console下)
			svn 地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/trunk
			如 /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/LBControlServiceImpl.java 参考其与slb后端交互逻辑。
		- slb后端的请求url从region表中获得。
		- post请求：
			注意请求内容以multipart的方式构造请求体，这样服务端接收时才能正确解析。
		- 返回码搞清楚
			对于slb后端返回的状态码，如果为负数则减去2000作为返回状态码
			如果slb api前端报错，则根据前端文档返回对应状态及msg

		- 任何异常(Exception)都指定到错误的result上去。
	* slb 测试
		测试地址：10.150.8.214
		部署
			部署结构：nginx+tomcat
			启动tomcat 
				/home/admin/slbapi/bin/tomcatctl start
			启动nginx（/home/admin/openapi/bin/nginxctl start）——若已启动，则不需要操作，只需启动tomcat即可
			
			http://10.250.8.214/slb/api?action=list_rs_pool&timestamp=2012-05-31+19%3A45%3A37&region_no=AT03-HOUYI1&session=lei.chang%40alibaba-inc.com&sign=kmEdDhkMXlIqGXxpsfwG3A%3D%3D

			查看tomcat日志，在..slbapi/.default/...tomcat-localhost-6.1xx.log
				
2. 
openapi接入的服务
mysql> select * from service_provider;
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
| sp_id | sp_name  | url                                 | version | description | gmt_create          | gmt_modify          |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
|     1 | ecs      | http://10.230.204.65/open/services? | 1.0     | ecs         | 2011-12-31 17:13:55 | 2011-12-31 17:13:55 |
|     2 | slb      | http://10.230.204.65/open/services? | 1.0     | slb         | 2012-01-10 10:21:07 | 2012-01-10 10:21:07 |
|     3 | ecs_test | http://127.0.0.1:8888/?             | 1.0     | ecs test    | 2012-01-18 17:31:33 | 2012-01-18 17:31:33 |
|     4 | boss     | http://10.230.128.5:8080/           | 1.0     | boss        | 2012-04-20 15:20:26 | 2012-04-20 15:20:26 |
|     5 | rds      | http://127.0.0.1:8888/?             | 1.0     | rds         | 2012-04-20 15:20:39 | 2012-04-20 15:20:39 |
|     6 | git      | http://ceqa-gitserver1:4567/api     | 1.0     | git         | 2012-04-23 16:42:49 | 2012-04-23 16:42:49 |
|     7 | ace      | http://10.230.129.182:8088/open?    | 1.0     | ace         | 2012-04-24 10:20:47 | 2012-04-24 10:20:47 |
+-------+----------+-------------------------------------+---------+-------------+---------------------+---------------------+
ecs - vm openapi

3. slb v2 
	测试url：http://localhost:8080/slb/api.do?action=create_loadbalancer
		 <?xml version="1.0" encoding="utf-8" ?> 
		 <rsp>
		  <code>-50</code> 
		  <msg>illegal user</msg> 
		  </rsp>


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day30 Thursday, April 26, 2012

1. 
	* slb api v2 
		* 走通一个action
			http://localhost:8080/slb/api?action=create_loadbalancer&user_id=1&session=xxx

2. maven web 项目debug ，maven tomcat debug
	修改tomcat启动脚本,远程调试：
		call "%EXECUTABLE%" jpda start %CMD_LINE_ARGS%  
3. 请求slb后端方式的修改
	slb后端服务是REST方式，在请求时需要满足其格式要求。
		比如除了get方式外，其他请求方式post，put，delete请求方式，都需要把请求体也放到URI中，目前采用的是 Matrix URIs  方式：
			Matrix URIs 
			Matrix spaces and Semicolons 
			It is maybe obvious to note that there are many, many hierarchical systems. An interesting analogy with a hierarchical power is, in a programming language, a sequence of parameters supplied to a command or a procedure. For example, in some languages a procedure may take positional parameters which may be optional so that any parameters from a certain point on may be omitted. This syntax can be compared with a hierarchical slash separated URL path. This is an interesting analogy because looking at the alternative representation for procedure parameters which consists of a list of procedure name and value pairs. This leads us naturally to a discussion of the use of the semi-colon in URLs and the matrix syntax. Just as the slash separated set of elements is useful for representing a tree, so a set of names and equally significant parameter can represent a space more like a (possible sparse) matrix. In this case navigation to "close" locations is done by varying one or more parameters which form the dimensions of the matrix. This is the purpose of the a=b; parts of URL syntax which was added later in the URL's history. The initial need was to put qualifiers onto URLs which were themselves hierarchical. 

			The analogy with procedure call holds still when looking at combined forms: The hierarchical part of the URL is paused first, and then the semi-colon separated qualifiers are paused as indicating positions in some matrix. As an example let's imagine the URL of an automatically generated map in which the parameters for latitude, longitude and scale are given separately. Each may be named, and each if omitted may take a default. So, for example,

				 //moremaps.com/map/color;lat=50;long=20;scale=32000

			might be the URL of an automatically generated map. 
			摘自：http://www.w3.org/DesignIssues/MatrixURIs.html
	根据上面：
			请求SLB后端时，get请求直接根据uri格式要求请求；对于有content内容(注意区别与普通post请求是放到请求体重)的请求，
		需要以Matrix URIs的方式，把请求内容放到uri中，再去请求。-tip-
	
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day31 Friday, April 27, 2012

1. 
	* SLB API v2
		- 根据slb对外api文档，将请求结果处理后依据slb后端调用文档调用，并返回结果
2. 测试
	* 创建LoadBalancer：		
		客户端请求：http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
		slb后端请求：http://10.230.130.129:8088/lbs/lbname1;lb_type=compact;region_id=region-test;eip_type=internet;user_id=1
			结果：{response={"data":{"lb_id":"25-region-test","eip":"42.120.64.227"},"code":200,"msg":"successful"}, status=200}
			struts的自定义result处理结果时报错。
				处理结果返回类型的 UserActionResult 在 response.getWriter().write(resultFormat.value(result)); 处转换对象为json或者xml时报错？
	* 查询LoadBalancer信息：
		http://10.230.130.129:8088/lbs/123/
		user_id如何传递？
	* 查询loadbalancer列表 http://10.230.130.129:8088/lbs;user_id=1
		结果：{"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","26-region-test","27-region-test","28-region-test","29-region-test","30-region-test","31-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test"]},"code":200,"msg":"successful"}



3. 
SLB API 错误码：
		2000 - 2100 -平台错误
		>2100 业务错误

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day32 Saturday, April 28, 2012

1. 
	* 根据slb后端文档，实现调用接口，对比前端用户api文档，修改接口实现中需要参数转换的逻辑。
	* 拿到rest服务的源码校对url请求 ？
		- 看rest服务代码，测试请求来的精确
			eg：查询lb:http://10.230.130.129:8088/lbs/43-region-test;user_id=1 这里需要将user_id传递过去，因为slb后端是根据lb_id和user_id都匹配来查询lb的
	* slb api v2 平台错误提示需要细化，比如：
		http://localhost:8080/slb/api?action=query_loadbalancer&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":-2003,"msg":"system exception"}
		http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=43-region-test&&session=accessid1&sign=xx
		{"code":200,"data":{"lb_id":"43-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.215","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		第一个请求的错误，具体原因是action的名称不对，可以细化错误提示，便于调试和理解。

		错误，异常提醒细化 

2. 
	测试记录：
		创建LB: 
			compact http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"53-region-test","eip":"42.120.64.204"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
				{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
			hybrid http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=hybrid&eip_type=internet&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"60-region-test","eip":"42.120.64.238"},"msg":"successful"}
				http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname2&lb_type=hybrid&eip_type=internet&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","eip":"42.120.64.226"},"msg":"successful"}
		查询LB: http://localhost:8080/slb/api?action=query_loadbalancer_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","frontend_port":[],"lb_type":"compact","eip":"42.120.64.227","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
		删除LB: http://localhost:8080/slb/api?action=delete_loadbalancer&region_no=region-test&lb_id=31-region-test&&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置LB: http://localhost:8080/slb/api?action=config_loadbalancer&region_no=region-test&lb_id=25-region-test&status=active&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询LB列表：http://localhost:8080/slb/api?action=list_loadbalancers&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"user_id":"1","lbs":["20-region-test","21-region-test","22-region-test","23-region-test","24-region-test","25-region-test","32-region-test","33-region-test","34-region-test","35-region-test","36-region-test","37-region-test","38-region-test","39-region-test","40-region-test","41-region-test","42-region-test","43-region-test","44-region-test"]},"msg":"successful"}
		
		创建VIP: 
			compact: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A80%2C%22backend_port%22%3A82%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22persistence_timeout%22%3A1000%2C%22check%22%3A{%22type%22%3A%22vtcp%22}}}%2C{%22protocol%22%3A%22tcp%22%2C%22frontend_port%22%3A83%2C%22status%22%3A%22inactive%22%2C%22backend_port%22%3A81%2C%22config%22%3A{%22scheduler%22%3A%22rr%22%2C%22forwardfor%22%3A%22on%22%2C%22keepalive%22%3A%22on%22}}]&lb_id=59-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}
			http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=401-AT03-HOUYI1&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
			hy: http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=62-region-test&region_no=region-test&status=active&session=accessid1&sign=xx
				{"code":200,"msg":"successful"}		
				http://localhost:8080/slb/api?action=create_vip&listeners=[{%22protocol%22:%22http%22,%22frontend_port%22:80,%22backend_port%22:82}]&lb_id=23-region-test&region_no=region-test&status=active&session=cao.yin&sign=xx
				{"code":200,"msg":"successful"}
		删除VIP: http://localhost:8080/slb/api?action=delete_vip&region_no=region-test&lb_id=25-region-test&frontend_port_list=[80,90]&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		配置VIP: http://localhost:8080/slb/api?action=config_vip&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		查询VIP: http://localhost:8080/slb/api?action=query_vip_info&region_no=region-test&frontend_port=80&rs_pool_name=rspool1&lb_id=25-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"protocol":"tcp","port":80,"status":"stopped","config":{"scheduler":"rr","check":{"type":"vtcp"},"persistence_timeout":1000}},"msg":"successful"}
		查询VIP的健康状态: http://localhost:8080/slb/api?action=query_vip_healthcheck&frontend_port=80&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"rs_list":[]},"msg":"successful"}

		添加VM: http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22vm1%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
				{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_vm&vm_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=22-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"22-region-test","vm_list":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		查询VM信息: http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=25-region-test&&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"25-region-test","vm_list":[{"weight":100,"vm_name":"vm1"}]},"msg":"successful"}
			注：ip与vm名称是一对一，如果为一对多则会出错。依据业务为准
			http://localhost:8080/slb/api?action=query_vm_info&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"data":{"lb_id":"53-region-test","vm_list":[]},"msg":"successful"}
		删除VM: http://localhost:8080/slb/api?action=delete_vm&vm_list=[%22vm1%22]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
		切换VM: http://localhost:8080/slb/api?action=switch_vm&old_vm=[%22vm1%22]&new_vm=[{%22vm_name%22:%22vm2%22,%22weight%22:100}]&region_no=region-test&lb_id=53-region-test&session=accessid1&sign=xx
			{"code":200,"msg":"successful"}
			注：与文档说明返回不一致？			
		
		// hybrid
		添加Rule: http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=59-region-test&session=accessid1&sign=xx
			{"code":-2402,"msg":"RuleNotSupport"} //compact lb 不能添加rule
			http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool1%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=60-region-test&session=accessid1&sign=xx
			hybrid:http://localhost:8080/slb/api?action=add_rule&frontend_port=80&rule_list=[{%22rule_name%22:%22rule1%22,%22domain%22:%22www.xxx.com%22,%22rs_pool_name%22:%22rspool2%22,%22private_header%22:{%22key1%22:%22value1%22,%22key2%22:%22value2%22}},{%22rule_name%22:%22rule2%22,%22domain%22:%22www.abc.com%22,%22rs_pool_name%22:%22rspool2%22}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","rule_id":"1-region-test"},{"name":"rule2","rule_id":"2-region-test"}]},"msg":"successful"}
		配置Rule: http://localhost:8080/slb/api?action=config_rule&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}
		查询Rule: http://localhost:8080/slb/api?action=query_rule_info&rule_name=rule1&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"lb_id":"23-region-test","frontend_port":80,"rules":[{"name":"rule1","domain":"www.xxx.com","rs_pool_name":"rspool2","rule_id":"1-region-test","scheduler":"wrr","private_header":{"key2":"value2","key1":"value1"}},{"name":"rule2","domain":"www.abc.com","rs_pool_name":"rspool2","rule_id":"2-region-test","scheduler":"wrr"}]},"msg":"successful"}
		删除Rule: http://localhost:8080/slb/api?action=delete_rule&rule_name_list=[%22rule1%22]&frontend_port=80&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"msg":"successful"}

		// compact
		添加rs pool: http://localhost:8080/slb/api?action=create_rs_pool&name=rspool1&protocol=http&port=80&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"name":"rspool1","protocol":"http","port":80},"msg":"successful"}
			http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool2&protocol=http&port=80&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"name":"rspool2","protocol":"http","port":80},"msg":"successful"}
		查询RS POOL列表: http://localhost:8080/slb/api?action=list_rs_pool&vm_name=vm2&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":-2502,"msg":"RealServerParseError"}
			http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=60-region-test&region_no=region-test&session=cao.yin&sign=xx
			{"code":-2502,"msg":"RealServerParseError"} //SLB 后端bug，待修改
		添加rs 到 rs pool: http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool1&rs_list=[{%22vm_name%22:%22vm2%22}]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
			http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool2&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=22-region-test&region_no=region-test&session=cao.yin&sign=xx
				{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		从rs pool 删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool1&rs_list=[%22vm-tes1%22,%22vm-test2%22]&lb_id=60-region-test&region_no=region-test&session=accessid1&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool1","rsList":[{"address":"10.1.1.1","weight":100}]},"msg":"successful"}
		删除rs pool:http://localhost:8080/slb/api?action=delete_rs_pool&rs_pool_name=rspool2&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":-2505,"msg":"RspoolRuleExist"} //前提 删除rs pool配置的rule
		删除rs: http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool2&rs_list=[%22ceqa-ag-0419160429%22]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
		切换rs: http://localhost:8080/slb/api?action=switch_rs&rs_pool_name=rspool2&old_rs=[%22ceqa-ag-0419160429%22]&new_rs=[{%22vm_name%22:%22ceqa-ag-0419160429%22,%22weight%22:100}]&region_no=region-test&lb_id=23-region-test&session=cao.yin&sign=xx
			{"code":200,"data":{"rsPoolName":"rspool2","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day33 Wednesday, May 02, 2012

1. 
	* SLB API action测试
		- vm 与 ip的转换，slbapi库的rs表ip与vm是一对一还是一对多？ select * from rs; ，一对一
	* 


2.系统错误提醒设计细化
	错误码提示易定位，人性化
	从总体设计异常提示。

3. 懂业务测试效率更高，特别对于具有依赖关系逻辑的测试。
	slb api测试中，不少用例的测试都是具有依赖关系的，需要前提条件满足才能继续下一个用例的测试
	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day34 Thursday, May 03, 2012

1. 
	* slb api需要和vm api交互的地方，参看 云服务器api说明4.0版本
		比如用户调用slb api传递的是vm的名称，slb api层需要将name转换为ip传给slb后端，slb后端返回的数据中将vm的ip消息转换为vm的名称。
			vm api的测试账户？key ，id
			vm_name = DotProject-4661  / ceqa-ag-0419160429
				cao.yin
				cao.yin
				ec.api.url=http://10.230.204.65/open/services?
	* 上面替换的需求，需要定义查找的key名称，可以统一到常量中，避免硬编码 ？
	* jce open api 修改action时也同时需要到open api表去修改action的名称，哪里会先处理action的正确性。
	* 在 add rs vm,delete rs vm,switch rs vm 时本地rs表的数据是否正确变化也需要测试通过？
	* 一些依赖导致的错误，比如add_rs时需要先add_vm这样在rs表里会有ip与name的对应数据，否则报错，此时应该细化这个错误提示，不都是 sysytemerror ，客户端或者
	开发者自己也不便于debug
	* rs ,vm 删除时都要去删除rs表的记录，也要查询是否有冲突？
2. slb api需要做vm ip和vm name转换的地方，对比slb后端api与slb api
	add_vm //done
	delete_vm //done
	switch_vm //done
	query_vm_info //done
	query_vip_healthcheck //done
	add_rs //done
	delete_rs //done
	switch_rs //done
	query_rs_pool_info  (list_rs_pool) //done
	delete_rs_pool //done

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day35 Friday, May 04, 2012

1. 
	* 配置slb api日志，调用日志，业务日志分开
		api调用日志记录调用前后时间，按照设计的日志格式输出。可以在拦截器中记录调用日志
	* slb api配上签名验证
		测试例子：http://localhost:8080/slb/api?sign=kxUxw8Op%2B8TsTemi6qrknQ%3D%3D&timestamp=2012-05-04%2014%3A53%3A51&session=cao.yin&action=query_loadbalancer_info&lb_id=25-region-test&region_no=region-test&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-region-test","frontend_port":[],"eip":"42.120.64.225","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day36 Monday, May 07, 2012

1. 
	* slb api日志记录在log拦截器执行 
	* 在 10.230.204.24机子上部署测试
		目录为 /home/admin/slbapi
		编译: build/build.sh
		关闭/启动tomcat: bin/tomcatctl stop/start
		eg:
			http://10.230.204.24/slb/api?sign=7kes%2FcmCqF5ofzJkpsI7rg%3D%3D&timestamp=2012-05-07%2015%3A21%3A13&session=cao.yin&lb_id=8-region-test&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":-2610,"msg":"LbIdNotExist"}
			http://10.230.204.24/slb/api?sign=pp9LAo7fjImc9ge4NoIbmg%3D%3D&timestamp=2012-05-08%2009%3A43%3A35&session=cao.yin&lb_id=25-AT03-HOUYI1&action=query_loadbalancer_info&region_no=AT03-HOUYI1&format=json
			{"code":200,"data":{"lb_type":"compact","lb_id":"25-AT03-HOUYI1","frontend_port":[],"eip":"42.120.64.197","eip_type":"internet","rs_type":"houyi"},"msg":"successful"}
	* 日志实现改为 将各处log项存入localthread中，最后记录log时，把log对象tostring即可。
		参考 http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLogHolder.java 实现
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.model/src/main/java/com/aliyun/openapi/entity/MonitorLog.java
		http://svn.alisoft-inc.com/repos/alisoft/houyi/openapi/trunk/aliyun.openapi.framework/src/main/java/com/aliyun/openapi/interceptor/LogInterceptor.java
	* slb api的region_no 问题
		AT03-HOUYI1,region-test 此值从slbapi库的region_mapping表中查询得到；将客户传递来的vm region转换为slb的region，对外统一用vm的region
	* rs表操作的测试，事务一致性测试
	* slb api上线需要做的工作：

2. slb api上线需要做的工作：部署
	(1)建库，建表，表订正
		slbapi库，表有：
			region(region_no ,region_name ,url ,status) slb api的region表，表示slb 的region(区别于vm的region)
			region_mapping(region_no ,vm_region_no) slb的region与vm region的映射关系表，根据vm的region找到slb的region
			rs(vm_name ,ip) 用来做负载均衡的vm服务器的名称对应的ip映射表(用户请求的vm名称通过调用vm的api得转换为其ip调用slb后端，slb后端返回时根据此表将ip转换回vm名称，即对外只提供vm名称的操作隐藏vm的ip)
			user( user_id ,user_name ,service_secret_key ,service_access_id  ,status ,is_admin) slb用户
			lb流量接口表：（这个表会存在多个实例吗？）
				monitor_datasource slb后端提供
		配置数据源：
			- slb api库数据源配置(库slbapi)
			- slb后端业务数据数据库源配置(xuanyuan)
			- 上面的 monitor_datasource 表中配置slb后端计量数据数据库源
	(2) svn下载默认目录结构，地址：http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api/deploy-env
	(3) 将上面目录中的 slbapi 目录cp到 /home/admin 下
	(4) 进入 slbapi 目录
		cd /home/admin/slbapi
	(5) 执行build并部署: sh build/build.sh
	(6) 启动容器: sh bin/tomcattrl start/stop

3. rs的一些操作事务一致性测试
	参看文档，那些地方需要事务保证？
	* 涉及到rs表操作的地方 ，文档中有vm_name, vm_list 相关的地方，据此查到action
		query_vip_healthcheck
		add_vm
		delete_vm
		query_vm_info
		switch_vm
		add_rs
		delete_rs
		switch_rs
		query_rs_pool_info
	* 注意： -tip- sprint事务配置 ，配置方式 + 触发回滚方式: 异常抛出，异常回滚
			spring的事务回滚下面的配置是依据异常抛出来触发回滚的，如果catch了异常，没有抛出，则事务不会回滚，这点在
		程序逻辑上要控制好，适当的抛出需要回滚的异常。
	* spring事务配置例子：
	
		<?xml version="1.0" encoding="UTF-8"?>
		<beans xmlns="http://www.springframework.org/schema/beans"
			xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
			xmlns:aop="http://www.springframework.org/schema/aop"
			xmlns:jee="http://www.springframework.org/schema/jee" 
			xmlns:tx="http://www.springframework.org/schema/tx"
			xsi:schemaLocation="http://www.springframework.org/schema/beans 
			http://www.springframework.org/schema/beans/spring-beans.xsd
			http://www.springframework.org/schema/aop 
			http://www.springframework.org/schema/aop/spring-aop.xsd
			http://www.springframework.org/schema/jee
			http://www.springframework.org/schema/jee/spring-jee-2.5.xsd
		    http://www.springframework.org/schema/tx 
		    http://www.springframework.org/schema/tx/spring-tx-2.5.xsd">
		<tx:advice id="txAdvice4Ip" transaction-manager="transactionManager">
			<tx:attributes>
				<tx:method name="get*" read-only="true" />
				<tx:method name="assign*" rollback-for="Throwable" />
				<tx:method name="release*" rollback-for="Throwable" />
				<tx:method name="modify*" rollback-for="Throwable" />
				<tx:method name="bind*" rollback-for="Throwable" />
				<tx:method name="unBind*" rollback-for="Throwable" />
			</tx:attributes>
		</tx:advice>
		<aop:config>
			<aop:pointcut
				expression="execution(* com.aliyun.houyi.service.impl.IpAddressServiceImpl.*(..))"
				id="ipAddressPointCut" />
			<aop:advisor advice-ref="txAdvice4Ip" pointcut-ref="ipAddressPointCut" />
		</aop:config>
		<aop:config>
			<aop:pointcut id="instanceStatusPointcut"
				expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
			<aop:advisor advice-ref="instanceStatusInterceptor"
				pointcut-ref="instanceStatusPointcut" order="10" />
		</aop:config>
		...
		
		spring 编程式事务：
			-------
			...
				DefaultTransactionDefinition def = new DefaultTransactionDefinition(
						TransactionDefinition.PROPAGATION_REQUIRED);// 事务定义类

				String[] results = null;
				TransactionStatus status = transactionManager.getTransaction(def);
				try
				{
					results = InstanceServiceHelper.createInstances(this.instanceDao,
							noGenerator, this.instancePassworder, instance, count);
					transactionManager.commit(status);
				} catch (DuplicateNameException e)
				{
					transactionManager.rollback(status);
					throw e;
				} catch (Throwable e)
				{
					transactionManager.rollback(status);
					throw new BizException("创建VM发生错误！", e);
				}
			...
			-------
	* 

4. rs 增加删除混乱？	
	目前是有问题的：
		比如，进行更新rs的操作
	是否每次将每个action自己的vm name 与ip关系保存到当前线程中，用好即抛弃？
	可行性：
		是否每次action查询的vm name 与ip映射都满足当前操作。根据文档分析
		会存在返回其他ip的情况

	第二种方式：
		维护vm name 与ip的表，从houyi库里取得，只做查询，更新，不修改？

	
	有个业务前提：
			rs表删除某个记录(vm name - ip address mapping)时，在slb后端已经事先删除了，即在后续查询中，除了再插入这个映射记录，
		否则后端不会返回此ip。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day37 Tuesday, May 08, 2012

1. 
	* rs 重复add操作时，会无判断插入rs表记录，需要判断下，已有的话就跳过记录插入操作。
	* delete_rs_pool 操作如果poo不存在，返回什么？文档需要定义此返回值，现根据slb后端返回来处理 ，先后端也没定义，只是返回 systembusy 
	* slb backend文档修改 ，查看
	* 目前对action的参数合法性没有进行验证，直接调用了slb后端？
		需要实现 ActionValidator 接口，对每个action的参数验证，
		slb api 具有自己的错误码和msg ，还是依赖slb后端的错误码，只是桥接？
		slb后端也会进行验证，可参考


2. rs重复操作测试例子：
	删除没有执行成功，slb后端不是按照json格式解析rslist字段，只返回当前的rs配置。slb后端修改

	http://localhost:8080/slb/api?action=create_loadbalancer&region_no=region-test&lb_name=lbname1&lb_type=compact&eip_type=internet&session=cao.yin&sign=xx+
	{"code":200,"data":{"lb_id":"29-region-test","eip":"42.120.64.225"},"msg":"successful"}
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool3&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool3","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool3&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"} // 返回值为更新后的rs列表。如果传入列表中有已经添加的rs，直接忽略，不会报错
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}

	一个vm对应在多个rs pool中，此时在某个pool中删除这个vm，另一个pool的vm返回正确吗？
	http://localhost:8080/slb/api?action=create_rs_pool&rs_pool_name=rspool4&protocol=http&port=80&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"name":"rspool4","protocol":"http","port":80},"msg":"successful"}
	http://localhost:8080/slb/api?action=add_rs&rs_pool_name=rspool4&rs_list=[{%22vm_name%22:%22ceqa-ag-0419160429%22}]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool4","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":200,"data":{"rsPoolName":"rspool3","rsList":[{"weight":100,"vm_name":"ceqa-ag-0419160429"}]},"msg":"successful"}
	再执行一次：
	http://localhost:8080/slb/api?action=delete_rs&rs_pool_name=rspool3&rs_list=[%22ceqa-ag-0419160429%22]&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2100,"msg":"SystemError"} //后端对不存在的rs直接忽略，返回最新的rs列表

	http://localhost:8080/slb/api?action=list_rs_pool&vm_name=ceqa-ag-0419160429&lb_id=29-region-test&region_no=region-test&session=cao.yin&sign=xx
	{"code":-2003,"msg":"system exception"}
3. action validator


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day38 Wednesday, May 09, 2012

1. 
	* action 的业务参数验证，由于slb后端会做业务参数验证，slb api不做验证
		如果要对每个action做各自的验证，可以在设计action时，提供公用方法通过spring IOC注入自己的validator，此时验证在执行action前操作；
		或者在拦截器层处理，可以在拦截器的上配置action名称对应的validator类。
	* slb api 文档与slb 后端文档在返回码参数定义上一致修正；compact，hybird文档独立
	* rs表在多个rs pool上都有同一个vm时，执行某个pool上删除此vm，导致其他pool再删除此vm时，ip映射不到name，
		解决：细化rs表，加入rs_pool_name ,lb_id分别用于rs操作和vm操作的ip映射,一标识各自的映射数据
			alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
			alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	* 单元测试 ,slb 后端调用加上单元测试
		在有改动时，便于发现问题 ，对于易变部分的逻辑更能体现其作用 ~
	* bug id #41
		由于cacheManage为null导致错误，系统用到cacheManage的地方暂不用。
		搜素整个project，处理
2. alter table
	修改表字段定义：
		sql server:
			alter table table_name alter column column_name varchar(200)
		mysql:
			alter table table_name modify column column_name varchar(100) 

	-- alter table rs add  rs_pool_name varchar(100) NOT NULL COMMENT '@desc rs pool name'
	-- alter table rs add  lb_id varchar(32) NOT NULL COMMENT '@desc lb_id'
	-- alter table rs add id int(10) unsigned NOT NULL COMMENT '@desc id'
	-- alter table rs add vm_name varchar(32) NOT NULL COMMENT '@desc vm name'

	-- delete from rs;

	-- alter table rs modify column rs_pool_name varchar(100) COMMENT '@desc rs pool name'
	-- alter table rs modify column lb_id varchar(32) COMMENT '@desc lb_id'

	修改主键
	-- alter table rs drop column vm_name
	-- alter table rs add id int(10) unsigned NOT NULL AUTO_INCREMENT primary key COMMENT '@desc id'
	
3. remote debug跳不过去，地址不是同一地址 ~~~


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day39 Thursday, May 10, 2012

1.
	* 单元测试补充
		junit
			mock
			数据库测试
			执行顺序
	* 文档修改查看
2. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day40 Friday, May 11, 2012

1. 
	* create_vip
		delete_vip 后端参数名称修改：frontend_port 改为 frontend_port_list
	delete_vm文档定义需要修改 ，address参数不需要，weight不需要？

2. linux系统不同权限账户操作同一目录时注意，可以对导致其他用户不能访问，权限高账户创建的内容，导致任务失败。
比如root创建了某个文件，其他没权限的账户就不能删除，导致文件没有更新。-tip-
	例子：
		root账户编译部署了web应用，换个admin账户去做同样操作时，root创建的文件不能被更新。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day41 Monday, May 14, 2012

1. 
	* 大region了解
		数据中心随着业务增长，当前region不能放入更多vm，需要跨region，但逻辑上他们还是属于同一region，这样上层下发规则时，能对应到同region的vm。
		当前解决方式，把region规则上提到api层，在这层统一region。
	* houyi api 在vm迁移时需要刷新cache中的region信息以映射到新的region，在region定位接口，提供清楚指定资源的cache接口。 clear_cache

		缓存：AbstractResourceLocator 类的 resourceRegionCache 方法 (定位用)

		com.aliyun.houyi.service.ResourceLocator
			DefaultResourceLocator 和 AbstractResourceLocator中实现(/houyi-console-service)
			然后添加一个action(包位置：com.aliyun.houyi.openapi.control.vm)，并配置(/houyi-console-openapi):在spring里配置action这个bean，至于action请求映射配置由于用了
			代理方式依据配置bean的name来执行，故不用再到struts.xml中配置(只配置一个代理的访问入口)。
		action bean名为clear_cache
		需要定义接口说明，传递参数，返回值，状态码说明等。
			参考houyi api文档
			cache_key: vm名称
			cache_type:instance,ip,.. 要删除的cache实例类型，目前有instance,ip_segment,group,ip_address四种类型，默认为instance类型

			ClearCacheErrorMessage
			状态码可复用已有的比如vm中的vm_name验证状态码：VmErrorMessage
				-200	vm name must set	没有指定VM的名称
				-205	vm not exists	待操作的VM 不存在
			对于cache type需要另外定义：
				-283 cache类型不存在
				-284 清除cache失败
			resourceNO根据不同的cache类型对应不同的值，需要处理。
2. open jce bug fix 
	pojo属性拷贝错位。
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (RestOpenApiService.java:76) - JCE OpenAPI called , paramsMap={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]} siteId=wwg
	2012-05-11 22:55:13,936   INFO [1700182798@qtp-980075617-11] (OpenApplicatonControllerImpl.java:95) - set App Start Args is called. params={start_args=[-Defg=abc], action=[set_app_start_args], app_id=[66], user_id=[wwg]}
	2012-05-11 22:55:13,937   INFO [1700182798@qtp-980075617-11] (OpenApiFacadeServiceImpl.java:225) - openapi called. action: setAppStartArgs, siteId: wwg, params: com.aliyun.cloudengine.openapi.model.SetAppStartArgsParamExt@28e2b1e1[appId=66,startArgs=66]

3. vm api 测试地址
	http://10.230.204.65/open/services
	签名 ，vm name和slb一致

	例子：http://10.230.204.65/open/services?sign=gMnnRDw0%2FIu05Yr9NpM0SA%3D%3D&timestamp=2012-05-14%2020%3A41%3A56&cache_type=instance&session=cao.yin&cache_key=AT03-HOUYI1&action=clear_cache&format=json
		{"code":-284,"data":null,"msg":"cache of this key not exist"}
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day42 Tuesday, May 15, 2012

1. 
	* slb api 加入流量查询接口2个，参考v1的文档：
		指定时间段查询负载均衡流量 query_loadbalancer_flow
		指定时间段批量获取负载均衡流量 list_loadbalancer_flows
		从数据库获取，参考v1版本，不需要调用slb后端

	* jce open api api表修改配置错误，并检查其他配置是否有误
	* slb 后端文档修改：
		- 查询vm接口删除，把其原先返回内容放到查询loadbalance信息接口的返回结果中
		- 查询rs信息接口删除，同时修改了查询rs pool信息的uri

2. lb流量查询的数据源
	是否和slb open api的库一致，还是需要再配个数据源？需要配置到数据库中，每个slb都有一个库；和操作slb后端api地址一样，每个slb是不同的地址。
	先根据基本datasource配置（维护monitor_datasource表(需要订正维护)，和rs表同在一个库中），取得所有region的datasource配置，然后动态返回对应region_no的数据源(slb后端的数据源)。

	* 验证上面到slb后端取数据的sql字段是否与slb后端的表结构一致，参考slb后端数据库表。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day43 Wednesday, May 16, 2012

1. 
	* slb api
		- 流量接口sql与后端表核对
		- 从slb后端得到region的数据源地址配置，并配置到monitor_datasource表中
			10.230.130.1 root/654123 xuanyuan_monitor
			insert  into monitor_datasource 
				(url,username,passwd,region_no) 
			values('jdbc:mysql://10.230.130.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8','root','654123','AT03-HOUYI1')
		- api文档修改
		- regionno从vm转为lb的region
	* slb api部署 day36

2. lb region ，slb api这层的region概念
	lb region在slbapi库region表里管理

3. 测试新加入的lb流量接口
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+10%3a10%3a10&end_time=2012-05-06+12%3a10%3a10&lb_id=31-region-test&&session=cao.yin&sign=xx

4. sql 对照
	LBMonitor.queryL4Flow —— vip_stats_xxx
	LBMonitor.queryL7Flow —— haproxy_rule_stats_xxx
	LBMonitor.loadBalancerCount —— loadbalancer
	
	lb_id 改为 lb_global_id
	
	loadbalancer 表在哪里?
	
5. tomcat报错一例，uri参数格式错误
	invalid chunk starting at byte
	http://localhost:8080/slb/api?action=query_loadbalancer_flow&=4
6. jdbc url 过个空格 ，报错 
	Cannot create JDBC driver of class 'com.mysql.jdbc.Driver' for connect URL ' jdbc:mysql://10.230.130
	.1/xuanyuan_monitor?useUnicode=true&amp;characterEncoding=utf-8'
	java.sql.SQLException: No suitable driver

	一个简单问题，复杂了太多，源于告知 No suitable driver == 驱动没找对 ，忽略了 url错误也是报这个错 ，汗
	+无语

6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day44 Thursday, May 17, 2012

1. 
	* 测试
	* slb后端分计量数据的库 和 业务数据的库
		即在LB流量接口的查询中，用到这两个库
			业务库配置：
				mysql -uroot -p654123 -h10.230.130.129 xuanyuan

		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；

	* lb后端创建lb时，去掉name参数，api需要做相应修改，api文档修改
	* 了解大region需求

	* vm api 之前实现了清除cache的action，现在需要确认是否也能把预加载的region去掉？
		houyi-console-openapi
		
2. 
	select sum(in_bytes) as tcp_internet_rx,lb_global_id      
	from  `vip_stats_20120506`      
	where lb_global_id='57-tr' 
	and user_id=235 
	and (gmt_create between '2012-05-06 05:10:10' and '2012-05-06 12:10:10')        
	group by lb_global_id

	http://localhost:8080/slb/api?action=query_loadbalancer_flow&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"tcp_internet_bandwidth":0,"http_internet_rx":0,"end_time":"2012-05-06 23:10:10","http_internet_bandwidth":0,"tcp_internet_tx":0,"lb_id":"83-tr","start_time":"2012-05-06 05:10:10","http_internet_tx":0,"tcp_internet_rx":477},"msg":"successful"}

	http://localhost:8080/slb/api?action=list_loadbalancer_flows&page_no=1&page_size=10&region_no=region-test&start_time=2012-05-06+05%3a10%3a10&end_time=2012-05-06+23%3a10%3a10&lb_id=83-tr&session=lei.chang@alibaba-inc.com&sign=xx
	{"code":200,"data":{"total":32,"page_size":10,"end_time":"2012-05-06 23:10:10","start_time":"2012-05-06 05:10:10","page_no":1,"loadbalancers":[{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"1","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"2","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"3","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"4","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"5","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"6","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"7","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"8","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"9","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0},{"http_internet_bandwidth":0,"http_internet_rx":0,"http_internet_tx":0,"loadbalancer_id":"10","tcp_internet_bandwidth":0,"tcp_internet_rx":0,"tcp_internet_tx":0}]},"msg":"successful"}

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day45 Friday, May 18, 2012

1. 
	* slb api cache region启用修改
		bug 41 继续报错

	* houyi防火墙规则了解，大region相关业务点熟悉
	* slb后端api user_id必选，rs_type参数名改为mode ，对api这层做相应调整(代码+文档)

2. 虚拟化
	防火墙规则



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day46 Monday, May 21, 2012
1. 
	* vm 内部接口文档整理
	* 大region设计预查看
		对比加入大region前后 vm api流程操作的区别，比如 create_img，原来逻辑哪里需要修改？预分析
		首先要了解原来的流程

	* vm region cache 清除接口是否需要做操作控制？
		属于某个用户的vm的缓存自己能清除，否则某个用户可以把别的缓存清除。再或者只留给内部调用，不需要控制。
	* slb后端文档修改，slb api文档也做相应修改：健康检查查询接口frontend_port必选之后，url也应相应变化
	* 

2. 新浪云计算(关于配额系统，系统稳定摘取)：sina app engine
		日志和统计中心：负责对用户所使用的所有服务进行统计和资源计费，并设定的分钟配额，来判定是否有非正常的使用。
	分钟配额描述了资源消耗的速度，当资源消耗的速度到达一个预警阈值时，SAE通知系统会提前向用户发出一个警告，提醒用
	户应用在某个服务上的使用可能存在问题，需要介入关注或处理，配额系统是SAE用来保证整个平台稳定的措施之一；日志中心
	负责将用户所有服务的日志汇总并备份，并提供检索查询服务。

	配额细化到每个调用者(用户)，以保证稳定持久的服务。

3. 消息中间件 MQ
	云服务器api
	/houyi-console-message

	<dependency>
		<groupId>com.rabbitmq</groupId>
		<artifactId>amqp-client</artifactId>
	</dependency>

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day47 Tuesday, May 22, 2012

1. 
	* big region 分3此迭代开发(测试尽早介入)  —— 具体见邮件
		对开发部分，做设计文档说明(程序流程，控制)，便于测试
		对于设计文档：
			- 参考已有文档说明及程序实现
		数据库：
			xuanyuan
	* big region 需求评审会议
		处理开发迭代1/3涉及的接口修改。
	* big region
		项目管理页面：http://redmine.aliyun-inc.com/projects/vm wb_shen.chengs 域密码
	* slb v2换build，此次改动较大，请前端注意查看最新的文档
		1) rs_type->mode; 2) 去掉rule_name(待修改文档？)
		
2. 业务
	云服务器 产品 - 通过api操作操作云服务器
	ACE云引擎产品 - 目前包含php,node.js,java(JCE)应用环境，基于云服务器产品之上

3.迭代一修改的地方列表如下：
	背景信息
	
	* cluster_id
			之前用户传入小region，以给api查找region；现在用户传入大region，api需要定位到小region，通过用户传入的cluster_id
		在zone表里找到对应的region_no。
			api操作需要定位到region，然后执行操作。

	* API 数据库在zone表增加cluster_id的初始化，记录每个zone_no对应的cluster_id。
		device_no改成：cluster_id-device_no；
		snapshot_id改成：cluster_id-device_no-snapshot_id；
		nc_id改成：cluster_id-nc_id
	* action的执行从AbstractExecuteAction的doExecute()方法开始，具体实现由子类action的execute方法处理。
		
	- snapshotid等格式设计(API)
	- add_disk时解析并拆分用户传入的snapshot_id
		处理请求的snapshot_id和响应结果中的device_no
		cluster_id由用户传递过来，那个地方需要用到？
		AddDiskExecuteAction

	- 查询VM设备接口，返回的device_no格式变成cluster_id-device_no
		query_vm_device
		QueryVmDeviceExecuteAction

	- 创建snapshot接口，解析并拆分传递的device_no参数
		CreateSnapshotExecuteAction
	- 取消创建snapshot接口，解析并拆分传递的snapshot_id参数
		CancelCreateSnapshotExecuteAction

	- 查询设备已有的快照接口(list_snapshot)，解析并拆分传递的device_no参数，并修改返回值中snapshot_id的格式
		ListSnapshotExecuteAction
	- 查询快照详情接口，解析并拆分传递的snapshot_id参数，并修改返回值中snapshot_id格式
		DetailSnapshotExecuteAction
	- 删除快照接口，解析并拆分传递的snapshot_id,device_no参数
		RemoveSnapshotExecuteAction
	- 回滚快照接口，解析并拆分传递的snapshot_id,device_no参数
		RollbackSnapshotExecuteAction
	- 保留快照接口，解析并拆分传递的snapshot_id,device_no参数
		RetainSnapshotExecuteAction
	- 查看已挂载的快照接口(list_mounted_snapshot),修改返回值中device_no格式
		ListMountedSnapshotExecuteAction
	- 挂载快照接口(mount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		MountSnapshotExecuteAction
	- 卸载快照接口(unmount_snapshot)，解析并拆分传递的snapshot_id,device_no参数
		UnmountSnapshotExecuteAction
	- 在线迁移接口( live_migrate_vm),解析并拆分传递的nc_id参数
		VmLiveMigrateExecuteAction
	- 故障迁移接口，解析并拆分参数destination_nc,destination_rack，并修改返回值中nc_id格式
		recover_vm
		VmRecoverExecuteAction
		
	- 查询可切换的nc接口，修改返回值中nc_id格式
		QueryAvaliableNcsExecuteAction
	- 查询nc详情(detail_nc)接口，解析并拆分传递的nc_id参数，并修改返回值中nc_id格式
		到houyi-openapi.xml找对应关系
		SingleNcResourceAction
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day48 Wednesday, May 23, 2012

1. 
	* big region需求分解，要做哪些工作？
		- 拦截器处理region时，根据： cluster_id-device_no； cluster_id-device_no-snapshot_id； cluster_id-nc_id
		   得到cluster_id，再到zone表查询得到region_no,再到region表得到小region信息(对外大region，内部暂还是小region)。
		- 设计文档

	* slb后端文档修改：
		create_rule: rule_list中去掉rule_name字段
			相关的delete_rule的修改：
				去掉原来的rule_name_list 改为 domain_list
			query_rule_info文档说明修改
		config_rule: domain由可选改为必选

		open api文档需要做相应修改
2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day49 Thursday, May 24, 2012

1. 
	* 继续迭代1文档及action流程整理


2. select * from `group`
group是mysql的关键词

3. visio描述简单流程图


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day50 Friday, May 25, 2012

1. 
	* 文档整理，今天整理结束
		文档根据项目模板文档要求修改
	* uml seq图流程基本类似，修改相应地方即可
	* slb后端 待？
	昨天跟aliyun.com的同事讨论之后，对query_healthcheck这个接口做了比较大的调整。已经提交了。你们注意相应的修改。
	另外 之前讨论所提到的“将一个rs从slb中删除”的接口(release_rs)，一直漏了，今天也添加到文档中了。
2. 业务关键点 理解 大region
	add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过snapshot_id得到其所属的region，然后进行相应操作

	这也是大region需要参数修改，参数如是修改的目的。-tip-

	大region需求分析：
		小region时,open api根据用户传入的资源（region_no）来定位region信息，后续的操作都是在此小region内执行的，即不跨region调用。
		随着业务增长，小region已不能满足业务上需要容纳更多的vm的需求，现需要在open api层实现跨region调用，这样对外就是一个大region，
	open api下一层还是小region结构。
		由上面跨region调用的需求结合内部是小region实现，现通过修改接口参数（在参数上携带cluster_id）以便open api通过请求参数定位资源
	所在的region，从而完成跨region操作。（比如：add_disk操作时如果instance和快照不在同一个region里，通过vm_name得到instance信息，通过
	snapshot_id得到其所属的region，然后进行相应操作），同时对应返回结果也做相应调整。


3. houyi open api部分在内部文档，或者过期文档中
	比如：list_mounted_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Monday, May 28, 2012

1. 
	* big region 参数修改文档再修订，加入4个接口修改说明
		修改文档
	* slb release_rs接口实现包含测试用例，并修改相应文档
	* meeting，修改文档
	
2. 添加4个接口
	解析并拆分创建VM（create_vm）接口用户传入的nc_id和rack_id参数
		
	解析并组装list_vm_status接口返回的nc_id
		
	解析并组装detail_vm接口返回的rack_id，nc_id
		
	解析并拆分调用remove_disk接口用户传入的device_no参数
		
		
3. spring 编程式事务

4. 业务 概念 清晰
	VM	Virtual Machine	虚拟机	通过物理服务器，采用虚拟化技术虚拟出来的计算机
	RS	Real server	后端服务器	用来做负载均衡的VM服务器

	2个对比，理解rs即用于slb的vm，实际就是vm。
	
	add_rs即添加一个vm作为slb负载均衡用~ 
	release_rs即在负载均衡集群中去掉一台vm（这里的去掉应该就是删除vm自身，具体看下面说明）

	delete_rs是从rspool删除rs，release rs是前端删掉一台vm后，清掉所有与他相关的slb配置，
	包括rspool里的rs，也包括loadbalancer里的vm
	
	zone属于某个region，是多对一的关系，cluster_id和region_no是一对一

	houyi api部分涉及权限的操作是在zone内进行的，即不跨zone，比如：迁移，

5. NIO
	解决同步IO资源耗尽问题 ，open api 等场景部分优化
	消息
	并发处理
	阻塞操作
	http://www.cnblogs.com/phoebus0501/archive/2010/12/05/1897245.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day51 Tuesday, May 29, 2012

1. 
	* 在处理参数时，注意新老存储的调用兼容性 ，比如老存储的api调用是没有snapshot_id参数的，如果解析抽象出来要
	考虑到这个情况。
	
2. 
	几个概念
		cluster	一个集群
		rack		机架
		region	数据中心	代表一个数据中心或者Houyi集群，不同数据中心的VM不能相互访问
		zone		安全域		代表一个安全域，不同安全域的VM不能进行数据迁移
		group	安全组		VM相关的安全组，一个VM一定属于某个安全控制组

	之间的关系理清楚？
		* 一个cluster对应一个region(小region)，多个region对外统一为一个大region
		* region和zone是一对多的关系？zone是网络用的概念，一个region下有多个zone，zone和cluster_id是一对一关系
		* region与group是一对多关系 ( group表中有region_no,user_id字段)
		* 从user层面看，user_id与group是一对多关系，某个user_id的group可以跨region
			目前，权限是对group授权(后面再加上到vm的授权)，
			授权源group的某个端口可以在公网(或者私网)网口通过某种协议访问目标group的某个端口的规则(accept，drop，reject)。
		* 
	tip：
		可以从库表中反应它们间一定的关系 :)
	
	api层只有region的概念，houyi后端有cluster_id概念？
	
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day52 Wednesday, May 30, 2012

1. 
	* 基于参数修改设计文档，设计逻辑实现：
		- 对于组合参数的解析，提供静态一个工具类方法，传入参数值和预知的组合个数，返回参数值依据“-”分割
			 后的结果数组
		- 封装一个service用于查询从cluster_id得到region_no
		- 返回值的处理封装：在action层统一处理，实现方式：
			在action的父类里实现，提供一个公用的方法处理。
		- 尽量避免不必要的网络交互（eg：访问数据库，访问网络上的其他service服务）
		- 
	* 整理houyi open api定位到region的规则
			现有2个api，北京那边api（不升级），杭州这边api（要升级），准备在2个api之上，用一个类似路由程序来统一接受访问api的请求，
		并根据预定规则，将请求转发给老api或者新api，故需要整理这个路由的规则，让其能判断某个请求是到老api还是新api的？
			新老版本如何共享一个DB？
				有没有表操作冲突，看数据库的改动。
			规则分析如下：
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				可供识别的条件有：（类似RegionAwareIntercept定位region的逻辑）
					- 首先根据所查询的资源(open api库)
						1) vm_name - 根据vm_name查询instance表
							select
								d.instance_id,d.instance_no,d.image_id,d.status,d.status_comment,d.ip_address,d.group_id,d.node_id,d.mount_type,d.type_id,d.usage_type,
								d.user_id,d.kernel_id,d.ramdisk_id,d.platform,d.passwd,d.start_to_passwd,d.gmt_modified,d.gmt_create,d.remark,d.zone_id,d.vlan_no,d.region_no,
								d.group_no,d.bps,d.rx,d.tx,d.rx_pub,d.tx_pub,d.cores,d.mem,d.disk,d.image_device_no,d.recoverable,d.ballon_enable,d.recover_policy,d.rack_id,d.safety_quota,d.intensive_io,
								d.hostname,d.intensive_cpu,d.intensive_net,a.image_no,a.image_name,a.location as image_location,a.version as image_version,a.services_sign as image_servicesSign,
								a.image_size,a.base_image_id,a.snapshot_id,a.sys_driver,a.region_no as image_region_no,a.iso_id as iso_id,b.image_no as kernel_no,b.image_name as kernel_name,b.location as kernel_location,c.image_no as ramdisk_no,c.image_name as ramdisk_name,
								c.location as ramdisk_location,k.key_pair_id,k.key_pair_name,k.public_key,d.nc_id,d.machine_no,d.machine_no,d.is_balloon,d.is_migrate,d.is_upgrade,d.startup_mode
							from instance d
							left outer join image a on d.image_id=a.image_id
							left outer join image b on d.kernel_id=b.image_id
							left outer join image c on d.ramdisk_id=c.image_id 
							left outer join key_pair k on d.key_pair_id=k.key_pair_id 
							where d.instance_no=#value#
							?instance_no不是region_no

						2)  ip - 根据ip查询zone_ip表得出ip所在的段的记录，从而得到其所属region
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #value# and ip_end >= #value#
							limit 1

						3)  group_no  根据group_no,user_id,region_no查询group表（由于需要region_no，故此资源的操作可被region_no代替）
							select 
								group_id,
								group_no,
								user_id,
								description,
								region_no 
							from `group` 
							where user_id=#userId# and group_no=#groupNo# and region_no=#regionNo#
							order by region_no,group_no desc

						4)  ip_segment 根据CIDR地址ip地址查询zone_ip表
							SELECT
								zone_id, 
								region_no,
								zone_ip_segment, 
								ip_begin, 
								ip_end
							FROM zone_ip 
							where ip_begin <= #ipBegin# and ip_end >= #ipEnd#
							limit 1
							结果例子：
								| zone_id       | region_no   | zone_ip_segment | ip_begin  | ip_end    |
								+---------------+-------------+-----------------+-----------+-----------+
								| region-test-a | region-test | 10.249.130.0/24 | 184123904 | 184124159 
					- 根据用户请求参数region_no
						region_no - 根据region_no查询
					- 根据调用者（user）
						比如query_region接口只能通过user信息定位region，user信息可以根据session参数查询houyi open api数据库得到
						但是，用户会在北京region和杭州region都有vm吗？

					上面，只是得到了用户所要请求的是那个region，还需要判断这个region是老api的，还是新api的？
						背景：
							原来api只有一个入口一个版本，现在api会有2个入口且版本不一致但DB公用；路由层需要一个映射——根据region转发请求到相应的api。

						是不是需要维护一张region和api地址的映射表，路由根据region_no从此表找到转发地址？

						
			/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
				还要考虑到用户传错参数的情况
				
				结果：
					优先根据region_no定位老api（北京）还是新api（杭州）
					再根据vm_name
					最后根据user所在的region

					要维护region和其对应的是老api，还是新api类型的映射关系表，不然只能到各自数据中心的region表查询是否存在，目前只部署一个点，
					故可以从唯一的库中查询。

2. 对于修改设计的实现设计部分细节分析
	* 返回值修改
			现有逻辑，已有一个从后端调用结果到api结果pojo对象转换的逻辑(在action层中，有的是map方式转，格局返回类型不同转换方式各异)，
		可以考虑在后端数据类型转换为api pojo时，进行我们需要的参数修改需求。eg: SnapshotApi
			现在，在那个位置统一处理好？影响小，透明化，易理解，好维护
				- 现定义在返回执行统一转换
				- 被转换的源类型包含多种(map,list,其他)
					通过方法多态，提供通用几种类型的方法，对于参数个数不一致，通过可变长参数实现
				- 被转换参数一个或者多个

			
3. houyi open api常量类设计分析
		对于一些常量，状态值的设计定义，减少硬编码：通过枚举定义一些常量，或者一组状态；通过一个接口定义枚举
	基本机构。
		* 枚举定义一些基本常量 eg: InstanceStatus定义vm的状态（待启动，启动中，运行中等）
		* 如果在上面基础上需要组合一组常量，为一个状态，通过往枚举的构造总放入数组即可
			eg: InstanceStatusSet定义vm可启动状态集合（包含：待启动，启动失败，已停止3个状态）

4. api操作权限控制 acl	
	通过注解设置service操作权限，再通过在spring里配置此注解到pointcut，拦截操作，判断权限
	
	spring + annotation + aop 实现权限与业务分离，注解配置权限点，通过aop拦截包含这些注解的方法的执行，校验权限，继续执行。
	被操作的对象（比如instance）有属性InstanceStatus（instance状态常量定义枚举）标记其状态，拦截器判断被操作的instance是否在允许的
	状态中，以判断操作是否可进行（比如mount_disk操作，instance只能在特定的状态下）。

	key words: expression="@annotation(
	
	<bean id="resourceQueryFacade" class="com.aliyun.houyi.acl.ResourceQueryFacade"/>
	
	<bean id="resourceSurveyor" class="com.aliyun.houyi.acl.ResourceSurveyor">
    		<property name="resourceQueryFacade" ref="resourceQueryFacade"></property>
	</bean>

	<bean id="instanceStatusInterceptor" class="com.aliyun.houyi.service.rule.InstanceStatusInterceptor">
		<property name="resourceSurveyor" ref="resourceSurveyor"/>
	</bean>

	<aop:config>
		<aop:pointcut id="instanceStatusPointcut"
			expression="@annotation(com.aliyun.houyi.service.rule.InstanceStatusConstraint)" />
		<aop:advisor advice-ref="instanceStatusInterceptor"
			pointcut-ref="instanceStatusPointcut" order="10" />
	</aop:config>	
	
	参考：http://raulraja.com/2009/06/13/aop-spring-intercepting-method-calls-using-annotations/


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day53 Thursday, May 31, 2012

1. 
	* region定位规则，并细化步骤，便于路由部分参考
		实现可以不一样，逻辑基本一致。
	* 除了db公用冲突分析外，是否还有其他地方需要考虑？
		考虑大region关于open api的需求还有那些地方可能会影响？
			迭代2,3需要评估
	* 后端mock：
		调用houyi后端的mock实现。
		对 ApsaraCommandExecutor 进行mock
			保证传递进去的参数是正确的，mock出预期的返回，便于测试。
	* 迭代2

	* slb release_rs接口url及参数名称修改 done
	
2. 
	分析迭代2部分需求：
			原来的概念，上了大region都会改变，比如原来查询某个region下某个zone中的vlan信息，大region后
		要查询的就是这个用户在大数据中心所有的zone下的vlan信息。
	

3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day54 Friday, June 01, 2012

1. 
	* 迭代1新增需求分析
		1）不停机升级云服务器配置，重启生效	API对modify_vm接口操作的VM前置状态增加running条件 1
		2）SLB的L4 VIP不能配置健康检查的问题 1
		3）因为machine_no（随机字段）这个值存在重复性，启用新的算法(类似于UUID类的算法)，保证生成的machine_no是不会重复的 2
		4）支持动态添加新region信息，不需要重启 1  动态添加新region信息
			是否有添加region这个接口？
				houyi.region表是手动插入记录
				没有这个接口，需要设计方案；RegionValuesFactory里的region缓存，如何在region表手动插入记录时，更新RegionValuesFactory里region
				缓存？
					a. 定时刷新
					b. 缓存找不到就去数据库找，若找到则加入缓存，找不到则返回相应的结果。




	* 迭代2需求，各接口流程梳理
	* 查询slb后端业务表的数据源，可能有多个的情况，配置在数据库中，根据不同的slb region调用不同的数据源。？待
2. 
	slb 测试环境：
		
		mysql
			mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi

	http://workflow.it.alibaba-inc.com/StartWorkflow.ashx?wfid=dfdd6d75-e539-4cb6-a289-a01eaaa5b426
	服务类型，新开令牌；需求权限，内网默认权限

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day55 Monday, June 04, 2012

1. 
	* 迭代1新增需求分析 见day54第1条
		详见迭代一新增需求文档（doc）
	* 将分支：http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_btc_migrate/中clear_cache接口代码加到分支	
	   http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_update_struts上。
		拉api_update_struts的代码，并更新上clear_cache接口
	* slb后端会部署多个slb，每个slb对应一个计量库，一个业务库； 参考day42 slb 流量
		一个slb对应多个vm，每个vm可能位于不同的region。
		每个slb都会有这2个库，故需要根据不同的slb查询不同的地址。和slb 的region是一对一的，即一个slb region对应一套库（包含计量数据的库 和 业务数据库）；
		？
		monitor_datasource表，就是保存了每个slb，其region_no对应的取流量数据库的地址映射。
			monitor_datasource的region_no指的是slb的region，不能和vm的混淆；region表里都是slb的信息，唯一vm和slb region有关系的就是region_mapping表，表示了vm region和slb
			region的映射。

		参考解决方案：
			1）在monitor_datasource表加个type字段，用以标识slb后端数据库类型（0-业务库；1-计量库）；在LBMonitorSqlMapTemplateFactory里，
			     初始化slb region对应的2个库的sqlmapclient实例。
			2）slb后端提供查询接口，这样传入user_id，分页参数即可（region表定义了到那个url上去取数据）
	* slb open api bugfix
		delete_loadbalance 接口，同时清除LoadBalancer相关的配置——对应open api层也要清理rs表。

2. redmine 任务列表
	拉分支 ：
	【代码SVN路径】
		houyi-api: http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_big_region
		控制系统：http://svn.alisoft-inc.com/repos/alisoft/houyi/ec/houyi/branches/ec_big_region
	
	list_vlan 第三周期？

3. cache不便于查找 缓存方案 cache方案
	RegionValuesFactory - CachedRegionValuesFactory 
	region 缓存

	如果系统有多处需要使用cache，可以考虑使用一种cache框架，统一cache使用方案。-tip-
		参考：http://www.cnblogs.com/ieage/archive/2012/05/20/2509454.html

4. maven 跳过test ？
	No goals needed for project - skipping


5. LB,RS,RS_POOL,VIP之间什么关系？待
	从delete_loadbalance接口需要删除那些相关东西入手
	
	看下面query_rs_ pool_info的结果截取：
		{
		"name":"testpool1",
		"protocol":"http",
		"port":80,
		"vips":[{"lb_id":"1377236b076-region1","frontend_port":80,"rules":["www.wqwqwq2.com","www.wqwqwq1.com","www.wqwqwq3.com"]}],
		"realservers":[{"address":"192.168.1.28","weight":100}]
		}
	一个rs pool对应多个vip，多个rs
	删除LB,是否也删除rs_pool？不用，rs pool为用户自己管理
	删除rs pool时，需要删除rs。
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day56 Tuesday, June 05, 2012

1. 
	* 迭代一开发 开始
	* slb open api bugfix
		表修改：
			alter table rs modify column vm_name varchar(50);
			alter table rs modify column ip varchar(15);
			alter table rs modify column lb_id varchar(110);
	
2. 迭代一开发记录
	结果处理：
		操作成功才需要修改返回内容，操作失败时，只返回错误码和状态，没有结果。
	返回码修改：
		由于参数格式修改，需要修改部分返回码的错误提示。
	结合jtester框架测试
		service层mock后端执行的返回值：mock后端返回值
			后端返回格式，参考每个command里的代码，比如：CreateSnapshotCommand ，这些命令都继承自 AbstractCommand
	service层的测试，对于内部私有类，可以通过替sprintg配置来实现mock。
		如果mock返回的类型不是预期，可以考虑让mock类实现相应的接口。
	测试环境
		测试依赖的配置文件，有一部分在用户目录下，需要在spring配置文件中配置正确。

	- 4.2	查询VM的设备接口（query_vm_device）
		* /houyi-console-service/src/main/java/com/aliyun/houyi/service/impl/InstanceServiceImpl.java
			queryDevice方法修改
		* zonedaoimpl
		* ZoneDaoImplTest
			jtester测试通过
		* zoneservice / zoneserviceimpl
		* /houyi-console-model/src/main/java/com/aliyun/houyi/entity/Zone.java 加上clusterId属性
		* zone表加cluster_id字段【sql 修改】
			alter table zone add cluster_id varchar(32) NOT NULL;
		* /houyi-console-util/src/main/java/com/aliyun/houyi/util/ResultParseUtil.java 工具类 ，处理返回值装配
		* QueryVmDeviceExecuteAction
			取得cluster_id，修改返回值
			待测
				dao
				service
				action
				util工具类
					单元测试通过
	- 4.3	磁盘创建snapshot接口（create_snapshot）
		* 修改错误码：
			SnapshotErrorMessage
			DEVICE_IS_NULL(-900, "device No. is null"), ——》 改为：DEVICE_IS_NOT_ILLEGAL(-900, "device No. is not illegal"),
		* CreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"), DOC
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		* 修改错误码：
			SNAPSHOT_IS_NULL(-920, "snapshot is null"), ——》改为： SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"),
		* CancelCreateSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
	- 4.1	add_disk接口
		* AddDiskExecuteAction
			待测
		状态码增加：
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "), DOC
		

3. maven 跨项目test
	独自测试依赖问题？

4. jtester测试 参考： * jtester

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day57 Wednesday, June 06, 2012

1. 
	* 迭代一开发
	* slb bugfix
		slb后端对于错误的url就直接返回原始错误，比如404之类；这样，open api这里需要保证url的准确性。

2. 迭代一开发记录
	- 4.5	查询设备已有的快照接口(list_snapshot)
		ListSnapshotExecuteAction
			待测
		状态码增加：
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),  DOC
	- 4.6	查询快照详情接口（detail_snapshot）
		SnapshotService
			mock测试
			主要是mock每个action相应的command执行结果，这个结果参考相应action的command中处理返回值的代码。比如：此接口参考 QuerySnapshotCommand （由于缺少后端接口说明）结果处理，处理结果
			？

		DetailSnapshotExecuteAction 
			待测
		状态码修改：
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法			
	- 4.7	删除快照接口（remove_snapshot）
		AbstractSnapshotExecuteAction 涉及deviceNo，需要修改
		RemoveSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法	
	- 4.8	回滚快照接口（rollback_snapshot）
		RollbackSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法		
	- 4.9	保留快照接口（retain_snapshot）
		SnapshotService
		RetainSnapshotExecuteAction
			待测
		状态码修改：
			DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), DOC
				device_no为空或格式不合法
			SNAPSHOT_ID_IS_NOT_ILLEGAL(-920, "snapshot id is not illegal"), DOC
				snapshot_id为空或格式不合法

3. spring，资源文件加载 问题
	如果导入资源文件的配置文件没有初始化，提前处理调用资源文件会报错：
		eg: jtester抽象父类，初始化spring context时。

	mock复杂的私有内部类时，通过新建一个类（继承原来的类）来mock，配置时初始化由于早于属性文件导入，报了错。放到属性文件加载之后即可。

4. 设计中测试的考虑


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day58 Thursday, June 07, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		SnapshotService
		ListMountedSnapshotExecuteAction
			待测
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotService
		MountSnapshotExecuteAction
		？snapshot 和 snapshot_id混用？
			String snapshot = ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT);
			if(StringUtils.isEmpty(snapshot)){
				 snapshot=ParameterValueGetter.getParameterValue(params, SnapshotParameter.SNAPSHOT_ID);
			}
			—— 查看过期API，是因为兼容老api，snapshot已废弃被snapshot_id替代
				按照当前逻辑，如果新旧参数都传了，还是以旧参数为准 ，其他接口一样，这点要注意。（以最新参数为准较好？）
		状态码修改：
			ILLEGAL_DEVICE_NO(-901,"illegal device no") DOC
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id ") DOC
	- 4.13	在线迁移接口( live_migrate_vm)
		InstanceService
		VmLiveMigrateExecuteAction
		状态码修改：
			增加错误码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), 表示迁移时需要在同一个region中 ？ DOC
					迁移目标NC和当前instance不在同一个region中
					注：这个与对外是一个大region矛盾，是否处理可迁移的nc列表，不包含不可迁移的nc？还是只供内部用？
				ILLEGAL_NC(-731,"illegal nc"),
			待测
	- 4.15	查询可切换的nc接口（query_available_nc）
		QueryAvaliableNcsExecuteAction
			待测
	- 4.16	查询nc详情(detail_nc)接口 (houyi-openapi.xml)
		NodeControlService
		SingleNcResourceAction
		状态码修改：NcErrorMessage 
				NC_NO_IS_NULL(-730, "nc_no is null"), —— 》NC_NO_IS_NOT_ILLEGAL(-730, "nc_no is not illegal"), DOC
			待测
	- 4.17	创建VM（create_vm）接口 
		VmCreateExecuteAction
			逻辑在getInstanceInfo方法里
		RackServiceImpl
		状态码修改：
			增加状态提示：
				GlobalErrorMessage NO_IN_THE_SAME_REGION (-142, "not in the same region"), DOC
				当rack的region和nc的region不一致时报错。
			待测
	- 4.14	故障切换接口（recover_vm）
		状态码修改：
			增加状态码：
				NcErrorMessage RACK_ID_NOT_ILLEGAL(-719,"rack is not illegal"), DOC
					rack_id格式不合法（destination_rack）
			增加状态码：
				GlobalErrorMessage NO_IN_THE_SAME_REGION(-142, "not in the same region"), DOC
					nc region 和intance region不一致。
		InstanceServiceImpl
		VmRecoverExecuteAction
			待测
	- query_racks action也要改动？ 多态一个，此接口暂不变。

3. 对于service层的 public CommandExecutor commandExecutor; mock费了不少时间，由于此属性的注入方式是通过一个工厂（CommandExecutorFactory）获得（spring的beanfactory接口的实现）
mock这个工厂取得commandExecutor对应的实例对象时，返回的却是这个工厂的类型，不是CommandExecutor的实现类。
		工厂内部通过一个私有内部类来得到真正的CommandExecutor实现类（不便mock），最后通过把这个工厂类的配置单独提出来，写一个mock类继承CommandExecutorFactory，并测试时
	配置为工厂的mock类，这样测试能通过。
		但是这个工厂需要根据场景返回不同的CommandExecutor实现类，不便于每次测试去修改mock类。
		debug发现在测试类中再去mock一下这个mock类时，返回的是其自身，转型时不能转为CommandExecutor类型，于是让这个工厂mock类实现CommandExecutor接口。
4. 
	拦截器mock
		如果不便于mock，则找到其内部关键点进行mock。
	mock里面嵌套mock 是否可行？不必要，正确mock了某个类，可以忽略其内部逻辑。

5. mock 与 expections 结合 jmockit ,jtester
	mock对象，编写期望 expections 。
		-------
		...
			@SpringBeanByName
			QueryVmDeviceExecuteAction query_vm_device;
			
		//	@Mocked
		//	@SpringBeanFor
		//	InstanceService instanceService;
			
			@Mocked
			@SpringBeanFor
			ZoneService zoneService;
			
			@SuppressWarnings("unchecked")
			@Test
			public void testExecute() throws Throwable{

				final Result<PagingInfo<DeviceEx,DeviceEx>> expectedDeviceResult = new Result<PagingInfo<DeviceEx,DeviceEx>>();
				expectedDeviceResult.setSuccessful(true);
				expectedDeviceResult.setResultInfo(new PagingInfo<DeviceEx, DeviceEx>(){
					@Override
					public List<DeviceEx> getItems() {
						List<DeviceEx> list = new ArrayList<DeviceEx>();
						list.add(new DeviceEx(10,1024,"System"));
						list.add(new DeviceEx(11,512,"System"));
						list.add(new DeviceEx(12,256,"System"));
						return list;
					}
				});
				
				final String expectedClusterId = "testClusterId";
				final ResultMessage expected = ResultMessage.SUCCESSFUL;
				
				final Instance instance = new Instance();
				instance.setInstanceNo("testNo");
				instance.setStatus(InstanceStatus.Running);
				
				final ResultDomain resultDomain = new ResultDomain(200, "successful");
				
				UserHolder.setCurrentUser(new User());
				RegionHolder.setCurrentRegion(new Region());
				
			new Expectations(){
				{
		//        		when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
					when(zoneService.queryClusterIdByZoneId(anyString)).thenReturn(expectedClusterId);
				}
				@Mocked(methods="queryDevice")
				InstanceService instanceService;
				{
					when(instanceService.queryDevice((Instance)any)).thenReturn(expectedDeviceResult);
				}

			};
				
				ResultMessage result = query_vm_device.execute(instance, null, resultDomain);
				
				Assert.assertEquals(result, expected);
				Assert.assertEquals(((List<DeviceApi>)resultDomain.getData().get("devices")).get(0).getDevice_no(), expectedClusterId+"-10");
			}
		...
		-------
	分析上面的测试用例代码的 instanceService 部分：
		如果要mock instanceService的某个方法，可以在属性里定义mock；如果只是想测试一个调用期望，可以写在expections里（录制-重现），以验证是否被调用。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day59 Friday, June 08, 2012

1. 
	* 迭代一开发

2. 开发记录
	- 继续 create_vm接口
		
	- 继续nc详情
	- 

3. mock 测试 
	代码里计量显式的传递变量，尽量少与第三方的代码耦合，否则耦合度高，同时也不利于单元测试。
		比如struts框架的 ServletActionContext 便于读取action的上下文，尽量只在入口处调用，不是每个地方都去调用这个类。逻辑尽量紧凑。

		即尽量减少与容器耦合。否则那些个特殊类都需要去mock（eg:session.rquest,respone....）

	测试一个action时，可通过mock其父类的方法来便于测试。
		利用mock框架的只对特定方法mock能力。

	mock某个类，那么spring 的注入就失效了（=null）

	* 对于静态方法，全局变量，可以再运行时设置进去。
		比如struts2的actoncontext，可以自己注入一个用于测试：
			ActionContext.setContext(new ActionContext(params));
	
			ActionContext.getContext().setParameters(params);
	
	* 下面2个方法的声明，就关于params参数的设置，看哪个好测试？
	（1）
		@Override
		public ResultMessage execute(Instance instance, Map<String, Object> params,
				ResultDomain resultHolder)
		{
	（2）
		@Override
		public ResultMessage execute()
		{
			Map<String, Object> params = ActionContext.getContext().getParamters();
		很明显，第一个测试时传入即可，第二个却要去自己访问第三方类，设置值，如果不方便设置就囧了~~~
		对于确实依赖第三方的地方，可以统一包装使用（通过参数传递进来），不零散调用。比如抽取到工具类中去。朝着低耦合，高内聚的目标走
4. 问题
	VmCreateExecuteAction.
		try{
			 image = super.getResources(Image.class, imageNo);
		}catch(ResourceUnfoundedException e){
			 image = imageService.queryCustomImageByImageNo(imageNo);
		} 
		？异常做逻辑处理？
	或者抛出，结束执行，或者捕获，日志，继续执行。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day60 Monday, June 11, 2012

1. 
	* 迭代一开发
	* 补偿迭代一单元测试
	* SLB open api原查询后端业务表的逻辑修改：
		不查询SLB后端业务表，改为从查询LoadBalancer列表(list_lb)接口获取需要的信息：
			a. 
			b. 

2. 开发记录
	- 4.18	查询用户所有VM状态（list_vm_status）接口  ？ 当前还只是返回指定region下的所有vm状态，待到后面迭代实现返回大region下信息
		QueryVmListInfoExecuteAction

	- 4.20	删除云硬盘(remove_disk)接口
		RemoveDiskExecuteAction
		InstanceService
		状态码修改：
			增加：SnapshotErrorMessage DEVICE_NO_IS_NOT_ILLEGAL(-900, "device No. is not illegal"), 错误码  DOC
	4.19	查询VM详情（detail_vm）接口
		VmQueryExecuteAction
		InstanceService修改queryInstanceAtNc方法
		InstanceService修改queryInstancePublicIp方法
		

3. 单元测试补充记录
	- CancelCreateSnapshotExecuteAction
		SnapshotService 的cancelCreateSnapshot方法 done
	- CreateSnapshotExecuteAction
		snapshotService.createSnapshot
	..具体见redmine

4.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day61 Tuesday, June 12, 2012

1. 
	* 迭代一开发 +　单元测试补偿
	* 迭代一接口的状态码修改，更新到设计文档中 ？待
	
	* SLB OPEN API bug修改
		检查请求后端的URL的正确性，比如某些关键参数为空的话，则URL请求返回404等错误，后端没有处理，open api需要处理。
		monitorInfoService 已处理一个方法，还有个得到分页的user lbs方法 待？
			listLoadBalancerFlows 接口：
				- slb流量接口，当前逻辑是查询统计所有流量数据，如何根据lb_id分页匹配数据，响应client。
					后面可以优化根据需要查询的lb_id的流量进行真分页查询。？
						先得到分页的lb_id列表，然后到后端流量表一次性查询对应的流量数据。
				- 此接口获取lb_ids的逻辑改为从list_loadbalances接口间接获取，排序后分页，返回。


2.  开发记录
	新增接口修改：没有列入参数修改设计文档，根据redmine开发：
	vlan_no 改为 cluster_id-vlan_no 涉及到 create_vm 也要修改
	- 查询虚拟网络信息（list_vlans），修改返回值(vlan_no改成cluster_id-vlan_no)
		VlanQueryAction

3. mock 测试
	测试框架提供了部分，常用J2EE框架的mock类 比如 ：HttpServletRequestSimulator ，用于测试struts时模拟request对象。

4. 设计 ，id，name ，。。。命名统一，或者叫id或者统一name。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day62 Wednesday, June 13, 2012

1. 
	* slb bug fix
	* 迭代一接口的状态码修改，更新到设计文档中 doing
	* 迭代一  补充接口处理	redmine没录入？
		- 4.12	卸载快照接口(unmount_snapshot)
	* SLB后端数据格式修改？
		查询用户lb列表：
			{\"code\":200,\"msg\":\"successful\",\"lbs\":[\"lb1\",\"lb2\"]}"); 由统一的data字段表示数据，改为lbs 。？

	* houyi open api 参数修改部分，某些参数不是必选的？逻辑需要考略 
		参考原有逻辑，处理可选参数。
	* 状态码修改补充
		原状态码不变（尽量减小对客户端的影响），新增需要的状态码：
			device_no is illegal	device_no参数格式不合法
			nc_no is illegal	nc_no格式不合法（cluster_id-nc_no）
			not in the same region	xxx的region和xxx的region不一致
			rack is illegal	xxx rack格式不合法（cluster_id-xxxrack）
			snapshot id is illegal	snapshot_id格式不合法

			device_no is illegal  device_no参数格式不合法
			ILLEGAL_DEVICE_NO(-901,"illegal device no"),

			 nc_no is illegal nc_no格式不合法（cluster_id-nc_no）
			ILLEGAL_NC(-731,"illegal nc"),

			 rack is illegal    xxx rack格式不合法（cluster_id-xxxrack）
			ILLEGAL_RACK_ID(-721, "illegal rack id") ;

			 snapshot id is illegal         snapshot_id格式不合法
			ILLEGAL_SNSPASHOT_ID(-921,"illegal snapshot id "),

			vlan_no
			ILLEGAL_VLAN_NO(-191, "illegal vlan_no"),;

	之前的状态码修改 ，修改为上面的格式。
	
2. 文档管理

3. 数组操作
	Arrays 工具类 collections 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day63 Thursday, June 14, 2012

1. 
	* 迭代一单元测试补充
	* umount_snapshot接口实现
	* slb  api bugfix
		及文档修改
			错误提示都修改为驼峰式。eg: NameIsEmpty 
	* 迭代一
		可选参数，逻辑处理检查 done

2. 补充
	- umount_snapshot 卸载快照接口
		UnmountSnapshotExecuteAction
		SnapshotServiceImpl
		状态码增加：
			-901	illegal device no	device_no格式不合法 DOC
			-921	illegal snapshot id	snapshot_id格式不合法 DOC
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day64 Friday, June 15, 2012

1. 
	* 动态添加region，不重启 ,
		具体需求为：添加region表的信息，添加region对应的monitor_datasource信息
		day54 no.1		
		RegionValuesFactory
			单元测试（region缓存初始化后，往数据库插一条新region记录，验证缓存中不存在就去数据库查找并存入缓存的逻辑）
		下半部分需求分析：
			- DefaultClcEndpointLoader （通过regionDao得到region_no与nuwa地址的map）
			- CommandExecutorFactory 根据上面的map，初始化 executors：
				this.executors = new HashMap<String, CommandExecutor>();
			- 上面的 executors 每次调用时根据regionNO返回对应的操作后端的 ApsaraCommandExecutor
				CommandExecutor executor = executors.get(regionNo);
			
			所以，更新 executors 即可将新region的monitor_datasource添加到缓存中。
				由于对外没有提供修改 executors 变量的入口，考虑通过反射来动态设置 executors 。
				这个逻辑的触发放到哪里？
					谁最先知道有了新region？
					分析代码知道，RegionAwareInterceptor 最先执行（需要通过 RegionValuesFactory 来查询用户请求中的region信息），所以，上面的逻辑触发
					放到 RegionValuesFactory 动态加region信息的逻辑中。
			方案：
				在 RegionValuesFactory 处理新增region的缓存逻辑中，同时增加更新CommandExecutorFactory的executors属性，加上新region的调用对象的逻辑。
			例外情况：
				手动加region表记录和加monitor_datasource记录是不同步的，或者可以理解2者没关系。
				所以上面的触发逻辑，分别处理各自在查找cache的逻辑中实现动态更新。
		
		monitor_datasource和 region，至少2者有各自的作用：
			MonitorSqlMapTemplateFactory 的 monitorDatasources 变量
				ConsistentCircle

	* houyi open api 测试环境
		http://10.250.6.33/open/services?
		key:lisw,secret:lisw

	* houyi open api 
		涉及snapsho的接口，原部分接口逻辑在操作快照时没有对用户是否有权限操作快照做约束，现需要判断：
			- 快照的owner和当前用户是否一致。
			（image是有visibility使用权限设置的，可以设置为私有或公有或者其他定义的类型，快照为私有）

			- 增加判断权限的单元测试
			- 参考 InstanceServiceImpl 的 mountDisk 方法
			- 修改范围：
				迭代一中涉及用户对snapshot操作的接口
			- 验证错误报：
				CLCErrorCode.SnapshotNoPrivilege

2. snapshot权限验证 （对snap操作时都应该验证owner，或是查询或取消创建或删除或挂载。。。）
	然后，上面的验证逻辑是在open api层还是控制层？
		是api自己去一次次查询再验证，还是把需要的参数给后端(user_id,snapshot_id etc..)，让后端来校验并返回给api？
	
	查询快照时，返回前判断快照是否属于这个user：

		DetailSnapshotExecuteAction
			if (!snapshotExt.getOwnerId().equals(
					String.valueOf(UserHolder.getCurrentUserId())))
			{
				ResultMessage message = SnapshotErrorMessage.SNAPSHOT_NO_PRIVILEGE;
				ResultDomain resultDomain = new ResultDomain(message);
				return resultDomain;
			}
	
	？ 需要确认，后端那些做了验证，那些没做验证？

	- 4.1	add_disk接口 done
		InstanceServiceImpl 的mountDisk方法
			done
			判断逻辑：
				snapshotExt = (SnapshotExt) result.getResultInfo();

				/** check permission **/
				if(snapshotExt.getOwnerId().equals(String.valuseOf(UserHolder.getCurrentUserId()))){
					return new Result<Object>(CLCErrorCode.SnapshotNoPrivilege);
				}			
		unit test
			done
	- 4.4	取消创建snapshot接口（cancel_create_snapshot）
		？此接口没有查询快照，直接传递snapshot_id给后端，执行取消快照创建 ，是否需要先查询，判断owner正确，再取消创建？ 待
			或者是后端会根据snapshot_id结合instance信息，判断是否有操作权限？后端确认，“无文档”，验证较好，权限体系
		若api层做验证，参考4.1实现。
	- 4.5	查询设备已有的快照接口(list_snapshot)
		？同4.4，返回的快照列表是否可能是其他用户的快照
			如果后端没验证，open api需要验证
		ListSnapshotExecuteAction
	- 4.6	查询快照详情接口（detail_snapshot）
		DetailSnapshotExecuteAction
		原逻辑已验证，跳过
	- 4.7	删除快照接口（remove_snapshot）
		？同4.4 ，原逻辑也是传递snapshotId给后端，是否需要先查询，再执行
		部分代码：
			RemoveSnapshotCommand command = new RemoveSnapshotCommand(instance, deviceNo, snapshotId);
			return commandExecutor.execute(command,snapshotRegionNo);
	- 4.8	回滚快照接口（rollback_snapshot）
		？同4.4
	- 4.9	保留快照接口（retain_snapshot）
		？同4.4
	- 4.10	查看已挂载的快照接口(list_mounted_snapshot)
		？同4.4
	- 4.11	挂载快照接口(mount_snapshot)
		SnapshotServiceImpl > mountSnapshot
			done
		unit test
			done
	- 4.12	卸载快照接口(unmount_snapshot)
		SnapshotServiceImpl
			done
		unit test 
			done
			


3. api调控制系统的设计
	采用command模式，每个接口都定义为一个command对象，封装了endpoint，参数，处理返回值等逻辑。

	统一由一个执行对象执行。

	action中处理返回值的逻辑，是否可以移到command的处理防护值方法中 职责划分

4. houyi open api 系统
	InstanceServiceImpl > mountDisk
		this.instanceDao.updateInstanceConfig(instance); //没返回值，没log，非理想情况如何处理
	mock？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day65 Monday, June 18, 2012

1. 
	* slb bug fix
		严格按照文档说明来开发，编写单元测试（基于文档）
		- 流量接口 pageNO,pageSize可选，空的话采用默认值。依据文档说明
		- 目前OPENAPI的RS表没有user_id字段，虽然lb_id是全局唯一的，但是rs_pool_name却是用户唯一的，所以光凭rs_pool_name无法唯一确定一个rs_pool，可能会有重复的情况出现。
			rs表加user_id字段，增加删除时都带上这个筛选字段。lb_id ，rs_pool_name都带上对应的user_id
			sql修改
				alter table rs add user_id int(10) unsigned;
	* big region
		svn提交格式：
			fix bug #3243 修复某问题的comments
2. 设计
action的参数验证，可以抽象出来，不用在acton的方法里详细验证

3. 基于文档 ，每个条件/参数都提供测试用例，测试用例覆盖每个错误状态
	理想状态用例
	参数不合法用例
	。。。
4. 实现 ApplicationContextAware 接口的类，在spring初始化时初始化应用的一些缓存等操作时，bean需要配置，以便spring来实例化
	

5. linux部署时，会由于权限问题导致，部署失败，或者部署时，有部分文件没被更新。
需要注意。

6. 整理 slbapi 操作rs表的接口及其操作rs的逻辑（增加逻辑/删除逻辑）
	- add_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
	- delete_rs
		根据vm_name,rs_pool_name和user_id删除rs表记录
	- switch_rs
		根据vm_name,rs_pool_name和user_id增加rs表记录
		根据vm_name,rs_pool_name和user_id删除rs表记录
	-add_vm
		根据vm_name,lb_id和user_id增加rs表记录
	-delete_vm
		根据vm_name,lb_id和user_id删除rs表记录
	- switch_vm
		根据vm_name,lb_id和user_id增加rs表记录
		根据vm_name,lb_id和user_id删除rs表记录
	- delete_lb
		根据lb_id和user_id删除记录
	- release_backend
		根据vm_name 和user_id删除rs表记录
	- delete_rs_pool
		根据rs_pool_name和user_id删除rs表记录


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day66 Tuesday, June 19, 2012

1. 
	* big region 动态添加regin，更新monitor datasource信息
		？更新缓存接口
		逻辑实现 + 测试
		触发条件：
				需要用到各自region的SqlMapClientOperations操作的dao层，都是通过MonitorSqlMapTemplateFactory的 getMonitorDatasource 方法取到 SqlMapClientOperations 进行后续操作，
			故，以 getMonitorDatasource 方法作为触发加载新region monitor datasource的点。
		修改点：
			MonitorSqlMapTemplateFactory 
				public SqlMapClientOperations getMonitorDatasource(String regionNo, String instanceNo){
	* slb rs表测试
	* big region ,根据cluster_id查询region_no时，如果region_no不存在应该报错 ？ 添加验证逻辑
		返回码设计：
			根据不同参数的cluster_id查询region，设计相应的返回码
			- cluster_id-device_no-snapshot_id
				报snapshot_id不存在
			- cluster_id-device_no
				报device_no不存在
			- cluster_id-nc_id
				报nc_di不存在
			- cluster_id-rack_id
				报rack_id不存在
			- cluster_id-vlan_no
				报vlan_no不存在

	* mysql case sensitive
		mysql 区分大小写
		参看下面：
				The default character set and collation are latin1 and latin1_swedish_ci, so nonbinary string comparisons are case insensitive by default. This means that if you search with col_name LIKE 'a%', 
			you get all column values that start with A or a. To make this search case sensitive, make sure that one of the operands has a case sensitive or binary collation. For example, if you are comparing a 
			column and a string that both have the latin1 character set, you can use the COLLATE operator to cause either operand to have the latin1_general_cs or latin1_bin collation:
				col_name COLLATE latin1_general_cs LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_general_cs
				col_name COLLATE latin1_bin LIKE 'a%'
				col_name LIKE 'a%' COLLATE latin1_bin
				If you want a column always to be treated in case-sensitive fashion, declare it with a case sensitive or binary collation.
			from:http://stackoverflow.com/questions/5629111/mysql-case-sensitive-string-comparison
		2种方式实现mysql支持大小写区分
			1) 查询时通过操作符 COLLATE
			2) 建表时声明
		此处选择建表时声明列区别大小写：
			-- 此为更新语句 sql修改
			alter table region_mapping modify column vm_region_no varchar(32) binary NOT NULL COMMENT '@desc vm region_no';  
			alter table region_mapping modify column region_no varchar(32) binary NOT NULL COMMENT '@desc slb region_no';  
			alter table region modify column region_no varchar(32) binary NOT NULL;  
			alter table rs modify column vm_name varchar(50) binary NOT NULL COMMENT '@desc vm name';
			alter table rs modify column rs_pool_name varchar(100) binary COMMENT '@desc rs pool name';
			alter table rs modify column lb_id varchar(110) binary COMMENT '@desc lb_id';
			alter table monitor_datasource modify column region_no varchar(32) binary NOT NULL;

			建表语句类似上面。
				  `region_no` varchar(32) binary NOT NULL COMMENT '@desc slb region_no',

2. monitor datasource相关修改点，测试点
	- monitorDatasource.xml 增加根据region_no查询记录的select语句定义
		MonitorSqlMapTemplateFactory 直接用了这个映射文件（充当dao层）
			测试时测试这个类即可
				测试新增的select
	- MonitorSqlMapTemplateFactory修改 getMonitorDatasource 方法
	
3. bug提交格式 
	fix bug #3243 修复某问题的comments

4. 单元测试覆盖程序的逻辑，覆盖关键点越细，工作量越大，但代码健壮性越强。
	slb这边测试用例只测试几个正常的场景，对一些例外没有写用例，导致qa测试bug。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day67 Wednesday, June 20, 2012

1. 
	*  slb bug fix #122
		先新建lb，然后重现问题
		原因：
			hybird类型 query_loadbalance_info时，返回值中没有vm_list字段
	* slbapi rs表加region_no字段（slb的region），目的在操作rs_pool_name记录时，处理多个slb region_no的rs_pool_name重名情况
		每个rs记录都记录region_no
		sql修改
			alter table rs add region_no varchar(32) DEFAULT NULL  COMMENT '@DESC slb region no';
	* 迭代一 参数修改部分 ，新增2个接口需要修改
		
2. slbapi 测试环境
	mysql -uhouyi -phouyiat03 -h10.230.204.19 slbapi
3. slb测试
	测试的条件能重现，就可以在本地debug

4. SystemError 2100
	slbapi在处理 ip2name时会报这个异常
5. rs表加region_no字段 —— 只在操作rs_pool_name时考虑这个字段
	rs.xml
6. 部署没更新问题
	删除部署的内容后，重新build再部署。
7. 接口测试，单元测试中，可能没有细致到返回结果处理的测试用例，隐藏了
	a. 调用成功
	b. 返回值正确
	c. 处理返回的相应正确

	一套单元测试用例很重要，打好基础，再变更时，处理就很方便；否则，未知数太多，需要QA或运行时才能暴露问题。

8. 迭代一 参数修改 新增接口 文档说明整理
	- 4.22	query_nc_resources接口
		ClusterNcResourceListAction

	- 4.23	query_racks接口
		RackQueryAction

		哪怕是那寥寥几个字节的注释，也能鼓起我看完这漫长代码的勇气~，如果连这点也剥夺，那也就只好苦逼的被一行行、一遍遍的摧残了

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day68 Thursday, June 21, 2012

1.
	* big region 迭代一bug处理
	* big region 迭代一新增2个接口开发
	* big region 测试环境
		请求api的client 位置：
			/houyi-console-openapi/src/test/java/com/aliyun/houyi/openapi/util
		10.242.209.4  api地址
		10.242.209.1 api db
		日志 /home/admin/houyi/service/logs/openapi
		10.250.8.214环境 admin操作
			cd /home/admin/houyi/service
			sh build/build.sh 
			sh bin/reloadws_alone 
			tail -f logs/openapi/jboss_stdout.log 
		配置文件：
			/home/admin/.houyi/

		dev开发测试环境：
			AT-HOUYIDEV-AG 10.250.6.27
			HOUYI-MASTER:10.250.8.212
			HOUYI-NETC:/10.250.6.32
			API:10.250.6.33
			DB:10.250.6.27

			

2. big region 迭代一bug处理
	- detail_vm 返回的vlan_no格式错误 http://bugfree.corp.taobao.com/bug/175626
		原因：设计时丢了vlan_no的格式转换（vlan_no为后续增加待修改参数）
		修改：
			VmQueryExecuteAction
			VmQueryExecuteActionTest
	- 

3.  big region 迭代一新增2个接口开发
	- 4.22	query_nc_resources 接口
		修改：
			ClusterNcResourceListAction
				zone_id的获取？
					AbstractExecuteAction 提供2个重载的 getCurrentZone 方法供action调用，采用哪个无参的方法。（即请求中无zone_no，则取用户默认的zone）
			ClusterNcResourceListActionTest
	- 4.23	query_racks接口
		修改：
			RackQueryAction
			RackQueryActionTest

4. 问题排查
	请求内容 + 错误返回内容 + 日志内容


5. 迭代一 cluster_id 修改整理：	 from mail
	3）cluster_id是否存在需要判断（nc_id,rack_id,vlan_no,device_no,snapshot_id）
	DEVICE_NOT_EXISTS(-905, "device not exists at vm"),
	SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
	NC_NOT_EXISTS(-700, "nc not exists"),
	RACK_NOT_EXISTS(-160, "rack not exits"),
	NC_NOT_EXISTS(-161, "nc not exits"),
	VLAN_NOT_EXISTS(-190, "Virtual Lan not exits")
	4）涉及新device_no，新snapshot_id中都需要判断格式中的device_no是否一致，若不存在，错误码是SNAPSHOT_NOT_EXISTS(-910, "snapshot id not exists"),
		 这个问题建议使用以前的错误码。
		如recover_vm接口，在vm_name和destination_rack 或destination_nc的cluster_id的region不匹配时，复用以前的错误码  -283（not in same zone of vm）
		如list_snapshot接口，在vm_name和device_no的cluster_id的region不匹配时，复用以前的错误码 -905（device not exists at vm ）

	5）需要判断涉及cluster_id与vm_name对应的region是否一致，这个错误码待考虑？
	以下4、5是在不跨region使用snapshot,disk情况下，API层作的权限验证。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day69 Monday, June 25, 2012

1. 
	* 迭代一cluster_id，device_no 验证bug修复
	* slbapi回归bug
		ip转name时，传入了lbId去查询，数据库中lb_id为null，导致ip转name错误；ip转name可以减少限定条件 只根据 vm_name,ip,region_no确定，如果多条记录报错，记录log，对外报SystemError
			select distinct vm_name region_no=xxx and ip=xxx
	* 职责
		谁操作，谁知道，谁负责校验。

2. bug 修复
	1）修改设计文档
	2）基于文档，修改程序
	3）test
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
		-283, not in same zone of vm
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),
		-917,snapshot not at the device
	修改记录：
		- add_disk
			AddDiskExecuteAction
			AddDiskExecuteActionTest
			InstanceServiceImpl
		- create_snapshot
			CreateSnapshotExecuteAction
			CreateSnapshotExecuteActionTest
		- cancel_create_snapshot
			CancelCreateSnapshotExecuteAction
			CancelCreateSnapshotExecuteActionTest
		- list_snapshot
			ListSnapshotExecuteAction
			ListSnapshotExecuteActionTest
		- detail_snapshot
			DetailSnapshotExecuteAction
			DetailSnapshotExecuteActionTest
		- remove_snapshot
			RemoveSnapshotExecuteAction
			RemoveSnapshotExecuteActionTest
		- rollback_snapshot
			RollbackSnapshotExecuteAction
			RollbackSnapshotExecuteActionTest
			RollbackSnapshotExecuteActionTestTest
		- retain_snapshot
			RetainSnapshotExecuteAction
		- mount_snapshot
			MountSnapshotExecuteAction
		- unmount_snapshot
			UnmountSnapshotExecuteAction
		- live_migrate_vm
			VmLiveMigrateExecuteAction
			
			
		if(!vmClusterId.equals(deviceClusterId)){//check same region
			logger.error("vmCluster and deviceClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		if(!vmClusterId.equals(snapshotClusterId)){//check same region
			logger.error("vmCluster and snapshotClusterId not in the same region");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(VmErrorMessage.NOT_IN_SAME_ZONE);
			return result;
		}
		String snapshotRegionNo = instance.getRegionNo();
		if(deviceNo!=null&&!deviceNo.equals(snapshotDeviceNo)){//check same device
			logger.error("deviceNo and snapshotDeviceNo is not equal");
			Result<Object> result = new Result<Object>();
			result.setResultInfo(SnapshotErrorMessage.SNAPSHOT_NOT_AT_THE_DEVICE);
			return result;
		}

3. 测试环境 部署时
	打开远程debug，便于分析bug。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day70 Tuesday, June 26, 2012

1. 
	* 文档review，
		修改部分内容，修改相应程序逻辑
	* 迭代一bug fix
		@Entry(action = Action.VM, resource = @Resource(argNo = 5)) }) 由于加了参数资源位置发生改变，需要更新
	* slb v2 测试环境 monitor库地址修改：
		10.230.204.24 slbapi monitor_datasource表 
	* big region
		状态码重复：							clear_cache接口状态码与现有重复
			CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
			NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

			CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
			NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
			-288
			-292
			ClearCacheErrorMessage
	* cluster_id ,device_no,vm的校验方案修改：
		方案改为：
			1）cluster_id校验是否存在，报相应id不存在
			2）nc_id,rack_id,vlan_no，vm校验cluster_id一致
			3）nc_id,rack_id,vlan_no同时传时，取最小的
			4）这5个参数的校验顺序：便于case
				snapshot_id
				device_no
				nc_id
				rack_id
				vlan_no
2. 资源位置改变更新bug修改点
	SnapshotServiceImpl
		unmountSnapshot
3. big region api&houyi avalible
	API:10.250.6.33
	DB:10.250.6.27
4. 错误码 ，调试时，错误码+log
	-283 ,not in same zone of vm
	-917,snapshot not existed at the device
5. 根据修改的文档，继续day69第2条任务
	VmErrorMessage
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),
	SnapshotErrorMessage
		SNAPSHOT_NOT_AT_THE_DEVICE(-917,"snapshot not at the device"),

6. 
	# web console staff
	cd `dirname $0`/..
	BASE_HOME=`pwd`

	#rm -rf $BASE_HOME/src/*
	svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api $BASE_HOME/src
	cd $BASE_HOME/src
	mvn clean package -Dmaven.test.skip=true 


	# HOUYI API
	cd $BASE_HOME
	./bin/tomcatctl stop
	cd $BASE_HOME/.default/webapps
	rm -rf slb
	rm -rf slb.war
	ln -s $BASE_HOME/src/target/slb.war

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day71 Wednesday, June 27, 2012

1. 
	* 迭代一，cluster_id等校验规则重新设计，见文档
		开发+测试用例
	* 迭代一 sql调整整理
	* action的validator方法
		会提前验证 参数的格式，需要修改为匹配新格式
			nc_id		NcParameter.NC_NO("nc_no",new RegularValidator("^[0-9]{0,75}$"),null),
			snapshot_id	SnapshotParameter.NAPSHOT_ID("snapshot_id",null), 
			device_no		SnapshotParameter.DEVICE_NO("device_no", null), 
			InstanceParameter
				RACK_ID("rack_id", null),
				NC_ID("nc_id", null),
				VLAN_NO("vlan_no", null),
	* list_snapshot 接口文档返回以删除部分字符串，以实际返回为准
				<rsp>
		  <code>200</code>
		  <msg>successful</msg>
		  <data>
		    <snapshotExts list="true">
		      <snapshotExt>
			<snapshot_id>27-703-520318</snapshot_id>
			<snapshot_name></snapshot_name>
			<progress>37%</progress>
			<create_time>2012-06-27 20:24:54</create_time>
			<image_no>windows2008_64_alibase_v02.vhd</image_no>
			<owner>149</owner>
		      </snapshotExt>
		    </snapshotExts>
		    <device_no>27-703</device_no>
		    <vm_name>wysh-627-a</vm_name>
		    <snapshots>
		      <snapshot>520318</snapshot>
		    </snapshots>
		    <vm_status>Running</vm_status>
		  </data>
		</rsp>
	* aghell05a10.250.6.27 hy create_vm_f vm_conf/windows_vm  wysh-627-a shell脚本执行操作，命名操作名称  ，参数

2. 修改记录
	- add_disk 
		AddDiskExecuteAction @ -
		AddDiskExecuteActionTest @
		InstanceServiceImpl
	- create_snapshot 
		CreateSnapshotExecuteAction @ -
		CreateSnapshotExecuteActionTest @
	- cancel_create_snapshot 
		CancelCreateSnapshotExecuteAction @ -
		CancelCreateSnapshotExecuteActionTest @
	- list_snapshot 
		ListSnapshotExecuteAction @ -
		ListSnapshotExecuteActionTest @
	- detail_snapshot 
		DetailSnapshotExecuteAction @ -
		DetailSnapshotExecuteActionTest @
	- remove_snapshot 
		RemoveSnapshotExecuteAction @ - result返回设置
		RemoveSnapshotExecuteActionTest @
	- rollback_snapshot
		RollbackSnapshotExecuteAction @ -
		RollbackSnapshotExecuteActionTest @
	- retain_snapshot
		RetainSnapshotExecuteAction @ -
		RetainSnapshotExecuteActionTest @
	- mount_snapshot
		MountSnapshotExecuteAction @ -
		MountSnapshotExecuteActionTest @
	- unmount_snapshot
		UnmountSnapshotExecuteAction @ -
		UnmountSnapshotExecuteActionTest @
	- live_migrate_vm
		VmLiveMigrateExecuteAction	@ -
		VmLiveMigrateExecuteActionTest @
	- recover_vm
		VmRecoverExecuteAction @ -
		VmRecoverExecuteActionTest @
		NodeControlServiceImpl @
	- detail_nc
		SingleNcResourceAction @ -
		SingleNcResourceActionTest @
	- create_vm 
		VmCreateExecuteAction @ -
	- remove_disk
		RemoveDiskExecuteAction @ -
		RemoveDiskExecuteActionTest @

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day72 Thursday, June 28, 2012

1. 
	* bugfix 
	* 项目单元测试报错问题
		- 如果是junit，它会去执行带Test开头或结尾的类去执行测试，类不用耦合junit的类，junit会根据自己的规则去找测试类，
		找到了，但类中没有测试方法会报：No runnable methods
		- mvn skip的原因
			原因为：testng框架在初始化时报错，对于依赖的测试用例都将skip
			解决：解决初始化问题，比如spring容器初始化错误等
				暂时先注释houyicontext重复加载抛错
				设置 houyi.openapi.test=true 标识
	* -90 system error 错误
		原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
			com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
				instance找到了，


2. sql整理
	houyi,zone表
	alter table zone add cluster_id varchar(32) NOT NULL;
	SELECT	region_no	FROM zone WHERE cluster_id=#clusterId#
	SELECT	cluster_id	FROM zone WHERE zone_id=#zoneId#	
	select 
		url,
		username,
		passwd,
		region_no,
		index_at_region,
		driver_class,
		min_idle,
		max_active,
		max_idle,
		validation_query
	from monitor_datasource
	where region_no=#regionNO#
3. bugfix
	- bug #177163 live_migrate_vm接口：nc_id为‘-’或者‘--’时，统一返回-90
		
4. mvn test
	mvn test -Dmaven.test.failure.ignore=true -Dmaven.test.skip=false -Dmaven.test.error.ignore=true -Duser.home=/home/admin/houyi-test/src/test/resources -e -Duser.home=/home/admin
		user.home为配置文件设置路径，不能错，spring容器初始化需要（可以用内包含逻辑，减少外部依赖）。

	big region ，重复设置houyi上下文，导致spring初始化失败

5. -90 system error 错误
	原因之一：vm找不到image，ibatis执行时，不能正确封装对象，报错
		instance.xml
		instance.selectInstanceDetailByNo
		com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
			instance找到了，left outer join 去找image时，image的记录是不存在的，但这种join方式，还是返回了vm存在的记录，只是image的字段都是空的。
			可以在 join 时，如果image找不到则不匹配，返回空。
			OR
			image对象字段都有默认值，但能判断是否存在。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day73 Friday, June 29, 2012

1. 
	* create_vm接口测试用例补充
		
	* web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
	* big region 状态码重复 修改

2. 

3. jtester 解析wiki文件时，会判断文件的编码格式 参考 jtester部分源码 [源码]
	org.jtester.utility.ResourceUtil	
		String encoding = ResourceUtil.getFileEncodingCharset(file);

	/* inputstream to string */
	public static String convertStreamToString(InputStream is, String encoding) {
		BufferedReader reader = null;
		String line = null;
		try {
			StringBuilder buffer = new StringBuilder();
			reader = new BufferedReader(new InputStreamReader(is, encoding));
			while ((line = reader.readLine()) != null) {
				buffer.append(line + "\n");
			}
			return buffer.toString();
		} catch (IOException e) {
			throw new RuntimeException(e);
		} finally {
			close(reader);
			close(is);
		}
	}
	/* 异常统一捕获，减少遍布try/catch的情况 */
	public static void close(Reader reader) {
		if (reader == null) {
			return;
		}
		try {
			reader.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	public static void close(InputStream is) {
		if (is == null) {
			return;
		}
		try {
			is.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	ResourceUtil中的其他工具方法，开源框架的工具类代码风格

4. web服务，对应非法的url，需要设计相应的错误提示页面，不直接返回服务器错误内容比如404之类。
		对于不同的web服务器，或web框架都提供错误url处理方式。
			java web项目可以再web.xml里针对异常或错误码配置error page
				<error-page>
					<error-code>404</error-code>
					<location>index.jsp</location>
				</error-page>
		或者通过配置代理服务器，将非法url指向到错误页面。

	生产环境的系统，要处理应用层的非法请求，还要处理服务器层的非法请求（比如，tomcat，apache处理非法请求的指向）；
		比如服务器层的非法请求处理，下面以tomcat为例，在$TOMCAT_HOM/conf/web.xml中配置：
			<error-page>
				<error-code>404</error-code>
				<location>/index.html</location>
			</error-page>			
		其他web服务器，可以参照其文档说明，找到配置点，配置即可。

	实验了下，baidu，等网站对于域名下非法url指向到首页。

5.  big region
	状态码重复：
		CACHE_TYPE_NOT_EXIST(-283,"cache type not exist"),
		NOT_IN_SAME_ZONE(-283, "not in same zone of vm"),

		CACHE_OF_THIS_KEY_NOT_EXIST(-284,"cache of this key not exist");
		NOT_IN_SAME_SUBNET(-284, "not in same subnet of vm"),
		-288
		-292
		ClearCacheErrorMessage

	暂不改


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day74 Monday, July 02, 2012

1. 
	* big region参数修改bug fix
		创建    unmount_snapshot API超时返回-95
		创建    API参数调整设计文档中未提及create_image接口
		query_available_ncs: vm用户非法情况，API报-90
		query_available_ncs: vm状态为destroyed的情况下，API报-90
	* 关键性log，记录并打印关键内容 ，便于后续查找log排查问题。个人感觉，log需要记录关键性的原生请求内容，比如请求参数，返回内容等
		进入拦截器打个日志，这样在某些关键点打日志就可以从日志中大致判断那个地方报错了。
	* live_migrate_vm接口nc_id是否为必须？
		待确定，代码里验证为必须。
		
2. big region参数修改bug fix
	qa环境不在6.33上，看日志需要到qa测试机查看 10.242.209.4 （改为 10.230.204.19）
	
	创建    unmount_snapshot API超时返回-95
	创建    API参数调整设计文档中未提及create_image接口			  done
		修改设计文档
		CreateImgExecuteAction
		ImageServiceImpl
	query_available_ncs: vm用户非法情况，API报-90
	query_available_ncs: vm状态为destroyed的情况下，API报-90	   （控制系统destory，api这层为release状态）
		在根据vm_name查找instance时（为了查询资源的regionNo），dao层sql语句报错，和之前一样，let join的表没数据，但result这个字段又是必须，故报ibatis设置result map错误，程序没有捕捉这个错误。
			应该报这个错，日志没记录：
				com.ibatis.common.beans.ProbeException: Could not set property 'servicesSign' to value 'null' for com.aliyun.houyi.entity.Image.  Cause: java.lang.IllegalArgumentException
		解决：
			捕捉这个错误，打出log。
		注：
			错误日志找了半天找不到（根据请求内容，返回结果），原因在于 log里没有打印请求相关的内容，不好根据请求内容匹配，建议可以适当打印请求的一些关键内容，便于排查错误。 【日志内容设计，建议】
				2012-07-02 14:12:13,249 ERROR [com.aliyun.houyi.openapi.interceptor.ParameterInterceptor] - [业务参数校验有问题，请检查原因：com.aliyun.houyi.openapi.exception.ParameterException: 协议参数校验不通过，参数名称：timestamp！]

				2012-07-02 14:35:38,204 ERROR [com.aliyun.houyi.openapi.interceptor.RegionAwareInterceptor] - [查询资源信息时发生错误!]
				就这条日志，导致error错误发生，log里没有明确的内容标识本此请求，故通过即时重现来得到log输出。这里可以适当打印一些请求内容，便于后续排查错误。

3. 日志打个唯一tag，再结合用户标识等唯一标识以及时间，可以从日志中统计出每个用户每次调用的所有有序日志输出。think it


4. debug 代码不一致，不是部署错了，就是自己的代码没更新，排查呀排查 。。。 呵呵

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day75 Tuesday, July 03, 2012

1. 
	* region转换需求分析 redmine
	*迭代三 开发需求分析
	* slb v1,v2的vm的小region转为大region	 需求分析


2. 迭代三任务
	- [ID:175057]兼容用户使用小region调用
		a. 兼容用户使用小Region的调用(用户传入的小region统一转成大region，用户输入小region,API返回小region)
			需求理解为：（需要review）
				1. 兼容用户使用小Region的调用(用户传入的小region统一转成大region)
				2. 用户传入小region，步骤1中转换为大region，即使用户传入小region，api实际返回的还是大region下的内容
				3. api只返回大region的region_no

				原则：
				所谓兼容，指的是用户可以传入小region_no，但api都转换为大region_no处理，包括返回的也统一为大region_no			
		b. 查询用户所有VM状态接口(list_vm_status)，根据用户输入的大Region返回大Region信息
			需求理解为：（需要review正确与否）
				1. 根据用户输入的大Region返回大Region下用户所有VM状态，返回大region_no
				2. 若传入小region,查询小region下用户所有VM状态,返回小region_no
				QA:
				1. 大小region_no如何区分？
					表region_alias记录小region与大region的关系
						region_no
						real_region_no
					参考：弹性计算大Region项目_调度设计_API部分__20120628.docx

			QueryVmListInfoExecuteAction
			InstanceDaoImpl

3. SLB V1版本，V2版本所使用region_no全部换成大region_no
	前提：现在vm的大region和slb的region是一对一的，即vm的大region都对应slb的一个region。
	有了上面的前提，v2版本的slb api项目要修改的地方：
		1）配置vm的大region对应slb的region的映射关系，保证大region传递过来能正确调用到slb的region。
		2）

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day76 Wednesday, July 04, 2012

1. 
	* 迭代三
		region_alias表big_region_no字段增加
	* 小region改为大region，涉及到的command中region属性判断需要设置为目标region。doing
		参考：CreateInstanceCommand
	* 迭代一的根据zoneId取clusterId逻辑，改为从cache中取，参考    QueryVmListInfoExecuteAction	       getRegionValuesFactory().getClusterIdByZoneId(xx)		  待
			

2. 迭代三
	- list_vm_status
		QueryVmListInfoExecuteAction
			转换nc_id时，要考虑到不同region取出的nc的cluster_id是不一致的。
			设计时，如果每个转换都查db，性能很低sql很简单当连接耗时，考虑缓存zone_id,cluster_id映射数据。
				在RegionValuesFactory存放此缓存 缓存设计（总体设计，类设计，更新策略，。。。）
					系统有多处小cache，是否设计一种通用方式，不用每个cache都自己去写个类，去clean等共性操作。
						抽象出缓存操作接口层，不论底层是什么缓存工具，接口的实现来实现细节。上层应用只调用接口，在配置中配置具体实现。应用系统缓存设计
			在处理每个nc不同的cluster_id前缀时，处理方式改为在原有逻辑循环中，从clusterId缓存中取得后设置。
		InstanceDaoImpl
		instance.xml 增加新查询，已有查询不动（避免影响已有调用）
		RegionValuesFactory
			getClusterIdByZoneId
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		QueryUnassignedIpsExecuteAction

		此接口需要根据 zone_id取到对应的小region_no，查询houyi时，指定在这个小region上操作。
		
3. dbfit 测试用的wiki文件，直接从sql检索结果贴过来，会有很多空格，可以用空来替换空格，再补上必要的空格，省去删空格的繁琐。
	替换功能帮助不小
4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day77 Thursday, July 05, 2012

1. 
	* 迭代三开发


2. 迭代三
	- [ID:175056]大region下查询可用公网IP资源(query_unassigned_ips)
		由于zone_id是必选，原有逻辑不变，不跨小region。
		QueryUnassignedIpsExecuteAction
		QueryUnassignedIpsExecuteActionTest
	- [ID:175055]查询可用的ISO接口(query_available_isos)，根据大Region参数该大Region下的所有资源
		QueryAvaliableIsosExecuteAction 
			region_no参数没用到 ，iso_resource表加入region_no字段待确定？ 这样iso就属于某个小region
				iso_resource 加region_no（小region_no）字段
				sql修改
					alter table iso_resource add region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的小region_no';
				相应要修改的点：
					iso.xml
						对region_no字段加入，需要修改的sql
					IsoDaoImpl 修改 selectUserAvailableIsos方法

3. 对于兼容的地方，文档应尽量说明，便于理解。
	比如一个必选的参数，但没传也ok，容易误解。文档描述与程序逻辑的一致。

4. 
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction

4. big region ,houyi api 代码中多处用到java对象的址传递方式来，从一个方法中取得多个结果
	比如：声明一个变量，传入到方法参数中，执行好后，方法返回一个结果，参数中对象也保存了结果

	这样的现象出现的原因？有何优缺点？
		原因还是对方法的结果没有更好的封装对象，需要
		弱封装，一个方法包含多个功能 

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day78 Friday, July 06, 2012

1. 
	* 迭代三开发
		- 根据写的开发修改文档
		- region表增加big_region_no字段，和region_alias表（real_region_no字段由于存储2个region_no对应同一个存储，
			在imge接口里，为了区分用）的big_region_no一致
			sql修改：
				alter table region add big_region_no varchar(32)  NOT NULL COMMENT '@desc 小region_no对应的大region_no';
			相应点的修改
			测试用例，wiki文件修改 待？

			注：7月9号，取消上面的修改，region表不增加big_region_no字段。
				通过svn版本还原各个修改点。

	* 缓存使用
		- 系统多处地方，频繁调用数据库，结合简单缓存service，将某些查询缓存起来。在查询缓存命中时，免去数据库操作，提高性能。
		- 提高公共缓存服务，可以根据类型操作各自缓存；便于扩展，加入新缓存类型
		- 缓存的更新，若缓存没命中，则继续到数据库中找，找到就放到缓存中，并返回
		- 缓存的过期清除，不用的缓存，命中率低的缓存，能自动清除或调整
		- 缓存总大小限制，控制无限增大缓存(个数控制，。。。)
		

2. 迭代三记录
	- [ID:175054]大region下获取监控项指标TopN的VM接口(monitor_vm_topn)
		  VmTopNMonitorExecuteAction
		  VmTopNMonitorExecuteActionTest
		  MonitorServiceImplTest

		  norm值，判断指标在指定的region是否支持，大region_no如何处理？
			内部判断region是否为大二层网络，因为现在到以后都会是大二层网络，故这个判断可以忽略。

	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		   VmPageMonitorExecuteAction


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day 79 Monday, July 09, 2012

1. 
	* region表取消big_region_no字段，相应修改
	* 迭代三开发

2. 迭代三
	- 查询可用的ISO接口(query_available_isos
		修改补充
	- [ID:175048]查询用户所有的VM监控信息接口，参数由小region变成大region(query_monitor_vms)
		VmPageMonitorExecuteAction
		InstanceMonitorInfoDaoImpl
		InstanceMonitorInfoDaoImplTest
	- list_vm_status		
		
	- query_rack
		RackQueryAction
		RackQueryActionTest
		AbstractExecuteAction
	- ID:175051]大region下list_vlans接口
		VlanQueryAction
		VlanQueryActionTest
	- [ID:175052]大region下 query_zones 接口
		返回的region_no改为大region_no
		ZoneQueryAction
		ZoneQueryActionTest
	- ID:175053]大region下 query_regions 接口
		文档返回结果说明需要修改，现在返回的是大region_no
			返回值格式不修改，用大region_no字符串构造region对象，返回；向前兼容
		RegionQueryAction
	- 大region下 add_ip_segment 接口，同时增加zone_no参数
		AddIpSegmentExecuteAction
		IpSegmentService


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day80 Tuesday, July 10, 2012

1. 
	* monitor_vm_topn 接口修改
		VmTopNMonitorExecuteAction
		排序
			Collections
			Arrays
	* 用户体系修改review
		关联到的slb v2用户改造
	* region缓存修改问题
		RegionValuesFactory
	* slb v2 slb region那些地方用到？
	* ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		需求分析

	* ibatis的sql注入问题：在使用##时，采用预编译可以避免sql注入，但用$$时要程序避免sql注入
		order by b.$orderBy$ $order$ 
	* cache修改，涉及到丢失修改的测试用例修改
		openapi模块


2. slb v2 slb region那些地方用到
	- 请求slb后端，需要slb region_no,定位后端请求信息（url之类）
	- 查询流量接口，需要根据slb region_no，调用其对应的monitor库
	- 操作api的rs表时用到slb region_no

3. ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	需求分析 
	slb v2 api ，在region_mapping表通过vm的region_no得到slb的region_no
	，然后，在调用slb后端和查询流量数据时用到这个slb region_no。

	slb v1 版本代码在houyi api的一个包中，属于houyi api project：
		
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day81 Wednesday, July 11, 2012

1. 
	* 迭代三开发
	* -1007,"desc":  "ip segment is used
		控制系统这个错误码，api层没有定义相应的错误映射，以默认-95，system error返回。暂不改

	* 接口兼容


2. 迭代三
	- ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
		前提:
			一个vm大region_no对应slb的一个region_no，他们是一对一关系
		需求分析
		请求参数中region_no为大region_no时	   ，只要在region_mapping表找到对应的slb region_no即可：
			SLB V1用到slb region_no的地方有(houyi库)：
				a. slb流量查询接口，
					slb_monitor_datasource（此表region_no为vm的region_no）
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。

				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					slb_region
			SLB V2 用到slb region_no的地方有（slbapi库）：
				a. slb流量查询接口，
					monitor_datasource
						一个vm大region_no对应一个slb region_no ,对应一个monitor库，即同大region_no下不同的小vm region_no都是对应相同的slb region及相同的slb monitor库。
				b. 调用slb后端时，根据region_no找到后端url
					region_mapping
						一个vm大region_no对应一个slb region_no,一一对应
					region
	数据订正：
		SLB V1（houyi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
			2）slb_monitor_datasource 表
				订正region_no为大region_no（原来此列值为小region_no）
		SLB V2（slbapi库）
			1）region_mapping 表
				订正 vm_region_no 字段为vm的大region_no值
	代码修改：
		SLB V1 : 部分代码需要修改，涉及到从vm的region_no得到slb region_no的地方


3. 全局变量设计 ，控制使用范围
	系统全局变量设计时要考虑好，尽量不用或少用，用的不好导致系统各个地方充斥着全局变量调用或设置，
	维护，调试比较麻烦，可通过在上层用，下层通过传参传递，这样也知道一个方法用到哪些参数，不是上层不知道的情况下，
	调用了一个全局变量。个人见解

4. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day82 Thursday, July 12, 2012

1. 
	* 迭代三修改点 与QA review
	* SLB V2中根据vm的region_no查询slb region_no部分逻辑代码修改
	* SLB V1,V2用户体系分析，新项目准备工作
	* 提测前准备工作：
		HOUYI API , SLB V1 API ,SLB V2 API
		- 表订正

	* iso_resource表增加的小region_no，修改为增加大region_no
		sql修改
			alter table iso_resource add big_region_no varchar(32)  NOT NULL COMMENT '@desc iso所在的大region_no';
		相应要修改的点：
			iso.xml
				对region_no字段加入，需要修改的sql
			IsoDaoImpl 修改 selectUserAvailableIsos方法		
		
	      待改数据库并svn提交 ？
2. 

										     

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day83 Friday, July 13, 2012

1. 
	* 用户体系改造项目设计review
	* houyi api 接口调用用例编写，便于测试
	* 
		
2. vm状态
	Pending(1, "待启动") 
	Starting(2, "启动中") 
	Running(3, "运行中"), 
	StartFailure(4, "启动失败") 
	Shutting(5, "停止中") 
	ShutFailure(6, "停止失败"), 
	Shutted(7, "已停止"), 
	Released(8, "已释放"), 	     释放后instance表记录保留
	Resetting(9, "重置中") 
	ResetFailure(10, "重置失败"),
	Transferring(11, "迁移中");

3. houyi api 接口调用用例编写，便于测试
	- create_vm接口返回值region_no为小region_no？   是否还有其他的也需要检查
	- 创建的vm，调start_vm状态为pengding，数据库为startfail
	- start_vm start fail 原因？控制系统
		看api调用此接口传递给控制系统的参数，isoName参数为空，因为iso_resource表增加了big_region_no，开发环境没有更新此表。
	- houyi api对取消创建快照接口，控制系统报 cancel failed错误时，api没有映射对应的错误，统一以-95报错	 ，或者是控制系统状态码错误？	
		注：确认为控制系统没有对错误码归类，比如不同错误可能都报-1码 ，有待控制系统返回特定码。
		result: {"code":  -1,"desc":  "cancel failed","isSuccess":  "FALSE"}。
		-95，invoke houyi system error
	- 同上，卸载快照接口，
		code":  -1,"desc":  "umount device from vm failed
		-95，invoke houyi system error
	- query_available_imgs 查询可用的镜像接口，返回值snapshot_id格式没更改	?
		   文档注明返回值中snapshot_id部分废弃，本次代码不动，后续将去掉这个值
	- list_vlans
		-95，invoke houyi system error
		Caused by: com.alibaba.apsara.kuafu.KuafuException: Exception: Message is dropped by KFC, server does not exist
		控制系统服务不正常，在重启

	qa测试：
		cd /home/admin/lix/lix-src/tools  or /home/admin/lix/lix-src/tools/houyiTestFrame/houyiTestFrame
		python2.7 houyiframe.py cases/release_test/bvt_ci.xml test vm_test		or python2.7 houyiframe.py cases/release_test/bvt_ci.xml 22:22
		[root@AT-HOUYIDEV-AG]$me
		Local_Address: 10.250.6.27

		涉及到参数值修改在: bvt_ci.xml test vm_test 中
			cluster_id=27


ZoneServiceImpl


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day84 Monday, July 16, 2012

1. 
	   *  qa bvt测试 ，开发自测
	   * big region项目中，缓存reload接口
		目前有，region，zone，clusterId三块缓存，根据指定的key，reload对应的缓存（用于源数据被修改后，需要同时更新缓存值的目的）
	   
2. bvt测试
	具体执行环境参考day83第3条

3. reload缓存接口，根据缓存类型，调用接口实现对应类型的缓存reload	    ，内部调用接口
	region，zone，clusterId三块缓存
	命名：
		action名： reload_cache
		ReloadCacheAction
		ReloadCacheService
		ReloadCacheServiceImpl
		ClearCacheParameter
			CACHE_MODULE("cache_module",NotEmptyValidator.instance)
		CacheModuleType
			REGION(1),
			ZONE(2),
			CLUSTER_ID(3);
		ServerErrorMessage			  新的错误码，到这里定义
			CACHE_MODULE_IS_EMPTY(-7100,"cache module is empty"),
			CACHE_MODULE_IS_ILLEGAL(-7101,"cache module is illegal"),
			RELOAD_CACHE_MODULE_FAILED(-7102,"reload cache module failed or cache module not found");			
		houyi-spring-action.xml
		houyi-spring-service.xml
			

4. 从StringUtils工具类的选用，看代码耦合 系统设计 工具类设计
	这个工具类在好多第三方包中都有，是直接用还是通过自己项目的工具类再包装下使用？
		为了减少耦合，建议自己做层简单封装，这样对第三方库通过一个入口来管理，即使以后换了实现，也只需要改一个地方即可，不用面临侵入代码
		各个地方的情况。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day85 Tuesday, July 17, 2012

1. 	
	* detail_vm接口 region_no返回为大region_no ？
		修改为大region_no
	* slb v2 用户体系改造
	* slb v1接口测试
		query_available_vips
		QueryAvailableVipsExecuteAction
		IpAddressServiceImpl
			slbRegionService没有注入
		vm region_no找不到slb region_no,报：-95，invoke houyi system error ？
	* list_vm_status
		QueryVmListInfoExecuteAction
		此接口，由于instance对应的image不存在报-90错误
		？是否修改sql，对于image数据错误的记录不返回
		instance.xml 中设置image属性默认值

2. slb v2 用户体系改造 需求分析
	1）代码修改
		支持原有用户验证；并支持新的AliyunIDKP用户方式。
		AliyunIDKP方式：
			请求中有此参数且不为空，表示已鉴权；
			到数据库user表查询此AliyunIDKP，若找不到则新增
		用户信息缓存起来，减少数据库io次数。
	2）数据订正
		涉及的表：user, rs：
			user表的user_id订正为AliyunIDKP的值，订正依据由portal提供，提供原user_id，key,id组合和AliyunIDKP的对应关系；
			rs表，portal提供原user_id，新AliyunIDKP，和rs_pool_name的关系
		订正方式：
			提供执行工具，根据上面的映射关系来更新表
		订正过程：
			（1）依据portal提供的映射关系表（文本方式,格式类似下面，具体格式见实际文本）
				user_id	aliyunIDKP	rs_pool_name
				144		1366		pool1
				144		1366		pool3
				144		1367		pool2
				144		1368		pool4
			（2）通过脚本（python，shell,...）解析上面文本
			（3）执行
				a. 读取第一行，
				b. 取到aliyunIDKP值，
				c. 到user表查询user_id字段是有此 aliyunIDKP
				d. 有则跳过，没有则插入此记录（user_id | user_name | service_secret_key        | service_access_id         | status | is_admin | billing），除了user_id为此	 aliyunIDKP的值外，其他字段和原user_id对应的值一致
				e. 取到 rs_pool_name 值
				f. 到rs表查询此rs_pool_name对应的记录
				g. 无则跳过，有记录，则更新此记录中的user_id值为步骤b得到的aliyunIDKP值，有多条则更新多条（循环执行）
				h. 读取下一行
				i. 继续从步骤b执行 
				j. 循环至末行处理结束

3. python表订正工具
	

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day86 Wednesday, July 18, 2012

1. 
	*   query_available_vips 接口
		查询时，没有将小region_no转换为大region_no
		QueryAvailableVipsExecuteAction										 s
		IpAddressServiceImpl
	* 用户体系改造项目
		 - 分支见redmine
		 - 订正工具（python脚本实现）
		 - 设计文档
	* 用户体系项目分支
		slb v2 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		houyi api http://svn.alisoft-inc.com/repos/alisoft/houyi/console/branches/api_user_reform

2. 

	
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day87 Thursday, July 19, 2012

1. 
	* 账户体系改造SLB V2相关设计文档编写
	* big region bug fix
	* jteser事务测试
		注意测试框架的事务会影响测试代码事务

2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day88 Friday, July 20, 2012

1. 
	* 会议
		防火墙，调度
	* SLB V2用户体系改造设计
	
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day89 Monday, July 23, 2012

1. 
	* SLB V2用户体系改造，根据邮件给出的prd文档，分析
	* big region后续bug提交方式，通过下面的地址建立子任务，并建立对应的bug进行提交：
		http://redmine.aliyun-inc.com/issues/2648
	* 单元测试严格划分职能，对于数据库测试，wiki文件只应出现在dao层中，service层不应该出现（信任dao层），层层完成自己的验证，层间依赖信任
		集成测试情况会跨多个层
	* big region
		- 迭代一周期 ，由于后续变动，需要更新redmine文档
		- device，snapshot，vmAPI这边的权限验证，代码实现  ，具体见redmine新任务 待？

		
2. houyi api白名单
	在配置文件定义白名单ip，spring注入到拦截器等需要校验的地方。
	配置时，多个ip间以“,”逗号隔开，spring注入时，调用set方法注入，在set方法里编写逻辑将ip字符串处理为Map。（通过重写set方法实现指定注入转换）

	也可通过直接在spring配置中配置Map数据。

3.  SLB V2用户体系改造，根据邮件给出的prd文档		  本周完成下面子任务
	- 白名单参考houyi api的实现
		slbapi.properties 配置白名单ip
		AgreementParameter 平台参数验证，session验证改为aliyun_idkp验证
		CheckUserSignInterceptor 白名单验证，注掉以前user_id验证
		GlobalErrorMessage
			新增错误码：ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),


		ServerErrorMessage 错误码定义

		原来用到user的地方需要修改：
			LogInterceptor
				SlbApiLog
			AbstractService
				Rs
				slbapi.sql rs表的user_id字段值为aliyunIDKP，原来是long类型的user_id，故重新定义字段，依据houyi api的user表user_id字段定义：
					aliyun_idkp` varchar(32) DEFAULT NULL, 待确认？
				RsService
				RsServiceImpl
				RsDao
				RsDaoImpl
			LoadBalancerServiceImpl
			查询SLB流量接口
				MonitorInfoDaoImpl
			调用houyi api改动
				ECServiceImpl


	- 原校验机制注释，只采用AliyunIDKP验证机制，是否涉及错误码改动？待检查
	- user表废弃
	- 数据订正：rs表的user_id和rs_pool_name
	- 调用houyi api部分，去掉原有签名（user表已废弃），通过aliyunIDKP方式调用houyi api（houyi api需要将slb api v2加入白名单中）
	- 对于关键点，类编写测试用例
		CheckUserSignInterceptorTest 


4. 设计中，对于id这类的字段，虽然目前是long，后面可能会改为string，设计pojo时最好设计为string类型，
否则后续类型改动，需要改相应接口及实现 设计
	对于某些可预知，后续字段数据类型可能发生变化的场景，设计pojo时考虑好类型，方便后续变动。

5. big region
	校验逻辑梳理：
		
 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day90 Tuesday, July 24, 2012

 1. 
	* 用户体系改造-SLB V2 API
	*  device，snapshot，vmAPI这边的权限验证
		API有user和vm的所属关系（houyi instance表）
		控制系统有VM，device，snapshot之间的所属关系
	* houyi API 与控制系统状态保持
		控制系统状态变化会通知rabbit MQ，API从MQ中得到消息，进行同步 ？	    Message模块中
		通过rabbitMQ java开发包实现
		eg：start_vm控制系统接到后返回200，过一段时间vm启动后，控制系统发消息到MQ,API读取消息，更新vm状态
	* 控制系统重启，导致部分操作成功，部分失败：
		结果之一：一个vm已经stop，但vm表的状态为starting，导致状态不一致。
	* start_vm 控制系统对于vm不存在的情况，不返回结果，API超时返回
	* VmCreateExecuteAction ，在createVM返回空时，instance = (Instance) result.getResultInfo(); 返回了快照对象，导致类型转换错误？
		待修改提交 

 2. 用户体系改造
	- 什么时候可以测试环境连调测试？
		SLB后端
		houyi API
		SLB V2 API
			流量接口
			调用SLB后端
			调用houyi API
	- 数据订正谁来做，portal数据什么时候提供？	     由其他同学负责
	- 测试类
	- 后面的问题在于测试
	- 修改点
		UserDaoImpl.		      废弃
		User			废弃
		UserStatus		废弃
		slbapi-ibatis-config.xml 修改
		UserServiceImpl 废弃
		RequestContext 修改
		UserService  废弃
		LoadBalancerServiceImplTest  修改
		AbstractServiceTest 修改
		User.xml 废弃
		spring-dao.xml 修改
		spring-service.xml 修改

 3.  device，snapshot，vmAPI这边的权限验证
	下面3个接口，暂定由API将必要消息传给控制系统，控制系做资源所属验证：
		a. API层验证user和vm的所属关系。
		b. 由控制系统来判断资源间的所属关系（vm，device，snapshot）

	- [ID:182636 ]retain_snapshot 安全风险 用户可retain其他用户的snapshot
		RetainSnapshotExecuteAction

		需求：用户进行retain快照操作时，检查快照是属于当前用户的
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		此接口，只传递了device_id和snapshot_id
			修改，将vm_name也传递到控制系统，由控制系统来验证vm，device，snapshot之间的所属关系

	- [ID:182495]remove_snapshot 安全风险 可以删除其他用户的snapshot
		RemoveSnapshotExecuteAction
		需求：用户只能删除自己的snapshot
			api目前只有snapshot_id，不带user信息，可以去再掉控制系统查快照详情
			或者将vm信息一并传入控制系统，由控制系统验证所属关系？
		[call houyi system. method:RemoveSnapshot,parameter:{"snapshot":"520322test","vmName":"mytestvm2012-2","deviceId":"817"}]
			给控制系统有VM名称,快照ID和设备ID
	- [ID:182101]cancel_create_snapshot时传入的vm_name和snapshot_id不匹配时没有报错
		CancelCreateSnapshotExecuteAction
		[call houyi system. method:CancelSnapshot,parameter:{"snapshotId":"520322","vmName":"mytestvm2012-2"}]
			传给控制系统 快照ID和VM名称，是否应该控制系统验证所属关系？API去验证的话就需要多一步查询控制系统步骤，最后验证还是由控制系统决定。
	- detail_snapshot需要判断snapshot是否属于该用户
		经查看代码，已有验证，跳过
	- umount_snapshot需要判断vm与device判断，device与snapshot判断
		UnmountSnapshotExecuteAction
		经查代码（region.isUpgrade() ==1），已有验证（跳过detail_snapshot接口去控制系统查询了下，这个接口vmName也是传递给控制系统的，对于这种有vmName的情况，
		vm对应的资源所属验证统一交由控制系统处理，API只保证
		user和vm的所属关系？）
		region的isUpgrade判断目的是什么？
			确定的是没有升级的region，快照没有userId字段，不需要验证快照与user的关系

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day91 Wednesday, July 25, 2012

1. 
	* big region
		list_mounted_snapshot接口，返回值中，snapshot_name内容是snapshot_id，如何转换为3元组？
		
	* 用户体系改造
		加入jtester测试框架，便于单元测试
			

	
			
2. list_mounted_snapshot 接口处理snapshot_name为cluster_id-device_no-snapshot_id三元组方式
	确认为API返回的snapshot_name值为snapshot_id，三元组构成，可以通过从控制系统返回结果中得到snapshot的deviceNo，
			从vm得到其clusterId，构造成：cluster_id-device_no-snapshot_id三元组整体返回。
			问题：
				返回结果中的deviceNo是快照挂载上去后，生成的新device的deviceNo,不是快照原来的deviceNo，这样对于用户来说，snapshot_id发生了变化，故不能从返回值的deviceNo拼接三元组
			解决：
				根据控制系统返回的快照id去查询其deviceNo,以拼接三元组返回？
					去detail_snapshot,
						具体见邮件：增加一个snapshot_id的属性，为了兼容性考虑目前保持snapshot_name与snapshot_id一致
	ListMountedSnapshotExecuteAction
		？待测

3. 可用的image ，测试
	select 
		image.image_no,
		image.region_no as imageRegionNo,
		inst.region_no as instanceRegionNo 
	from image image,instance inst 
	where image.image_id=inst.image_id limit 1,2;
	加上user，大region条件，筛选可用image。

4. 高亮显示光标所在字符或字符串
	命令行模式下：
		*：读取光标处的字符串，并且移动光标到它再次出现的地方。
	　　#：读取光标处的字符串，但是是往反方向寻找。

	和 /text 方式查询类似，但可根据文本内多次直接搜索，不需输入检索字符串。

5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day92 Thursday, July 26, 2012

1. 
	* big region 测试用例验证，修改
		http://10.250.8.214:81/surefire-report-dao.html		   fixed
		http://10.250.8.214:81/surefire-report-service.html	   
		提交ID:
			[ID:183748]完善测试用例
	* list_mounted_snapshot接口测试用例修改，提交代码
	* houyi api
		控制系统返回的对象类型定义在各自的command实现类中，可以查看API与控制系统交互的数据格式
		确认rpc返回的pojo类类型。
	* SLB API V2用户体系改造，调用SLB后端的user_id名称不变，只是值为aliyun_idkp
	* SLB API V2流量查询接口，查询的时间早于计量库保存记录的时间点，导致计量库找不到对应的表，API报：
		code":-2001,"msg":"backend service exception
		是否要修改？要知道计量库的表设计逻辑，比如保存几天的记录表？这里跨系统访问数据库，不是接口，导致此类依赖问题
			接口说明是7天，那么需要判断从当前时间往前6天供7天的表是有的，超出这个范围的是没有记录的，API需要做判断，并加入对应的状态码？
				或者超出时间的直接返回空？
				计量库 原lb_global_id改回为lb_id?
					这是旧的库，新库地址：
						mysql -uhouyi_odbs -phouyi_odbs -hmy3306.mysql.aliyun.com xuanyuan

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day93 Friday, July 27, 2012

1. 
	* 用户体系改造	
		涉及到list_vm_status接口改动
	* 	业务熟悉
		技术：多线程，并发，性能，服务器编程，重构
		
	* houyi api 数据推送模块后续重构
		考虑使用独立的缓存系统（比如，memcached），可以在API上抽象出操作缓存的接口，
		可以针对不同的缓存框架使用对应的实现，比如通过操作memcached的接口，操作memcached缓存
	* detail_vm接口问题
		当vm release过后，调detail_vm接口报：-90 system error
		文档没有说明不能查询released的vm
		原因为代码处理问题导致空指针。fixed
		
2.  用户体系改造
	- portal查询vm状态接口，由于此次用户改造，原有的根据144大用户取得其卖出的所有vm状态信息的功能已经不能用（已拆分为子用户，然后没有用户组等关系来
		判断子用户属于哪个大用户；目前，vm主要包含portal和万网的vm，还有少量的其他用户的vm，暂定为在查询用户所有vm状态的接口逻辑里，以硬编码aliyunIDKP方式判断是portal的请求还是
		万网的请求，portal的请求就返回除了万网的所有vm信息，万网的请求只返回万网的vm信息）
	
		问题：
			如何区分IDKP是不是portal来的IDKP？
				设置专门对原144的IDKP值，API根据此值可以知道是否为portal的请求。

		需求变动，验证方式为key方式+白名单方式，即先需要经过key验证（通过在user表继续保留144账户），
		然后判断是否有AliyunIDKP值，如果有继续处理，如果没有处理逻辑待定（判断为管理调用，返回所有接口的所有内容？）
			上面的返回所有内容问题缘于之前是144用户的所有数据，现在切分为一个个独立的IDKP对应的数据，现在要返回这个大用户下所有IDKP账户对应的数据。这样portal需要遍历每个
			IDKP去Houyi API取数据，原来一次即可，如何解决？
				提供一个接口，能根据portal传递过来的IDKP列表批量返回对应的数据。							

3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day94 Saturday, July 28, 2012

1. 
	* big region
		排查涉及 RegionHolder.getCurrentRegion() 语句的代码，此代码得到的小region_no可能为用户默认region_no。
			eg：用户为HZ用户，需要到BZ的大region中create_vm，传入的是BZ的大region_no，而小region_no却默认到HZ了？
				可以根据大region_no得到其默认操作的小region_no（）
				检查用到用户小region_no的点
	* 用户体系改造，user表加入代理商ID字段，标识子用户属于哪个代理商
		- 所有请求都需要先经过签名认证
		- 白名单配置代理商ID（IP会存在改变的问题）
		- 没有传AliyunIDKP值，则用户类型为代理商用户，返回结果时需要处理，返回代理商下所有子用户的数据（涉及到的接口由PD整理）
		- 传递了AliyunIDKP的	 ，判断user表是否已有记录，没有则增加记录（代理商ID根据白名单配置），有则继续操作。
2. 
													      


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day95 Monday, July 30, 2012

1. 
	* 用户体系改造，流程图ok
	* big region 
		- RegionAwareInterceptor 的region缓存替换为RegionCacheManage的统一方式
		- RegionAwareInterceptor中，用户传入大region_no时，设置小region不能用user的默认小region,改为从大region的小region列表中取第一个。
			排查代码用用到regionHolder中默认小region的点。
				RegionHolder.getCurrentRegion().isUpgrade()
				boolean isBigEtherNetwork = RegionHolder.getCurrentRegion().isBigEtherNetwork()
				list_vlans接口
					有region_no和zone_no
					ZoneServiceImpl
			提交修改后，在开发环境验证功能
				
	* SLB V2 用户体系改造，构建目录，deploy目录设置好，便于部署
		http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/build.sh

		svn checkout 部署目录：			nginx+tomcat
			在/home/admin/slbapi目录下：
				svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi
				sh build/build.sh
				sh bin/tomcatctl start
		
		部署一个nginx对外监听80端口，通过转发实现代理多个应用的访问（以uri区分请求的应用）：
			
			小结：
					当nginx正确启动后，某个应用启动后能正常访问，另一个uri的访问确是空（没任何内容，这个是因为中间多了proxy层处理），可能原因就是后端应用（比如tomcat）
				启动失败了，即服务器是起来了，但应用确没起来，导致访问应用的路径时浏览器没显示任何内容，如果直接去访问后端的tomcat路径会报404（一看就知道路径访问到，确认路径
				ok的情况下极可能就是应用启动失败）。
					这种有多个层转发的情况，错误排查可以从原始的端开始，逐一排查。
			
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day96 Tuesday, July 31, 2012

1. 
	* big region bug fix
		- 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。

	* 用户体系改造，SLB API build脚本
		当前的方式，需要在部署机去build，可能会因为网络不通等问题导致依赖找不到，编译失败，通过先build再分发的方式解决此问题，也是build机的用意。
		参考已有build过程
	* 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	* big region
		create_vm等接口流程（在原有基础上加上了调度，防火墙的逻辑）
	* SLB V2 在大region项目中的变动
		兼容用户小region_no请求？待
		维护小region_no到大region_no的映射，在请求传入时，将小region_no转换为大region_no。
	* big region
		计量推送，region_no改为大region_no？待
	* 10.230.204.24 部署slb v2 user_reform环境
		在slbapi-user-reform目录
		svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform/deploy-env/slbapi .
			删除src目录下的所有内容
		修改build/build.sh的svn地址为 http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/branches/slb_user_reform
		sh build/build.sh
		修改spring配置文件中的属性文件路径：默认为 ${user.home}/slbapi/conf目录下
			在src下修改spring配置，然后mvn build
		配置白名单
			slbapi.properties
		通过各自项目的nginx.conf,mime.type文件，启动自己的应用监听。	    （不推荐，这样会导致端口修改，2个独立的nginx进程不能共享同一个端口）
		下面，通过配置转发规则，让多个应用公用80端口：
		 ---------
			  ...
				   server {
					listen       80;
					server_name  openapi.aliyun.com;

					charset UTF-8;

					proxy_connect_timeout 600;
					proxy_read_timeout 600;
					proxy_send_timeout 600;

					#access_log  logs/host.access.log  main;

					if ( $host ~* (.*)\.(.*)\.(.*)\.(.*)) 
					{ 
					  set $domain $1; 
					  set $new_uri /openapi/$domain$request_uri;
					} 

					location /{
					    proxy_set_header        X-Real-IP $remote_addr;
					    proxy_set_header        Host $host;
					    proxy_pass http://127.0.0.1:8080$new_uri;
					
					}

				       location /slb/api{
						   proxy_set_header        X-Real-IP $remote_addr;
						   proxy_set_header        Host $host;
			...
			---------
			此方式，先验证后端服务启动正常，再验证nginx转发正常，因为后端的错误可能不能从nginx的相应内容中直接看到，比如后端tomcat返回404，nginx给你的可能就是
			空白。

2. 原有查询数据库得到clusterId,region_no等部分，改用新的 cluster,zone,region缓存方案。
	AbstractExecuteAction
	SingleNcResourceAction
	SingleNcResourceActionTest
	CancelCreateSnapshotExecuteAction
	CancelCreateSnapshotExecuteActionTest
	CreateSnapshotExecuteAction
	CreateSnapshotExecuteActionTest
	DetailSnapshotExecuteAction
	DetailSnapshotExecuteActionTest
	ListSnapshotExecuteAction
	ListSnapshotExecuteActionTest
	MountSnapshotExecuteAction
	MountSnapshotExecuteActionTest
	RemoveSnapshotExecuteAction
	RemoveSnapshotExecuteActionTest
	RetainSnapshotExecuteAction
	RetainSnapshotExecuteActionTest
	RollbackSnapshotExecuteAction
	RollbackSnapshotExecuteActionTest
	UnmountSnapshotExecuteAction
	UnmountSnapshotExecuteActionTest
	VmCreateExecuteAction
	VmCreateExecuteActionTest

3. 用户体系改造 houyi api
	user表修改，sql修改：
	alter table user add is_agent tinyint default 0 COMMENT '@desc 0 不是代理商，默认为0;1 是代理商';
	alter table user add agent_id int(10) unsigned DEFAULT null COMMENT '@desc 代理商ID，表示子用户属于哪个代理商';
	alter table user add image_using_mode int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted;1 : only private image permitted';
	alter table  user  add  image_using_mode  int(2) NOT NULL default 0 COMMENT '@desc 0 : public_and_private image permitted ; 1 : only private image permitted';

4. userholder 加标识isGent，标识用户身份。
	user插入逻辑确定：

5. 用户体系改造，houyi api验证逻辑（管理接口前的逻辑实现）
	- user表增加字段，参看第3条
	- 修改user表改动涉及的类改动，mapping文件改动
		user.xml
		User
	- UserHolder不变，存入的是代理商用户还是最终用户需要根据user的isgent属性判断
	- 老userId方式调用时，订正表时，isagent要标记为0，即非agent用户（比如万网）
	- 兼容老userId方式调用（isgent=0，但agent_id为空），新aliyunIDKP调用，管理接口调用（取得对应的子aliyunIDKP账号）
	- 新aliyunIDKP插入user记录，字段定义：
		aliyun_idkp
		key
			沿用其代理商的key，自己的key字段为空
				由于原user表字段约束，某些字段必须设置值（或者修改表约束，暂定位不动约束）
				user默认值：insertSql = " insert into  user ( default_region , default_zone , aliyun_idkp ,  user_name ,  md5_password ,  service_secret_key , email ,  service_access_id ,  status ,  gmt_last_login, agent_id ) 
											values('cn-hangzhou-1','cn-hangzhou-1-a', $idkp, $idkp, $idkp, $idkp, 'developer@aliyun.com', $idkp, 0, now(), 144) ; "
		region_no
		zone_no

		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day97 Wednesday, August 01, 2012

1. 
	* 用户体系改造，houyi api
	* 用户体系改造，SLB V2 api
	* 大region，slb v2兼容小region

2. 用户体系改造，houyi api
	- 是否为管理接口调用的判定？在白名单且aliyunidkp值为空
	- 在判断IDKP是否为空前，增加判断，请求的接口是否必须IDKP参数值
		在哪里判断？通过配置文件还是其他方式标识
	- 搭建 houyi api user_reform版本开发环境， doing
		10.250.8.214
	- 	- 万网等非白名单用户，数据表订正时，标识为非agent用户，即isagent=0（万网等非白名单用户，和以前一样没有切分子用户）


		
3.  用户体系改造，SLB V2 api
		需求待确定，SLB v2都需要做签名验证？
			user表存基本的验证必须字段，aliyunIDKP透传和调用。
			slb v2 api请求vm api和原来一样，走签名

4. 大region，slb v2兼容小region
	兼容用户大小region_no请求，小region_no转换为大region_no；
	传递给SLB后端为大region_no；
	后端接受的是大regionNo,对其数据推送影响？待确定
	- sql修改
		alter table region_mapping add vm_big_region_no varchar(32) NOT NULL COMMENT '@desc vm big region no',
		一个vm小region_no对应一个vm大region_no，一个vm大region_no对应一个slb region_no。
		修改约束，slb region_no与 vm_big_region_no联合主键：
			alter table region_mapping drop primary key
			alter table region_mapping add constraint primary key (region_no,vm_big_region_no);
		region_mapping表维护：
			vm小region_no和vm 大region_no关系，
			加上vm大region_no和slb region_no关系，2种关系。
			
	- region拦截器中中处理大小vm region_no请求兼容问题：
		将小vm region_no转换为大vm region_no后放入threadlocal中，
	- SLB API调用需要lb所属的vm region_no，SLB API调用SLB后端只在create_loadbalance接口传入了vm的region_no。8/1/20128/1/20128/1/2012
	- 兼容大小vm regionNo调用程序要处理的有两个地方：
		a. 由vm regionNo取到对应的slb reigon，从而知道slb region调用信息
		b. create_loadbalance接口需要将vm大region_no传递给SLB后端
	- bug id：[ID:175049]SLB V1版本，V2版本所使用region_no全部换成大region_no
	- 修改结束后，用 AbstractServiceTest 类测试几个接口，验证修改逻辑。	
	- 大region中SLB V2 API没有分支，提交的代码需要回滚，重新拉分支提交，待处理？


sudo bash root

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day98 Thursday, August 02, 2012

1. 
	* 用户体系改造 houyi api
		提供管理者调用功能，
		修改的点：
			- 签名验证逻辑实现完善
			- 白名单userid配置，以区别是idkp调用还是老接口调用及是
				配置到spring文件中（List便于判断是否存在）
			- 配置必需待IDKP参数的接口，即不提供管理功能的接口
				配置到spring文件中（List便于判断是否存在）
				必须带IDKP参数的接口，在拦截器中就判断后，如果没带返回错误；对于业务接口调用不用修改、
				业务接口不需修改的接口列表：
					1) 创建VM 
					2) 创建自定义image  ： A, 用户自定义image， idkp为用户id；B,对外售卖的自定义镜像， idkp指定为：26842
					3) 新增硬盘 
					4) 创建Group
					5) 创建快照 
					6) 创建Key Pair
			- 对于其他接口，都需要处理管理接口调用
				业务接口需要修改
			- 资源check类中（instance,ip,...ResourceChecker ），增加代理商调用处理逻辑，如果是代理商调用，且资源所属用户的代理商
				check列表：
					InstanceChecker
					GroupChecker
					ImageUseChecker
					IpAddressChecker

			- 对于有管理功能接口的修改，支持返回代理商下面所有用户对应原接口的数据
				以list_vm_status接口为例。
				查询数据时，原来根据user_id筛选；现在对于代理商调用，需要返回代理商下所有用户的数据。
			- 对于接口返回值，代理商调用和最终用户调用（老user_id方式比如万网，待IDKP值的用户）的区别
				类似detail_vm(指定了vm)，list_snapshot（指定了device）接口，指定了资源操作的接口，返回的是资源所属的信息（不存在跨代理商的子用户）
				类似list_vm_status（指定用户），指定用户去操作用户的数据的接口，代理商去调用时，返回或操作的是代理商下所有用户的数据
			- 对于代理商，也分配有IDKP，如果传入的是代理商自身的IDKP，视为最终用户处理
				在返回代理商所有用户的数据时，还需加上代理商自身的数据（能否通过将代理商的agent_id设置为其自身一个sql解决？）
			- 对于万网这些没有进行用户改造的用户，数据订正时，标识为非代理商用户。
			- session拦截器取到用户后，需要判断其is_agent值为1（是代理商），这层check是因为最终用户的session_id列也是有值的（现在订正为用户的idkp），如果其传session_id为自身
			的idkp时，会误认为其实代理商。
				上面方式兼容万网等老用户调用有问题（万网is_agent=0）,判断代理商条件修改为：能根据session_id找到用户且其service_secret_key值不为空
				
			- houyi api数据库的user表，service_secret_key字段去掉不为空约束，对于代理商的子用户，此字段为空
			- 配置白名单和action必须带IDKP的配置文件为：/houyi-console-openapi/src/main/resources/houyi-openapi.xml


	* 用户体系改造 SLB V2 API需求列表：
		- 所有请求都需签名验证（和用户体系改造前的验证一样）
		- 只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的key）
		- 原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
		- rs表数据订正

2. 用户体系改造 houyi api  —— 参考第一条说明
	管理接口修改：
		- detail_vm
			VmQueryExecuteAction
			getInstanceService().viewInstanceAtNc(instance); 做权限验证（注解方式），需要修改：
				修改check包下对应的 InstanceChecker 
				
			ResourceChecker抽象类中加入user cache，便于子checker调用。

			InstanceChecker 修改，后面vm验证所属用户操作都会用这个checker，不再做说明
			
		- list_vm_status
			先
	
	acl模块与service模块相互引用，导致依赖循环，如何解决？
			

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day99 Friday, August 03, 2012

1. 
	* 用户体系改造，houyi api
		- 解决maven循环依赖问题，将依赖的接口独立到一个接口模块中，接口的实现在其他模块中
			mvn a
		- cache方式，
	* 大region项目
		涉及SLB V2 API改动点，需要另开分支提交，不在下面分支提交，对已提交的兼容大小region_no调用修改进行回滚：
			http://svn.alisoft-inc.com/repos/alisoft/houyi/slb/slb_v2/trunk/sources/api
	* 用户体系改造 SLB V2 api 代码回滚，提交后，将需要修改的地方再reversion回来
		

2. 用户体系改造 houyi api 
	    管理接口修改
		check修改
			ipAddressChecker
				isBinary 判断ip是否为网段
		- list_vm_status			列表接口
			限定条件：
				region_no	必选	string		云服务器所属于的Region
				zone_no	必选	string		云服务器所属的可用域
					zone如果没传，取代理商的默认zone，保持原接口一致
			QueryVmListInfoExecuteAction
				是代理商时，去掉一些限定参数（如zone_id）	      ,不去掉，代理商也需要传
			instance.xml
				where条件里加上代理商查询条件，关联user表，查询出代理商所有子用户的数据
					传参时需要处理
			InstanceServiceImpl. 的 queryOwnInstances方法
				涉及传入user筛选条件的地方需要修改（处理代理商调用条件）。			
					数据订正逻辑？万网关联user_id字段，得到其instance列表；传入IDKP值的用户，也是关联user_id字段？
						数据订正案例：业务方提供aliyun_idkp和vm_name的映射表，订正工具到user表加入此idkp对应的用户（user_id为自增值）记录（如果没有的话），然后
						把user_id这个自增值更新到instance表对应vm_name的记录。
			修改的sql是否会被多个dao层调用，加入了agent_id筛选条件是否会影响其他调用此sql的逻辑？
				控制传入agetn_id的入口，即agent_id是显式的传入的，调用者知道传入agent_id会返回什么样的结果。
					当前设计，只好在dao层还去取user信息，后续需要重构，参数从service传过来，dao层不做过多依赖 -tip-
						在原有的statement上在加上分支查询逻辑，不利于维护，后续需要修改。
			InstanceDaoImpl
		- start_vm
			VmStartExecuteAction
			InstanceServiceImpl
				addUrlCallback方法中，当是代理商调用时，不能取UserHolder.getCurrentUserId()用户，暂定用instance对象的user_id属性，待确认？
					后面需要搜索整个项目用到：UserHolder.getCurrentUserId() 和 UserHolder.getCurrentUser() 的地方，确认调用是否ok？
				每个操作过后，把回调信息存入houyidb的url_callback表。
		- stop_vm
			VmStopExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法
		- restart_vm
			VmRestartExecuteAction
			和start_vm一样，也要调：addUrlCallback 方法


3. 用户体系改造bugfree
	http://bugfree.corp.taobao.com/bug/list/156?productmodule_id=12215


4. 系统设计tip
	- maven开发时，模块划分，在依赖方便需要设计好，可以剥离接口和实现到不同模块，避免交叉依赖问题
	 - 方法的参数设计，需要利于扩展，比如增加或减少参数，或不同类型的参数等需求。
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day100 Saturday, August 04, 2012

1. 
	* 
2. 用户体系改造 houyi api 
	重要：
		- 原用到UserHolder.getCurrentUser() 或 UserHolder.getCurrentUserId()的地方，都需要考虑user不是最终用户的情况了。	     （幽灵般的userholder~~~）
		- 代理商调用时，regionNo需要模拟最终用户的调用，否则会取代理商自身的默认region去操作。
		- describe_vip接口属于slb v1接口，不需要处理
	管理接口修改
	- release_vm
		VmReleaseExecuteAction
		InstanceServiceImpl
			releaseInstances方法，释放的VIP时需要传入user_id
				暂改为instance的user_id，即销毁vm时，vm的vip和vm的user_id一致。
			修改的点：
				GetVIPInfoCommand
				IpAddressServiceImpl
				IpAddressService
	- reset_vm
		VmResetExecuteAction
		ImageDaoImpl
			selectImageByNos方法在dao层，调用了threadlocal中的user，建议从调用层传参过来，避免各层充斥这全局变量。
			修改多个点：
				实现查询资源带user信息
		InstanceServiceImpl
			getInstanceService().addUrlCallback(instance, url,Message.statusSync);
	- reset_passwd
		VmResetPasswdExecuteAction	       
	- modify_vm
		VmModifyExecuteAction
	- modify_flow_limit
		VmModifyFlowLimitExecuteAction
	- modify_hostname
		ModifyVmHostNameAction
	- create_image
		CreateImgExecuteAction
		因为必带IDKP值，故userholder中的user为end user，业务逻辑代码不需修改
	- remove_image  ？
		先查询image和user关系，然后删除，代理商去查询image是否存在时，是否会存在返回多个image的情况，
		即：imageNo+end userId是唯一的，imageNo+agent userId不唯一，可能会删除过个子用户同名的image，待确认？
			加个参数标识代理商所操作的用户ID？targetAliyunIdkp
				加个resource_owner参数（值为IDKP），以便代理商告知api其操作资源的目标用户是谁
					错误提示：resource_owner不能为空
						RESOURCE_OWNER_IS_EMPTY(-8000,"resource_owner must set")	resource_owner参数值为空或没传
						RESOURCE_OWNER_NOT_EXISTS(-8005,"resource_owner not exists") resource_owner对应的用户找不到
		RemoveImgExecuteAction
			if(image.getUserId() != UserHolder.getCurrentUser().getUserId()){ 修改增加处理代理商调用逻辑
		ImageServiceImpl
			增加方法：queryImageDetailByImageNo(String image_no,Long userId)
	- recover_vm
		VmRecoverExecuteAction
	- query_available_ncs
		QueryAvaliableNcsExecuteAction
	- query_available_isos	 列表接口
		QueryAvaliableIsosExecuteAction
		IsoServiceImpl 
			加入代理商查询逻辑
				新增代理商查询业务接口
			修改点：
				IsoDao
				IsoDaoImpl
	- mount_iso
		VmMountIsoExecuteAction
			
		


3. 通过方法拦截器结合注解来实现权限验证，设计的好，是个好的方式。	   设计 -tip-
		将日志记录，性能统计，安全控制，事务处理，异常处理等代码从业务逻辑代码中划分出来，通过对这些行为的分离，
	我们希望可以将它们独立到非指导业务逻辑的方法中，进而改变这些行为的时候不影响业务逻辑的代码。

4. 业务逻辑堆在action层，导致依赖变动复杂
	

5. 读取Houyi配置信息发生错误，装载Endpoint信息不能为空
	houyi api启动时会初始化到控制系统的endpoint对象，需要提前在数据库配置好。
	at java.lang.Thread.run(Thread.java:619)
Caused by: com.aliyun.houyi.clc.CLCConfigException: 读取Houyi配置信息发生错误，装载Endpoint信息不能为空！
        at com.aliyun.houyi.service.support.CommandExecutorFactory.afterPropertiesSet(CommandExecutorFactory.java:88)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1369)

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day101 Monday, August 06, 2012

1. 
	* big region bug fix
		调用cancel_create_snapshot时传入的vm和snapshot不匹配时，报-95
	* 用户体系改造-houyi api修改
	* 用户体系改造，slb api 需求列表，最后修改整理说明，便于调用方知晓 待？

2. 用户体系改造-houyi api修改
	- mount_iso
		VmMountIsoExecuteAction
			增加处理代理商操作逻辑，此类验证逻辑代码后续可以移到service层，或者再抽取，提到切面中去。-tip-
	- unmount_iso
		VmUnMountIsoExecuteAction
	- add_disk
		AddDiskExecuteAction
	- remove_disk
		RemoveDiskExecuteAction
	- shift_disk
		ShiftDiskExecuteAction
		------
		...
		@Authority(
			{ @Entry(action = Action.VM),
					@Entry(action = Action.VM, resource = @Resource(argNo = 1)) })
			@InstanceStatusConstraint(statusSet = InstanceStatusSet.canRecover)
			public Result<?> shiftDisk(Instance instance, Instance srcInstance,	  权限验证，多个entry，后续指定位置
		...
		-------
	- detail_vm
		VmQueryExecuteAction
	- query_vm_security
		QueryVMSecurityExecuteAction
	- query_available_imgs			     列表接口
		是否需要带目标用户去查？
		查询代理商可用的image，这个结果是否为业务方需要的结果？
			暂定返回代理商下所有的
		ImgQueryExecuteAction
		ImageServiceImpl 增加代理商查询可用image逻辑
		imageUsingMode对结果的筛选逻辑？	代理商查询时，设置默认
			0 : default 可以使用公有image和自建image   1 : 只使用自己的image
	- query_unassigned_ips			 列表接口
		QueryUnassignedIpsExecuteAction
		user_id需要传给控制系统，结果如何返回？分页返回	，代理商调用返回public的ips
		注意：ip相关接口，user_id都传递给了控制系统，api层不能通过代理商调用
	- assign_ip  ？
		确认houyi db的subnet表，原user_id=144的记录，是否都订正为public？如果是这样，那么传递代理商ID给控制系统即可。
			这样接口就不需要修改，代理商传递代理商的userId给控制系统
		AssignIpExecuteAction
		IpAddressServiceImpl
			assignIpAddressCommand 需要带user_id	   ？？
			ipStatusCanOperate方法代理商调用逻辑添加
	- release_ip	？
		ReleaseIpExecuteAction
		ReleaseIpAddressCommand 需要带user_id操作，必须传IDKP？
	- bind_ip	    ？
		BindIpExecuteAction
		BindIpAddressCommand 需要user_id到控制系统		？
	- unbind_ip     ？
		UnBindIpExecuteAction
		UnbindIpAddressCommand 需要user_id传递给控制系统 ？
	- open_ftp_pasv
		OpenFtpPasvExecuteAction
		IpAddressServiceImpl
			非大二层网络下，需要判断用户是否可用ip
				ipStatusCanOperate方法，增加代理商调用处理逻辑
	- add_ip_segment			 ？
		AddIpSegmentExecuteAction
		大二层，AddIpSegmentCommand需要传user_id到控制系统，代理商如何调用	      ？
		非大二层，IpSegmentServiceImpl 的addIpSegment方法执行添加操作时，需要user_id ？
		解决：
			类似create_vm接口，必须传IDKP？
	- add_dns_alias
		AddDnsAliasExecuteAction
	- del_dns_alias
		RemoveDnsAliasExecuteAction
	- monitor_vm
		VmMonitorDataQueryExecuteAction
	- monitor_vm_topn	       doing
		VmTopNMonitorExecuteAction
		需要到monitor库去查询，哪里的表没有agent_id字段，只能在api层遍历agent对应的所有user，然后去查询
		monitorInfo.xml

	- create_group
		必须传IDKP
	- authorize_group		  
		AuthorizeGroupExecuteAction
		AbstractGroupAuthExecuteAction
		需要知道用户所拥有的group，代理商调用没有目标用户标识？
			根据之前查询出来的group，找到userId，保证源group都是属于这个userId的（原逻辑是直接传userHOlder.getCurrentUser().getUserId()）
	- revoke_group 撤销group规则	     
		RevokeGroupExecuteAction
	- adjust_group_auth
		AdjustGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 方法增加代理商查询子用户数据逻辑
	- remove_group
		RemoveGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupBaseInfo 
	- detail_group
		DetailGroupExecuteAction
		GroupServiceImpl
			viewOwnGroupWithAuthes方法增加代理商调用处理逻辑
	- query_groups			   列表接口
		QueryGroupsExecuteAction
		GroupServiceImpl
			viewOwnGroups方法增加代理商调用逻辑
	- guard_ddos
		GuardDDoSExecuteAction
		对ip进行操作
		IpAddressQuerier 查询出ip资源（需要user_id）	     结合ipaddresschecker
			public Map<String, IpAddress> query(String[] businessCodes) {
	- unguard_ddos
		UnguardDDosExecuteAction
	- query_vm_device
		QueryVmDeviceExecuteAction
	-  create_snapshot
		必须带IDKP
	- cancel_create_snapshot
		CancelCreateSnapshotExecuteAction
	- retain_snapshot
		RetainSnapshotExecuteAction
	- list_snapshot device的所有snapshot列表
		ListSnapshotExecuteAction
	- detail_snapshot
		DetailSnapshotExecuteAction
	- list_mounted_snapshot
		ListMountedSnapshotExecuteAction
	- remove_snapshot		imageService没注入？	     spring在配置文件中声明自动注入
		RemoveSnapshotExecuteAction
	- rollback_snapshot
		RollbackSnapshotExecuteAction
	- mount_snapshot
		MountSnapshotExecuteAction
	- unmount_snapshot
		UnmountSnapshotExecuteAction
	- query_nc_resources	 查询集群的nc资源信息（regionNo中的zone_id范围）
		ClusterNcResourceListAction
	- detail_nc
		SingleNcResourceAction
	- query_regions		？
		 RegionQueryAction
		 RegionSQL.xml 的 Region_listRegion 块带了分页参数，接口中无分页参数说明？
	- query_zones	  查询指定集群下的Zone信息
		ZoneQueryAction
	- query_racks 查询指定region,，指定zone下rack列表
		RackQueryAction
	- list_vlans	  查询指定集群的Zone下的VLan信息 ？
		VlanQueryAction
		GetVlanListCommand 需要传递user_id？
	- query_instance_type	  查询云服务器类型
		QueryInstanceTypeAction
	- create_key_pair
		必须传IDKP
	- remove_key_pair
		KeyPairRemoveExecuteAction
		KeyPairServiceImpl
			public ErrorCode removeOwnKeyPair(String keyPairName) { 增加代理商处理逻辑。
	- describe_key_pair
		KeyPairDescribeExecuteAction
		KeyPairServiceImpl
			修改describeOwnKeyPair方法，增加代理商调用逻辑
	
3. image ,iso,snapshot三者关系
	image为用户自定义image，系统盘
	iso镜像为数据镜像，可以被挂载。

4. 权限	，权限体系结构之一
	级联权限关系
		有了vm的操作权限，默认就有对vm已有资源的操作权限，比如卸载快照，查询其ip信息等

5. pojo
       BaseDomain中的动态字段，维护一个map，动态添加字段，这种方式用pojo传递动态新增的属性值到其他层。
	dynamicFileds

6. 用户体系改造，houyi api测试环境
	http://10.250.8.214/open/service?action=detail_vm
	部署的tomcat报内部错误：
		500 
		The server encountered an internal error () that prevented it from fulfilling this request.
		java.lang.NullPointerException
	org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
	com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
	org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
	org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
	com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
	org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
	org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
	org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
	org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
	是不是服务器文件不完整？
	请求路径错误，应用的struts拦截器抛错，没有log，定位struts没找到执行的action，
	nginx + tomcat
		nginx负责把符合要求的uri请求转发给tomcat，tomcat自己配置接受处理的uri。

	MQ配置
		message.properties
	EC配置（控制系统）

	配置文件目录
		/home/admin/.houyi/
	EC日志查看
		root@houyi-vm17.dev.sd.aliyun.com # vim /var/log/houyi/master/HouyiMaster.LOG
		10.250.8.212
7. nginx + tomcat
	请求uri设置，在nginx的conf配置文件里，告诉那些uri需要proxy_pass到目标应用服务器地址即可，nginx直接把请求转发给应用服务器。

8. ip,vlan 资源的userId在控制系统维护，依赖性增加

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day102 Tuesday, August 07, 2012

1. 
	* 用户体系改造 hoiuyi api
		remove_image最终定为加上 resource_owner标识最终用户
	
2. 处理day101第2条带问号的接口
	
3. linux + tomcat7 + houyi api		  ，500 internal error 1990 
	http://10.250.8.214/open/services
		正确URI
	http://10.250.8.214/open/service
		这个路径由于struts没有配置此action（请求的uri找不到映射的action，即找不到servlet），导致在struts的自带拦截器：
			 <interceptor name="prepare" class="com.opensymphony.xwork2.interceptor.PrepareInterceptor"/>
			执行时，浏览器报：500 java.lang.NullPointerException 空指针错误，
			错误如下：
				----------
					HTTP Status 500 -
					type Exception report
					message
					description The server encountered an internal error () that prevented it from fulfilling this request.
					exception
					java.lang.NullPointerException
						org.apache.struts2.impl.StrutsActionProxy.getErrorMessage(StrutsActionProxy.java:69)
						com.opensymphony.xwork2.DefaultActionProxy.prepare(DefaultActionProxy.java:185)
						org.apache.struts2.impl.StrutsActionProxy.prepare(StrutsActionProxy.java:63)
						org.apache.struts2.impl.StrutsActionProxyFactory.createActionProxy(StrutsActionProxyFactory.java:39)
						com.opensymphony.xwork2.DefaultActionProxyFactory.createActionProxy(DefaultActionProxyFactory.java:58)
						org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:500)
						org.apache.struts2.dispatcher.FilterDispatcher.doFilter(FilterDispatcher.java:432)
						org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:96)
						org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76)
				----------
			debug进入源码分析：
				----------
				    protected void prepare() {
					String profileKey = "create DefaultActionProxy: ";
					try {
					    UtilTimerStack.push(profileKey);
					    config = configuration.getRuntimeConfiguration().getActionConfig(namespace, actionName);

					    if (config == null && unknownHandlerManager.hasUnknownHandlers()) {
						config = unknownHandlerManager.handleUnknownAction(namespace, actionName);
					    }
					    if (config == null) {
						throw new ConfigurationException(getErrorMessage());
					    }		
				----------		
				在找不到  config 时抛出了ConfigurationException。

		从上面错误结果看，程序已经执行到houyi api应用中，在struts框架中报了错，找不到action的config信息。

		然后看houyi api的action配置，地址为services ，struts找不到action，prepare拦截器执行时就抛出了异常，可能是设置原因，应用和服务器都没有对应log，囧。

		实际struts.xml配置的action路径为services。

		小结：-tip-
			先判断问题出在哪个层次/部分，有log依据log，实在没log，debug源码，查找是什么原因导致抛出问题

4. vim 查找替换
	vi/vim 中可以使用 :s 命令来替换字符串
	:s/vivian/sky/ 替换当前行第一个 vivian 为 sky
	:s/vivian/sky/g 替换当前行所有 vivian 为 sky
	:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky
	:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky
	n 为数字，若 n 为 .，表示从当前行开始到最后一行
	:%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky
	:%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky
	可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符
	:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/	


5. 用户体系改造-houyi api白名单暂放到 houyi.properties中

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
typhoon

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day103 Thursday, August 09, 2012

1. 
	*  用户体系改造-houyi api
		集成测试
			
	* 用户体系改造-slb api
		rs表订正
			portal提供 lb_id ,IDKP映射表，订正lb_id不为null的记录中的user_id为IDKP值
			另外订正lb_id为null的记录的user_id为指定的测试用IDKP值
	* big region
		流量接口bigregion查询检查

2. 本机ip地址是通过dhcp获取的，测试环境调用本地mysql，需要调整ip。 houyi apidev测试环境（8.214）

3. 用户体系改造-houyi api
	不支持管理员是个最终用户
		比如不能创建vm
	集成测试
		白名单userId,
			管理接口
				299代理商操作其子用户数据
					比如detail_vm （属于275用户）
				调用必传IDKP接口时，报错
			最终用户
				299的一个子用户调用
			万网老用户调用	       （没进行用户体系改造，is_agent=0,agent_id=null）
				is_agent=0
	接口修改
		  monitor_vm_topn
		VmTopNMonitorExecuteAction

4. spring抽象类注入，spring接口注入有区别 * spring
	抽象类注入，子类需要显示的定义parent属性，指向到抽象类，否则抽象类中注入的属性不能从子类中获取。
	还是尽量面向接口编程
5. 测试 create_vm保证image对应的快照是存在的
	表查看，找快照id
	detail_snapshot 查询快照详情（有快照id值）	
	15-147019-137.vhd                           |          1 |      21 | 428         | AT03-HOUYI1
6. monitor计量数据	  业务
	根据是否大二层网络，对应的数据在不同的库中，表结构不一致。
		rx - rx_intra
7. slb 8.214测试
	http://10.250.8.214/slb/api?
	houyi api
	http://10.250.8.214/open/services?


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day104 Friday, August 10, 2012

1. 
	* 用户体系改造 slb api处理
		query_monitor_vms 
			VmPageMonitorExecuteAction

	* 用户体系改造　houyi api bug fix
		
2. 用户体系改造 slb api处理						  slb v2 api
	用户体系改造 SLB V2 API需求和关键点列表：
	1）所有请求都需签名验证（和用户体系改造前的验证一样）
	2）只支持新用户AliyunIDKP的调用（签名沿用其代理商（比如 144）的签名信息）
	3）原user表保持不变，用于SLB API签名验证（只记录代理商账户）和访问houyi api请求的签名
	4）rs表数据订正
	5）slb api透传aliyun_id值给slb后端，参数名和原来一致（即user_id）

	对照上面需求点，处理SLB api代码

	修改点：
		新增错误码：
			ILLEGAL_ALIYUN_IDKP(-2052, "illegal aliyun idkp"),
3. mysql数据dump
	mysqldump -hlocalhost -uxx -pxx dbName > /home/xx.sql
	source /home/xx.sql

4. 
	8.214开发测试环境的slb环境，新建slb后端的计量库便于测试，地址在本机
	houyi api 的db改用big region的db（6.27的db）


	http://www.cnblogs.com/lovecindywang/archive/2012/08/06/2624678.html

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day105

1. bug fix


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day106 Monday, August 13, 2012

1. 
	* 用户体系改造 houyi api bug fix
		- live_migrate_vm 接口修改（需求时文档未列出此接口）
		- create_vm接口
			处理user_image_mode的逻辑，  只用自己的image还是可用自己的和公有的	   （0可用自己和公有的image；1只能用属于自己的image）
		- reset_vm
			处理user_image_mode的逻辑，只用自己的image还是可用自己的和公有的
		- release_ip
			控制系统新增接口，根据ips得到vm_names，api根据vm_name验证是否有release_ip权限。
			
	* 
2. 

3.  Linux查看程序端口占用情况，占用的程序
	Tomcat 8080端口起不来，老提示端口已经被占用。
	使用命令：
	ps -aux | grep tomcat
	发现并没有8080端口的Tomcat进程。
	使用命令：netstat –apn
	查看所有的进程和端口使用情况。发现下面的进程列表，其中最后一栏是PID/Program name 
	clip_image002
	发现8080端口被PID为9658的Java进程占用。
	进一步使用命令：ps -aux | grep java，或者直接：ps -aux | grep pid 查看
	clip_image004
	就可以明确知道8080端口是被哪个程序占用了！然后判断是否使用KILL命令干掉！
	方法二：直接使用 netstat   -anp   |   grep  portno
	即：netstat –apn | grep 8080

4. houyi api db业务
	iso表
		user_iso - 标识iso是用户上传还是管理员上传的，用户查询iso时，不会返回user_iso=0的iso，
		visibility标识iso可见性，0为公有（此时忽略user_id），1为私有
	image表
		visibility 0为公有（忽略user_id），1为私有
	
	资源所属校验时，处理这些逻辑。不仅筛选user_id条件，还需处理公有私有情况等。

	remove_image
		删除image，用户必须为image所属的user_id，或其代理商
	
	user表
		image_user_mode 0可用自己和公有的image；1只能用属于自己的image
5. 根据ips返回names
	http://10.250.6.111/wiki/index.php/QueryVmByIp

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day107 Tuesday, August 14, 2012

1. 
	* 用户体系改造 - houyi api
		release_ip
		ReleaseIpExecuteAction
		需求：
			修复用户可以release状态为public的ip，控制系统提供根据ip列表找到vmName列表接口，api判断vm与用户的所属关系后执行release操作。

		IpAddressServiceImpl的 public Result<Object> releaseIpAddress(String ipAddress) 方法，注解判断权限
		@Authority(
		{ @Entry(action = Action.IpUse, actAtNetwork = HouyiNetworkSetting.nonBigEther, resource = @Resource(identify = Resource.Identify.QByCode, argNo = 0)) })
		对于以“，”隔开的ip，根据注解配置找到其资源查询类，验证每个ip的权限
		
		增加错误码：
			IP_ADDRESS_UNAUTHORIZED(-5008,"has no privilege to release ip"),
		release_ip
			ip为多个ip用“,”隔开时，根据资源定位region时报错-90。
			那个版本修复？
	* x
2. 签名时api去掉了某些字段，然后进行服务端签名，再与用户签名比对
	去掉 app_key,sign,sign_type，
		app_key

3. houyi api bug fix
	- bug id：187183
		UNIQUE KEY `key_pair` (`key_pair_name`,`user_id`) ，key_pair表key_pair_name不唯一

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day108 Wednesday, August 15, 2012

1. 
	*　用户体系改造 houyi api
		remove_key_pair
			KeyPairRemoveExecuteAction
			增加错误码：
				ILLEGAL_RESOURCE_OWNER(-8007,"illegal resource_owner")		   
					resource_owner表示的IDKP不是最终用户或不是当前代理商的子用户
		describe_key_pair
			KeyPairDescribeExecuteAction
			2个接口都增加 resource_owner 参数，标识代理商操作资源所属的用户标识，和remove_image类似。
		release_ip
			控制系统对于没分配的ip，vm_name值为0，此为控制系统的业务，返回给api应该为空。
			api判断ip没找到vm。
2. 

3. 业务
	资源No定位region，zone_ip表通过ip的long格式映射其对应的zone。

4. 
	 * @deprecated
	 * @param keyPairName
	 */
	public

5. 日志级别定义
	info
	debug
	error
	fatal
	对各种异常的日志级别设置
		系统级错误打error
		业务级别，用户级别打info
		调试用的打debug

6. rpc同步，异步调用 （封装rpc调用包，内部提供调用接口，对外屏蔽调用细节） aos
	线程池调用
	ThreadPoolExecutor
		java concurrent包
	
	每个请求封装为一个个工作任务（task，workitem），交给工作线程池去处理。
	
	接口开发，面向接口开发、
	
	合适的工具
7. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Wednesday, August 16, 2012 - Wednesday, August 26, 2012
missing by svn revert operation
补加：

* svn 代码合并(tortoiseSVN)
	eg：branch合并到trunk
		将trunk代码check out到本地，在其目录中调用merger命令，选择相应的选项，可先预览合并结果，进行合并；
		合并好后，通过diff工具(kdiff)对比branch目录，验证合并是否正确。
		kdiff
			对比时可设置参数，比如忽略的文件或目录等，然后比较。

* 发布步骤整理及演练，发布失败回滚方案设计
	保证正式发布顺利和优化发布流程

	发布步骤细化到每个命令，具体到能直接执行。

		服务停止
		数据订正
			大数据量，关联复杂时，订正方式，订正语句的优化
		代码发布
		回归测试

	多系统联合发布，需要全盘考虑。
* 系统全局变量使用设计
	在mvc架构中，全局变量控制在c层即控制层，比如action层，保证其他层的逻辑不会意外的从全局变量中去取值，导致控制层对逻辑的不可控，不利于后续的
	扩展和维护。
	userholder控制范围，就不会出现不走到dao的执行层（参数交给ibatis）都不敢保证最终传入的参数的担心，它可能在dao层从userholder取了userId传入的~
		不利于统一验证user的逻辑，而需要

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day118 Monday, August 27, 2012
1. 
	* big region+user_reform check go on
		对user_reform改动到的接口，big region和进来后，再进行review，是否满足user_reform需求？
		根据之前列出的修改接口列表查看：
			

	* 权限验证优化重构，aop，切面编程，方法拦截器
		可通过注解，将必要的参数放到方法的参数中，通过拦截器来处理这些注解，来验证用户操作资源的权限，这种设计，需要将待验证的资源显式的定义出来，比如
		通过放在方法的参数中（一般在service层），通过方法拦截，进行权限验证；从而，避免验证逻辑充斥业务代码，也利于维护和扩展。-tip-
			eg：
				现有的vm和user的验证就是通过方法拦截器，解析service层操作资源的方法中的参数（由注解定义check类型和check的arg）来验证用户操作vm的权限。

		验证能不能操作（比如现有的vm和user所属）和根据用户类型不同调用不同逻辑需要区分开，将功能分类；比如start_vm只需验证能否操作，后续操作管理接口和end user是一样的。

		小节下权限分类：
			不同系统有不同的权限体系，用户权限体系中，有角色权限（不同的角色对应的可访问功能不一样），资源权限/数据权限(对资源或数据用户是否有权限查看或操作)。
		
		user_reform项目由于接口设计，不便于

2. big region+user_reform check go on
	- 合并好的代码与big region比较，分析user_reform的修改点 ，是否正确
		无
	- 合并好的代码与user_reform比较，分析big_region的修改点，并分析是否需要再修改
	查看big region的代码是否有需要对应user_reform进行修改？
		- SnapshotServiceImpl
		     mountSnapshot方法，快照校验所属用户需要修改？
		- SnapshotServiceImpl.
		     unmountSnapshot方法
		- AdjustGroupExecuteAction
		     executeAdjust方法查找group传入的userId
			       Group group1 = groupControlService.viewOwnGroupBaseInfo(resourceOwnerUserId, source, bigRregionNo);
			
		- AuthorizeGroupExecuteAction
		     原groupService替换为big region的groupcontrulservice，user部分需要修改        ？如果userId只用来生成lock，不进行比较所属，是否不需要修改？
		     建议，从group取userId不从userHolder取。
		- ReviseVmToolsAction
		     可忽略
		- QueryGroupVmInfoExecuteAction
		     user_reform没修改，遗漏？
		- GlobalErrorMessage
		     -191错误码重复
		- JoinGroupAction        还有其他big region加入涉及取userHolder取user操作的新接口
		     此为新增接口，不修改，根据代理商找不到group。
		  
3.  big region+user_reform check go on

	- release_vm
		GroupControlServiceImpl
			private boolean leaveAllGroups(Instance instance, List<Group> groups) {
			long ownerId = instance.getUserId();//此处替换从userholder取user
		测试验证释放VIP是否正确
	- remove_image
		imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId()))
		userholder中取user改为显式传参
	- bind_ip
		houyi-spring-action.xml
		action配置修改：
			<property name="limit" value="780"/> 改为：<property name="limit" value="5000"/>
	- authorize_group		  
		AuthorizeGroupExecuteAction
		groupControlService.addGroupAuth(currentUserId, group, groupAuth)
			此处user只用来取锁，代理商也ok，或者直接改为用group对象中的userId来做锁？谭总确认：已确认锁的逻辑不受影响
	- adjust_group_auth
		AdjustGroupExecuteAction
		private ResultDomain executeAdjust(String bigRregionNo, String groupNo, String adjust) {
		查询group时，显式的带userId过去查，替换原来从userholder中取的方式
	- remove_group
		RemoveGroupExecuteAction
			groupControlService.deleteGroup(resourceOwnerUserId, bigRegionNo, groupNo);	      //此为新方法，用了userholder.getUser()
			修改：
				GroupControlServiceImpl
					public OperationResult deleteGroup(long ownerId, String bigRegionNo, String groupNo) {
	- mount_snapshot
		MountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),	      -913状态码废弃
	- unmount_snapshot
		UnmountSnapshotExecuteAction
		暂修改为去掉user和快照所属校验，控制系统对deviceNO和快照已有校验
		-913 变为 SNAPSHOT_NOT_EXISTED_AT_VM(-970, "snapshot not existed at vm"),



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day119 Tuesday, August 28, 2012

1. 
	* 
2. 

3. 服务器性能检查
	netstat

4. lb

5. tcp状态
	eg：在6.33上打开一个访问8.214的mysql命令行终端
	在8.214上查看网络连接情况：
	netstat -n | grep 3306
	tcp        0      0 10.250.8.214:3306           10.250.6.33:45378           ESTABLISHED
	表示一个打开的连接

* TCP/IP
	tcp状态：
	LISTEN：侦听来自远方的TCP端口的连接请求
	SYN-SENT：再发送连接请求后等待匹配的连接请求
	SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认
	ESTABLISHED：代表一个打开的连接
	FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认
	FIN-WAIT-2：从远程TCP等待连接中断请求
	CLOSE-WAIT：等待从本地用户发来的连接中断请求
	CLOSING：等待远程TCP对连接中断的确认
	LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认
	TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认
	CLOSED：没有任何连接状态

6. 网络性能监控
	netperf
		is  a  benchmark that can be used to measure various aspects of networking performance.
	netserver
		a network performance benchmark server, listens  for  connections  from a benchmark, and responds accordingly.
	http://www.netperf.org/netperf/

7. grep -v 查看不匹配的行
	eg：
		tail -f -n200 logs/openapi/info.log logs/openapi/error.log | grep -v 'hello world'

8. pangu 存储
	k-v
	rds

9. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day120 Wednesday, August 29, 2012

1. 
	* 通过工具模拟大量并发请求，重现socket red 问题（服务访问缓慢甚至返回500错误）
		然后分析原因
	* big region合到trunk后，数据库表的改动对mapping文件中sql的影响排查
		执行dao单元测试
	* 大region对sql的修改，用户体系改造需检查是否有对应的修改
		eg ：image.xml查询用户可用image sql

		svn对比big region对mapping文件做了哪些修改点

		*inBigRegion(xxx的方法都需要考虑从新加入user_reform逻辑。
		byagentid 是否已换成新方法？
			inbigregion的方法，还是用此方法，加入user_reform逻辑
				没有对应的byagentid方法，就是从原有的方法中取需要的逻辑
			byagentid还是用byagentid方法，加入bigregion逻辑
		
		daoimpl类中搜索 inbigregion ， byagentid

		所有byagentid的sql加上big region逻辑。
			
		- remove_image
			RemoveImgExecuteAction
			用imageService.queryParentImageInBigRegion(imageNo,currentUser.getUserId())查询是否正确？
	
			

2. 通过工具模拟大量并发请求，重现socket red 问题
	- 并发请求，重现socketread问题
		ab -n10000 -c300 http://xxxx

	- jstack dump堆栈信息 （以时间段dump多份便于对比）
		jstack 1345 > dump1
		----------
		java的线程状态值有：定义在 java.lang.State中
			A thread state. A thread can be in one of the following states: 

			NEW
				A thread that has not yet started is in this state. 
			RUNNABLE
				A thread executing in the Java virtual machine is in this state. 
			BLOCKED
				A thread that is blocked waiting for a monitor lock is in this state. 
			WAITING
				A thread that is waiting indefinitely for another thread to perform a particular action is in this state. 
			TIMED_WAITING
				A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. 
			TERMINATED
				A thread that has exited is in this state. 
			
			A thread can be in only one state at a given point in time. These states are virtual machine states which do not reflect any operating system thread states.
		----------


		分析运行的细节
3. linux help
	svn --help
	svn co --help
4. jboss ,tomcat
	tomcat报 NoClassDefFoundError: org/slf4j/impl/StaticLoggerBinder ，表示缺少对应的jar或找不到
	但，jboss却正常，是不是在不同的jar中有了这个实现？

5. ibatis映射
	返回值中无此参数和表中无此字段的报错的区别？
		select中无此字段：
		org.springframework.jdbc.BadSqlGrammarException: SqlMapClient operation; bad SQL grammar []; nested exception is com.ibatis.common.jdbc.exception.NestedSQLException:   
		--- The error occurred in ibatis/iso.xml.  
		--- The error occurred while applying a result map.  
		--- Check the iso.isoMap.  
		--- Check the result mapping for the 'bigRegionNo' property.  
		--- Cause: java.sql.SQLException: Column 'big_region_no' not found.
		
		select有此字段，表中无此字段：
		？

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day121 Thursday, August 30, 2012

1. 
	* bug fix test 
	* houyi api 需要 slf4j-log4j12-1.5.8.jar依赖
		jboss可不要？
	* slb v2 ，houyi api
		cache梳理，是否提供reload方法？


2. bug fix test 

	create_vm
		image使用
	reset_vm
		image的检查
	create_image	     (create_snapshot)
		
	remove_image

	start_vm后，收到MQ的状态改变可确定vm是否启动成功。

3. 控制系统维护vmName?
	报vm exists

4. create_snapshot过程中，master重启
	ec master reboot ,but agent at nc is still working ,they send the latest message to db or master 
5. slb v2 ，houyi api cache梳理，是否提供reload方法？


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day122 Friday, August 31, 2012

1. 
	* user_reform & big region test
		instance
		image
		iso


	* 缓存方案 ，简单缓存方案(需要有缓存更新机制)
		缓存超时



2. mysql执行计划，sql执行计划
	mysql> desc select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

	mysql> explain select * from region r left join region_alias r_a on r.region_no=r_a.region_no ;       
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	| id | select_type | table | type | possible_keys | key     | key_len | ref               | rows | Extra |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+
	|  1 | SIMPLE      | r     | ALL  | NULL          | NULL    | NULL    | NULL              |    3 |       |
	|  1 | SIMPLE      | r_a   | ref  | PRIMARY       | PRIMARY | 98      | houyi.r.region_no |    1 |       |
	+----+-------------+-------+------+---------------+---------+---------+-------------------+------+-------+

3. 既然使用这些载体或工具，要想发挥其应有的能力，就需要去了解它，熟悉它，会用工具，用好工具，让它们帮忙我们更好的实现目标。-tip-
	linux iptables
	....
4. Customized Image
	from System Snapshot

5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day123 Saturday, September 01, 2012

1. 
	* 

2. 

3. slb
	临时预发布环境信息：

	ag 10.250.6.36

	master 192.168.1.16

	lvs: 192.168.1.111 - 112

	haproxy: 192.168.1.113

			192.168.1.115

	rs: 192.168.1.116-119

	db: mysql -h 10.250.6.1 -uroot

	qa回归用机器：10.250.6.37


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day124 Monday, September 03, 2012

1. 
	* code，msg采用英文编码，避免中文问题
	* 测试用户默认region为非大二层region，能正常调用接口

2. linux进程系统参数
	ps aux | grep -i java 

	cat /proc/7314/limits | grep 'open files'
	Max open files            655360               655360               files     

	进程打开最大文件数：655360
3. 测试用户默认region为非大二层region，能正常调用接口	  (新老api share db，非空字段的地方是否ok？)
	8.214上
	用户未非大二层region
	region表加入此region
	zone表加入zone

	259 ，229的子用户，设置非大二层region，测试：
		detail_vm
		list_snapshot
		query_vm_device
		create_snapshot
		detail_snapshot
		mount_snapshot
		list_mounted_snapshot
		unmount_snapshot
		restart_vm
		stop_vm
		remove_snapshot
			在mount快照过后执行remove_snapshot操作，报状态不对删除不了；再unmount_snapshot，执行删除同样问题；
			<rsp>
			  <code>-912</code>
			  <msg>device or snapshot is not ready</msg>
			</rsp>

		query_available_isos
		list_vm_status
		monitor_vm 无数据（vm监控数据）
		monitor_vm_topn 同上

		query_nc_resources
		query_vm_security.

		add_disk
		remove_disk
		detail_nc
		query_instance_type
		query_available_ncs
		list_vlans
		query_zones
		query_regions
		release_ip
		assign_ip
		query_available_imgs
		query_unassigned_ips

		rollback_snapshot
		list_snapshot


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day125 Tuesday, September 04, 2012

1. 
	* big region 
		历史bug
	* api_user_reform在加入了大region的db修改后，接口测试



2. 业务
	mount_snapshot
		vm1的快照，挂载到vm2，需要验证vm1，vm2的关系
	pending,startfail
		master第一次启动失败pending，成功后为stop
		api根据MQ和显示调用更新状态，pending只能通过MQ收到，故detail_vm会从starting到pending。


3. api_user_reform在加入了大region的db修改后，接口测试
	query_regions
	query_zones
	list_vlans
	query_instance_type

	detail_vm
	query_vm_device
	query_available_isos
	list_vm_status

	monitor_vm（无数据）
	monitor_vm_topn

	create_snapshot
		控制系统返回-1的码，api统一报-95，如快照名称重复
	detail_snapshot
	cancel_create_snapshot
		已cancel的再去cancel，控制系统报：
		-1,"desc":  "cancel failed
		-95给用户
	mount_snapshot
	list_mounted_snapshot
	unmount_snapshot
	remove_snapshot
	restart_vm
	stop_vm
	rollback_snapshot
	query_unassigned_ips
	query_available_imgs
	assign_ip
	release_ip
	query_available_ncs
	detail_nc
	add_disk
	query_vm_security
	query_nc_resources



4. fdisk	   linux分区	    * fdisk
	fdisk -l
	fdisk /dev/hda
	n
	1
	10
	w
	reboot
	fdisk -l
	vgcreate guestvol /dev/hda6
		No physical volume label read from /dev/hda6
		Physical volume "/dev/hda6" successfully created
		Volume group "guestvol" successfully created
	lvcreate -nubuntu01 -L5.4G /dev/guestvol
		Rounding up size to full physical extent 5.40 GB
		Logical volume "ubuntu01" created


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day126 Wednesday, September 05, 2012

1. 
	* 线上环境，vm创建后起不来原因定位，无pending？


2. 线上环境，vm创建后起不来原因定位，无pending？
		已定位为资源不足

3. 业务,日志查看，控制系统日志，问题排查
	iso在nuwa本地pangu，image同步工具
	nuwa(master日志)
		从reigon找nuwa地址，ssh上去，/apaxxx/nuwa/xxx.Log查看 日志，控制系统日志

	api-kfc(httpd-record service name and address,do forward)-master/netc-agent-operate

	控制系统角色查看 (AG上查看)/apsara/deploy/Fuxisrvd -v houyi status 	       （ag作为master访问入口admin gateway）
	master、netc
	history |grep status
	/apsara/deploy/Fuxisrvd -v houyi status
		查看控制系统，集群的角色（由多少nc组成，有哪些服务角色，各自在那个ip上）
	ps axf |grep master
	vim /var/log/houyi/master/HouyiMaster.LOG
	vim /var/log/houyi/netc/HouyiNetcLOG

	vim /var/log/xen/xend.log
	
	eg：
		在6.33的api，看nuwa，找ag，看master日志

	pending状态需要结合配置，保证start_vm ok。

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day127 Thursday, September 06, 2012

1. 
	*  wiki
	* 6.33日志
		release_vm时master调netc释放ip失败，在ag 6.27上找到netc地址，上去看log


2. 
	
		
3. 抛砖引玉的效果
	demo

4. /apaxx目录下熟悉各组件，总线服务
	nuwa
	pangu
	...

5. lvs			       * tcpdump
	tcpdump -n -i any port 80		   tcp包查看

	eg:
	------
	Examples
		To print all packets arriving at or departing from devo:
		tcpdump host devo
		1. To print traffic between gil and either devo or bevo:
		tcpdump ip host gil and \(devo bevo\)
		2. To print all IP packets between bevo and any host except gil:
		tcpdump ip host bevo and bevo gil
		3. To print all traffic between local hosts and hosts on network 192.100.192:
		tcpdump net 192.100.192
		4. To print traffic neither sourced from nor destined for local hosts:
		tcpdump ip and not net localnet
		5. To print the start and end packets (the SYN and FIN packets) of each TCP conversation that
		involves a non-local host:
		tcpdump \(tcp[13] \& 3 !=0 and not src and dst net localnet\)
		6. To print all ICMP packets that are not echo requests or replies (not ping packets):
		tcpdump \(icmp[0] !=8 and icmp[0] !=0\)
		7. To immediately print packet information, enter
		tcpdump -I
		8. To specify the token-ring interface to listen on, enter:
		tcpdump -i tr0
		9. To print packet information to the file TraceInfo, enter:
		tcpdump -wTraceInfo
	------


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day128 Friday, September 07, 2012

1. 
	* wanwang 连调
		缓存deviceNo等数据，重新生成缓存
	* 

					

2. wanwang 连调 ，业务
	release_vm失败丢失group信息。
	vm stopped，group

	join group多次fail，no log


														
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day129 Monday, September 10, 2012

1. 
	* big region连调支持
		a. 环境原因导致的netc调用释放ip超时
		b. image的版权问题，密码问题
		c. 老master的无资源启动问题
		d. vm的连通性授权访问问题（默认规则不能访问，参考api文档）
		e. 


	* ec了解
	* 新项目讨论
		a. 计费需求(安全提供查询接口)
		b. ace4j
		c. big region项目2新增接口进行user reform改造
		d. big region包括api和master的bug fix
		e. houyi计量推送优化
		f. houyi api优化，部分重构；本地cache的优化（统一cache实现，提供cache更新方案-自动或被动调用）
	* ace4j(lxc)需要api提供几个防火墙的接口，看master提供的接口说明
		添加ip白名单（ip放行）
		删除ip白名单
		查询ip白名单列表
			补偿描述
		http://10.250.6.111/wiki/index.php/Firewall_add_white_list
		
	* 并发测试
		环境
	* 双开发布
		region查询存在的limit 1问题。
		

2. 联调 big region
	api log > master log (master位置从ag中调用命令查看)> nc log(xen log)	nc_id位置从master的log中确定，nc ip从api接口中查询

	liveMigrateFailed 不对外，统一报-95

3. 数据库索引，数据库优化

	从数据库的查询方式分析优化方案，参考数据库提供的优化功能，比如各种索引等。

	指导方针：
			要了解跑在数据库上的应用程序/用户，使用索引的主要目的是为了提高跑在数据库上应用程序读取和操作数据的速度，
		如果你不知道程序主要对数据库进行什么操作，索引优化就无从谈起。


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day130 Tuesday, September 11, 2012

1. 
	* ace4j对houyi api的需求背景说明
		master提供的3个接口熟悉，对应api的接口设计


2. 
