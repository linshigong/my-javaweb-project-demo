
本机ip 10.1.171.132

通过svn管理记录文件 eg google code  TortoiseSVN
搭建centos测试系统(vmware7) ssh连接
wiki scheng 
Linux Container - LXC	
openapi rds  (关系型数据库服务)
	ref: http://www.ibm.com/developerworks/linux/library/l-lxc-containers/
test
	https://my-javaweb-project-demo.googlecode.com/svn
google 检索 apache site:*.apache.org 高级搜索
* mysql
	一些命令使用，可以参考gui工具执行命令的sql参考 比如：Aqua Data Studio ，在alter table 时可以查看preview sql
	insert into vip (host,port,gmt_create,gmt_modify)values('host3',80,'2012-12-12 00:00:00','2012-12-12 00:00:00'); //id为自增列
	 select last_insert_id() as id from vip limit 1 

Apply address:http://www.taobao.ali.com/chanpin/wb/Lists/List4/view.aspx
* ide eclipse 文件夹上下关系 project property - build path -move
	source folder ，设置源码包 build path - change to source folder
	xml 标签自动提示，schema ，dtd定义正确即可
* 简称
	 业务运营支撑系统(BOSS) 
	 弹性计算(Elastic Computing - EC) 
	 云引擎(Cloud Engine - CE) 
	 开放存储服务(Open Storage Service - OSS) 
	 云数据库服务(Cloud Database Service - CDS) 
	 阿里邮箱(Ali Mail - AM) 
	 开放表服务（Open Table Service - OTS）
* 工具类
	 apache commond 
		StringUtils 
		...
* 协作
	”系统间协作的部分，找到相关人员沟通效率就快了，都是人定义的，谁定义谁最清楚 “

* python
	Zope - opensource appserver written by python

* Google App Engine 
		虽然GAE有很多限制和缺陷，但是我对GAE还是喜爱有加的。GAE是免费的，任何人都可以很轻松的通过GAE实现自己的Web应用。比如，做一些实用的小工具，
	实现一个博客程序来练手。通过GAE，我们可以轻松的搭建属于自己的Blog(micolog)，搭建属于自己的Wiki系统(NancyWiki)。
	没有GAE，就不会有大家都懂的gappproxy，gtap，twiter-feed。是的，你懂的。	
	from: http://www.cnblogs.com/coderzh/archive/2010/11/30/goodby-google-app-engine.html
* powerdesigner  生成er图
	pd12 连接mysql，database菜单-configure data connection - 选择 connection profiles 设置即可

* shell
	- 根据参数执行任务shell
		#!/bin/bash
		if [ ! -n "$1" ]
		then
		    echo  "usage: $0 [insert|remove]";
		    exit 1
		fi
		ACTION="$1"
		case $ACTION in
		    insert) echo "device inserted.";;
		    remove) echo "device removed.";;
		    *) echo "invalid option.";;
		esac

* linux
linux shell命令中Esac是什么意思？
一些刚刚接触bash编程的人，总是很奇怪bash里的一些关键字，知道它的功能，但不知道为什么要这样写。比如：
#!/bin/bash
if [ ! -n "$1" ]
then
    echo  "usage: $0 [insert|remove]";
    exit 1
fi
ACTION="$1"
case $ACTION in
    insert) echo "device inserted.";;
    remove) echo "device removed.";;
    *) echo "invalid option.";;
esac
fi是if语句的结束，esac是case语句的结束。Fi和esac这样的关键字是不是很怪异呢？呵，仔细想一想，一点也不怪，考虑一下{} [] 等等，{和}是垂直轴对称的，[和]是垂直轴对称的。现在来看， if和fi及case和esac不也是这样吗？它们刚好反过，分别表示开始和结束。


linux command eg 命令
字符转换 unix字符 window字符
unix2dos dos2unix

SERVER=/home/user - 定义=号两边不能有空格

将shell执行的pid保存到文件，读取文件中的pid关闭程序
#! /bin/sh
SERVER=/home/chengs
java test > $SERVER/server.log & echo $! > $SERVER/server.pid
kill `cat server.pid` -- 这里注意是波浪号 ，不是单引号
	--------
		############################################################################
		mount -l -t

		sh startup.sh

		############################################################################
		该如何才能知道系统都有什么硬件设备，有如下几种方式：
		方式一：
		使用lsdev命令，可以显示系统中的设备及其特征。
		例如：lsdev -C
		但是一般的系统上可能没有这个命令，比如我装的fedora上面就没有这个命令。
		方法二：
		显示/proc/dev文件，这个文件记录了系统的一些硬件信息，
		例如：cat /proc/dev
		方法三：
		如果要查找特定的usb设备，则可以使用lsusb命令，列出所有的usb设备。
		如果要查找特定的pcmcia设备，则可以使用lspcmcia命令，列出所有的pcmcia设备。
		如果要查找特定的pci设备，则可以使用lspci命令，列出所有的pcm设备。
		来自：达内BBS
		############################################################################

		有些在freebsd下也能用…
		# uname -a               # 查看内核/操作系统/CPU信息
		# head -n 1 /etc/issue   # 查看操作系统版本
		# cat /proc/cpuinfo      # 查看CPU信息
		# hostname               # 查看计算机名
		# lspci -tv              # 列出所有PCI设备
		# lsusb -tv              # 列出所有USB设备
		# lsmod                  # 列出加载的内核模块
		# env                    # 查看环境变量资源
		# free -m                # 查看内存使用量和交换区使用量
		# df -h                  # 查看各分区使用情况
		# du -sh         # 查看指定目录的大小
		# grep MemTotal /proc/meminfo   # 查看内存总量
		# grep MemFree /proc/meminfo    # 查看空闲内存量
		# uptime                 # 查看系统运行时间、用户数、负载
		# cat /proc/loadavg      # 查看系统负载磁盘和分区
		# mount | column -t      # 查看挂接的分区状态
		# fdisk -l               # 查看所有分区
		# swapon -s              # 查看所有交换分区
		# hdparm -i /dev/hda     # 查看磁盘参数(仅适用于IDE设备)
		# dmesg | grep IDE       # 查看启动时IDE设备检测状况网络
		# ifconfig               # 查看所有网络接口的属性
		# iptables -L            # 查看防火墙设置
		# route -n               # 查看路由表
		# netstat -lntp          # 查看所有监听端口
		# netstat -antp          # 查看所有已经建立的连接
		# netstat -s             # 查看网络统计信息进程
		# ps -ef                 # 查看所有进程
		# top                    # 实时显示进程状态用户
		# w                      # 查看活动用户
		# id             # 查看指定用户信息
		# last                   # 查看用户登录日志
		# cut -d: -f1 /etc/passwd   # 查看系统所有用户
		# cut -d: -f1 /etc/group    # 查看系统所有组
		# crontab -l             # 查看当前用户的计划任务服务
		# chkconfig –list       # 列出所有系统服务
		# chkconfig –list | grep on    # 列出所有启动的系统服务程序
		# rpm -qa                # 查看所有安装的软件包
		cat /proc/cpuinfo ：查看CPU相关参数
		cat /proc/partitions ：查看硬盘和分区
		cat /proc/meminfo ：查看内存信息
		cat /proc/version ：查看版本，类似uname -r
		cat /proc/ioports ：查看设备io端口
		cat /proc/interrupts ：查看中断
		cat /proc/pci ：查看pci设备的信息
		cat /proc/swaps ：查看所有swap分区的信息
		来自：达内BBS
		############################################################################
		linux目录架构
		/   根目录
		/bin    常用的命令 binary file 的目錄
		/boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内
		     /boot/grub/menu.lst   GRUB设置
		     /boot/vmlinuz   内核
		     /boot/initrd     核心解壓縮所需 RAM Disk
		/dev    系统周边设备     
		/etc    系统相关设定文件
		     /etc/DIR_COLORS   设定颜色
		     /etc/HOSTNAME   设定用户的节点名
		     /etc/NETWORKING   只有YES标明网络存在
		     /etc/host.conf 文件说明用户的系统如何查询节点名
		     /etc/hosts 设定用户自已的IP与名字的对应表
		     /etc/hosts.allow 设置允许使用inetd的机器使用 
		     /etc/hosts.deny 设置不允许使用inetd的机器使用
		     /etc/hosts.equiv 设置远端机不用密码
		     /etc/inetd.conf 设定系统网络守护进程inetd的配置
		     /etc/gateways 设定路由器
		     /etc/protocols 设定系统支持的协议
		     /etc/named.boot 设定本机为名字服务器的配置文件
		     /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP
		     /etc/resolv.conf    设置DNS  
		     /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這兩個 X Server 的設定檔
		     /etc/fstab    记录开机要mount的文件系统
		     /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel
		     /etc/issue 记录用户登录前显示的信息
		     /etc/group 设定用户的组名与相关信息
		     /etc/passwd 帐号信息
		     /etc/shadow 密码信息
		     /etc/sudoers 可以sudo命令的配置文件
		     /etc/securetty 设定哪些终端可以让root登录
		     /etc/login.defs 所有用户登录时的缺省配置
		     /etc/exports 设定NFS系统用的
		     /etc/init.d/   所有服務的預設啟動 script 都是放在這裡的，例如要啟動或者關閉
		     /etc/xinetd.d/  這就是所謂的 super daemon 管理的各項服務的設定檔目錄
		     /etc/modprobe.conf   内核模块额外参数设定
		     /etc/syslog.conf   日志设置文件
		/home   使用者家目录
		/lib    系统会使用到的函数库
		     /lib/modules   kernel 的相关模块
		     /var/lib/rpm   rpm套件安装处 
		/lost+found    系統不正常產生錯誤時，會將一些遺失的片段放置於此目錄下
		/mnt     外设的挂载点
		/media   与/mnt类似
		/opt     主机额外安装的软件
		/proc    虚拟目录，是内存的映射
		      /proc/version   内核版本
		       /proc/sys/kernel   系统内核功能
		/root    系统管理员的家目录
		/sbin    系统管理员才能执行的指令
		/srv     一些服務啟動之後，這些服務所需要取用的資料目錄
		/tmp     一般使用者或者是正在執行的程序暫時放置檔案的地方
		/usr     最大的目录，存许应用程序和文件
		    /usr/X11R6：   X-Window目录 
		    /usr/src：    Linux源代码
		    /usr/include：系统头文件
		    /usr/openwin 存放SUN的OpenWin 
		    /usr/man 在线使用手册
		    /usr/bin           使用者可執行的 binary file 的目錄
		    /usr/local/bin     使用者可執行的 binary file 的目錄
		    /usr/lib           系统会使用到的函数库
		    /usr/local/lib     系统会使用到的函数库
		    /usr/sbin          系统管理员才能执行的指令
		    /usr/local/sbin    系统管理员才能执行的指令
		/var   日志文件
		    /var/log/secure    記錄登入系統存取資料的檔案，例如 pop3, ssh, telnet, ftp 等都會記錄在此檔案中
		    /var/log/wtmp      記錄登入者的訊息資料, last
		    /var/log/messages  幾乎系統發生的錯誤訊息
		    /var/log/boot.log  記錄開機或者是一些服務啟動的時候，所顯示的啟動或關閉訊息
		    /var/log/maillog   紀錄郵件存取或往來( sendmail 與 pop3 )的使用者記錄
		    /var/log/cron      記錄 crontab 這個例行性服務的內容
		    /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log/procmail.log：
		    分別是幾個不同的網路服務的記錄檔
		 
		一些常用的基本命令:
		uname -a    查看内核版本       
		ls -al    显示所有文件的属性
			-R, --recursive            list subdirectories recursively
			ls -a -R 显示子目录文件
		pwd         显示当前路径        
		cd -    返回上一次目录     cd ~    返回主目录
		date s      设置时间、日期          
		cal      显示日历     cal 2006
		bc          计算器具               
		man  & info     帮助手册
		locale     显示当前字体     locale -a    所有可用字体     /etc/sysconfig/i18n设置文件
		LANG=en    使用英文字体            
		sync       将数据同步写入硬盘        
		shutdonw -h now & half & poweroff  关机
		reboot     重启                   
		startx  &  init 5   进入图形介面
		/work  & ?work    向上、下查找文档内容
		chgrp      改变档案群组  chgrp testing install.log    
		chown     改变所属人   chown root:root install.log
		chmod      改变属性     chmod 777 install.log     read=4  write=2  execute=1
		cp   复制   cp filename
		rm   删除文件  rm -rf filename   强制删除文件 
			rm -rf directory or file   -r或-R或--recursive 　递归处理，将指定目录下的所有文件及子目录一并处理。
		rmdir   删除文件夹
		mv  移动    mv 123.txt 222.txt  重命名
		mkdir     创建文件夹  
			mkdir -p /usr/dat.txt  # -p 参数表示如果上级目录不存在则创建
		touch     创建文件  更新当前时间
		cat       由第一行开始显示     cat |more  分页
		nl        在内容前加行号
		more  &  less   一面一面翻动
		head -n filename   显示第N行内容
		tail -n filename  显示后N行内容
		od        显示非纯文档
		df -h 显示分区空间
		du  显示目录或文件的大小
		fdisk   分区设置    fdisk -l /dev/hda  显示硬盘分区状态
		mkfs    建立各种文件系统  mkfs -t ext3  /dev/ram15   
		fsck    检查和修复LINUX档案
		ln      硬链接   ln -s  软件链接
		whereis   查找命令
		locate    查找
		find      查找   find / -name "***.***"
		which     查看工具
		whoami    显示当前用户
		gcc -v    查看GCC版本
		chattr +i filename  禁止删除   chattr -i filename  取消禁止
		lsattr    显示隐藏档属性
		updatedb  更新资料库
		mke2fs    格式化   mkfs -t ext3 
		dd if=/etc/passwd of=/tmp/passwd.bak    备份
		mount     列出系统所有的分区
		mount -t iso9660 /dev/cdrom /mnt/cdrom   挂载光盘
		mount -t vfat /dev/fd0 /mnt/floppy       挂载软盘
		mount -t vfat -o iocharset=utf8,umask=000 /dev/hda2 /mnt/hda2   挂载fat32分区
		mount -t ntfs -o nls=utf8,umask=000 /dev/hda3 /mnt/hda3         挂载ntfs分区
		Linux-NTFS Project: http://linux-ntfs.sourceforge.net/
		umount /mnt/hda3  缷载
		ifconfig   显示或设置网络设备
		service network restart   重启网卡  
		ifdown eth0  关闭网卡
		ifup eth0    开启网卡
		clear    清屏
		history    历史记录       !55  执行第55个指令
		stty   设置终端    stty -a
		fdisk /mbr   删除GRUB
		at     僅進行一次的工作排程
		crontab   循環執行的例行性命令    [e]编辑,[l]显示,[r]删除任务
		&       后台运行程序    tar -zxvf 123.tar.gz & --------->后台运行
		jobs    观看后台暂停的程序   jobs -l
		fg      将后台程序调到前台   fg n ------>n是数字,可以指定进行那个程序
		bg      让工作在后台运行
		kill    结束进程    kill -9 PID     [9]强制结束,[15]正常结束,[l]列出可用的kill信号
		ps aux  查看后台程序   
		top     查看后台程序   top -d 2    每两秒更新一次        top -d 2 -p10604   观看某个PID
			top -b -n 2 > /tmp/top.txt ----->將 top 的資訊進行 2 次，然後將結果輸出到 /tmp/top.txt    
		pstree   以树状图显示程序    [A]以 ASCII 來連接, [u]列出PID, [p]列出帐号
		killall   要刪除某個服務    killall -9 httpd
		free      显示内存状态     free -m  -------->以M为单位显示
		uptime    显示目前系统开机时间
		netstat   显示网络状态    netstat -tulnp------>找出目前系統上已在監聽的網路連線及其 PID
		dmesg     显示开机信息    demsg | more
		nice      设置优先权      nice -n -5 vi & ----->用 root 給一個 nice 植為 -5 ，用於執行 vi 
		renice    调整已存在优先权
		runlevel  显示目前的runlevel
		depmod    分析可载入模块的相依性
		lsmod     显示已载入系统的模块
		modinfo   显示kernel模块的信息
		insmod    载入模块
		modprobe   自动处理可载入模块
		rmmod     删除模块
		chkconfig   检查，设置系统的各种服务     chkconfig --list ----->列出各项服务状态
		ntsysv     设置系统的各种服务
		cpio      备份文件
		 

		压缩命令：
		 *.Z      compress 程式壓縮的檔案； 
		 *.bz2    bzip2 程式壓縮的檔案； 
		 *.gz     gzip 程式壓縮的檔案； 
		 *.tar    tar 程式打包的資料，並沒有壓縮過； 
		 *.tar.gz tar 程式打包的檔案，其中並且經過 gzip 的壓縮
		compress filename  压缩文件  加[-d]解压  uncompress
		gzip filename   压缩  加[-d]解压  zcat 123.gz 查看压缩文件内容
		bzip2 -z filename  压缩  加[-d]解压   bzcat filename.bz2  查看压缩文件内容
		tar -cvf /home/123.tar /etc  打包，不压缩
		tar -xvf 123.tar   解开包
		tar -zxvf /home/123.tar.gz  以gzip解压
		tar -jxvf /home/123.tar.bz2  以bzip2解压
		tar -ztvf /tmp/etc.tar.gz   查看tar内容
		cpio -covB  > [file|device]   份份
		cpio -icduv < [file|device]   还原
		 
		vi一般用法
		一般模式              编辑模式                  指令模式
		h 左               a,i,r,o,A,I,R,O             :w 保存
		j 下                进入编辑模式                :w! 强制保存
		k 上                dd 删除光标当前行           :q! 不保存离开
		l 右                ndd 删除n行                 :wq! 保存后离开
		0 移动到行首        yy 复制当前行                :e! 还原原始档
		$ 移动到行尾        nyy 复制n行                  :w filename 另存为
		H 屏幕最上          p,P 粘贴                     :set nu 设置行号
		M 屏幕中央          u  撤消                      :set nonu 取消行号
		L 屏幕最下          [Ctrl]+r 重做上一个动作       ZZ 保存离开
		G 档案最后一行      [ctrl]+z 暂停退出            :set nohlsearch   永久地关闭高亮显示
		/work 向下搜索                                   :sp 同时打开两个文档 
		?work 向上搜索                                   [Ctrl]+w 两个文档设换
		gg 移动到档案第一行                              :nohlsearch    暂时关闭高亮显示
		 
		认识SHELL
		alias    显示当前所有的命令别名      alias lm="ls -al"   命令别名    unalias lm 取消命令别名
		type      类似which
		exprot    设置或显示环境变量
		exprot PATH="$PATH":/sbin  添加/sbin入PATH路径
		echo $PATH    显示PATH路径
		bash      进入子程序
		name=yang     设定变量
		unset name    取消变量
		echo $name    显示变量的内容
		myname="$name its me"   &   myname='$name its me'     单引号时$name失去变量内容
		ciw=/etc/sysconfig/network-scripts/     设置路径
		env      列出所有环境变量
		echo $RANDOM    显示随意产生的数
		set      设置SHELL
		PS1='[\u@\h \w \A #\#]\$ '     提示字元的設定
		   [root@linux ~]# read [-pt] variable     -----------读取键盘输入的变量
		   參數：
		   -p  ：後面可以接提示字元！
		   -t  ：後面可以接等待的『秒數！』
		declare    声明 shell 变量
		ulimit -a   显示所有限制资料
		 ls /tmp/yang && echo "exist" || echo "not exist"
		 意思是說，當 ls /tmp/yang 執行後，若正確，就執行echo "exist" ,若有問題，就執行echo "not exist" 
		 echo $PATH | cut -d ':' -f 5       以:为分隔符,读取第5段内容
		 export | cut -c 10-20      读取第10到20个字节的内容
		 last | grep 'root'    搜索有root的一行,加[-v]反向搜索
		 cat /etc/passwd | sort    排序显示
		 cat /etc/passwd | wc      显示『行、字数、字节数』
		正规表示法
		[root@test root]# grep [-acinv] '搜尋字串' filename
		       參數說明：
		       -a ：將 binary 檔案以 text 檔案的方式搜尋資料
		       -c ：計算找到 '搜尋字串' 的次數
		       -i ：忽略大小寫的不同，所以大小寫視為相同
		       -n ：順便輸出行號
		       -v ：反向選擇，亦即顯示出沒有 '搜尋字串' 內容的那一行！

		文件内容查找：

		 grep -n 'the' 123.txt     搜索the字符 -----------搜尋特定字串       
		 grep -n 't[ea]st' 123.txt    搜索test或taste两个字符---------利用 [] 來搜尋集合字元
		 grep -n '[^g]oo' 123.txt     搜索前面不为g的oo-----------向選擇 [^] 
		 grep -n '[0-9]' 123.txt  搜索有0-9的数字
		 grep -n '^the' 123.txt 搜索以the为行首-----------行首搜索^
		 grep -n '^[^a-zA-Z]' 123.txt  搜索不以英文字母开头
		 grep -n '[a-z]$' 123.txt    搜索以a-z结尾的行---------- 行尾搜索$
		 grep -n 'g..d' 123.txt     搜索开头g结尾d字符----------任意一個字元 . 
		 grep -n 'ooo*' 123.txt     搜索至少有两个oo的字符---------重複字元 *
		sed    文本流编辑器    利用脚本命令来处理文本文件
		awd    模式扫描和处理语言
		 nl 123.txt | sed '2,5d'   删除第二到第五行的内容
		diff     比较文件的差异
		cmp      比较两个文件是否有差异
		patch    修补文件
		pr       要打印的文件格式化
		 

		帐号管理
		/etc/passwd    系统帐号信息
		/etc/shadow    帐号密码信息    经MD5 32位加密
		     在密码栏前面加『 * 』『 ! 』禁止使用某帐号
		/etc/group     系统群组信息
		/etc/gshadow
		newgrp    改变登陆组
		useradd  &  adduser    建立新用户  ---------> useradd -m test  自动建立用户的登入目录
			  useradd -m -g pgroup test --------->指定所属级
		/etc/default/useradd   相关设定
		/etc/login.defs       UID/GID 有關的設定
		passwd    更改密码 -----------> passwd test
		usermod   修改用户帐号
		userdel   删除帐号 ----------->userdel -r test
		chsh      更换登陆系统时使用的SHELL   [-l]显示可用的SHELL;[-s]修改自己的SHELL
		chfn      改变finger指令显示的信息
		finger    查找并显示用户信息
		id        显示用户的ID ----------->  id test
		groupadd   添加组
		groupmod   与usermod类似
		groupdel   删除组
		su test    更改用户   su -    进入root,且使用root的环境变量
		sudo       以其他身份来执行指令
		visudo     编辑/etc/sudoers      加入一行『 test ALL=(ALL) ALL 』
			   %wheel ALL = (ALL) ALL               系统里所有wheel群组的用户都可用sudo
			   %wheel ALL = (ALL) NOPASSWD: ALL     wheel群组所有用户都不用密码NOPASSWD
		       User_Alias ADMPW = vbird, dmtsai, vbird1, vbird3         加入ADMPW组
		       ADMPW ALL = NOPASSWD: !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, \
		       !/usr/bin/passwd root      可以更改使用者密码,但不能更改root密码 (在指令前面加入 ! 代表不可)
		PAM (Pluggable Authentication Modules, 嵌入式模組)
		who & w     看谁在线                     
		last        最近登陆主机的信息
		lastlog     最近登入的時間    读取 /var/log/lastlog 
		talk        与其他用户交谈
		write       发送信息    write test   [ctrl]+d 发送
		mesg        设置终端机的写入权限    mesg n 禁止接收     mesg y 
		wall        向所有用户发送信息    wall this is q test
		mail        写mail   
		/etc/default/useradd    家目录默认设置
		quota      显示磁盘已使用的空间与限制     quota -guvs ----->秀出目前 root 自己的 quota 限制值
			   quota -vu   查询
		quotacheck   检查磁盘的使用空间与限制     quotacheck -avug  ----->將所有的在 /etc/mtab 內，含有 quota 支援的 partition 進行掃瞄
			     [-m] 强制扫描  
		     quota一定要是独立的分区,要有quota.user和quota.group两件文件,在/etc/fstab添加一句:
		     /dev/hda3 /home ext3 defaults,usrquota,grpquota 1 2
		     chmod 600 quota*         设置完成,重启生效
		edquota    编辑用户或群组的quota  [u]用户,[g]群组,[p]复制,[t]设置宽限期限 
			   edquota -a yang       edquota -p yang -u young ----->复制    
		quotaon    开启磁盘空间限制     quotaon -auvg -------->啟動所有的具有 quota 的 filesystem
		quotaoff   关闭磁盘空间限制     quotaoff -a  -------->關閉了 quota 的限制
		repquota -av     查閱系統內所有的具有 quota 的 filesystem 的限值狀態
		Quota 從開始準備 filesystem 的支援到整個設定結束的主要的步驟大概是：
		1、設定 partition 的 filesystem 支援 quota 參數：
		由於 quota 必須要讓 partition 上面的 filesystem 支援才行，一般來說， 支援度最好的是 ext2/ext3 ，
		其他的 filesystem 類型鳥哥我是沒有試過啦！ 啟動 filesystem 支援 quota 最簡單就是編輯 /etc/fstab ，
		使得準備要開放的 quota 磁碟可以支援 quota 囉；
		2、建立 quota 記錄檔：
		剛剛前面講過，整個 quota 進行磁碟限制值記錄的檔案是 aquota.user/aquota.group， 
		要建立這兩個檔案就必須要先利用 quotacheck 掃瞄才行喔！
		3、編輯 quota 限制值資料：
		再來就是使用 edquota 來編輯每個使用者或群組的可使用空間囉；
		4、重新掃瞄與啟動 quota ：
		設定好 quota 之後，建議可以再進行一次 quotacheck ，然後再以 quotaon 來啟動吧！

		开机流程简介
		1、載入 BIOS 的硬體資訊，並取得第一個開機裝置的代號； 
		2、讀取第一個開機裝置的 MBR 的 boot Loader (亦即是 lilo, grub, spfdisk 等等) 的開機資訊； 
		3、載入 Kernel 作業系統核心資訊， Kernel 開始解壓縮，並且嘗試驅動所有硬體裝置； 
		4、Kernel 執行 init 程式並取得 run-level 資訊； 
		5、init 執行 /etc/rc.d/rc.sysinit 檔案； 
		6、啟動核心的外掛模組 (/etc/modprobe.conf)； 
		7、init 執行 run-level 的各個批次檔( Scripts )； 
		8、init 執行 /etc/rc.d/rc.local 檔案； 
		9、執行 /bin/login 程式，並等待使用者登入； 
		10、登入之後開始以 Shell 控管主機。 
		在/etc/rc.d/rc3.d內,以S开头的为开机启动,以K开头的为关闭,接着的数字代表执行顺序
		GRUB vga设定
		彩度\解析度  640x480  800x600  1024x768  1280x1024   bit 
		    256        769      771      773       775      8 bit 
		   32768       784      787      790       793     15 bit 
		   65536       785      788      791       794     16 bit 
		   16.8M       786      789      792       795     32 bit 

		./configure    检查系统信息       ./configure --help | more  帮助信息
		make clean     清除之前留下的文件
		make           编译
		make install   安装
		rpm -q  ----->查询是否安装             rpm -ql ------>查询该套件所有的目录
		rpm -qi ----->查询套件的说明资料       rpm -qc[d] ----->设定档与说明档
		rpm -ivh  ---->安装                    rpm -V  -------->查看套件有否更动过
		rpm -e  ------>删除                    rpm -Uvh ------->升级安装  
		--nodeps ----->强行安装                --test ----->测试安装

		来自：http://blogold.chinaunix.net/u/30619/showart.php?id=249558

		1、alternatives --install /usr/bin/java java /usr/java/jdk1.6.0_24/bin/java 300
		这一句的意思是给java这个LINK多加一个Path。至于什么是Link，请man alternatives，看alternatives命令的帮助，就大概能明白了。
		2、alternatives --config java 会出现一下信息：
		----------------------------------------------------------------------
		*  1           /usr/lib/jvm/jre-1.4.2-gcj/bin/java
		+ 2           /usr/java/jdk1.6.0_24/bin/java
		按 Enter 来保存当前选择[+]，或键入选择号码：2

		shutdown -h now
		halt
	
		############################################################################

		linux下Java环境的配置
		linux下Java环境的配置
			　　现在用linux的朋友越来越多了，前几天就有两个朋友问我linux下怎么配置java环境，我想还有很多朋友想了解学习这方面的东西，就写一个完全一点的linux java环境配置吧，希望对大家有帮助。
		一. 下载jdk5.0 for linux
		　　到sun的主页 http://java.sun.com/j2se/1.5.0/download.jsp 下载jdk安装文件jdk-1_5_0_05-linux-i586.bin
		二. 解压安装jdk
		　　在shell终端下进入jdk-1_5_0_05-linux-i586.bin文件所在目录，执行命令./jdk-1_5_0_05-linux-i586.bin这时会出现一段协议，连继敲回车，当询问是否同意的时候，输入yes，回车。之后会在当前目录下生成一个jdk-1.5.0_05目录，你可以将它复制到任何一个目录下。
		三. 需要配置的环境变量
		　　1.PATH环境变量。作用是指定命令搜索路径，在shell下面执行命令时，它会到PATH变量所指定的路径中查找看是否能找到相应的命令程序。我们需要把jdk安装目录下的bin目录增加到现有的PATH变量中，bin目录中包含经常要用到的可执行文件如javac/java/javadoc等待，设置好PATH变量后，就可以在任何目录下执行javac/java等工具了。
		　　2.CLASSPATH环境变量。作用是指定类搜索路径，要使用已经编写好的类，前提当然是能够找到它们了，JVM就是通过CLASSPTH来寻找类的。我们需要把jdk安装目录下的lib子目录中的dt.jar和tools.jar设置到CLASSPATH中，当然，当前目录“.”也必须加入到该变量中。
		　　3. JAVA_HOME环境变量。它指向jdk的安装目录，Eclipse/NetBeans/Tomcat等软件就是通过搜索JAVA_HOME变量来找到并使用安装好的jdk。
		四. 三种配置环境变量的方法
		　　1. 修改/etc/profile文件
		　　　　如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。
		　　　　·用文本编辑器打开/etc/profile
		　　　　·在profile文件末尾加入：
		　　　　　　JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　PATH=$JAVA_HOME/binPATH
		　　　　　　CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		　　　　　　export JAVA_HOME
		　　　　　　export PATH
		　　　　　　export CLASSPATH
		　　　　·重新登录
		　　　　·注解
		　　　　　　a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录
		　　　　　　b. linux下用冒号“:”来分隔路径
		　　　　　　c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值
		　　　　　　　 在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种
		　　　　　　　 常见的错误。
		　　　　　　d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。
		　　　　　　e. export是把这三个变量导出为全局变量。
		　　　　　　f. 大小写必须严格区分。
		　　2. 修改.bashrc文件
		　　　　
		　　　　这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。
		　　　　·用文本编辑器打开用户目录下的.bashrc文件
		　　　　·在.bashrc文件末尾加入：
		　　　　　　
		　　　　　　set JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　　　export JAVA_HOME
		　　　　　　set PATH=$JAVA_HOME/binPATH
			    　　　export PATH
			    　　　set CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
			    　　　export CLASSPATH
		　　　　·重新登录
		　　3. 直接在shell下设置变量
		　　　　不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。
		　　　　只需在shell终端执行下列命令：
		　　　　export JAVA_HOME=/usr/share/jdk1.5.0_05
		　　　　export PATH=$JAVA_HOME/binPATH
		　　　　export CLASSPATH=.JAVA_HOME/lib/dt.jarJAVA_HOME/lib/tools.jar
		五. 测试jdk
		　　1. 用文本编辑器新建一个Test.java文件，在其中输入以下代码并保存：
		　　　　public class test {
		　　　　　　public static void main(String args[]) {
		　　　　　　　　System.out.println("A new jdk test !");
		　　　　　　}
		　　　　}
		　　2. 编译：在shell终端执行命令 javac Test.java
		　　3. 运行：在shell终端执行命令 java Test
		　　　　当shell下出现“A new jdk test !”字样则jdk运行正常。
		六. 卸载jdk
		　　·找到jdk安装目录的_uninst子目录
		　　·在shell终端执行命令./uninstall.sh即可卸载jdk。 



		############################################################################


		vi 

		保存退出
		* shift + ： 进入命令行状态
		* 输入wq ，并回车，即保存退出

		:w   保存文件但不退出vi 
		:w file 将修改另外保存到file中，不退出vi 
		:w!  强制保存，不推出vi
		:wq  保存文件并退出vi 
		:wq! 强制保存文件，并退出vi
		q：不保存文件，退出vi
		:q!不保存文件，强制退出vi 
		:e! 放弃所有修改，从上次保存文件开始再编辑



		############################################################################


		命令 结果定向到文件 

		rpm -qa >> /home/show

		查找到安装软件包名 ： java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5

		rpm -ql  java-1.6.0-openjdk-1.6.0.0-1.16.b17.el5 —— 查询该套件所有的目录
		
		查找是否已安装mysql，有则卸载掉
		# rpm -qa | grep -i  mysql
		...
		# rpm -e xxxx

		############################################################################

		安装 bin格式的jdk软件包 
		进到软件包的目录下 ，运行 ./jdk1.6***.bin 即可安装
	--------

* base64 编码
		Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。
	Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符
	（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为
	适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所
	直接看到。

*	vmware7安装centos5 - 自定义方式 -  OS Installlation步骤选择install later(否则后面可能直接进入live CD 模式，不是正常安装模式)
		确保ssh模块已安装 ，通过ssh客户端连接vmware中的centos

*	虚拟集群,及其相关应用测试【测试】

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day1 2012年3月14日

1. 环境
	..
	eclipse 
		常用插件
			svn 
			mavn 
			spring插件 - 主要编译配置文件定位到java文件,自动提示等便捷功能
			Eclipse Web Tools Platform
			python 插件 pydev http://pydev.org/updates
			uml
			er - http://www.eclipse.org/gef/updates/index.php
			...
		eclipse jre配置设置为jdk
		-vm
		D:\Java\jdk1.6.0_10\bin\javaw.exe —— 这里路径注意下 空格之类处理为 progra~1
		-vmargs
		-Dosgi.requiredJavaVersion=1.5
		-Xms128m
		-Xmx256m	

		ide eclipse 依赖 ，依赖从上到下配置，上面不对会导致下面的类编译报错。

2. svn 
	wiki http://wiki.houyi.alibaba-inc.com/dashboard.action
	申请权限
	http://svn.alisoft-inc.com/repos/alisoft/houyi/console/
	和
	http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine

	department
	阿里云-云计算业务发展-基础产品-平台技术

wiki：
	http://wiki.houyi.alibaba-inc.com/dashboard.action

bbs:
	http://bbs.aliyun.com/

feitian SLB ACE（JCE...） (ACE - Ali Cloud Engine云引擎) OSS(kv storage)
	
	ACE php container, nodejs container,jsp container

3. Cloud Engine - Cloud Engine是一个基于AEC的web应用托管运行环境，能够提供应用的自动伸缩以及多种核心服务。
	
	Google App Engine
	


4. linux about
	* gdb:
		What is GDB?

		GDB, the GNU Project debugger, allows you to see what is going on `inside' another program while it executes -- or what another 
		program was doing at the moment it crashed.

		GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act:

		    Start your program, specifying anything that might affect its behavior.
		    Make your program stop on specified conditions.
		    Examine what has happened, when your program has stopped.
		    Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. 

		The program being debugged can be written in Ada, C, C++, Objective-C, Pascal (and many other languages). Those programs might 
		be executing on the same machine as GDB (native) or on another machine (remote). GDB can run on most popular UNIX and Microsoft 
		Windows variants.
		
		DBP实战：
			问题：

			ndb进程cpu达到99%，怀疑存在死循环，需要排查

			1.   ps -eLf | grep nbd-server

			找出那个nbd-server线程占用cpu最高，记住他的ppid（线程id）

			2.   gdb nbd-server <pid>

			启动gdb ， attach到运行的nbd-server进程

			3.  info thread

			查看所有线程

			4. thread 10

			切换到这个线程

			5. bt

			查看线程堆栈

			6. 分析代码

			from:wiki http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=3932212

5. ssh client
	PuTTY
6. 路由  消息订阅

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day2 2012年3月15日

1. 后羿系统
	
	参考资料 Sina App Engine数据存储服务架构
	
2.  svn 账户授权 即 svn 注册用户 
	wb_shen.chengs + pwd

	url
		...houyi/cloudengine
		...houyi/console
			branches-api...-requirement 

3. houyi 异步通知
	
	异步通知是后羿系统提供的一套基于HTTP协议主动向客户系统发送VM操作结果状态的基础服务。其基本流程如下：
	 
	通知系统交互流程说明：
	1. 后羿向外部系统发出通知，即访问外部系统提供的通知接收URL。// 外部系统提供的通知接收URL
	2. 客户系统接到通知请求，根据签名信息验证通知真实性。
	3. 客户系统处理通知。
	摘自：houyi api 说明doc

4. 通过svn checkout 部分houyi项目 熟悉 【配置 svn】
	svn插件拉下项目代码 (svn 项目绑定到对应的svn库上，(对于eclipse，如果绑定错误，先删除原有svn库，从team里重新绑定即可))
	maven插件构建
		部分依赖找不到的情况：(把所在目录下已有的文件删除)通过到依赖库手动下载pom文件和相应jar.swf等文件，放到maven的.m2文件夹中解决。
		nexus http://10.250.6.11:8081/nexus/index.html#welcome 

	maven版本问题，比如编译，打包等用到plugin时，选择合适的版本，配置正确的repo，目前用maven2.2.1
		配置文件配置:
			   <!-- profile
			     | Specifies a set of introductions to the build process, to be activated using one or more of the
			     | mechanisms described above. For inheritance purposes, and to activate profiles via <activatedProfiles/>
			     | or the command line, profiles have to have an ID that is unique.
			     |
			     | An encouraged best practice for profile identification is to use a consistent naming convention
			     | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc.
			     | This will make it more intuitive to understand what the set of introduced profiles is attempting
			     | to accomplish, particularly when you only have a list of profile id's for debug.
			     |
			     | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo.
			    -->			
			 <profile>
			      <id>dev</id>

			      <repositories>
				
				<repository>
				  <id>ay32-releases</id>
				  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>

				<repository>
				  <id>nexus-releases</id>
				  <name>nexusre</name>
				  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
				  <releases>
						<enabled>true</enabled>
					  </releases>
					  <snapshots>
						<enabled>true</enabled>
					  </snapshots>
				</repository>
			     
			 </repositories>
				  <pluginRepositories>
				<pluginRepository>
					  <id>ay32-releases</id>
					  <url>http://repos.houyi.alibaba-inc.com:8081/nexus/content/repositories/releases/</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				<pluginRepository>
					  <id>nexus-releases</id>
					  <url>http://10.250.6.11:8081/nexus/content/groups/public</url>
					  <releases>
					    <enabled>true</enabled>
					  </releases>
					  <snapshots>
					   <enabled>true</enabled>
				      </snapshots>
					</pluginRepository>

				  </pluginRepositories>
			    </profile>
	

	通过maven脚本构建测试部署 ？

	ide里编辑，构建工具统一编译测试部署。
	mvn clean install -rf :houyi-console-web-staff 
	参数参考：
		usage: mvn [options] [<goal(s)>] [<phase(s)>]

		Options:
		 -am,--also-make                        If project list is specified, al
							build projects required by the
							list
		 -amd,--also-make-dependents            If project list is specified, al
							build projects that depend on
							projects on the list
		 -B,--batch-mode                        Run in non-interactive (batch)
							mode
		 -C,--strict-checksums                  Fail the build if checksums don'
							match
		 -c,--lax-checksums                     Warn if checksums don't match
		 -cpu,--check-plugin-updates            Ineffective, only kept for
							backward compatibility
		 -D,--define <arg>                      Define a system property
		 -e,--errors                            Produce execution error messages
		 -emp,--encrypt-master-password <arg>   Encrypt master security password
		 -ep,--encrypt-password <arg>           Encrypt server password
		 -f,--file <arg>                        Force the use of an alternate PO
							file.
		 -fae,--fail-at-end                     Only fail the build afterwards;
							allow all non-impacted builds to
							continue
		 -ff,--fail-fast                        Stop at first failure in
							reactorized builds
		 -fn,--fail-never                       NEVER fail the build, regardless
							of project result
		 -gs,--global-settings <arg>            Alternate path for the global
							settings file
		 -h,--help                              Display help information
		 -l,--log-file <arg>                    Log file to where all build outp
							will go.
		 -N,--non-recursive                     Do not recurse into sub-projects
		 -npr,--no-plugin-registry              Ineffective, only kept for
							backward compatibility
		 -npu,--no-plugin-updates               Ineffective, only kept for
							backward compatibility
		 -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates
		 -o,--offline                           Work offline
		 -P,--activate-profiles <arg>           Comma-delimited list of profiles
							to activate
		 -pl,--projects <arg>                   Comma-delimited list of specifie
							reactor projects to build instea
							of all projects. A project can b
							specified by [groupId]:artifactI
							or by its relative path.
		 -q,--quiet                             Quiet output - only show errors
		 -rf,--resume-from <arg>                Resume reactor from specified
							project
		 -s,--settings <arg>                    Alternate path for the user
							settings file
		 -T,--threads <arg>                     Thread count, for instance 2.0C
							where C is core multiplied
		 -t,--toolchains <arg>                  Alternate path for the user
							toolchains file
		 -U,--update-snapshots                  Forces a check for updated
							releases and snapshots on remote
							repositories
		 -up,--update-plugins                   Ineffective, only kept for
							backward compatibility
		 -V,--show-version                      Display version information
							WITHOUT stopping build
		 -v,--version                           Display version information
		 -X,--debug                             Produce execution debug output

		tip:
			parent pom declare most properties ,plugins etc,models under parent,only needs to config special requiments ,if needs to make war package for example and it can references definetions
			from parent pom ,just lile inheritance(eg struts2's configuration file struts.xml).

		maven 插件 ，源码自动下载

5. 熟悉houyi代码，结构
	
	
	
6. xStream javabean 与 xml ，json映射工具
	参考：http://www.cnblogs.com/hoojo/archive/2011/04/22/2025197.html
	部分如下：
		xStream框架

			xStream可以轻易的将Java对象和xml文档相互转换，而且可以修改某个特定的属性和节点名称，而且也支持json的转换；

			前面有介绍过json-lib这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/21/2023805.html

			以及Jackson这个框架，在线博文：http://www.cnblogs.com/hoojo/archive/2011/04/22/2024628.html

			它们都完美支持JSON，但是对xml的支持还不是很好。一定程度上限制了对Java对象的描述，不能让xml完全体现到对Java对象的描述。
			这里将会介绍xStream对JSON、XML的完美支持。xStream不仅对XML的转换非常友好，而且提供annotation注解，可以在JavaBean中完成
			对xml节点、属性的描述。以及对JSON也支持，只需要提供相关的JSONDriver就可以完成转换。 

7. Quartz 调度

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day3 2012年3月16日

1. 项目目录结构 maven
	
	

2. 结合 openapi 接口文档 ，熟悉代码，规范

	以hoyi-console-openapi  为例，熟悉大体框架，配置方式，处理流程
	
	根据应用上下文配置文件(web.xml)，熟悉请求处理流程 （web应用 ,java应用根据程序入口）

		* struts2 ,spring ,ibatis
			spring
				bean管理 - pojo,dao bean ,action
				事务管理
			struts2
				interceptor - default and user defined interceptors / pluggable
				objectfactory = spring
				action继承/接口关系(部分)
					public class RackQueryAction extends PagingInfovalidator implements ExecuteAction {
					-> public abstract class PagingInfovalidator extends AbstractExecuteAction implements ActionValidator{
					-> public abstract class AbstractExecuteAction implements ExecuteAction {

				部分struts源码截取：【struts】
					multi-thread safe
					--------
						package com.opensymphony.xwork2;
						...
						public class ActionContext implements Serializable {
						    static ThreadLocal actionContext = new ThreadLocal();
						...
						    Map<String, Object> context;

						    public ActionContext(Map<String, Object> context) {
							this.context = context;
						    }
						...
						    public static void setContext(ActionContext context) {
							actionContext.set(context);
						    }
						    public static ActionContext getContext() {
							return (ActionContext) actionContext.get();
					--------
					
					--------
					...
					package com.opensymphony.xwork2;
					public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable {
					...
					    public Locale getLocale() {
						ActionContext ctx = ActionContext.getContext();
						if (ctx != null) {
						    return ctx.getLocale();
						} else {
						    LOG.debug("Action context not initialized");
						    return null;
						}
					    }
					...
					--------
					Interface :
						Action - All actions may implement this interface, which exposes the execute() method. 
						Validateable - Provides an interface in which a call for a validation check can be done.
						ValidationAware - ValidationAware classes can accept Action (class level) or field level error messages. Action level messages are kept in a Collection. 
									Field level error messages are kept in a Map from String field name to a List of field error msgs.
						TextProvider - Provides access to ResourceBundles and their underlying text messages.
						LocalProvider - Indicates that the implementing class can provide its own Locale. 
					
					ActionInvocation
							An ActionInvocation represents the execution state of an Action. It holds the Interceptors and the Action instance. By repeated re-entrant execution 
						of the invoke() method, initially by the ActionProxy, then by the Interceptors, the Interceptors are all executed, and then the Action and the Result.
						代理类，维护interceptors集合并依次序传递和执行ActionInvocation的实现类。？




			ibatis openAPI通过spring提供ibatis的template进行dao操作
				部分代码，spring集成ibatis部分
					--------
					package org.springframework.orm.ibatis;
					...
					public class SqlMapClientTemplate extends JdbcAccessor implements SqlMapClientOperations {
						public Object queryForObject(final String statementName, final Object parameterObject)
								throws DataAccessException {

							return execute(new SqlMapClientCallback() {
								public Object doInSqlMapClient(SqlMapExecutor executor) throws SQLException {
									return executor.queryForObject(statementName, parameterObject);
								}
							});
						...
						public Object execute(SqlMapClientCallback action) throws DataAccessException {
							Assert.notNull(action, "Callback object must not be null");
							Assert.notNull(this.sqlMapClient, "No SqlMapClient specified");

							// We always needs to use a SqlMapSession, as we need to pass a Spring-managed
							// Connection (potentially transactional) in. This shouldn't be necessary if
							// we run against a TransactionAwareDataSourceProxy underneath, but unfortunately
							// we still need it to make iBATIS batch execution work properly: If iBATIS
							// doesn't recognize an existing transaction, it automatically executes the
							// batch for every single statement...

							SqlMapSession session = this.sqlMapClient.openSession();
							if (logger.isDebugEnabled()) {
								logger.debug("Opened SqlMapSession [" + session + "] for iBATIS operation");
							}
							Connection ibatisCon = null;

							try {
								Connection springCon = null;
								DataSource dataSource = getDataSource();
								boolean transactionAware = (dataSource instanceof TransactionAwareDataSourceProxy);

								// Obtain JDBC Connection to operate on...
								try {
									ibatisCon = session.getCurrentConnection();
									if (ibatisCon == null) {
										springCon = (transactionAware ?
												dataSource.getConnection() : DataSourceUtils.doGetConnection(dataSource));
										session.setUserConnection(springCon);
										if (logger.isDebugEnabled()) {
											logger.debug("Obtained JDBC Connection [" + springCon + "] for iBATIS operation");
										}
									}
									else {
										if (logger.isDebugEnabled()) {
											logger.debug("Reusing JDBC Connection [" + ibatisCon + "] for iBATIS operation");
										}
									}
								}
								catch (SQLException ex) {
									throw new CannotGetJdbcConnectionException("Could not get JDBC Connection", ex);
								}

								// Execute given callback...
								try {
									return action.doInSqlMapClient(session);
								}
								catch (SQLException ex) {
									throw getExceptionTranslator().translate("SqlMapClient operation", null, ex);
								}
								finally {
									try {
										if (springCon != null) {
											if (transactionAware) {
												springCon.close();
											}
											else {
												DataSourceUtils.doReleaseConnection(springCon, dataSource);
											}
										}
									}
									catch (Throwable ex) {
										logger.debug("Could not close JDBC Connection", ex);
									}
								}

								// Processing finished - potentially session still to be closed.
							}
							finally {
								// Only close SqlMapSession if we know we've actually opened it
								// at the present level.
								if (ibatisCon == null) {
									session.close();
								}
							}
						}	}
					...
					--------
			dbcp - DB connection pool


		* 枚举 enum 
			定义常量(可扩展的)，优于普通常量定义
			 AgreementParameter
			 GlobalErrorMessage
			...
				eg:
				return CloudEngineEvent.NGINX.getEvent();

				public enum CloudEngineEvent {
					REGISTER(10001),
					NGINX(30001),
					FASTCGI(30002),
					SLB(30003),
					MEMCACHED(30004),
					RDS(30005),
					NODEJS(30006)
					;
					
					private CloudEngineEvent(Integer event) {
						this.event = event;
					}
					
					private Integer event;
					public Integer getEvent() {
						return event;
					}
				}

		* 

	openAPI mode 要引用到得其他各层分别在不同的model中: (openapi为houyi项目其中一个model)
		<modules>
		  <module>houyi.console.model</module> 域模型(历史原因有部分分散在其他model中)
		  <module>houyi.console.util</module> 工具
		  <module>houyi.console.acl</module> 访问控制
		  <module>houyi.console.dao</module> DAO
		  <module>houyi.console.clc</module> 对内master交互模块(操作vm等)
		  <module>houyi.console.service</module> 逻辑层
		  <module>houyi.console.message</module> 消息
		  <module>houyi.console.statistics</module>  
		  <module>houyi.console.web/houyi.console.web.support</module>  web这块原先以portal调
		  <module>houyi.console.web/houyi.console.web.staff</module>
		  <module>houyi.console.web/houyi.console.web.admin</module>
		  <module>houyi.console.web/houyi.console.web.isv</module>
		  <module>houyi.console.openapi</module> 对外openapi模块
		</modules>		
	
	openAPI 放开的请求action配置：- 统一出入口 ？
		<package name="instance" extends="houyi-open" namespace="/">
			<action name="services" class="openAPIProxyAction" method="proxy"><!-- action交给spring管理，此action为：open api 的访问代理 -->
			   <result type="userActionResult"></result> <!-- 自定义result -->
			</action>
		</package>
		代理action利用req请求消息，通过工厂方式(目标action都实现相同接口)调用对应的目标acton，目标action通过spring context获得：
			// Return the bean instances that match the given object type (including subclasses), judging from either bean definitions or the value of getObjectType in the case of FactoryBeans. 
			Map map = context.getBeansOfType(ExecuteAction.class);


3. xen 快照 了解  虚拟机快照 【快照】
	虚拟机快照是一个非常好的功能，它能保存当前虚拟机的状态。不幸的是开源Xen不提供对快照的支持，而Linux能支持。
由于开源Xen通常使用Linux作为它的特权域，所以你能使用Linux命令创建快照。
	chain 模式 比如 struts的intercepter ，插拔式
	
	http://server.it168.com/a2009/0723/611/000000611079.shtml
4. StringEscapeUtils 
	Escapes and unescapes Strings for Java, Java Script, HTML, XML, and SQL
	commons-lang包

5. 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day4 2012年3月19日

1. RESTful REST 请求

http://svn.alisoft-inc.com/repos/alisoft/houyi/cloudengine/branches/tgt_jce_20120507_v2/master/src/main/java/com/aliyun/cloudengine/
JCE的master以REST架构，处理openAPI(为get/post请求规范)请求需要提供一个适配层(将REST请求转换为http方式的get/post请求) ？ - Java Cloud Engine

jce的rest实现基于

rest http://www.ibm.com/developerworks/cn/java/j-lo-jaxrs/
	介绍jdk1.6提供的rest接口，master的rest基于jdk的rest接口 javax.ws.rs

基于 REST 的 Web 服务遵循一些基本的设计原则：
    系统中的每一个对象或是资源都可以通过一个唯一的 URI 来进行寻址，URI 的结构应该简单、可预测且易于理解，比如定义目录结构式的 URI。
    以遵循 RFC-2616 所定义的协议的方式显式地使用 HTTP 方法，建立创建、检索、更新和删除（CRUD：Create, Retrieve, Update and Delete）操作与 HTTP 方法之间的一对一映射：
        若要在服务器上创建资源，应该使用 POST 方法；
        若要检索某个资源，应该使用 GET 方法；
        若要更改资源状态或对其进行更新，应该使用 PUT 方法；
        若要删除某个资源，应该使用 DELETE 方法。
    URI 所访问的每个资源都可以使用不同的形式加以表示（比如 XML 或者 JSON），具体的表现形式取决于访问资源的客户端，客户端与服务提供者使用一种内容协商的机制（请求头与 MIME 类型）来选择合适的数据格式，最小化彼此之间的数据耦合。

【Task】
	以 /houyi-cloudengine-master/src/main/java/com/aliyun/cloudengine/RestAdminApplication.java 为例，熟悉rest方式，并分析rest方式与openapi标准的get/post方式如何转换 ？
	houyi-cloudengine-master 提供几个rest接口供外界调用。
	由于rest方式的请求url不同于普通http请求的url，需要提供一个模块处理标准http请求的处理(接受请求-调用接口-返回结果)
		rest方式URI: persion/123		http方式: persion?id=123
	
	cloudengine 运行是基于xuanyuan的一个组件，xuanyuan负责请求分配。
	
	参考实现的文档，搭建测试环境测试，判断是否支持预想的解决方案。 - tip -

2.  test 测试
JTester
	   http://java-tester.googlecode.com/svn/maven2/

	   http://www.blogjava.net/kiral/archive/2011/02/04/344072.html usage
	

3. 搭建 restful 环境，测试
	jersey + tomcat 的restful测试环境搭建：
		wiki https://wikis.oracle.com/display/Jersey/Main
		参考 http://www.ibm.com/developerworks/cn/web/wa-aj-tomcat/

	@POST 
	@Path("/test")
	@Produces(MediaType.APPLICATION_JSON)
	public String showTime(@FormParam("username") String userName,@Context HttpServletRequest httpRequest) {
	:
	:
	:
	}
	// jersey - 通过context注解获得httprequest对象
	
	对于openAPI调用(待测试)：
		可以给定URI请求，匹配到一个service上，然后取得request对象，做后续处理。
		(要做的步骤：
			配置一个service匹配opanapi的所有请求

		)

Using Entity Providers toMapHTTP Response and
Request Entity Bodies
Entity providers supply mapping services between representations and their associated Java
types. There are two types of entity providers: MessageBodyReader and MessageBodyWriter.
For HTTP requests, the MessageBodyReader is used to map an HTTP request entity body to
method parameters. On the response side, a return value is mapped to an HTTP response entity
body using a MessageBodyWriter. If the application needs to supply additional metadata, such
Responding to HTTP Resources
Chapter 3 • Creating a RESTful Resource Class 19
as HTTP headers or a different status code, a method can return a Response that wraps the
entity, and which can be built using Response.ResponseBuilder.

——jersey文档

4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day5 Tuesday, March 20, 2012

1. day4第3条 go on
	* 下载jersey包
	* 新建web项目，导入jersey必要包
	* 配置jersey的请求处理servlet，并正确配置package属性：com.sun.jersey.config.property.packages - 指向你的resource包
	* 部署到tomcat中
	* 测试

	部分代码：
	-----
		<servlet>
			<servlet-name>Jersey REST Service</servlet-name>
			<servlet-class>
			  com.sun.jersey.spi.container.servlet.ServletContainer
			</servlet-class>
			<init-param>
			  <param-name>com.sun.jersey.config.property.packages</param-name>
			  <param-value>test.jersey.service</param-value>
			</init-param>
			<load-on-startup>1</load-on-startup>
		</servlet>
		<servlet-mapping>
		  <servlet-name>Jersey REST Service</servlet-name>
		  <url-pattern>/rest/*</url-pattern>
		</servlet-mapping>

		package test.jersey.service;
		@Path("hello")
		public class HelloResponse {

			@GET
			@Produces(MediaType.TEXT_PLAIN)
			public String sayHello(){
				return "Hello jersey";
			}
	
		}
	------
	[ Test ]
		req: http://localhost:8080/jersey/rest/hello
		resp: Hello jersey

	[ Test ]
		@GET
		@Produces(MediaType.TEXT_PLAIN)
		public String sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
			return "id:"+id+" name:"+name;
		}	
		request: http://localhost:8080/jersey/rest/hello?id=1&name=jack   - 
		response: id:1 name:jack

	[ Test ]
		@Path("/hello")
		public class HelloResponse {

			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			public MyResponse sayHello(@DefaultValue("0") @QueryParam("id") String id,@DefaultValue("NaN")@QueryParam("name") String name){
		//		return "NORMAL id:"+id+" name:"+name+"\n";
				return new MyResponse(id,name);
			}
			
			@GET
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			@Path("/sayhello/{id}/{name}")
			public Object sayHelloRest(@DefaultValue("1") @PathParam("id") String id,@DefaultValue("1NaN") @PathParam("name") String name){
				return new MyResponse("1","jack");
			}
		}
		web.xml: 
			<servlet-mapping>
				  <servlet-name>Jersey REST Service</servlet-name>
				  <url-pattern>/open/*</url-pattern>
			</servlet-mapping>
		request: http://localhost:8080/jersey/open/hello/sayhello/1/1
		response: 
				<data>
					<id>1</id><
					name>jack</name>
				</data>

	要返回json或xml，需要将返回的对象配置上对象到xml的映射注解，比如利用jaxb等 ，需要提供一个对象到json或者xml的映射机制，如果直接返回
	jdk的list对象会报错，无法转换：
		A message body writer for Java class java.util.ArrayList, and Java type interface java.util.List, and MIME media type application/xml was not found
		eg:http://blog.coderunnr.com/2011/02/clienthandlerexception-a-message-body-writer-for-java-type-class-and-mime-media-type-applicationoctet-stream-was-not-found/
	将返回的pojo通过注解映射到xml即可：
		@XmlRootElement(name="data")
		public class MyResponse {
			
			private String id;
			
			private String name;
			
			public MyResponse(){}
			
			public MyResponse(String id,String name){
				this.id = id;
				this.name = name;
			}
			
			@XmlElement(name="id")
			public String getId() {
				return id;
			}
			public void setId(String id) {
				this.id = id;
			}
			
			@XmlElement(name="name")
			public String getName() {
				return name;
			}
			public void setName(String name) {
				this.name = name;
			}
		}
		

		问题：
			// 这个标签标示注解的方法支持下面定义的 2 种返回数据格式，具体确定？
			@Produces({MediaType.APPLICATION_XML,MediaType.APPLICATION_JSON})
			
			如上，可以返回多个MIME，如何选择，确定返回的类型？
				比如，需要返回xml，或者需要返回json 
				看openAPI是根据什么返回指定格式的数据的？
					openAPI通过请求参数 format 来判断client请求的数据格式，故这里需要用到 @queryparam 来取得 format ，从而返回对应的
				格式。
			jersey guide：
					If a resource class is capable of producing more that one MIME media type then the resource method chosen will correspond to the most acceptable media type 
				as declared by the client. More specifically the Accept header of the HTTP request declared what is most acceptable. For example if the Accept header is:
					Accept: text/plain
				then the doGetAsPlainText method will be invoked. Alternatively if the Accept header is:
					Accept: text/plain;q=0.9, text/html
				which declares that the client can accept media types of "text/plain" and "text/html" but prefers the latter, then the doGetAsHtml method will be invoked.
				More than one media type may be declared in the same @Produces declaration, for example:
			方案1：从jersey guide看，可以根据http请求头的 accept定义值返回相应格式。
				但openapi规范提供的是根据get方式的 format参数来确定返回格式的
			方案2:：根据 format 字段，找到rest框架提供的动态自定义返回格式的设置 ？ 在哪里设置？
				在response里设置header，rest框架根据header定义的格式渲染结果。
				通过response根据需要的返回状态(status)取得responsebuilder对象(处理返回内容)，取得请求参数，通过builder设置返回的Cotent-Type类型(MediaType定义的类型)
				builder的entry方法处理需要返回的对象，build()，返回即可。

			【tip】误区，试图设置request的accept值来影响response的返回数据格式，要返回什么样的数据及其格式都可以通过response来设置。
				拥有者或者自身或其相关工具一般会提供操作其自身的值的入口。

				

2. jax-rs 注解(from jax-rs api)
	Consumer - Defines the media types that the methods of a resource class or MessageBodyReader can accept 定义资源可以接受处理的请求类型
	Produces - Defines the media type(s) that the methods of a resource class or MessageBodyWriter can produce
	MediaType - An abstraction for a media type. Instances are immutable(不变的). 


3. 对于第1条的REST框架也支持非REST请求uri的转发，这其中，只是转发的作用，不带有业务逻辑，是否可以用nginx的rewrite来实现？
	后续SLB也需要对openapi提供处理层，其中含业务逻辑，选择REST方式。

4. nginx rewrite 重写
	目标：将openapi的标准请求重写为符合REST接口的rest请求。
	nginx的rewrite规则(rewrite模块)：
	http://xx.host/action?id=xx&name=xx rewrite为 http://xx.host/action/xx/xx

	
	URL rewriting is a key element to Search Engine Optimization (SEO). ——　摘自：Nginx HTTP Server p141

		参考 http://chenxiaoyu.org/2011/10/30/nginx-modules.html
	正则表达式 规则 regex
	regular expression(Perl Compatible Regular Expression (PCRE) library):
		Metacharacter
			Description
		^
		Beginning
			The entity after this character must be found at the beginning.
			Example pattern: ^h
			Matching strings: hello, h, hh
			Non-matching strings: character, ssh
		$
		End
			The entity before this character must be found at the end.
			Example pattern: e$
			Matching strings: sample, e, file
			Non-matching strings: extra, shell
		.
		Any
			Matches any character.
			Example pattern: hell.
			Matching strings: hello, hellx, hell5, hell!
			Non-matching strings: hell, helo
		[ ]
		Set
			Matches any character within the specified set.
			Syntax: [a-z] for a range, [abcd] for a set, and [a-z0-9] for
			two ranges
			Example pattern: hell[a-y123]
			Matching strings: hello, hell1, hell2, hell3
			Non-matching strings: hellz, hell4, heloo
		[^ ]
		Negate set
			Matches any character that is not within the specified set.
			Example pattern: hell[^a-np-z0-9]
			Matching strings: hello, hell;
			Non-matching strings: hella, hell5
		|
		Alternation
			Matches the entity placed either before or after the |.
			Example pattern: hello|welcome
			Matching strings: hello, welcome, helloes, awelcome
			Non-matching strings: hell, ellow, owelcom
		( )
		Grouping
			Groups a set of entities, often to be used in conjunction with |.
			Example pattern: ^(hello|hi) there$
			Matching strings: hello there, hi there.
			Non-matching strings: hey there, ahoy there
		\
		Escape
			Allows you to escape special characters.
			Example pattern: Hello\.
			Matching strings: Hello., Hello. How are you?, Hi! Hello...
			Non-matching strings: Hello, Hello, how are you?

		Quantifiers
		So far, you are able to express simple patterns with a limited number of characters. Quantifiers allow you to extend the amount of accepted entities:
		Quantifier
			Description
		*
		0 or more times
			The entity preceding * must be found 0 or more times.
			Example pattern: he*llo
			Matching strings: hllo, hello, heeeello
			Non-matching strings: hallo, ello
		+
		1 or more times
			The entity preceding + must be found 1 or more times.
			Example pattern: he+llo
			Matching strings: hello, heeeello
			Non-matching strings: hllo, helo
		?
		0 or 1 time
			The entity preceding ? must be found 0 or 1 time.
			Example pattern: he?llo
			Matching strings: hello, hllo
			Non-matching strings: heello, heeeello
		{x}
		x times
			The entity preceding {x} must be found x times.
			Example pattern: he{3}llo
			Matching strings: heeello, oh heeello there!
			Non-matching strings: hello, heello, heeeello
		{x,}
		At least x times
			The entity preceding {x,} must be found at least x times.
			Example pattern: he{3}llo
			Matching strings: heeello, heeeeeeello
			Non-matching strings: hllo, hello, heello
		{x,y}
		x to y times
			The entity preceding {x,y} must be found between x and y times.
			Example pattern: he{2,4}llo
			Matching strings: heello, heeello, heeeello
			Non-matching strings: hello, heeeeello
5. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day6 Wednesday, March 21, 2012

1. openapi 
	OpenAPI - 消息推送/订阅(Message push/subscrible)  -Master 
	
	根据登记在消息服务器上的订阅节点信息，进行push

2. python nodejs 
	python yaml模块 - YAML是一种直观的能够被电脑识别的的数据序列化格式，容易被人类阅读，并且容易和脚本语言交互。YAML类似于XML，但是语法比XML简单得多，对于转化成数组或可以hash的数据时是很简单有效的。

3.  wget 从vmware中的centso访问本机的rest服务
	取得返回内容，cat查看
	sshl连接到centos命令行操作。
	
	环境：
		apache ,
		tomcat,
		nginx,
		mysql,
		eclipse,
		python,(test)
		nodejs,(test)
		linux container(test)

4. CIDR Classless Inter-Domain Routing 了解
	无类别域间路由选择
	ref:
		CIDR（无类型域间选路，Classless Inter-Domain Routing）是一个在Internet上创建附加地址的方法，这些地址提供给
	服务提供商（ISP），	再由ISP分配给客户。CIDR将路由集中起来，使一个IP地址代表主要骨干提供商服务的几千个IP地址，
	从而减轻Internet路由器的负担。		

5. ce里shell脚本熟悉
	"#!/bin/sh" - 对shell的声明，说明你所用的是那种类型的shell及其路径所在。
	自定义shell function封装常用功能，提高shell编写效率。
		eg: 


6. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day7 Thursday, March 22, 2012

1. ace mast agent(python shell) 
	master 职责


2.  ace 计量单位讨论会议，
	字段需要取出推送到消息系统，供后续计量，计费
	主要关于 计量字段需求，及可行性确认
	详见记录
	tip: 由于涉及多个系统的交互，如何处理规则，处理变化的问题，如果适应变化减少依赖耦合。

3. cloudengine 熟悉
	master ,agent 部分
	master调用agent
	agent根据不同的应用类型(目前:php，nodejs，jsp)调用相应的build脚本(配置环境运行环境，部署应用，启动应用，启动agent)

	nodejs http://nodejs.org/
4. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day8 Friday, March 23, 2012

1. cloudengine 
	trunk
		agent - agent模块(python)
			fastcgi
			memcached
			monitor
			nginx
			nodejs
			test
			yaml
		carrier - Erlang (rebar ...)
		ftpserver - ftp服务(java)
		master - master(java)
		memcahched_pach - memchche部署
		nginx_pach - nginx部署
		nodejs -  nodejs部署(build_agent -> install_agent -> install_nodejs -> upgrade_nodejs)
		php - php部署

2. ACE计量 
	计量单位，字段说明
	oss接口
	ms接口

	目标：将ACE各计量单位取到并以ms要求的格式推送给ms(Metering Service)计量系统系统 ，有一个python的
	的实现可以参考:
		python 
			程序基本结构
			变量，运算 etc
			模块
				MySQLdb
					eg 通过此模块与mysql数据库交互：(下载这个库有linux和win版本)
						conn=MySQLdb.connect(host="localhost",user="root",passwd="sa",db="mytable")
	
			执行
			应用
	* 

	参考 houyi-console/static (java)实现，上述任务 【Task】
	= = URL请求的要求(格式，构造)等可以参考这个实现 = =
		定义数据格式
		定义任务
		spring配置调用执行

		步骤：(公用动作比如推送等已有实现，调用其逻辑处理即可) 细化
			>> 取
				* MS取SLB流量(appid对应的流量，appid指每个具体的应用)	单位 byte
					- 从ACE DB中取得appid对应的slb_id，及应用的id与SLB的id对应关系 1对1
						- 从DB得到app_id对应的slb_id(cloudengine库)

							-- 从DB得到app_id对应的slb_id
							select 
								app.id app_id,
								slb.id slb_id
							from app app,slb_alloc_record slb
							where app.id = slb.id
							
					- 请求Meteriing Service，根据slb_id取数据
						MS接口文档(比如如何查询SLB数据？)
						

					-  MS返回vip对应的流量数据的数据格式
						Flow_detail的格式如下：
						[tcp(VIP:80|2|3|)(VIP:8080|2|3|)][http(www.a.com:80|2|3|)(www.b.com:90|2|3|)]
					
					- 

				* MS取OSS
					- 从app表(cloudengine)取得kv_bucket
						select 
							id app_id,
							kv_bucket
						from app
					- URL格式
						columns: storage;
						where: openid=ace;pid=oss;bid=26842;inst_id=$bucketname;begin_time=13123121400;end_time =132123241500;inst_id,migrate-win2003-vifs
						http://10.1.157.163:8080/aliyun/QS/OSS/RAW
						bid - 用户ID，app所属的用户
						$bucketname对应kv_bucket
					- 
						
				* DB取cpu时间等
					‘cloudengine`.`fastcgi_app_running_info` cpu_acc_usage App的cpu持续使用时间，单位：秒

			>> 处理

			>> 推送 写往MS
				推送数据格式
					* 在 DataFormat里定义枚举 
					*  pojo (实现接口)
					* 请求
						http request header:
						PUT /aliyun.com/QS/SLB/RAW HTTP/1.1（待定，需姜一提供）
						HOST: ms.aliyun.com
						CONTENT‐LENGTH: 12345
						META: uid,string;inst_id,string; time, integer; usetime,integer; total_in,integer;total_out,integer;tcp_flow_in,integer;tcp_flow_out,integer;http_flow_in,integer;http_flow_out,integer;vip_type,string;rs,integer;flow_detail,string;region_id,string;end_time,integer;
						“META为用户发送的数据的格式信息，这部分必须添加在http的header部分，为计量服务(MS)特有字段”
						http://metering.aliyun-inc.com:8080/aliyun/QS/OSS/RAW  —— 线上系统的地址
						http://10.1.157.163:8080/aliyun/QS/SLB/RAW —— 测试时用测试系统地址
					* 整理推送的字段对照 doc ？
						Cpu(ms)、流量(byte)、存储空间(byte)、请求次数、memory-cache(byte)

						属性名			类型			单位			描述
						uid				string							包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务
						time				integer							开始时间(记录当前记录的时刻，为一点态时间，如果用户的计量数据采集并非实时，则time表示抽样开始时间即begin_time，采用可显示的unix时间表示法)
						end_time			integer							结束时间(表示抽样结束时间，同样采用可显示的unix时间表示法)
						inst_id			string							应用id即appid
						cpu				integer			ms				cpu使用时间
						flow				integer			byte				总流量(http流量)
						flow_in			integer			byte				流入流量
						flow_out			integer			byte				流出流量
						app_size			integer			byte				存储空间(oss)
						req_count			integer			个				请求次数(包括pv内的多个异步请求)
						version			integer							版本号，目前为1



						






		uid：包含用户在aliyun.com注册的用户名(openid),  用户购买产品类型(pid)和用户渠道商标识(bid), 格式为openid#pid#bid方式，彼此用sharp(#)分隔，由aliyun.com提供给各个产品服务。
3. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day9 Monday, March 26, 2012

1. 计量的接口说明 最新的 ？
	

2. 把ace计量初步需求写入文档，
	类似于slb接口文档等
	
	目的：设计ace计量项，并取到后处理然后提交到ms系统
	计量项列表：
	实现：
		计量项获取：
		处理
		推送
	xuanyuan cloudengine数据库表间关系由程序控制，注释说明关系。

3. job的具体实现，失败补偿逻辑，参看console中的static模块
	？


4. 通过powerdesigner的reverse engine ，从database的sql文件将ddl转换为er图，了解db表关系

5. velocity 方便对象格式化到文件
	...
	velocityEngine.init();//spring配置好resourceLoaderPath
	template = velocityEngine.getTemplate(templateFile);
	VelocityContext context = new VelocityContext();
	context.put("datasMap", map);
	writer = new FileWriter(outfile);
	template.merge(context, writer);
	...
6. spring + quartz 执行定时任务
	<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
		<property name="targetObject" ref="task" />
		<property name="targetMethod" value="execute" />
		<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
	</bean>	
	<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
		<property name="jobDetail" ref="collectDataDetail" />
		<property name="cronExpression" value="0 0 */1 * * ?" />
	</bean>  
	<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="triggers">
			<list>
				<ref bean="collectDataTrigger" />
			</list>
		</property>
	</bean>
7. 操作记录及时保存为数据库的日志，后续补偿机制根据数据库补偿并更新 ？
	细节

8. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day10 Tuesday, March 27, 2012

1. 根据上面ace计量文档，编码
	对于时间如何处理，补偿机制

2. ACE计量先不提供需要访问MS的SLB和OSS数据，暂先考虑DB数据 【task】
	先实现ace监控数据的抽取推送。
		一些dao需要自己定义以取监控数据
		时间校准，以抽取逻辑定义的时间为准，根据定义的时间去取监控数据并汇总，处理，推送
	处理的整体流程：
		关键是发生错误的补偿处理逻辑：
		tasklog表记录task日志。		

3. 表说明
	region - 代表一个集群
测试环境 mysql
mysql -h10.249.153.1 -ucloudengine -pcloudengine2011 -Dcloudengine



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day11 Wednesday, March 28, 2012

1. 设计好补偿处理逻辑
	结合day10第二条的表记录job及其result实现补偿处理。

2. 任务处理已有设计，在已有的任务设计下实现功能
	* job代表每一次执行的任务
		job推送前都记录到数据库，job下的内容保存为临时文件。
	* spring+squza定时任务
	* 日期处理
		DateUtils.java —— 将date日期格式化为需要的格式；date到秒；string+patten到date  (SimpleDateFormat实现)
	* pojo
		TaskLog 任务日志pojo
			private Long id;
			private int status; // 1:success,0:failed
			private String filename;
			private Long taskTime;
			private int jobType; //[0:vm job,1:device job; default 0]
			private Date beginTime;
			private Date endTime;
			OR文件：/houyi-console-dao/src/main/resources/ibatis/TaskLog.xm
				houyi库 statistics_log
	* service
		JobService ：job相关操作
			public boolean addOrModify(TaskLog job);
			public boolean checkStatus(TaskLog job);
			public List<TaskLog> listFailedJobs(long startTime);
			public List<TaskLog> listJobs(long startTime,long endTime);
			public TaskLog getLastJob();
	* dao
		TaskLogDao ：任务日志DAO操作
			void insertTaskLog(TaskLog log) ;
			void updateTaskLog(TaskLog log) ;
			TaskLog getTaskLog(TaskLog log) ;
			TaskLog getLastTaskLog();
			List<TaskLog> getFailedTaskLogs(Long bTime);
			List<TaskLog> getTaskLogs(Long bTaskTime,Long eTaskTime);

	* task 由于时间等内容不好共用，可再设计一个task，并通过spring配置执行。
		或对task进行业务无关的再抽象，只留下共用的逻辑，其他都内聚到job自身中。-tip-

	处理流程：(包括 Task ，JobProducer，需要的service,dao,pojo) - 由程序入口分析
		--> task - execute()定时执行这个方法 - 调用dojob()  —— dojob是单线程的，如果job多或者某个前面的job占用时间长会影响后面的job的执行开始时间 ？ tip 如果是独立的task则不用考虑影响问题
			遍历执行注入的jobproducer实现 (获取方式：beans = (Map<String, JobProducer>) applicationContext.getBeansOfType(JobProducer.class))
		--> jobproducer(具体job逻辑在jobproducer的实现类里编写)\
		--> service
		--> dao
		逻辑就在task，jobproducer,abstract jobproducer中，定义自己的逻辑即可。
			原有任务以task作为主流程控制，jobproducer抽象类及其实现定义了所有逻辑。抽象类提供公用逻辑或抽象方法统一逻辑。-tip-
				取数据 - 存入数据库/文件(通过velocity映射对象集合(以appid为标识)存为文本) - push - 更新状态
3. 模拟实现
	根据原有static模块任务设计
		* 定义数据结构 pojo ,velocity模板(用于对象格式化持久化)
			是否需要将此pojo作为对象查询？即某个查询直接返回此pojo，需要ibatis映射配置，这样只要查询一次关联几张表得到数据；或者分别查询在程序中处理。
			暂定位分别查询。分别查询，减少关联
		* 实现一个job producer
		* 定时task类，可能需要再实现一个并在spring里配置(原task再抽象以下，可配置)，
		参考配置：
			<bean id="collectDataDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">
				<property name="targetObject" ref="task" />
				<property name="targetMethod" value="execute" />
				<property name="concurrent" value="false" /> <!-- 设置是否并发执行，如果为true，则targetObject执行的逻辑需要注意线程并发控制 -->
			</bean>	
			<bean id="collectDataTrigger" class="org.springframework.scheduling.quartz.CronTriggerBean">
				<property name="jobDetail" ref="collectDataDetail" />
				<property name="cronExpression" value="0 0 */1 * * ?" />
			</bean>  
			<bean id="collectDataScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
				<property name="triggers">
					<list> <!-- 此处配置定时要执行的task列表 -->
						<ref bean="collectDataTrigger" /> 
					</list>
				</property>
			</bean>
		* 判断tasklog是否已执行过，通过jobtype类型和jobtime-job开始时间，如果是依据查询的最新执行时间作为job开始时间
			if (jobService.checkStatus(job))
			{
				logger.info("exist job:" + jobTime);
				return true;
			}
		* abstract producer的一些公用成员变量是否可以提供get方法供子类调用，子类不用重复定义 ？
		* task的recoverJob逻辑处理丢失的任务（比如关机等造成的任务丢失），目前任务是能处理丢失10次的任务，是否可以根据做新一次的任务的开始时间
		结合当前时间计算共丢失多少次任务，然后执行所有丢失的任务？
			Task
			------
			...
				/** Get the last record of success in the log table **/
				TaskLog log = jobService.getLastJob();

				/** compensate for missing the task **/
				if (log != null)
				{
					int i = 1;
					while (log.getTaskTime() + i * HOUR_SEC < jobTime)
					{
						/** Compensate for 10 times **/
						if (i == 10)
						{
							break;
						}

						TaskLog job = new TaskLog();
						job.setBeginTime(new Date());
						job.setTaskTime(log.getTaskTime() + i * HOUR_SEC);
						job.setStatus(0);
						jobService.addOrModify(job);
						i++;
					}
				}
			...
			------
		* 一些任务参数是否可以配置到配置文件中，类似abstract job producer的parentpath路径配置 比如：采集间隔，一些补偿机制参数 ？
		* statistics_log表？
		* app的类别区分是哪个字段(php,nodejs,jsp) ?
			templetid?
		* 用到的一些接口需要修改 ，通过的方式过少，是否可修改，其他地方是否有调用？
			比如提供id数组查询。
		* 应用运行时状态表
			fastcgi_app_running_info
			nginx_app_running_info
			memcache_app_running_info
			nodejs_app_running_info
		* console与cloudengine不是同一项目，maven管理依赖，引入cloudengine的包？
			自己重新写maping文件pojo及dao接口和实现。不依赖不相关系统。
			在dao，model等模块加入对应代码。
		* ibatis查询，可以根据外键设置关联查询，减少查询次数
		* 由于是另外一个数据库，需要再配置数据源
		* 在houyi-console-dao里写dao层用到pojo是static中的，是否把pojo，dao，service都按照模块放置，负责dao就要依赖到static中的pojo ？
			static的model不直接提供dao，而是从其他数据组合而成。比如从appdao的查询记录里组合而成。
		* 统计一个时间段的缓存使用量，如何取？暂定为求和
		* 参考master的constant 包定义的常量，帮助了解一些业务知识
			AppType 定义了应用的类型。php.nodejs...
			app 的 language 属性定义apptype类型。
		* 



+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day12 Thursday, March 29, 2012

1. go on 
	新建maven project开发，独立功能
	参考console的static模块，做成一个任务模块(业务，逻辑分离，易配置)
	wiki地址：http://wiki.houyi.alibaba-inc.com/pages/viewpage.action?pageId=8259199
	svn ：http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk
	web项目 or java进程(jar包main函数启动) or 作为一个组件部署（作为组件部署，有哪些要求，比如 cloudengine 在 xuanyuan 上运行）？
	
	* 导入需要的包
	* 拷贝公用代码 工具类 等
	* dao设计依据master，提供抽象dao实现namespace的spring配置
	* 参考master用jtester测试
		加入jtester依赖包 地址http://java-tester.googlecode.com
		jtester 配置文件中 unitils.modules=database,dbunit,dbfit,inject,spring,tracer ，这里列出了需要的模块
		编译测试，提示编译版本问题时，可以切换下jdk版本，并clean下project。
		测试用例数据，参考master的：eg
			@DbFit(when = {"AgentCheckResultDaoTest.testReadByAgentId.when.wiki"})
		集成spring测试时，可能由于spring配置等问题导致maven test失败；可通过基本的main函数先保证spring的注入式正确的 -tip-
		maven test + main method test
		maven clean + eclipse project clean solve cmplile problems 
	
		如何自动生成测试用例 ？ ，对每个方法都手工去编写基础测试代码过于繁琐

	*  wiki project描述

2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day13 Friday, March 30, 2012

1. ameasure-data project
	job基础代码与业务代码分离，实现可配置。
	* 配置maven插件,jar (以及插件的参数配置，jar执行main函数配置 etc - 参考maven jar插件说明：http://maven.apache.org/shared/maven-archiver/index.html)
	* 测试报 Could not find Velocity resource: class path resource [VM_global_library.vm
	* 配置maven插件 maven-assembly-plugin ,packaged with-dependencies 打包并加上依赖 ,配置assembly参数，比如jar分别打包，
		打包时可能jar包文件重复，test目录下的测试文件也打包进来，配置一些参数即可，例如：
			-----
			...
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.Test</mainClass>
							</manifest>
						</archive>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				(2)
				<plugin>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.2-beta-5</version>
					<configuration>
						<descriptors>
							<descriptor>src/main/assembly/src.xml</descriptor>
						</descriptors>
						<archive>
							<manifest>
								<mainClass>com.aliyun.houyi.acecalc.StartTask</mainClass>
							</manifest>
						</archive>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0" 
				  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				  xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.0 http://maven.apache.org/xsd/assembly-1.1.0.xsd">
				  <!-- TODO: a jarjar format would be better -->
				  <id>with-dependencies</id>
				  <formats>
				    <format>zip</format>
				  </formats>
				  <includeBaseDirectory>false</includeBaseDirectory>
				  
				  <dependencySets>
				    <dependencySet>
				      <outputDirectory>/</outputDirectory>
				      <useProjectArtifact>true</useProjectArtifact>
				      <unpack>false</unpack>
				      <scope>runtime</scope>
				    </dependencySet>
				  </dependencySets>
				</assembly>
			...
			-----
			打成上面这种jar包集合方式，在同一文件夹下运行即可，省去classpath配置的麻烦。

		maven clean after close resource opened -tip-
	* 加上shell执行脚本，调用此jar并执行
	* 原有推送逻辑，一次job比如推50条，一条失败就退出，暂处理为本次任务再尝试推送(设定尝试次数)
	*  ibatis 在命令行下运行找不到mapping文件，在eclipse下测试ok 原因？ 待  —— ibatis没问题，spring也ok，字体用的不好(大小写居然相似，
		最后还是仔细看了错误输出，错误点才发现大小写)大小写错误，配置文件配置和实际文件大小写不一致！！！-tip-
		如何避免：提示文件找不到，名称不匹配等等，首要看是否书写错误，能拷贝一定拷贝，不要手工输入，特变是在配置文件场合。 -tip-




2. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day14 Saturday, March 31, 2012

1. measure-data
	* 逻辑细化 command
	* quartz ? cluster
		利用quartz实现调度执行，将操作记入日志，失败处理另外实现并
	* 任务测试
		测试表 tasklog `statistics_log`
			CREATE TABLE  `cloudengine`.`statistics_log` (
			  `id` int unsigned NOT NULL AUTO_INCREMENT  COMMENT '@desc 主键ID' ,
			  `status` tinyint NOT NULL COMMENT '@desc 1', 
			  `filename` varchar(128)  COMMENT '@desc filename',
			  `task_time` datetime NOT NULL  COMMENT '@desc tasktime',
			  `begin_time` datetime NOT NULL  COMMENT '@desc begin_time',
			  `end_time` datetime NOT NULL  COMMENT '@desc end_time',
			  `job_type` tinyint NOT NULL COMMENT '@desc 1', 
			  PRIMARY KEY (`id`)
			) ENGINE=InnoDB DEFAULT CHARSET=utf8;
			ALTER TABLE `statistics_log` MODIFY COLUMN `task_time` bigint(20) NOT NULL GO
			测试数据：
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(1,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',3);
			 insert into statistics_log (status,filename,task_time,begin_time,end_time,job_type) values(2,'testname','1333168395627','2012-02-02 00:10:00','2012-02-02 00:1:00',1);
	* 提供开启程序，退出程序脚本 ，通过命令操作即可 。可参考tomcatd的脚本
		手工停止任务执行。（或强制停止并处理强制停止任务的恢复逻辑），假如某次job有200条记录在推送了150条时，程序关闭了
2. 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day15 Thursday, April 05, 2012

1. 逻辑实现
计量会议
linux环境：
	10.250.8.214 chengs 123456
shell 下java程序控制：
	  -----
	  ...
		#! /bin/sh

		#启动方法
		start(){

			java -Xms128m -Xmx2048m -jar test1.jar 5 > log.log &
			java -Xms128m -Xmx2048m -jar test2.jar 5 > log.log &
			tail -f result.log
		}
		#停止方法
		stop(){
			ps -ef|grep test|awk '{print $2}'|while read pid
			do
			   kill -9 $pid
			done
		}

		case "$1" in
		start)
		  start
		  ;;
		stop)
		  stop
		  ;;
		restart)
		  stop
		  start
		  ;;
		*)
		  printf 'Usage: %s {start|stop|restart}\n' "$prog"
		  exit 1
		  ;;
		esac

		...
		CLASS_PATH=dayemail.jar
		CLASS_PATH=$CLASS_PATH:lib/activation.jar
		CLASS_PATH=$CLASS_PATH:lib/classes12.jar
		CLASS_PATH=$CLASS_PATH:lib/c3p0-0.9.1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/commons-email-1.2.jar
		CLASS_PATH=$CLASS_PATH:lib/dom4j-1.6.jar
		CLASS_PATH=$CLASS_PATH:lib/jaxen-1.1.1.jar
		CLASS_PATH=$CLASS_PATH:lib/jxl.jar
		CLASS_PATH=$CLASS_PATH:lib/log4j-1.2.16.jar
		CLASS_PATH=$CLASS_PATH:lib/mail.jar

		SERVER=/qzpt/mydayemail
		cd $SERVER   
		  
		case "$1" in   
		  
		  start)   
		    nohup java -Dfile.encoding=UTF8 -Xms64M -Xmx256M -cp $CLASS_PATH com.trendsnet.myemail.EmailShell > $SERVER/server.log 2>&1 &   
		    echo $! > $SERVER/server.pid   
		    ;;   
		  
		  stop)   
		    kill `cat $SERVER/server.pid`   
		    rm -rf $SERVER/server.pid   
		    ;;   
		  
		  restart)   
		    $0 stop   
		    sleep 1   
		    $0 start   
		    ;;   
		  
		  *)   
		    echo "Usage: myshell.sh {start|stop|restart}"  
		    ;;   
		  
		esac   
		  
		exit 0  
	...
	-----
	来自：http://www.iteye.com/topic/1122093
	* 在程序中中增加一个hook,jvm退出时会执行hook中的代码 
	Runtime.getRuntime().addShutdownHook(Thread); 
	kill -15 （SIGTERM）能够执行hook中代码 
	kill -9   (SIGKILL) 不能够执行hook中代码 
	在程序关闭前做处理工作，然后关闭。
	* 启动的时候将shell脚本的PID记录到文件里面，然后关闭的时候就可以直接读文件获取PID，避免用ps查询了，有可能不准确的 
	echo $! > $SERVER/server.pid

2. mvn test package etc 配置好资源文件 如 -tip-
	<resource>
	<directory>src/main/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>

	<resource>
	<directory>src/test/resource</directory>
	<filtering>true</filtering>
	<includes>
		<include>**/*.wiki</include>
		<include>**/*.xml</include>
		<include>*.properties</include>
	</includes>
	</resource>
	上面，加载包括main和test下的所有配置文件(部分子目录下的文件)。
mvn test生成的报告会说明失败原因，依据错误解决问题。
maven test failure —— 错误报告会告知哪里导致错误，一步步检查 cause 即可。另，test等都是依据pom的配置执行的，pom的配置要细心。
3. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day16 Friday, April 06, 2012

1. test 抽象类(实现方法，测视类中静态内部类继承) ，私有方法（反射）

2. Cron expressions  ,quartz
	

3. acecalc
	* 任务第一次执行时，采集时间点的确定，根据app的创建日期为起点开始采集？
		自动查询数据库得出 or 配置文件配置初始抽取时间点 or 两者都支持
	* 

4. MS 改为 OMS 参看其文档
	开放计量服务(OMS)的数据模型包括以下几个概念:
		 Object
		 Domain
		 Accessid
		 Accesskey
	上面观念划分，体现了OMS的REST服务方式。
	
	推送数据格式：
		* Date 目前Date只支持GMT格式，具体的GMT格式可参考如下示例:
			Wed, 30 Aug 1991 09:13:05 GMT
			更多关于GMT时间格式的信息，请参考RFC|1123
		* 
		
5. 
cpu

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day17 Monday, April 09, 2012

1. 新OMS提交修改

2. 访问次数 pv 所在表
	nginx_app_abstract_running_info 
	nginx_app_running_info
3. 推送测试环境 ？ OMS测试环境提供推送测试
	测试推送逻辑
demo http://svn.simba.taobao.com/svn/Apsara/openapi/trunk/java/src/com/aliyun/openservices/oms/

	uri：http://10.230.201.85:8080/ACE_RAW
	accessid: rot1d0cc9bxp97vpcwjyo98o
	accesskey: 0GC/ahEtRiNReKA1NhuNimJ2b3A

	* 推送格式改为xml
	* 请求头变化
	
	加好各种header后，进行签名，带上content 发送请求。

	
	临时文件名，取名时需要考虑2个或2个以上操作发生在同一秒内的情况。

	403 签名错误 ，
	400 非法参数 InvalidParameterValue <Message>unsuported content-type</Message>
	* put内容的字段变化了 原来的uid，改为3个分开：
		eg:
			#foreach ($data.value in $datasMap.entrySet())
			   <Object><uid>default</uid><pid>ace</pid><bid>aliyun</bid><inst_id>$data.value.appId</inst_id><time>$data.value.startTime</time><cpu_acc_usage>$data.value.cpuAccUsage</cpu_acc_usage><memcache_size>$data.value.memcacheSize</memcache_size><req_count>$data.value.reqCount</req_count><lb_id>$!data.value.lbId</lb_id><version>$data.value.version</version><end_time>$data.value.endTime</end_time></Object>
			#end
	 * OMS client的get方法，查询测试用。
		查询OMS
	main test 输出：
		{response=<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authenticate user</Message>
		<RequestID>41e3d2b9-31d0-2c4f-493b-e4635bff819b</RequestID>
		</Error>
		, status=403}

4. mem_size 暂取为某个计量时间段内的平均值 


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day18 Tuesday, April 10, 2012

1. 
	* oms get测试 - pass
	* 一次put多个object测试
	* 启动，关闭脚本修改 
	* 计量值多数据测试，统计的sql是否存在问题，大数据计算精度问题
	* 某些job中app并没有产生任何数据是否应该抛弃，不推送到OMS上，导致的问题是，在某个时间点或者区间查询时导致没有数据。？
	* quartz 挂起api ，正常停止任务，不建议job执行时强制关闭进程（程序逻辑需要处理这种例外）
	* 运行jar的配置文件独立到jar外面便于配置 
		通过spring配置加载外部配置文件。
			spring配置文件也配置在外部(不在classpath上)，spring提供了org.springframework.context.support.ClassPathXmlApplicationContext 以加载classpath之外的配置文件。外部配置文件 -tip-
		log4j提供的配置文件设置类 org.apache.log4j.xml.DOMConfigurator ，可以设置定时检查配置文件修改并重新加载配置。在main函数里初始化如下：
			String log4jfile = System.getProperty("user.dir") +File.separator +"config"+ File.separator +"log4j.xml";
			DOMConfigurator.configure(log4jfile);
		配置文件改为：
			spring和properties文件都移到jar外面，ibatis配置文件还是在jar包中。
			问题是，maven如何打包时，把config文件夹拷贝一份和包在同目录下？ assembly ？
			改为：
				配置文件只把关键的 log4j,job,jdbc 等放在jar外面加载，其他进jar包。
			shell 脚本需要在bin目录下运行，否则有配置文件找不到等错误 -tip- ，如何优化shell脚本
	* 拿到真实环境的相关数据库表机构，是否与本机一致？比如statistics_log表
	

2.  oms get测试

	已push成功的待查询测试数据：
		<?xml version="1.0" encoding="UTF-8"?>
		<Objects>   
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id></lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>
	get查询请求参数：
		"GET /ACE_RAW HTTP/1.1[\r][\n]"
		"Authorization: OMS rot1d0cc9bxp97vpcwjyo98o:yqb7kFIP3prg8z0x4gw5T4lnXEw=[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:30 GMT[\r][\n]"
		"x-oms-filter: time=1334019600[\r][\n]"
		"x-oms-select: uid;pid;bid;inst_id;time;cpu_acc_usage;memcache_size;req_count;lb_id;version;end_time[\r][\n]"
		"User-Agent: Jakarta Commons-HttpClient/3.1[\r][\n]"
		"Host: 10.230.201.85:8080[\r][\n]"
		"[\r][\n]"

	返回成功信息：
		"HTTP/1.1 200 OK[\r][\n]"
		"Date: Tue, 10 Apr 2012 02:15:31 GMT[\r][\n]"
		"Server: Apache/2.2.17 (Unix)[\r][\n]"
		"Content-Length: 322[\r][\n]"
		"Content-Type: text/xml;charset=UTF-8[\r][\n]"
		"[\r][\n]"
		"<?xml version="1.0" encoding="UTF-8" ?>
		<Objects>
			<Object>
				<uid>default</uid>
				<pid>ace</pid>
				<bid>aliyun</bid>
				<inst_id>1</inst_id>
				<time>1334019600</time>
				<cpu_acc_usage>0</cpu_acc_usage>
				<memcache_size>0</memcache_size>
				<req_count>0</req_count>
				<lb_id>0</lb_id>
				<version>1</version>
				<end_time>1334023200</end_time>
			</Object>
		</Objects>"

	注：上面put的数据与get返回的数据 lb_id由空变为了0，这是OMS对某些字段如果空会置默认值的逻辑。

	uid+time
	uid+pid+bid+inst_id+time
	目前就这两个你有权限查
	
	domain没有操作权限：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>AuthFailure</Code>
		<Message>cannot authorize user</Message>
		<RequestID>7a44a74b-211a-fda1-68b6-7f5907108b41</RequestID>
		</Error>	
	查询条件错误：
		<?xml version="1.0" encoding="UTF-8"?>
		<Error>
		<Code>InvalidQueryExpressison</Code>
		<Message>query condition not match any dimension</Message>
		<RequestID>66a00276-6ad9-d94f-1bf7-db7f0c4830ba</RequestID>
		</Error>	
3. 部署  程序运行目录定义说明（配置简单操作为好）
		bin - 放运行脚本
		build - 放编译脚本(svn下载，maven构建，部署到设定的目录(到bin,lib,config))
		config - 存放配置文件(log4j,job等的配置文件)
		lib - jar文件
		logs - 日志

		操作从调用build下的脚本开始执行。
		build下放置build好的文件，如何deploy脚本将build好的文件分别部署到相应的目录中去。
		bin下的启动脚本需要在bin当前目录下运行，否则报配置文件找不到？

4. sh -x xx.sh 查看
	脚本可能因为隐藏字符导致错误，执行时 -x 查看即可。
5. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
day19 Wednesday, April 11, 2012

1. 
	执行过程中断处理
	那些数据时不用推送的，比如某个时间段都没有产生数据（这压缩数据交给oms？）


2. shell 执行路径问题  shell 必须在当前路径执行，否则路径错误 ，解决？【 spring加载资源文件路径 ，类路径，外部路径 配置路径 路径设置 改变工作目录 当前路径】
	关键：cd 命令，设置当前路径 
	#!/root/bash
	echo `pwd`
	current_dir=$(cd "$(dirname "${0}")";pwd)
	echo $current_dir
	
	pwd会因为执行路径不同而变化，current_dir可以取到shell所在路径。 

	但对于没有动态调用 user.dir 找到classpath之外资源路径的情况，可以在非shell所在目录执行时，在shell里cd到所在base目录，这样
	后续java加载取值时，取得就是cd后的路径。-tip-

	shell执行时，指定java系统参数 user.dir 即可 ，即指定java执行时用户当前目录为程序所在主目录（base目录，其子目录有lib，bin等等）。-tip-
	通过java命令的 -D 参数指定 user.dir ,结合程序逻辑，指定资源文件等的路径path。
		String log4jFile = System.getProperty("user.dir") + File.separator + "config"+ File.separator +"log4j.xml";
		-----
		...
			#!/bin/bash
			BIN_DIR=$(cd "$(dirname "${0}")";pwd)
			BASE_DIR=`dirname $BIN_DIR`
			LIB_DIR=$BASE_DIR/lib
			LOG_DIR=$BASE_DIR/logs
			#set for java to load resource
			USER_DIR=$BASE_DIR
			JAR_NAME=houyi-measuredata-all-0.0.1.jar
			if [ ! -n "$1" ]
			then
			    echo  "usage: $0 [insert|remove]";
			    exit 1
			fi
			ACTION="$1"
			case $ACTION in
			    start)
				cd $BASE_DIR # 转到程序需要的工作路径，比如需要此路径来加载资源文件，spring里从外部文件加载的资源文件相对此$BASE_DIR取路径即可。
				java -Xms64M -Xmx256M -Duser.dir=$USER_DIR -jar $LIB_DIR/$JAR_NAME > $BIN_DIR/server.log 2>&1 &
				echo $! > $BIN_DIR/server.pid
				;;
			    stop)
				kill `cat $BIN_DIR/server.pid`
				rm -rf $BIN_DIR/server.pid
				;;
			    *)
				echo  "invalid option ,usage: $0 [insert|remove]";
				;;
			esac

			exit 0
		...
		-----
		通过 -Duser.dir=xxx 设置user.dir参数好

		执行路径，相对路径 ，程序默认读当前路径，执行路径时，在shell可以 cd 到所需要的当前路径(工作路径)，再执行即可。
		
3. svn 提交 eclipse ，还是用svn客户端 
	eg: TortoiseSVN   
		check for modification - revert  
	可以用客户端管理版本，eclipse只负责项目开发。 不同svn客户端交叉用可能出错误。
	svn co http://svn.alisoft-inc.com/repos/alisoft/houyi/api/measure-data/trunk 
	username
	password
4. 从svn下载到maven编译到部署运行 ，整个的脚本
	svn取到项目源码
	mvn 构建
		不同机子上构建时依赖可能出现的问题：
			Error transferring file: Connection refused
			Specified destination directory cannot be created: /usr/ali/maven/repository/org/slf4j/slf4j-api/1.5.6 - maven库没有添加jar权限，改为已有的版本绕过
				eg: ls /usr/ali/maven/repository/org/slf4j/slf4j-api


5. 部署说明文档 (测试，部署人员依据此文档操作)
	* 从10.250.8.214机子上拷贝目录measure(/home/admin/measure)到目标机/home/admin目录下，进入该目录 (编译机和运行机都采用上面的目录结构)
	* 执行bulid 目录中的build.sh构建
	* 然后执行build目录下的deploy.sh部署
	* 再执行bin目录下的execute.sh启动和关闭程序，用法如下：
		execute.sh start - 启动程序
		execute.sh stop - 关闭程序
	目录结构说明：
		measure
			- bin 包含执行程序的脚本 execute.sh ，shell执行日志文件server.log,程序的的pid备份server.pid
			- build 包含构建和部署脚本build.sh,deploy.sh
			- config 包含程序配置文件log4j，job，jdbc的属性配置
			- logs 程序执行日志
			- src 存放源码
				- target 打包后的文件(zip)

6. maven换其他环境编译时，依赖找不到解决，看错误日志找到依赖找不到的原因，一般即可解决

7.  shell 脚本  ,字符不认识问题 ，在windows下的文本，通过ssh工具拷贝到linux中后，不能正常执行命令。可能是字符编码或者异常特殊符号(;/r)等问题，可在linux下
新建shell解决，拷贝的一般都有问题。

或者，是因为使用的ssh客户端没设置好，传输时编码问题？从svn下载下来的shell(原在windows下创建)都不能正常执行。 -tip-

原因：unix，dos 字符间需要转换 
	xxx@xxx$ uni
		unicode_start  unicode_stop   uniq           unix2dos       unix_chkpwd
	dos2unix

8. 

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ unix2dos dos2unix
day20 Thursday, April 12, 2012

1.  

2. 
	ls -R 
	shell判断文件是否存在，再做后续操作
		if [ -f urfile ]  then
			./a.sh   
		fi